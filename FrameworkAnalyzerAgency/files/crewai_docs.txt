# Get Execution Status
Source: https://docs.crewai.com/api-reference/get-execution-status

enterprise-api.yaml get /status/{kickoff_id}
**📋 Reference Example Only** - *This shows the request format. To test with your actual crew, copy the cURL example and replace the URL + token with your real values.*

Retrieves the current status and results of a crew execution using its kickoff ID.

The response structure varies depending on the execution state:
- **running**: Execution in progress with current task info
- **completed**: Execution finished with full results
- **error**: Execution failed with error details




# Get Required Inputs
Source: https://docs.crewai.com/api-reference/get-required-inputs

enterprise-api.yaml get /inputs
**📋 Reference Example Only** - *This shows the request format. To test with your actual crew, copy the cURL example and replace the URL + token with your real values.*

Retrieves the list of all required input parameters that your crew expects for execution.
Use this endpoint to discover what inputs you need to provide when starting a crew execution.




# Start Crew Execution
Source: https://docs.crewai.com/api-reference/start-crew-execution

enterprise-api.yaml post /kickoff
**📋 Reference Example Only** - *This shows the request format. To test with your actual crew, copy the cURL example and replace the URL + token with your real values.*

Initiates a new crew execution with the provided inputs. Returns a kickoff ID that can be used
to track the execution progress and retrieve results.

Crew executions can take anywhere from seconds to minutes depending on their complexity.
Consider using webhooks for real-time notifications or implement polling with the status endpoint.




# Introduction
Source: https://docs.crewai.com/en/api-reference/introduction

Complete reference for the CrewAI Enterprise REST API

# CrewAI Enterprise API

Welcome to the CrewAI Enterprise API reference. This API allows you to programmatically interact with your deployed crews, enabling integration with your applications, workflows, and services.

## Quick Start

<Steps>
  <Step title="Get Your API Credentials">
    Navigate to your crew's detail page in the CrewAI Enterprise dashboard and copy your Bearer Token from the Status tab.
  </Step>

  <Step title="Discover Required Inputs">
    Use the `GET /inputs` endpoint to see what parameters your crew expects.
  </Step>

  <Step title="Start a Crew Execution">
    Call `POST /kickoff` with your inputs to start the crew execution and receive a `kickoff_id`.
  </Step>

  <Step title="Monitor Progress">
    Use `GET /status/{kickoff_id}` to check execution status and retrieve results.
  </Step>
</Steps>

## Authentication

All API requests require authentication using a Bearer token. Include your token in the `Authorization` header:

```bash
curl -H "Authorization: Bearer YOUR_CREW_TOKEN" \
  https://your-crew-url.crewai.com/inputs
```

### Token Types

| Token Type            | Scope                     | Use Case                                                     |
| :-------------------- | :------------------------ | :----------------------------------------------------------- |
| **Bearer Token**      | Organization-level access | Full crew operations, ideal for server-to-server integration |
| **User Bearer Token** | User-scoped access        | Limited permissions, suitable for user-specific operations   |

<Tip>
  You can find both token types in the Status tab of your crew's detail page in the CrewAI Enterprise dashboard.
</Tip>

## Base URL

Each deployed crew has its own unique API endpoint:

```
https://your-crew-name.crewai.com
```

Replace `your-crew-name` with your actual crew's URL from the dashboard.

## Typical Workflow

1. **Discovery**: Call `GET /inputs` to understand what your crew needs
2. **Execution**: Submit inputs via `POST /kickoff` to start processing
3. **Monitoring**: Poll `GET /status/{kickoff_id}` until completion
4. **Results**: Extract the final output from the completed response

## Error Handling

The API uses standard HTTP status codes:

| Code  | Meaning                                    |
| ----- | :----------------------------------------- |
| `200` | Success                                    |
| `400` | Bad Request - Invalid input format         |
| `401` | Unauthorized - Invalid bearer token        |
| `404` | Not Found - Resource doesn't exist         |
| `422` | Validation Error - Missing required inputs |
| `500` | Server Error - Contact support             |

## Interactive Testing

<Info>
  **Why no "Send" button?** Since each CrewAI Enterprise user has their own unique crew URL, we use **reference mode** instead of an interactive playground to avoid confusion. This shows you exactly what the requests should look like without non-functional send buttons.
</Info>

Each endpoint page shows you:

* ✅ **Exact request format** with all parameters
* ✅ **Response examples** for success and error cases
* ✅ **Code samples** in multiple languages (cURL, Python, JavaScript, etc.)
* ✅ **Authentication examples** with proper Bearer token format

### **To Test Your Actual API:**

<CardGroup cols={2}>
  <Card title="Copy cURL Examples" icon="terminal">
    Copy the cURL examples and replace the URL + token with your real values
  </Card>

  <Card title="Use Postman/Insomnia" icon="play">
    Import the examples into your preferred API testing tool
  </Card>
</CardGroup>

**Example workflow:**

1. **Copy this cURL example** from any endpoint page
2. **Replace `your-actual-crew-name.crewai.com`** with your real crew URL
3. **Replace the Bearer token** with your real token from the dashboard
4. **Run the request** in your terminal or API client

## Need Help?

<CardGroup cols={2}>
  <Card title="Enterprise Support" icon="headset" href="mailto:support@crewai.com">
    Get help with API integration and troubleshooting
  </Card>

  <Card title="Enterprise Dashboard" icon="chart-line" href="https://app.crewai.com">
    Manage your crews and view execution logs
  </Card>
</CardGroup>


# Agents
Source: https://docs.crewai.com/en/concepts/agents

Detailed guide on creating and managing agents within the CrewAI framework.

## Overview of an Agent

In the CrewAI framework, an `Agent` is an autonomous unit that can:

* Perform specific tasks
* Make decisions based on its role and goal
* Use tools to accomplish objectives
* Communicate and collaborate with other agents
* Maintain memory of interactions
* Delegate tasks when allowed

<Tip>
  Think of an agent as a specialized team member with specific skills, expertise, and responsibilities. For example, a `Researcher` agent might excel at gathering and analyzing information, while a `Writer` agent might be better at creating content.
</Tip>

<Note type="info" title="Enterprise Enhancement: Visual Agent Builder">
  CrewAI Enterprise includes a Visual Agent Builder that simplifies agent creation and configuration without writing code. Design your agents visually and test them in real-time.

  ![Visual Agent Builder Screenshot](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-studio-interface.png)

  The Visual Agent Builder enables:

  * Intuitive agent configuration with form-based interfaces
  * Real-time testing and validation
  * Template library with pre-configured agent types
  * Easy customization of agent attributes and behaviors
</Note>

## Agent Attributes

| Attribute                               | Parameter                | Type                                  | Description                                                                                              |
| :-------------------------------------- | :----------------------- | :------------------------------------ | :------------------------------------------------------------------------------------------------------- |
| **Role**                                | `role`                   | `str`                                 | Defines the agent's function and expertise within the crew.                                              |
| **Goal**                                | `goal`                   | `str`                                 | The individual objective that guides the agent's decision-making.                                        |
| **Backstory**                           | `backstory`              | `str`                                 | Provides context and personality to the agent, enriching interactions.                                   |
| **LLM** *(optional)*                    | `llm`                    | `Union[str, LLM, Any]`                | Language model that powers the agent. Defaults to the model specified in `OPENAI_MODEL_NAME` or "gpt-4". |
| **Tools** *(optional)*                  | `tools`                  | `List[BaseTool]`                      | Capabilities or functions available to the agent. Defaults to an empty list.                             |
| **Function Calling LLM** *(optional)*   | `function_calling_llm`   | `Optional[Any]`                       | Language model for tool calling, overrides crew's LLM if specified.                                      |
| **Max Iterations** *(optional)*         | `max_iter`               | `int`                                 | Maximum iterations before the agent must provide its best answer. Default is 20.                         |
| **Max RPM** *(optional)*                | `max_rpm`                | `Optional[int]`                       | Maximum requests per minute to avoid rate limits.                                                        |
| **Max Execution Time** *(optional)*     | `max_execution_time`     | `Optional[int]`                       | Maximum time (in seconds) for task execution.                                                            |
| **Verbose** *(optional)*                | `verbose`                | `bool`                                | Enable detailed execution logs for debugging. Default is False.                                          |
| **Allow Delegation** *(optional)*       | `allow_delegation`       | `bool`                                | Allow the agent to delegate tasks to other agents. Default is False.                                     |
| **Step Callback** *(optional)*          | `step_callback`          | `Optional[Any]`                       | Function called after each agent step, overrides crew callback.                                          |
| **Cache** *(optional)*                  | `cache`                  | `bool`                                | Enable caching for tool usage. Default is True.                                                          |
| **System Template** *(optional)*        | `system_template`        | `Optional[str]`                       | Custom system prompt template for the agent.                                                             |
| **Prompt Template** *(optional)*        | `prompt_template`        | `Optional[str]`                       | Custom prompt template for the agent.                                                                    |
| **Response Template** *(optional)*      | `response_template`      | `Optional[str]`                       | Custom response template for the agent.                                                                  |
| **Allow Code Execution** *(optional)*   | `allow_code_execution`   | `Optional[bool]`                      | Enable code execution for the agent. Default is False.                                                   |
| **Max Retry Limit** *(optional)*        | `max_retry_limit`        | `int`                                 | Maximum number of retries when an error occurs. Default is 2.                                            |
| **Respect Context Window** *(optional)* | `respect_context_window` | `bool`                                | Keep messages under context window size by summarizing. Default is True.                                 |
| **Code Execution Mode** *(optional)*    | `code_execution_mode`    | `Literal["safe", "unsafe"]`           | Mode for code execution: 'safe' (using Docker) or 'unsafe' (direct). Default is 'safe'.                  |
| **Multimodal** *(optional)*             | `multimodal`             | `bool`                                | Whether the agent supports multimodal capabilities. Default is False.                                    |
| **Inject Date** *(optional)*            | `inject_date`            | `bool`                                | Whether to automatically inject the current date into tasks. Default is False.                           |
| **Date Format** *(optional)*            | `date_format`            | `str`                                 | Format string for date when inject\_date is enabled. Default is "%Y-%m-%d" (ISO format).                 |
| **Reasoning** *(optional)*              | `reasoning`              | `bool`                                | Whether the agent should reflect and create a plan before executing a task. Default is False.            |
| **Max Reasoning Attempts** *(optional)* | `max_reasoning_attempts` | `Optional[int]`                       | Maximum number of reasoning attempts before executing the task. If None, will try until ready.           |
| **Embedder** *(optional)*               | `embedder`               | `Optional[Dict[str, Any]]`            | Configuration for the embedder used by the agent.                                                        |
| **Knowledge Sources** *(optional)*      | `knowledge_sources`      | `Optional[List[BaseKnowledgeSource]]` | Knowledge sources available to the agent.                                                                |
| **Use System Prompt** *(optional)*      | `use_system_prompt`      | `Optional[bool]`                      | Whether to use system prompt (for o1 model support). Default is True.                                    |

## Creating Agents

There are two ways to create agents in CrewAI: using **YAML configuration (recommended)** or defining them **directly in code**.

### YAML Configuration (Recommended)

Using YAML configuration provides a cleaner, more maintainable way to define agents. We strongly recommend using this approach in your CrewAI projects.

After creating your CrewAI project as outlined in the [Installation](/en/installation) section, navigate to the `src/latest_ai_development/config/agents.yaml` file and modify the template to match your requirements.

<Note>
  Variables in your YAML files (like `{topic}`) will be replaced with values from your inputs when running the crew:

  ```python Code
  crew.kickoff(inputs={'topic': 'AI Agents'})
  ```
</Note>

Here's an example of how to configure agents using YAML:

```yaml agents.yaml
# src/latest_ai_development/config/agents.yaml
researcher:
  role: >
    {topic} Senior Data Researcher
  goal: >
    Uncover cutting-edge developments in {topic}
  backstory: >
    You're a seasoned researcher with a knack for uncovering the latest
    developments in {topic}. Known for your ability to find the most relevant
    information and present it in a clear and concise manner.

reporting_analyst:
  role: >
    {topic} Reporting Analyst
  goal: >
    Create detailed reports based on {topic} data analysis and research findings
  backstory: >
    You're a meticulous analyst with a keen eye for detail. You're known for
    your ability to turn complex data into clear and concise reports, making
    it easy for others to understand and act on the information you provide.
```

To use this YAML configuration in your code, create a crew class that inherits from `CrewBase`:

```python Code
# src/latest_ai_development/crew.py
from crewai import Agent, Crew, Process
from crewai.project import CrewBase, agent, crew
from crewai_tools import SerperDevTool

@CrewBase
class LatestAiDevelopmentCrew():
  """LatestAiDevelopment crew"""

  agents_config = "config/agents.yaml"

  @agent
  def researcher(self) -> Agent:
    return Agent(
      config=self.agents_config['researcher'], # type: ignore[index]
      verbose=True,
      tools=[SerperDevTool()]
    )

  @agent
  def reporting_analyst(self) -> Agent:
    return Agent(
      config=self.agents_config['reporting_analyst'], # type: ignore[index]
      verbose=True
    )
```

<Note>
  The names you use in your YAML files (`agents.yaml`) should match the method names in your Python code.
</Note>

### Direct Code Definition

You can create agents directly in code by instantiating the `Agent` class. Here's a comprehensive example showing all available parameters:

```python Code
from crewai import Agent
from crewai_tools import SerperDevTool

# Create an agent with all available parameters
agent = Agent(
    role="Senior Data Scientist",
    goal="Analyze and interpret complex datasets to provide actionable insights",
    backstory="With over 10 years of experience in data science and machine learning, "
              "you excel at finding patterns in complex datasets.",
    llm="gpt-4",  # Default: OPENAI_MODEL_NAME or "gpt-4"
    function_calling_llm=None,  # Optional: Separate LLM for tool calling
    verbose=False,  # Default: False
    allow_delegation=False,  # Default: False
    max_iter=20,  # Default: 20 iterations
    max_rpm=None,  # Optional: Rate limit for API calls
    max_execution_time=None,  # Optional: Maximum execution time in seconds
    max_retry_limit=2,  # Default: 2 retries on error
    allow_code_execution=False,  # Default: False
    code_execution_mode="safe",  # Default: "safe" (options: "safe", "unsafe")
    respect_context_window=True,  # Default: True
    use_system_prompt=True,  # Default: True
    multimodal=False,  # Default: False
    inject_date=False,  # Default: False
    date_format="%Y-%m-%d",  # Default: ISO format
    reasoning=False,  # Default: False
    max_reasoning_attempts=None,  # Default: None
    tools=[SerperDevTool()],  # Optional: List of tools
    knowledge_sources=None,  # Optional: List of knowledge sources
    embedder=None,  # Optional: Custom embedder configuration
    system_template=None,  # Optional: Custom system prompt template
    prompt_template=None,  # Optional: Custom prompt template
    response_template=None,  # Optional: Custom response template
    step_callback=None,  # Optional: Callback function for monitoring
)
```

Let's break down some key parameter combinations for common use cases:

#### Basic Research Agent

```python Code
research_agent = Agent(
    role="Research Analyst",
    goal="Find and summarize information about specific topics",
    backstory="You are an experienced researcher with attention to detail",
    tools=[SerperDevTool()],
    verbose=True  # Enable logging for debugging
)
```

#### Code Development Agent

```python Code
dev_agent = Agent(
    role="Senior Python Developer",
    goal="Write and debug Python code",
    backstory="Expert Python developer with 10 years of experience",
    allow_code_execution=True,
    code_execution_mode="safe",  # Uses Docker for safety
    max_execution_time=300,  # 5-minute timeout
    max_retry_limit=3  # More retries for complex code tasks
)
```

#### Long-Running Analysis Agent

```python Code
analysis_agent = Agent(
    role="Data Analyst",
    goal="Perform deep analysis of large datasets",
    backstory="Specialized in big data analysis and pattern recognition",
    memory=True,
    respect_context_window=True,
    max_rpm=10,  # Limit API calls
    function_calling_llm="gpt-4o-mini"  # Cheaper model for tool calls
)
```

#### Custom Template Agent

```python Code
custom_agent = Agent(
    role="Customer Service Representative",
    goal="Assist customers with their inquiries",
    backstory="Experienced in customer support with a focus on satisfaction",
    system_template="""<|start_header_id|>system<|end_header_id|>
                        {{ .System }}<|eot_id|>""",
    prompt_template="""<|start_header_id|>user<|end_header_id|>
                        {{ .Prompt }}<|eot_id|>""",
    response_template="""<|start_header_id|>assistant<|end_header_id|>
                        {{ .Response }}<|eot_id|>""",
)
```

#### Date-Aware Agent with Reasoning

```python Code
strategic_agent = Agent(
    role="Market Analyst",
    goal="Track market movements with precise date references and strategic planning",
    backstory="Expert in time-sensitive financial analysis and strategic reporting",
    inject_date=True,  # Automatically inject current date into tasks
    date_format="%B %d, %Y",  # Format as "May 21, 2025"
    reasoning=True,  # Enable strategic planning
    max_reasoning_attempts=2,  # Limit planning iterations
    verbose=True
)
```

#### Reasoning Agent

```python Code
reasoning_agent = Agent(
    role="Strategic Planner",
    goal="Analyze complex problems and create detailed execution plans",
    backstory="Expert strategic planner who methodically breaks down complex challenges",
    reasoning=True,  # Enable reasoning and planning
    max_reasoning_attempts=3,  # Limit reasoning attempts
    max_iter=30,  # Allow more iterations for complex planning
    verbose=True
)
```

#### Multimodal Agent

```python Code
multimodal_agent = Agent(
    role="Visual Content Analyst",
    goal="Analyze and process both text and visual content",
    backstory="Specialized in multimodal analysis combining text and image understanding",
    multimodal=True,  # Enable multimodal capabilities
    verbose=True
)
```

### Parameter Details

#### Critical Parameters

* `role`, `goal`, and `backstory` are required and shape the agent's behavior
* `llm` determines the language model used (default: OpenAI's GPT-4)

#### Memory and Context

* `memory`: Enable to maintain conversation history
* `respect_context_window`: Prevents token limit issues
* `knowledge_sources`: Add domain-specific knowledge bases

#### Execution Control

* `max_iter`: Maximum attempts before giving best answer
* `max_execution_time`: Timeout in seconds
* `max_rpm`: Rate limiting for API calls
* `max_retry_limit`: Retries on error

#### Code Execution

* `allow_code_execution`: Must be True to run code
* `code_execution_mode`:
  * `"safe"`: Uses Docker (recommended for production)
  * `"unsafe"`: Direct execution (use only in trusted environments)

<Note>
  This runs a default Docker image. If you want to configure the docker image, the checkout the Code Interpreter Tool in the tools section.
  Add the code interpreter tool as a tool in the agent as a tool parameter.
</Note>

#### Advanced Features

* `multimodal`: Enable multimodal capabilities for processing text and visual content
* `reasoning`: Enable agent to reflect and create plans before executing tasks
* `inject_date`: Automatically inject current date into task descriptions

#### Templates

* `system_template`: Defines agent's core behavior
* `prompt_template`: Structures input format
* `response_template`: Formats agent responses

<Note>
  When using custom templates, ensure that both `system_template` and `prompt_template` are defined. The `response_template` is optional but recommended for consistent output formatting.
</Note>

<Note>
  When using custom templates, you can use variables like `{role}`, `{goal}`, and `{backstory}` in your templates. These will be automatically populated during execution.
</Note>

## Agent Tools

Agents can be equipped with various tools to enhance their capabilities. CrewAI supports tools from:

* [CrewAI Toolkit](https://github.com/joaomdmoura/crewai-tools)
* [LangChain Tools](https://python.langchain.com/docs/integrations/tools)

Here's how to add tools to an agent:

```python Code
from crewai import Agent
from crewai_tools import SerperDevTool, WikipediaTools

# Create tools
search_tool = SerperDevTool()
wiki_tool = WikipediaTools()

# Add tools to agent
researcher = Agent(
    role="AI Technology Researcher",
    goal="Research the latest AI developments",
    tools=[search_tool, wiki_tool],
    verbose=True
)
```

## Agent Memory and Context

Agents can maintain memory of their interactions and use context from previous tasks. This is particularly useful for complex workflows where information needs to be retained across multiple tasks.

```python Code
from crewai import Agent

analyst = Agent(
    role="Data Analyst",
    goal="Analyze and remember complex data patterns",
    memory=True,  # Enable memory
    verbose=True
)
```

<Note>
  When `memory` is enabled, the agent will maintain context across multiple interactions, improving its ability to handle complex, multi-step tasks.
</Note>

## Context Window Management

CrewAI includes sophisticated automatic context window management to handle situations where conversations exceed the language model's token limits. This powerful feature is controlled by the `respect_context_window` parameter.

### How Context Window Management Works

When an agent's conversation history grows too large for the LLM's context window, CrewAI automatically detects this situation and can either:

1. **Automatically summarize content** (when `respect_context_window=True`)
2. **Stop execution with an error** (when `respect_context_window=False`)

### Automatic Context Handling (`respect_context_window=True`)

This is the **default and recommended setting** for most use cases. When enabled, CrewAI will:

```python Code
# Agent with automatic context management (default)
smart_agent = Agent(
    role="Research Analyst",
    goal="Analyze large documents and datasets",
    backstory="Expert at processing extensive information",
    respect_context_window=True,  # 🔑 Default: auto-handle context limits
    verbose=True
)
```

**What happens when context limits are exceeded:**

* ⚠️ **Warning message**: `"Context length exceeded. Summarizing content to fit the model context window."`
* 🔄 **Automatic summarization**: CrewAI intelligently summarizes the conversation history
* ✅ **Continued execution**: Task execution continues seamlessly with the summarized context
* 📝 **Preserved information**: Key information is retained while reducing token count

### Strict Context Limits (`respect_context_window=False`)

When you need precise control and prefer execution to stop rather than lose any information:

```python Code
# Agent with strict context limits
strict_agent = Agent(
    role="Legal Document Reviewer",
    goal="Provide precise legal analysis without information loss",
    backstory="Legal expert requiring complete context for accurate analysis",
    respect_context_window=False,  # ❌ Stop execution on context limit
    verbose=True
)
```

**What happens when context limits are exceeded:**

* ❌ **Error message**: `"Context length exceeded. Consider using smaller text or RAG tools from crewai_tools."`
* 🛑 **Execution stops**: Task execution halts immediately
* 🔧 **Manual intervention required**: You need to modify your approach

### Choosing the Right Setting

#### Use `respect_context_window=True` (Default) when:

* **Processing large documents** that might exceed context limits
* **Long-running conversations** where some summarization is acceptable
* **Research tasks** where general context is more important than exact details
* **Prototyping and development** where you want robust execution

```python Code
# Perfect for document processing
document_processor = Agent(
    role="Document Analyst",
    goal="Extract insights from large research papers",
    backstory="Expert at analyzing extensive documentation",
    respect_context_window=True,  # Handle large documents gracefully
    max_iter=50,  # Allow more iterations for complex analysis
    verbose=True
)
```

#### Use `respect_context_window=False` when:

* **Precision is critical** and information loss is unacceptable
* **Legal or medical tasks** requiring complete context
* **Code review** where missing details could introduce bugs
* **Financial analysis** where accuracy is paramount

```python Code
# Perfect for precision tasks
precision_agent = Agent(
    role="Code Security Auditor",
    goal="Identify security vulnerabilities in code",
    backstory="Security expert requiring complete code context",
    respect_context_window=False,  # Prefer failure over incomplete analysis
    max_retry_limit=1,  # Fail fast on context issues
    verbose=True
)
```

### Alternative Approaches for Large Data

When dealing with very large datasets, consider these strategies:

#### 1. Use RAG Tools

```python Code
from crewai_tools import RagTool

# Create RAG tool for large document processing
rag_tool = RagTool()

rag_agent = Agent(
    role="Research Assistant",
    goal="Query large knowledge bases efficiently",
    backstory="Expert at using RAG tools for information retrieval",
    tools=[rag_tool],  # Use RAG instead of large context windows
    respect_context_window=True,
    verbose=True
)
```

#### 2. Use Knowledge Sources

```python Code
# Use knowledge sources instead of large prompts
knowledge_agent = Agent(
    role="Knowledge Expert",
    goal="Answer questions using curated knowledge",
    backstory="Expert at leveraging structured knowledge sources",
    knowledge_sources=[your_knowledge_sources],  # Pre-processed knowledge
    respect_context_window=True,
    verbose=True
)
```

### Context Window Best Practices

1. **Monitor Context Usage**: Enable `verbose=True` to see context management in action
2. **Design for Efficiency**: Structure tasks to minimize context accumulation
3. **Use Appropriate Models**: Choose LLMs with context windows suitable for your tasks
4. **Test Both Settings**: Try both `True` and `False` to see which works better for your use case
5. **Combine with RAG**: Use RAG tools for very large datasets instead of relying solely on context windows

### Troubleshooting Context Issues

**If you're getting context limit errors:**

```python Code
# Quick fix: Enable automatic handling
agent.respect_context_window = True

# Better solution: Use RAG tools for large data
from crewai_tools import RagTool
agent.tools = [RagTool()]

# Alternative: Break tasks into smaller pieces
# Or use knowledge sources instead of large prompts
```

**If automatic summarization loses important information:**

```python Code
# Disable auto-summarization and use RAG instead
agent = Agent(
    role="Detailed Analyst",
    goal="Maintain complete information accuracy",
    backstory="Expert requiring full context",
    respect_context_window=False,  # No summarization
    tools=[RagTool()],  # Use RAG for large data
    verbose=True
)
```

<Note>
  The context window management feature works automatically in the background. You don't need to call any special functions - just set `respect_context_window` to your preferred behavior and CrewAI handles the rest!
</Note>

## Important Considerations and Best Practices

### Security and Code Execution

* When using `allow_code_execution`, be cautious with user input and always validate it
* Use `code_execution_mode: "safe"` (Docker) in production environments
* Consider setting appropriate `max_execution_time` limits to prevent infinite loops

### Performance Optimization

* Use `respect_context_window: true` to prevent token limit issues
* Set appropriate `max_rpm` to avoid rate limiting
* Enable `cache: true` to improve performance for repetitive tasks
* Adjust `max_iter` and `max_retry_limit` based on task complexity

### Memory and Context Management

* Leverage `knowledge_sources` for domain-specific information
* Configure `embedder` when using custom embedding models
* Use custom templates (`system_template`, `prompt_template`, `response_template`) for fine-grained control over agent behavior

### Advanced Features

* Enable `reasoning: true` for agents that need to plan and reflect before executing complex tasks
* Set appropriate `max_reasoning_attempts` to control planning iterations (None for unlimited attempts)
* Use `inject_date: true` to provide agents with current date awareness for time-sensitive tasks
* Customize the date format with `date_format` using standard Python datetime format codes
* Enable `multimodal: true` for agents that need to process both text and visual content

### Agent Collaboration

* Enable `allow_delegation: true` when agents need to work together
* Use `step_callback` to monitor and log agent interactions
* Consider using different LLMs for different purposes:
  * Main `llm` for complex reasoning
  * `function_calling_llm` for efficient tool usage

### Date Awareness and Reasoning

* Use `inject_date: true` to provide agents with current date awareness for time-sensitive tasks
* Customize the date format with `date_format` using standard Python datetime format codes
* Valid format codes include: %Y (year), %m (month), %d (day), %B (full month name), etc.
* Invalid date formats will be logged as warnings and will not modify the task description
* Enable `reasoning: true` for complex tasks that benefit from upfront planning and reflection

### Model Compatibility

* Set `use_system_prompt: false` for older models that don't support system messages
* Ensure your chosen `llm` supports the features you need (like function calling)

## Troubleshooting Common Issues

1. **Rate Limiting**: If you're hitting API rate limits:
   * Implement appropriate `max_rpm`
   * Use caching for repetitive operations
   * Consider batching requests

2. **Context Window Errors**: If you're exceeding context limits:
   * Enable `respect_context_window`
   * Use more efficient prompts
   * Clear agent memory periodically

3. **Code Execution Issues**: If code execution fails:
   * Verify Docker is installed for safe mode
   * Check execution permissions
   * Review code sandbox settings

4. **Memory Issues**: If agent responses seem inconsistent:
   * Check knowledge source configuration
   * Review conversation history management

Remember that agents are most effective when configured according to their specific use case. Take time to understand your requirements and adjust these parameters accordingly.


# CLI
Source: https://docs.crewai.com/en/concepts/cli

Learn how to use the CrewAI CLI to interact with CrewAI.

<Warning>Since release 0.140.0, CrewAI Enterprise started a process of migrating their login provider. As such, the authentication flow via CLI was updated. Users that use Google to login, or that created their account after July 3rd, 2025 will be unable to log in with older versions of the `crewai` library.</Warning>

## Overview

The CrewAI CLI provides a set of commands to interact with CrewAI, allowing you to create, train, run, and manage crews & flows.

## Installation

To use the CrewAI CLI, make sure you have CrewAI installed:

```shell Terminal
pip install crewai
```

## Basic Usage

The basic structure of a CrewAI CLI command is:

```shell Terminal
crewai [COMMAND] [OPTIONS] [ARGUMENTS]
```

## Available Commands

### 1. Create

Create a new crew or flow.

```shell Terminal
crewai create [OPTIONS] TYPE NAME
```

* `TYPE`: Choose between "crew" or "flow"
* `NAME`: Name of the crew or flow

Example:

```shell Terminal
crewai create crew my_new_crew
crewai create flow my_new_flow
```

### 2. Version

Show the installed version of CrewAI.

```shell Terminal
crewai version [OPTIONS]
```

* `--tools`: (Optional) Show the installed version of CrewAI tools

Example:

```shell Terminal
crewai version
crewai version --tools
```

### 3. Train

Train the crew for a specified number of iterations.

```shell Terminal
crewai train [OPTIONS]
```

* `-n, --n_iterations INTEGER`: Number of iterations to train the crew (default: 5)
* `-f, --filename TEXT`: Path to a custom file for training (default: "trained\_agents\_data.pkl")

Example:

```shell Terminal
crewai train -n 10 -f my_training_data.pkl
```

### 4. Replay

Replay the crew execution from a specific task.

```shell Terminal
crewai replay [OPTIONS]
```

* `-t, --task_id TEXT`: Replay the crew from this task ID, including all subsequent tasks

Example:

```shell Terminal
crewai replay -t task_123456
```

### 5. Log-tasks-outputs

Retrieve your latest crew\.kickoff() task outputs.

```shell Terminal
crewai log-tasks-outputs
```

### 6. Reset-memories

Reset the crew memories (long, short, entity, latest\_crew\_kickoff\_outputs).

```shell Terminal
crewai reset-memories [OPTIONS]
```

* `-l, --long`: Reset LONG TERM memory
* `-s, --short`: Reset SHORT TERM memory
* `-e, --entities`: Reset ENTITIES memory
* `-k, --kickoff-outputs`: Reset LATEST KICKOFF TASK OUTPUTS
* `-kn, --knowledge`: Reset KNOWLEDGE storage
* `-akn, --agent-knowledge`: Reset AGENT KNOWLEDGE storage
* `-a, --all`: Reset ALL memories

Example:

```shell Terminal
crewai reset-memories --long --short
crewai reset-memories --all
```

### 7. Test

Test the crew and evaluate the results.

```shell Terminal
crewai test [OPTIONS]
```

* `-n, --n_iterations INTEGER`: Number of iterations to test the crew (default: 3)
* `-m, --model TEXT`: LLM Model to run the tests on the Crew (default: "gpt-4o-mini")

Example:

```shell Terminal
crewai test -n 5 -m gpt-3.5-turbo
```

### 8. Run

Run the crew or flow.

```shell Terminal
crewai run
```

<Note>
  Starting from version 0.103.0, the `crewai run` command can be used to run both standard crews and flows. For flows, it automatically detects the type from pyproject.toml and runs the appropriate command. This is now the recommended way to run both crews and flows.
</Note>

<Note>
  Make sure to run these commands from the directory where your CrewAI project is set up.
  Some commands may require additional configuration or setup within your project structure.
</Note>

### 9. Chat

Starting in version `0.98.0`, when you run the `crewai chat` command, you start an interactive session with your crew. The AI assistant will guide you by asking for necessary inputs to execute the crew. Once all inputs are provided, the crew will execute its tasks.

After receiving the results, you can continue interacting with the assistant for further instructions or questions.

```shell Terminal
crewai chat
```

<Note>
  Ensure you execute these commands from your CrewAI project's root directory.
</Note>

<Note>
  IMPORTANT: Set the `chat_llm` property in your `crew.py` file to enable this command.

  ```python
  @crew
  def crew(self) -> Crew:
      return Crew(
          agents=self.agents,
          tasks=self.tasks,
          process=Process.sequential,
          verbose=True,
          chat_llm="gpt-4o",  # LLM for chat orchestration
      )
  ```
</Note>

### 10. Deploy

Deploy the crew or flow to [CrewAI Enterprise](https://app.crewai.com).

* **Authentication**: You need to be authenticated to deploy to CrewAI Enterprise.
  You can login or create an account with:
  ```shell Terminal
  crewai login
  ```

* **Create a deployment**: Once you are authenticated, you can create a deployment for your crew or flow from the root of your localproject.
  ```shell Terminal
  crewai deploy create
  ```
  * Reads your local project configuration.
  * Prompts you to confirm the environment variables (like `OPENAI_API_KEY`, `SERPER_API_KEY`) found locally. These will be securely stored with the deployment on the Enterprise platform. Ensure your sensitive keys are correctly configured locally (e.g., in a `.env` file) before running this.

### 11. Organization Management

Manage your CrewAI Enterprise organizations.

```shell Terminal
crewai org [COMMAND] [OPTIONS]
```

#### Commands:

* `list`: List all organizations you belong to

```shell Terminal
crewai org list
```

* `current`: Display your currently active organization

```shell Terminal
crewai org current
```

* `switch`: Switch to a specific organization

```shell Terminal
crewai org switch <organization_id>
```

<Note>
  You must be authenticated to CrewAI Enterprise to use these organization management commands.
</Note>

* **Create a deployment** (continued):
  * Links the deployment to the corresponding remote GitHub repository (it usually detects this automatically).

* **Deploy the Crew**: Once you are authenticated, you can deploy your crew or flow to CrewAI Enterprise.
  ```shell Terminal
  crewai deploy push
  ```
  * Initiates the deployment process on the CrewAI Enterprise platform.
  * Upon successful initiation, it will output the Deployment created successfully! message along with the Deployment Name and a unique Deployment ID (UUID).

* **Deployment Status**: You can check the status of your deployment with:
  ```shell Terminal
  crewai deploy status
  ```
  This fetches the latest deployment status of your most recent deployment attempt (e.g., `Building Images for Crew`, `Deploy Enqueued`, `Online`).

* **Deployment Logs**: You can check the logs of your deployment with:
  ```shell Terminal
  crewai deploy logs
  ```
  This streams the deployment logs to your terminal.

* **List deployments**: You can list all your deployments with:
  ```shell Terminal
  crewai deploy list
  ```
  This lists all your deployments.

* **Delete a deployment**: You can delete a deployment with:
  ```shell Terminal
  crewai deploy remove
  ```
  This deletes the deployment from the CrewAI Enterprise platform.

* **Help Command**: You can get help with the CLI with:
  ```shell Terminal
  crewai deploy --help
  ```
  This shows the help message for the CrewAI Deploy CLI.

Watch this video tutorial for a step-by-step demonstration of deploying your crew to [CrewAI Enterprise](http://app.crewai.com) using the CLI.

<iframe width="100%" height="400" src="https://www.youtube.com/embed/3EqSV-CYDZA" title="CrewAI Deployment Guide" frameborder="0" style={{ borderRadius: '10px' }} allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

### 11. API Keys

When running `crewai create crew` command, the CLI will show you a list of available LLM providers to choose from, followed by model selection for your chosen provider.

Once you've selected an LLM provider and model, you will be prompted for API keys.

#### Available LLM Providers

Here's a list of the most popular LLM providers suggested by the CLI:

* OpenAI
* Groq
* Anthropic
* Google Gemini
* SambaNova

When you select a provider, the CLI will then show you available models for that provider and prompt you to enter your API key.

#### Other Options

If you select "other", you will be able to select from a list of LiteLLM supported providers.

When you select a provider, the CLI will prompt you to enter the Key name and the API key.

See the following link for each provider's key name:

* [LiteLLM Providers](https://docs.litellm.ai/docs/providers)


# Collaboration
Source: https://docs.crewai.com/en/concepts/collaboration

How to enable agents to work together, delegate tasks, and communicate effectively within CrewAI teams.

## Overview

Collaboration in CrewAI enables agents to work together as a team by delegating tasks and asking questions to leverage each other's expertise. When `allow_delegation=True`, agents automatically gain access to powerful collaboration tools.

## Quick Start: Enable Collaboration

```python
from crewai import Agent, Crew, Task

# Enable collaboration for agents
researcher = Agent(
    role="Research Specialist",
    goal="Conduct thorough research on any topic",
    backstory="Expert researcher with access to various sources",
    allow_delegation=True,  # 🔑 Key setting for collaboration
    verbose=True
)

writer = Agent(
    role="Content Writer",
    goal="Create engaging content based on research",
    backstory="Skilled writer who transforms research into compelling content",
    allow_delegation=True,  # 🔑 Enables asking questions to other agents
    verbose=True
)

# Agents can now collaborate automatically
crew = Crew(
    agents=[researcher, writer],
    tasks=[...],
    verbose=True
)
```

## How Agent Collaboration Works

When `allow_delegation=True`, CrewAI automatically provides agents with two powerful tools:

### 1. **Delegate Work Tool**

Allows agents to assign tasks to teammates with specific expertise.

```python
# Agent automatically gets this tool:
# Delegate work to coworker(task: str, context: str, coworker: str)
```

### 2. **Ask Question Tool**

Enables agents to ask specific questions to gather information from colleagues.

```python
# Agent automatically gets this tool:
# Ask question to coworker(question: str, context: str, coworker: str)
```

## Collaboration in Action

Here's a complete example showing agents collaborating on a content creation task:

```python
from crewai import Agent, Crew, Task, Process

# Create collaborative agents
researcher = Agent(
    role="Research Specialist",
    goal="Find accurate, up-to-date information on any topic",
    backstory="""You're a meticulous researcher with expertise in finding
    reliable sources and fact-checking information across various domains.""",
    allow_delegation=True,
    verbose=True
)

writer = Agent(
    role="Content Writer",
    goal="Create engaging, well-structured content",
    backstory="""You're a skilled content writer who excels at transforming
    research into compelling, readable content for different audiences.""",
    allow_delegation=True,
    verbose=True
)

editor = Agent(
    role="Content Editor",
    goal="Ensure content quality and consistency",
    backstory="""You're an experienced editor with an eye for detail,
    ensuring content meets high standards for clarity and accuracy.""",
    allow_delegation=True,
    verbose=True
)

# Create a task that encourages collaboration
article_task = Task(
    description="""Write a comprehensive 1000-word article about 'The Future of AI in Healthcare'.

    The article should include:
    - Current AI applications in healthcare
    - Emerging trends and technologies
    - Potential challenges and ethical considerations
    - Expert predictions for the next 5 years

    Collaborate with your teammates to ensure accuracy and quality.""",
    expected_output="A well-researched, engaging 1000-word article with proper structure and citations",
    agent=writer  # Writer leads, but can delegate research to researcher
)

# Create collaborative crew
crew = Crew(
    agents=[researcher, writer, editor],
    tasks=[article_task],
    process=Process.sequential,
    verbose=True
)

result = crew.kickoff()
```

## Collaboration Patterns

### Pattern 1: Research → Write → Edit

```python
research_task = Task(
    description="Research the latest developments in quantum computing",
    expected_output="Comprehensive research summary with key findings and sources",
    agent=researcher
)

writing_task = Task(
    description="Write an article based on the research findings",
    expected_output="Engaging 800-word article about quantum computing",
    agent=writer,
    context=[research_task]  # Gets research output as context
)

editing_task = Task(
    description="Edit and polish the article for publication",
    expected_output="Publication-ready article with improved clarity and flow",
    agent=editor,
    context=[writing_task]  # Gets article draft as context
)
```

### Pattern 2: Collaborative Single Task

```python
collaborative_task = Task(
    description="""Create a marketing strategy for a new AI product.

    Writer: Focus on messaging and content strategy
    Researcher: Provide market analysis and competitor insights

    Work together to create a comprehensive strategy.""",
    expected_output="Complete marketing strategy with research backing",
    agent=writer  # Lead agent, but can delegate to researcher
)
```

## Hierarchical Collaboration

For complex projects, use a hierarchical process with a manager agent:

```python
from crewai import Agent, Crew, Task, Process

# Manager agent coordinates the team
manager = Agent(
    role="Project Manager",
    goal="Coordinate team efforts and ensure project success",
    backstory="Experienced project manager skilled at delegation and quality control",
    allow_delegation=True,
    verbose=True
)

# Specialist agents
researcher = Agent(
    role="Researcher",
    goal="Provide accurate research and analysis",
    backstory="Expert researcher with deep analytical skills",
    allow_delegation=False,  # Specialists focus on their expertise
    verbose=True
)

writer = Agent(
    role="Writer",
    goal="Create compelling content",
    backstory="Skilled writer who creates engaging content",
    allow_delegation=False,
    verbose=True
)

# Manager-led task
project_task = Task(
    description="Create a comprehensive market analysis report with recommendations",
    expected_output="Executive summary, detailed analysis, and strategic recommendations",
    agent=manager  # Manager will delegate to specialists
)

# Hierarchical crew
crew = Crew(
    agents=[manager, researcher, writer],
    tasks=[project_task],
    process=Process.hierarchical,  # Manager coordinates everything
    manager_llm="gpt-4o",  # Specify LLM for manager
    verbose=True
)
```

## Best Practices for Collaboration

### 1. **Clear Role Definition**

```python
# ✅ Good: Specific, complementary roles
researcher = Agent(role="Market Research Analyst", ...)
writer = Agent(role="Technical Content Writer", ...)

# ❌ Avoid: Overlapping or vague roles
agent1 = Agent(role="General Assistant", ...)
agent2 = Agent(role="Helper", ...)
```

### 2. **Strategic Delegation Enabling**

```python
# ✅ Enable delegation for coordinators and generalists
lead_agent = Agent(
    role="Content Lead",
    allow_delegation=True,  # Can delegate to specialists
    ...
)

# ✅ Disable for focused specialists (optional)
specialist_agent = Agent(
    role="Data Analyst",
    allow_delegation=False,  # Focuses on core expertise
    ...
)
```

### 3. **Context Sharing**

```python
# ✅ Use context parameter for task dependencies
writing_task = Task(
    description="Write article based on research",
    agent=writer,
    context=[research_task],  # Shares research results
    ...
)
```

### 4. **Clear Task Descriptions**

```python
# ✅ Specific, actionable descriptions
Task(
    description="""Research competitors in the AI chatbot space.
    Focus on: pricing models, key features, target markets.
    Provide data in a structured format.""",
    ...
)

# ❌ Vague descriptions that don't guide collaboration
Task(description="Do some research about chatbots", ...)
```

## Troubleshooting Collaboration

### Issue: Agents Not Collaborating

**Symptoms:** Agents work in isolation, no delegation occurs

```python
# ✅ Solution: Ensure delegation is enabled
agent = Agent(
    role="...",
    allow_delegation=True,  # This is required!
    ...
)
```

### Issue: Too Much Back-and-Forth

**Symptoms:** Agents ask excessive questions, slow progress

```python
# ✅ Solution: Provide better context and specific roles
Task(
    description="""Write a technical blog post about machine learning.

    Context: Target audience is software developers with basic ML knowledge.
    Length: 1200 words
    Include: code examples, practical applications, best practices

    If you need specific technical details, delegate research to the researcher.""",
    ...
)
```

### Issue: Delegation Loops

**Symptoms:** Agents delegate back and forth indefinitely

```python
# ✅ Solution: Clear hierarchy and responsibilities
manager = Agent(role="Manager", allow_delegation=True)
specialist1 = Agent(role="Specialist A", allow_delegation=False)  # No re-delegation
specialist2 = Agent(role="Specialist B", allow_delegation=False)
```

## Advanced Collaboration Features

### Custom Collaboration Rules

```python
# Set specific collaboration guidelines in agent backstory
agent = Agent(
    role="Senior Developer",
    backstory="""You lead development projects and coordinate with team members.

    Collaboration guidelines:
    - Delegate research tasks to the Research Analyst
    - Ask the Designer for UI/UX guidance
    - Consult the QA Engineer for testing strategies
    - Only escalate blocking issues to the Project Manager""",
    allow_delegation=True
)
```

### Monitoring Collaboration

```python
def track_collaboration(output):
    """Track collaboration patterns"""
    if "Delegate work to coworker" in output.raw:
        print("🤝 Delegation occurred")
    if "Ask question to coworker" in output.raw:
        print("❓ Question asked")

crew = Crew(
    agents=[...],
    tasks=[...],
    step_callback=track_collaboration,  # Monitor collaboration
    verbose=True
)
```

## Memory and Learning

Enable agents to remember past collaborations:

```python
agent = Agent(
    role="Content Lead",
    memory=True,  # Remembers past interactions
    allow_delegation=True,
    verbose=True
)
```

With memory enabled, agents learn from previous collaborations and improve their delegation decisions over time.

## Next Steps

* **Try the examples**: Start with the basic collaboration example
* **Experiment with roles**: Test different agent role combinations
* **Monitor interactions**: Use `verbose=True` to see collaboration in action
* **Optimize task descriptions**: Clear tasks lead to better collaboration
* **Scale up**: Try hierarchical processes for complex projects

Collaboration transforms individual AI agents into powerful teams that can tackle complex, multi-faceted challenges together.


# Crews
Source: https://docs.crewai.com/en/concepts/crews

Understanding and utilizing crews in the crewAI framework with comprehensive attributes and functionalities.

## Overview

A crew in crewAI represents a collaborative group of agents working together to achieve a set of tasks. Each crew defines the strategy for task execution, agent collaboration, and the overall workflow.

## Crew Attributes

| Attribute                             | Parameters             | Description                                                                                                                                                                                           |
| :------------------------------------ | :--------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Tasks**                             | `tasks`                | A list of tasks assigned to the crew.                                                                                                                                                                 |
| **Agents**                            | `agents`               | A list of agents that are part of the crew.                                                                                                                                                           |
| **Process** *(optional)*              | `process`              | The process flow (e.g., sequential, hierarchical) the crew follows. Default is `sequential`.                                                                                                          |
| **Verbose** *(optional)*              | `verbose`              | The verbosity level for logging during execution. Defaults to `False`.                                                                                                                                |
| **Manager LLM** *(optional)*          | `manager_llm`          | The language model used by the manager agent in a hierarchical process. **Required when using a hierarchical process.**                                                                               |
| **Function Calling LLM** *(optional)* | `function_calling_llm` | If passed, the crew will use this LLM to do function calling for tools for all agents in the crew. Each agent can have its own LLM, which overrides the crew's LLM for function calling.              |
| **Config** *(optional)*               | `config`               | Optional configuration settings for the crew, in `Json` or `Dict[str, Any]` format.                                                                                                                   |
| **Max RPM** *(optional)*              | `max_rpm`              | Maximum requests per minute the crew adheres to during execution. Defaults to `None`.                                                                                                                 |
| **Memory** *(optional)*               | `memory`               | Utilized for storing execution memories (short-term, long-term, entity memory).                                                                                                                       |
| **Memory Config** *(optional)*        | `memory_config`        | Configuration for the memory provider to be used by the crew.                                                                                                                                         |
| **Cache** *(optional)*                | `cache`                | Specifies whether to use a cache for storing the results of tools' execution. Defaults to `True`.                                                                                                     |
| **Embedder** *(optional)*             | `embedder`             | Configuration for the embedder to be used by the crew. Mostly used by memory for now. Default is `{"provider": "openai"}`.                                                                            |
| **Step Callback** *(optional)*        | `step_callback`        | A function that is called after each step of every agent. This can be used to log the agent's actions or to perform other operations; it won't override the agent-specific `step_callback`.           |
| **Task Callback** *(optional)*        | `task_callback`        | A function that is called after the completion of each task. Useful for monitoring or additional operations post-task execution.                                                                      |
| **Share Crew** *(optional)*           | `share_crew`           | Whether you want to share the complete crew information and execution with the crewAI team to make the library better, and allow us to train models.                                                  |
| **Output Log File** *(optional)*      | `output_log_file`      | Set to True to save logs as logs.txt in the current directory or provide a file path. Logs will be in JSON format if the filename ends in .json, otherwise .txt. Defaults to `None`.                  |
| **Manager Agent** *(optional)*        | `manager_agent`        | `manager` sets a custom agent that will be used as a manager.                                                                                                                                         |
| **Prompt File** *(optional)*          | `prompt_file`          | Path to the prompt JSON file to be used for the crew.                                                                                                                                                 |
| **Planning** *(optional)*             | `planning`             | Adds planning ability to the Crew. When activated before each Crew iteration, all Crew data is sent to an AgentPlanner that will plan the tasks and this plan will be added to each task description. |
| **Planning LLM** *(optional)*         | `planning_llm`         | The language model used by the AgentPlanner in a planning process.                                                                                                                                    |

<Tip>
  **Crew Max RPM**: The `max_rpm` attribute sets the maximum number of requests per minute the crew can perform to avoid rate limits and will override individual agents' `max_rpm` settings if you set it.
</Tip>

## Creating Crews

There are two ways to create crews in CrewAI: using **YAML configuration (recommended)** or defining them **directly in code**.

### YAML Configuration (Recommended)

Using YAML configuration provides a cleaner, more maintainable way to define crews and is consistent with how agents and tasks are defined in CrewAI projects.

After creating your CrewAI project as outlined in the [Installation](/en/installation) section, you can define your crew in a class that inherits from `CrewBase` and uses decorators to define agents, tasks, and the crew itself.

#### Example Crew Class with Decorators

```python code
from crewai import Agent, Crew, Task, Process
from crewai.project import CrewBase, agent, task, crew, before_kickoff, after_kickoff
from crewai.agents.agent_builder.base_agent import BaseAgent
from typing import List

@CrewBase
class YourCrewName:
    """Description of your crew"""

    agents: List[BaseAgent]
    tasks: List[Task]

    # Paths to your YAML configuration files
    # To see an example agent and task defined in YAML, checkout the following:
    # - Task: https://docs.crewai.com/concepts/tasks#yaml-configuration-recommended
    # - Agents: https://docs.crewai.com/concepts/agents#yaml-configuration-recommended
    agents_config = 'config/agents.yaml'
    tasks_config = 'config/tasks.yaml'

    @before_kickoff
    def prepare_inputs(self, inputs):
        # Modify inputs before the crew starts
        inputs['additional_data'] = "Some extra information"
        return inputs

    @after_kickoff
    def process_output(self, output):
        # Modify output after the crew finishes
        output.raw += "\nProcessed after kickoff."
        return output

    @agent
    def agent_one(self) -> Agent:
        return Agent(
            config=self.agents_config['agent_one'], # type: ignore[index]
            verbose=True
        )

    @agent
    def agent_two(self) -> Agent:
        return Agent(
            config=self.agents_config['agent_two'], # type: ignore[index]
            verbose=True
        )

    @task
    def task_one(self) -> Task:
        return Task(
            config=self.tasks_config['task_one'] # type: ignore[index]
        )

    @task
    def task_two(self) -> Task:
        return Task(
            config=self.tasks_config['task_two'] # type: ignore[index]
        )

    @crew
    def crew(self) -> Crew:
        return Crew(
            agents=self.agents,  # Automatically collected by the @agent decorator
            tasks=self.tasks,    # Automatically collected by the @task decorator.
            process=Process.sequential,
            verbose=True,
        )
```

How to run the above code:

```python code
YourCrewName().crew().kickoff(inputs={"any": "input here"})
```

<Note>
  Tasks will be executed in the order they are defined.
</Note>

The `CrewBase` class, along with these decorators, automates the collection of agents and tasks, reducing the need for manual management.

#### Decorators overview from `annotations.py`

CrewAI provides several decorators in the `annotations.py` file that are used to mark methods within your crew class for special handling:

* `@CrewBase`: Marks the class as a crew base class.
* `@agent`: Denotes a method that returns an `Agent` object.
* `@task`: Denotes a method that returns a `Task` object.
* `@crew`: Denotes the method that returns the `Crew` object.
* `@before_kickoff`: (Optional) Marks a method to be executed before the crew starts.
* `@after_kickoff`: (Optional) Marks a method to be executed after the crew finishes.

These decorators help in organizing your crew's structure and automatically collecting agents and tasks without manually listing them.

### Direct Code Definition (Alternative)

Alternatively, you can define the crew directly in code without using YAML configuration files.

```python code
from crewai import Agent, Crew, Task, Process
from crewai_tools import YourCustomTool

class YourCrewName:
    def agent_one(self) -> Agent:
        return Agent(
            role="Data Analyst",
            goal="Analyze data trends in the market",
            backstory="An experienced data analyst with a background in economics",
            verbose=True,
            tools=[YourCustomTool()]
        )

    def agent_two(self) -> Agent:
        return Agent(
            role="Market Researcher",
            goal="Gather information on market dynamics",
            backstory="A diligent researcher with a keen eye for detail",
            verbose=True
        )

    def task_one(self) -> Task:
        return Task(
            description="Collect recent market data and identify trends.",
            expected_output="A report summarizing key trends in the market.",
            agent=self.agent_one()
        )

    def task_two(self) -> Task:
        return Task(
            description="Research factors affecting market dynamics.",
            expected_output="An analysis of factors influencing the market.",
            agent=self.agent_two()
        )

    def crew(self) -> Crew:
        return Crew(
            agents=[self.agent_one(), self.agent_two()],
            tasks=[self.task_one(), self.task_two()],
            process=Process.sequential,
            verbose=True
        )
```

How to run the above code:

```python code
YourCrewName().crew().kickoff(inputs={})
```

In this example:

* Agents and tasks are defined directly within the class without decorators.
* We manually create and manage the list of agents and tasks.
* This approach provides more control but can be less maintainable for larger projects.

## Crew Output

The output of a crew in the CrewAI framework is encapsulated within the `CrewOutput` class.
This class provides a structured way to access results of the crew's execution, including various formats such as raw strings, JSON, and Pydantic models.
The `CrewOutput` includes the results from the final task output, token usage, and individual task outputs.

### Crew Output Attributes

| Attribute        | Parameters     | Type                       | Description                                                                                          |
| :--------------- | :------------- | :------------------------- | :--------------------------------------------------------------------------------------------------- |
| **Raw**          | `raw`          | `str`                      | The raw output of the crew. This is the default format for the output.                               |
| **Pydantic**     | `pydantic`     | `Optional[BaseModel]`      | A Pydantic model object representing the structured output of the crew.                              |
| **JSON Dict**    | `json_dict`    | `Optional[Dict[str, Any]]` | A dictionary representing the JSON output of the crew.                                               |
| **Tasks Output** | `tasks_output` | `List[TaskOutput]`         | A list of `TaskOutput` objects, each representing the output of a task in the crew.                  |
| **Token Usage**  | `token_usage`  | `Dict[str, Any]`           | A summary of token usage, providing insights into the language model's performance during execution. |

### Crew Output Methods and Properties

| Method/Property | Description                                                                                       |
| :-------------- | :------------------------------------------------------------------------------------------------ |
| **json**        | Returns the JSON string representation of the crew output if the output format is JSON.           |
| **to\_dict**    | Converts the JSON and Pydantic outputs to a dictionary.                                           |
| \***\*str\*\*** | Returns the string representation of the crew output, prioritizing Pydantic, then JSON, then raw. |

### Accessing Crew Outputs

Once a crew has been executed, its output can be accessed through the `output` attribute of the `Crew` object. The `CrewOutput` class provides various ways to interact with and present this output.

#### Example

```python Code
# Example crew execution
crew = Crew(
    agents=[research_agent, writer_agent],
    tasks=[research_task, write_article_task],
    verbose=True
)

crew_output = crew.kickoff()

# Accessing the crew output
print(f"Raw Output: {crew_output.raw}")
if crew_output.json_dict:
    print(f"JSON Output: {json.dumps(crew_output.json_dict, indent=2)}")
if crew_output.pydantic:
    print(f"Pydantic Output: {crew_output.pydantic}")
print(f"Tasks Output: {crew_output.tasks_output}")
print(f"Token Usage: {crew_output.token_usage}")
```

## Accessing Crew Logs

You can see real time log of the crew execution, by setting `output_log_file` as a `True(Boolean)` or a `file_name(str)`. Supports logging of events as both `file_name.txt` and `file_name.json`.
In case of `True(Boolean)` will save as `logs.txt`.

In case of `output_log_file` is set as `False(Boolean)` or `None`, the logs will not be populated.

```python Code
# Save crew logs
crew = Crew(output_log_file = True)  # Logs will be saved as logs.txt
crew = Crew(output_log_file = file_name)  # Logs will be saved as file_name.txt
crew = Crew(output_log_file = file_name.txt)  # Logs will be saved as file_name.txt
crew = Crew(output_log_file = file_name.json)  # Logs will be saved as file_name.json
```

## Memory Utilization

Crews can utilize memory (short-term, long-term, and entity memory) to enhance their execution and learning over time. This feature allows crews to store and recall execution memories, aiding in decision-making and task execution strategies.

## Cache Utilization

Caches can be employed to store the results of tools' execution, making the process more efficient by reducing the need to re-execute identical tasks.

## Crew Usage Metrics

After the crew execution, you can access the `usage_metrics` attribute to view the language model (LLM) usage metrics for all tasks executed by the crew. This provides insights into operational efficiency and areas for improvement.

```python Code
# Access the crew's usage metrics
crew = Crew(agents=[agent1, agent2], tasks=[task1, task2])
crew.kickoff()
print(crew.usage_metrics)
```

## Crew Execution Process

* **Sequential Process**: Tasks are executed one after another, allowing for a linear flow of work.
* **Hierarchical Process**: A manager agent coordinates the crew, delegating tasks and validating outcomes before proceeding. **Note**: A `manager_llm` or `manager_agent` is required for this process and it's essential for validating the process flow.

### Kicking Off a Crew

Once your crew is assembled, initiate the workflow with the `kickoff()` method. This starts the execution process according to the defined process flow.

```python Code
# Start the crew's task execution
result = my_crew.kickoff()
print(result)
```

### Different Ways to Kick Off a Crew

Once your crew is assembled, initiate the workflow with the appropriate kickoff method. CrewAI provides several methods for better control over the kickoff process: `kickoff()`, `kickoff_for_each()`, `kickoff_async()`, and `kickoff_for_each_async()`.

* `kickoff()`: Starts the execution process according to the defined process flow.
* `kickoff_for_each()`: Executes tasks sequentially for each provided input event or item in the collection.
* `kickoff_async()`: Initiates the workflow asynchronously.
* `kickoff_for_each_async()`: Executes tasks concurrently for each provided input event or item, leveraging asynchronous processing.

```python Code
# Start the crew's task execution
result = my_crew.kickoff()
print(result)

# Example of using kickoff_for_each
inputs_array = [{'topic': 'AI in healthcare'}, {'topic': 'AI in finance'}]
results = my_crew.kickoff_for_each(inputs=inputs_array)
for result in results:
    print(result)

# Example of using kickoff_async
inputs = {'topic': 'AI in healthcare'}
async_result = await my_crew.kickoff_async(inputs=inputs)
print(async_result)

# Example of using kickoff_for_each_async
inputs_array = [{'topic': 'AI in healthcare'}, {'topic': 'AI in finance'}]
async_results = await my_crew.kickoff_for_each_async(inputs=inputs_array)
for async_result in async_results:
    print(async_result)
```

These methods provide flexibility in how you manage and execute tasks within your crew, allowing for both synchronous and asynchronous workflows tailored to your needs.

### Replaying from a Specific Task

You can now replay from a specific task using our CLI command `replay`.

The replay feature in CrewAI allows you to replay from a specific task using the command-line interface (CLI). By running the command `crewai replay -t <task_id>`, you can specify the `task_id` for the replay process.

Kickoffs will now save the latest kickoffs returned task outputs locally for you to be able to replay from.

### Replaying from a Specific Task Using the CLI

To use the replay feature, follow these steps:

1. Open your terminal or command prompt.
2. Navigate to the directory where your CrewAI project is located.
3. Run the following command:

To view the latest kickoff task IDs, use:

```shell
crewai log-tasks-outputs
```

Then, to replay from a specific task, use:

```shell
crewai replay -t <task_id>
```

These commands let you replay from your latest kickoff tasks, still retaining context from previously executed tasks.


# Event Listeners
Source: https://docs.crewai.com/en/concepts/event-listener

Tap into CrewAI events to build custom integrations and monitoring

## Overview

CrewAI provides a powerful event system that allows you to listen for and react to various events that occur during the execution of your Crew. This feature enables you to build custom integrations, monitoring solutions, logging systems, or any other functionality that needs to be triggered based on CrewAI's internal events.

## How It Works

CrewAI uses an event bus architecture to emit events throughout the execution lifecycle. The event system is built on the following components:

1. **CrewAIEventsBus**: A singleton event bus that manages event registration and emission
2. **BaseEvent**: Base class for all events in the system
3. **BaseEventListener**: Abstract base class for creating custom event listeners

When specific actions occur in CrewAI (like a Crew starting execution, an Agent completing a task, or a tool being used), the system emits corresponding events. You can register handlers for these events to execute custom code when they occur.

<Note type="info" title="Enterprise Enhancement: Prompt Tracing">
  CrewAI Enterprise provides a built-in Prompt Tracing feature that leverages the event system to track, store, and visualize all prompts, completions, and associated metadata. This provides powerful debugging capabilities and transparency into your agent operations.

  ![Prompt Tracing Dashboard](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/traces-overview.png)

  With Prompt Tracing you can:

  * View the complete history of all prompts sent to your LLM
  * Track token usage and costs
  * Debug agent reasoning failures
  * Share prompt sequences with your team
  * Compare different prompt strategies
  * Export traces for compliance and auditing
</Note>

## Creating a Custom Event Listener

To create a custom event listener, you need to:

1. Create a class that inherits from `BaseEventListener`
2. Implement the `setup_listeners` method
3. Register handlers for the events you're interested in
4. Create an instance of your listener in the appropriate file

Here's a simple example of a custom event listener class:

```python
from crewai.utilities.events import (
    CrewKickoffStartedEvent,
    CrewKickoffCompletedEvent,
    AgentExecutionCompletedEvent,
)
from crewai.utilities.events.base_event_listener import BaseEventListener

class MyCustomListener(BaseEventListener):
    def __init__(self):
        super().__init__()

    def setup_listeners(self, crewai_event_bus):
        @crewai_event_bus.on(CrewKickoffStartedEvent)
        def on_crew_started(source, event):
            print(f"Crew '{event.crew_name}' has started execution!")

        @crewai_event_bus.on(CrewKickoffCompletedEvent)
        def on_crew_completed(source, event):
            print(f"Crew '{event.crew_name}' has completed execution!")
            print(f"Output: {event.output}")

        @crewai_event_bus.on(AgentExecutionCompletedEvent)
        def on_agent_execution_completed(source, event):
            print(f"Agent '{event.agent.role}' completed task")
            print(f"Output: {event.output}")
```

## Properly Registering Your Listener

Simply defining your listener class isn't enough. You need to create an instance of it and ensure it's imported in your application. This ensures that:

1. The event handlers are registered with the event bus
2. The listener instance remains in memory (not garbage collected)
3. The listener is active when events are emitted

### Option 1: Import and Instantiate in Your Crew or Flow Implementation

The most important thing is to create an instance of your listener in the file where your Crew or Flow is defined and executed:

#### For Crew-based Applications

Create and import your listener at the top of your Crew implementation file:

```python
# In your crew.py file
from crewai import Agent, Crew, Task
from my_listeners import MyCustomListener

# Create an instance of your listener
my_listener = MyCustomListener()

class MyCustomCrew:
    # Your crew implementation...

    def crew(self):
        return Crew(
            agents=[...],
            tasks=[...],
            # ...
        )
```

#### For Flow-based Applications

Create and import your listener at the top of your Flow implementation file:

```python
# In your main.py or flow.py file
from crewai.flow import Flow, listen, start
from my_listeners import MyCustomListener

# Create an instance of your listener
my_listener = MyCustomListener()

class MyCustomFlow(Flow):
    # Your flow implementation...

    @start()
    def first_step(self):
        # ...
```

This ensures that your listener is loaded and active when your Crew or Flow is executed.

### Option 2: Create a Package for Your Listeners

For a more structured approach, especially if you have multiple listeners:

1. Create a package for your listeners:

```
my_project/
  ├── listeners/
  │   ├── __init__.py
  │   ├── my_custom_listener.py
  │   └── another_listener.py
```

2. In `my_custom_listener.py`, define your listener class and create an instance:

```python
# my_custom_listener.py
from crewai.utilities.events.base_event_listener import BaseEventListener
# ... import events ...

class MyCustomListener(BaseEventListener):
    # ... implementation ...

# Create an instance of your listener
my_custom_listener = MyCustomListener()
```

3. In `__init__.py`, import the listener instances to ensure they're loaded:

```python
# __init__.py
from .my_custom_listener import my_custom_listener
from .another_listener import another_listener

# Optionally export them if you need to access them elsewhere
__all__ = ['my_custom_listener', 'another_listener']
```

4. Import your listeners package in your Crew or Flow file:

```python
# In your crew.py or flow.py file
import my_project.listeners  # This loads all your listeners

class MyCustomCrew:
    # Your crew implementation...
```

This is exactly how CrewAI's built-in `agentops_listener` is registered. In the CrewAI codebase, you'll find:

```python
# src/crewai/utilities/events/third_party/__init__.py
from .agentops_listener import agentops_listener
```

This ensures the `agentops_listener` is loaded when the `crewai.utilities.events` package is imported.

## Available Event Types

CrewAI provides a wide range of events that you can listen for:

### Crew Events

* **CrewKickoffStartedEvent**: Emitted when a Crew starts execution
* **CrewKickoffCompletedEvent**: Emitted when a Crew completes execution
* **CrewKickoffFailedEvent**: Emitted when a Crew fails to complete execution
* **CrewTestStartedEvent**: Emitted when a Crew starts testing
* **CrewTestCompletedEvent**: Emitted when a Crew completes testing
* **CrewTestFailedEvent**: Emitted when a Crew fails to complete testing
* **CrewTrainStartedEvent**: Emitted when a Crew starts training
* **CrewTrainCompletedEvent**: Emitted when a Crew completes training
* **CrewTrainFailedEvent**: Emitted when a Crew fails to complete training

### Agent Events

* **AgentExecutionStartedEvent**: Emitted when an Agent starts executing a task
* **AgentExecutionCompletedEvent**: Emitted when an Agent completes executing a task
* **AgentExecutionErrorEvent**: Emitted when an Agent encounters an error during execution

### Task Events

* **TaskStartedEvent**: Emitted when a Task starts execution
* **TaskCompletedEvent**: Emitted when a Task completes execution
* **TaskFailedEvent**: Emitted when a Task fails to complete execution
* **TaskEvaluationEvent**: Emitted when a Task is evaluated

### Tool Usage Events

* **ToolUsageStartedEvent**: Emitted when a tool execution is started
* **ToolUsageFinishedEvent**: Emitted when a tool execution is completed
* **ToolUsageErrorEvent**: Emitted when a tool execution encounters an error
* **ToolValidateInputErrorEvent**: Emitted when a tool input validation encounters an error
* **ToolExecutionErrorEvent**: Emitted when a tool execution encounters an error
* **ToolSelectionErrorEvent**: Emitted when there's an error selecting a tool

### Knowledge Events

* **KnowledgeRetrievalStartedEvent**: Emitted when a knowledge retrieval is started
* **KnowledgeRetrievalCompletedEvent**: Emitted when a knowledge retrieval is completed
* **KnowledgeQueryStartedEvent**: Emitted when a knowledge query is started
* **KnowledgeQueryCompletedEvent**: Emitted when a knowledge query is completed
* **KnowledgeQueryFailedEvent**: Emitted when a knowledge query fails
* **KnowledgeSearchQueryFailedEvent**: Emitted when a knowledge search query fails

### LLM Guardrail Events

* **LLMGuardrailStartedEvent**: Emitted when a guardrail validation starts. Contains details about the guardrail being applied and retry count.
* **LLMGuardrailCompletedEvent**: Emitted when a guardrail validation completes. Contains details about validation success/failure, results, and error messages if any.

### Flow Events

* **FlowCreatedEvent**: Emitted when a Flow is created
* **FlowStartedEvent**: Emitted when a Flow starts execution
* **FlowFinishedEvent**: Emitted when a Flow completes execution
* **FlowPlotEvent**: Emitted when a Flow is plotted
* **MethodExecutionStartedEvent**: Emitted when a Flow method starts execution
* **MethodExecutionFinishedEvent**: Emitted when a Flow method completes execution
* **MethodExecutionFailedEvent**: Emitted when a Flow method fails to complete execution

### LLM Events

* **LLMCallStartedEvent**: Emitted when an LLM call starts
* **LLMCallCompletedEvent**: Emitted when an LLM call completes
* **LLMCallFailedEvent**: Emitted when an LLM call fails
* **LLMStreamChunkEvent**: Emitted for each chunk received during streaming LLM responses

### Memory Events

* **MemoryQueryStartedEvent**: Emitted when a memory query is started. Contains the query, limit, and optional score threshold.
* **MemoryQueryCompletedEvent**: Emitted when a memory query is completed successfully. Contains the query, results, limit, score threshold, and query execution time.
* **MemoryQueryFailedEvent**: Emitted when a memory query fails. Contains the query, limit, score threshold, and error message.
* **MemorySaveStartedEvent**: Emitted when a memory save operation is started. Contains the value to be saved, metadata, and optional agent role.
* **MemorySaveCompletedEvent**: Emitted when a memory save operation is completed successfully. Contains the saved value, metadata, agent role, and save execution time.
* **MemorySaveFailedEvent**: Emitted when a memory save operation fails. Contains the value, metadata, agent role, and error message.
* **MemoryRetrievalStartedEvent**: Emitted when memory retrieval for a task prompt starts. Contains the optional task ID.
* **MemoryRetrievalCompletedEvent**: Emitted when memory retrieval for a task prompt completes successfully. Contains the task ID, memory content, and retrieval execution time.

## Event Handler Structure

Each event handler receives two parameters:

1. **source**: The object that emitted the event
2. **event**: The event instance, containing event-specific data

The structure of the event object depends on the event type, but all events inherit from `BaseEvent` and include:

* **timestamp**: The time when the event was emitted
* **type**: A string identifier for the event type

Additional fields vary by event type. For example, `CrewKickoffCompletedEvent` includes `crew_name` and `output` fields.

## Real-World Example: Integration with AgentOps

CrewAI includes an example of a third-party integration with [AgentOps](https://github.com/AgentOps-AI/agentops), a monitoring and observability platform for AI agents. Here's how it's implemented:

```python
from typing import Optional

from crewai.utilities.events import (
    CrewKickoffCompletedEvent,
    ToolUsageErrorEvent,
    ToolUsageStartedEvent,
)
from crewai.utilities.events.base_event_listener import BaseEventListener
from crewai.utilities.events.crew_events import CrewKickoffStartedEvent
from crewai.utilities.events.task_events import TaskEvaluationEvent

try:
    import agentops
    AGENTOPS_INSTALLED = True
except ImportError:
    AGENTOPS_INSTALLED = False

class AgentOpsListener(BaseEventListener):
    tool_event: Optional["agentops.ToolEvent"] = None
    session: Optional["agentops.Session"] = None

    def __init__(self):
        super().__init__()

    def setup_listeners(self, crewai_event_bus):
        if not AGENTOPS_INSTALLED:
            return

        @crewai_event_bus.on(CrewKickoffStartedEvent)
        def on_crew_kickoff_started(source, event: CrewKickoffStartedEvent):
            self.session = agentops.init()
            for agent in source.agents:
                if self.session:
                    self.session.create_agent(
                        name=agent.role,
                        agent_id=str(agent.id),
                    )

        @crewai_event_bus.on(CrewKickoffCompletedEvent)
        def on_crew_kickoff_completed(source, event: CrewKickoffCompletedEvent):
            if self.session:
                self.session.end_session(
                    end_state="Success",
                    end_state_reason="Finished Execution",
                )

        @crewai_event_bus.on(ToolUsageStartedEvent)
        def on_tool_usage_started(source, event: ToolUsageStartedEvent):
            self.tool_event = agentops.ToolEvent(name=event.tool_name)
            if self.session:
                self.session.record(self.tool_event)

        @crewai_event_bus.on(ToolUsageErrorEvent)
        def on_tool_usage_error(source, event: ToolUsageErrorEvent):
            agentops.ErrorEvent(exception=event.error, trigger_event=self.tool_event)
```

This listener initializes an AgentOps session when a Crew starts, registers agents with AgentOps, tracks tool usage, and ends the session when the Crew completes.

The AgentOps listener is registered in CrewAI's event system through the import in `src/crewai/utilities/events/third_party/__init__.py`:

```python
from .agentops_listener import agentops_listener
```

This ensures the `agentops_listener` is loaded when the `crewai.utilities.events` package is imported.

## Advanced Usage: Scoped Handlers

For temporary event handling (useful for testing or specific operations), you can use the `scoped_handlers` context manager:

```python
from crewai.utilities.events import crewai_event_bus, CrewKickoffStartedEvent

with crewai_event_bus.scoped_handlers():
    @crewai_event_bus.on(CrewKickoffStartedEvent)
    def temp_handler(source, event):
        print("This handler only exists within this context")

    # Do something that emits events

# Outside the context, the temporary handler is removed
```

## Use Cases

Event listeners can be used for a variety of purposes:

1. **Logging and Monitoring**: Track the execution of your Crew and log important events
2. **Analytics**: Collect data about your Crew's performance and behavior
3. **Debugging**: Set up temporary listeners to debug specific issues
4. **Integration**: Connect CrewAI with external systems like monitoring platforms, databases, or notification services
5. **Custom Behavior**: Trigger custom actions based on specific events

## Best Practices

1. **Keep Handlers Light**: Event handlers should be lightweight and avoid blocking operations
2. **Error Handling**: Include proper error handling in your event handlers to prevent exceptions from affecting the main execution
3. **Cleanup**: If your listener allocates resources, ensure they're properly cleaned up
4. **Selective Listening**: Only listen for events you actually need to handle
5. **Testing**: Test your event listeners in isolation to ensure they behave as expected

By leveraging CrewAI's event system, you can extend its functionality and integrate it seamlessly with your existing infrastructure.


# Flows
Source: https://docs.crewai.com/en/concepts/flows

Learn how to create and manage AI workflows using CrewAI Flows.

## Overview

CrewAI Flows is a powerful feature designed to streamline the creation and management of AI workflows. Flows allow developers to combine and coordinate coding tasks and Crews efficiently, providing a robust framework for building sophisticated AI automations.

Flows allow you to create structured, event-driven workflows. They provide a seamless way to connect multiple tasks, manage state, and control the flow of execution in your AI applications. With Flows, you can easily design and implement multi-step processes that leverage the full potential of CrewAI's capabilities.

1. **Simplified Workflow Creation**: Easily chain together multiple Crews and tasks to create complex AI workflows.

2. **State Management**: Flows make it super easy to manage and share state between different tasks in your workflow.

3. **Event-Driven Architecture**: Built on an event-driven model, allowing for dynamic and responsive workflows.

4. **Flexible Control Flow**: Implement conditional logic, loops, and branching within your workflows.

## Getting Started

Let's create a simple Flow where you will use OpenAI to generate a random city in one task and then use that city to generate a fun fact in another task.

```python Code

from crewai.flow.flow import Flow, listen, start
from dotenv import load_dotenv
from litellm import completion


class ExampleFlow(Flow):
    model = "gpt-4o-mini"

    @start()
    def generate_city(self):
        print("Starting flow")
        # Each flow state automatically gets a unique ID
        print(f"Flow State ID: {self.state['id']}")

        response = completion(
            model=self.model,
            messages=[
                {
                    "role": "user",
                    "content": "Return the name of a random city in the world.",
                },
            ],
        )

        random_city = response["choices"][0]["message"]["content"]
        # Store the city in our state
        self.state["city"] = random_city
        print(f"Random City: {random_city}")

        return random_city

    @listen(generate_city)
    def generate_fun_fact(self, random_city):
        response = completion(
            model=self.model,
            messages=[
                {
                    "role": "user",
                    "content": f"Tell me a fun fact about {random_city}",
                },
            ],
        )

        fun_fact = response["choices"][0]["message"]["content"]
        # Store the fun fact in our state
        self.state["fun_fact"] = fun_fact
        return fun_fact



flow = ExampleFlow()
flow.plot()
result = flow.kickoff()

print(f"Generated fun fact: {result}")
```

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-1.png)
In the above example, we have created a simple Flow that generates a random city using OpenAI and then generates a fun fact about that city. The Flow consists of two tasks: `generate_city` and `generate_fun_fact`. The `generate_city` task is the starting point of the Flow, and the `generate_fun_fact` task listens for the output of the `generate_city` task.

Each Flow instance automatically receives a unique identifier (UUID) in its state, which helps track and manage flow executions. The state can also store additional data (like the generated city and fun fact) that persists throughout the flow's execution.

When you run the Flow, it will:

1. Generate a unique ID for the flow state
2. Generate a random city and store it in the state
3. Generate a fun fact about that city and store it in the state
4. Print the results to the console

The state's unique ID and stored data can be useful for tracking flow executions and maintaining context between tasks.

**Note:** Ensure you have set up your `.env` file to store your `OPENAI_API_KEY`. This key is necessary for authenticating requests to the OpenAI API.

### @start()

The `@start()` decorator is used to mark a method as the starting point of a Flow. When a Flow is started, all the methods decorated with `@start()` are executed in parallel. You can have multiple start methods in a Flow, and they will all be executed when the Flow is started.

### @listen()

The `@listen()` decorator is used to mark a method as a listener for the output of another task in the Flow. The method decorated with `@listen()` will be executed when the specified task emits an output. The method can access the output of the task it is listening to as an argument.

#### Usage

The `@listen()` decorator can be used in several ways:

1. **Listening to a Method by Name**: You can pass the name of the method you want to listen to as a string. When that method completes, the listener method will be triggered.

   ```python Code
   @listen("generate_city")
   def generate_fun_fact(self, random_city):
       # Implementation
   ```

2. **Listening to a Method Directly**: You can pass the method itself. When that method completes, the listener method will be triggered.
   ```python Code
   @listen(generate_city)
   def generate_fun_fact(self, random_city):
       # Implementation
   ```

### Flow Output

Accessing and handling the output of a Flow is essential for integrating your AI workflows into larger applications or systems. CrewAI Flows provide straightforward mechanisms to retrieve the final output, access intermediate results, and manage the overall state of your Flow.

#### Retrieving the Final Output

When you run a Flow, the final output is determined by the last method that completes. The `kickoff()` method returns the output of this final method.

Here's how you can access the final output:

<CodeGroup>
  ```python Code
  from crewai.flow.flow import Flow, listen, start

  class OutputExampleFlow(Flow):
      @start()
      def first_method(self):
          return "Output from first_method"

      @listen(first_method)
      def second_method(self, first_output):
          return f"Second method received: {first_output}"


  flow = OutputExampleFlow()
  flow.plot("my_flow_plot")
  final_output = flow.kickoff()

  print("---- Final Output ----")
  print(final_output)
  ```

  ```text Output
  ---- Final Output ----
  Second method received: Output from first_method
  ```
</CodeGroup>

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-2.png)

In this example, the `second_method` is the last method to complete, so its output will be the final output of the Flow.
The `kickoff()` method will return the final output, which is then printed to the console. The `plot()` method will generate the HTML file, which will help you understand the flow.

#### Accessing and Updating State

In addition to retrieving the final output, you can also access and update the state within your Flow. The state can be used to store and share data between different methods in the Flow. After the Flow has run, you can access the state to retrieve any information that was added or updated during the execution.

Here's an example of how to update and access the state:

<CodeGroup>
  ```python Code
  from crewai.flow.flow import Flow, listen, start
  from pydantic import BaseModel

  class ExampleState(BaseModel):
      counter: int = 0
      message: str = ""

  class StateExampleFlow(Flow[ExampleState]):

      @start()
      def first_method(self):
          self.state.message = "Hello from first_method"
          self.state.counter += 1

      @listen(first_method)
      def second_method(self):
          self.state.message += " - updated by second_method"
          self.state.counter += 1
          return self.state.message

  flow = StateExampleFlow()
  flow.plot("my_flow_plot")
  final_output = flow.kickoff()
  print(f"Final Output: {final_output}")
  print("Final State:")
  print(flow.state)
  ```

  ```text Output
  Final Output: Hello from first_method - updated by second_method
  Final State:
  counter=2 message='Hello from first_method - updated by second_method'
  ```
</CodeGroup>

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-2.png)

In this example, the state is updated by both `first_method` and `second_method`.
After the Flow has run, you can access the final state to see the updates made by these methods.

By ensuring that the final method's output is returned and providing access to the state, CrewAI Flows make it easy to integrate the results of your AI workflows into larger applications or systems,
while also maintaining and accessing the state throughout the Flow's execution.

## Flow State Management

Managing state effectively is crucial for building reliable and maintainable AI workflows. CrewAI Flows provides robust mechanisms for both unstructured and structured state management,
allowing developers to choose the approach that best fits their application's needs.

### Unstructured State Management

In unstructured state management, all state is stored in the `state` attribute of the `Flow` class.
This approach offers flexibility, enabling developers to add or modify state attributes on the fly without defining a strict schema.
Even with unstructured states, CrewAI Flows automatically generates and maintains a unique identifier (UUID) for each state instance.

```python Code
from crewai.flow.flow import Flow, listen, start

class UnstructuredExampleFlow(Flow):

    @start()
    def first_method(self):
        # The state automatically includes an 'id' field
        print(f"State ID: {self.state['id']}")
        self.state['counter'] = 0
        self.state['message'] = "Hello from structured flow"

    @listen(first_method)
    def second_method(self):
        self.state['counter'] += 1
        self.state['message'] += " - updated"

    @listen(second_method)
    def third_method(self):
        self.state['counter'] += 1
        self.state['message'] += " - updated again"

        print(f"State after third_method: {self.state}")


flow = UnstructuredExampleFlow()
flow.plot("my_flow_plot")
flow.kickoff()
```

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-3.png)

**Note:** The `id` field is automatically generated and preserved throughout the flow's execution. You don't need to manage or set it manually, and it will be maintained even when updating the state with new data.

**Key Points:**

* **Flexibility:** You can dynamically add attributes to `self.state` without predefined constraints.
* **Simplicity:** Ideal for straightforward workflows where state structure is minimal or varies significantly.

### Structured State Management

Structured state management leverages predefined schemas to ensure consistency and type safety across the workflow.
By using models like Pydantic's `BaseModel`, developers can define the exact shape of the state, enabling better validation and auto-completion in development environments.

Each state in CrewAI Flows automatically receives a unique identifier (UUID) to help track and manage state instances. This ID is automatically generated and managed by the Flow system.

```python Code
from crewai.flow.flow import Flow, listen, start
from pydantic import BaseModel


class ExampleState(BaseModel):
    # Note: 'id' field is automatically added to all states
    counter: int = 0
    message: str = ""


class StructuredExampleFlow(Flow[ExampleState]):

    @start()
    def first_method(self):
        # Access the auto-generated ID if needed
        print(f"State ID: {self.state.id}")
        self.state.message = "Hello from structured flow"

    @listen(first_method)
    def second_method(self):
        self.state.counter += 1
        self.state.message += " - updated"

    @listen(second_method)
    def third_method(self):
        self.state.counter += 1
        self.state.message += " - updated again"

        print(f"State after third_method: {self.state}")


flow = StructuredExampleFlow()
flow.kickoff()
```

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-3.png)

**Key Points:**

* **Defined Schema:** `ExampleState` clearly outlines the state structure, enhancing code readability and maintainability.
* **Type Safety:** Leveraging Pydantic ensures that state attributes adhere to the specified types, reducing runtime errors.
* **Auto-Completion:** IDEs can provide better auto-completion and error checking based on the defined state model.

### Choosing Between Unstructured and Structured State Management

* **Use Unstructured State Management when:**

  * The workflow's state is simple or highly dynamic.
  * Flexibility is prioritized over strict state definitions.
  * Rapid prototyping is required without the overhead of defining schemas.

* **Use Structured State Management when:**
  * The workflow requires a well-defined and consistent state structure.
  * Type safety and validation are important for your application's reliability.
  * You want to leverage IDE features like auto-completion and type checking for better developer experience.

By providing both unstructured and structured state management options, CrewAI Flows empowers developers to build AI workflows that are both flexible and robust, catering to a wide range of application requirements.

## Flow Persistence

The @persist decorator enables automatic state persistence in CrewAI Flows, allowing you to maintain flow state across restarts or different workflow executions. This decorator can be applied at either the class level or method level, providing flexibility in how you manage state persistence.

### Class-Level Persistence

When applied at the class level, the @persist decorator automatically persists all flow method states:

```python
@persist  # Using SQLiteFlowPersistence by default
class MyFlow(Flow[MyState]):
    @start()
    def initialize_flow(self):
        # This method will automatically have its state persisted
        self.state.counter = 1
        print("Initialized flow. State ID:", self.state.id)

    @listen(initialize_flow)
    def next_step(self):
        # The state (including self.state.id) is automatically reloaded
        self.state.counter += 1
        print("Flow state is persisted. Counter:", self.state.counter)
```

### Method-Level Persistence

For more granular control, you can apply @persist to specific methods:

```python
class AnotherFlow(Flow[dict]):
    @persist  # Persists only this method's state
    @start()
    def begin(self):
        if "runs" not in self.state:
            self.state["runs"] = 0
        self.state["runs"] += 1
        print("Method-level persisted runs:", self.state["runs"])
```

### How It Works

1. **Unique State Identification**
   * Each flow state automatically receives a unique UUID
   * The ID is preserved across state updates and method calls
   * Supports both structured (Pydantic BaseModel) and unstructured (dictionary) states

2. **Default SQLite Backend**
   * SQLiteFlowPersistence is the default storage backend
   * States are automatically saved to a local SQLite database
   * Robust error handling ensures clear messages if database operations fail

3. **Error Handling**
   * Comprehensive error messages for database operations
   * Automatic state validation during save and load
   * Clear feedback when persistence operations encounter issues

### Important Considerations

* **State Types**: Both structured (Pydantic BaseModel) and unstructured (dictionary) states are supported
* **Automatic ID**: The `id` field is automatically added if not present
* **State Recovery**: Failed or restarted flows can automatically reload their previous state
* **Custom Implementation**: You can provide your own FlowPersistence implementation for specialized storage needs

### Technical Advantages

1. **Precise Control Through Low-Level Access**
   * Direct access to persistence operations for advanced use cases
   * Fine-grained control via method-level persistence decorators
   * Built-in state inspection and debugging capabilities
   * Full visibility into state changes and persistence operations

2. **Enhanced Reliability**
   * Automatic state recovery after system failures or restarts
   * Transaction-based state updates for data integrity
   * Comprehensive error handling with clear error messages
   * Robust validation during state save and load operations

3. **Extensible Architecture**
   * Customizable persistence backend through FlowPersistence interface
   * Support for specialized storage solutions beyond SQLite
   * Compatible with both structured (Pydantic) and unstructured (dict) states
   * Seamless integration with existing CrewAI flow patterns

The persistence system's architecture emphasizes technical precision and customization options, allowing developers to maintain full control over state management while benefiting from built-in reliability features.

## Flow Control

### Conditional Logic: `or`

The `or_` function in Flows allows you to listen to multiple methods and trigger the listener method when any of the specified methods emit an output.

<CodeGroup>
  ```python Code
  from crewai.flow.flow import Flow, listen, or_, start

  class OrExampleFlow(Flow):

      @start()
      def start_method(self):
          return "Hello from the start method"

      @listen(start_method)
      def second_method(self):
          return "Hello from the second method"

      @listen(or_(start_method, second_method))
      def logger(self, result):
          print(f"Logger: {result}")



  flow = OrExampleFlow()
  flow.plot("my_flow_plot")
  flow.kickoff()
  ```

  ```text Output
  Logger: Hello from the start method
  Logger: Hello from the second method
  ```
</CodeGroup>

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-4.png)

When you run this Flow, the `logger` method will be triggered by the output of either the `start_method` or the `second_method`.
The `or_` function is used to listen to multiple methods and trigger the listener method when any of the specified methods emit an output.

### Conditional Logic: `and`

The `and_` function in Flows allows you to listen to multiple methods and trigger the listener method only when all the specified methods emit an output.

<CodeGroup>
  ```python Code
  from crewai.flow.flow import Flow, and_, listen, start

  class AndExampleFlow(Flow):

      @start()
      def start_method(self):
          self.state["greeting"] = "Hello from the start method"

      @listen(start_method)
      def second_method(self):
          self.state["joke"] = "What do computers eat? Microchips."

      @listen(and_(start_method, second_method))
      def logger(self):
          print("---- Logger ----")
          print(self.state)

  flow = AndExampleFlow()
  flow.plot()
  flow.kickoff()
  ```

  ```text Output
  ---- Logger ----
  {'greeting': 'Hello from the start method', 'joke': 'What do computers eat? Microchips.'}
  ```
</CodeGroup>

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-5.png)

When you run this Flow, the `logger` method will be triggered only when both the `start_method` and the `second_method` emit an output.
The `and_` function is used to listen to multiple methods and trigger the listener method only when all the specified methods emit an output.

### Router

The `@router()` decorator in Flows allows you to define conditional routing logic based on the output of a method.
You can specify different routes based on the output of the method, allowing you to control the flow of execution dynamically.

<CodeGroup>
  ```python Code
  import random
  from crewai.flow.flow import Flow, listen, router, start
  from pydantic import BaseModel

  class ExampleState(BaseModel):
      success_flag: bool = False

  class RouterFlow(Flow[ExampleState]):

      @start()
      def start_method(self):
          print("Starting the structured flow")
          random_boolean = random.choice([True, False])
          self.state.success_flag = random_boolean

      @router(start_method)
      def second_method(self):
          if self.state.success_flag:
              return "success"
          else:
              return "failed"

      @listen("success")
      def third_method(self):
          print("Third method running")

      @listen("failed")
      def fourth_method(self):
          print("Fourth method running")


  flow = RouterFlow()
  flow.plot("my_flow_plot")
  flow.kickoff()
  ```

  ```text Output
  Starting the structured flow
  Third method running
  Fourth method running
  ```
</CodeGroup>

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-6.png)

In the above example, the `start_method` generates a random boolean value and sets it in the state.
The `second_method` uses the `@router()` decorator to define conditional routing logic based on the value of the boolean.
If the boolean is `True`, the method returns `"success"`, and if it is `False`, the method returns `"failed"`.
The `third_method` and `fourth_method` listen to the output of the `second_method` and execute based on the returned value.

When you run this Flow, the output will change based on the random boolean value generated by the `start_method`.

## Adding Agents to Flows

Agents can be seamlessly integrated into your flows, providing a lightweight alternative to full Crews when you need simpler, focused task execution. Here's an example of how to use an Agent within a flow to perform market research:

```python
import asyncio
from typing import Any, Dict, List

from crewai_tools import SerperDevTool
from pydantic import BaseModel, Field

from crewai.agent import Agent
from crewai.flow.flow import Flow, listen, start


# Define a structured output format
class MarketAnalysis(BaseModel):
    key_trends: List[str] = Field(description="List of identified market trends")
    market_size: str = Field(description="Estimated market size")
    competitors: List[str] = Field(description="Major competitors in the space")


# Define flow state
class MarketResearchState(BaseModel):
    product: str = ""
    analysis: MarketAnalysis | None = None


# Create a flow class
class MarketResearchFlow(Flow[MarketResearchState]):
    @start()
    def initialize_research(self) -> Dict[str, Any]:
        print(f"Starting market research for {self.state.product}")
        return {"product": self.state.product}

    @listen(initialize_research)
    async def analyze_market(self) -> Dict[str, Any]:
        # Create an Agent for market research
        analyst = Agent(
            role="Market Research Analyst",
            goal=f"Analyze the market for {self.state.product}",
            backstory="You are an experienced market analyst with expertise in "
            "identifying market trends and opportunities.",
            tools=[SerperDevTool()],
            verbose=True,
        )

        # Define the research query
        query = f"""
        Research the market for {self.state.product}. Include:
        1. Key market trends
        2. Market size
        3. Major competitors

        Format your response according to the specified structure.
        """

        # Execute the analysis with structured output format
        result = await analyst.kickoff_async(query, response_format=MarketAnalysis)
        if result.pydantic:
            print("result", result.pydantic)
        else:
            print("result", result)

        # Return the analysis to update the state
        return {"analysis": result.pydantic}

    @listen(analyze_market)
    def present_results(self, analysis) -> None:
        print("\nMarket Analysis Results")
        print("=====================")

        if isinstance(analysis, dict):
            # If we got a dict with 'analysis' key, extract the actual analysis object
            market_analysis = analysis.get("analysis")
        else:
            market_analysis = analysis

        if market_analysis and isinstance(market_analysis, MarketAnalysis):
            print("\nKey Market Trends:")
            for trend in market_analysis.key_trends:
                print(f"- {trend}")

            print(f"\nMarket Size: {market_analysis.market_size}")

            print("\nMajor Competitors:")
            for competitor in market_analysis.competitors:
                print(f"- {competitor}")
        else:
            print("No structured analysis data available.")
            print("Raw analysis:", analysis)


# Usage example
async def run_flow():
    flow = MarketResearchFlow()
    flow.plot("MarketResearchFlowPlot")
    result = await flow.kickoff_async(inputs={"product": "AI-powered chatbots"})
    return result


# Run the flow
if __name__ == "__main__":
    asyncio.run(run_flow())
```

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-7.png)

This example demonstrates several key features of using Agents in flows:

1. **Structured Output**: Using Pydantic models to define the expected output format (`MarketAnalysis`) ensures type safety and structured data throughout the flow.

2. **State Management**: The flow state (`MarketResearchState`) maintains context between steps and stores both inputs and outputs.

3. **Tool Integration**: Agents can use tools (like `WebsiteSearchTool`) to enhance their capabilities.

## Adding Crews to Flows

Creating a flow with multiple crews in CrewAI is straightforward.

You can generate a new CrewAI project that includes all the scaffolding needed to create a flow with multiple crews by running the following command:

```bash
crewai create flow name_of_flow
```

This command will generate a new CrewAI project with the necessary folder structure. The generated project includes a prebuilt crew called `poem_crew` that is already working. You can use this crew as a template by copying, pasting, and editing it to create other crews.

### Folder Structure

After running the `crewai create flow name_of_flow` command, you will see a folder structure similar to the following:

| Directory/File         | Description                                                         |
| :--------------------- | :------------------------------------------------------------------ |
| `name_of_flow/`        | Root directory for the flow.                                        |
| ├── `crews/`           | Contains directories for specific crews.                            |
| │ └── `poem_crew/`     | Directory for the "poem\_crew" with its configurations and scripts. |
| │ ├── `config/`        | Configuration files directory for the "poem\_crew".                 |
| │ │ ├── `agents.yaml`  | YAML file defining the agents for "poem\_crew".                     |
| │ │ └── `tasks.yaml`   | YAML file defining the tasks for "poem\_crew".                      |
| │ ├── `poem_crew.py`   | Script for "poem\_crew" functionality.                              |
| ├── `tools/`           | Directory for additional tools used in the flow.                    |
| │ └── `custom_tool.py` | Custom tool implementation.                                         |
| ├── `main.py`          | Main script for running the flow.                                   |
| ├── `README.md`        | Project description and instructions.                               |
| ├── `pyproject.toml`   | Configuration file for project dependencies and settings.           |
| └── `.gitignore`       | Specifies files and directories to ignore in version control.       |

### Building Your Crews

In the `crews` folder, you can define multiple crews. Each crew will have its own folder containing configuration files and the crew definition file. For example, the `poem_crew` folder contains:

* `config/agents.yaml`: Defines the agents for the crew.
* `config/tasks.yaml`: Defines the tasks for the crew.
* `poem_crew.py`: Contains the crew definition, including agents, tasks, and the crew itself.

You can copy, paste, and edit the `poem_crew` to create other crews.

### Connecting Crews in `main.py`

The `main.py` file is where you create your flow and connect the crews together. You can define your flow by using the `Flow` class and the decorators `@start` and `@listen` to specify the flow of execution.

Here's an example of how you can connect the `poem_crew` in the `main.py` file:

```python Code
#!/usr/bin/env python
from random import randint

from pydantic import BaseModel
from crewai.flow.flow import Flow, listen, start
from .crews.poem_crew.poem_crew import PoemCrew

class PoemState(BaseModel):
    sentence_count: int = 1
    poem: str = ""

class PoemFlow(Flow[PoemState]):

    @start()
    def generate_sentence_count(self):
        print("Generating sentence count")
        self.state.sentence_count = randint(1, 5)

    @listen(generate_sentence_count)
    def generate_poem(self):
        print("Generating poem")
        result = PoemCrew().crew().kickoff(inputs={"sentence_count": self.state.sentence_count})

        print("Poem generated", result.raw)
        self.state.poem = result.raw

    @listen(generate_poem)
    def save_poem(self):
        print("Saving poem")
        with open("poem.txt", "w") as f:
            f.write(self.state.poem)

def kickoff():
    poem_flow = PoemFlow()
    poem_flow.kickoff()


def plot():
    poem_flow = PoemFlow()
    poem_flow.plot("PoemFlowPlot")

if __name__ == "__main__":
    kickoff()
    plot()
```

In this example, the `PoemFlow` class defines a flow that generates a sentence count, uses the `PoemCrew` to generate a poem, and then saves the poem to a file. The flow is kicked off by calling the `kickoff()` method. The PoemFlowPlot will be generated by `plot()` method.

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-8.png)

### Running the Flow

(Optional) Before running the flow, you can install the dependencies by running:

```bash
crewai install
```

Once all of the dependencies are installed, you need to activate the virtual environment by running:

```bash
source .venv/bin/activate
```

After activating the virtual environment, you can run the flow by executing one of the following commands:

```bash
crewai flow kickoff
```

or

```bash
uv run kickoff
```

The flow will execute, and you should see the output in the console.

## Plot Flows

Visualizing your AI workflows can provide valuable insights into the structure and execution paths of your flows. CrewAI offers a powerful visualization tool that allows you to generate interactive plots of your flows, making it easier to understand and optimize your AI workflows.

### What are Plots?

Plots in CrewAI are graphical representations of your AI workflows. They display the various tasks, their connections, and the flow of data between them. This visualization helps in understanding the sequence of operations, identifying bottlenecks, and ensuring that the workflow logic aligns with your expectations.

### How to Generate a Plot

CrewAI provides two convenient methods to generate plots of your flows:

#### Option 1: Using the `plot()` Method

If you are working directly with a flow instance, you can generate a plot by calling the `plot()` method on your flow object. This method will create an HTML file containing the interactive plot of your flow.

```python Code
# Assuming you have a flow instance
flow.plot("my_flow_plot")
```

This will generate a file named `my_flow_plot.html` in your current directory. You can open this file in a web browser to view the interactive plot.

#### Option 2: Using the Command Line

If you are working within a structured CrewAI project, you can generate a plot using the command line. This is particularly useful for larger projects where you want to visualize the entire flow setup.

```bash
crewai flow plot
```

This command will generate an HTML file with the plot of your flow, similar to the `plot()` method. The file will be saved in your project directory, and you can open it in a web browser to explore the flow.

### Understanding the Plot

The generated plot will display nodes representing the tasks in your flow, with directed edges indicating the flow of execution. The plot is interactive, allowing you to zoom in and out, and hover over nodes to see additional details.

By visualizing your flows, you can gain a clearer understanding of the workflow's structure, making it easier to debug, optimize, and communicate your AI processes to others.

### Conclusion

Plotting your flows is a powerful feature of CrewAI that enhances your ability to design and manage complex AI workflows. Whether you choose to use the `plot()` method or the command line, generating plots will provide you with a visual representation of your workflows, aiding in both development and presentation.

## Next Steps

If you're interested in exploring additional examples of flows, we have a variety of recommendations in our examples repository. Here are four specific flow examples, each showcasing unique use cases to help you match your current problem type to a specific example:

1. **Email Auto Responder Flow**: This example demonstrates an infinite loop where a background job continually runs to automate email responses. It's a great use case for tasks that need to be performed repeatedly without manual intervention. [View Example](https://github.com/crewAIInc/crewAI-examples/tree/main/email_auto_responder_flow)

2. **Lead Score Flow**: This flow showcases adding human-in-the-loop feedback and handling different conditional branches using the router. It's an excellent example of how to incorporate dynamic decision-making and human oversight into your workflows. [View Example](https://github.com/crewAIInc/crewAI-examples/tree/main/lead-score-flow)

3. **Write a Book Flow**: This example excels at chaining multiple crews together, where the output of one crew is used by another. Specifically, one crew outlines an entire book, and another crew generates chapters based on the outline. Eventually, everything is connected to produce a complete book. This flow is perfect for complex, multi-step processes that require coordination between different tasks. [View Example](https://github.com/crewAIInc/crewAI-examples/tree/main/write_a_book_with_flows)

4. **Meeting Assistant Flow**: This flow demonstrates how to broadcast one event to trigger multiple follow-up actions. For instance, after a meeting is completed, the flow can update a Trello board, send a Slack message, and save the results. It's a great example of handling multiple outcomes from a single event, making it ideal for comprehensive task management and notification systems. [View Example](https://github.com/crewAIInc/crewAI-examples/tree/main/meeting_assistant_flow)

By exploring these examples, you can gain insights into how to leverage CrewAI Flows for various use cases, from automating repetitive tasks to managing complex, multi-step processes with dynamic decision-making and human feedback.

Also, check out our YouTube video on how to use flows in CrewAI below!

<iframe width="560" height="315" src="https://www.youtube.com/embed/MTb5my6VOT8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen />

## Running Flows

There are two ways to run a flow:

### Using the Flow API

You can run a flow programmatically by creating an instance of your flow class and calling the `kickoff()` method:

```python
flow = ExampleFlow()
result = flow.kickoff()
```

### Using the CLI

Starting from version 0.103.0, you can run flows using the `crewai run` command:

```shell
crewai run
```

This command automatically detects if your project is a flow (based on the `type = "flow"` setting in your pyproject.toml) and runs it accordingly. This is the recommended way to run flows from the command line.

For backward compatibility, you can also use:

```shell
crewai flow kickoff
```

However, the `crewai run` command is now the preferred method as it works for both crews and flows.


# Knowledge
Source: https://docs.crewai.com/en/concepts/knowledge

What is knowledge in CrewAI and how to use it.

## Overview

Knowledge in CrewAI is a powerful system that allows AI agents to access and utilize external information sources during their tasks.
Think of it as giving your agents a reference library they can consult while working.

<Info>
  Key benefits of using Knowledge:

  * Enhance agents with domain-specific information
  * Support decisions with real-world data
  * Maintain context across conversations
  * Ground responses in factual information
</Info>

## Quickstart Examples

<Tip>
  For file-based Knowledge Sources, make sure to place your files in a `knowledge` directory at the root of your project.
  Also, use relative paths from the `knowledge` directory when creating the source.
</Tip>

### Basic String Knowledge Example

```python Code
from crewai import Agent, Task, Crew, Process, LLM
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# Create a knowledge source
content = "Users name is John. He is 30 years old and lives in San Francisco."
string_source = StringKnowledgeSource(content=content)

# Create an LLM with a temperature of 0 to ensure deterministic outputs
llm = LLM(model="gpt-4o-mini", temperature=0)

# Create an agent with the knowledge store
agent = Agent(
    role="About User",
    goal="You know everything about the user.",
    backstory="You are a master at understanding people and their preferences.",
    verbose=True,
    allow_delegation=False,
    llm=llm,
)

task = Task(
    description="Answer the following questions about the user: {question}",
    expected_output="An answer to the question.",
    agent=agent,
)

crew = Crew(
    agents=[agent],
    tasks=[task],
    verbose=True,
    process=Process.sequential,
    knowledge_sources=[string_source], # Enable knowledge by adding the sources here
)

result = crew.kickoff(inputs={"question": "What city does John live in and how old is he?"})
```

### Web Content Knowledge Example

<Note>
  You need to install `docling` for the following example to work: `uv add docling`
</Note>

```python Code
from crewai import LLM, Agent, Crew, Process, Task
from crewai.knowledge.source.crew_docling_source import CrewDoclingSource

# Create a knowledge source from web content
content_source = CrewDoclingSource(
    file_paths=[
        "https://lilianweng.github.io/posts/2024-11-28-reward-hacking",
        "https://lilianweng.github.io/posts/2024-07-07-hallucination",
    ],
)

# Create an LLM with a temperature of 0 to ensure deterministic outputs
llm = LLM(model="gpt-4o-mini", temperature=0)

# Create an agent with the knowledge store
agent = Agent(
    role="About papers",
    goal="You know everything about the papers.",
    backstory="You are a master at understanding papers and their content.",
    verbose=True,
    allow_delegation=False,
    llm=llm,
)

task = Task(
    description="Answer the following questions about the papers: {question}",
    expected_output="An answer to the question.",
    agent=agent,
)

crew = Crew(
    agents=[agent],
    tasks=[task],
    verbose=True,
    process=Process.sequential,
    knowledge_sources=[content_source],
)

result = crew.kickoff(
    inputs={"question": "What is the reward hacking paper about? Be sure to provide sources."}
)
```

## Supported Knowledge Sources

CrewAI supports various types of knowledge sources out of the box:

<CardGroup cols={2}>
  <Card title="Text Sources" icon="text">
    * Raw strings
    * Text files (.txt)
    * PDF documents
  </Card>

  <Card title="Structured Data" icon="table">
    * CSV files
    * Excel spreadsheets
    * JSON documents
  </Card>
</CardGroup>

### Text File Knowledge Source

```python
from crewai.knowledge.source.text_file_knowledge_source import TextFileKnowledgeSource

text_source = TextFileKnowledgeSource(
    file_paths=["document.txt", "another.txt"]
)
```

### PDF Knowledge Source

```python
from crewai.knowledge.source.pdf_knowledge_source import PDFKnowledgeSource

pdf_source = PDFKnowledgeSource(
    file_paths=["document.pdf", "another.pdf"]
)
```

### CSV Knowledge Source

```python
from crewai.knowledge.source.csv_knowledge_source import CSVKnowledgeSource

csv_source = CSVKnowledgeSource(
    file_paths=["data.csv"]
)
```

### Excel Knowledge Source

```python
from crewai.knowledge.source.excel_knowledge_source import ExcelKnowledgeSource

excel_source = ExcelKnowledgeSource(
    file_paths=["spreadsheet.xlsx"]
)
```

### JSON Knowledge Source

```python
from crewai.knowledge.source.json_knowledge_source import JSONKnowledgeSource

json_source = JSONKnowledgeSource(
    file_paths=["data.json"]
)
```

<Note>
  Please ensure that you create the ./knowledge folder. All source files (e.g., .txt, .pdf, .xlsx, .json) should be placed in this folder for centralized management.
</Note>

## Agent vs Crew Knowledge: Complete Guide

<Info>
  **Understanding Knowledge Levels**: CrewAI supports knowledge at both agent and crew levels. This section clarifies exactly how each works, when they're initialized, and addresses common misconceptions about dependencies.
</Info>

### How Knowledge Initialization Actually Works

Here's exactly what happens when you use knowledge:

#### Agent-Level Knowledge (Independent)

```python
from crewai import Agent, Task, Crew
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# Agent with its own knowledge - NO crew knowledge needed
specialist_knowledge = StringKnowledgeSource(
    content="Specialized technical information for this agent only"
)

specialist_agent = Agent(
    role="Technical Specialist",
    goal="Provide technical expertise",
    backstory="Expert in specialized technical domains",
    knowledge_sources=[specialist_knowledge]  # Agent-specific knowledge
)

task = Task(
    description="Answer technical questions",
    agent=specialist_agent,
    expected_output="Technical answer"
)

# No crew-level knowledge required
crew = Crew(
    agents=[specialist_agent],
    tasks=[task]
)

result = crew.kickoff()  # Agent knowledge works independently
```

#### What Happens During `crew.kickoff()`

When you call `crew.kickoff()`, here's the exact sequence:

```python
# During kickoff
for agent in self.agents:
    agent.crew = self  # Agent gets reference to crew
    agent.set_knowledge(crew_embedder=self.embedder)  # Agent knowledge initialized
    agent.create_agent_executor()
```

#### Storage Independence

Each knowledge level uses independent storage collections:

```python
# Agent knowledge storage
agent_collection_name = agent.role  # e.g., "Technical Specialist"

# Crew knowledge storage
crew_collection_name = "crew"

# Both stored in same ChromaDB instance but different collections
# Path: ~/.local/share/CrewAI/{project}/knowledge/
#   ├── crew/                    # Crew knowledge collection
#   ├── Technical Specialist/    # Agent knowledge collection
#   └── Another Agent Role/      # Another agent's collection
```

### Complete Working Examples

#### Example 1: Agent-Only Knowledge

```python
from crewai import Agent, Task, Crew
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# Agent-specific knowledge
agent_knowledge = StringKnowledgeSource(
    content="Agent-specific information that only this agent needs"
)

agent = Agent(
    role="Specialist",
    goal="Use specialized knowledge",
    backstory="Expert with specific knowledge",
    knowledge_sources=[agent_knowledge],
    embedder={  # Agent can have its own embedder
        "provider": "openai",
        "config": {"model": "text-embedding-3-small"}
    }
)

task = Task(
    description="Answer using your specialized knowledge",
    agent=agent,
    expected_output="Answer based on agent knowledge"
)

# No crew knowledge needed
crew = Crew(agents=[agent], tasks=[task])
result = crew.kickoff()  # Works perfectly
```

#### Example 2: Both Agent and Crew Knowledge

```python
# Crew-wide knowledge (shared by all agents)
crew_knowledge = StringKnowledgeSource(
    content="Company policies and general information for all agents"
)

# Agent-specific knowledge
specialist_knowledge = StringKnowledgeSource(
    content="Technical specifications only the specialist needs"
)

specialist = Agent(
    role="Technical Specialist",
    goal="Provide technical expertise",
    backstory="Technical expert",
    knowledge_sources=[specialist_knowledge]  # Agent-specific
)

generalist = Agent(
    role="General Assistant",
    goal="Provide general assistance",
    backstory="General helper"
    # No agent-specific knowledge
)

crew = Crew(
    agents=[specialist, generalist],
    tasks=[...],
    knowledge_sources=[crew_knowledge]  # Crew-wide knowledge
)

# Result:
# - specialist gets: crew_knowledge + specialist_knowledge
# - generalist gets: crew_knowledge only
```

#### Example 3: Multiple Agents with Different Knowledge

```python
# Different knowledge for different agents
sales_knowledge = StringKnowledgeSource(content="Sales procedures and pricing")
tech_knowledge = StringKnowledgeSource(content="Technical documentation")
support_knowledge = StringKnowledgeSource(content="Support procedures")

sales_agent = Agent(
    role="Sales Representative",
    knowledge_sources=[sales_knowledge],
    embedder={"provider": "openai", "config": {"model": "text-embedding-3-small"}}
)

tech_agent = Agent(
    role="Technical Expert",
    knowledge_sources=[tech_knowledge],
    embedder={"provider": "ollama", "config": {"model": "mxbai-embed-large"}}
)

support_agent = Agent(
    role="Support Specialist",
    knowledge_sources=[support_knowledge]
    # Will use crew embedder as fallback
)

crew = Crew(
    agents=[sales_agent, tech_agent, support_agent],
    tasks=[...],
    embedder={  # Fallback embedder for agents without their own
        "provider": "google",
        "config": {"model": "text-embedding-004"}
    }
)

# Each agent gets only their specific knowledge
# Each can use different embedding providers
```

<Tip>
  Unlike retrieval from a vector database using a tool, agents preloaded with knowledge will not need a retrieval persona or task.
  Simply add the relevant knowledge sources your agent or crew needs to function.

  Knowledge sources can be added at the agent or crew level.
  Crew level knowledge sources will be used by **all agents** in the crew.
  Agent level knowledge sources will be used by the **specific agent** that is preloaded with the knowledge.
</Tip>

## Knowledge Configuration

You can configure the knowledge configuration for the crew or agent.

```python Code
from crewai.knowledge.knowledge_config import KnowledgeConfig

knowledge_config = KnowledgeConfig(results_limit=10, score_threshold=0.5)

agent = Agent(
    ...
    knowledge_config=knowledge_config
)
```

<Tip>
  `results_limit`: is the number of relevant documents to return. Default is 3.
  `score_threshold`: is the minimum score for a document to be considered relevant. Default is 0.35.
</Tip>

## Supported Knowledge Parameters

<ParamField body="sources" type="List[BaseKnowledgeSource]" required="Yes">
  List of knowledge sources that provide content to be stored and queried. Can include PDF, CSV, Excel, JSON, text files, or string content.
</ParamField>

<ParamField body="collection_name" type="str">
  Name of the collection where the knowledge will be stored. Used to identify different sets of knowledge. Defaults to "knowledge" if not provided.
</ParamField>

<ParamField body="storage" type="Optional[KnowledgeStorage]">
  Custom storage configuration for managing how the knowledge is stored and retrieved. If not provided, a default storage will be created.
</ParamField>

## Knowledge Storage Transparency

<Info>
  **Understanding Knowledge Storage**: CrewAI automatically stores knowledge sources in platform-specific directories using ChromaDB for vector storage. Understanding these locations and defaults helps with production deployments, debugging, and storage management.
</Info>

### Where CrewAI Stores Knowledge Files

By default, CrewAI uses the same storage system as memory, storing knowledge in platform-specific directories:

#### Default Storage Locations by Platform

**macOS:**

```
~/Library/Application Support/CrewAI/{project_name}/
└── knowledge/                    # Knowledge ChromaDB files
    ├── chroma.sqlite3           # ChromaDB metadata
    ├── {collection_id}/         # Vector embeddings
    └── knowledge_{collection}/  # Named collections
```

**Linux:**

```
~/.local/share/CrewAI/{project_name}/
└── knowledge/
    ├── chroma.sqlite3
    ├── {collection_id}/
    └── knowledge_{collection}/
```

**Windows:**

```
C:\Users\{username}\AppData\Local\CrewAI\{project_name}\
└── knowledge\
    ├── chroma.sqlite3
    ├── {collection_id}\
    └── knowledge_{collection}\
```

### Finding Your Knowledge Storage Location

To see exactly where CrewAI is storing your knowledge files:

```python
from crewai.utilities.paths import db_storage_path
import os

# Get the knowledge storage path
knowledge_path = os.path.join(db_storage_path(), "knowledge")
print(f"Knowledge storage location: {knowledge_path}")

# List knowledge collections and files
if os.path.exists(knowledge_path):
    print("\nKnowledge storage contents:")
    for item in os.listdir(knowledge_path):
        item_path = os.path.join(knowledge_path, item)
        if os.path.isdir(item_path):
            print(f"📁 Collection: {item}/")
            # Show collection contents
            try:
                for subitem in os.listdir(item_path):
                    print(f"   └── {subitem}")
            except PermissionError:
                print(f"   └── (permission denied)")
        else:
            print(f"📄 {item}")
else:
    print("No knowledge storage found yet.")
```

### Controlling Knowledge Storage Locations

#### Option 1: Environment Variable (Recommended)

```python
import os
from crewai import Crew

# Set custom storage location for all CrewAI data
os.environ["CREWAI_STORAGE_DIR"] = "./my_project_storage"

# All knowledge will now be stored in ./my_project_storage/knowledge/
crew = Crew(
    agents=[...],
    tasks=[...],
    knowledge_sources=[...]
)
```

#### Option 2: Custom Knowledge Storage

```python
from crewai.knowledge.storage.knowledge_storage import KnowledgeStorage
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# Create custom storage with specific embedder
custom_storage = KnowledgeStorage(
    embedder={
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    },
    collection_name="my_custom_knowledge"
)

# Use with knowledge sources
knowledge_source = StringKnowledgeSource(
    content="Your knowledge content here"
)
knowledge_source.storage = custom_storage
```

#### Option 3: Project-Specific Knowledge Storage

```python
import os
from pathlib import Path

# Store knowledge in project directory
project_root = Path(__file__).parent
knowledge_dir = project_root / "knowledge_storage"

os.environ["CREWAI_STORAGE_DIR"] = str(knowledge_dir)

# Now all knowledge will be stored in your project directory
```

### Default Embedding Provider Behavior

<Info>
  **Default Embedding Provider**: CrewAI defaults to OpenAI embeddings (`text-embedding-3-small`) for knowledge storage, even when using different LLM providers. You can easily customize this to match your setup.
</Info>

#### Understanding Default Behavior

```python
from crewai import Agent, Crew, LLM
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# When using Claude as your LLM...
agent = Agent(
    role="Researcher",
    goal="Research topics",
    backstory="Expert researcher",
    llm=LLM(provider="anthropic", model="claude-3-sonnet")  # Using Claude
)

# CrewAI will still use OpenAI embeddings by default for knowledge
# This ensures consistency but may not match your LLM provider preference
knowledge_source = StringKnowledgeSource(content="Research data...")

crew = Crew(
    agents=[agent],
    tasks=[...],
    knowledge_sources=[knowledge_source]
    # Default: Uses OpenAI embeddings even with Claude LLM
)
```

#### Customizing Knowledge Embedding Providers

```python
# Option 1: Use Voyage AI (recommended by Anthropic for Claude users)
crew = Crew(
    agents=[agent],
    tasks=[...],
    knowledge_sources=[knowledge_source],
    embedder={
        "provider": "voyageai",  # Recommended for Claude users
        "config": {
            "api_key": "your-voyage-api-key",
            "model": "voyage-3"  # or "voyage-3-large" for best quality
        }
    }
)

# Option 2: Use local embeddings (no external API calls)
crew = Crew(
    agents=[agent],
    tasks=[...],
    knowledge_sources=[knowledge_source],
    embedder={
        "provider": "ollama",
        "config": {
            "model": "mxbai-embed-large",
            "url": "http://localhost:11434/api/embeddings"
        }
    }
)

# Option 3: Agent-level embedding customization
agent = Agent(
    role="Researcher",
    goal="Research topics",
    backstory="Expert researcher",
    knowledge_sources=[knowledge_source],
    embedder={
        "provider": "google",
        "config": {
            "model": "models/text-embedding-004",
            "api_key": "your-google-key"
        }
    }
)
```

#### Configuring Azure OpenAI Embeddings

When using Azure OpenAI embeddings:

1. Make sure you deploy the embedding model in Azure platform first
2. Then you need to use the following configuration:

```python
agent = Agent(
    role="Researcher",
    goal="Research topics",
    backstory="Expert researcher",
    knowledge_sources=[knowledge_source],
    embedder={
        "provider": "azure",
        "config": {
            "api_key": "your-azure-api-key",
            "model": "text-embedding-ada-002", # change to the model you are using and is deployed in Azure
            "api_base": "https://your-azure-endpoint.openai.azure.com/",
            "api_version": "2024-02-01"
        }
    }
)
```

## Advanced Features

### Query Rewriting

CrewAI implements an intelligent query rewriting mechanism to optimize knowledge retrieval. When an agent needs to search through knowledge sources, the raw task prompt is automatically transformed into a more effective search query.

#### How Query Rewriting Works

1. When an agent executes a task with knowledge sources available, the `_get_knowledge_search_query` method is triggered
2. The agent's LLM is used to transform the original task prompt into an optimized search query
3. This optimized query is then used to retrieve relevant information from knowledge sources

#### Benefits of Query Rewriting

<CardGroup cols={2}>
  <Card title="Improved Retrieval Accuracy" icon="bullseye-arrow">
    By focusing on key concepts and removing irrelevant content, query rewriting helps retrieve more relevant information.
  </Card>

  <Card title="Context Awareness" icon="brain">
    The rewritten queries are designed to be more specific and context-aware for vector database retrieval.
  </Card>
</CardGroup>

#### Example

```python
# Original task prompt
task_prompt = "Answer the following questions about the user's favorite movies: What movie did John watch last week? Format your answer in JSON."

# Behind the scenes, this might be rewritten as:
rewritten_query = "What movies did John watch last week?"
```

The rewritten query is more focused on the core information need and removes irrelevant instructions about output formatting.

<Tip>
  This mechanism is fully automatic and requires no configuration from users. The agent's LLM is used to perform the query rewriting, so using a more capable LLM can improve the quality of rewritten queries.
</Tip>

### Knowledge Events

CrewAI emits events during the knowledge retrieval process that you can listen for using the event system. These events allow you to monitor, debug, and analyze how knowledge is being retrieved and used by your agents.

#### Available Knowledge Events

* **KnowledgeRetrievalStartedEvent**: Emitted when an agent starts retrieving knowledge from sources
* **KnowledgeRetrievalCompletedEvent**: Emitted when knowledge retrieval is completed, including the query used and the retrieved content
* **KnowledgeQueryStartedEvent**: Emitted when a query to knowledge sources begins
* **KnowledgeQueryCompletedEvent**: Emitted when a query completes successfully
* **KnowledgeQueryFailedEvent**: Emitted when a query to knowledge sources fails
* **KnowledgeSearchQueryFailedEvent**: Emitted when a search query fails

#### Example: Monitoring Knowledge Retrieval

```python
from crewai.utilities.events import (
    KnowledgeRetrievalStartedEvent,
    KnowledgeRetrievalCompletedEvent,
)
from crewai.utilities.events.base_event_listener import BaseEventListener

class KnowledgeMonitorListener(BaseEventListener):
    def setup_listeners(self, crewai_event_bus):
        @crewai_event_bus.on(KnowledgeRetrievalStartedEvent)
        def on_knowledge_retrieval_started(source, event):
            print(f"Agent '{event.agent.role}' started retrieving knowledge")

        @crewai_event_bus.on(KnowledgeRetrievalCompletedEvent)
        def on_knowledge_retrieval_completed(source, event):
            print(f"Agent '{event.agent.role}' completed knowledge retrieval")
            print(f"Query: {event.query}")
            print(f"Retrieved {len(event.retrieved_knowledge)} knowledge chunks")

# Create an instance of your listener
knowledge_monitor = KnowledgeMonitorListener()
```

For more information on using events, see the [Event Listeners](https://docs.crewai.com/concepts/event-listener) documentation.

### Custom Knowledge Sources

CrewAI allows you to create custom knowledge sources for any type of data by extending the `BaseKnowledgeSource` class. Let's create a practical example that fetches and processes space news articles.

#### Space News Knowledge Source Example

<CodeGroup>
  ```python Code
  from crewai import Agent, Task, Crew, Process, LLM
  from crewai.knowledge.source.base_knowledge_source import BaseKnowledgeSource
  import requests
  from datetime import datetime
  from typing import Dict, Any
  from pydantic import BaseModel, Field

  class SpaceNewsKnowledgeSource(BaseKnowledgeSource):
      """Knowledge source that fetches data from Space News API."""

      api_endpoint: str = Field(description="API endpoint URL")
      limit: int = Field(default=10, description="Number of articles to fetch")

      def load_content(self) -> Dict[Any, str]:
          """Fetch and format space news articles."""
          try:
              response = requests.get(
                  f"{self.api_endpoint}?limit={self.limit}"
              )
              response.raise_for_status()

              data = response.json()
              articles = data.get('results', [])

              formatted_data = self.validate_content(articles)
              return {self.api_endpoint: formatted_data}
          except Exception as e:
              raise ValueError(f"Failed to fetch space news: {str(e)}")

      def validate_content(self, articles: list) -> str:
          """Format articles into readable text."""
          formatted = "Space News Articles:\n\n"
          for article in articles:
              formatted += f"""
                  Title: {article['title']}
                  Published: {article['published_at']}
                  Summary: {article['summary']}
                  News Site: {article['news_site']}
                  URL: {article['url']}
                  -------------------"""
          return formatted

      def add(self) -> None:
          """Process and store the articles."""
          content = self.load_content()
          for _, text in content.items():
              chunks = self._chunk_text(text)
              self.chunks.extend(chunks)

          self._save_documents()

  # Create knowledge source
  recent_news = SpaceNewsKnowledgeSource(
      api_endpoint="https://api.spaceflightnewsapi.net/v4/articles",
      limit=10,
  )

  # Create specialized agent
  space_analyst = Agent(
      role="Space News Analyst",
      goal="Answer questions about space news accurately and comprehensively",
      backstory="""You are a space industry analyst with expertise in space exploration,
      satellite technology, and space industry trends. You excel at answering questions
      about space news and providing detailed, accurate information.""",
      knowledge_sources=[recent_news],
      llm=LLM(model="gpt-4", temperature=0.0)
  )

  # Create task that handles user questions
  analysis_task = Task(
      description="Answer this question about space news: {user_question}",
      expected_output="A detailed answer based on the recent space news articles",
      agent=space_analyst
  )

  # Create and run the crew
  crew = Crew(
      agents=[space_analyst],
      tasks=[analysis_task],
      verbose=True,
      process=Process.sequential
  )

  # Example usage
  result = crew.kickoff(
      inputs={"user_question": "What are the latest developments in space exploration?"}
  )
  ```

  ```output Output
  # Agent: Space News Analyst
  ## Task: Answer this question about space news: What are the latest developments in space exploration?


  # Agent: Space News Analyst
  ## Final Answer:
  The latest developments in space exploration, based on recent space news articles, include the following:

  1. SpaceX has received the final regulatory approvals to proceed with the second integrated Starship/Super Heavy launch, scheduled for as soon as the morning of Nov. 17, 2023. This is a significant step in SpaceX's ambitious plans for space exploration and colonization. [Source: SpaceNews](https://spacenews.com/starship-cleared-for-nov-17-launch/)

  2. SpaceX has also informed the US Federal Communications Commission (FCC) that it plans to begin launching its first next-generation Starlink Gen2 satellites. This represents a major upgrade to the Starlink satellite internet service, which aims to provide high-speed internet access worldwide. [Source: Teslarati](https://www.teslarati.com/spacex-first-starlink-gen2-satellite-launch-2022/)

  3. AI startup Synthetaic has raised $15 million in Series B funding. The company uses artificial intelligence to analyze data from space and air sensors, which could have significant applications in space exploration and satellite technology. [Source: SpaceNews](https://spacenews.com/ai-startup-synthetaic-raises-15-million-in-series-b-funding/)

  4. The Space Force has formally established a unit within the U.S. Indo-Pacific Command, marking a permanent presence in the Indo-Pacific region. This could have significant implications for space security and geopolitics. [Source: SpaceNews](https://spacenews.com/space-force-establishes-permanent-presence-in-indo-pacific-region/)

  5. Slingshot Aerospace, a space tracking and data analytics company, is expanding its network of ground-based optical telescopes to increase coverage of low Earth orbit. This could improve our ability to track and analyze objects in low Earth orbit, including satellites and space debris. [Source: SpaceNews](https://spacenews.com/slingshots-space-tracking-network-to-extend-coverage-of-low-earth-orbit/)

  6. The National Natural Science Foundation of China has outlined a five-year project for researchers to study the assembly of ultra-large spacecraft. This could lead to significant advancements in spacecraft technology and space exploration capabilities. [Source: SpaceNews](https://spacenews.com/china-researching-challenges-of-kilometer-scale-ultra-large-spacecraft/)

  7. The Center for AEroSpace Autonomy Research (CAESAR) at Stanford University is focusing on spacecraft autonomy. The center held a kickoff event on May 22, 2024, to highlight the industry, academia, and government collaboration it seeks to foster. This could lead to significant advancements in autonomous spacecraft technology. [Source: SpaceNews](https://spacenews.com/stanford-center-focuses-on-spacecraft-autonomy/)
  ```
</CodeGroup>

## Debugging and Troubleshooting

### Debugging Knowledge Issues

#### Check Agent Knowledge Initialization

```python
from crewai import Agent, Crew, Task
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

knowledge_source = StringKnowledgeSource(content="Test knowledge")

agent = Agent(
    role="Test Agent",
    goal="Test knowledge",
    backstory="Testing",
    knowledge_sources=[knowledge_source]
)

crew = Crew(agents=[agent], tasks=[Task(...)])

# Before kickoff - knowledge not initialized
print(f"Before kickoff - Agent knowledge: {getattr(agent, 'knowledge', None)}")

crew.kickoff()

# After kickoff - knowledge initialized
print(f"After kickoff - Agent knowledge: {agent.knowledge}")
print(f"Agent knowledge collection: {agent.knowledge.storage.collection_name}")
print(f"Number of sources: {len(agent.knowledge.sources)}")
```

#### Verify Knowledge Storage Locations

```python
import os
from crewai.utilities.paths import db_storage_path

# Check storage structure
storage_path = db_storage_path()
knowledge_path = os.path.join(storage_path, "knowledge")

if os.path.exists(knowledge_path):
    print("Knowledge collections found:")
    for collection in os.listdir(knowledge_path):
        collection_path = os.path.join(knowledge_path, collection)
        if os.path.isdir(collection_path):
            print(f"  - {collection}/")
            # Show collection contents
            for item in os.listdir(collection_path):
                print(f"    └── {item}")
```

#### Test Knowledge Retrieval

```python
# Test agent knowledge retrieval
if hasattr(agent, 'knowledge') and agent.knowledge:
    test_query = ["test query"]
    results = agent.knowledge.query(test_query)
    print(f"Agent knowledge results: {len(results)} documents found")

    # Test crew knowledge retrieval (if exists)
    if hasattr(crew, 'knowledge') and crew.knowledge:
        crew_results = crew.query_knowledge(test_query)
        print(f"Crew knowledge results: {len(crew_results)} documents found")
```

#### Inspect Knowledge Collections

```python
import chromadb
from crewai.utilities.paths import db_storage_path
import os

# Connect to CrewAI's knowledge ChromaDB
knowledge_path = os.path.join(db_storage_path(), "knowledge")

if os.path.exists(knowledge_path):
    client = chromadb.PersistentClient(path=knowledge_path)
    collections = client.list_collections()

    print("Knowledge Collections:")
    for collection in collections:
        print(f"  - {collection.name}: {collection.count()} documents")

        # Sample a few documents to verify content
        if collection.count() > 0:
            sample = collection.peek(limit=2)
            print(f"    Sample content: {sample['documents'][0][:100]}...")
else:
    print("No knowledge storage found")
```

#### Check Knowledge Processing

```python
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# Create a test knowledge source
test_source = StringKnowledgeSource(
    content="Test knowledge content for debugging",
    chunk_size=100,  # Small chunks for testing
    chunk_overlap=20
)

# Check chunking behavior
print(f"Original content length: {len(test_source.content)}")
print(f"Chunk size: {test_source.chunk_size}")
print(f"Chunk overlap: {test_source.chunk_overlap}")

# Process and inspect chunks
test_source.add()
print(f"Number of chunks created: {len(test_source.chunks)}")
for i, chunk in enumerate(test_source.chunks[:3]):  # Show first 3 chunks
    print(f"Chunk {i+1}: {chunk[:50]}...")
```

### Common Knowledge Storage Issues

**"File not found" errors:**

```python
# Ensure files are in the correct location
from crewai.utilities.constants import KNOWLEDGE_DIRECTORY
import os

knowledge_dir = KNOWLEDGE_DIRECTORY  # Usually "knowledge"
file_path = os.path.join(knowledge_dir, "your_file.pdf")

if not os.path.exists(file_path):
    print(f"File not found: {file_path}")
    print(f"Current working directory: {os.getcwd()}")
    print(f"Expected knowledge directory: {os.path.abspath(knowledge_dir)}")
```

**"Embedding dimension mismatch" errors:**

```python
# This happens when switching embedding providers
# Reset knowledge storage to clear old embeddings
crew.reset_memories(command_type='knowledge')

# Or use consistent embedding providers
crew = Crew(
    agents=[...],
    tasks=[...],
    knowledge_sources=[...],
    embedder={"provider": "openai", "config": {"model": "text-embedding-3-small"}}
)
```

**"ChromaDB permission denied" errors:**

```bash
# Fix storage permissions
chmod -R 755 ~/.local/share/CrewAI/
```

**Knowledge not persisting between runs:**

```python
# Verify storage location consistency
import os
from crewai.utilities.paths import db_storage_path

print("CREWAI_STORAGE_DIR:", os.getenv("CREWAI_STORAGE_DIR"))
print("Computed storage path:", db_storage_path())
print("Knowledge path:", os.path.join(db_storage_path(), "knowledge"))
```

### Knowledge Reset Commands

```python
# Reset only agent-specific knowledge
crew.reset_memories(command_type='agent_knowledge')

# Reset both crew and agent knowledge
crew.reset_memories(command_type='knowledge')

# CLI commands
# crewai reset-memories --agent-knowledge  # Agent knowledge only
# crewai reset-memories --knowledge        # All knowledge
```

### Clearing Knowledge

If you need to clear the knowledge stored in CrewAI, you can use the `crewai reset-memories` command with the `--knowledge` option.

```bash Command
crewai reset-memories --knowledge
```

This is useful when you've updated your knowledge sources and want to ensure that the agents are using the most recent information.

## Best Practices

<AccordionGroup>
  <Accordion title="Content Organization">
    * Keep chunk sizes appropriate for your content type
    * Consider content overlap for context preservation
    * Organize related information into separate knowledge sources
  </Accordion>

  <Accordion title="Performance Tips">
    * Adjust chunk sizes based on content complexity
    * Configure appropriate embedding models
    * Consider using local embedding providers for faster processing
  </Accordion>

  <Accordion title="One Time Knowledge">
    * With the typical file structure provided by CrewAI, knowledge sources are embedded every time the kickoff is triggered.
    * If the knowledge sources are large, this leads to inefficiency and increased latency, as the same data is embedded each time.
    * To resolve this, directly initialize the knowledge parameter instead of the knowledge\_sources parameter.
    * Link to the issue to get complete idea [Github Issue](https://github.com/crewAIInc/crewAI/issues/2755)
  </Accordion>

  <Accordion title="Knowledge Management">
    * Use agent-level knowledge for role-specific information
    * Use crew-level knowledge for shared information all agents need
    * Set embedders at agent level if you need different embedding strategies
    * Use consistent collection naming by keeping agent roles descriptive
    * Test knowledge initialization by checking agent.knowledge after kickoff
    * Monitor storage locations to understand where knowledge is stored
    * Reset knowledge appropriately using the correct command types
  </Accordion>

  <Accordion title="Production Best Practices">
    * Set `CREWAI_STORAGE_DIR` to a known location in production
    * Choose explicit embedding providers to match your LLM setup and avoid API key conflicts
    * Monitor knowledge storage size as it grows with document additions
    * Organize knowledge sources by domain or purpose using collection names
    * Include knowledge directories in your backup and deployment strategies
    * Set appropriate file permissions for knowledge files and storage directories
    * Use environment variables for API keys and sensitive configuration
  </Accordion>
</AccordionGroup>


# LLMs
Source: https://docs.crewai.com/en/concepts/llms

A comprehensive guide to configuring and using Large Language Models (LLMs) in your CrewAI projects

## Overview

CrewAI integrates with multiple LLM providers through LiteLLM, giving you the flexibility to choose the right model for your specific use case. This guide will help you understand how to configure and use different LLM providers in your CrewAI projects.

## What are LLMs?

Large Language Models (LLMs) are the core intelligence behind CrewAI agents. They enable agents to understand context, make decisions, and generate human-like responses. Here's what you need to know:

<CardGroup cols={2}>
  <Card title="LLM Basics" icon="brain">
    Large Language Models are AI systems trained on vast amounts of text data. They power the intelligence of your CrewAI agents, enabling them to understand and generate human-like text.
  </Card>

  <Card title="Context Window" icon="window">
    The context window determines how much text an LLM can process at once. Larger windows (e.g., 128K tokens) allow for more context but may be more expensive and slower.
  </Card>

  <Card title="Temperature" icon="temperature-three-quarters">
    Temperature (0.0 to 1.0) controls response randomness. Lower values (e.g., 0.2) produce more focused, deterministic outputs, while higher values (e.g., 0.8) increase creativity and variability.
  </Card>

  <Card title="Provider Selection" icon="server">
    Each LLM provider (e.g., OpenAI, Anthropic, Google) offers different models with varying capabilities, pricing, and features. Choose based on your needs for accuracy, speed, and cost.
  </Card>
</CardGroup>

## Setting up your LLM

There are different places in CrewAI code where you can specify the model to use. Once you specify the model you are using, you will need to provide the configuration (like an API key) for each of the model providers you use. See the [provider configuration examples](#provider-configuration-examples) section for your provider.

<Tabs>
  <Tab title="1. Environment Variables">
    The simplest way to get started. Set the model in your environment directly, through an `.env` file or in your app code. If you used `crewai create` to bootstrap your project, it will be set already.

    ```bash .env
    MODEL=model-id  # e.g. gpt-4o, gemini-2.0-flash, claude-3-sonnet-...

    # Be sure to set your API keys here too. See the Provider
    # section below.
    ```

    <Warning>
      Never commit API keys to version control. Use environment files (.env) or your system's secret management.
    </Warning>
  </Tab>

  <Tab title="2. YAML Configuration">
    Create a YAML file to define your agent configurations. This method is great for version control and team collaboration:

    ```yaml agents.yaml {6}
    researcher:
        role: Research Specialist
        goal: Conduct comprehensive research and analysis
        backstory: A dedicated research professional with years of experience
        verbose: true
        llm: provider/model-id  # e.g. openai/gpt-4o, google/gemini-2.0-flash, anthropic/claude...
        # (see provider configuration examples below for more)
    ```

    <Info>
      The YAML configuration allows you to:

      * Version control your agent settings
      * Easily switch between different models
      * Share configurations across team members
      * Document model choices and their purposes
    </Info>
  </Tab>

  <Tab title="3. Direct Code">
    For maximum flexibility, configure LLMs directly in your Python code:

    ```python {4,8}
    from crewai import LLM

    # Basic configuration
    llm = LLM(model="model-id-here")  # gpt-4o, gemini-2.0-flash, anthropic/claude...

    # Advanced configuration with detailed parameters
    llm = LLM(
        model="model-id-here",  # gpt-4o, gemini-2.0-flash, anthropic/claude...
        temperature=0.7,        # Higher for more creative outputs
        timeout=120,            # Seconds to wait for response
        max_tokens=4000,        # Maximum length of response
        top_p=0.9,              # Nucleus sampling parameter
        frequency_penalty=0.1 , # Reduce repetition
        presence_penalty=0.1,   # Encourage topic diversity
        response_format={"type": "json"},  # For structured outputs
        seed=42                 # For reproducible results
    )
    ```

    <Info>
      Parameter explanations:

      * `temperature`: Controls randomness (0.0-1.0)
      * `timeout`: Maximum wait time for response
      * `max_tokens`: Limits response length
      * `top_p`: Alternative to temperature for sampling
      * `frequency_penalty`: Reduces word repetition
      * `presence_penalty`: Encourages new topics
      * `response_format`: Specifies output structure
      * `seed`: Ensures consistent outputs
    </Info>
  </Tab>
</Tabs>

## Provider Configuration Examples

CrewAI supports a multitude of LLM providers, each offering unique features, authentication methods, and model capabilities.
In this section, you'll find detailed examples that help you select, configure, and optimize the LLM that best fits your project's needs.

<AccordionGroup>
  <Accordion title="OpenAI">
    Set the following environment variables in your `.env` file:

    ```toml Code
    # Required
    OPENAI_API_KEY=sk-...

    # Optional
    OPENAI_API_BASE=<custom-base-url>
    OPENAI_ORGANIZATION=<your-org-id>
    ```

    Example usage in your CrewAI project:

    ```python Code
    from crewai import LLM

    llm = LLM(
        model="openai/gpt-4", # call model by provider/model_name
        temperature=0.8,
        max_tokens=150,
        top_p=0.9,
        frequency_penalty=0.1,
        presence_penalty=0.1,
        stop=["END"],
        seed=42
    )
    ```

    OpenAI is one of the leading providers of LLMs with a wide range of models and features.

    | Model                | Context Window | Best For                                |
    | -------------------- | -------------- | --------------------------------------- |
    | GPT-4                | 8,192 tokens   | High-accuracy tasks, complex reasoning  |
    | GPT-4 Turbo          | 128,000 tokens | Long-form content, document analysis    |
    | GPT-4o & GPT-4o-mini | 128,000 tokens | Cost-effective large context processing |
    | o3-mini              | 200,000 tokens | Fast reasoning, complex reasoning       |
    | o1-mini              | 128,000 tokens | Fast reasoning, complex reasoning       |
    | o1-preview           | 128,000 tokens | Fast reasoning, complex reasoning       |
    | o1                   | 200,000 tokens | Fast reasoning, complex reasoning       |
  </Accordion>

  <Accordion title="Meta-Llama">
    Meta's Llama API provides access to Meta's family of large language models.
    The API is available through the [Meta Llama API](https://llama.developer.meta.com?utm_source=partner-crewai\&utm_medium=website).
    Set the following environment variables in your `.env` file:

    ```toml Code
    # Meta Llama API Key Configuration
    LLAMA_API_KEY=LLM|your_api_key_here
    ```

    Example usage in your CrewAI project:

    ```python Code
    from crewai import LLM

    # Initialize Meta Llama LLM
    llm = LLM(
        model="meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8",
        temperature=0.8,
        stop=["END"],
        seed=42
    )
    ```

    All models listed here [https://llama.developer.meta.com/docs/models/](https://llama.developer.meta.com/docs/models/) are supported.

    | Model ID                                            | Input context length | Output context length | Input Modalities | Output Modalities |
    | --------------------------------------------------- | -------------------- | --------------------- | ---------------- | ----------------- |
    | `meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8`     | 128k                 | 4028                  | Text, Image      | Text              |
    | `meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8` | 128k                 | 4028                  | Text, Image      | Text              |
    | `meta_llama/Llama-3.3-70B-Instruct`                 | 128k                 | 4028                  | Text             | Text              |
    | `meta_llama/Llama-3.3-8B-Instruct`                  | 128k                 | 4028                  | Text             | Text              |
  </Accordion>

  <Accordion title="Anthropic">
    ```toml Code
    # Required
    ANTHROPIC_API_KEY=sk-ant-...

    # Optional
    ANTHROPIC_API_BASE=<custom-base-url>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="anthropic/claude-3-sonnet-20240229-v1:0",
        temperature=0.7
    )
    ```
  </Accordion>

  <Accordion title="Google (Gemini API)">
    Set your API key in your `.env` file. If you need a key, or need to find an
    existing key, check [AI Studio](https://aistudio.google.com/apikey).

    ```toml .env
    # https://ai.google.dev/gemini-api/docs/api-key
    GEMINI_API_KEY=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    from crewai import LLM

    llm = LLM(
        model="gemini/gemini-2.0-flash",
        temperature=0.7,
    )
    ```

    ### Gemini models

    Google offers a range of powerful models optimized for different use cases.

    | Model                          | Context Window | Best For                                                                                                         |
    | ------------------------------ | -------------- | ---------------------------------------------------------------------------------------------------------------- |
    | gemini-2.5-flash-preview-04-17 | 1M tokens      | Adaptive thinking, cost efficiency                                                                               |
    | gemini-2.5-pro-preview-05-06   | 1M tokens      | Enhanced thinking and reasoning, multimodal understanding, advanced coding, and more                             |
    | gemini-2.0-flash               | 1M tokens      | Next generation features, speed, thinking, and realtime streaming                                                |
    | gemini-2.0-flash-lite          | 1M tokens      | Cost efficiency and low latency                                                                                  |
    | gemini-1.5-flash               | 1M tokens      | Balanced multimodal model, good for most tasks                                                                   |
    | gemini-1.5-flash-8B            | 1M tokens      | Fastest, most cost-efficient, good for high-frequency tasks                                                      |
    | gemini-1.5-pro                 | 2M tokens      | Best performing, wide variety of reasoning tasks including logical reasoning, coding, and creative collaboration |

    The full list of models is available in the [Gemini model docs](https://ai.google.dev/gemini-api/docs/models).

    ### Gemma

    The Gemini API also allows you to use your API key to access [Gemma models](https://ai.google.dev/gemma/docs) hosted on Google infrastructure.

    | Model          | Context Window |
    | -------------- | -------------- |
    | gemma-3-1b-it  | 32k tokens     |
    | gemma-3-4b-it  | 32k tokens     |
    | gemma-3-12b-it | 32k tokens     |
    | gemma-3-27b-it | 128k tokens    |
  </Accordion>

  <Accordion title="Google (Vertex AI)">
    Get credentials from your Google Cloud Console and save it to a JSON file, then load it with the following code:

    ```python Code
    import json

    file_path = 'path/to/vertex_ai_service_account.json'

    # Load the JSON file
    with open(file_path, 'r') as file:
        vertex_credentials = json.load(file)

    # Convert the credentials to a JSON string
    vertex_credentials_json = json.dumps(vertex_credentials)
    ```

    Example usage in your CrewAI project:

    ```python Code
    from crewai import LLM

    llm = LLM(
        model="gemini/gemini-1.5-pro-latest",
        temperature=0.7,
        vertex_credentials=vertex_credentials_json
    )
    ```

    Google offers a range of powerful models optimized for different use cases:

    | Model                          | Context Window | Best For                                                                                                         |
    | ------------------------------ | -------------- | ---------------------------------------------------------------------------------------------------------------- |
    | gemini-2.5-flash-preview-04-17 | 1M tokens      | Adaptive thinking, cost efficiency                                                                               |
    | gemini-2.5-pro-preview-05-06   | 1M tokens      | Enhanced thinking and reasoning, multimodal understanding, advanced coding, and more                             |
    | gemini-2.0-flash               | 1M tokens      | Next generation features, speed, thinking, and realtime streaming                                                |
    | gemini-2.0-flash-lite          | 1M tokens      | Cost efficiency and low latency                                                                                  |
    | gemini-1.5-flash               | 1M tokens      | Balanced multimodal model, good for most tasks                                                                   |
    | gemini-1.5-flash-8B            | 1M tokens      | Fastest, most cost-efficient, good for high-frequency tasks                                                      |
    | gemini-1.5-pro                 | 2M tokens      | Best performing, wide variety of reasoning tasks including logical reasoning, coding, and creative collaboration |
  </Accordion>

  <Accordion title="Azure">
    ```toml Code
    # Required
    AZURE_API_KEY=<your-api-key>
    AZURE_API_BASE=<your-resource-url>
    AZURE_API_VERSION=<api-version>

    # Optional
    AZURE_AD_TOKEN=<your-azure-ad-token>
    AZURE_API_TYPE=<your-azure-api-type>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="azure/gpt-4",
        api_version="2023-05-15"
    )
    ```
  </Accordion>

  <Accordion title="AWS Bedrock">
    ```toml Code
    AWS_ACCESS_KEY_ID=<your-access-key>
    AWS_SECRET_ACCESS_KEY=<your-secret-key>
    AWS_DEFAULT_REGION=<your-region>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="bedrock/anthropic.claude-3-sonnet-20240229-v1:0"
    )
    ```

    Before using Amazon Bedrock, make sure you have boto3 installed in your environment

    [Amazon Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/models-regions.html) is a managed service that provides access to multiple foundation models from top AI companies through a unified API, enabling secure and responsible AI application development.

    | Model                   | Context Window     | Best For                                                                                                                              |
    | ----------------------- | ------------------ | ------------------------------------------------------------------------------------------------------------------------------------- |
    | Amazon Nova Pro         | Up to 300k tokens  | High-performance, model balancing accuracy, speed, and cost-effectiveness across diverse tasks.                                       |
    | Amazon Nova Micro       | Up to 128k tokens  | High-performance, cost-effective text-only model optimized for lowest latency responses.                                              |
    | Amazon Nova Lite        | Up to 300k tokens  | High-performance, affordable multimodal processing for images, video, and text with real-time capabilities.                           |
    | Claude 3.7 Sonnet       | Up to 128k tokens  | High-performance, best for complex reasoning, coding & AI agents                                                                      |
    | Claude 3.5 Sonnet v2    | Up to 200k tokens  | State-of-the-art model specialized in software engineering, agentic capabilities, and computer interaction at optimized cost.         |
    | Claude 3.5 Sonnet       | Up to 200k tokens  | High-performance model delivering superior intelligence and reasoning across diverse tasks with optimal speed-cost balance.           |
    | Claude 3.5 Haiku        | Up to 200k tokens  | Fast, compact multimodal model optimized for quick responses and seamless human-like interactions                                     |
    | Claude 3 Sonnet         | Up to 200k tokens  | Multimodal model balancing intelligence and speed for high-volume deployments.                                                        |
    | Claude 3 Haiku          | Up to 200k tokens  | Compact, high-speed multimodal model optimized for quick responses and natural conversational interactions                            |
    | Claude 3 Opus           | Up to 200k tokens  | Most advanced multimodal model exceling at complex tasks with human-like reasoning and superior contextual understanding.             |
    | Claude 2.1              | Up to 200k tokens  | Enhanced version with expanded context window, improved reliability, and reduced hallucinations for long-form and RAG applications    |
    | Claude                  | Up to 100k tokens  | Versatile model excelling in sophisticated dialogue, creative content, and precise instruction following.                             |
    | Claude Instant          | Up to 100k tokens  | Fast, cost-effective model for everyday tasks like dialogue, analysis, summarization, and document Q\&A                               |
    | Llama 3.1 405B Instruct | Up to 128k tokens  | Advanced LLM for synthetic data generation, distillation, and inference for chatbots, coding, and domain-specific tasks.              |
    | Llama 3.1 70B Instruct  | Up to 128k tokens  | Powers complex conversations with superior contextual understanding, reasoning and text generation.                                   |
    | Llama 3.1 8B Instruct   | Up to 128k tokens  | Advanced state-of-the-art model with language understanding, superior reasoning, and text generation.                                 |
    | Llama 3 70B Instruct    | Up to 8k tokens    | Powers complex conversations with superior contextual understanding, reasoning and text generation.                                   |
    | Llama 3 8B Instruct     | Up to 8k tokens    | Advanced state-of-the-art LLM with language understanding, superior reasoning, and text generation.                                   |
    | Titan Text G1 - Lite    | Up to 4k tokens    | Lightweight, cost-effective model optimized for English tasks and fine-tuning with focus on summarization and content generation.     |
    | Titan Text G1 - Express | Up to 8k tokens    | Versatile model for general language tasks, chat, and RAG applications with support for English and 100+ languages.                   |
    | Cohere Command          | Up to 4k tokens    | Model specialized in following user commands and delivering practical enterprise solutions.                                           |
    | Jurassic-2 Mid          | Up to 8,191 tokens | Cost-effective model balancing quality and affordability for diverse language tasks like Q\&A, summarization, and content generation. |
    | Jurassic-2 Ultra        | Up to 8,191 tokens | Model for advanced text generation and comprehension, excelling in complex tasks like analysis and content creation.                  |
    | Jamba-Instruct          | Up to 256k tokens  | Model with extended context window optimized for cost-effective text generation, summarization, and Q\&A.                             |
    | Mistral 7B Instruct     | Up to 32k tokens   | This LLM follows instructions, completes requests, and generates creative text.                                                       |
    | Mistral 8x7B Instruct   | Up to 32k tokens   | An MOE LLM that follows instructions, completes requests, and generates creative text.                                                |
  </Accordion>

  <Accordion title="Amazon SageMaker">
    ```toml Code
    AWS_ACCESS_KEY_ID=<your-access-key>
    AWS_SECRET_ACCESS_KEY=<your-secret-key>
    AWS_DEFAULT_REGION=<your-region>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="sagemaker/<my-endpoint>"
    )
    ```
  </Accordion>

  <Accordion title="Mistral">
    Set the following environment variables in your `.env` file:

    ```toml Code
    MISTRAL_API_KEY=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="mistral/mistral-large-latest",
        temperature=0.7
    )
    ```
  </Accordion>

  <Accordion title="Nvidia NIM">
    Set the following environment variables in your `.env` file:

    ```toml Code
    NVIDIA_API_KEY=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="nvidia_nim/meta/llama3-70b-instruct",
        temperature=0.7
    )
    ```

    Nvidia NIM provides a comprehensive suite of models for various use cases, from general-purpose tasks to specialized applications.

    | Model                                       | Context Window | Best For                                                                                                                    |
    | ------------------------------------------- | -------------- | --------------------------------------------------------------------------------------------------------------------------- |
    | nvidia/mistral-nemo-minitron-8b-8k-instruct | 8,192 tokens   | State-of-the-art small language model delivering superior accuracy for chatbot, virtual assistants, and content generation. |
    | nvidia/nemotron-4-mini-hindi-4b-instruct    | 4,096 tokens   | A bilingual Hindi-English SLM for on-device inference, tailored specifically for Hindi Language.                            |
    | nvidia/llama-3.1-nemotron-70b-instruct      | 128k tokens    | Customized for enhanced helpfulness in responses                                                                            |
    | nvidia/llama3-chatqa-1.5-8b                 | 128k tokens    | Advanced LLM to generate high-quality, context-aware responses for chatbots and search engines.                             |
    | nvidia/llama3-chatqa-1.5-70b                | 128k tokens    | Advanced LLM to generate high-quality, context-aware responses for chatbots and search engines.                             |
    | nvidia/vila                                 | 128k tokens    | Multi-modal vision-language model that understands text/img/video and creates informative responses                         |
    | nvidia/neva-22                              | 4,096 tokens   | Multi-modal vision-language model that understands text/images and generates informative responses                          |
    | nvidia/nemotron-mini-4b-instruct            | 8,192 tokens   | General-purpose tasks                                                                                                       |
    | nvidia/usdcode-llama3-70b-instruct          | 128k tokens    | State-of-the-art LLM that answers OpenUSD knowledge queries and generates USD-Python code.                                  |
    | nvidia/nemotron-4-340b-instruct             | 4,096 tokens   | Creates diverse synthetic data that mimics the characteristics of real-world data.                                          |
    | meta/codellama-70b                          | 100k tokens    | LLM capable of generating code from natural language and vice versa.                                                        |
    | meta/llama2-70b                             | 4,096 tokens   | Cutting-edge large language AI model capable of generating text and code in response to prompts.                            |
    | meta/llama3-8b-instruct                     | 8,192 tokens   | Advanced state-of-the-art LLM with language understanding, superior reasoning, and text generation.                         |
    | meta/llama3-70b-instruct                    | 8,192 tokens   | Powers complex conversations with superior contextual understanding, reasoning and text generation.                         |
    | meta/llama-3.1-8b-instruct                  | 128k tokens    | Advanced state-of-the-art model with language understanding, superior reasoning, and text generation.                       |
    | meta/llama-3.1-70b-instruct                 | 128k tokens    | Powers complex conversations with superior contextual understanding, reasoning and text generation.                         |
    | meta/llama-3.1-405b-instruct                | 128k tokens    | Advanced LLM for synthetic data generation, distillation, and inference for chatbots, coding, and domain-specific tasks.    |
    | meta/llama-3.2-1b-instruct                  | 128k tokens    | Advanced state-of-the-art small language model with language understanding, superior reasoning, and text generation.        |
    | meta/llama-3.2-3b-instruct                  | 128k tokens    | Advanced state-of-the-art small language model with language understanding, superior reasoning, and text generation.        |
    | meta/llama-3.2-11b-vision-instruct          | 128k tokens    | Advanced state-of-the-art small language model with language understanding, superior reasoning, and text generation.        |
    | meta/llama-3.2-90b-vision-instruct          | 128k tokens    | Advanced state-of-the-art small language model with language understanding, superior reasoning, and text generation.        |
    | google/gemma-7b                             | 8,192 tokens   | Cutting-edge text generation model text understanding, transformation, and code generation.                                 |
    | google/gemma-2b                             | 8,192 tokens   | Cutting-edge text generation model text understanding, transformation, and code generation.                                 |
    | google/codegemma-7b                         | 8,192 tokens   | Cutting-edge model built on Google's Gemma-7B specialized for code generation and code completion.                          |
    | google/codegemma-1.1-7b                     | 8,192 tokens   | Advanced programming model for code generation, completion, reasoning, and instruction following.                           |
    | google/recurrentgemma-2b                    | 8,192 tokens   | Novel recurrent architecture based language model for faster inference when generating long sequences.                      |
    | google/gemma-2-9b-it                        | 8,192 tokens   | Cutting-edge text generation model text understanding, transformation, and code generation.                                 |
    | google/gemma-2-27b-it                       | 8,192 tokens   | Cutting-edge text generation model text understanding, transformation, and code generation.                                 |
    | google/gemma-2-2b-it                        | 8,192 tokens   | Cutting-edge text generation model text understanding, transformation, and code generation.                                 |
    | google/deplot                               | 512 tokens     | One-shot visual language understanding model that translates images of plots into tables.                                   |
    | google/paligemma                            | 8,192 tokens   | Vision language model adept at comprehending text and visual inputs to produce informative responses.                       |
    | mistralai/mistral-7b-instruct-v0.2          | 32k tokens     | This LLM follows instructions, completes requests, and generates creative text.                                             |
    | mistralai/mixtral-8x7b-instruct-v0.1        | 8,192 tokens   | An MOE LLM that follows instructions, completes requests, and generates creative text.                                      |
    | mistralai/mistral-large                     | 4,096 tokens   | Creates diverse synthetic data that mimics the characteristics of real-world data.                                          |
    | mistralai/mixtral-8x22b-instruct-v0.1       | 8,192 tokens   | Creates diverse synthetic data that mimics the characteristics of real-world data.                                          |
    | mistralai/mistral-7b-instruct-v0.3          | 32k tokens     | This LLM follows instructions, completes requests, and generates creative text.                                             |
    | nv-mistralai/mistral-nemo-12b-instruct      | 128k tokens    | Most advanced language model for reasoning, code, multilingual tasks; runs on a single GPU.                                 |
    | mistralai/mamba-codestral-7b-v0.1           | 256k tokens    | Model for writing and interacting with code across a wide range of programming languages and tasks.                         |
    | microsoft/phi-3-mini-128k-instruct          | 128K tokens    | Lightweight, state-of-the-art open LLM with strong math and logical reasoning skills.                                       |
    | microsoft/phi-3-mini-4k-instruct            | 4,096 tokens   | Lightweight, state-of-the-art open LLM with strong math and logical reasoning skills.                                       |
    | microsoft/phi-3-small-8k-instruct           | 8,192 tokens   | Lightweight, state-of-the-art open LLM with strong math and logical reasoning skills.                                       |
    | microsoft/phi-3-small-128k-instruct         | 128K tokens    | Lightweight, state-of-the-art open LLM with strong math and logical reasoning skills.                                       |
    | microsoft/phi-3-medium-4k-instruct          | 4,096 tokens   | Lightweight, state-of-the-art open LLM with strong math and logical reasoning skills.                                       |
    | microsoft/phi-3-medium-128k-instruct        | 128K tokens    | Lightweight, state-of-the-art open LLM with strong math and logical reasoning skills.                                       |
    | microsoft/phi-3.5-mini-instruct             | 128K tokens    | Lightweight multilingual LLM powering AI applications in latency bound, memory/compute constrained environments             |
    | microsoft/phi-3.5-moe-instruct              | 128K tokens    | Advanced LLM based on Mixture of Experts architecture to deliver compute efficient content generation                       |
    | microsoft/kosmos-2                          | 1,024 tokens   | Groundbreaking multimodal model designed to understand and reason about visual elements in images.                          |
    | microsoft/phi-3-vision-128k-instruct        | 128k tokens    | Cutting-edge open multimodal model exceling in high-quality reasoning from images.                                          |
    | microsoft/phi-3.5-vision-instruct           | 128k tokens    | Cutting-edge open multimodal model exceling in high-quality reasoning from images.                                          |
    | databricks/dbrx-instruct                    | 12k tokens     | A general-purpose LLM with state-of-the-art performance in language understanding, coding, and RAG.                         |
    | snowflake/arctic                            | 1,024 tokens   | Delivers high efficiency inference for enterprise applications focused on SQL generation and coding.                        |
    | aisingapore/sea-lion-7b-instruct            | 4,096 tokens   | LLM to represent and serve the linguistic and cultural diversity of Southeast Asia                                          |
    | ibm/granite-8b-code-instruct                | 4,096 tokens   | Software programming LLM for code generation, completion, explanation, and multi-turn conversion.                           |
    | ibm/granite-34b-code-instruct               | 8,192 tokens   | Software programming LLM for code generation, completion, explanation, and multi-turn conversion.                           |
    | ibm/granite-3.0-8b-instruct                 | 4,096 tokens   | Advanced Small Language Model supporting RAG, summarization, classification, code, and agentic AI                           |
    | ibm/granite-3.0-3b-a800m-instruct           | 4,096 tokens   | Highly efficient Mixture of Experts model for RAG, summarization, entity extraction, and classification                     |
    | mediatek/breeze-7b-instruct                 | 4,096 tokens   | Creates diverse synthetic data that mimics the characteristics of real-world data.                                          |
    | upstage/solar-10.7b-instruct                | 4,096 tokens   | Excels in NLP tasks, particularly in instruction-following, reasoning, and mathematics.                                     |
    | writer/palmyra-med-70b-32k                  | 32k tokens     | Leading LLM for accurate, contextually relevant responses in the medical domain.                                            |
    | writer/palmyra-med-70b                      | 32k tokens     | Leading LLM for accurate, contextually relevant responses in the medical domain.                                            |
    | writer/palmyra-fin-70b-32k                  | 32k tokens     | Specialized LLM for financial analysis, reporting, and data processing                                                      |
    | 01-ai/yi-large                              | 32k tokens     | Powerful model trained on English and Chinese for diverse tasks including chatbot and creative writing.                     |
    | deepseek-ai/deepseek-coder-6.7b-instruct    | 2k tokens      | Powerful coding model offering advanced capabilities in code generation, completion, and infilling                          |
    | rakuten/rakutenai-7b-instruct               | 1,024 tokens   | Advanced state-of-the-art LLM with language understanding, superior reasoning, and text generation.                         |
    | rakuten/rakutenai-7b-chat                   | 1,024 tokens   | Advanced state-of-the-art LLM with language understanding, superior reasoning, and text generation.                         |
    | baichuan-inc/baichuan2-13b-chat             | 4,096 tokens   | Support Chinese and English chat, coding, math, instruction following, solving quizzes                                      |
  </Accordion>

  <Accordion title="Local NVIDIA NIM Deployed using WSL2">
    NVIDIA NIM enables you to run powerful LLMs locally on your Windows machine using WSL2 (Windows Subsystem for Linux).
    This approach allows you to leverage your NVIDIA GPU for private, secure, and cost-effective AI inference without relying on cloud services.
    Perfect for development, testing, or production scenarios where data privacy or offline capabilities are required.

    Here is a step-by-step guide to setting up a local NVIDIA NIM model:

    1. Follow installation instructions from [NVIDIA Website](https://docs.nvidia.com/nim/wsl2/latest/getting-started.html)

    2. Install the local model. For Llama 3.1-8b follow [instructions](https://build.nvidia.com/meta/llama-3_1-8b-instruct/deploy)

    3. Configure your crewai local models:

    ```python Code
    from crewai.llm import LLM

    local_nvidia_nim_llm = LLM(
        model="openai/meta/llama-3.1-8b-instruct", # it's an openai-api compatible model
        base_url="http://localhost:8000/v1",
        api_key="<your_api_key|any text if you have not configured it>", # api_key is required, but you can use any text
    )

    # Then you can use it in your crew:

    @CrewBase
    class MyCrew():
        # ...

        @agent
        def researcher(self) -> Agent:
            return Agent(
                config=self.agents_config['researcher'], # type: ignore[index]
                llm=local_nvidia_nim_llm
            )

        # ...
    ```
  </Accordion>

  <Accordion title="Groq">
    Set the following environment variables in your `.env` file:

    ```toml Code
    GROQ_API_KEY=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="groq/llama-3.2-90b-text-preview",
        temperature=0.7
    )
    ```

    | Model            | Context Window | Best For                              |
    | ---------------- | -------------- | ------------------------------------- |
    | Llama 3.1 70B/8B | 131,072 tokens | High-performance, large context tasks |
    | Llama 3.2 Series | 8,192 tokens   | General-purpose tasks                 |
    | Mixtral 8x7B     | 32,768 tokens  | Balanced performance and context      |
  </Accordion>

  <Accordion title="IBM watsonx.ai">
    Set the following environment variables in your `.env` file:

    ```toml Code
    # Required
    WATSONX_URL=<your-url>
    WATSONX_APIKEY=<your-apikey>
    WATSONX_PROJECT_ID=<your-project-id>

    # Optional
    WATSONX_TOKEN=<your-token>
    WATSONX_DEPLOYMENT_SPACE_ID=<your-space-id>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="watsonx/meta-llama/llama-3-1-70b-instruct",
        base_url="https://api.watsonx.ai/v1"
    )
    ```
  </Accordion>

  <Accordion title="Ollama (Local LLMs)">
    1. Install Ollama: [ollama.ai](https://ollama.ai/)
    2. Run a model: `ollama run llama3`
    3. Configure:

    ```python Code
    llm = LLM(
        model="ollama/llama3:70b",
        base_url="http://localhost:11434"
    )
    ```
  </Accordion>

  <Accordion title="Fireworks AI">
    Set the following environment variables in your `.env` file:

    ```toml Code
    FIREWORKS_API_KEY=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="fireworks_ai/accounts/fireworks/models/llama-v3-70b-instruct",
        temperature=0.7
    )
    ```
  </Accordion>

  <Accordion title="Perplexity AI">
    Set the following environment variables in your `.env` file:

    ```toml Code
    PERPLEXITY_API_KEY=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="llama-3.1-sonar-large-128k-online",
        base_url="https://api.perplexity.ai/"
    )
    ```
  </Accordion>

  <Accordion title="Hugging Face">
    Set the following environment variables in your `.env` file:

    ```toml Code
    HF_TOKEN=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="huggingface/meta-llama/Meta-Llama-3.1-8B-Instruct"
    )
    ```
  </Accordion>

  <Accordion title="SambaNova">
    Set the following environment variables in your `.env` file:

    ```toml Code
    SAMBANOVA_API_KEY=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="sambanova/Meta-Llama-3.1-8B-Instruct",
        temperature=0.7
    )
    ```

    | Model            | Context Window       | Best For                              |
    | ---------------- | -------------------- | ------------------------------------- |
    | Llama 3.1 70B/8B | Up to 131,072 tokens | High-performance, large context tasks |
    | Llama 3.1 405B   | 8,192 tokens         | High-performance and output quality   |
    | Llama 3.2 Series | 8,192 tokens         | General-purpose, multimodal tasks     |
    | Llama 3.3 70B    | Up to 131,072 tokens | High-performance and output quality   |
    | Qwen2 familly    | 8,192 tokens         | High-performance and output quality   |
  </Accordion>

  <Accordion title="Cerebras">
    Set the following environment variables in your `.env` file:

    ```toml Code
    # Required
    CEREBRAS_API_KEY=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="cerebras/llama3.1-70b",
        temperature=0.7,
        max_tokens=8192
    )
    ```

    <Info>
      Cerebras features:

      * Fast inference speeds
      * Competitive pricing
      * Good balance of speed and quality
      * Support for long context windows
    </Info>
  </Accordion>

  <Accordion title="Open Router">
    Set the following environment variables in your `.env` file:

    ```toml Code
    OPENROUTER_API_KEY=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="openrouter/deepseek/deepseek-r1",
        base_url="https://openrouter.ai/api/v1",
        api_key=OPENROUTER_API_KEY
    )
    ```

    <Info>
      Open Router models:

      * openrouter/deepseek/deepseek-r1
      * openrouter/deepseek/deepseek-chat
    </Info>
  </Accordion>

  <Accordion title="Nebius AI Studio">
    Set the following environment variables in your `.env` file:

    ```toml Code
    NEBIUS_API_KEY=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="nebius/Qwen/Qwen3-30B-A3B"
    )
    ```

    <Info>
      Nebius AI Studio features:

      * Large collection of open source models
      * Higher rate limits
      * Competitive pricing
      * Good balance of speed and quality
    </Info>
  </Accordion>
</AccordionGroup>

## Streaming Responses

CrewAI supports streaming responses from LLMs, allowing your application to receive and process outputs in real-time as they're generated.

<Tabs>
  <Tab title="Basic Setup">
    Enable streaming by setting the `stream` parameter to `True` when initializing your LLM:

    ```python
    from crewai import LLM

    # Create an LLM with streaming enabled
    llm = LLM(
        model="openai/gpt-4o",
        stream=True  # Enable streaming
    )
    ```

    When streaming is enabled, responses are delivered in chunks as they're generated, creating a more responsive user experience.
  </Tab>

  <Tab title="Event Handling">
    CrewAI emits events for each chunk received during streaming:

    ```python
    from crewai.utilities.events import (
      LLMStreamChunkEvent
    )
    from crewai.utilities.events.base_event_listener import BaseEventListener

    class MyCustomListener(BaseEventListener):
        def setup_listeners(self, crewai_event_bus):
            @crewai_event_bus.on(LLMStreamChunkEvent)
            def on_llm_stream_chunk(self, event: LLMStreamChunkEvent):
              # Process each chunk as it arrives
              print(f"Received chunk: {event.chunk}")

    my_listener = MyCustomListener()
    ```

    <Tip>
      [Click here](https://docs.crewai.com/concepts/event-listener#event-listeners) for more details
    </Tip>
  </Tab>

  <Tab title="Agent & Task Tracking">
    All LLM events in CrewAI include agent and task information, allowing you to track and filter LLM interactions by specific agents or tasks:

    ```python
    from crewai import LLM, Agent, Task, Crew
    from crewai.utilities.events import LLMStreamChunkEvent
    from crewai.utilities.events.base_event_listener import BaseEventListener

    class MyCustomListener(BaseEventListener):
        def setup_listeners(self, crewai_event_bus):
            @crewai_event_bus.on(LLMStreamChunkEvent)
            def on_llm_stream_chunk(source, event):
                if researcher.id == event.agent_id:
                    print("\n==============\n Got event:", event, "\n==============\n")


    my_listener = MyCustomListener()

    llm = LLM(model="gpt-4o-mini", temperature=0, stream=True)

    researcher = Agent(
        role="About User",
        goal="You know everything about the user.",
        backstory="""You are a master at understanding people and their preferences.""",
        llm=llm,
    )

    search = Task(
        description="Answer the following questions about the user: {question}",
        expected_output="An answer to the question.",
        agent=researcher,
    )

    crew = Crew(agents=[researcher], tasks=[search])

    result = crew.kickoff(
        inputs={"question": "..."}
    )
    ```

    <Info>
      This feature is particularly useful for:

      * Debugging specific agent behaviors
      * Logging LLM usage by task type
      * Auditing which agents are making what types of LLM calls
      * Performance monitoring of specific tasks
    </Info>
  </Tab>
</Tabs>

## Structured LLM Calls

CrewAI supports structured responses from LLM calls by allowing you to define a `response_format` using a Pydantic model. This enables the framework to automatically parse and validate the output, making it easier to integrate the response into your application without manual post-processing.

For example, you can define a Pydantic model to represent the expected response structure and pass it as the `response_format` when instantiating the LLM. The model will then be used to convert the LLM output into a structured Python object.

```python Code
from crewai import LLM

class Dog(BaseModel):
    name: str
    age: int
    breed: str


llm = LLM(model="gpt-4o", response_format=Dog)

response = llm.call(
    "Analyze the following messages and return the name, age, and breed. "
    "Meet Kona! She is 3 years old and is a black german shepherd."
)
print(response)

# Output:
# Dog(name='Kona', age=3, breed='black german shepherd')
```

## Advanced Features and Optimization

Learn how to get the most out of your LLM configuration:

<AccordionGroup>
  <Accordion title="Context Window Management">
    CrewAI includes smart context management features:

    ```python
    from crewai import LLM

    # CrewAI automatically handles:
    # 1. Token counting and tracking
    # 2. Content summarization when needed
    # 3. Task splitting for large contexts

    llm = LLM(
        model="gpt-4",
        max_tokens=4000,  # Limit response length
    )
    ```

    <Info>
      Best practices for context management:

      1. Choose models with appropriate context windows
      2. Pre-process long inputs when possible
      3. Use chunking for large documents
      4. Monitor token usage to optimize costs
    </Info>
  </Accordion>

  <Accordion title="Performance Optimization">
    <Steps>
      <Step title="Token Usage Optimization">
        Choose the right context window for your task:

        * Small tasks (up to 4K tokens): Standard models
        * Medium tasks (between 4K-32K): Enhanced models
        * Large tasks (over 32K): Large context models

        ```python
        # Configure model with appropriate settings
        llm = LLM(
            model="openai/gpt-4-turbo-preview",
            temperature=0.7,    # Adjust based on task
            max_tokens=4096,    # Set based on output needs
            timeout=300        # Longer timeout for complex tasks
        )
        ```

        <Tip>
          * Lower temperature (0.1 to 0.3) for factual responses
          * Higher temperature (0.7 to 0.9) for creative tasks
        </Tip>
      </Step>

      <Step title="Best Practices">
        1. Monitor token usage
        2. Implement rate limiting
        3. Use caching when possible
        4. Set appropriate max\_tokens limits
      </Step>
    </Steps>

    <Info>
      Remember to regularly monitor your token usage and adjust your configuration as needed to optimize costs and performance.
    </Info>
  </Accordion>

  <Accordion title="Drop Additional Parameters">
    CrewAI internally uses Litellm for LLM calls, which allows you to drop additional parameters that are not needed for your specific use case. This can help simplify your code and reduce the complexity of your LLM configuration.
    For example, if you don't need to send the <code>stop</code> parameter, you can simply omit it from your LLM call:

    ```python
    from crewai import LLM
    import os

    os.environ["OPENAI_API_KEY"] = "<api-key>"

    o3_llm = LLM(
        model="o3",
        drop_params=True,
        additional_drop_params=["stop"]
    )
    ```
  </Accordion>
</AccordionGroup>

## Common Issues and Solutions

<Tabs>
  <Tab title="Authentication">
    <Warning>
      Most authentication issues can be resolved by checking API key format and environment variable names.
    </Warning>

    ```bash
    # OpenAI
    OPENAI_API_KEY=sk-...

    # Anthropic
    ANTHROPIC_API_KEY=sk-ant-...
    ```
  </Tab>

  <Tab title="Model Names">
    <Check>
      Always include the provider prefix in model names
    </Check>

    ```python
    # Correct
    llm = LLM(model="openai/gpt-4")

    # Incorrect
    llm = LLM(model="gpt-4")
    ```
  </Tab>

  <Tab title="Context Length">
    <Tip>
      Use larger context models for extensive tasks
    </Tip>

    ```python
    # Large context model
    llm = LLM(model="openai/gpt-4o")  # 128K tokens
    ```
  </Tab>
</Tabs>


# Memory
Source: https://docs.crewai.com/en/concepts/memory

Leveraging memory systems in the CrewAI framework to enhance agent capabilities.

## Overview

The CrewAI framework provides a sophisticated memory system designed to significantly enhance AI agent capabilities. CrewAI offers **three distinct memory approaches** that serve different use cases:

1. **Basic Memory System** - Built-in short-term, long-term, and entity memory
2. **User Memory** - User-specific memory with Mem0 integration (legacy approach)
3. **External Memory** - Standalone external memory providers (new approach)

## Memory System Components

| Component             | Description                                                                                                                                                                                                      |
| :-------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Short-Term Memory** | Temporarily stores recent interactions and outcomes using `RAG`, enabling agents to recall and utilize information relevant to their current context during the current executions.                              |
| **Long-Term Memory**  | Preserves valuable insights and learnings from past executions, allowing agents to build and refine their knowledge over time.                                                                                   |
| **Entity Memory**     | Captures and organizes information about entities (people, places, concepts) encountered during tasks, facilitating deeper understanding and relationship mapping. Uses `RAG` for storing entity information.    |
| **Contextual Memory** | Maintains the context of interactions by combining `ShortTermMemory`, `LongTermMemory`, and `EntityMemory`, aiding in the coherence and relevance of agent responses over a sequence of tasks or a conversation. |

## 1. Basic Memory System (Recommended)

The simplest and most commonly used approach. Enable memory for your crew with a single parameter:

### Quick Start

```python
from crewai import Crew, Agent, Task, Process

# Enable basic memory system
crew = Crew(
    agents=[...],
    tasks=[...],
    process=Process.sequential,
    memory=True,  # Enables short-term, long-term, and entity memory
    verbose=True
)
```

### How It Works

* **Short-Term Memory**: Uses ChromaDB with RAG for current context
* **Long-Term Memory**: Uses SQLite3 to store task results across sessions
* **Entity Memory**: Uses RAG to track entities (people, places, concepts)
* **Storage Location**: Platform-specific location via `appdirs` package
* **Custom Storage Directory**: Set `CREWAI_STORAGE_DIR` environment variable

## Storage Location Transparency

<Info>
  **Understanding Storage Locations**: CrewAI uses platform-specific directories to store memory and knowledge files following OS conventions. Understanding these locations helps with production deployments, backups, and debugging.
</Info>

### Where CrewAI Stores Files

By default, CrewAI uses the `appdirs` library to determine storage locations following platform conventions. Here's exactly where your files are stored:

#### Default Storage Locations by Platform

**macOS:**

```
~/Library/Application Support/CrewAI/{project_name}/
├── knowledge/           # Knowledge base ChromaDB files
├── short_term_memory/   # Short-term memory ChromaDB files
├── long_term_memory/    # Long-term memory ChromaDB files
├── entities/            # Entity memory ChromaDB files
└── long_term_memory_storage.db  # SQLite database
```

**Linux:**

```
~/.local/share/CrewAI/{project_name}/
├── knowledge/
├── short_term_memory/
├── long_term_memory/
├── entities/
└── long_term_memory_storage.db
```

**Windows:**

```
C:\Users\{username}\AppData\Local\CrewAI\{project_name}\
├── knowledge\
├── short_term_memory\
├── long_term_memory\
├── entities\
└── long_term_memory_storage.db
```

### Finding Your Storage Location

To see exactly where CrewAI is storing files on your system:

```python
from crewai.utilities.paths import db_storage_path
import os

# Get the base storage path
storage_path = db_storage_path()
print(f"CrewAI storage location: {storage_path}")

# List all CrewAI storage directories
if os.path.exists(storage_path):
    print("\nStored files and directories:")
    for item in os.listdir(storage_path):
        item_path = os.path.join(storage_path, item)
        if os.path.isdir(item_path):
            print(f"📁 {item}/")
            # Show ChromaDB collections
            if os.path.exists(item_path):
                for subitem in os.listdir(item_path):
                    print(f"   └── {subitem}")
        else:
            print(f"📄 {item}")
else:
    print("No CrewAI storage directory found yet.")
```

### Controlling Storage Locations

#### Option 1: Environment Variable (Recommended)

```python
import os
from crewai import Crew

# Set custom storage location
os.environ["CREWAI_STORAGE_DIR"] = "./my_project_storage"

# All memory and knowledge will now be stored in ./my_project_storage/
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True
)
```

#### Option 2: Custom Storage Paths

```python
import os
from crewai import Crew
from crewai.memory import LongTermMemory
from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage

# Configure custom storage location
custom_storage_path = "./storage"
os.makedirs(custom_storage_path, exist_ok=True)

crew = Crew(
    memory=True,
    long_term_memory=LongTermMemory(
        storage=LTMSQLiteStorage(
            db_path=f"{custom_storage_path}/memory.db"
        )
    )
)
```

#### Option 3: Project-Specific Storage

```python
import os
from pathlib import Path

# Store in project directory
project_root = Path(__file__).parent
storage_dir = project_root / "crewai_storage"

os.environ["CREWAI_STORAGE_DIR"] = str(storage_dir)

# Now all storage will be in your project directory
```

### Embedding Provider Defaults

<Info>
  **Default Embedding Provider**: CrewAI defaults to OpenAI embeddings for consistency and reliability. You can easily customize this to match your LLM provider or use local embeddings.
</Info>

#### Understanding Default Behavior

```python
# When using Claude as your LLM...
from crewai import Agent, LLM

agent = Agent(
    role="Analyst",
    goal="Analyze data",
    backstory="Expert analyst",
    llm=LLM(provider="anthropic", model="claude-3-sonnet")  # Using Claude
)

# CrewAI will use OpenAI embeddings by default for consistency
# You can easily customize this to match your preferred provider
```

#### Customizing Embedding Providers

```python
from crewai import Crew

# Option 1: Match your LLM provider
crew = Crew(
    agents=[agent],
    tasks=[task],
    memory=True,
    embedder={
        "provider": "anthropic",  # Match your LLM provider
        "config": {
            "api_key": "your-anthropic-key",
            "model": "text-embedding-3-small"
        }
    }
)

# Option 2: Use local embeddings (no external API calls)
crew = Crew(
    agents=[agent],
    tasks=[task],
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    }
)
```

### Debugging Storage Issues

#### Check Storage Permissions

```python
import os
from crewai.utilities.paths import db_storage_path

storage_path = db_storage_path()
print(f"Storage path: {storage_path}")
print(f"Path exists: {os.path.exists(storage_path)}")
print(f"Is writable: {os.access(storage_path, os.W_OK) if os.path.exists(storage_path) else 'Path does not exist'}")

# Create with proper permissions
if not os.path.exists(storage_path):
    os.makedirs(storage_path, mode=0o755, exist_ok=True)
    print(f"Created storage directory: {storage_path}")
```

#### Inspect ChromaDB Collections

```python
import chromadb
from crewai.utilities.paths import db_storage_path

# Connect to CrewAI's ChromaDB
storage_path = db_storage_path()
chroma_path = os.path.join(storage_path, "knowledge")

if os.path.exists(chroma_path):
    client = chromadb.PersistentClient(path=chroma_path)
    collections = client.list_collections()

    print("ChromaDB Collections:")
    for collection in collections:
        print(f"  - {collection.name}: {collection.count()} documents")
else:
    print("No ChromaDB storage found")
```

#### Reset Storage (Debugging)

```python
from crewai import Crew

# Reset all memory storage
crew = Crew(agents=[...], tasks=[...], memory=True)

# Reset specific memory types
crew.reset_memories(command_type='short')     # Short-term memory
crew.reset_memories(command_type='long')      # Long-term memory
crew.reset_memories(command_type='entity')    # Entity memory
crew.reset_memories(command_type='knowledge') # Knowledge storage
```

### Production Best Practices

1. **Set `CREWAI_STORAGE_DIR`** to a known location in production for better control
2. **Choose explicit embedding providers** to match your LLM setup
3. **Monitor storage directory size** for large-scale deployments
4. **Include storage directories** in your backup strategy
5. **Set appropriate file permissions** (0o755 for directories, 0o644 for files)
6. **Use project-relative paths** for containerized deployments

### Common Storage Issues

**"ChromaDB permission denied" errors:**

```bash
# Fix permissions
chmod -R 755 ~/.local/share/CrewAI/
```

**"Database is locked" errors:**

```python
# Ensure only one CrewAI instance accesses storage
import fcntl
import os

storage_path = db_storage_path()
lock_file = os.path.join(storage_path, ".crewai.lock")

with open(lock_file, 'w') as f:
    fcntl.flock(f.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
    # Your CrewAI code here
```

**Storage not persisting between runs:**

```python
# Verify storage location is consistent
import os
print("CREWAI_STORAGE_DIR:", os.getenv("CREWAI_STORAGE_DIR"))
print("Current working directory:", os.getcwd())
print("Computed storage path:", db_storage_path())
```

## Custom Embedder Configuration

CrewAI supports multiple embedding providers to give you flexibility in choosing the best option for your use case. Here's a comprehensive guide to configuring different embedding providers for your memory system.

### Why Choose Different Embedding Providers?

* **Cost Optimization**: Local embeddings (Ollama) are free after initial setup
* **Privacy**: Keep your data local with Ollama or use your preferred cloud provider
* **Performance**: Some models work better for specific domains or languages
* **Consistency**: Match your embedding provider with your LLM provider
* **Compliance**: Meet specific regulatory or organizational requirements

### OpenAI Embeddings (Default)

OpenAI provides reliable, high-quality embeddings that work well for most use cases.

```python
from crewai import Crew

# Basic OpenAI configuration (uses environment OPENAI_API_KEY)
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "model": "text-embedding-3-small"  # or "text-embedding-3-large"
        }
    }
)

# Advanced OpenAI configuration
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "api_key": "your-openai-api-key",  # Optional: override env var
            "model": "text-embedding-3-large",
            "dimensions": 1536,  # Optional: reduce dimensions for smaller storage
            "organization_id": "your-org-id"  # Optional: for organization accounts
        }
    }
)
```

### Azure OpenAI Embeddings

For enterprise users with Azure OpenAI deployments.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",  # Use openai provider for Azure
        "config": {
            "api_key": "your-azure-api-key",
            "api_base": "https://your-resource.openai.azure.com/",
            "api_type": "azure",
            "api_version": "2023-05-15",
            "model": "text-embedding-3-small",
            "deployment_id": "your-deployment-name"  # Azure deployment name
        }
    }
)
```

### Google AI Embeddings

Use Google's text embedding models for integration with Google Cloud services.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "google",
        "config": {
            "api_key": "your-google-api-key",
            "model": "text-embedding-004"  # or "text-embedding-preview-0409"
        }
    }
)
```

### Vertex AI Embeddings

For Google Cloud users with Vertex AI access.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "vertexai",
        "config": {
            "project_id": "your-gcp-project-id",
            "region": "us-central1",  # or your preferred region
            "api_key": "your-service-account-key",
            "model_name": "textembedding-gecko"
        }
    }
)
```

### Ollama Embeddings (Local)

Run embeddings locally for privacy and cost savings.

```python
# First, install and run Ollama locally, then pull an embedding model:
# ollama pull mxbai-embed-large

crew = Crew(
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {
            "model": "mxbai-embed-large",  # or "nomic-embed-text"
            "url": "http://localhost:11434/api/embeddings"  # Default Ollama URL
        }
    }
)

# For custom Ollama installations
crew = Crew(
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {
            "model": "mxbai-embed-large",
            "url": "http://your-ollama-server:11434/api/embeddings"
        }
    }
)
```

### Cohere Embeddings

Use Cohere's embedding models for multilingual support.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "cohere",
        "config": {
            "api_key": "your-cohere-api-key",
            "model": "embed-english-v3.0"  # or "embed-multilingual-v3.0"
        }
    }
)
```

### VoyageAI Embeddings

High-performance embeddings optimized for retrieval tasks.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "voyageai",
        "config": {
            "api_key": "your-voyage-api-key",
            "model": "voyage-large-2",  # or "voyage-code-2" for code
            "input_type": "document"  # or "query"
        }
    }
)
```

### AWS Bedrock Embeddings

For AWS users with Bedrock access.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "bedrock",
        "config": {
            "aws_access_key_id": "your-access-key",
            "aws_secret_access_key": "your-secret-key",
            "region_name": "us-east-1",
            "model": "amazon.titan-embed-text-v1"
        }
    }
)
```

### Hugging Face Embeddings

Use open-source models from Hugging Face.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "huggingface",
        "config": {
            "api_key": "your-hf-token",  # Optional for public models
            "model": "sentence-transformers/all-MiniLM-L6-v2",
            "api_url": "https://api-inference.huggingface.co"  # or your custom endpoint
        }
    }
)
```

### IBM Watson Embeddings

For IBM Cloud users.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "watson",
        "config": {
            "api_key": "your-watson-api-key",
            "url": "your-watson-instance-url",
            "model": "ibm/slate-125m-english-rtrvr"
        }
    }
)
```

### Choosing the Right Embedding Provider

| Provider         | Best For                 | Pros                      | Cons                    |
| :--------------- | :----------------------- | :------------------------ | :---------------------- |
| **OpenAI**       | General use, reliability | High quality, well-tested | Cost, requires API key  |
| **Ollama**       | Privacy, cost savings    | Free, local, private      | Requires local setup    |
| **Google AI**    | Google ecosystem         | Good performance          | Requires Google account |
| **Azure OpenAI** | Enterprise, compliance   | Enterprise features       | Complex setup           |
| **Cohere**       | Multilingual content     | Great language support    | Specialized use case    |
| **VoyageAI**     | Retrieval tasks          | Optimized for search      | Newer provider          |

### Environment Variable Configuration

For security, store API keys in environment variables:

```python
import os

# Set environment variables
os.environ["OPENAI_API_KEY"] = "your-openai-key"
os.environ["GOOGLE_API_KEY"] = "your-google-key"
os.environ["COHERE_API_KEY"] = "your-cohere-key"

# Use without exposing keys in code
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "model": "text-embedding-3-small"
            # API key automatically loaded from environment
        }
    }
)
```

### Testing Different Embedding Providers

Compare embedding providers for your specific use case:

```python
from crewai import Crew
from crewai.utilities.paths import db_storage_path

# Test different providers with the same data
providers_to_test = [
    {
        "name": "OpenAI",
        "config": {
            "provider": "openai",
            "config": {"model": "text-embedding-3-small"}
        }
    },
    {
        "name": "Ollama",
        "config": {
            "provider": "ollama",
            "config": {"model": "mxbai-embed-large"}
        }
    }
]

for provider in providers_to_test:
    print(f"\nTesting {provider['name']} embeddings...")

    # Create crew with specific embedder
    crew = Crew(
        agents=[...],
        tasks=[...],
        memory=True,
        embedder=provider['config']
    )

    # Run your test and measure performance
    result = crew.kickoff()
    print(f"{provider['name']} completed successfully")
```

### Troubleshooting Embedding Issues

**Model not found errors:**

```python
# Verify model availability
from crewai.utilities.embedding_configurator import EmbeddingConfigurator

configurator = EmbeddingConfigurator()
try:
    embedder = configurator.configure_embedder({
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    })
    print("Embedder configured successfully")
except Exception as e:
    print(f"Configuration error: {e}")
```

**API key issues:**

```python
import os

# Check if API keys are set
required_keys = ["OPENAI_API_KEY", "GOOGLE_API_KEY", "COHERE_API_KEY"]
for key in required_keys:
    if os.getenv(key):
        print(f"✅ {key} is set")
    else:
        print(f"❌ {key} is not set")
```

**Performance comparison:**

```python
import time

def test_embedding_performance(embedder_config, test_text="This is a test document"):
    start_time = time.time()

    crew = Crew(
        agents=[...],
        tasks=[...],
        memory=True,
        embedder=embedder_config
    )

    # Simulate memory operation
    crew.kickoff()

    end_time = time.time()
    return end_time - start_time

# Compare performance
openai_time = test_embedding_performance({
    "provider": "openai",
    "config": {"model": "text-embedding-3-small"}
})

ollama_time = test_embedding_performance({
    "provider": "ollama",
    "config": {"model": "mxbai-embed-large"}
})

print(f"OpenAI: {openai_time:.2f}s")
print(f"Ollama: {ollama_time:.2f}s")
```

## 2. User Memory with Mem0 (Legacy)

<Warning>
  **Legacy Approach**: While fully functional, this approach is considered legacy. For new projects requiring user-specific memory, consider using External Memory instead.
</Warning>

User Memory integrates with [Mem0](https://mem0.ai/) to provide user-specific memory that persists across sessions and integrates with the crew's contextual memory system.

### Prerequisites

```bash
pip install mem0ai
```

### Mem0 Cloud Configuration

```python
import os
from crewai import Crew, Process

# Set your Mem0 API key
os.environ["MEM0_API_KEY"] = "m0-your-api-key"

crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,  # Required for contextual memory integration
    memory_config={
        "provider": "mem0",
        "config": {"user_id": "john"},
        "user_memory": {}  # Required - triggers user memory initialization
    },
    process=Process.sequential,
    verbose=True
)
```

### Advanced Mem0 Configuration

```python
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,
    memory_config={
        "provider": "mem0",
        "config": {
            "user_id": "john",
            "org_id": "my_org_id",        # Optional
            "project_id": "my_project_id", # Optional
            "api_key": "custom-api-key"    # Optional - overrides env var
        },
        "user_memory": {}
    }
)
```

### Local Mem0 Configuration

```python
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,
    memory_config={
        "provider": "mem0",
        "config": {
            "user_id": "john",
            "local_mem0_config": {
                "vector_store": {
                    "provider": "qdrant",
                    "config": {"host": "localhost", "port": 6333}
                },
                "llm": {
                    "provider": "openai",
                    "config": {"api_key": "your-api-key", "model": "gpt-4"}
                },
                "embedder": {
                    "provider": "openai",
                    "config": {"api_key": "your-api-key", "model": "text-embedding-3-small"}
                }
            }
        },
        "user_memory": {}
    }
)
```

## 3. External Memory (New Approach)

External Memory provides a standalone memory system that operates independently from the crew's built-in memory. This is ideal for specialized memory providers or cross-application memory sharing.

### Basic External Memory with Mem0

```python
import os
from crewai import Agent, Crew, Process, Task
from crewai.memory.external.external_memory import ExternalMemory

os.environ["MEM0_API_KEY"] = "your-api-key"

# Create external memory instance
external_memory = ExternalMemory(
    embedder_config={
        "provider": "mem0",
        "config": {"user_id": "U-123"}
    }
)

crew = Crew(
    agents=[...],
    tasks=[...],
    external_memory=external_memory,  # Separate from basic memory
    process=Process.sequential,
    verbose=True
)
```

### Custom Storage Implementation

```python
from crewai.memory.external.external_memory import ExternalMemory
from crewai.memory.storage.interface import Storage

class CustomStorage(Storage):
    def __init__(self):
        self.memories = []

    def save(self, value, metadata=None, agent=None):
        self.memories.append({
            "value": value,
            "metadata": metadata,
            "agent": agent
        })

    def search(self, query, limit=10, score_threshold=0.5):
        # Implement your search logic here
        return [m for m in self.memories if query.lower() in str(m["value"]).lower()]

    def reset(self):
        self.memories = []

# Use custom storage
external_memory = ExternalMemory(storage=CustomStorage())

crew = Crew(
    agents=[...],
    tasks=[...],
    external_memory=external_memory
)
```

## Memory System Comparison

| Feature              | Basic Memory        | User Memory (Legacy)       | External Memory   |
| -------------------- | ------------------- | -------------------------- | ----------------- |
| **Setup Complexity** | Simple              | Medium                     | Medium            |
| **Integration**      | Built-in contextual | Contextual + User-specific | Standalone        |
| **Storage**          | Local files         | Mem0 Cloud/Local           | Custom/Mem0       |
| **Cross-session**    | ✅                   | ✅                          | ✅                 |
| **User-specific**    | ❌                   | ✅                          | ✅                 |
| **Custom providers** | Limited             | Mem0 only                  | Any provider      |
| **Recommended for**  | Most use cases      | Legacy projects            | Specialized needs |

## Supported Embedding Providers

### OpenAI (Default)

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {"model": "text-embedding-3-small"}
    }
)
```

### Ollama

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    }
)
```

### Google AI

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "google",
        "config": {
            "api_key": "your-api-key",
            "model": "text-embedding-004"
        }
    }
)
```

### Azure OpenAI

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "api_key": "your-api-key",
            "api_base": "https://your-resource.openai.azure.com/",
            "api_version": "2023-05-15",
            "model_name": "text-embedding-3-small"
        }
    }
)
```

### Vertex AI

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "vertexai",
        "config": {
            "project_id": "your-project-id",
            "region": "your-region",
            "api_key": "your-api-key",
            "model_name": "textembedding-gecko"
        }
    }
)
```

## Security Best Practices

### Environment Variables

```python
import os
from crewai import Crew

# Store sensitive data in environment variables
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "api_key": os.getenv("OPENAI_API_KEY"),
            "model": "text-embedding-3-small"
        }
    }
)
```

### Storage Security

```python
import os
from crewai import Crew
from crewai.memory import LongTermMemory
from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage

# Use secure storage paths
storage_path = os.getenv("CREWAI_STORAGE_DIR", "./storage")
os.makedirs(storage_path, mode=0o700, exist_ok=True)  # Restricted permissions

crew = Crew(
    memory=True,
    long_term_memory=LongTermMemory(
        storage=LTMSQLiteStorage(
            db_path=f"{storage_path}/memory.db"
        )
    )
)
```

## Troubleshooting

### Common Issues

**Memory not persisting between sessions?**

* Check `CREWAI_STORAGE_DIR` environment variable
* Ensure write permissions to storage directory
* Verify memory is enabled with `memory=True`

**Mem0 authentication errors?**

* Verify `MEM0_API_KEY` environment variable is set
* Check API key permissions on Mem0 dashboard
* Ensure `mem0ai` package is installed

**High memory usage with large datasets?**

* Consider using External Memory with custom storage
* Implement pagination in custom storage search methods
* Use smaller embedding models for reduced memory footprint

### Performance Tips

* Use `memory=True` for most use cases (simplest and fastest)
* Only use User Memory if you need user-specific persistence
* Consider External Memory for high-scale or specialized requirements
* Choose smaller embedding models for faster processing
* Set appropriate search limits to control memory retrieval size

## Benefits of Using CrewAI's Memory System

* 🦾 **Adaptive Learning:** Crews become more efficient over time, adapting to new information and refining their approach to tasks.
* 🫡 **Enhanced Personalization:** Memory enables agents to remember user preferences and historical interactions, leading to personalized experiences.
* 🧠 **Improved Problem Solving:** Access to a rich memory store aids agents in making more informed decisions, drawing on past learnings and contextual insights.

## Memory Events

CrewAI's event system provides powerful insights into memory operations. By leveraging memory events, you can monitor, debug, and optimize your memory system's performance and behavior.

### Available Memory Events

CrewAI emits the following memory-related events:

| Event                             | Description                                                 | Key Properties                                                  |
| :-------------------------------- | :---------------------------------------------------------- | :-------------------------------------------------------------- |
| **MemoryQueryStartedEvent**       | Emitted when a memory query begins                          | `query`, `limit`, `score_threshold`                             |
| **MemoryQueryCompletedEvent**     | Emitted when a memory query completes successfully          | `query`, `results`, `limit`, `score_threshold`, `query_time_ms` |
| **MemoryQueryFailedEvent**        | Emitted when a memory query fails                           | `query`, `limit`, `score_threshold`, `error`                    |
| **MemorySaveStartedEvent**        | Emitted when a memory save operation begins                 | `value`, `metadata`, `agent_role`                               |
| **MemorySaveCompletedEvent**      | Emitted when a memory save operation completes successfully | `value`, `metadata`, `agent_role`, `save_time_ms`               |
| **MemorySaveFailedEvent**         | Emitted when a memory save operation fails                  | `value`, `metadata`, `agent_role`, `error`                      |
| **MemoryRetrievalStartedEvent**   | Emitted when memory retrieval for a task prompt starts      | `task_id`                                                       |
| **MemoryRetrievalCompletedEvent** | Emitted when memory retrieval completes successfully        | `task_id`, `memory_content`, `retrieval_time_ms`                |

### Practical Applications

#### 1. Memory Performance Monitoring

Track memory operation timing to optimize your application:

```python
from crewai.utilities.events.base_event_listener import BaseEventListener
from crewai.utilities.events import (
    MemoryQueryCompletedEvent,
    MemorySaveCompletedEvent
)
import time

class MemoryPerformanceMonitor(BaseEventListener):
    def __init__(self):
        super().__init__()
        self.query_times = []
        self.save_times = []

    def setup_listeners(self, crewai_event_bus):
        @crewai_event_bus.on(MemoryQueryCompletedEvent)
        def on_memory_query_completed(source, event: MemoryQueryCompletedEvent):
            self.query_times.append(event.query_time_ms)
            print(f"Memory query completed in {event.query_time_ms:.2f}ms. Query: '{event.query}'")
            print(f"Average query time: {sum(self.query_times)/len(self.query_times):.2f}ms")

        @crewai_event_bus.on(MemorySaveCompletedEvent)
        def on_memory_save_completed(source, event: MemorySaveCompletedEvent):
            self.save_times.append(event.save_time_ms)
            print(f"Memory save completed in {event.save_time_ms:.2f}ms")
            print(f"Average save time: {sum(self.save_times)/len(self.save_times):.2f}ms")

# Create an instance of your listener
memory_monitor = MemoryPerformanceMonitor()
```

#### 2. Memory Content Logging

Log memory operations for debugging and insights:

```python
from crewai.utilities.events.base_event_listener import BaseEventListener
from crewai.utilities.events import (
    MemorySaveStartedEvent,
    MemoryQueryStartedEvent,
    MemoryRetrievalCompletedEvent
)
import logging

# Configure logging
logger = logging.getLogger('memory_events')

class MemoryLogger(BaseEventListener):
    def setup_listeners(self, crewai_event_bus):
        @crewai_event_bus.on(MemorySaveStartedEvent)
        def on_memory_save_started(source, event: MemorySaveStartedEvent):
            if event.agent_role:
                logger.info(f"Agent '{event.agent_role}' saving memory: {event.value[:50]}...")
            else:
                logger.info(f"Saving memory: {event.value[:50]}...")

        @crewai_event_bus.on(MemoryQueryStartedEvent)
        def on_memory_query_started(source, event: MemoryQueryStartedEvent):
            logger.info(f"Memory query started: '{event.query}' (limit: {event.limit})")

        @crewai_event_bus.on(MemoryRetrievalCompletedEvent)
        def on_memory_retrieval_completed(source, event: MemoryRetrievalCompletedEvent):
            if event.task_id:
                logger.info(f"Memory retrieved for task {event.task_id} in {event.retrieval_time_ms:.2f}ms")
            else:
                logger.info(f"Memory retrieved in {event.retrieval_time_ms:.2f}ms")
            logger.debug(f"Memory content: {event.memory_content}")

# Create an instance of your listener
memory_logger = MemoryLogger()
```

#### 3. Error Tracking and Notifications

Capture and respond to memory errors:

```python
from crewai.utilities.events.base_event_listener import BaseEventListener
from crewai.utilities.events import (
    MemorySaveFailedEvent,
    MemoryQueryFailedEvent
)
import logging
from typing import Optional

# Configure logging
logger = logging.getLogger('memory_errors')

class MemoryErrorTracker(BaseEventListener):
    def __init__(self, notify_email: Optional[str] = None):
        super().__init__()
        self.notify_email = notify_email
        self.error_count = 0

    def setup_listeners(self, crewai_event_bus):
        @crewai_event_bus.on(MemorySaveFailedEvent)
        def on_memory_save_failed(source, event: MemorySaveFailedEvent):
            self.error_count += 1
            agent_info = f"Agent '{event.agent_role}'" if event.agent_role else "Unknown agent"
            error_message = f"Memory save failed: {event.error}. {agent_info}"
            logger.error(error_message)

            if self.notify_email and self.error_count % 5 == 0:
                self._send_notification(error_message)

        @crewai_event_bus.on(MemoryQueryFailedEvent)
        def on_memory_query_failed(source, event: MemoryQueryFailedEvent):
            self.error_count += 1
            error_message = f"Memory query failed: {event.error}. Query: '{event.query}'"
            logger.error(error_message)

            if self.notify_email and self.error_count % 5 == 0:
                self._send_notification(error_message)

    def _send_notification(self, message):
        # Implement your notification system (email, Slack, etc.)
        print(f"[NOTIFICATION] Would send to {self.notify_email}: {message}")

# Create an instance of your listener
error_tracker = MemoryErrorTracker(notify_email="admin@example.com")
```

### Integrating with Analytics Platforms

Memory events can be forwarded to analytics and monitoring platforms to track performance metrics, detect anomalies, and visualize memory usage patterns:

```python
from crewai.utilities.events.base_event_listener import BaseEventListener
from crewai.utilities.events import (
    MemoryQueryCompletedEvent,
    MemorySaveCompletedEvent
)

class MemoryAnalyticsForwarder(BaseEventListener):
    def __init__(self, analytics_client):
        super().__init__()
        self.client = analytics_client

    def setup_listeners(self, crewai_event_bus):
        @crewai_event_bus.on(MemoryQueryCompletedEvent)
        def on_memory_query_completed(source, event: MemoryQueryCompletedEvent):
            # Forward query metrics to analytics platform
            self.client.track_metric({
                "event_type": "memory_query",
                "query": event.query,
                "duration_ms": event.query_time_ms,
                "result_count": len(event.results) if hasattr(event.results, "__len__") else 0,
                "timestamp": event.timestamp
            })

        @crewai_event_bus.on(MemorySaveCompletedEvent)
        def on_memory_save_completed(source, event: MemorySaveCompletedEvent):
            # Forward save metrics to analytics platform
            self.client.track_metric({
                "event_type": "memory_save",
                "agent_role": event.agent_role,
                "duration_ms": event.save_time_ms,
                "timestamp": event.timestamp
            })
```

### Best Practices for Memory Event Listeners

1. **Keep handlers lightweight**: Avoid complex processing in event handlers to prevent performance impacts
2. **Use appropriate logging levels**: Use INFO for normal operations, DEBUG for details, ERROR for issues
3. **Batch metrics when possible**: Accumulate metrics before sending to external systems
4. **Handle exceptions gracefully**: Ensure your event handlers don't crash due to unexpected data
5. **Consider memory consumption**: Be mindful of storing large amounts of event data

## Conclusion

Integrating CrewAI's memory system into your projects is straightforward. By leveraging the provided memory components and configurations,
you can quickly empower your agents with the ability to remember, reason, and learn from their interactions, unlocking new levels of intelligence and capability.


# Planning
Source: https://docs.crewai.com/en/concepts/planning

Learn how to add planning to your CrewAI Crew and improve their performance.

## Overview

The planning feature in CrewAI allows you to add planning capability to your crew. When enabled, before each Crew iteration,
all Crew information is sent to an AgentPlanner that will plan the tasks step by step, and this plan will be added to each task description.

### Using the Planning Feature

Getting started with the planning feature is very easy, the only step required is to add `planning=True` to your Crew:

<CodeGroup>
  ```python Code
  from crewai import Crew, Agent, Task, Process

  # Assemble your crew with planning capabilities
  my_crew = Crew(
      agents=self.agents,
      tasks=self.tasks,
      process=Process.sequential,
      planning=True,
  )
  ```
</CodeGroup>

From this point on, your crew will have planning enabled, and the tasks will be planned before each iteration.

<Warning>
  When planning is enabled, crewAI will use `gpt-4o-mini` as the default LLM for planning, which requires a valid OpenAI API key. Since your agents might be using different LLMs, this could cause confusion if you don't have an OpenAI API key configured or if you're experiencing unexpected behavior related to LLM API calls.
</Warning>

#### Planning LLM

Now you can define the LLM that will be used to plan the tasks.

When running the base case example, you will see something like the output below, which represents the output of the `AgentPlanner`
responsible for creating the step-by-step logic to add to the Agents' tasks.

<CodeGroup>
  ```python Code
  from crewai import Crew, Agent, Task, Process

  # Assemble your crew with planning capabilities and custom LLM
  my_crew = Crew(
      agents=self.agents,
      tasks=self.tasks,
      process=Process.sequential,
      planning=True,
      planning_llm="gpt-4o"
  )

  # Run the crew
  my_crew.kickoff()
  ```

  ````markdown Result
  [2024-07-15 16:49:11][INFO]: Planning the crew execution
  **Step-by-Step Plan for Task Execution**

  **Task Number 1: Conduct a thorough research about AI LLMs**

  **Agent:** AI LLMs Senior Data Researcher

  **Agent Goal:** Uncover cutting-edge developments in AI LLMs

  **Task Expected Output:** A list with 10 bullet points of the most relevant information about AI LLMs

  **Task Tools:** None specified

  **Agent Tools:** None specified

  **Step-by-Step Plan:**

  1. **Define Research Scope:**

     - Determine the specific areas of AI LLMs to focus on, such as advancements in architecture, use cases, ethical considerations, and performance metrics.

  2. **Identify Reliable Sources:**

     - List reputable sources for AI research, including academic journals, industry reports, conferences (e.g., NeurIPS, ACL), AI research labs (e.g., OpenAI, Google AI), and online databases (e.g., IEEE Xplore, arXiv).

  3. **Collect Data:**

     - Search for the latest papers, articles, and reports published in 2024 and early 2025.
     - Use keywords like "Large Language Models 2025", "AI LLM advancements", "AI ethics 2025", etc.

  4. **Analyze Findings:**

     - Read and summarize the key points from each source.
     - Highlight new techniques, models, and applications introduced in the past year.

  5. **Organize Information:**

     - Categorize the information into relevant topics (e.g., new architectures, ethical implications, real-world applications).
     - Ensure each bullet point is concise but informative.

  6. **Create the List:**

     - Compile the 10 most relevant pieces of information into a bullet point list.
     - Review the list to ensure clarity and relevance.

  **Expected Output:**

  A list with 10 bullet points of the most relevant information about AI LLMs.

  ---

  **Task Number 2: Review the context you got and expand each topic into a full section for a report**

  **Agent:** AI LLMs Reporting Analyst

  **Agent Goal:** Create detailed reports based on AI LLMs data analysis and research findings

  **Task Expected Output:** A fully fledged report with the main topics, each with a full section of information. Formatted as markdown without '```'

  **Task Tools:** None specified

  **Agent Tools:** None specified

  **Step-by-Step Plan:**

  1. **Review the Bullet Points:**
     - Carefully read through the list of 10 bullet points provided by the AI LLMs Senior Data Researcher.

  2. **Outline the Report:**
     - Create an outline with each bullet point as a main section heading.
     - Plan sub-sections under each main heading to cover different aspects of the topic.

  3. **Research Further Details:**
     - For each bullet point, conduct additional research if necessary to gather more detailed information.
     - Look for case studies, examples, and statistical data to support each section.

  4. **Write Detailed Sections:**
     - Expand each bullet point into a comprehensive section.
     - Ensure each section includes an introduction, detailed explanation, examples, and a conclusion.
     - Use markdown formatting for headings, subheadings, lists, and emphasis.

  5. **Review and Edit:**
     - Proofread the report for clarity, coherence, and correctness.
     - Make sure the report flows logically from one section to the next.
     - Format the report according to markdown standards.

  6. **Finalize the Report:**
     - Ensure the report is complete with all sections expanded and detailed.
     - Double-check formatting and make any necessary adjustments.

  **Expected Output:**
  A fully fledged report with the main topics, each with a full section of information. Formatted as markdown without '```'.
  ````
</CodeGroup>


# Processes
Source: https://docs.crewai.com/en/concepts/processes

Detailed guide on workflow management through processes in CrewAI, with updated implementation details.

## Overview

<Tip>
  Processes orchestrate the execution of tasks by agents, akin to project management in human teams.
  These processes ensure tasks are distributed and executed efficiently, in alignment with a predefined strategy.
</Tip>

## Process Implementations

* **Sequential**: Executes tasks sequentially, ensuring tasks are completed in an orderly progression.
* **Hierarchical**: Organizes tasks in a managerial hierarchy, where tasks are delegated and executed based on a structured chain of command. A manager language model (`manager_llm`) or a custom manager agent (`manager_agent`) must be specified in the crew to enable the hierarchical process, facilitating the creation and management of tasks by the manager.
* **Consensual Process (Planned)**: Aiming for collaborative decision-making among agents on task execution, this process type introduces a democratic approach to task management within CrewAI. It is planned for future development and is not currently implemented in the codebase.

## The Role of Processes in Teamwork

Processes enable individual agents to operate as a cohesive unit, streamlining their efforts to achieve common objectives with efficiency and coherence.

## Assigning Processes to a Crew

To assign a process to a crew, specify the process type upon crew creation to set the execution strategy. For a hierarchical process, ensure to define `manager_llm` or `manager_agent` for the manager agent.

```python
from crewai import Crew, Process

# Example: Creating a crew with a sequential process
crew = Crew(
    agents=my_agents,
    tasks=my_tasks,
    process=Process.sequential
)

# Example: Creating a crew with a hierarchical process
# Ensure to provide a manager_llm or manager_agent
crew = Crew(
    agents=my_agents,
    tasks=my_tasks,
    process=Process.hierarchical,
    manager_llm="gpt-4o"
    # or
    # manager_agent=my_manager_agent
)
```

**Note:** Ensure `my_agents` and `my_tasks` are defined prior to creating a `Crew` object, and for the hierarchical process, either `manager_llm` or `manager_agent` is also required.

## Sequential Process

This method mirrors dynamic team workflows, progressing through tasks in a thoughtful and systematic manner. Task execution follows the predefined order in the task list, with the output of one task serving as context for the next.

To customize task context, utilize the `context` parameter in the `Task` class to specify outputs that should be used as context for subsequent tasks.

## Hierarchical Process

Emulates a corporate hierarchy, CrewAI allows specifying a custom manager agent or automatically creates one, requiring the specification of a manager language model (`manager_llm`). This agent oversees task execution, including planning, delegation, and validation. Tasks are not pre-assigned; the manager allocates tasks to agents based on their capabilities, reviews outputs, and assesses task completion.

## Process Class: Detailed Overview

The `Process` class is implemented as an enumeration (`Enum`), ensuring type safety and restricting process values to the defined types (`sequential`, `hierarchical`). The consensual process is planned for future inclusion, emphasizing our commitment to continuous development and innovation.

## Conclusion

The structured collaboration facilitated by processes within CrewAI is crucial for enabling systematic teamwork among agents.
This documentation has been updated to reflect the latest features, enhancements, and the planned integration of the Consensual Process, ensuring users have access to the most current and comprehensive information.


# Reasoning
Source: https://docs.crewai.com/en/concepts/reasoning

Learn how to enable and use agent reasoning to improve task execution.

## Overview

Agent reasoning is a feature that allows agents to reflect on a task and create a plan before execution. This helps agents approach tasks more methodically and ensures they're ready to perform the assigned work.

## Usage

To enable reasoning for an agent, simply set `reasoning=True` when creating the agent:

```python
from crewai import Agent

agent = Agent(
    role="Data Analyst",
    goal="Analyze complex datasets and provide insights",
    backstory="You are an experienced data analyst with expertise in finding patterns in complex data.",
    reasoning=True,  # Enable reasoning
    max_reasoning_attempts=3  # Optional: Set a maximum number of reasoning attempts
)
```

## How It Works

When reasoning is enabled, before executing a task, the agent will:

1. Reflect on the task and create a detailed plan
2. Evaluate whether it's ready to execute the task
3. Refine the plan as necessary until it's ready or max\_reasoning\_attempts is reached
4. Inject the reasoning plan into the task description before execution

This process helps the agent break down complex tasks into manageable steps and identify potential challenges before starting.

## Configuration Options

<ParamField body="reasoning" type="bool" default="False">
  Enable or disable reasoning
</ParamField>

<ParamField body="max_reasoning_attempts" type="int" default="None">
  Maximum number of attempts to refine the plan before proceeding with execution. If None (default), the agent will continue refining until it's ready.
</ParamField>

## Example

Here's a complete example:

```python
from crewai import Agent, Task, Crew

# Create an agent with reasoning enabled
analyst = Agent(
    role="Data Analyst",
    goal="Analyze data and provide insights",
    backstory="You are an expert data analyst.",
    reasoning=True,
    max_reasoning_attempts=3  # Optional: Set a limit on reasoning attempts
)

# Create a task
analysis_task = Task(
    description="Analyze the provided sales data and identify key trends.",
    expected_output="A report highlighting the top 3 sales trends.",
    agent=analyst
)

# Create a crew and run the task
crew = Crew(agents=[analyst], tasks=[analysis_task])
result = crew.kickoff()

print(result)
```

## Error Handling

The reasoning process is designed to be robust, with error handling built in. If an error occurs during reasoning, the agent will proceed with executing the task without the reasoning plan. This ensures that tasks can still be executed even if the reasoning process fails.

Here's how to handle potential errors in your code:

```python
from crewai import Agent, Task
import logging

# Set up logging to capture any reasoning errors
logging.basicConfig(level=logging.INFO)

# Create an agent with reasoning enabled
agent = Agent(
    role="Data Analyst",
    goal="Analyze data and provide insights",
    reasoning=True,
    max_reasoning_attempts=3
)

# Create a task
task = Task(
    description="Analyze the provided sales data and identify key trends.",
    expected_output="A report highlighting the top 3 sales trends.",
    agent=agent
)

# Execute the task
# If an error occurs during reasoning, it will be logged and execution will continue
result = agent.execute_task(task)
```

## Example Reasoning Output

Here's an example of what a reasoning plan might look like for a data analysis task:

```
Task: Analyze the provided sales data and identify key trends.

Reasoning Plan:
I'll analyze the sales data to identify the top 3 trends.

1. Understanding of the task:
   I need to analyze sales data to identify key trends that would be valuable for business decision-making.

2. Key steps I'll take:
   - First, I'll examine the data structure to understand what fields are available
   - Then I'll perform exploratory data analysis to identify patterns
   - Next, I'll analyze sales by time periods to identify temporal trends
   - I'll also analyze sales by product categories and customer segments
   - Finally, I'll identify the top 3 most significant trends

3. Approach to challenges:
   - If the data has missing values, I'll decide whether to fill or filter them
   - If the data has outliers, I'll investigate whether they're valid data points or errors
   - If trends aren't immediately obvious, I'll apply statistical methods to uncover patterns

4. Use of available tools:
   - I'll use data analysis tools to explore and visualize the data
   - I'll use statistical tools to identify significant patterns
   - I'll use knowledge retrieval to access relevant information about sales analysis

5. Expected outcome:
   A concise report highlighting the top 3 sales trends with supporting evidence from the data.

READY: I am ready to execute the task.
```

This reasoning plan helps the agent organize its approach to the task, consider potential challenges, and ensure it delivers the expected output.


# Tasks
Source: https://docs.crewai.com/en/concepts/tasks

Detailed guide on managing and creating tasks within the CrewAI framework.

## Overview

In the CrewAI framework, a `Task` is a specific assignment completed by an `Agent`.

Tasks provide all necessary details for execution, such as a description, the agent responsible, required tools, and more, facilitating a wide range of action complexities.

Tasks within CrewAI can be collaborative, requiring multiple agents to work together. This is managed through the task properties and orchestrated by the Crew's process, enhancing teamwork and efficiency.

<Note type="info" title="Enterprise Enhancement: Visual Task Builder">
  CrewAI Enterprise includes a Visual Task Builder in Crew Studio that simplifies complex task creation and chaining. Design your task flows visually and test them in real-time without writing code.

  ![Task Builder Screenshot](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-studio-interface.png)

  The Visual Task Builder enables:

  * Drag-and-drop task creation
  * Visual task dependencies and flow
  * Real-time testing and validation
  * Easy sharing and collaboration
</Note>

### Task Execution Flow

Tasks can be executed in two ways:

* **Sequential**: Tasks are executed in the order they are defined
* **Hierarchical**: Tasks are assigned to agents based on their roles and expertise

The execution flow is defined when creating the crew:

```python Code
crew = Crew(
    agents=[agent1, agent2],
    tasks=[task1, task2],
    process=Process.sequential  # or Process.hierarchical
)
```

## Task Attributes

| Attribute                        | Parameters        | Type                        | Description                                                                                                     |
| :------------------------------- | :---------------- | :-------------------------- | :-------------------------------------------------------------------------------------------------------------- |
| **Description**                  | `description`     | `str`                       | A clear, concise statement of what the task entails.                                                            |
| **Expected Output**              | `expected_output` | `str`                       | A detailed description of what the task's completion looks like.                                                |
| **Name** *(optional)*            | `name`            | `Optional[str]`             | A name identifier for the task.                                                                                 |
| **Agent** *(optional)*           | `agent`           | `Optional[BaseAgent]`       | The agent responsible for executing the task.                                                                   |
| **Tools** *(optional)*           | `tools`           | `List[BaseTool]`            | The tools/resources the agent is limited to use for this task.                                                  |
| **Context** *(optional)*         | `context`         | `Optional[List["Task"]]`    | Other tasks whose outputs will be used as context for this task.                                                |
| **Async Execution** *(optional)* | `async_execution` | `Optional[bool]`            | Whether the task should be executed asynchronously. Defaults to False.                                          |
| **Human Input** *(optional)*     | `human_input`     | `Optional[bool]`            | Whether the task should have a human review the final answer of the agent. Defaults to False.                   |
| **Markdown** *(optional)*        | `markdown`        | `Optional[bool]`            | Whether the task should instruct the agent to return the final answer formatted in Markdown. Defaults to False. |
| **Config** *(optional)*          | `config`          | `Optional[Dict[str, Any]]`  | Task-specific configuration parameters.                                                                         |
| **Output File** *(optional)*     | `output_file`     | `Optional[str]`             | File path for storing the task output.                                                                          |
| **Output JSON** *(optional)*     | `output_json`     | `Optional[Type[BaseModel]]` | A Pydantic model to structure the JSON output.                                                                  |
| **Output Pydantic** *(optional)* | `output_pydantic` | `Optional[Type[BaseModel]]` | A Pydantic model for task output.                                                                               |
| **Callback** *(optional)*        | `callback`        | `Optional[Any]`             | Function/object to be executed after task completion.                                                           |

## Creating Tasks

There are two ways to create tasks in CrewAI: using **YAML configuration (recommended)** or defining them **directly in code**.

### YAML Configuration (Recommended)

Using YAML configuration provides a cleaner, more maintainable way to define tasks. We strongly recommend using this approach to define tasks in your CrewAI projects.

After creating your CrewAI project as outlined in the [Installation](/en/installation) section, navigate to the `src/latest_ai_development/config/tasks.yaml` file and modify the template to match your specific task requirements.

<Note>
  Variables in your YAML files (like `{topic}`) will be replaced with values from your inputs when running the crew:

  ```python Code
  crew.kickoff(inputs={'topic': 'AI Agents'})
  ```
</Note>

Here's an example of how to configure tasks using YAML:

````yaml tasks.yaml
research_task:
  description: >
    Conduct a thorough research about {topic}
    Make sure you find any interesting and relevant information given
    the current year is 2025.
  expected_output: >
    A list with 10 bullet points of the most relevant information about {topic}
  agent: researcher

reporting_task:
  description: >
    Review the context you got and expand each topic into a full section for a report.
    Make sure the report is detailed and contains any and all relevant information.
  expected_output: >
    A fully fledge reports with the mains topics, each with a full section of information.
    Formatted as markdown without '```'
  agent: reporting_analyst
  markdown: true
  output_file: report.md
````

To use this YAML configuration in your code, create a crew class that inherits from `CrewBase`:

```python crew.py
# src/latest_ai_development/crew.py

from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task
from crewai_tools import SerperDevTool

@CrewBase
class LatestAiDevelopmentCrew():
  """LatestAiDevelopment crew"""

  @agent
  def researcher(self) -> Agent:
    return Agent(
      config=self.agents_config['researcher'], # type: ignore[index]
      verbose=True,
      tools=[SerperDevTool()]
    )

  @agent
  def reporting_analyst(self) -> Agent:
    return Agent(
      config=self.agents_config['reporting_analyst'], # type: ignore[index]
      verbose=True
    )

  @task
  def research_task(self) -> Task:
    return Task(
      config=self.tasks_config['research_task'] # type: ignore[index]
    )

  @task
  def reporting_task(self) -> Task:
    return Task(
      config=self.tasks_config['reporting_task'] # type: ignore[index]
    )

  @crew
  def crew(self) -> Crew:
    return Crew(
      agents=[
        self.researcher(),
        self.reporting_analyst()
      ],
      tasks=[
        self.research_task(),
        self.reporting_task()
      ],
      process=Process.sequential
    )
```

<Note>
  The names you use in your YAML files (`agents.yaml` and `tasks.yaml`) should match the method names in your Python code.
</Note>

### Direct Code Definition (Alternative)

Alternatively, you can define tasks directly in your code without using YAML configuration:

```python task.py
from crewai import Task

research_task = Task(
    description="""
        Conduct a thorough research about AI Agents.
        Make sure you find any interesting and relevant information given
        the current year is 2025.
    """,
    expected_output="""
        A list with 10 bullet points of the most relevant information about AI Agents
    """,
    agent=researcher
)

reporting_task = Task(
    description="""
        Review the context you got and expand each topic into a full section for a report.
        Make sure the report is detailed and contains any and all relevant information.
    """,
    expected_output="""
        A fully fledge reports with the mains topics, each with a full section of information.
    """,
    agent=reporting_analyst,
    markdown=True,  # Enable markdown formatting for the final output
    output_file="report.md"
)
```

<Tip>
  Directly specify an `agent` for assignment or let the `hierarchical` CrewAI's process decide based on roles, availability, etc.
</Tip>

## Task Output

Understanding task outputs is crucial for building effective AI workflows. CrewAI provides a structured way to handle task results through the `TaskOutput` class, which supports multiple output formats and can be easily passed between tasks.

The output of a task in CrewAI framework is encapsulated within the `TaskOutput` class. This class provides a structured way to access results of a task, including various formats such as raw output, JSON, and Pydantic models.

By default, the `TaskOutput` will only include the `raw` output. A `TaskOutput` will only include the `pydantic` or `json_dict` output if the original `Task` object was configured with `output_pydantic` or `output_json`, respectively.

### Task Output Attributes

| Attribute         | Parameters      | Type                       | Description                                                                                        |
| :---------------- | :-------------- | :------------------------- | :------------------------------------------------------------------------------------------------- |
| **Description**   | `description`   | `str`                      | Description of the task.                                                                           |
| **Summary**       | `summary`       | `Optional[str]`            | Summary of the task, auto-generated from the first 10 words of the description.                    |
| **Raw**           | `raw`           | `str`                      | The raw output of the task. This is the default format for the output.                             |
| **Pydantic**      | `pydantic`      | `Optional[BaseModel]`      | A Pydantic model object representing the structured output of the task.                            |
| **JSON Dict**     | `json_dict`     | `Optional[Dict[str, Any]]` | A dictionary representing the JSON output of the task.                                             |
| **Agent**         | `agent`         | `str`                      | The agent that executed the task.                                                                  |
| **Output Format** | `output_format` | `OutputFormat`             | The format of the task output, with options including RAW, JSON, and Pydantic. The default is RAW. |

### Task Methods and Properties

| Method/Property | Description                                                                                       |
| :-------------- | :------------------------------------------------------------------------------------------------ |
| **json**        | Returns the JSON string representation of the task output if the output format is JSON.           |
| **to\_dict**    | Converts the JSON and Pydantic outputs to a dictionary.                                           |
| **str**         | Returns the string representation of the task output, prioritizing Pydantic, then JSON, then raw. |

### Accessing Task Outputs

Once a task has been executed, its output can be accessed through the `output` attribute of the `Task` object. The `TaskOutput` class provides various ways to interact with and present this output.

#### Example

```python Code
# Example task
task = Task(
    description='Find and summarize the latest AI news',
    expected_output='A bullet list summary of the top 5 most important AI news',
    agent=research_agent,
    tools=[search_tool]
)

# Execute the crew
crew = Crew(
    agents=[research_agent],
    tasks=[task],
    verbose=True
)

result = crew.kickoff()

# Accessing the task output
task_output = task.output

print(f"Task Description: {task_output.description}")
print(f"Task Summary: {task_output.summary}")
print(f"Raw Output: {task_output.raw}")
if task_output.json_dict:
    print(f"JSON Output: {json.dumps(task_output.json_dict, indent=2)}")
if task_output.pydantic:
    print(f"Pydantic Output: {task_output.pydantic}")
```

## Markdown Output Formatting

The `markdown` parameter enables automatic markdown formatting for task outputs. When set to `True`, the task will instruct the agent to format the final answer using proper Markdown syntax.

### Using Markdown Formatting

```python Code
# Example task with markdown formatting enabled
formatted_task = Task(
    description="Create a comprehensive report on AI trends",
    expected_output="A well-structured report with headers, sections, and bullet points",
    agent=reporter_agent,
    markdown=True  # Enable automatic markdown formatting
)
```

When `markdown=True`, the agent will receive additional instructions to format the output using:

* `#` for headers
* `**text**` for bold text
* `*text*` for italic text
* `-` or `*` for bullet points
* `` `code` `` for inline code
* ` `language \`\`\` for code blocks

### YAML Configuration with Markdown

```yaml tasks.yaml
analysis_task:
  description: >
    Analyze the market data and create a detailed report
  expected_output: >
    A comprehensive analysis with charts and key findings
  agent: analyst
  markdown: true  # Enable markdown formatting
  output_file: analysis.md
```

### Benefits of Markdown Output

* **Consistent Formatting**: Ensures all outputs follow proper markdown conventions
* **Better Readability**: Structured content with headers, lists, and emphasis
* **Documentation Ready**: Output can be directly used in documentation systems
* **Cross-Platform Compatibility**: Markdown is universally supported

<Note>
  The markdown formatting instructions are automatically added to the task prompt when `markdown=True`, so you don't need to specify formatting requirements in your task description.
</Note>

## Task Dependencies and Context

Tasks can depend on the output of other tasks using the `context` attribute. For example:

```python Code
research_task = Task(
    description="Research the latest developments in AI",
    expected_output="A list of recent AI developments",
    agent=researcher
)

analysis_task = Task(
    description="Analyze the research findings and identify key trends",
    expected_output="Analysis report of AI trends",
    agent=analyst,
    context=[research_task]  # This task will wait for research_task to complete
)
```

## Task Guardrails

Task guardrails provide a way to validate and transform task outputs before they
are passed to the next task. This feature helps ensure data quality and provides
feedback to agents when their output doesn't meet specific criteria.

### Using Task Guardrails

To add a guardrail to a task, provide a validation function through the `guardrail` parameter:

```python Code
from typing import Tuple, Union, Dict, Any
from crewai import TaskOutput

def validate_blog_content(result: TaskOutput) -> Tuple[bool, Any]:
    """Validate blog content meets requirements."""
    try:
        # Check word count
        word_count = len(result.split())
        if word_count > 200:
            return (False, "Blog content exceeds 200 words")

        # Additional validation logic here
        return (True, result.strip())
    except Exception as e:
        return (False, "Unexpected error during validation")

blog_task = Task(
    description="Write a blog post about AI",
    expected_output="A blog post under 200 words",
    agent=blog_agent,
    guardrail=validate_blog_content  # Add the guardrail function
)
```

### Guardrail Function Requirements

1. **Function Signature**:
   * Must accept exactly one parameter (the task output)
   * Should return a tuple of `(bool, Any)`
   * Type hints are recommended but optional

2. **Return Values**:
   * On success: it returns a tuple of `(bool, Any)`. For example: `(True, validated_result)`
   * On Failure: it returns a tuple of `(bool, str)`. For example: `(False, "Error message explain the failure")`

### LLMGuardrail

The `LLMGuardrail` class offers a robust mechanism for validating task outputs.

### Error Handling Best Practices

1. **Structured Error Responses**:

```python Code
from crewai import TaskOutput, LLMGuardrail

def validate_with_context(result: TaskOutput) -> Tuple[bool, Any]:
    try:
        # Main validation logic
        validated_data = perform_validation(result)
        return (True, validated_data)
    except ValidationError as e:
        return (False, f"VALIDATION_ERROR: {str(e)}")
    except Exception as e:
        return (False, str(e))
```

2. **Error Categories**:
   * Use specific error codes
   * Include relevant context
   * Provide actionable feedback

3. **Validation Chain**:

```python Code
from typing import Any, Dict, List, Tuple, Union
from crewai import TaskOutput

def complex_validation(result: TaskOutput) -> Tuple[bool, Any]:
    """Chain multiple validation steps."""
    # Step 1: Basic validation
    if not result:
        return (False, "Empty result")

    # Step 2: Content validation
    try:
        validated = validate_content(result)
        if not validated:
            return (False, "Invalid content")

        # Step 3: Format validation
        formatted = format_output(validated)
        return (True, formatted)
    except Exception as e:
        return (False, str(e))
```

### Handling Guardrail Results

When a guardrail returns `(False, error)`:

1. The error is sent back to the agent
2. The agent attempts to fix the issue
3. The process repeats until:
   * The guardrail returns `(True, result)`
   * Maximum retries are reached

Example with retry handling:

```python Code
from typing import Optional, Tuple, Union
from crewai import TaskOutput, Task

def validate_json_output(result: TaskOutput) -> Tuple[bool, Any]:
    """Validate and parse JSON output."""
    try:
        # Try to parse as JSON
        data = json.loads(result)
        return (True, data)
    except json.JSONDecodeError as e:
        return (False, "Invalid JSON format")

task = Task(
    description="Generate a JSON report",
    expected_output="A valid JSON object",
    agent=analyst,
    guardrail=validate_json_output,
    max_retries=3  # Limit retry attempts
)
```

## Getting Structured Consistent Outputs from Tasks

<Note>
  It's also important to note that the output of the final task of a crew becomes the final output of the actual crew itself.
</Note>

### Using `output_pydantic`

The `output_pydantic` property allows you to define a Pydantic model that the task output should conform to. This ensures that the output is not only structured but also validated according to the Pydantic model.

Here's an example demonstrating how to use output\_pydantic:

```python Code
import json

from crewai import Agent, Crew, Process, Task
from pydantic import BaseModel


class Blog(BaseModel):
    title: str
    content: str


blog_agent = Agent(
    role="Blog Content Generator Agent",
    goal="Generate a blog title and content",
    backstory="""You are an expert content creator, skilled in crafting engaging and informative blog posts.""",
    verbose=False,
    allow_delegation=False,
    llm="gpt-4o",
)

task1 = Task(
    description="""Create a blog title and content on a given topic. Make sure the content is under 200 words.""",
    expected_output="A compelling blog title and well-written content.",
    agent=blog_agent,
    output_pydantic=Blog,
)

# Instantiate your crew with a sequential process
crew = Crew(
    agents=[blog_agent],
    tasks=[task1],
    verbose=True,
    process=Process.sequential,
)

result = crew.kickoff()

# Option 1: Accessing Properties Using Dictionary-Style Indexing
print("Accessing Properties - Option 1")
title = result["title"]
content = result["content"]
print("Title:", title)
print("Content:", content)

# Option 2: Accessing Properties Directly from the Pydantic Model
print("Accessing Properties - Option 2")
title = result.pydantic.title
content = result.pydantic.content
print("Title:", title)
print("Content:", content)

# Option 3: Accessing Properties Using the to_dict() Method
print("Accessing Properties - Option 3")
output_dict = result.to_dict()
title = output_dict["title"]
content = output_dict["content"]
print("Title:", title)
print("Content:", content)

# Option 4: Printing the Entire Blog Object
print("Accessing Properties - Option 5")
print("Blog:", result)

```

In this example:

* A Pydantic model Blog is defined with title and content fields.
* The task task1 uses the output\_pydantic property to specify that its output should conform to the Blog model.
* After executing the crew, you can access the structured output in multiple ways as shown.

#### Explanation of Accessing the Output

1. Dictionary-Style Indexing: You can directly access the fields using result\["field\_name"]. This works because the CrewOutput class implements the **getitem** method.
2. Directly from Pydantic Model: Access the attributes directly from the result.pydantic object.
3. Using to\_dict() Method: Convert the output to a dictionary and access the fields.
4. Printing the Entire Object: Simply print the result object to see the structured output.

### Using `output_json`

The `output_json` property allows you to define the expected output in JSON format. This ensures that the task's output is a valid JSON structure that can be easily parsed and used in your application.

Here's an example demonstrating how to use `output_json`:

```python Code
import json

from crewai import Agent, Crew, Process, Task
from pydantic import BaseModel


# Define the Pydantic model for the blog
class Blog(BaseModel):
    title: str
    content: str


# Define the agent
blog_agent = Agent(
    role="Blog Content Generator Agent",
    goal="Generate a blog title and content",
    backstory="""You are an expert content creator, skilled in crafting engaging and informative blog posts.""",
    verbose=False,
    allow_delegation=False,
    llm="gpt-4o",
)

# Define the task with output_json set to the Blog model
task1 = Task(
    description="""Create a blog title and content on a given topic. Make sure the content is under 200 words.""",
    expected_output="A JSON object with 'title' and 'content' fields.",
    agent=blog_agent,
    output_json=Blog,
)

# Instantiate the crew with a sequential process
crew = Crew(
    agents=[blog_agent],
    tasks=[task1],
    verbose=True,
    process=Process.sequential,
)

# Kickoff the crew to execute the task
result = crew.kickoff()

# Option 1: Accessing Properties Using Dictionary-Style Indexing
print("Accessing Properties - Option 1")
title = result["title"]
content = result["content"]
print("Title:", title)
print("Content:", content)

# Option 2: Printing the Entire Blog Object
print("Accessing Properties - Option 2")
print("Blog:", result)
```

In this example:

* A Pydantic model Blog is defined with title and content fields, which is used to specify the structure of the JSON output.
* The task task1 uses the output\_json property to indicate that it expects a JSON output conforming to the Blog model.
* After executing the crew, you can access the structured JSON output in two ways as shown.

#### Explanation of Accessing the Output

1. Accessing Properties Using Dictionary-Style Indexing: You can access the fields directly using result\["field\_name"]. This is possible because the CrewOutput class implements the **getitem** method, allowing you to treat the output like a dictionary. In this option, we're retrieving the title and content from the result.
2. Printing the Entire Blog Object: By printing result, you get the string representation of the CrewOutput object. Since the **str** method is implemented to return the JSON output, this will display the entire output as a formatted string representing the Blog object.

***

By using output\_pydantic or output\_json, you ensure that your tasks produce outputs in a consistent and structured format, making it easier to process and utilize the data within your application or across multiple tasks.

## Integrating Tools with Tasks

Leverage tools from the [CrewAI Toolkit](https://github.com/joaomdmoura/crewai-tools) and [LangChain Tools](https://python.langchain.com/docs/integrations/tools) for enhanced task performance and agent interaction.

## Creating a Task with Tools

```python Code
import os
os.environ["OPENAI_API_KEY"] = "Your Key"
os.environ["SERPER_API_KEY"] = "Your Key" # serper.dev API key

from crewai import Agent, Task, Crew
from crewai_tools import SerperDevTool

research_agent = Agent(
  role='Researcher',
  goal='Find and summarize the latest AI news',
  backstory="""You're a researcher at a large company.
  You're responsible for analyzing data and providing insights
  to the business.""",
  verbose=True
)

# to perform a semantic search for a specified query from a text's content across the internet
search_tool = SerperDevTool()

task = Task(
  description='Find and summarize the latest AI news',
  expected_output='A bullet list summary of the top 5 most important AI news',
  agent=research_agent,
  tools=[search_tool]
)

crew = Crew(
    agents=[research_agent],
    tasks=[task],
    verbose=True
)

result = crew.kickoff()
print(result)
```

This demonstrates how tasks with specific tools can override an agent's default set for tailored task execution.

## Referring to Other Tasks

In CrewAI, the output of one task is automatically relayed into the next one, but you can specifically define what tasks' output, including multiple, should be used as context for another task.

This is useful when you have a task that depends on the output of another task that is not performed immediately after it. This is done through the `context` attribute of the task:

```python Code
# ...

research_ai_task = Task(
    description="Research the latest developments in AI",
    expected_output="A list of recent AI developments",
    async_execution=True,
    agent=research_agent,
    tools=[search_tool]
)

research_ops_task = Task(
    description="Research the latest developments in AI Ops",
    expected_output="A list of recent AI Ops developments",
    async_execution=True,
    agent=research_agent,
    tools=[search_tool]
)

write_blog_task = Task(
    description="Write a full blog post about the importance of AI and its latest news",
    expected_output="Full blog post that is 4 paragraphs long",
    agent=writer_agent,
    context=[research_ai_task, research_ops_task]
)

#...
```

## Asynchronous Execution

You can define a task to be executed asynchronously. This means that the crew will not wait for it to be completed to continue with the next task. This is useful for tasks that take a long time to be completed, or that are not crucial for the next tasks to be performed.

You can then use the `context` attribute to define in a future task that it should wait for the output of the asynchronous task to be completed.

```python Code
#...

list_ideas = Task(
    description="List of 5 interesting ideas to explore for an article about AI.",
    expected_output="Bullet point list of 5 ideas for an article.",
    agent=researcher,
    async_execution=True # Will be executed asynchronously
)

list_important_history = Task(
    description="Research the history of AI and give me the 5 most important events.",
    expected_output="Bullet point list of 5 important events.",
    agent=researcher,
    async_execution=True # Will be executed asynchronously
)

write_article = Task(
    description="Write an article about AI, its history, and interesting ideas.",
    expected_output="A 4 paragraph article about AI.",
    agent=writer,
    context=[list_ideas, list_important_history] # Will wait for the output of the two tasks to be completed
)

#...
```

## Callback Mechanism

The callback function is executed after the task is completed, allowing for actions or notifications to be triggered based on the task's outcome.

```python Code
# ...

def callback_function(output: TaskOutput):
    # Do something after the task is completed
    # Example: Send an email to the manager
    print(f"""
        Task completed!
        Task: {output.description}
        Output: {output.raw}
    """)

research_task = Task(
    description='Find and summarize the latest AI news',
    expected_output='A bullet list summary of the top 5 most important AI news',
    agent=research_agent,
    tools=[search_tool],
    callback=callback_function
)

#...
```

## Accessing a Specific Task Output

Once a crew finishes running, you can access the output of a specific task by using the `output` attribute of the task object:

```python Code
# ...
task1 = Task(
    description='Find and summarize the latest AI news',
    expected_output='A bullet list summary of the top 5 most important AI news',
    agent=research_agent,
    tools=[search_tool]
)

#...

crew = Crew(
    agents=[research_agent],
    tasks=[task1, task2, task3],
    verbose=True
)

result = crew.kickoff()

# Returns a TaskOutput object with the description and results of the task
print(f"""
    Task completed!
    Task: {task1.output.description}
    Output: {task1.output.raw}
""")
```

## Tool Override Mechanism

Specifying tools in a task allows for dynamic adaptation of agent capabilities, emphasizing CrewAI's flexibility.

## Error Handling and Validation Mechanisms

While creating and executing tasks, certain validation mechanisms are in place to ensure the robustness and reliability of task attributes. These include but are not limited to:

* Ensuring only one output type is set per task to maintain clear output expectations.
* Preventing the manual assignment of the `id` attribute to uphold the integrity of the unique identifier system.

These validations help in maintaining the consistency and reliability of task executions within the crewAI framework.

## Task Guardrails

Task guardrails provide a powerful way to validate, transform, or filter task outputs before they are passed to the next task. Guardrails are optional functions that execute before the next task starts, allowing you to ensure that task outputs meet specific requirements or formats.

### Basic Usage

#### Define your own logic to validate

```python Code
from typing import Tuple, Union
from crewai import Task

def validate_json_output(result: str) -> Tuple[bool, Union[dict, str]]:
    """Validate that the output is valid JSON."""
    try:
        json_data = json.loads(result)
        return (True, json_data)
    except json.JSONDecodeError:
        return (False, "Output must be valid JSON")

task = Task(
    description="Generate JSON data",
    expected_output="Valid JSON object",
    guardrail=validate_json_output
)
```

#### Leverage a no-code approach for validation

```python Code
from crewai import Task

task = Task(
    description="Generate JSON data",
    expected_output="Valid JSON object",
    guardrail="Ensure the response is a valid JSON object"
)
```

#### Using YAML

```yaml
research_task:
  ...
  guardrail: make sure each bullet contains a minimum of 100 words
  ...
```

```python Code
@CrewBase
class InternalCrew:
    agents_config = "config/agents.yaml"
    tasks_config = "config/tasks.yaml"

    ...
    @task
    def research_task(self):
        return Task(config=self.tasks_config["research_task"])  # type: ignore[index]
    ...
```

#### Use custom models for code generation

```python Code
from crewai import Task
from crewai.llm import LLM

task = Task(
    description="Generate JSON data",
    expected_output="Valid JSON object",
    guardrail=LLMGuardrail(
        description="Ensure the response is a valid JSON object",
        llm=LLM(model="gpt-4o-mini"),
    )
)
```

### How Guardrails Work

1. **Optional Attribute**: Guardrails are an optional attribute at the task level, allowing you to add validation only where needed.
2. **Execution Timing**: The guardrail function is executed before the next task starts, ensuring valid data flow between tasks.
3. **Return Format**: Guardrails must return a tuple of `(success, data)`:
   * If `success` is `True`, `data` is the validated/transformed result
   * If `success` is `False`, `data` is the error message
4. **Result Routing**:
   * On success (`True`), the result is automatically passed to the next task
   * On failure (`False`), the error is sent back to the agent to generate a new answer

### Common Use Cases

#### Data Format Validation

```python Code
def validate_email_format(result: str) -> Tuple[bool, Union[str, str]]:
    """Ensure the output contains a valid email address."""
    import re
    email_pattern = r'^[\w\.-]+@[\w\.-]+\.\w+$'
    if re.match(email_pattern, result.strip()):
        return (True, result.strip())
    return (False, "Output must be a valid email address")
```

#### Content Filtering

```python Code
def filter_sensitive_info(result: str) -> Tuple[bool, Union[str, str]]:
    """Remove or validate sensitive information."""
    sensitive_patterns = ['SSN:', 'password:', 'secret:']
    for pattern in sensitive_patterns:
        if pattern.lower() in result.lower():
            return (False, f"Output contains sensitive information ({pattern})")
    return (True, result)
```

#### Data Transformation

```python Code
def normalize_phone_number(result: str) -> Tuple[bool, Union[str, str]]:
    """Ensure phone numbers are in a consistent format."""
    import re
    digits = re.sub(r'\D', '', result)
    if len(digits) == 10:
        formatted = f"({digits[:3]}) {digits[3:6]}-{digits[6:]}"
        return (True, formatted)
    return (False, "Output must be a 10-digit phone number")
```

### Advanced Features

#### Chaining Multiple Validations

```python Code
def chain_validations(*validators):
    """Chain multiple validators together."""
    def combined_validator(result):
        for validator in validators:
            success, data = validator(result)
            if not success:
                return (False, data)
            result = data
        return (True, result)
    return combined_validator

# Usage
task = Task(
    description="Get user contact info",
    expected_output="Email and phone",
    guardrail=chain_validations(
        validate_email_format,
        filter_sensitive_info
    )
)
```

#### Custom Retry Logic

```python Code
task = Task(
    description="Generate data",
    expected_output="Valid data",
    guardrail=validate_data,
    max_retries=5  # Override default retry limit
)
```

## Creating Directories when Saving Files

You can now specify if a task should create directories when saving its output to a file. This is particularly useful for organizing outputs and ensuring that file paths are correctly structured.

```python Code
# ...

save_output_task = Task(
    description='Save the summarized AI news to a file',
    expected_output='File saved successfully',
    agent=research_agent,
    tools=[file_save_tool],
    output_file='outputs/ai_news_summary.txt',
    create_directory=True
)

#...
```

Check out the video below to see how to use structured outputs in CrewAI:

<iframe width="560" height="315" src="https://www.youtube.com/embed/dNpKQk5uxHw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen />

## Conclusion

Tasks are the driving force behind the actions of agents in CrewAI.
By properly defining tasks and their outcomes, you set the stage for your AI agents to work effectively, either independently or as a collaborative unit.
Equipping tasks with appropriate tools, understanding the execution process, and following robust validation practices are crucial for maximizing CrewAI's potential,
ensuring agents are effectively prepared for their assignments and that tasks are executed as intended.


# Testing
Source: https://docs.crewai.com/en/concepts/testing

Learn how to test your CrewAI Crew and evaluate their performance.

## Overview

Testing is a crucial part of the development process, and it is essential to ensure that your crew is performing as expected. With crewAI, you can easily test your crew and evaluate its performance using the built-in testing capabilities.

### Using the Testing Feature

We added the CLI command `crewai test` to make it easy to test your crew. This command will run your crew for a specified number of iterations and provide detailed performance metrics. The parameters are `n_iterations` and `model`, which are optional and default to 2 and `gpt-4o-mini` respectively. For now, the only provider available is OpenAI.

```bash
crewai test
```

If you want to run more iterations or use a different model, you can specify the parameters like this:

```bash
crewai test --n_iterations 5 --model gpt-4o
```

or using the short forms:

```bash
crewai test -n 5 -m gpt-4o
```

When you run the `crewai test` command, the crew will be executed for the specified number of iterations, and the performance metrics will be displayed at the end of the run.

A table of scores at the end will show the performance of the crew in terms of the following metrics:

<center>**Tasks Scores (1-10 Higher is better)**</center>

| Tasks/Crew/Agents  | Run 1 | Run 2 | Avg. Total |            Agents            | Additional Info                |
| :----------------- | :---: | :---: | :--------: | :--------------------------: | :----------------------------- |
| Task 1             |  9.0  |  9.5  |   **9.2**  |     Professional Insights    |                                |
|                    |       |       |            |          Researcher          |                                |
| Task 2             |  9.0  |  10.0 |   **9.5**  | Company Profile Investigator |                                |
| Task 3             |  9.0  |  9.0  |   **9.0**  |      Automation Insights     |                                |
|                    |       |       |            |          Specialist          |                                |
| Task 4             |  9.0  |  9.0  |   **9.0**  |     Final Report Compiler    | Automation Insights Specialist |
| Crew               |  9.00 |  9.38 |   **9.2**  |                              |                                |
| Execution Time (s) |  126  |  145  |   **135**  |                              |                                |

The example above shows the test results for two runs of the crew with two tasks, with the average total score for each task and the crew as a whole.


# Tools
Source: https://docs.crewai.com/en/concepts/tools

Understanding and leveraging tools within the CrewAI framework for agent collaboration and task execution.

## Overview

CrewAI tools empower agents with capabilities ranging from web searching and data analysis to collaboration and delegating tasks among coworkers.
This documentation outlines how to create, integrate, and leverage these tools within the CrewAI framework, including a new focus on collaboration tools.

## What is a Tool?

A tool in CrewAI is a skill or function that agents can utilize to perform various actions.
This includes tools from the [CrewAI Toolkit](https://github.com/joaomdmoura/crewai-tools) and [LangChain Tools](https://python.langchain.com/docs/integrations/tools),
enabling everything from simple searches to complex interactions and effective teamwork among agents.

<Note type="info" title="Enterprise Enhancement: Tools Repository">
  CrewAI Enterprise provides a comprehensive Tools Repository with pre-built integrations for common business systems and APIs. Deploy agents with enterprise tools in minutes instead of days.

  The Enterprise Tools Repository includes:

  * Pre-built connectors for popular enterprise systems
  * Custom tool creation interface
  * Version control and sharing capabilities
  * Security and compliance features
</Note>

## Key Characteristics of Tools

* **Utility**: Crafted for tasks such as web searching, data analysis, content generation, and agent collaboration.
* **Integration**: Boosts agent capabilities by seamlessly integrating tools into their workflow.
* **Customizability**: Provides the flexibility to develop custom tools or utilize existing ones, catering to the specific needs of agents.
* **Error Handling**: Incorporates robust error handling mechanisms to ensure smooth operation.
* **Caching Mechanism**: Features intelligent caching to optimize performance and reduce redundant operations.
* **Asynchronous Support**: Handles both synchronous and asynchronous tools, enabling non-blocking operations.

## Using CrewAI Tools

To enhance your agents' capabilities with crewAI tools, begin by installing our extra tools package:

```bash
pip install 'crewai[tools]'
```

Here's an example demonstrating their use:

```python Code
import os
from crewai import Agent, Task, Crew
# Importing crewAI tools
from crewai_tools import (
    DirectoryReadTool,
    FileReadTool,
    SerperDevTool,
    WebsiteSearchTool
)

# Set up API keys
os.environ["SERPER_API_KEY"] = "Your Key" # serper.dev API key
os.environ["OPENAI_API_KEY"] = "Your Key"

# Instantiate tools
docs_tool = DirectoryReadTool(directory='./blog-posts')
file_tool = FileReadTool()
search_tool = SerperDevTool()
web_rag_tool = WebsiteSearchTool()

# Create agents
researcher = Agent(
    role='Market Research Analyst',
    goal='Provide up-to-date market analysis of the AI industry',
    backstory='An expert analyst with a keen eye for market trends.',
    tools=[search_tool, web_rag_tool],
    verbose=True
)

writer = Agent(
    role='Content Writer',
    goal='Craft engaging blog posts about the AI industry',
    backstory='A skilled writer with a passion for technology.',
    tools=[docs_tool, file_tool],
    verbose=True
)

# Define tasks
research = Task(
    description='Research the latest trends in the AI industry and provide a summary.',
    expected_output='A summary of the top 3 trending developments in the AI industry with a unique perspective on their significance.',
    agent=researcher
)

write = Task(
    description='Write an engaging blog post about the AI industry, based on the research analyst's summary. Draw inspiration from the latest blog posts in the directory.',
    expected_output='A 4-paragraph blog post formatted in markdown with engaging, informative, and accessible content, avoiding complex jargon.',
    agent=writer,
    output_file='blog-posts/new_post.md'  # The final blog post will be saved here
)

# Assemble a crew with planning enabled
crew = Crew(
    agents=[researcher, writer],
    tasks=[research, write],
    verbose=True,
    planning=True,  # Enable planning feature
)

# Execute tasks
crew.kickoff()
```

## Available CrewAI Tools

* **Error Handling**: All tools are built with error handling capabilities, allowing agents to gracefully manage exceptions and continue their tasks.
* **Caching Mechanism**: All tools support caching, enabling agents to efficiently reuse previously obtained results, reducing the load on external resources and speeding up the execution time. You can also define finer control over the caching mechanism using the `cache_function` attribute on the tool.

Here is a list of the available tools and their descriptions:

| Tool                             | Description                                                                                    |
| :------------------------------- | :--------------------------------------------------------------------------------------------- |
| **ApifyActorsTool**              | A tool that integrates Apify Actors with your workflows for web scraping and automation tasks. |
| **BrowserbaseLoadTool**          | A tool for interacting with and extracting data from web browsers.                             |
| **CodeDocsSearchTool**           | A RAG tool optimized for searching through code documentation and related technical documents. |
| **CodeInterpreterTool**          | A tool for interpreting python code.                                                           |
| **ComposioTool**                 | Enables use of Composio tools.                                                                 |
| **CSVSearchTool**                | A RAG tool designed for searching within CSV files, tailored to handle structured data.        |
| **DALL-E Tool**                  | A tool for generating images using the DALL-E API.                                             |
| **DirectorySearchTool**          | A RAG tool for searching within directories, useful for navigating through file systems.       |
| **DOCXSearchTool**               | A RAG tool aimed at searching within DOCX documents, ideal for processing Word files.          |
| **DirectoryReadTool**            | Facilitates reading and processing of directory structures and their contents.                 |
| **EXASearchTool**                | A tool designed for performing exhaustive searches across various data sources.                |
| **FileReadTool**                 | Enables reading and extracting data from files, supporting various file formats.               |
| **FirecrawlSearchTool**          | A tool to search webpages using Firecrawl and return the results.                              |
| **FirecrawlCrawlWebsiteTool**    | A tool for crawling webpages using Firecrawl.                                                  |
| **FirecrawlScrapeWebsiteTool**   | A tool for scraping webpages URL using Firecrawl and returning its contents.                   |
| **GithubSearchTool**             | A RAG tool for searching within GitHub repositories, useful for code and documentation search. |
| **SerperDevTool**                | A specialized tool for development purposes, with specific functionalities under development.  |
| **TXTSearchTool**                | A RAG tool focused on searching within text (.txt) files, suitable for unstructured data.      |
| **JSONSearchTool**               | A RAG tool designed for searching within JSON files, catering to structured data handling.     |
| **LlamaIndexTool**               | Enables the use of LlamaIndex tools.                                                           |
| **MDXSearchTool**                | A RAG tool tailored for searching within Markdown (MDX) files, useful for documentation.       |
| **PDFSearchTool**                | A RAG tool aimed at searching within PDF documents, ideal for processing scanned documents.    |
| **PGSearchTool**                 | A RAG tool optimized for searching within PostgreSQL databases, suitable for database queries. |
| **Vision Tool**                  | A tool for generating images using the DALL-E API.                                             |
| **RagTool**                      | A general-purpose RAG tool capable of handling various data sources and types.                 |
| **ScrapeElementFromWebsiteTool** | Enables scraping specific elements from websites, useful for targeted data extraction.         |
| **ScrapeWebsiteTool**            | Facilitates scraping entire websites, ideal for comprehensive data collection.                 |
| **WebsiteSearchTool**            | A RAG tool for searching website content, optimized for web data extraction.                   |
| **XMLSearchTool**                | A RAG tool designed for searching within XML files, suitable for structured data formats.      |
| **YoutubeChannelSearchTool**     | A RAG tool for searching within YouTube channels, useful for video content analysis.           |
| **YoutubeVideoSearchTool**       | A RAG tool aimed at searching within YouTube videos, ideal for video data extraction.          |

## Creating your own Tools

<Tip>
  Developers can craft `custom tools` tailored for their agent's needs or
  utilize pre-built options.
</Tip>

There are two main ways for one to create a CrewAI tool:

### Subclassing `BaseTool`

```python Code
from crewai.tools import BaseTool
from pydantic import BaseModel, Field

class MyToolInput(BaseModel):
    """Input schema for MyCustomTool."""
    argument: str = Field(..., description="Description of the argument.")

class MyCustomTool(BaseTool):
    name: str = "Name of my tool"
    description: str = "What this tool does. It's vital for effective utilization."
    args_schema: Type[BaseModel] = MyToolInput

    def _run(self, argument: str) -> str:
        # Your tool's logic here
        return "Tool's result"
```

## Asynchronous Tool Support

CrewAI supports asynchronous tools, allowing you to implement tools that perform non-blocking operations like network requests, file I/O, or other async operations without blocking the main execution thread.

### Creating Async Tools

You can create async tools in two ways:

#### 1. Using the `tool` Decorator with Async Functions

```python Code
from crewai.tools import tool

@tool("fetch_data_async")
async def fetch_data_async(query: str) -> str:
    """Asynchronously fetch data based on the query."""
    # Simulate async operation
    await asyncio.sleep(1)
    return f"Data retrieved for {query}"
```

#### 2. Implementing Async Methods in Custom Tool Classes

```python Code
from crewai.tools import BaseTool

class AsyncCustomTool(BaseTool):
    name: str = "async_custom_tool"
    description: str = "An asynchronous custom tool"

    async def _run(self, query: str = "") -> str:
        """Asynchronously run the tool"""
        # Your async implementation here
        await asyncio.sleep(1)
        return f"Processed {query} asynchronously"
```

### Using Async Tools

Async tools work seamlessly in both standard Crew workflows and Flow-based workflows:

```python Code
# In standard Crew
agent = Agent(role="researcher", tools=[async_custom_tool])

# In Flow
class MyFlow(Flow):
    @start()
    async def begin(self):
        crew = Crew(agents=[agent])
        result = await crew.kickoff_async()
        return result
```

The CrewAI framework automatically handles the execution of both synchronous and asynchronous tools, so you don't need to worry about how to call them differently.

### Utilizing the `tool` Decorator

```python Code
from crewai.tools import tool
@tool("Name of my tool")
def my_tool(question: str) -> str:
    """Clear description for what this tool is useful for, your agent will need this information to use it."""
    # Function logic here
    return "Result from your custom tool"
```

### Custom Caching Mechanism

<Tip>
  Tools can optionally implement a `cache_function` to fine-tune caching
  behavior. This function determines when to cache results based on specific
  conditions, offering granular control over caching logic.
</Tip>

```python Code
from crewai.tools import tool

@tool
def multiplication_tool(first_number: int, second_number: int) -> str:
    """Useful for when you need to multiply two numbers together."""
    return first_number * second_number

def cache_func(args, result):
    # In this case, we only cache the result if it's a multiple of 2
    cache = result % 2 == 0
    return cache

multiplication_tool.cache_function = cache_func

writer1 = Agent(
        role="Writer",
        goal="You write lessons of math for kids.",
        backstory="You're an expert in writing and you love to teach kids but you know nothing of math.",
        tools=[multiplication_tool],
        allow_delegation=False,
    )
    #...
```

## Conclusion

Tools are pivotal in extending the capabilities of CrewAI agents, enabling them to undertake a broad spectrum of tasks and collaborate effectively.
When building solutions with CrewAI, leverage both custom and existing tools to empower your agents and enhance the AI ecosystem. Consider utilizing error handling,
caching mechanisms, and the flexibility of tool arguments to optimize your agents' performance and capabilities.


# Training
Source: https://docs.crewai.com/en/concepts/training

Learn how to train your CrewAI agents by giving them feedback early on and get consistent results.

## Overview

The training feature in CrewAI allows you to train your AI agents using the command-line interface (CLI).
By running the command `crewai train -n <n_iterations>`, you can specify the number of iterations for the training process.

During training, CrewAI utilizes techniques to optimize the performance of your agents along with human feedback.
This helps the agents improve their understanding, decision-making, and problem-solving abilities.

### Training Your Crew Using the CLI

To use the training feature, follow these steps:

1. Open your terminal or command prompt.
2. Navigate to the directory where your CrewAI project is located.
3. Run the following command:

```shell
crewai train -n <n_iterations> <filename> (optional)
```

<Tip>
  Replace `<n_iterations>` with the desired number of training iterations and `<filename>` with the appropriate filename ending with `.pkl`.
</Tip>

### Training Your Crew Programmatically

To train your crew programmatically, use the following steps:

1. Define the number of iterations for training.
2. Specify the input parameters for the training process.
3. Execute the training command within a try-except block to handle potential errors.

```python Code
n_iterations = 2
inputs = {"topic": "CrewAI Training"}
filename = "your_model.pkl"

try:
    YourCrewName_Crew().crew().train(
      n_iterations=n_iterations,
      inputs=inputs,
      filename=filename
    )

except Exception as e:
    raise Exception(f"An error occurred while training the crew: {e}")
```

### Key Points to Note

* **Positive Integer Requirement:** Ensure that the number of iterations (`n_iterations`) is a positive integer. The code will raise a `ValueError` if this condition is not met.
* **Filename Requirement:** Ensure that the filename ends with `.pkl`. The code will raise a `ValueError` if this condition is not met.
* **Error Handling:** The code handles subprocess errors and unexpected exceptions, providing error messages to the user.

It is important to note that the training process may take some time, depending on the complexity of your agents and will also require your feedback on each iteration.

Once the training is complete, your agents will be equipped with enhanced capabilities and knowledge, ready to tackle complex tasks and provide more consistent and valuable insights.

Remember to regularly update and retrain your agents to ensure they stay up-to-date with the latest information and advancements in the field.

Happy training with CrewAI! 🚀

## Small Language Model Considerations

<Warning>
  When using smaller language models (≤7B parameters) for training data evaluation, be aware that they may face challenges with generating structured outputs and following complex instructions.
</Warning>

### Limitations of Small Models in Training Evaluation

<CardGroup cols={2}>
  <Card title="JSON Output Accuracy" icon="triangle-exclamation">
    Smaller models often struggle with producing valid JSON responses needed for structured training evaluations, leading to parsing errors and incomplete data.
  </Card>

  <Card title="Evaluation Quality" icon="chart-line">
    Models under 7B parameters may provide less nuanced evaluations with limited reasoning depth compared to larger models.
  </Card>

  <Card title="Instruction Following" icon="list-check">
    Complex training evaluation criteria may not be fully followed or considered by smaller models.
  </Card>

  <Card title="Consistency" icon="rotate">
    Evaluations across multiple training iterations may lack consistency with smaller models.
  </Card>
</CardGroup>

### Recommendations for Training

<Tabs>
  <Tab title="Best Practice">
    For optimal training quality and reliable evaluations, we strongly recommend using models with at least 7B parameters or larger:

    ```python
    from crewai import Agent, Crew, Task, LLM

    # Recommended minimum for training evaluation
    llm = LLM(model="mistral/open-mistral-7b")

    # Better options for reliable training evaluation
    llm = LLM(model="anthropic/claude-3-sonnet-20240229-v1:0")
    llm = LLM(model="gpt-4o")

    # Use this LLM with your agents
    agent = Agent(
        role="Training Evaluator",
        goal="Provide accurate training feedback",
        llm=llm
    )
    ```

    <Tip>
      More powerful models provide higher quality feedback with better reasoning, leading to more effective training iterations.
    </Tip>
  </Tab>

  <Tab title="Small Model Usage">
    If you must use smaller models for training evaluation, be aware of these constraints:

    ```python
    # Using a smaller model (expect some limitations)
    llm = LLM(model="huggingface/microsoft/Phi-3-mini-4k-instruct")
    ```

    <Warning>
      While CrewAI includes optimizations for small models, expect less reliable and less nuanced evaluation results that may require more human intervention during training.
    </Warning>
  </Tab>
</Tabs>


# Hallucination Guardrail
Source: https://docs.crewai.com/en/enterprise/features/hallucination-guardrail

Prevent and detect AI hallucinations in your CrewAI tasks

## Overview

The Hallucination Guardrail is an enterprise feature that validates AI-generated content to ensure it's grounded in facts and doesn't contain hallucinations. It analyzes task outputs against reference context and provides detailed feedback when potentially hallucinated content is detected.

## What are Hallucinations?

AI hallucinations occur when language models generate content that appears plausible but is factually incorrect or not supported by the provided context. The Hallucination Guardrail helps prevent these issues by:

* Comparing outputs against reference context
* Evaluating faithfulness to source material
* Providing detailed feedback on problematic content
* Supporting custom thresholds for validation strictness

## Basic Usage

### Setting Up the Guardrail

```python
from crewai.tasks.hallucination_guardrail import HallucinationGuardrail
from crewai import LLM

# Basic usage - will use task's expected_output as context
guardrail = HallucinationGuardrail(
    llm=LLM(model="gpt-4o-mini")
)

# With explicit reference context
context_guardrail = HallucinationGuardrail(
    context="AI helps with various tasks including analysis and generation.",
    llm=LLM(model="gpt-4o-mini")
)
```

### Adding to Tasks

```python
from crewai import Task

# Create your task with the guardrail
task = Task(
    description="Write a summary about AI capabilities",
    expected_output="A factual summary based on the provided context",
    agent=my_agent,
    guardrail=guardrail  # Add the guardrail to validate output
)
```

## Advanced Configuration

### Custom Threshold Validation

For stricter validation, you can set a custom faithfulness threshold (0-10 scale):

```python
# Strict guardrail requiring high faithfulness score
strict_guardrail = HallucinationGuardrail(
    context="Quantum computing uses qubits that exist in superposition states.",
    llm=LLM(model="gpt-4o-mini"),
    threshold=8.0  # Requires score >= 8 to pass validation
)
```

### Including Tool Response Context

When your task uses tools, you can include tool responses for more accurate validation:

```python
# Guardrail with tool response context
weather_guardrail = HallucinationGuardrail(
    context="Current weather information for the requested location",
    llm=LLM(model="gpt-4o-mini"),
    tool_response="Weather API returned: Temperature 22°C, Humidity 65%, Clear skies"
)
```

## How It Works

### Validation Process

1. **Context Analysis**: The guardrail compares task output against the provided reference context
2. **Faithfulness Scoring**: Uses an internal evaluator to assign a faithfulness score (0-10)
3. **Verdict Determination**: Determines if content is faithful or contains hallucinations
4. **Threshold Checking**: If a custom threshold is set, validates against that score
5. **Feedback Generation**: Provides detailed reasons when validation fails

### Validation Logic

* **Default Mode**: Uses verdict-based validation (FAITHFUL vs HALLUCINATED)
* **Threshold Mode**: Requires faithfulness score to meet or exceed the specified threshold
* **Error Handling**: Gracefully handles evaluation errors and provides informative feedback

## Guardrail Results

The guardrail returns structured results indicating validation status:

```python
# Example of guardrail result structure
{
    "valid": False,
    "feedback": "Content appears to be hallucinated (score: 4.2/10, verdict: HALLUCINATED). The output contains information not supported by the provided context."
}
```

### Result Properties

* **valid**: Boolean indicating whether the output passed validation
* **feedback**: Detailed explanation when validation fails, including:
  * Faithfulness score
  * Verdict classification
  * Specific reasons for failure

## Integration with Task System

### Automatic Validation

When a guardrail is added to a task, it automatically validates the output before the task is marked as complete:

```python
# Task output validation flow
task_output = agent.execute_task(task)
validation_result = guardrail(task_output)

if validation_result.valid:
    # Task completes successfully
    return task_output
else:
    # Task fails with validation feedback
    raise ValidationError(validation_result.feedback)
```

### Event Tracking

The guardrail integrates with CrewAI's event system to provide observability:

* **Validation Started**: When guardrail evaluation begins
* **Validation Completed**: When evaluation finishes with results
* **Validation Failed**: When technical errors occur during evaluation

## Best Practices

### Context Guidelines

<Steps>
  <Step title="Provide Comprehensive Context">
    Include all relevant factual information that the AI should base its output on:

    ```python
    context = """
    Company XYZ was founded in 2020 and specializes in renewable energy solutions.
    They have 150 employees and generated $50M revenue in 2023.
    Their main products include solar panels and wind turbines.
    """
    ```
  </Step>

  <Step title="Keep Context Relevant">
    Only include information directly related to the task to avoid confusion:

    ```python
    # Good: Focused context
    context = "The current weather in New York is 18°C with light rain."

    # Avoid: Unrelated information
    context = "The weather is 18°C. The city has 8 million people. Traffic is heavy."
    ```
  </Step>

  <Step title="Update Context Regularly">
    Ensure your reference context reflects current, accurate information.
  </Step>
</Steps>

### Threshold Selection

<Steps>
  <Step title="Start with Default Validation">
    Begin without custom thresholds to understand baseline performance.
  </Step>

  <Step title="Adjust Based on Requirements">
    * **High-stakes content**: Use threshold 8-10 for maximum accuracy
    * **General content**: Use threshold 6-7 for balanced validation
    * **Creative content**: Use threshold 4-5 or default verdict-based validation
  </Step>

  <Step title="Monitor and Iterate">
    Track validation results and adjust thresholds based on false positives/negatives.
  </Step>
</Steps>

## Performance Considerations

### Impact on Execution Time

* **Validation Overhead**: Each guardrail adds \~1-3 seconds per task
* **LLM Efficiency**: Choose efficient models for evaluation (e.g., gpt-4o-mini)

### Cost Optimization

* **Model Selection**: Use smaller, efficient models for guardrail evaluation
* **Context Size**: Keep reference context concise but comprehensive
* **Caching**: Consider caching validation results for repeated content

## Troubleshooting

<Accordion title="Validation Always Fails">
  **Possible Causes:**

  * Context is too restrictive or unrelated to task output
  * Threshold is set too high for the content type
  * Reference context contains outdated information

  **Solutions:**

  * Review and update context to match task requirements
  * Lower threshold or use default verdict-based validation
  * Ensure context is current and accurate
</Accordion>

<Accordion title="False Positives (Valid Content Marked Invalid)">
  **Possible Causes:**

  * Threshold too high for creative or interpretive tasks
  * Context doesn't cover all valid aspects of the output
  * Evaluation model being overly conservative

  **Solutions:**

  * Lower threshold or use default validation
  * Expand context to include broader acceptable content
  * Test with different evaluation models
</Accordion>

<Accordion title="Evaluation Errors">
  **Possible Causes:**

  * Network connectivity issues
  * LLM model unavailable or rate limited
  * Malformed task output or context

  **Solutions:**

  * Check network connectivity and LLM service status
  * Implement retry logic for transient failures
  * Validate task output format before guardrail evaluation
</Accordion>

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with hallucination guardrail configuration or troubleshooting.
</Card>


# Integrations
Source: https://docs.crewai.com/en/enterprise/features/integrations

Connected applications for your agents to take actions.

## Overview

Enable your agents to authenticate with any OAuth enabled provider and take actions. From Salesforce and HubSpot to Google and GitHub, we've got you covered with 16+ integrated services.

<Frame>
  ![Integrations](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew_connectors.png)
</Frame>

## Supported Integrations

### **Communication & Collaboration**

* **Gmail** - Manage emails and drafts
* **Slack** - Workspace notifications and alerts
* **Microsoft** - Office 365 and Teams integration

### **Project Management**

* **Jira** - Issue tracking and project management
* **ClickUp** - Task and productivity management
* **Asana** - Team task and project coordination
* **Notion** - Page and database management
* **Linear** - Software project and bug tracking
* **GitHub** - Repository and issue management

### **Customer Relationship Management**

* **Salesforce** - CRM account and opportunity management
* **HubSpot** - Sales pipeline and contact management
* **Zendesk** - Customer support ticket management

### **Business & Finance**

* **Stripe** - Payment processing and customer management
* **Shopify** - E-commerce store and product management

### **Productivity & Storage**

* **Google Sheets** - Spreadsheet data synchronization
* **Google Calendar** - Event and schedule management
* **Box** - File storage and document management

and more to come!

## Prerequisites

Before using Authentication Integrations, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account. You can get started with a free trial.

## Setting Up Integrations

### 1. Connect Your Account

1. Navigate to [CrewAI Enterprise](https://app.crewai.com)
2. Go to **Integrations** tab - [https://app.crewai.com/crewai\_plus/connectors](https://app.crewai.com/crewai_plus/connectors)
3. Click **Connect** on your desired service from the Authentication Integrations section
4. Complete the OAuth authentication flow
5. Grant necessary permissions for your use case
6. Get your Enterprise Token from your [CrewAI Enterprise](https://app.crewai.com) account page - [https://app.crewai.com/crewai\_plus/settings/account](https://app.crewai.com/crewai_plus/settings/account)

<Frame>
  ![Integrations](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/enterprise_action_auth_token.png)
</Frame>

### 2. Install Integration Tools

All you need is the latest version of `crewai-tools` package.

```bash
uv add crewai-tools
```

## Usage Examples

### Basic Usage

<Tip>
  All the services you are authenticated into will be available as tools. So all you need to do is add the `CrewaiEnterpriseTools` to your agent and you are good to go.
</Tip>

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Gmail tool will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)
# print the tools
print(enterprise_tools)

# Create an agent with Gmail capabilities
email_agent = Agent(
    role="Email Manager",
    goal="Manage and organize email communications",
    backstory="An AI assistant specialized in email management and communication.",
    tools=enterprise_tools
)

# Task to send an email
email_task = Task(
    description="Draft and send a follow-up email to john@example.com about the project update",
    agent=email_agent,
    expected_output="Confirmation that email was sent successfully"
)

# Run the task
crew = Crew(
    agents=[email_agent],
    tasks=[email_task]
)

# Run the crew
crew.kickoff()
```

### Filtering Tools

```python
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    actions_list=["gmail_find_email"] # only gmail_find_email tool will be available
)
gmail_tool = enterprise_tools["gmail_find_email"]

gmail_agent = Agent(
    role="Gmail Manager",
    goal="Manage gmail communications and notifications",
    backstory="An AI assistant that helps coordinate gmail communications.",
    tools=[gmail_tool]
)

notification_task = Task(
    description="Find the email from john@example.com",
    agent=gmail_agent,
    expected_output="Email found from john@example.com"
)

# Run the task
crew = Crew(
    agents=[slack_agent],
    tasks=[notification_task]
)
```

## Best Practices

### Security

* **Principle of Least Privilege**: Only grant the minimum permissions required for your agents' tasks
* **Regular Audits**: Periodically review connected integrations and their permissions
* **Secure Credentials**: Never hardcode credentials; use CrewAI's secure authentication flow

### Filtering Tools

On a deployed crew, you can specify which actions are avialbel for each integration from the settings page of the service you connected to.

<Frame>
  ![Integrations](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/filtering_enterprise_action_tools.png)
</Frame>

### Scoped Deployments for multi user organizations

You can deploy your crew and scope each integration to a specific user. For example, a crew that connects to google can use a specific user's gmail account.

<Tip>
  This is useful for multi user organizations where you want to scope the integration to a specific user.
</Tip>

Use the `user_bearer_token` to scope the integration to a specific user so that when the crew is kicked off, it will use the user's bearer token to authenticate with the integration. If user is not logged in, then the crew will not use any connected integrations. Use the default bearer token to authenticate with the integrations thats deployed with the crew.

<Frame>
  ![Integrations](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/user_bearer_token.png)
</Frame>

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with integration setup or troubleshooting.
</Card>


# Tool Repository
Source: https://docs.crewai.com/en/enterprise/features/tool-repository

Using the Tool Repository to manage your tools

## Overview

The Tool Repository is a package manager for CrewAI tools. It allows users to publish, install, and manage tools that integrate with CrewAI crews and flows.

Tools can be:

* **Private**: accessible only within your organization (default)
* **Public**: accessible to all CrewAI users if published with the `--public` flag

The repository is not a version control system. Use Git to track code changes and enable collaboration.

## Prerequisites

Before using the Tool Repository, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account
* [CrewAI CLI](https://docs.crewai.com/concepts/cli#cli) installed
* uv>=0.5.0 installed. Check out [how to upgrade](https://docs.astral.sh/uv/getting-started/installation/#upgrading-uv)
* [Git](https://git-scm.com) installed and configured
* Access permissions to publish or install tools in your CrewAI Enterprise organization

## Installing Tools

To install a tool:

```bash
crewai tool install <tool-name>
```

This installs the tool and adds it to `pyproject.toml`.

## Creating and Publishing Tools

To create a new tool project:

```bash
crewai tool create <tool-name>
```

This generates a scaffolded tool project locally.

After making changes, initialize a Git repository and commit the code:

```bash
git init
git add .
git commit -m "Initial version"
```

To publish the tool:

```bash
crewai tool publish
```

By default, tools are published as private. To make a tool public:

```bash
crewai tool publish --public
```

For more details on how to build tools, see [Creating your own tools](https://docs.crewai.com/concepts/tools#creating-your-own-tools).

## Updating Tools

To update a published tool:

1. Modify the tool locally
2. Update the version in `pyproject.toml` (e.g., from `0.1.0` to `0.1.1`)
3. Commit the changes and publish

```bash
git commit -m "Update version to 0.1.1"
crewai tool publish
```

## Deleting Tools

To delete a tool:

1. Go to [CrewAI Enterprise](https://app.crewai.com)
2. Navigate to **Tools**
3. Select the tool
4. Click **Delete**

<Warning>
  Deletion is permanent. Deleted tools cannot be restored or re-installed.
</Warning>

## Security Checks

Every published version undergoes automated security checks, and are only available to install after they pass.

You can check the security check status of a tool at:

`CrewAI Enterprise > Tools > Your Tool > Versions`

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with API integration or troubleshooting.
</Card>


# Traces
Source: https://docs.crewai.com/en/enterprise/features/traces

Using Traces to monitor your Crews

## Overview

Traces provide comprehensive visibility into your crew executions, helping you monitor performance, debug issues, and optimize your AI agent workflows.

## What are Traces?

Traces in CrewAI Enterprise are detailed execution records that capture every aspect of your crew's operation, from initial inputs to final outputs. They record:

* Agent thoughts and reasoning
* Task execution details
* Tool usage and outputs
* Token consumption metrics
* Execution times
* Cost estimates

<Frame>
  ![Traces Overview](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/traces-overview.png)
</Frame>

## Accessing Traces

<Steps>
  <Step title="Navigate to the Traces Tab">
    Once in your CrewAI Enterprise dashboard, click on the **Traces** to view all execution records.
  </Step>

  <Step title="Select an Execution">
    You'll see a list of all crew executions, sorted by date. Click on any execution to view its detailed trace.
  </Step>
</Steps>

## Understanding the Trace Interface

The trace interface is divided into several sections, each providing different insights into your crew's execution:

### 1. Execution Summary

The top section displays high-level metrics about the execution:

* **Total Tokens**: Number of tokens consumed across all tasks
* **Prompt Tokens**: Tokens used in prompts to the LLM
* **Completion Tokens**: Tokens generated in LLM responses
* **Requests**: Number of API calls made
* **Execution Time**: Total duration of the crew run
* **Estimated Cost**: Approximate cost based on token usage

<Frame>
  ![Execution Summary](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/trace-summary.png)
</Frame>

### 2. Tasks & Agents

This section shows all tasks and agents that were part of the crew execution:

* Task name and agent assignment
* Agents and LLMs used for each task
* Status (completed/failed)
* Individual execution time of the task

<Frame>
  ![Task List](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/trace-tasks.png)
</Frame>

### 3. Final Output

Displays the final result produced by the crew after all tasks are completed.

<Frame>
  ![Final Output](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/final-output.png)
</Frame>

### 4. Execution Timeline

A visual representation of when each task started and ended, helping you identify bottlenecks or parallel execution patterns.

<Frame>
  ![Execution Timeline](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/trace-timeline.png)
</Frame>

### 5. Detailed Task View

When you click on a specific task in the timeline or task list, you'll see:

<Frame>
  ![Detailed Task View](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/trace-detailed-task.png)
</Frame>

* **Task Key**: Unique identifier for the task
* **Task ID**: Technical identifier in the system
* **Status**: Current state (completed/running/failed)
* **Agent**: Which agent performed the task
* **LLM**: Language model used for this task
* **Start/End Time**: When the task began and completed
* **Execution Time**: Duration of this specific task
* **Task Description**: What the agent was instructed to do
* **Expected Output**: What output format was requested
* **Input**: Any input provided to this task from previous tasks
* **Output**: The actual result produced by the agent

## Using Traces for Debugging

Traces are invaluable for troubleshooting issues with your crews:

<Steps>
  <Step title="Identify Failure Points">
    When a crew execution doesn't produce the expected results, examine the trace to find where things went wrong. Look for:

    * Failed tasks
    * Unexpected agent decisions
    * Tool usage errors
    * Misinterpreted instructions

    <Frame>
      ![Failure Points](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/failure.png)
    </Frame>
  </Step>

  <Step title="Optimize Performance">
    Use execution metrics to identify performance bottlenecks:

    * Tasks that took longer than expected
    * Excessive token usage
    * Redundant tool operations
    * Unnecessary API calls
  </Step>

  <Step title="Improve Cost Efficiency">
    Analyze token usage and cost estimates to optimize your crew's efficiency:

    * Consider using smaller models for simpler tasks
    * Refine prompts to be more concise
    * Cache frequently accessed information
    * Structure tasks to minimize redundant operations
  </Step>
</Steps>

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with trace analysis or any other CrewAI Enterprise features.
</Card>


# Webhook Streaming
Source: https://docs.crewai.com/en/enterprise/features/webhook-streaming

Using Webhook Streaming to stream events to your webhook

## Overview

Enterprise Event Streaming lets you receive real-time webhook updates about your crews and flows deployed to
CrewAI Enterprise, such as model calls, tool usage, and flow steps.

## Usage

When using the Kickoff API, include a `webhooks` object to your request, for example:

```json
{
  "inputs": {"foo": "bar"},
  "webhooks": {
    "events": ["crew_kickoff_started", "llm_call_started"],
    "url": "https://your.endpoint/webhook",
    "realtime": false,
    "authentication": {
      "strategy": "bearer",
      "token": "my-secret-token"
    }
  }
}
```

If `realtime` is set to `true`, each event is delivered individually and immediately, at the cost of crew/flow performance.

## Webhook Format

Each webhook sends a list of events:

```json
{
  "events": [
    {
      "id": "event-id",
      "execution_id": "crew-run-id",
      "timestamp": "2025-02-16T10:58:44.965Z",
      "type": "llm_call_started",
      "data": {
        "model": "gpt-4",
        "messages": [
          {"role": "system", "content": "You are an assistant."},
          {"role": "user", "content": "Summarize this article."}
        ]
      }
    }
  ]
}
```

The `data` object structure varies by event type. Refer to the [event list](https://github.com/crewAIInc/crewAI/tree/main/src/crewai/utilities/events) on GitHub.

As requests are sent over HTTP, the order of events can't be guaranteed. If you need ordering, use the `timestamp` field.

## Supported Events

CrewAI supports both system events and custom events in Enterprise Event Streaming. These events are sent to your configured webhook endpoint during crew and flow execution.

* `crew_kickoff_started`
* `crew_step_started`
* `crew_step_completed`
* `crew_execution_completed`
* `llm_call_started`
* `llm_call_completed`
* `tool_usage_started`
* `tool_usage_completed`
* `crew_test_failed`
* *...and others*

Event names match the internal event bus. See [GitHub source](https://github.com/crewAIInc/crewAI/tree/main/src/crewai/utilities/events) for the full list.

You can emit your own custom events, and they will be delivered through the webhook stream alongside system events.

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with webhook integration or troubleshooting.
</Card>


# Azure OpenAI Setup
Source: https://docs.crewai.com/en/enterprise/guides/azure-openai-setup

Configure Azure OpenAI with Crew Studio for enterprise LLM connections

This guide walks you through connecting Azure OpenAI with Crew Studio for seamless enterprise AI operations.

## Setup Process

<Steps>
  <Step title="Access Azure OpenAI Studio">
    1. In Azure, go to `Azure AI Services > select your deployment > open Azure OpenAI Studio`.
    2. On the left menu, click `Deployments`. If you don't have one, create a deployment with your desired model.
    3. Once created, select your deployment and locate the `Target URI` and `Key` on the right side of the page. Keep this page open, as you'll need this information.
       <Frame>
         <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/azure-openai-studio.png" alt="Azure OpenAI Studio" />
       </Frame>
  </Step>

  <Step title="Configure CrewAI Enterprise Connection">
    4. In another tab, open `CrewAI Enterprise > LLM Connections`. Name your LLM Connection, select Azure as the provider, and choose the same model you selected in Azure.
    5. On the same page, add environment variables from step 3:
       * One named `AZURE_DEPLOYMENT_TARGET_URL` (using the Target URI). The URL should look like this: [https://your-deployment.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-08-01-preview](https://your-deployment.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-08-01-preview)
       * Another named `AZURE_API_KEY` (using the Key).
    6. Click `Add Connection` to save your LLM Connection.
  </Step>

  <Step title="Set Default Configuration">
    7. In `CrewAI Enterprise > Settings > Defaults > Crew Studio LLM Settings`, set the new LLM Connection and model as defaults.
  </Step>

  <Step title="Configure Network Access">
    8. Ensure network access settings:
       * In Azure, go to `Azure OpenAI > select your deployment`.
       * Navigate to `Resource Management > Networking`.
       * Ensure that `Allow access from all networks` is enabled. If this setting is restricted, CrewAI may be blocked from accessing your Azure OpenAI endpoint.
  </Step>
</Steps>

## Verification

You're all set! Crew Studio will now use your Azure OpenAI connection. Test the connection by creating a simple crew or task to ensure everything is working properly.

## Troubleshooting

If you encounter issues:

* Verify the Target URI format matches the expected pattern
* Check that the API key is correct and has proper permissions
* Ensure network access is configured to allow CrewAI connections
* Confirm the deployment model matches what you've configured in CrewAI


# Build Crew
Source: https://docs.crewai.com/en/enterprise/guides/build-crew

A Crew is a group of agents that work together to complete a task.

## Overview

[CrewAI Enterprise](https://app.crewai.com) streamlines the process of **creating**, **deploying**, and **managing** your AI agents in production environments.

## Getting Started

<iframe width="100%" height="400" src="https://www.youtube.com/embed/-kSOTtYzgEw" title="Building Crews with CrewAI CLI" frameborder="0" style={{ borderRadius: '10px' }} allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

### Installation and Setup

<Card title="Follow Standard Installation" icon="wrench" href="/en/installation">
  Follow our standard installation guide to set up CrewAI CLI and create your first project.
</Card>

### Building Your Crew

<Card title="Quickstart Tutorial" icon="rocket" href="/en/quickstart">
  Follow our quickstart guide to create your first agent crew using YAML configuration.
</Card>

## Support and Resources

For Enterprise-specific support or questions, contact our dedicated support team at [support@crewai.com](mailto:support@crewai.com).

<Card title="Schedule a Demo" icon="calendar" href="mailto:support@crewai.com">
  Book time with our team to learn more about Enterprise features and how they can benefit your organization.
</Card>


# Deploy Crew
Source: https://docs.crewai.com/en/enterprise/guides/deploy-crew

Deploying a Crew on CrewAI Enterprise

<Note>
  After creating a crew locally or through Crew Studio, the next step is deploying it to the CrewAI Enterprise platform. This guide covers multiple deployment methods to help you choose the best approach for your workflow.
</Note>

## Prerequisites

<CardGroup cols={2}>
  <Card title="Crew Ready for Deployment" icon="users">
    You should have a working crew either built locally or created through Crew Studio
  </Card>

  <Card title="GitHub Repository" icon="github">
    Your crew code should be in a GitHub repository (for GitHub integration method)
  </Card>
</CardGroup>

## Option 1: Deploy Using CrewAI CLI

The CLI provides the fastest way to deploy locally developed crews to the Enterprise platform.

<Steps>
  <Step title="Install CrewAI CLI">
    If you haven't already, install the CrewAI CLI:

    ```bash
    pip install crewai[tools]
    ```

    <Tip>
      The CLI comes with the main CrewAI package, but the `[tools]` extra ensures you have all deployment dependencies.
    </Tip>
  </Step>

  <Step title="Authenticate with the Enterprise Platform">
    First, you need to authenticate your CLI with the CrewAI Enterprise platform:

    ```bash
    # If you already have a CrewAI Enterprise account, or want to create one:
    crewai login
    ```

    When you run either command, the CLI will:

    1. Display a URL and a unique device code
    2. Open your browser to the authentication page
    3. Prompt you to confirm the device
    4. Complete the authentication process

    Upon successful authentication, you'll see a confirmation message in your terminal!
  </Step>

  <Step title="Create a Deployment">
    From your project directory, run:

    ```bash
    crewai deploy create
    ```

    This command will:

    1. Detect your GitHub repository information
    2. Identify environment variables in your local `.env` file
    3. Securely transfer these variables to the Enterprise platform
    4. Create a new deployment with a unique identifier

    On successful creation, you'll see a message like:

    ```shell
    Deployment created successfully!
    Name: your_project_name
    Deployment ID: 01234567-89ab-cdef-0123-456789abcdef
    Current Status: Deploy Enqueued
    ```
  </Step>

  <Step title="Monitor Deployment Progress">
    Track the deployment status with:

    ```bash
    crewai deploy status
    ```

    For detailed logs of the build process:

    ```bash
    crewai deploy logs
    ```

    <Tip>
      The first deployment typically takes 10-15 minutes as it builds the container images. Subsequent deployments are much faster.
    </Tip>
  </Step>
</Steps>

## Additional CLI Commands

The CrewAI CLI offers several commands to manage your deployments:

```bash
# List all your deployments
crewai deploy list

# Get the status of your deployment
crewai deploy status

# View the logs of your deployment
crewai deploy logs

# Push updates after code changes
crewai deploy push

# Remove a deployment
crewai deploy remove <deployment_id>
```

## Option 2: Deploy Directly via Web Interface

You can also deploy your crews directly through the CrewAI Enterprise web interface by connecting your GitHub account. This approach doesn't require using the CLI on your local machine.

<Steps>
  <Step title="Pushing to GitHub">
    You need to push your crew to a GitHub repository. If you haven't created a crew yet, you can [follow this tutorial](/en/quickstart).
  </Step>

  <Step title="Connecting GitHub to CrewAI Enterprise">
    1. Log in to [CrewAI Enterprise](https://app.crewai.com)
    2. Click on the button "Connect GitHub"

    <Frame>
      ![Connect GitHub Button](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/connect-github.png)
    </Frame>
  </Step>

  <Step title="Select the Repository">
    After connecting your GitHub account, you'll be able to select which repository to deploy:

    <Frame>
      ![Select Repository](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/select-repo.png)
    </Frame>
  </Step>

  <Step title="Set Environment Variables">
    Before deploying, you'll need to set up your environment variables to connect to your LLM provider or other services:

    1. You can add variables individually or in bulk
    2. Enter your environment variables in `KEY=VALUE` format (one per line)

    <Frame>
      ![Set Environment Variables](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/set-env-variables.png)
    </Frame>
  </Step>

  <Step title="Deploy Your Crew">
    1. Click the "Deploy" button to start the deployment process
    2. You can monitor the progress through the progress bar
    3. The first deployment typically takes around 10-15 minutes; subsequent deployments will be faster

    <Frame>
      ![Deploy Progress](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/deploy-progress.png)
    </Frame>

    Once deployment is complete, you'll see:

    * Your crew's unique URL
    * A Bearer token to protect your crew API
    * A "Delete" button if you need to remove the deployment
  </Step>
</Steps>

## ⚠️ Environment Variable Security Requirements

<Warning>
  **Important**: CrewAI Enterprise has security restrictions on environment variable names that can cause deployment failures if not followed.
</Warning>

### Blocked Environment Variable Patterns

For security reasons, the following environment variable naming patterns are **automatically filtered** and will cause deployment issues:

**Blocked Patterns:**

* Variables ending with `_TOKEN` (e.g., `MY_API_TOKEN`)
* Variables ending with `_PASSWORD` (e.g., `DB_PASSWORD`)
* Variables ending with `_SECRET` (e.g., `API_SECRET`)
* Variables ending with `_KEY` in certain contexts

**Specific Blocked Variables:**

* `GITHUB_USER`, `GITHUB_TOKEN`
* `AWS_REGION`, `AWS_DEFAULT_REGION`
* Various internal CrewAI system variables

### Allowed Exceptions

Some variables are explicitly allowed despite matching blocked patterns:

* `AZURE_AD_TOKEN`
* `AZURE_OPENAI_AD_TOKEN`
* `ENTERPRISE_ACTION_TOKEN`
* `CREWAI_ENTEPRISE_TOOLS_TOKEN`

### How to Fix Naming Issues

If your deployment fails due to environment variable restrictions:

```bash
# ❌ These will cause deployment failures
OPENAI_TOKEN=sk-...
DATABASE_PASSWORD=mypassword
API_SECRET=secret123

# ✅ Use these naming patterns instead
OPENAI_API_KEY=sk-...
DATABASE_CREDENTIALS=mypassword
API_CONFIG=secret123
```

### Best Practices

1. **Use standard naming conventions**: `PROVIDER_API_KEY` instead of `PROVIDER_TOKEN`
2. **Test locally first**: Ensure your crew works with the renamed variables
3. **Update your code**: Change any references to the old variable names
4. **Document changes**: Keep track of renamed variables for your team

<Tip>
  If you encounter deployment failures with cryptic environment variable errors, check your variable names against these patterns first.
</Tip>

### Interact with Your Deployed Crew

Once deployment is complete, you can access your crew through:

1. **REST API**: The platform generates a unique HTTPS endpoint with these key routes:
   * `/inputs`: Lists the required input parameters
   * `/kickoff`: Initiates an execution with provided inputs
   * `/status/{kickoff_id}`: Checks the execution status

2. **Web Interface**: Visit [app.crewai.com](https://app.crewai.com) to access:
   * **Status tab**: View deployment information, API endpoint details, and authentication token
   * **Run tab**: Visual representation of your crew's structure
   * **Executions tab**: History of all executions
   * **Metrics tab**: Performance analytics
   * **Traces tab**: Detailed execution insights

### Trigger an Execution

From the Enterprise dashboard, you can:

1. Click on your crew's name to open its details
2. Select "Trigger Crew" from the management interface
3. Enter the required inputs in the modal that appears
4. Monitor progress as the execution moves through the pipeline

### Monitoring and Analytics

The Enterprise platform provides comprehensive observability features:

* **Execution Management**: Track active and completed runs
* **Traces**: Detailed breakdowns of each execution
* **Metrics**: Token usage, execution times, and costs
* **Timeline View**: Visual representation of task sequences

### Advanced Features

The Enterprise platform also offers:

* **Environment Variables Management**: Securely store and manage API keys
* **LLM Connections**: Configure integrations with various LLM providers
* **Custom Tools Repository**: Create, share, and install tools
* **Crew Studio**: Build crews through a chat interface without writing code

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with deployment issues or questions about the Enterprise platform.
</Card>


# Enable Crew Studio
Source: https://docs.crewai.com/en/enterprise/guides/enable-crew-studio

Enabling Crew Studio on CrewAI Enterprise

<Tip>
  Crew Studio is a powerful **no-code/low-code** tool that allows you to quickly scaffold or build Crews through a conversational interface.
</Tip>

## What is Crew Studio?

Crew Studio is an innovative way to create AI agent crews without writing code.

<Frame>
  ![Crew Studio Interface](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-studio-interface.png)
</Frame>

With Crew Studio, you can:

* Chat with the Crew Assistant to describe your problem
* Automatically generate agents and tasks
* Select appropriate tools
* Configure necessary inputs
* Generate downloadable code for customization
* Deploy directly to the CrewAI Enterprise platform

## Configuration Steps

Before you can start using Crew Studio, you need to configure your LLM connections:

<Steps>
  <Step title="Set Up LLM Connection">
    Go to the **LLM Connections** tab in your CrewAI Enterprise dashboard and create a new LLM connection.

    <Note>
      Feel free to use any LLM provider you want that is supported by CrewAI.
    </Note>

    Configure your LLM connection:

    * Enter a `Connection Name` (e.g., `OpenAI`)
    * Select your model provider: `openai` or `azure`
    * Select models you'd like to use in your Studio-generated Crews
      * We recommend at least `gpt-4o`, `o1-mini`, and `gpt-4o-mini`
    * Add your API key as an environment variable:
      * For OpenAI: Add `OPENAI_API_KEY` with your API key
      * For Azure OpenAI: Refer to [this article](https://blog.crewai.com/configuring-azure-openai-with-crewai-a-comprehensive-guide/) for configuration details
    * Click `Add Connection` to save your configuration

    <Frame>
      ![LLM Connection Configuration](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/llm-connection-config.png)
    </Frame>
  </Step>

  <Step title="Verify Connection Added">
    Once you complete the setup, you'll see your new connection added to the list of available connections.

    <Frame>
      ![Connection Added](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/connection-added.png)
    </Frame>
  </Step>

  <Step title="Configure LLM Defaults">
    In the main menu, go to **Settings → Defaults** and configure the LLM Defaults settings:

    * Select default models for agents and other components
    * Set default configurations for Crew Studio

    Click `Save Settings` to apply your changes.

    <Frame>
      ![LLM Defaults Configuration](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/llm-defaults.png)
    </Frame>
  </Step>
</Steps>

## Using Crew Studio

Now that you've configured your LLM connection and default settings, you're ready to start using Crew Studio!

<Steps>
  <Step title="Access Studio">
    Navigate to the **Studio** section in your CrewAI Enterprise dashboard.
  </Step>

  <Step title="Start a Conversation">
    Start a conversation with the Crew Assistant by describing the problem you want to solve:

    ```md
    I need a crew that can research the latest AI developments and create a summary report.
    ```

    The Crew Assistant will ask clarifying questions to better understand your requirements.
  </Step>

  <Step title="Review Generated Crew">
    Review the generated crew configuration, including:

    * Agents and their roles
    * Tasks to be performed
    * Required inputs
    * Tools to be used

    This is your opportunity to refine the configuration before proceeding.
  </Step>

  <Step title="Deploy or Download">
    Once you're satisfied with the configuration, you can:

    * Download the generated code for local customization
    * Deploy the crew directly to the CrewAI Enterprise platform
    * Modify the configuration and regenerate the crew
  </Step>

  <Step title="Test Your Crew">
    After deployment, test your crew with sample inputs to ensure it performs as expected.
  </Step>
</Steps>

<Tip>
  For best results, provide clear, detailed descriptions of what you want your crew to accomplish. Include specific inputs and expected outputs in your description.
</Tip>

## Example Workflow

Here's a typical workflow for creating a crew with Crew Studio:

<Steps>
  <Step title="Describe Your Problem">
    Start by describing your problem:

    ```md
    I need a crew that can analyze financial news and provide investment recommendations
    ```
  </Step>

  <Step title="Answer Questions">
    Respond to clarifying questions from the Crew Assistant to refine your requirements.
  </Step>

  <Step title="Review the Plan">
    Review the generated crew plan, which might include:

    * A Research Agent to gather financial news
    * An Analysis Agent to interpret the data
    * A Recommendations Agent to provide investment advice
  </Step>

  <Step title="Approve or Modify">
    Approve the plan or request changes if necessary.
  </Step>

  <Step title="Download or Deploy">
    Download the code for customization or deploy directly to the platform.
  </Step>

  <Step title="Test and Refine">
    Test your crew with sample inputs and refine as needed.
  </Step>
</Steps>

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with Crew Studio or any other CrewAI Enterprise features.
</Card>


# HubSpot Trigger
Source: https://docs.crewai.com/en/enterprise/guides/hubspot-trigger

Trigger CrewAI crews directly from HubSpot Workflows

This guide provides a step-by-step process to set up HubSpot triggers for CrewAI Enterprise, enabling you to initiate crews directly from HubSpot Workflows.

## Prerequisites

* A CrewAI Enterprise account
* A HubSpot account with the [HubSpot Workflows](https://knowledge.hubspot.com/workflows/create-workflows) feature

## Setup Steps

<Steps>
  <Step title="Connect your HubSpot account with CrewAI Enterprise">
    * Log in to your `CrewAI Enterprise account > Triggers`
    * Select `HubSpot` from the list of available triggers
    * Choose the HubSpot account you want to connect with CrewAI Enterprise
    * Follow the on-screen prompts to authorize CrewAI Enterprise access to your HubSpot account
    * A confirmation message will appear once HubSpot is successfully connected with CrewAI Enterprise
  </Step>

  <Step title="Create a HubSpot Workflow">
    * Log in to your `HubSpot account > Automations > Workflows > New workflow`
    * Select the workflow type that fits your needs (e.g., Start from scratch)
    * In the workflow builder, click the Plus (+) icon to add a new action.
    * Choose `Integrated apps > CrewAI > Kickoff a Crew`.
    * Select the Crew you want to initiate.
    * Click `Save` to add the action to your workflow

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/hubspot-workflow-1.png" alt="HubSpot Workflow 1" />
    </Frame>
  </Step>

  <Step title="Use Crew results with other actions">
    * After the Kickoff a Crew step, click the Plus (+) icon to add a new action.
    * For example, to send an internal email notification, choose `Communications > Send internal email notification`
    * In the Body field, click `Insert data`, select `View properties or action outputs from > Action outputs > Crew Result` to include Crew data in the email
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/hubspot-workflow-2.png" alt="HubSpot Workflow 2" />
      </Frame>
    * Configure any additional actions as needed
    * Review your workflow steps to ensure everything is set up correctly
    * Activate the workflow
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/hubspot-workflow-3.png" alt="HubSpot Workflow 3" />
      </Frame>
  </Step>
</Steps>

## Additional Resources

For more detailed information on available actions and customization options, refer to the [HubSpot Workflows Documentation](https://knowledge.hubspot.com/workflows/create-workflows).


# HITL Workflows
Source: https://docs.crewai.com/en/enterprise/guides/human-in-the-loop

Learn how to implement Human-In-The-Loop workflows in CrewAI for enhanced decision-making

Human-In-The-Loop (HITL) is a powerful approach that combines artificial intelligence with human expertise to enhance decision-making and improve task outcomes. This guide shows you how to implement HITL within CrewAI.

## Setting Up HITL Workflows

<Steps>
  <Step title="Configure Your Task">
    Set up your task with human input enabled:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-human-input.png" alt="Crew Human Input" />
    </Frame>
  </Step>

  <Step title="Provide Webhook URL">
    When kicking off your crew, include a webhook URL for human input:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-webhook-url.png" alt="Crew Webhook URL" />
    </Frame>
  </Step>

  <Step title="Receive Webhook Notification">
    Once the crew completes the task requiring human input, you'll receive a webhook notification containing:

    * **Execution ID**
    * **Task ID**
    * **Task output**
  </Step>

  <Step title="Review Task Output">
    The system will pause in the `Pending Human Input` state. Review the task output carefully.
  </Step>

  <Step title="Submit Human Feedback">
    Call the resume endpoint of your crew with the following information:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-resume-endpoint.png" alt="Crew Resume Endpoint" />
    </Frame>

    <Warning>
      **Feedback Impact on Task Execution**:
      It's crucial to exercise care when providing feedback, as the entire feedback content will be incorporated as additional context for further task executions.
    </Warning>

    This means:

    * All information in your feedback becomes part of the task's context.
    * Irrelevant details may negatively influence it.
    * Concise, relevant feedback helps maintain task focus and efficiency.
    * Always review your feedback carefully before submission to ensure it contains only pertinent information that will positively guide the task's execution.
  </Step>

  <Step title="Handle Negative Feedback">
    If you provide negative feedback:

    * The crew will retry the task with added context from your feedback.
    * You'll receive another webhook notification for further review.
    * Repeat steps 4-6 until satisfied.
  </Step>

  <Step title="Execution Continuation">
    When you submit positive feedback, the execution will proceed to the next steps.
  </Step>
</Steps>

## Best Practices

* **Be Specific**: Provide clear, actionable feedback that directly addresses the task at hand
* **Stay Relevant**: Only include information that will help improve the task execution
* **Be Timely**: Respond to HITL prompts promptly to avoid workflow delays
* **Review Carefully**: Double-check your feedback before submitting to ensure accuracy

## Common Use Cases

HITL workflows are particularly valuable for:

* Quality assurance and validation
* Complex decision-making scenarios
* Sensitive or high-stakes operations
* Creative tasks requiring human judgment
* Compliance and regulatory reviews


# Kickoff Crew
Source: https://docs.crewai.com/en/enterprise/guides/kickoff-crew

Kickoff a Crew on CrewAI Enterprise

## Overview

Once you've deployed your crew to the CrewAI Enterprise platform, you can kickoff executions through the web interface or the API. This guide covers both approaches.

## Method 1: Using the Web Interface

### Step 1: Navigate to Your Deployed Crew

1. Log in to [CrewAI Enterprise](https://app.crewai.com)
2. Click on the crew name from your projects list
3. You'll be taken to the crew's detail page

<Frame>
  ![Crew Dashboard](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-dashboard.png)
</Frame>

### Step 2: Initiate Execution

From your crew's detail page, you have two options to kickoff an execution:

#### Option A: Quick Kickoff

1. Click the `Kickoff` link in the Test Endpoints section
2. Enter the required input parameters for your crew in the JSON editor
3. Click the `Send Request` button

<Frame>
  ![Kickoff Endpoint](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-endpoint.png)
</Frame>

#### Option B: Using the Visual Interface

1. Click the `Run` tab in the crew detail page
2. Enter the required inputs in the form fields
3. Click the `Run Crew` button

<Frame>
  ![Run Crew](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/run-crew.png)
</Frame>

### Step 3: Monitor Execution Progress

After initiating the execution:

1. You'll receive a response containing a `kickoff_id` - **copy this ID**
2. This ID is essential for tracking your execution

<Frame>
  ![Copy Task ID](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/copy-task-id.png)
</Frame>

### Step 4: Check Execution Status

To monitor the progress of your execution:

1. Click the "Status" endpoint in the Test Endpoints section
2. Paste the `kickoff_id` into the designated field
3. Click the "Get Status" button

<Frame>
  ![Get Status](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/get-status.png)
</Frame>

The status response will show:

* Current execution state (`running`, `completed`, etc.)
* Details about which tasks are in progress
* Any outputs produced so far

### Step 5: View Final Results

Once execution is complete:

1. The status will change to `completed`
2. You can view the full execution results and outputs
3. For a more detailed view, check the `Executions` tab in the crew detail page

## Method 2: Using the API

You can also kickoff crews programmatically using the CrewAI Enterprise REST API.

### Authentication

All API requests require a bearer token for authentication:

```bash
curl -H "Authorization: Bearer YOUR_CREW_TOKEN" https://your-crew-url.crewai.com
```

Your bearer token is available on the Status tab of your crew's detail page.

### Checking Crew Health

Before executing operations, you can verify that your crew is running properly:

```bash
curl -H "Authorization: Bearer YOUR_CREW_TOKEN" https://your-crew-url.crewai.com
```

A successful response will return a message indicating the crew is operational:

```
Healthy%
```

### Step 1: Retrieve Required Inputs

First, determine what inputs your crew requires:

```bash
curl -X GET \
  -H "Authorization: Bearer YOUR_CREW_TOKEN" \
  https://your-crew-url.crewai.com/inputs
```

The response will be a JSON object containing an array of required input parameters, for example:

```json
{"inputs":["topic","current_year"]}
```

This example shows that this particular crew requires two inputs: `topic` and `current_year`.

### Step 2: Kickoff Execution

Initiate execution by providing the required inputs:

```bash
curl -X POST \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_CREW_TOKEN" \
  -d '{"inputs": {"topic": "AI Agent Frameworks", "current_year": "2025"}}' \
  https://your-crew-url.crewai.com/kickoff
```

The response will include a `kickoff_id` that you'll need for tracking:

```json
{"kickoff_id":"abcd1234-5678-90ef-ghij-klmnopqrstuv"}
```

### Step 3: Check Execution Status

Monitor the execution progress using the kickoff\_id:

```bash
curl -X GET \
  -H "Authorization: Bearer YOUR_CREW_TOKEN" \
  https://your-crew-url.crewai.com/status/abcd1234-5678-90ef-ghij-klmnopqrstuv
```

## Handling Executions

### Long-Running Executions

For executions that may take a long time:

1. Consider implementing a polling mechanism to check status periodically
2. Use webhooks (if available) for notification when execution completes
3. Implement error handling for potential timeouts

### Execution Context

The execution context includes:

* Inputs provided at kickoff
* Environment variables configured during deployment
* Any state maintained between tasks

### Debugging Failed Executions

If an execution fails:

1. Check the "Executions" tab for detailed logs
2. Review the "Traces" tab for step-by-step execution details
3. Look for LLM responses and tool usage in the trace details

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with execution issues or questions about the Enterprise platform.
</Card>


# React Component Export
Source: https://docs.crewai.com/en/enterprise/guides/react-component-export

Learn how to export and integrate CrewAI Enterprise React components into your applications

This guide explains how to export CrewAI Enterprise crews as React components and integrate them into your own applications.

## Exporting a React Component

<Steps>
  <Step title="Export the Component">
    Click on the ellipsis (three dots on the right of your deployed crew) and select the export option and save the file locally. We will be using `CrewLead.jsx` for our example.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/export-react-component.png" alt="Export React Component" />
    </Frame>
  </Step>
</Steps>

## Setting Up Your React Environment

To run this React component locally, you'll need to set up a React development environment and integrate this component into a React project.

<Steps>
  <Step title="Install Node.js">
    * Download and install Node.js from the official website: [https://nodejs.org/](https://nodejs.org/)
    * Choose the LTS (Long Term Support) version for stability.
  </Step>

  <Step title="Create a new React project">
    * Open Command Prompt or PowerShell
    * Navigate to the directory where you want to create your project
    * Run the following command to create a new React project:

      ```bash
      npx create-react-app my-crew-app
      ```
    * Change into the project directory:

      ```bash
      cd my-crew-app
      ```
  </Step>

  <Step title="Install necessary dependencies">
    ```bash
    npm install react-dom
    ```
  </Step>

  <Step title="Create the CrewLead component">
    * Move the downloaded file `CrewLead.jsx` into the `src` folder of your project,
  </Step>

  <Step title="Modify your App.js to use the CrewLead component">
    * Open `src/App.js`
    * Replace its contents with something like this:

    ```jsx
    import React from 'react';
    import CrewLead from './CrewLead';

    function App() {
        return (
            <div className="App">
                <CrewLead baseUrl="YOUR_API_BASE_URL" bearerToken="YOUR_BEARER_TOKEN" />
            </div>
        );
    }

    export default App;
    ```

    * Replace `YOUR_API_BASE_URL` and `YOUR_BEARER_TOKEN` with the actual values for your API.
  </Step>

  <Step title="Start the development server">
    * In your project directory, run:

      ```bash
      npm start
      ```
    * This will start the development server, and your default web browser should open automatically to [http://localhost:3000](http://localhost:3000), where you'll see your React app running.
  </Step>
</Steps>

## Customization

You can then customise the `CrewLead.jsx` to add color, title etc

<Frame>
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/customise-react-component.png" alt="Customise React Component" />
</Frame>

<Frame>
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/customise-react-component-2.png" alt="Customise React Component" />
</Frame>

## Next Steps

* Customize the component styling to match your application's design
* Add additional props for configuration
* Integrate with your application's state management
* Add error handling and loading states


# Salesforce Trigger
Source: https://docs.crewai.com/en/enterprise/guides/salesforce-trigger

Trigger CrewAI crews from Salesforce workflows for CRM automation

CrewAI Enterprise can be triggered from Salesforce to automate customer relationship management workflows and enhance your sales operations.

## Overview

Salesforce is a leading customer relationship management (CRM) platform that helps businesses streamline their sales, service, and marketing operations. By setting up CrewAI triggers from Salesforce, you can:

* Automate lead scoring and qualification
* Generate personalized sales materials
* Enhance customer service with AI-powered responses
* Streamline data analysis and reporting

## Demo

<Frame>
  <iframe width="100%" height="400" src="https://www.youtube.com/embed/oJunVqjjfu4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />
</Frame>

## Getting Started

To set up Salesforce triggers:

1. **Contact Support**: Reach out to CrewAI Enterprise support for assistance with Salesforce trigger setup
2. **Review Requirements**: Ensure you have the necessary Salesforce permissions and API access
3. **Configure Connection**: Work with the support team to establish the connection between CrewAI and your Salesforce instance
4. **Test Triggers**: Verify the triggers work correctly with your specific use cases

## Use Cases

Common Salesforce + CrewAI trigger scenarios include:

* **Lead Processing**: Automatically analyze and score incoming leads
* **Proposal Generation**: Create customized proposals based on opportunity data
* **Customer Insights**: Generate analysis reports from customer interaction history
* **Follow-up Automation**: Create personalized follow-up messages and recommendations

## Next Steps

For detailed setup instructions and advanced configuration options, please contact CrewAI Enterprise support who can provide tailored guidance for your specific Salesforce environment and business needs.


# Slack Trigger
Source: https://docs.crewai.com/en/enterprise/guides/slack-trigger

Trigger CrewAI crews directly from Slack using slash commands

This guide explains how to start a crew directly from Slack using CrewAI triggers.

## Prerequisites

* CrewAI Slack trigger installed and connected to your Slack workspace
* At least one crew configured in CrewAI

## Setup Steps

<Steps>
  <Step title="Ensure the CrewAI Slack trigger is set up">
    In the CrewAI dashboard, navigate to the **Triggers** section.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/slack-integration.png" alt="CrewAI Slack Integration" />
    </Frame>

    Verify that Slack is listed and is connected.
  </Step>

  <Step title="Open your Slack channel">
    * Navigate to the channel where you want to kickoff the crew.
    * Type the slash command "**/kickoff**" to initiate the crew kickoff process.
    * You should see a  "**Kickoff crew**" appear as you type:
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-slack-crew.png" alt="Kickoff crew" />
      </Frame>
    * Press Enter or select the "**Kickoff crew**" option. A dialog box titled "**Kickoff an AI Crew**" will appear.
  </Step>

  <Step title="Select the crew you want to start">
    * In the dropdown menu labeled "**Select of the crews online:**", choose the crew you want to start.
    * In the example below, "**prep-for-meeting**" is selected:
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-slack-crew-dropdown.png" alt="Kickoff crew dropdown" />
      </Frame>
    * If your crew requires any inputs, click the "**Add Inputs**" button to provide them.
      <Note>
        The "**Add Inputs**" button is shown in the example above but is not yet clicked.
      </Note>
  </Step>

  <Step title="Click Kickoff and wait for the crew to complete">
    * Once you've selected the crew and added any necessary inputs, click "**Kickoff**" to start the crew.
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-slack-crew-kickoff.png" alt="Kickoff crew" />
      </Frame>
    * The crew will start executing and you will see the results in the Slack channel.
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-slack-crew-results.png" alt="Kickoff crew results" />
      </Frame>
  </Step>
</Steps>

## Tips

* Make sure you have the necessary permissions to use the `/kickoff` command in your Slack workspace.
* If you don't see your desired crew in the dropdown, ensure it's properly configured and online in CrewAI.


# Team Management
Source: https://docs.crewai.com/en/enterprise/guides/team-management

Learn how to invite and manage team members in your CrewAI Enterprise organization

As an administrator of a CrewAI Enterprise account, you can easily invite new team members to join your organization. This guide will walk you through the process step-by-step.

## Inviting Team Members

<Steps>
  <Step title="Access the Settings Page">
    * Log in to your CrewAI Enterprise account
    * Look for the gear icon (⚙️) in the top right corner of the dashboard
    * Click on the gear icon to access the **Settings** page:
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/settings-page.png" alt="Settings Page" />
      </Frame>
  </Step>

  <Step title="Navigate to the Members Section">
    * On the Settings page, you'll see a `Members` tab
    * Click on the `Members` tab to access the **Members** page:
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/members-tab.png" alt="Members Tab" />
      </Frame>
  </Step>

  <Step title="Invite New Members">
    * In the Members section, you'll see a list of current members (including yourself)
    * Locate the `Email` input field
    * Enter the email address of the person you want to invite
    * Click the `Invite` button to send the invitation
  </Step>

  <Step title="Repeat as Needed">
    * You can repeat this process to invite multiple team members
    * Each invited member will receive an email invitation to join your organization
  </Step>
</Steps>

## Adding Roles

You can add roles to your team members to control their access to different parts of the platform.

<Steps>
  <Step title="Access the Settings Page">
    * Log in to your CrewAI Enterprise account
    * Look for the gear icon (⚙️) in the top right corner of the dashboard
    * Click on the gear icon to access the **Settings** page:
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/settings-page.png" alt="Settings Page" />
      </Frame>
  </Step>

  <Step title="Navigate to the Members Section">
    * On the Settings page, you'll see a `Roles` tab
    * Click on the `Roles` tab to access the **Roles** page.
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/roles-tab.png" alt="Roles Tab" />
      </Frame>
    * Click on the `Add Role` button to add a new role.
    * Enter the details and permissions of the role and click the `Create Role` button to create the role.
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/add-role-modal.png" alt="Add Role Modal" />
      </Frame>
  </Step>

  <Step title="Add Roles to Members">
    * In the Members section, you'll see a list of current members (including yourself)
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/member-accepted-invitation.png" alt="Member Accepted Invitation" />
      </Frame>
    * Once the member has accepted the invitation, you can add a role to them.
    * Navigate back to `Roles` tab
    * Go to the member you want to add a role to and under the `Role` column, click on the dropdown
    * Select the role you want to add to the member
    * Click the `Update` button to save the role
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/assign-role.png" alt="Add Role to Member" />
      </Frame>
  </Step>
</Steps>

## Important Notes

* **Admin Privileges**: Only users with administrative privileges can invite new members
* **Email Accuracy**: Ensure you have the correct email addresses for your team members
* **Invitation Acceptance**: Invited members will need to accept the invitation to join your organization
* **Email Notifications**: You may want to inform your team members to check their email (including spam folders) for the invitation

By following these steps, you can easily expand your team and collaborate more effectively within your CrewAI Enterprise organization.


# Update Crew
Source: https://docs.crewai.com/en/enterprise/guides/update-crew

Updating a Crew on CrewAI Enterprise

<Note>
  After deploying your crew to CrewAI Enterprise, you may need to make updates to the code, security settings, or configuration.
  This guide explains how to perform these common update operations.
</Note>

## Why Update Your Crew?

CrewAI won't automatically pick up GitHub updates by default, so you'll need to manually trigger updates, unless you checked the `Auto-update` option when deploying your crew.

There are several reasons you might want to update your crew deployment:

* You want to update the code with a latest commit you pushed to GitHub
* You want to reset the bearer token for security reasons
* You want to update environment variables

## 1. Updating Your Crew Code for a Latest Commit

When you've pushed new commits to your GitHub repository and want to update your deployment:

1. Navigate to your crew in the CrewAI Enterprise platform
2. Click on the `Re-deploy` button on your crew details page

<Frame>
  ![Re-deploy Button](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/redeploy-button.png)
</Frame>

This will trigger an update that you can track using the progress bar. The system will pull the latest code from your repository and rebuild your deployment.

## 2. Resetting Bearer Token

If you need to generate a new bearer token (for example, if you suspect the current token might have been compromised):

1. Navigate to your crew in the CrewAI Enterprise platform
2. Find the `Bearer Token` section
3. Click the `Reset` button next to your current token

<Frame>
  ![Reset Token](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/reset-token.png)
</Frame>

<Warning>
  Resetting your bearer token will invalidate the previous token immediately. Make sure to update any applications or scripts that are using the old token.
</Warning>

## 3. Updating Environment Variables

To update the environment variables for your crew:

1. First access the deployment page by clicking on your crew's name

<Frame>
  ![Environment Variables Button](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/env-vars-button.png)
</Frame>

2. Locate the `Environment Variables` section (you will need to click the `Settings` icon to access it)
3. Edit the existing variables or add new ones in the fields provided
4. Click the `Update` button next to each variable you modify

<Frame>
  ![Update Environment Variables](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/update-env-vars.png)
</Frame>

5. Finally, click the `Update Deployment` button at the bottom of the page to apply the changes

<Note>
  Updating environment variables will trigger a new deployment, but this will only update the environment configuration and not the code itself.
</Note>

## After Updating

After performing any update:

1. The system will rebuild and redeploy your crew
2. You can monitor the deployment progress in real-time
3. Once complete, test your crew to ensure the changes are working as expected

<Tip>
  If you encounter any issues after updating, you can view deployment logs in the platform or contact support for assistance.
</Tip>

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with updating your crew or troubleshooting deployment issues.
</Card>


# Webhook Automation
Source: https://docs.crewai.com/en/enterprise/guides/webhook-automation

Automate CrewAI Enterprise workflows using webhooks with platforms like ActivePieces, Zapier, and Make.com

CrewAI Enterprise allows you to automate your workflow using webhooks. This article will guide you through the process of setting up and using webhooks to kickoff your crew execution, with a focus on integration with ActivePieces, a workflow automation platform similar to Zapier and Make.com.

## Setting Up Webhooks

<Steps>
  <Step title="Accessing the Kickoff Interface">
    * Navigate to the CrewAI Enterprise dashboard
    * Look for the `/kickoff` section, which is used to start the crew execution
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-interface.png" alt="Kickoff Interface" />
      </Frame>
  </Step>

  <Step title="Configuring the JSON Content">
    In the JSON Content section, you'll need to provide the following information:

    * **inputs**: A JSON object containing:
      * `company`: The name of the company (e.g., "tesla")
      * `product_name`: The name of the product (e.g., "crewai")
      * `form_response`: The type of response (e.g., "financial")
      * `icp_description`: A brief description of the Ideal Customer Profile
      * `product_description`: A short description of the product
      * `taskWebhookUrl`, `stepWebhookUrl`, `crewWebhookUrl`: URLs for various webhook endpoints (ActivePieces, Zapier, Make.com or another compatible platform)
  </Step>

  <Step title="Integrating with ActivePieces">
    In this example we will be using ActivePieces. You can use other platforms such as Zapier and Make.com

    To integrate with ActivePieces:

    1. Set up a new flow in ActivePieces

    2. Add a trigger (e.g., `Every Day` schedule)
       <Frame>
         <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-trigger.png" alt="ActivePieces Trigger" />
       </Frame>

    3. Add an HTTP action step
       * Set the action to `Send HTTP request`

       * Use `POST` as the method

       * Set the URL to your CrewAI Enterprise kickoff endpoint

       * Add necessary headers (e.g., `Bearer Token`)
         <Frame>
           <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-headers.png" alt="ActivePieces Headers" />
         </Frame>

       * In the body, include the JSON content as configured in step 2
         <Frame>
           <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-body.png" alt="ActivePieces Body" />
         </Frame>

       * The crew will then kickoff at the pre-defined time.
  </Step>

  <Step title="Setting Up the Webhook">
    1. Create a new flow in ActivePieces and name it
       <Frame>
         <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-flow.png" alt="ActivePieces Flow" />
       </Frame>

    2. Add a webhook step as the trigger:
       * Select `Catch Webhook` as the trigger type

       * This will generate a unique URL that will receive HTTP requests and trigger your flow
         <Frame>
           <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-webhook.png" alt="ActivePieces Webhook" />
         </Frame>

       * Configure the email to use crew webhook body text
         <Frame>
           <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-email.png" alt="ActivePieces Email" />
         </Frame>
  </Step>
</Steps>

## Webhook Output Examples

<Tabs>
  <Tab title="Step Webhook">
    `stepWebhookUrl` - Callback that will be executed upon each agent inner thought

    ```json
    {
        "action": "**Preliminary Research Report on the Financial Industry for crewai Enterprise Solution**\n1. Industry Overview and Trends\nThe financial industry in ....\nConclusion:\nThe financial industry presents a fertile ground for implementing AI solutions like crewai, particularly in areas such as digital customer engagement, risk management, and regulatory compliance. Further engagement with the lead is recommended to better tailor the crewai solution to their specific needs and scale.",
        "task_id": "97eba64f-958c-40a0-b61c-625fe635a3c0"
    }
    ```
  </Tab>

  <Tab title="Task Webhook">
    `taskWebhookUrl` - Callback that will be executed upon the end of each task

    ```json
    {
        "description": "Using the information gathered from the lead's data, conduct preliminary research on the lead's industry, company background, and potential use cases for crewai. Focus on finding relevant data that can aid in scoring the lead and planning a strategy to pitch them crewai.The financial industry presents a fertile ground for implementing AI solutions like crewai, particularly in areas such as digital customer engagement, risk management, and regulatory compliance. Further engagement with the lead is recommended to better tailor the crewai solution to their specific needs and scale.",
        "task_id": "97eba64f-958c-40a0-b61c-625fe635a3c0"
    }
    ```
  </Tab>

  <Tab title="Crew Webhook">
    `crewWebhookUrl` - Callback that will be executed upon the end of the crew execution

    ```json
    {
        "task_id": "97eba64f-958c-40a0-b61c-625fe635a3c0",
        "result": {
            "lead_score": "Customer service enhancement, and compliance are particularly relevant.",
            "talking_points": [
                "Highlight how crewai's AI solutions can transform customer service with automated, personalized experiences and 24/7 support, improving both customer satisfaction and operational efficiency.",
                "Discuss crewai's potential to help the institution achieve its sustainability goals through better data analysis and decision-making, contributing to responsible investing and green initiatives.",
                "Emphasize crewai's ability to enhance compliance with evolving regulations through efficient data processing and reporting, reducing the risk of non-compliance penalties.",
                "Stress the adaptability of crewai to support both extensive multinational operations and smaller, targeted projects, ensuring the solution grows with the institution's needs."
            ]
        }
    }
    ```
  </Tab>
</Tabs>


# Zapier Trigger
Source: https://docs.crewai.com/en/enterprise/guides/zapier-trigger

Trigger CrewAI crews from Zapier workflows to automate cross-app workflows

This guide will walk you through the process of setting up Zapier triggers for CrewAI Enterprise, allowing you to automate workflows between CrewAI Enterprise and other applications.

## Prerequisites

* A CrewAI Enterprise account
* A Zapier account
* A Slack account (for this specific example)

## Step-by-Step Setup

<Steps>
  <Step title="Set Up the Slack Trigger">
    * In Zapier, create a new Zap.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-1.png" alt="Zapier 1" />
    </Frame>
  </Step>

  <Step title="Choose Slack as your trigger app">
    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-2.png" alt="Zapier 2" />
    </Frame>

    * Select `New Pushed Message` as the Trigger Event.
    * Connect your Slack account if you haven't already.
  </Step>

  <Step title="Configure the CrewAI Enterprise Action">
    * Add a new action step to your Zap.
    * Choose CrewAI+ as your action app and Kickoff as the Action Event

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-3.png" alt="Zapier 5" />
    </Frame>
  </Step>

  <Step title="Connect your CrewAI Enterprise account">
    * Connect your CrewAI Enterprise account.
    * Select the appropriate Crew for your workflow.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-4.png" alt="Zapier 6" />
    </Frame>

    * Configure the inputs for the Crew using the data from the Slack message.
  </Step>

  <Step title="Format the CrewAI Enterprise Output">
    * Add another action step to format the text output from CrewAI Enterprise.
    * Use Zapier's formatting tools to convert the Markdown output to HTML.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-5.png" alt="Zapier 8" />
    </Frame>

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-6.png" alt="Zapier 9" />
    </Frame>
  </Step>

  <Step title="Send the Output via Email">
    * Add a final action step to send the formatted output via email.
    * Choose your preferred email service (e.g., Gmail, Outlook).
    * Configure the email details, including recipient, subject, and body.
    * Insert the formatted CrewAI Enterprise output into the email body.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-7.png" alt="Zapier 7" />
    </Frame>
  </Step>

  <Step title="Kick Off the crew from Slack">
    * Enter the text in your Slack channel

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-7b.png" alt="Zapier 10" />
    </Frame>

    * Select the 3 ellipsis button and then chose Push to Zapier

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-8.png" alt="Zapier 11" />
    </Frame>
  </Step>

  <Step title="Select the crew and then Push to Kick Off">
    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-9.png" alt="Zapier 12" />
    </Frame>
  </Step>
</Steps>

## Tips for Success

* Ensure that your CrewAI Enterprise inputs are correctly mapped from the Slack message.
* Test your Zap thoroughly before turning it on to catch any potential issues.
* Consider adding error handling steps to manage potential failures in the workflow.

By following these steps, you'll have successfully set up Zapier triggers for CrewAI Enterprise, allowing for automated workflows triggered by Slack messages and resulting in email notifications with CrewAI Enterprise output.


# Asana Integration
Source: https://docs.crewai.com/en/enterprise/integrations/asana

Team task and project coordination with Asana integration for CrewAI.

## Overview

Enable your agents to manage tasks, projects, and team coordination through Asana. Create tasks, update project status, manage assignments, and streamline your team's workflow with AI-powered automation.

## Prerequisites

Before using the Asana integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* An Asana account with appropriate permissions
* Connected your Asana account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors)

## Setting Up Asana Integration

### 1. Connect Your Asana Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors)
2. Find **Asana** in the Authentication Integrations section
3. Click **Connect** and complete the OAuth flow
4. Grant the necessary permissions for task and project management
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account)

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="ASANA_CREATE_COMMENT">
    **Description:** Create a comment in Asana.

    **Parameters:**

    * `task` (string, required): Task ID - The ID of the Task the comment will be added to. The comment will be authored by the currently authenticated user.
    * `text` (string, required): Text (example: "This is a comment.").
  </Accordion>

  <Accordion title="ASANA_CREATE_PROJECT">
    **Description:** Create a project in Asana.

    **Parameters:**

    * `name` (string, required): Name (example: "Stuff to buy").
    * `workspace` (string, required): Workspace - Use Connect Portal Workflow Settings to allow users to select which Workspace to create Projects in. Defaults to the user's first Workspace if left blank.
    * `team` (string, optional): Team - Use Connect Portal Workflow Settings to allow users to select which Team to share this Project with. Defaults to the user's first Team if left blank.
    * `notes` (string, optional): Notes (example: "These are things we need to purchase.").
  </Accordion>

  <Accordion title="ASANA_GET_PROJECTS">
    **Description:** Get a list of projects in Asana.

    **Parameters:**

    * `archived` (string, optional): Archived - Choose "true" to show archived projects, "false" to display only active projects, or "default" to show both archived and active projects.
      * Options: `default`, `true`, `false`
  </Accordion>

  <Accordion title="ASANA_GET_PROJECT_BY_ID">
    **Description:** Get a project by ID in Asana.

    **Parameters:**

    * `projectFilterId` (string, required): Project ID.
  </Accordion>

  <Accordion title="ASANA_CREATE_TASK">
    **Description:** Create a task in Asana.

    **Parameters:**

    * `name` (string, required): Name (example: "Task Name").
    * `workspace` (string, optional): Workspace - Use Connect Portal Workflow Settings to allow users to select which Workspace to create Tasks in. Defaults to the user's first Workspace if left blank..
    * `project` (string, optional): Project - Use Connect Portal Workflow Settings to allow users to select which Project to create this Task in.
    * `notes` (string, optional): Notes.
    * `dueOnDate` (string, optional): Due On - The date on which this task is due. Cannot be used together with Due At. (example: "YYYY-MM-DD").
    * `dueAtDate` (string, optional): Due At - The date and time (ISO timestamp) at which this task is due. Cannot be used together with Due On. (example: "2019-09-15T02:06:58.147Z").
    * `assignee` (string, optional): Assignee - The ID of the Asana user this task will be assigned to. Use Connect Portal Workflow Settings to allow users to select an Assignee.
    * `gid` (string, optional): External ID - An ID from your application to associate this task with. You can use this ID to sync updates to this task later.
  </Accordion>

  <Accordion title="ASANA_UPDATE_TASK">
    **Description:** Update a task in Asana.

    **Parameters:**

    * `taskId` (string, required): Task ID - The ID of the Task that will be updated.
    * `completeStatus` (string, optional): Completed Status.
      * Options: `true`, `false`
    * `name` (string, optional): Name (example: "Task Name").
    * `notes` (string, optional): Notes.
    * `dueOnDate` (string, optional): Due On - The date on which this task is due. Cannot be used together with Due At. (example: "YYYY-MM-DD").
    * `dueAtDate` (string, optional): Due At - The date and time (ISO timestamp) at which this task is due. Cannot be used together with Due On. (example: "2019-09-15T02:06:58.147Z").
    * `assignee` (string, optional): Assignee - The ID of the Asana user this task will be assigned to. Use Connect Portal Workflow Settings to allow users to select an Assignee.
    * `gid` (string, optional): External ID - An ID from your application to associate this task with. You can use this ID to sync updates to this task later.
  </Accordion>

  <Accordion title="ASANA_GET_TASKS">
    **Description:** Get a list of tasks in Asana.

    **Parameters:**

    * `workspace` (string, optional): Workspace - The ID of the Workspace to filter tasks on. Use Connect Portal Workflow Settings to allow users to select a Workspace.
    * `project` (string, optional): Project - The ID of the Project to filter tasks on. Use Connect Portal Workflow Settings to allow users to select a Project.
    * `assignee` (string, optional): Assignee - The ID of the assignee to filter tasks on. Use Connect Portal Workflow Settings to allow users to select an Assignee.
    * `completedSince` (string, optional): Completed since - Only return tasks that are either incomplete or that have been completed since this time (ISO or Unix timestamp). (example: "2014-04-25T16:15:47-04:00").
  </Accordion>

  <Accordion title="ASANA_GET_TASKS_BY_ID">
    **Description:** Get a list of tasks by ID in Asana.

    **Parameters:**

    * `taskId` (string, required): Task ID.
  </Accordion>

  <Accordion title="ASANA_GET_TASK_BY_EXTERNAL_ID">
    **Description:** Get a task by external ID in Asana.

    **Parameters:**

    * `gid` (string, required): External ID - The ID that this task is associated or synced with, from your application.
  </Accordion>

  <Accordion title="ASANA_ADD_TASK_TO_SECTION">
    **Description:** Add a task to a section in Asana.

    **Parameters:**

    * `sectionId` (string, required): Section ID - The ID of the section to add this task to.
    * `taskId` (string, required): Task ID - The ID of the task. (example: "1204619611402340").
    * `beforeTaskId` (string, optional): Before Task ID - The ID of a task in this section that this task will be inserted before. Cannot be used with After Task ID. (example: "1204619611402340").
    * `afterTaskId` (string, optional): After Task ID - The ID of a task in this section that this task will be inserted after. Cannot be used with Before Task ID. (example: "1204619611402340").
  </Accordion>

  <Accordion title="ASANA_GET_TEAMS">
    **Description:** Get a list of teams in Asana.

    **Parameters:**

    * `workspace` (string, required): Workspace - Returns the teams in this workspace visible to the authorized user.
  </Accordion>

  <Accordion title="ASANA_GET_WORKSPACES">
    **Description:** Get a list of workspaces in Asana.

    **Parameters:** None required.
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Asana Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Asana tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Asana capabilities
asana_agent = Agent(
    role="Project Manager",
    goal="Manage tasks and projects in Asana efficiently",
    backstory="An AI assistant specialized in project management and task coordination.",
    tools=[enterprise_tools]
)

# Task to create a new project
create_project_task = Task(
    description="Create a new project called 'Q1 Marketing Campaign' in the Marketing workspace",
    agent=asana_agent,
    expected_output="Confirmation that the project was created successfully with project ID"
)

# Run the task
crew = Crew(
    agents=[asana_agent],
    tasks=[create_project_task]
)

crew.kickoff()
```

### Filtering Specific Asana Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Asana tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["asana_create_task", "asana_update_task", "asana_get_tasks"]
)

task_manager_agent = Agent(
    role="Task Manager",
    goal="Create and manage tasks efficiently",
    backstory="An AI assistant that focuses on task creation and management.",
    tools=enterprise_tools
)

# Task to create and assign a task
task_management = Task(
    description="Create a task called 'Review quarterly reports' and assign it to the appropriate team member",
    agent=task_manager_agent,
    expected_output="Task created and assigned successfully"
)

crew = Crew(
    agents=[task_manager_agent],
    tasks=[task_management]
)

crew.kickoff()
```

### Advanced Project Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

project_coordinator = Agent(
    role="Project Coordinator",
    goal="Coordinate project activities and track progress",
    backstory="An experienced project coordinator who ensures projects run smoothly.",
    tools=[enterprise_tools]
)

# Complex task involving multiple Asana operations
coordination_task = Task(
    description="""
    1. Get all active projects in the workspace
    2. For each project, get the list of incomplete tasks
    3. Create a summary report task in the 'Management Reports' project
    4. Add comments to overdue tasks to request status updates
    """,
    agent=project_coordinator,
    expected_output="Summary report created and status update requests sent for overdue tasks"
)

crew = Crew(
    agents=[project_coordinator],
    tasks=[coordination_task]
)

crew.kickoff()
```


# Box Integration
Source: https://docs.crewai.com/en/enterprise/integrations/box

File storage and document management with Box integration for CrewAI.

## Overview

Enable your agents to manage files, folders, and documents through Box. Upload files, organize folder structures, search content, and streamline your team's document management with AI-powered automation.

## Prerequisites

Before using the Box integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Box account with appropriate permissions
* Connected your Box account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors)

## Setting Up Box Integration

### 1. Connect Your Box Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors)
2. Find **Box** in the Authentication Integrations section
3. Click **Connect** and complete the OAuth flow
4. Grant the necessary permissions for file and folder management
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account)

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="BOX_SAVE_FILE">
    **Description:** Save a file from URL in Box.

    **Parameters:**

    * `fileAttributes` (object, required): Attributes - File metadata including name, parent folder, and timestamps.
      ```json
      {
        "content_created_at": "2012-12-12T10:53:43-08:00",
        "content_modified_at": "2012-12-12T10:53:43-08:00",
        "name": "qwerty.png",
        "parent": { "id": "1234567" }
      }
      ```
    * `file` (string, required): File URL - Files must be smaller than 50MB in size. (example: "[https://picsum.photos/200/300](https://picsum.photos/200/300)").
  </Accordion>

  <Accordion title="BOX_SAVE_FILE_FROM_OBJECT">
    **Description:** Save a file in Box.

    **Parameters:**

    * `file` (string, required): File - Accepts a File Object containing file data. Files must be smaller than 50MB in size.
    * `fileName` (string, required): File Name (example: "qwerty.png").
    * `folder` (string, optional): Folder - Use Connect Portal Workflow Settings to allow users to select the File's Folder destination. Defaults to the user's root folder if left blank.
  </Accordion>

  <Accordion title="BOX_GET_FILE_BY_ID">
    **Description:** Get a file by ID in Box.

    **Parameters:**

    * `fileId` (string, required): File ID - The unique identifier that represents a file. (example: "12345").
  </Accordion>

  <Accordion title="BOX_LIST_FILES">
    **Description:** List files in Box.

    **Parameters:**

    * `folderId` (string, required): Folder ID - The unique identifier that represents a folder. (example: "0").
    * `filterFormula` (object, optional): A filter in disjunctive normal form - OR of AND groups of single conditions.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "direction",
                "operator": "$stringExactlyMatches",
                "value": "ASC"
              }
            ]
          }
        ]
      }
      ```
  </Accordion>

  <Accordion title="BOX_CREATE_FOLDER">
    **Description:** Create a folder in Box.

    **Parameters:**

    * `folderName` (string, required): Name - The name for the new folder. (example: "New Folder").
    * `folderParent` (object, required): Parent Folder - The parent folder where the new folder will be created.
      ```json
      {
        "id": "123456"
      }
      ```
  </Accordion>

  <Accordion title="BOX_MOVE_FOLDER">
    **Description:** Move a folder in Box.

    **Parameters:**

    * `folderId` (string, required): Folder ID - The unique identifier that represents a folder. (example: "0").
    * `folderName` (string, required): Name - The name for the folder. (example: "New Folder").
    * `folderParent` (object, required): Parent Folder - The new parent folder destination.
      ```json
      {
        "id": "123456"
      }
      ```
  </Accordion>

  <Accordion title="BOX_GET_FOLDER_BY_ID">
    **Description:** Get a folder by ID in Box.

    **Parameters:**

    * `folderId` (string, required): Folder ID - The unique identifier that represents a folder. (example: "0").
  </Accordion>

  <Accordion title="BOX_SEARCH_FOLDERS">
    **Description:** Search folders in Box.

    **Parameters:**

    * `folderId` (string, required): Folder ID - The folder to search within.
    * `filterFormula` (object, optional): A filter in disjunctive normal form - OR of AND groups of single conditions.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "sort",
                "operator": "$stringExactlyMatches",
                "value": "name"
              }
            ]
          }
        ]
      }
      ```
  </Accordion>

  <Accordion title="BOX_DELETE_FOLDER">
    **Description:** Delete a folder in Box.

    **Parameters:**

    * `folderId` (string, required): Folder ID - The unique identifier that represents a folder. (example: "0").
    * `recursive` (boolean, optional): Recursive - Delete a folder that is not empty by recursively deleting the folder and all of its content.
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Box Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Box tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Box capabilities
box_agent = Agent(
    role="Document Manager",
    goal="Manage files and folders in Box efficiently",
    backstory="An AI assistant specialized in document management and file organization.",
    tools=[enterprise_tools]
)

# Task to create a folder structure
create_structure_task = Task(
    description="Create a folder called 'Project Files' in the root directory and upload a document from URL",
    agent=box_agent,
    expected_output="Folder created and file uploaded successfully"
)

# Run the task
crew = Crew(
    agents=[box_agent],
    tasks=[create_structure_task]
)

crew.kickoff()
```

### Filtering Specific Box Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Box tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["box_create_folder", "box_save_file", "box_list_files"]
)

file_organizer_agent = Agent(
    role="File Organizer",
    goal="Organize and manage file storage efficiently",
    backstory="An AI assistant that focuses on file organization and storage management.",
    tools=enterprise_tools
)

# Task to organize files
organization_task = Task(
    description="Create a folder structure for the marketing team and organize existing files",
    agent=file_organizer_agent,
    expected_output="Folder structure created and files organized"
)

crew = Crew(
    agents=[file_organizer_agent],
    tasks=[organization_task]
)

crew.kickoff()
```

### Advanced File Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

file_manager = Agent(
    role="File Manager",
    goal="Maintain organized file structure and manage document lifecycle",
    backstory="An experienced file manager who ensures documents are properly organized and accessible.",
    tools=[enterprise_tools]
)

# Complex task involving multiple Box operations
management_task = Task(
    description="""
    1. List all files in the root folder
    2. Create monthly archive folders for the current year
    3. Move old files to appropriate archive folders
    4. Generate a summary report of the file organization
    """,
    agent=file_manager,
    expected_output="Files organized into archive structure with summary report"
)

crew = Crew(
    agents=[file_manager],
    tasks=[management_task]
)

crew.kickoff()
```


# ClickUp Integration
Source: https://docs.crewai.com/en/enterprise/integrations/clickup

Task and productivity management with ClickUp integration for CrewAI.

## Overview

Enable your agents to manage tasks, projects, and productivity workflows through ClickUp. Create and update tasks, organize projects, manage team assignments, and streamline your productivity management with AI-powered automation.

## Prerequisites

Before using the ClickUp integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A ClickUp account with appropriate permissions
* Connected your ClickUp account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors)

## Setting Up ClickUp Integration

### 1. Connect Your ClickUp Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors)
2. Find **ClickUp** in the Authentication Integrations section
3. Click **Connect** and complete the OAuth flow
4. Grant the necessary permissions for task and project management
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account)

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="CLICKUP_SEARCH_TASKS">
    **Description:** Search for tasks in ClickUp using advanced filters.

    **Parameters:**

    * `taskFilterFormula` (object, optional): A filter in disjunctive normal form - OR of AND groups of single conditions.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "statuses%5B%5D",
                "operator": "$stringExactlyMatches",
                "value": "open"
              }
            ]
          }
        ]
      }
      ```
      Available fields: `space_ids%5B%5D`, `project_ids%5B%5D`, `list_ids%5B%5D`, `statuses%5B%5D`, `include_closed`, `assignees%5B%5D`, `tags%5B%5D`, `due_date_gt`, `due_date_lt`, `date_created_gt`, `date_created_lt`, `date_updated_gt`, `date_updated_lt`
  </Accordion>

  <Accordion title="CLICKUP_GET_TASK_IN_LIST">
    **Description:** Get tasks in a specific list in ClickUp.

    **Parameters:**

    * `listId` (string, required): List - Select a List to get tasks from. Use Connect Portal User Settings to allow users to select a ClickUp List.
    * `taskFilterFormula` (string, optional): Search for tasks that match specified filters. For example: name=task1.
  </Accordion>

  <Accordion title="CLICKUP_CREATE_TASK">
    **Description:** Create a task in ClickUp.

    **Parameters:**

    * `listId` (string, required): List - Select a List to create this task in. Use Connect Portal User Settings to allow users to select a ClickUp List.
    * `name` (string, required): Name - The task name.
    * `description` (string, optional): Description - Task description.
    * `status` (string, optional): Status - Select a Status for this task. Use Connect Portal User Settings to allow users to select a ClickUp Status.
    * `assignees` (string, optional): Assignees - Select a Member (or an array of member IDs) to be assigned to this task. Use Connect Portal User Settings to allow users to select a ClickUp Member.
    * `dueDate` (string, optional): Due Date - Specify a date for this task to be due on.
    * `additionalFields` (string, optional): Additional Fields - Specify additional fields to include on this task as JSON.
  </Accordion>

  <Accordion title="CLICKUP_UPDATE_TASK">
    **Description:** Update a task in ClickUp.

    **Parameters:**

    * `taskId` (string, required): Task ID - The ID of the task to update.
    * `listId` (string, required): List - Select a List to create this task in. Use Connect Portal User Settings to allow users to select a ClickUp List.
    * `name` (string, optional): Name - The task name.
    * `description` (string, optional): Description - Task description.
    * `status` (string, optional): Status - Select a Status for this task. Use Connect Portal User Settings to allow users to select a ClickUp Status.
    * `assignees` (string, optional): Assignees - Select a Member (or an array of member IDs) to be assigned to this task. Use Connect Portal User Settings to allow users to select a ClickUp Member.
    * `dueDate` (string, optional): Due Date - Specify a date for this task to be due on.
    * `additionalFields` (string, optional): Additional Fields - Specify additional fields to include on this task as JSON.
  </Accordion>

  <Accordion title="CLICKUP_DELETE_TASK">
    **Description:** Delete a task in ClickUp.

    **Parameters:**

    * `taskId` (string, required): Task ID - The ID of the task to delete.
  </Accordion>

  <Accordion title="CLICKUP_GET_LIST">
    **Description:** Get List information in ClickUp.

    **Parameters:**

    * `spaceId` (string, required): Space ID - The ID of the space containing the lists.
  </Accordion>

  <Accordion title="CLICKUP_GET_CUSTOM_FIELDS_IN_LIST">
    **Description:** Get Custom Fields in a List in ClickUp.

    **Parameters:**

    * `listId` (string, required): List ID - The ID of the list to get custom fields from.
  </Accordion>

  <Accordion title="CLICKUP_GET_ALL_FIELDS_IN_LIST">
    **Description:** Get All Fields in a List in ClickUp.

    **Parameters:**

    * `listId` (string, required): List ID - The ID of the list to get all fields from.
  </Accordion>

  <Accordion title="CLICKUP_GET_SPACE">
    **Description:** Get Space information in ClickUp.

    **Parameters:**

    * `spaceId` (string, optional): Space ID - The ID of the space to retrieve.
  </Accordion>

  <Accordion title="CLICKUP_GET_FOLDERS">
    **Description:** Get Folders in ClickUp.

    **Parameters:**

    * `spaceId` (string, required): Space ID - The ID of the space containing the folders.
  </Accordion>

  <Accordion title="CLICKUP_GET_MEMBER">
    **Description:** Get Member information in ClickUp.

    **Parameters:** None required.
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic ClickUp Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (ClickUp tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with ClickUp capabilities
clickup_agent = Agent(
    role="Task Manager",
    goal="Manage tasks and projects in ClickUp efficiently",
    backstory="An AI assistant specialized in task management and productivity coordination.",
    tools=[enterprise_tools]
)

# Task to create a new task
create_task = Task(
    description="Create a task called 'Review Q1 Reports' in the Marketing list with high priority",
    agent=clickup_agent,
    expected_output="Task created successfully with task ID"
)

# Run the task
crew = Crew(
    agents=[clickup_agent],
    tasks=[create_task]
)

crew.kickoff()
```

### Filtering Specific ClickUp Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific ClickUp tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["clickup_create_task", "clickup_update_task", "clickup_search_tasks"]
)

task_coordinator = Agent(
    role="Task Coordinator",
    goal="Create and manage tasks efficiently",
    backstory="An AI assistant that focuses on task creation and status management.",
    tools=enterprise_tools
)

# Task to manage task workflow
task_workflow = Task(
    description="Create a task for project planning and assign it to the development team",
    agent=task_coordinator,
    expected_output="Task created and assigned successfully"
)

crew = Crew(
    agents=[task_coordinator],
    tasks=[task_workflow]
)

crew.kickoff()
```

### Advanced Project Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

project_manager = Agent(
    role="Project Manager",
    goal="Coordinate project activities and track team productivity",
    backstory="An experienced project manager who ensures projects are delivered on time.",
    tools=[enterprise_tools]
)

# Complex task involving multiple ClickUp operations
project_coordination = Task(
    description="""
    1. Get all open tasks in the current space
    2. Identify overdue tasks and update their status
    3. Create a weekly report task summarizing project progress
    4. Assign the report task to the team lead
    """,
    agent=project_manager,
    expected_output="Project status updated and weekly report task created and assigned"
)

crew = Crew(
    agents=[project_manager],
    tasks=[project_coordination]
)

crew.kickoff()
```

### Task Search and Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

task_analyst = Agent(
    role="Task Analyst",
    goal="Analyze task patterns and optimize team productivity",
    backstory="An AI assistant that analyzes task data to improve team efficiency.",
    tools=[enterprise_tools]
)

# Task to analyze and optimize task distribution
task_analysis = Task(
    description="""
    Search for all tasks assigned to team members in the last 30 days,
    analyze completion patterns, and create optimization recommendations
    """,
    agent=task_analyst,
    expected_output="Task analysis report with optimization recommendations"
)

crew = Crew(
    agents=[task_analyst],
    tasks=[task_analysis]
)

crew.kickoff()
```

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with ClickUp integration setup or troubleshooting.
</Card>


# GitHub Integration
Source: https://docs.crewai.com/en/enterprise/integrations/github

Repository and issue management with GitHub integration for CrewAI.

## Overview

Enable your agents to manage repositories, issues, and releases through GitHub. Create and update issues, manage releases, track project development, and streamline your software development workflow with AI-powered automation.

## Prerequisites

Before using the GitHub integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A GitHub account with appropriate repository permissions
* Connected your GitHub account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors)

## Setting Up GitHub Integration

### 1. Connect Your GitHub Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors)
2. Find **GitHub** in the Authentication Integrations section
3. Click **Connect** and complete the OAuth flow
4. Grant the necessary permissions for repository and issue management
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account)

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="GITHUB_CREATE_ISSUE">
    **Description:** Create an issue in GitHub.

    **Parameters:**

    * `owner` (string, required): Owner - Specify the name of the account owner of the associated repository for this Issue. (example: "abc").
    * `repo` (string, required): Repository - Specify the name of the associated repository for this Issue.
    * `title` (string, required): Issue Title - Specify the title of the issue to create.
    * `body` (string, optional): Issue Body - Specify the body contents of the issue to create.
    * `assignees` (string, optional): Assignees - Specify the assignee(s)' GitHub login as an array of strings for this issue. (example: `["octocat"]`).
  </Accordion>

  <Accordion title="GITHUB_UPDATE_ISSUE">
    **Description:** Update an issue in GitHub.

    **Parameters:**

    * `owner` (string, required): Owner - Specify the name of the account owner of the associated repository for this Issue. (example: "abc").
    * `repo` (string, required): Repository - Specify the name of the associated repository for this Issue.
    * `issue_number` (string, required): Issue Number - Specify the number of the issue to update.
    * `title` (string, required): Issue Title - Specify the title of the issue to update.
    * `body` (string, optional): Issue Body - Specify the body contents of the issue to update.
    * `assignees` (string, optional): Assignees - Specify the assignee(s)' GitHub login as an array of strings for this issue. (example: `["octocat"]`).
    * `state` (string, optional): State - Specify the updated state of the issue.
      * Options: `open`, `closed`
  </Accordion>

  <Accordion title="GITHUB_GET_ISSUE_BY_NUMBER">
    **Description:** Get an issue by number in GitHub.

    **Parameters:**

    * `owner` (string, required): Owner - Specify the name of the account owner of the associated repository for this Issue. (example: "abc").
    * `repo` (string, required): Repository - Specify the name of the associated repository for this Issue.
    * `issue_number` (string, required): Issue Number - Specify the number of the issue to fetch.
  </Accordion>

  <Accordion title="GITHUB_LOCK_ISSUE">
    **Description:** Lock an issue in GitHub.

    **Parameters:**

    * `owner` (string, required): Owner - Specify the name of the account owner of the associated repository for this Issue. (example: "abc").
    * `repo` (string, required): Repository - Specify the name of the associated repository for this Issue.
    * `issue_number` (string, required): Issue Number - Specify the number of the issue to lock.
    * `lock_reason` (string, required): Lock Reason - Specify a reason for locking the issue or pull request conversation.
      * Options: `off-topic`, `too heated`, `resolved`, `spam`
  </Accordion>

  <Accordion title="GITHUB_SEARCH_ISSUE">
    **Description:** Search for issues in GitHub.

    **Parameters:**

    * `owner` (string, required): Owner - Specify the name of the account owner of the associated repository for this Issue. (example: "abc").
    * `repo` (string, required): Repository - Specify the name of the associated repository for this Issue.
    * `filter` (object, required): A filter in disjunctive normal form - OR of AND groups of single conditions.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "assignee",
                "operator": "$stringExactlyMatches",
                "value": "octocat"
              }
            ]
          }
        ]
      }
      ```
      Available fields: `assignee`, `creator`, `mentioned`, `labels`
  </Accordion>

  <Accordion title="GITHUB_CREATE_RELEASE">
    **Description:** Create a release in GitHub.

    **Parameters:**

    * `owner` (string, required): Owner - Specify the name of the account owner of the associated repository for this Release. (example: "abc").
    * `repo` (string, required): Repository - Specify the name of the associated repository for this Release.
    * `tag_name` (string, required): Name - Specify the name of the release tag to be created. (example: "v1.0.0").
    * `target_commitish` (string, optional): Target - Specify the target of the release. This can either be a branch name or a commit SHA. Defaults to the main branch. (example: "master").
    * `body` (string, optional): Body - Specify a description for this release.
    * `draft` (string, optional): Draft - Specify whether the created release should be a draft (unpublished) release.
      * Options: `true`, `false`
    * `prerelease` (string, optional): Prerelease - Specify whether the created release should be a prerelease.
      * Options: `true`, `false`
    * `discussion_category_name` (string, optional): Discussion Category Name - If specified, a discussion of the specified category is created and linked to the release. The value must be a category that already exists in the repository.
    * `generate_release_notes` (string, optional): Release Notes - Specify whether the created release should automatically create release notes using the provided name and body specified.
      * Options: `true`, `false`
  </Accordion>

  <Accordion title="GITHUB_UPDATE_RELEASE">
    **Description:** Update a release in GitHub.

    **Parameters:**

    * `owner` (string, required): Owner - Specify the name of the account owner of the associated repository for this Release. (example: "abc").
    * `repo` (string, required): Repository - Specify the name of the associated repository for this Release.
    * `id` (string, required): Release ID - Specify the ID of the release to update.
    * `tag_name` (string, optional): Name - Specify the name of the release tag to be updated. (example: "v1.0.0").
    * `target_commitish` (string, optional): Target - Specify the target of the release. This can either be a branch name or a commit SHA. Defaults to the main branch. (example: "master").
    * `body` (string, optional): Body - Specify a description for this release.
    * `draft` (string, optional): Draft - Specify whether the created release should be a draft (unpublished) release.
      * Options: `true`, `false`
    * `prerelease` (string, optional): Prerelease - Specify whether the created release should be a prerelease.
      * Options: `true`, `false`
    * `discussion_category_name` (string, optional): Discussion Category Name - If specified, a discussion of the specified category is created and linked to the release. The value must be a category that already exists in the repository.
    * `generate_release_notes` (string, optional): Release Notes - Specify whether the created release should automatically create release notes using the provided name and body specified.
      * Options: `true`, `false`
  </Accordion>

  <Accordion title="GITHUB_GET_RELEASE_BY_ID">
    **Description:** Get a release by ID in GitHub.

    **Parameters:**

    * `owner` (string, required): Owner - Specify the name of the account owner of the associated repository for this Release. (example: "abc").
    * `repo` (string, required): Repository - Specify the name of the associated repository for this Release.
    * `id` (string, required): Release ID - Specify the release ID of the release to fetch.
  </Accordion>

  <Accordion title="GITHUB_GET_RELEASE_BY_TAG_NAME">
    **Description:** Get a release by tag name in GitHub.

    **Parameters:**

    * `owner` (string, required): Owner - Specify the name of the account owner of the associated repository for this Release. (example: "abc").
    * `repo` (string, required): Repository - Specify the name of the associated repository for this Release.
    * `tag_name` (string, required): Name - Specify the tag of the release to fetch. (example: "v1.0.0").
  </Accordion>

  <Accordion title="GITHUB_DELETE_RELEASE">
    **Description:** Delete a release in GitHub.

    **Parameters:**

    * `owner` (string, required): Owner - Specify the name of the account owner of the associated repository for this Release. (example: "abc").
    * `repo` (string, required): Repository - Specify the name of the associated repository for this Release.
    * `id` (string, required): Release ID - Specify the ID of the release to delete.
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic GitHub Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (GitHub tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with GitHub capabilities
github_agent = Agent(
    role="Repository Manager",
    goal="Manage GitHub repositories, issues, and releases efficiently",
    backstory="An AI assistant specialized in repository management and issue tracking.",
    tools=[enterprise_tools]
)

# Task to create a new issue
create_issue_task = Task(
    description="Create a bug report issue for the login functionality in the main repository",
    agent=github_agent,
    expected_output="Issue created successfully with issue number"
)

# Run the task
crew = Crew(
    agents=[github_agent],
    tasks=[create_issue_task]
)

crew.kickoff()
```

### Filtering Specific GitHub Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific GitHub tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["github_create_issue", "github_update_issue", "github_search_issue"]
)

issue_manager = Agent(
    role="Issue Manager",
    goal="Create and manage GitHub issues efficiently",
    backstory="An AI assistant that focuses on issue tracking and management.",
    tools=enterprise_tools
)

# Task to manage issue workflow
issue_workflow = Task(
    description="Create a feature request issue and assign it to the development team",
    agent=issue_manager,
    expected_output="Feature request issue created and assigned successfully"
)

crew = Crew(
    agents=[issue_manager],
    tasks=[issue_workflow]
)

crew.kickoff()
```

### Release Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

release_manager = Agent(
    role="Release Manager",
    goal="Manage software releases and versioning",
    backstory="An experienced release manager who handles version control and release processes.",
    tools=[enterprise_tools]
)

# Task to create a new release
release_task = Task(
    description="""
    Create a new release v2.1.0 for the project with:
    - Auto-generated release notes
    - Target the main branch
    - Include a description of new features and bug fixes
    """,
    agent=release_manager,
    expected_output="Release v2.1.0 created successfully with release notes"
)

crew = Crew(
    agents=[release_manager],
    tasks=[release_task]
)

crew.kickoff()
```

### Issue Tracking and Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

project_coordinator = Agent(
    role="Project Coordinator",
    goal="Track and coordinate project issues and development progress",
    backstory="An AI assistant that helps coordinate development work and track project progress.",
    tools=[enterprise_tools]
)

# Complex task involving multiple GitHub operations
coordination_task = Task(
    description="""
    1. Search for all open issues assigned to the current milestone
    2. Identify overdue issues and update their priority labels
    3. Create a weekly progress report issue
    4. Lock resolved issues that have been inactive for 30 days
    """,
    agent=project_coordinator,
    expected_output="Project coordination completed with progress report and issue management"
)

crew = Crew(
    agents=[project_coordinator],
    tasks=[coordination_task]
)

crew.kickoff()
```

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with GitHub integration setup or troubleshooting.
</Card>


# Gmail Integration
Source: https://docs.crewai.com/en/enterprise/integrations/gmail

Email and contact management with Gmail integration for CrewAI.

## Overview

Enable your agents to manage emails, contacts, and drafts through Gmail. Send emails, search messages, manage contacts, create drafts, and streamline your email communications with AI-powered automation.

## Prerequisites

Before using the Gmail integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Gmail account with appropriate permissions
* Connected your Gmail account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors)

## Setting Up Gmail Integration

### 1. Connect Your Gmail Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors)
2. Find **Gmail** in the Authentication Integrations section
3. Click **Connect** and complete the OAuth flow
4. Grant the necessary permissions for email and contact management
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account)

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="GMAIL_SEND_EMAIL">
    **Description:** Send an email in Gmail.

    **Parameters:**

    * `toRecipients` (array, required): To - Specify the recipients as either a single string or a JSON array.
      ```json
      [
        "recipient1@domain.com",
        "recipient2@domain.com"
      ]
      ```
    * `from` (string, required): From - Specify the email of the sender.
    * `subject` (string, required): Subject - Specify the subject of the message.
    * `messageContent` (string, required): Message Content - Specify the content of the email message as plain text or HTML.
    * `attachments` (string, optional): Attachments - Accepts either a single file object or a JSON array of file objects.
    * `additionalHeaders` (object, optional): Additional Headers - Specify any additional header fields here.
      ```json
      {
        "reply-to": "Sender Name <sender@domain.com>"
      }
      ```
  </Accordion>

  <Accordion title="GMAIL_GET_EMAIL_BY_ID">
    **Description:** Get an email by ID in Gmail.

    **Parameters:**

    * `userId` (string, required): User ID - Specify the user's email address. (example: "[user@domain.com](mailto:user@domain.com)").
    * `messageId` (string, required): Message ID - Specify the ID of the message to retrieve.
  </Accordion>

  <Accordion title="GMAIL_SEARCH_FOR_EMAIL">
    **Description:** Search for emails in Gmail using advanced filters.

    **Parameters:**

    * `emailFilterFormula` (object, optional): A filter in disjunctive normal form - OR of AND groups of single conditions.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "from",
                "operator": "$stringContains",
                "value": "example@domain.com"
              }
            ]
          }
        ]
      }
      ```
      Available fields: `from`, `to`, `date`, `label`, `subject`, `cc`, `bcc`, `category`, `deliveredto:`, `size`, `filename`, `older_than`, `newer_than`, `list`, `is:important`, `is:unread`, `is:snoozed`, `is:starred`, `is:read`, `has:drive`, `has:document`, `has:spreadsheet`, `has:presentation`, `has:attachment`, `has:youtube`, `has:userlabels`
    * `paginationParameters` (object, optional): Pagination Parameters.
      ```json
      {
        "pageCursor": "page_cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="GMAIL_DELETE_EMAIL">
    **Description:** Delete an email in Gmail.

    **Parameters:**

    * `userId` (string, required): User ID - Specify the user's email address. (example: "[user@domain.com](mailto:user@domain.com)").
    * `messageId` (string, required): Message ID - Specify the ID of the message to trash.
  </Accordion>

  <Accordion title="GMAIL_CREATE_A_CONTACT">
    **Description:** Create a contact in Gmail.

    **Parameters:**

    * `givenName` (string, required): Given Name - Specify the Given Name of the Contact to create. (example: "John").
    * `familyName` (string, required): Family Name - Specify the Family Name of the Contact to create. (example: "Doe").
    * `email` (string, required): Email - Specify the Email Address of the Contact to create.
    * `additionalFields` (object, optional): Additional Fields - Additional contact information.
      ```json
      {
        "addresses": [
          {
            "streetAddress": "1000 North St.",
            "city": "Los Angeles"
          }
        ]
      }
      ```
  </Accordion>

  <Accordion title="GMAIL_GET_CONTACT_BY_RESOURCE_NAME">
    **Description:** Get a contact by resource name in Gmail.

    **Parameters:**

    * `resourceName` (string, required): Resource Name - Specify the resource name of the contact to fetch.
  </Accordion>

  <Accordion title="GMAIL_SEARCH_FOR_CONTACT">
    **Description:** Search for a contact in Gmail.

    **Parameters:**

    * `searchTerm` (string, required): Term - Specify a search term to search for near or exact matches on the names, nickNames, emailAddresses, phoneNumbers, or organizations Contact properties.
  </Accordion>

  <Accordion title="GMAIL_DELETE_CONTACT">
    **Description:** Delete a contact in Gmail.

    **Parameters:**

    * `resourceName` (string, required): Resource Name - Specify the resource name of the contact to delete.
  </Accordion>

  <Accordion title="GMAIL_CREATE_DRAFT">
    **Description:** Create a draft in Gmail.

    **Parameters:**

    * `toRecipients` (array, optional): To - Specify the recipients as either a single string or a JSON array.
      ```json
      [
        "recipient1@domain.com",
        "recipient2@domain.com"
      ]
      ```
    * `from` (string, optional): From - Specify the email of the sender.
    * `subject` (string, optional): Subject - Specify the subject of the message.
    * `messageContent` (string, optional): Message Content - Specify the content of the email message as plain text or HTML.
    * `attachments` (string, optional): Attachments - Accepts either a single file object or a JSON array of file objects.
    * `additionalHeaders` (object, optional): Additional Headers - Specify any additional header fields here.
      ```json
      {
        "reply-to": "Sender Name <sender@domain.com>"
      }
      ```
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Gmail Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Gmail tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Gmail capabilities
gmail_agent = Agent(
    role="Email Manager",
    goal="Manage email communications and contacts efficiently",
    backstory="An AI assistant specialized in email management and communication.",
    tools=[enterprise_tools]
)

# Task to send a follow-up email
send_email_task = Task(
    description="Send a follow-up email to john@example.com about the project update meeting",
    agent=gmail_agent,
    expected_output="Email sent successfully with confirmation"
)

# Run the task
crew = Crew(
    agents=[gmail_agent],
    tasks=[send_email_task]
)

crew.kickoff()
```

### Filtering Specific Gmail Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Gmail tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["gmail_send_email", "gmail_search_for_email", "gmail_create_draft"]
)

email_coordinator = Agent(
    role="Email Coordinator",
    goal="Coordinate email communications and manage drafts",
    backstory="An AI assistant that focuses on email coordination and draft management.",
    tools=enterprise_tools
)

# Task to prepare and send emails
email_coordination = Task(
    description="Search for emails from the marketing team, create a summary draft, and send it to stakeholders",
    agent=email_coordinator,
    expected_output="Summary email sent to stakeholders"
)

crew = Crew(
    agents=[email_coordinator],
    tasks=[email_coordination]
)

crew.kickoff()
```

### Contact Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

contact_manager = Agent(
    role="Contact Manager",
    goal="Manage and organize email contacts efficiently",
    backstory="An experienced contact manager who maintains organized contact databases.",
    tools=[enterprise_tools]
)

# Task to manage contacts
contact_task = Task(
    description="""
    1. Search for contacts from the 'example.com' domain
    2. Create new contacts for recent email senders not in the contact list
    3. Update contact information with recent interaction data
    """,
    agent=contact_manager,
    expected_output="Contact database updated with new contacts and recent interactions"
)

crew = Crew(
    agents=[contact_manager],
    tasks=[contact_task]
)

crew.kickoff()
```

### Email Search and Analysis

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

email_analyst = Agent(
    role="Email Analyst",
    goal="Analyze email patterns and provide insights",
    backstory="An AI assistant that analyzes email data to provide actionable insights.",
    tools=[enterprise_tools]
)

# Task to analyze email patterns
analysis_task = Task(
    description="""
    Search for all unread emails from the last 7 days,
    categorize them by sender domain,
    and create a summary report of communication patterns
    """,
    agent=email_analyst,
    expected_output="Email analysis report with communication patterns and recommendations"
)

crew = Crew(
    agents=[email_analyst],
    tasks=[analysis_task]
)

crew.kickoff()
```

### Automated Email Workflows

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

workflow_manager = Agent(
    role="Email Workflow Manager",
    goal="Automate email workflows and responses",
    backstory="An AI assistant that manages automated email workflows and responses.",
    tools=[enterprise_tools]
)

# Complex task involving multiple Gmail operations
workflow_task = Task(
    description="""
    1. Search for emails with 'urgent' in the subject from the last 24 hours
    2. Create draft responses for each urgent email
    3. Send automated acknowledgment emails to senders
    4. Create a summary report of urgent items requiring attention
    """,
    agent=workflow_manager,
    expected_output="Urgent emails processed with automated responses and summary report"
)

crew = Crew(
    agents=[workflow_manager],
    tasks=[workflow_task]
)

crew.kickoff()
```

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with Gmail integration setup or troubleshooting.
</Card>


# Google Calendar Integration
Source: https://docs.crewai.com/en/enterprise/integrations/google_calendar

Event and schedule management with Google Calendar integration for CrewAI.

## Overview

Enable your agents to manage calendar events, schedules, and availability through Google Calendar. Create and update events, manage attendees, check availability, and streamline your scheduling workflows with AI-powered automation.

## Prerequisites

Before using the Google Calendar integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Google account with Google Calendar access
* Connected your Google account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors)

## Setting Up Google Calendar Integration

### 1. Connect Your Google Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors)
2. Find **Google Calendar** in the Authentication Integrations section
3. Click **Connect** and complete the OAuth flow
4. Grant the necessary permissions for calendar and contact access
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account)

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="GOOGLE_CALENDAR_CREATE_EVENT">
    **Description:** Create an event in Google Calendar.

    **Parameters:**

    * `eventName` (string, required): Event name.
    * `startTime` (string, required): Start time - Accepts Unix timestamp or ISO8601 date formats.
    * `endTime` (string, optional): End time - Defaults to one hour after the start time if left blank.
    * `calendar` (string, optional): Calendar - Use Connect Portal Workflow Settings to allow users to select which calendar the event will be added to. Defaults to the user's primary calendar if left blank.
    * `attendees` (string, optional): Attendees - Accepts an array of email addresses or email addresses separated by commas.
    * `eventLocation` (string, optional): Event location.
    * `eventDescription` (string, optional): Event description.
    * `eventId` (string, optional): Event ID - An ID from your application to associate this event with. You can use this ID to sync updates to this event later.
    * `includeMeetLink` (boolean, optional): Include Google Meet link? - Automatically creates Google Meet conference link for this event.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_UPDATE_EVENT">
    **Description:** Update an existing event in Google Calendar.

    **Parameters:**

    * `eventId` (string, required): Event ID - The ID of the event to update.
    * `eventName` (string, optional): Event name.
    * `startTime` (string, optional): Start time - Accepts Unix timestamp or ISO8601 date formats.
    * `endTime` (string, optional): End time - Defaults to one hour after the start time if left blank.
    * `calendar` (string, optional): Calendar - Use Connect Portal Workflow Settings to allow users to select which calendar the event will be added to. Defaults to the user's primary calendar if left blank.
    * `attendees` (string, optional): Attendees - Accepts an array of email addresses or email addresses separated by commas.
    * `eventLocation` (string, optional): Event location.
    * `eventDescription` (string, optional): Event description.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_LIST_EVENTS">
    **Description:** List events from Google Calendar.

    **Parameters:**

    * `calendar` (string, optional): Calendar - Use Connect Portal Workflow Settings to allow users to select which calendar the event will be added to. Defaults to the user's primary calendar if left blank.
    * `after` (string, optional): After - Filters events that start after the provided date (Unix in milliseconds or ISO timestamp). (example: "2025-04-12T10:00:00Z or 1712908800000").
    * `before` (string, optional): Before - Filters events that end before the provided date (Unix in milliseconds or ISO timestamp). (example: "2025-04-12T10:00:00Z or 1712908800000").
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_GET_EVENT_BY_ID">
    **Description:** Get a specific event by ID from Google Calendar.

    **Parameters:**

    * `eventId` (string, required): Event ID.
    * `calendar` (string, optional): Calendar - Use Connect Portal Workflow Settings to allow users to select which calendar the event will be added to. Defaults to the user's primary calendar if left blank.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_DELETE_EVENT">
    **Description:** Delete an event from Google Calendar.

    **Parameters:**

    * `eventId` (string, required): Event ID - The ID of the calendar event to be deleted.
    * `calendar` (string, optional): Calendar - Use Connect Portal Workflow Settings to allow users to select which calendar the event will be added to. Defaults to the user's primary calendar if left blank.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_GET_CONTACTS">
    **Description:** Get contacts from Google Calendar.

    **Parameters:**

    * `paginationParameters` (object, optional): Pagination Parameters.
      ```json
      {
        "pageCursor": "page_cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_SEARCH_CONTACTS">
    **Description:** Search for contacts in Google Calendar.

    **Parameters:**

    * `query` (string, optional): Search query to search contacts.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_LIST_DIRECTORY_PEOPLE">
    **Description:** List directory people.

    **Parameters:**

    * `paginationParameters` (object, optional): Pagination Parameters.
      ```json
      {
        "pageCursor": "page_cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_SEARCH_DIRECTORY_PEOPLE">
    **Description:** Search directory people.

    **Parameters:**

    * `query` (string, required): Search query to search contacts.
    * `paginationParameters` (object, optional): Pagination Parameters.
      ```json
      {
        "pageCursor": "page_cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_LIST_OTHER_CONTACTS">
    **Description:** List other contacts.

    **Parameters:**

    * `paginationParameters` (object, optional): Pagination Parameters.
      ```json
      {
        "pageCursor": "page_cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_SEARCH_OTHER_CONTACTS">
    **Description:** Search other contacts.

    **Parameters:**

    * `query` (string, optional): Search query to search contacts.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_GET_AVAILABILITY">
    **Description:** Get availability information for calendars.

    **Parameters:**

    * `timeMin` (string, required): The start of the interval. In ISO format.
    * `timeMax` (string, required): The end of the interval. In ISO format.
    * `timeZone` (string, optional): Time zone used in the response. Optional. The default is UTC.
    * `items` (array, optional): List of calendars and/or groups to query. Defaults to the user default calendar.
      ```json
      [
        {
          "id": "calendar_id_1"
        },
        {
          "id": "calendar_id_2"
        }
      ]
      ```
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Calendar Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Google Calendar tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Google Calendar capabilities
calendar_agent = Agent(
    role="Schedule Manager",
    goal="Manage calendar events and scheduling efficiently",
    backstory="An AI assistant specialized in calendar management and scheduling coordination.",
    tools=[enterprise_tools]
)

# Task to create a meeting
create_meeting_task = Task(
    description="Create a team standup meeting for tomorrow at 9 AM with the development team",
    agent=calendar_agent,
    expected_output="Meeting created successfully with Google Meet link"
)

# Run the task
crew = Crew(
    agents=[calendar_agent],
    tasks=[create_meeting_task]
)

crew.kickoff()
```

### Filtering Specific Calendar Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Google Calendar tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["google_calendar_create_event", "google_calendar_list_events", "google_calendar_get_availability"]
)

meeting_coordinator = Agent(
    role="Meeting Coordinator",
    goal="Coordinate meetings and check availability",
    backstory="An AI assistant that focuses on meeting scheduling and availability management.",
    tools=enterprise_tools
)

# Task to schedule a meeting with availability check
schedule_meeting = Task(
    description="Check availability for next week and schedule a project review meeting with stakeholders",
    agent=meeting_coordinator,
    expected_output="Meeting scheduled after checking availability of all participants"
)

crew = Crew(
    agents=[meeting_coordinator],
    tasks=[schedule_meeting]
)

crew.kickoff()
```

### Event Management and Updates

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

event_manager = Agent(
    role="Event Manager",
    goal="Manage and update calendar events efficiently",
    backstory="An experienced event manager who handles event logistics and updates.",
    tools=[enterprise_tools]
)

# Task to manage event updates
event_management = Task(
    description="""
    1. List all events for this week
    2. Update any events that need location changes to include video conference links
    3. Send calendar invitations to new team members for recurring meetings
    """,
    agent=event_manager,
    expected_output="Weekly events updated with proper locations and new attendees added"
)

crew = Crew(
    agents=[event_manager],
    tasks=[event_management]
)

crew.kickoff()
```

### Contact and Availability Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

availability_coordinator = Agent(
    role="Availability Coordinator",
    goal="Coordinate availability and manage contacts for scheduling",
    backstory="An AI assistant that specializes in availability management and contact coordination.",
    tools=[enterprise_tools]
)

# Task to coordinate availability
availability_task = Task(
    description="""
    1. Search for contacts in the engineering department
    2. Check availability for all engineers next Friday afternoon
    3. Create a team meeting for the first available 2-hour slot
    4. Include Google Meet link and send invitations
    """,
    agent=availability_coordinator,
    expected_output="Team meeting scheduled based on availability with all engineers invited"
)

crew = Crew(
    agents=[availability_coordinator],
    tasks=[availability_task]
)

crew.kickoff()
```

### Automated Scheduling Workflows

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

scheduling_automator = Agent(
    role="Scheduling Automator",
    goal="Automate scheduling workflows and calendar management",
    backstory="An AI assistant that automates complex scheduling scenarios and calendar workflows.",
    tools=[enterprise_tools]
)

# Complex scheduling automation task
automation_task = Task(
    description="""
    1. List all upcoming events for the next two weeks
    2. Identify any scheduling conflicts or back-to-back meetings
    3. Suggest optimal meeting times by checking availability
    4. Create buffer time between meetings where needed
    5. Update event descriptions with agenda items and meeting links
    """,
    agent=scheduling_automator,
    expected_output="Calendar optimized with resolved conflicts, buffer times, and updated meeting details"
)

crew = Crew(
    agents=[scheduling_automator],
    tasks=[automation_task]
)

crew.kickoff()
```

## Troubleshooting

### Common Issues

**Authentication Errors**

* Ensure your Google account has the necessary permissions for calendar access
* Verify that the OAuth connection includes all required scopes for Google Calendar API
* Check if calendar sharing settings allow the required access level

**Event Creation Issues**

* Verify that time formats are correct (ISO8601 or Unix timestamps)
* Ensure attendee email addresses are properly formatted
* Check that the target calendar exists and is accessible
* Verify time zones are correctly specified

**Availability and Time Conflicts**

* Use proper ISO format for time ranges when checking availability
* Ensure time zones are consistent across all operations
* Verify that calendar IDs are correct when checking multiple calendars

**Contact and People Search**

* Ensure search queries are properly formatted
* Check that directory access permissions are granted
* Verify that contact information is up to date and accessible

**Event Updates and Deletions**

* Verify that event IDs are correct and events exist
* Ensure you have edit permissions for the events
* Check that calendar ownership allows modifications

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with Google Calendar integration setup or troubleshooting.
</Card>


# Google Sheets Integration
Source: https://docs.crewai.com/en/enterprise/integrations/google_sheets

Spreadsheet data synchronization with Google Sheets integration for CrewAI.

## Overview

Enable your agents to manage spreadsheet data through Google Sheets. Read rows, create new entries, update existing data, and streamline your data management workflows with AI-powered automation. Perfect for data tracking, reporting, and collaborative data management.

## Prerequisites

Before using the Google Sheets integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Google account with Google Sheets access
* Connected your Google account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors)
* Spreadsheets with proper column headers for data operations

## Setting Up Google Sheets Integration

### 1. Connect Your Google Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors)
2. Find **Google Sheets** in the Authentication Integrations section
3. Click **Connect** and complete the OAuth flow
4. Grant the necessary permissions for spreadsheet access
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account)

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="GOOGLE_SHEETS_GET_ROW">
    **Description:** Get rows from a Google Sheets spreadsheet.

    **Parameters:**

    * `spreadsheetId` (string, required): Spreadsheet - Use Connect Portal Workflow Settings to allow users to select a spreadsheet. Defaults to using the first worksheet in the selected spreadsheet.
    * `limit` (string, optional): Limit rows - Limit the maximum number of rows to return.
  </Accordion>

  <Accordion title="GOOGLE_SHEETS_CREATE_ROW">
    **Description:** Create a new row in a Google Sheets spreadsheet.

    **Parameters:**

    * `spreadsheetId` (string, required): Spreadsheet - Use Connect Portal Workflow Settings to allow users to select a spreadsheet. Defaults to using the first worksheet in the selected spreadsheet..
    * `worksheet` (string, required): Worksheet - Your worksheet must have column headers.
    * `additionalFields` (object, required): Fields - Include fields to create this row with, as an object with keys of Column Names. Use Connect Portal Workflow Settings to allow users to select a Column Mapping.
      ```json
      {
        "columnName1": "columnValue1",
        "columnName2": "columnValue2",
        "columnName3": "columnValue3",
        "columnName4": "columnValue4"
      }
      ```
  </Accordion>

  <Accordion title="GOOGLE_SHEETS_UPDATE_ROW">
    **Description:** Update existing rows in a Google Sheets spreadsheet.

    **Parameters:**

    * `spreadsheetId` (string, required): Spreadsheet - Use Connect Portal Workflow Settings to allow users to select a spreadsheet. Defaults to using the first worksheet in the selected spreadsheet.
    * `worksheet` (string, required): Worksheet - Your worksheet must have column headers.
    * `filterFormula` (object, optional): A filter in disjunctive normal form - OR of AND groups of single conditions to identify which rows to update.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "status",
                "operator": "$stringExactlyMatches",
                "value": "pending"
              }
            ]
          }
        ]
      }
      ```
      Available operators: `$stringContains`, `$stringDoesNotContain`, `$stringExactlyMatches`, `$stringDoesNotExactlyMatch`, `$stringStartsWith`, `$stringDoesNotStartWith`, `$stringEndsWith`, `$stringDoesNotEndWith`, `$numberGreaterThan`, `$numberLessThan`, `$numberEquals`, `$numberDoesNotEqual`, `$dateTimeAfter`, `$dateTimeBefore`, `$dateTimeEquals`, `$booleanTrue`, `$booleanFalse`, `$exists`, `$doesNotExist`
    * `additionalFields` (object, required): Fields - Include fields to update, as an object with keys of Column Names. Use Connect Portal Workflow Settings to allow users to select a Column Mapping.
      ```json
      {
        "columnName1": "newValue1",
        "columnName2": "newValue2",
        "columnName3": "newValue3",
        "columnName4": "newValue4"
      }
      ```
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Google Sheets Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Google Sheets tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Google Sheets capabilities
sheets_agent = Agent(
    role="Data Manager",
    goal="Manage spreadsheet data and track information efficiently",
    backstory="An AI assistant specialized in data management and spreadsheet operations.",
    tools=[enterprise_tools]
)

# Task to add new data to a spreadsheet
data_entry_task = Task(
    description="Add a new customer record to the customer database spreadsheet with name, email, and signup date",
    agent=sheets_agent,
    expected_output="New customer record added successfully to the spreadsheet"
)

# Run the task
crew = Crew(
    agents=[sheets_agent],
    tasks=[data_entry_task]
)

crew.kickoff()
```

### Filtering Specific Google Sheets Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Google Sheets tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["google_sheets_get_row", "google_sheets_create_row"]
)

data_collector = Agent(
    role="Data Collector",
    goal="Collect and organize data in spreadsheets",
    backstory="An AI assistant that focuses on data collection and organization.",
    tools=enterprise_tools
)

# Task to collect and organize data
data_collection = Task(
    description="Retrieve current inventory data and add new product entries to the inventory spreadsheet",
    agent=data_collector,
    expected_output="Inventory data retrieved and new products added successfully"
)

crew = Crew(
    agents=[data_collector],
    tasks=[data_collection]
)

crew.kickoff()
```

### Data Analysis and Reporting

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

data_analyst = Agent(
    role="Data Analyst",
    goal="Analyze spreadsheet data and generate insights",
    backstory="An experienced data analyst who extracts insights from spreadsheet data.",
    tools=[enterprise_tools]
)

# Task to analyze data and create reports
analysis_task = Task(
    description="""
    1. Retrieve all sales data from the current month's spreadsheet
    2. Analyze the data for trends and patterns
    3. Create a summary report in a new row with key metrics
    """,
    agent=data_analyst,
    expected_output="Sales data analyzed and summary report created with key insights"
)

crew = Crew(
    agents=[data_analyst],
    tasks=[analysis_task]
)

crew.kickoff()
```

### Automated Data Updates

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

data_updater = Agent(
    role="Data Updater",
    goal="Automatically update and maintain spreadsheet data",
    backstory="An AI assistant that maintains data accuracy and updates records automatically.",
    tools=[enterprise_tools]
)

# Task to update data based on conditions
update_task = Task(
    description="""
    1. Find all pending orders in the orders spreadsheet
    2. Update their status to 'processing'
    3. Add a timestamp for when the status was updated
    4. Log the changes in a separate tracking sheet
    """,
    agent=data_updater,
    expected_output="All pending orders updated to processing status with timestamps logged"
)

crew = Crew(
    agents=[data_updater],
    tasks=[update_task]
)

crew.kickoff()
```

### Complex Data Management Workflow

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

workflow_manager = Agent(
    role="Data Workflow Manager",
    goal="Manage complex data workflows across multiple spreadsheets",
    backstory="An AI assistant that orchestrates complex data operations across multiple spreadsheets.",
    tools=[enterprise_tools]
)

# Complex workflow task
workflow_task = Task(
    description="""
    1. Get all customer data from the main customer spreadsheet
    2. Create monthly summary entries for active customers
    3. Update customer status based on activity in the last 30 days
    4. Generate a monthly report with customer metrics
    5. Archive inactive customer records to a separate sheet
    """,
    agent=workflow_manager,
    expected_output="Monthly customer workflow completed with updated statuses and generated reports"
)

crew = Crew(
    agents=[workflow_manager],
    tasks=[workflow_task]
)

crew.kickoff()
```

## Troubleshooting

### Common Issues

**Permission Errors**

* Ensure your Google account has edit access to the target spreadsheets
* Verify that the OAuth connection includes required scopes for Google Sheets API
* Check that spreadsheets are shared with the authenticated account

**Spreadsheet Structure Issues**

* Ensure worksheets have proper column headers before creating or updating rows
* Verify that column names in `additionalFields` match the actual column headers
* Check that the specified worksheet exists in the spreadsheet

**Data Type and Format Issues**

* Ensure data values match the expected format for each column
* Use proper date formats for date columns (ISO format recommended)
* Verify that numeric values are properly formatted for number columns

**Filter Formula Issues**

* Ensure filter formulas follow the correct JSON structure for disjunctive normal form
* Use valid field names that match actual column headers
* Test simple filters before building complex multi-condition queries
* Verify that operator types match the data types in the columns

**Row Limits and Performance**

* Be mindful of row limits when using `GOOGLE_SHEETS_GET_ROW`
* Consider pagination for large datasets
* Use specific filters to reduce the amount of data processed

**Update Operations**

* Ensure filter conditions properly identify the intended rows for updates
* Test filter conditions with small datasets before large updates
* Verify that all required fields are included in update operations

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with Google Sheets integration setup or troubleshooting.
</Card>


# HubSpot Integration
Source: https://docs.crewai.com/en/enterprise/integrations/hubspot

Manage companies and contacts in HubSpot with CrewAI.

## Overview

Enable your agents to manage companies and contacts within HubSpot. Create new records and streamline your CRM processes with AI-powered automation.

## Prerequisites

Before using the HubSpot integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription.
* A HubSpot account with appropriate permissions.
* Connected your HubSpot account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors).

## Setting Up HubSpot Integration

### 1. Connect Your HubSpot Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors).
2. Find **HubSpot** in the Authentication Integrations section.
3. Click **Connect** and complete the OAuth flow.
4. Grant the necessary permissions for company and contact management.
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account).

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="HUBSPOT_CREATE_RECORD_COMPANIES">
    **Description:** Create a new company record in HubSpot.

    **Parameters:**

    * `name` (string, required): Name of the company.
    * `domain` (string, optional): Company Domain Name.
    * `industry` (string, optional): Industry. Must be one of the predefined values from HubSpot.
    * `phone` (string, optional): Phone Number.
    * `hubspot_owner_id` (string, optional): Company owner ID.
    * `type` (string, optional): Type of the company. Available values: `PROSPECT`, `PARTNER`, `RESELLER`, `VENDOR`, `OTHER`.
    * `city` (string, optional): City.
    * `state` (string, optional): State/Region.
    * `zip` (string, optional): Postal Code.
    * `numberofemployees` (number, optional): Number of Employees.
    * `annualrevenue` (number, optional): Annual Revenue.
    * `timezone` (string, optional): Time Zone.
    * `description` (string, optional): Description.
    * `linkedin_company_page` (string, optional): LinkedIn Company Page URL.
    * `company_email` (string, optional): Company Email.
    * `first_name` (string, optional): First Name of a contact at the company.
    * `last_name` (string, optional): Last Name of a contact at the company.
    * `about_us` (string, optional): About Us.
    * `hs_csm_sentiment` (string, optional): CSM Sentiment. Available values: `at_risk`, `neutral`, `healthy`.
    * `closedate` (string, optional): Close Date.
    * `hs_keywords` (string, optional): Company Keywords. Must be one of the predefined values.
    * `country` (string, optional): Country/Region.
    * `hs_country_code` (string, optional): Country/Region Code.
    * `hs_employee_range` (string, optional): Employee range.
    * `facebook_company_page` (string, optional): Facebook Company Page URL.
    * `facebookfans` (number, optional): Number of Facebook Fans.
    * `hs_gps_coordinates` (string, optional): GPS Coordinates.
    * `hs_gps_error` (string, optional): GPS Error.
    * `googleplus_page` (string, optional): Google Plus Page URL.
    * `owneremail` (string, optional): HubSpot Owner Email.
    * `ownername` (string, optional): HubSpot Owner Name.
    * `hs_ideal_customer_profile` (string, optional): Ideal Customer Profile Tier. Available values: `tier_1`, `tier_2`, `tier_3`.
    * `hs_industry_group` (string, optional): Industry group.
    * `is_public` (boolean, optional): Is Public.
    * `hs_last_metered_enrichment_timestamp` (string, optional): Last Metered Enrichment Timestamp.
    * `hs_lead_status` (string, optional): Lead Status. Available values: `NEW`, `OPEN`, `IN_PROGRESS`, `OPEN_DEAL`, `UNQUALIFIED`, `ATTEMPTED_TO_CONTACT`, `CONNECTED`, `BAD_TIMING`.
    * `lifecyclestage` (string, optional): Lifecycle Stage. Available values: `subscriber`, `lead`, `marketingqualifiedlead`, `salesqualifiedlead`, `opportunity`, `customer`, `evangelist`, `other`.
    * `linkedinbio` (string, optional): LinkedIn Bio.
    * `hs_linkedin_handle` (string, optional): LinkedIn handle.
    * `hs_live_enrichment_deadline` (string, optional): Live enrichment deadline.
    * `hs_logo_url` (string, optional): Logo URL.
    * `hs_analytics_source` (string, optional): Original Traffic Source.
    * `hs_pinned_engagement_id` (number, optional): Pinned Engagement ID.
    * `hs_quick_context` (string, optional): Quick context.
    * `hs_revenue_range` (string, optional): Revenue range.
    * `hs_state_code` (string, optional): State/Region Code.
    * `address` (string, optional): Street Address.
    * `address2` (string, optional): Street Address 2.
    * `hs_is_target_account` (boolean, optional): Target Account.
    * `hs_target_account` (string, optional): Target Account Tier. Available values: `tier_1`, `tier_2`, `tier_3`.
    * `hs_target_account_recommendation_snooze_time` (string, optional): Target Account Recommendation Snooze Time.
    * `hs_target_account_recommendation_state` (string, optional): Target Account Recommendation State. Available values: `DISMISSED`, `NONE`, `SNOOZED`.
    * `total_money_raised` (string, optional): Total Money Raised.
    * `twitterbio` (string, optional): Twitter Bio.
    * `twitterfollowers` (number, optional): Twitter Followers.
    * `twitterhandle` (string, optional): Twitter Handle.
    * `web_technologies` (string, optional): Web Technologies used. Must be one of the predefined values.
    * `website` (string, optional): Website URL.
    * `founded_year` (string, optional): Year Founded.
  </Accordion>

  <Accordion title="HUBSPOT_CREATE_RECORD_CONTACTS">
    **Description:** Create a new contact record in HubSpot.

    **Parameters:**

    * `email` (string, required): Email address of the contact.
    * `firstname` (string, optional): First Name.
    * `lastname` (string, optional): Last Name.
    * `phone` (string, optional): Phone Number.
    * `hubspot_owner_id` (string, optional): Contact owner.
    * `lifecyclestage` (string, optional): Lifecycle Stage. Available values: `subscriber`, `lead`, `marketingqualifiedlead`, `salesqualifiedlead`, `opportunity`, `customer`, `evangelist`, `other`.
    * `hs_lead_status` (string, optional): Lead Status. Available values: `NEW`, `OPEN`, `IN_PROGRESS`, `OPEN_DEAL`, `UNQUALIFIED`, `ATTEMPTED_TO_CONTACT`, `CONNECTED`, `BAD_TIMING`.
    * `annualrevenue` (string, optional): Annual Revenue.
    * `hs_buying_role` (string, optional): Buying Role.
    * `cc_emails` (string, optional): CC Emails.
    * `ch_customer_id` (string, optional): Chargify Customer ID.
    * `ch_customer_reference` (string, optional): Chargify Customer Reference.
    * `chargify_sites` (string, optional): Chargify Site(s).
    * `city` (string, optional): City.
    * `hs_facebook_ad_clicked` (boolean, optional): Clicked Facebook ad.
    * `hs_linkedin_ad_clicked` (string, optional): Clicked LinkedIn Ad.
    * `hs_clicked_linkedin_ad` (string, optional): Clicked on a LinkedIn Ad.
    * `closedate` (string, optional): Close Date.
    * `company` (string, optional): Company Name.
    * `company_size` (string, optional): Company size.
    * `country` (string, optional): Country/Region.
    * `hs_country_region_code` (string, optional): Country/Region Code.
    * `date_of_birth` (string, optional): Date of birth.
    * `degree` (string, optional): Degree.
    * `hs_email_customer_quarantined_reason` (string, optional): Email address quarantine reason.
    * `hs_role` (string, optional): Employment Role. Must be one of the predefined values.
    * `hs_seniority` (string, optional): Employment Seniority. Must be one of the predefined values.
    * `hs_sub_role` (string, optional): Employment Sub Role. Must be one of the predefined values.
    * `hs_employment_change_detected_date` (string, optional): Employment change detected date.
    * `hs_enriched_email_bounce_detected` (boolean, optional): Enriched Email Bounce Detected.
    * `hs_facebookid` (string, optional): Facebook ID.
    * `hs_facebook_click_id` (string, optional): Facebook click id.
    * `fax` (string, optional): Fax Number.
    * `field_of_study` (string, optional): Field of study.
    * `followercount` (number, optional): Follower Count.
    * `gender` (string, optional): Gender.
    * `hs_google_click_id` (string, optional): Google ad click id.
    * `graduation_date` (string, optional): Graduation date.
    * `owneremail` (string, optional): HubSpot Owner Email (legacy).
    * `ownername` (string, optional): HubSpot Owner Name (legacy).
    * `industry` (string, optional): Industry.
    * `hs_inferred_language_codes` (string, optional): Inferred Language Codes. Must be one of the predefined values.
    * `jobtitle` (string, optional): Job Title.
    * `hs_job_change_detected_date` (string, optional): Job change detected date.
    * `job_function` (string, optional): Job function.
    * `hs_journey_stage` (string, optional): Journey Stage. Must be one of the predefined values.
    * `kloutscoregeneral` (number, optional): Klout Score.
    * `hs_last_metered_enrichment_timestamp` (string, optional): Last Metered Enrichment Timestamp.
    * `hs_latest_source` (string, optional): Latest Traffic Source.
    * `hs_latest_source_timestamp` (string, optional): Latest Traffic Source Date.
    * `hs_legal_basis` (string, optional): Legal basis for processing contact's data.
    * `linkedinbio` (string, optional): LinkedIn Bio.
    * `linkedinconnections` (number, optional): LinkedIn Connections.
    * `hs_linkedin_url` (string, optional): LinkedIn URL.
    * `hs_linkedinid` (string, optional): Linkedin ID.
    * `hs_live_enrichment_deadline` (string, optional): Live enrichment deadline.
    * `marital_status` (string, optional): Marital Status.
    * `hs_content_membership_email` (string, optional): Member email.
    * `hs_content_membership_notes` (string, optional): Membership Notes.
    * `message` (string, optional): Message.
    * `military_status` (string, optional): Military status.
    * `mobilephone` (string, optional): Mobile Phone Number.
    * `numemployees` (string, optional): Number of Employees.
    * `hs_analytics_source` (string, optional): Original Traffic Source.
    * `photo` (string, optional): Photo.
    * `hs_pinned_engagement_id` (number, optional): Pinned engagement ID.
    * `zip` (string, optional): Postal Code.
    * `hs_language` (string, optional): Preferred language. Must be one of the predefined values.
    * `associatedcompanyid` (number, optional): Primary Associated Company ID.
    * `hs_email_optout_survey_reason` (string, optional): Reason for opting out of email.
    * `relationship_status` (string, optional): Relationship Status.
    * `hs_returning_to_office_detected_date` (string, optional): Returning to office detected date.
    * `salutation` (string, optional): Salutation.
    * `school` (string, optional): School.
    * `seniority` (string, optional): Seniority.
    * `hs_feedback_show_nps_web_survey` (boolean, optional): Should be shown an NPS web survey.
    * `start_date` (string, optional): Start date.
    * `state` (string, optional): State/Region.
    * `hs_state_code` (string, optional): State/Region Code.
    * `hs_content_membership_status` (string, optional): Status.
    * `address` (string, optional): Street Address.
    * `tax_exempt` (string, optional): Tax Exempt.
    * `hs_timezone` (string, optional): Time Zone. Must be one of the predefined values.
    * `twitterbio` (string, optional): Twitter Bio.
    * `hs_twitterid` (string, optional): Twitter ID.
    * `twitterprofilephoto` (string, optional): Twitter Profile Photo.
    * `twitterhandle` (string, optional): Twitter Username.
    * `vat_number` (string, optional): VAT Number.
    * `ch_verified` (string, optional): Verified for ACH/eCheck Payments.
    * `website` (string, optional): Website URL.
    * `hs_whatsapp_phone_number` (string, optional): WhatsApp Phone Number.
    * `work_email` (string, optional): Work email.
    * `hs_googleplusid` (string, optional): googleplus ID.
  </Accordion>

  <Accordion title="HUBSPOT_CREATE_RECORD_DEALS">
    **Description:** Create a new deal record in HubSpot.

    **Parameters:**

    * `dealname` (string, required): Name of the deal.
    * `amount` (number, optional): The value of the deal.
    * `dealstage` (string, optional): The pipeline stage of the deal.
    * `pipeline` (string, optional): The pipeline the deal belongs to.
    * `closedate` (string, optional): The date the deal is expected to close.
    * `hubspot_owner_id` (string, optional): The owner of the deal.
    * `dealtype` (string, optional): The type of deal. Available values: `newbusiness`, `existingbusiness`.
    * `description` (string, optional): A description of the deal.
    * `hs_priority` (string, optional): The priority of the deal. Available values: `low`, `medium`, `high`.
  </Accordion>

  <Accordion title="HUBSPOT_CREATE_RECORD_ENGAGEMENTS">
    **Description:** Create a new engagement (e.g., note, email, call, meeting, task) in HubSpot.

    **Parameters:**

    * `engagementType` (string, required): The type of engagement. Available values: `NOTE`, `EMAIL`, `CALL`, `MEETING`, `TASK`.
    * `hubspot_owner_id` (string, optional): The user the activity is assigned to.
    * `hs_timestamp` (string, optional): The date and time of the activity.
    * `hs_note_body` (string, optional): The body of the note. (Used for `NOTE`)
    * `hs_task_subject` (string, optional): The title of the task. (Used for `TASK`)
    * `hs_task_body` (string, optional): The notes for the task. (Used for `TASK`)
    * `hs_task_status` (string, optional): The status of the task. (Used for `TASK`)
    * `hs_meeting_title` (string, optional): The title of the meeting. (Used for `MEETING`)
    * `hs_meeting_body` (string, optional): The description for the meeting. (Used for `MEETING`)
    * `hs_meeting_start_time` (string, optional): The start time of the meeting. (Used for `MEETING`)
    * `hs_meeting_end_time` (string, optional): The end time of the meeting. (Used for `MEETING`)
  </Accordion>

  <Accordion title="HUBSPOT_UPDATE_RECORD_COMPANIES">
    **Description:** Update an existing company record in HubSpot.

    **Parameters:**

    * `recordId` (string, required): The ID of the company to update.
    * `name` (string, optional): Name of the company.
    * `domain` (string, optional): Company Domain Name.
    * `industry` (string, optional): Industry.
    * `phone` (string, optional): Phone Number.
    * `city` (string, optional): City.
    * `state` (string, optional): State/Region.
    * `zip` (string, optional): Postal Code.
    * `numberofemployees` (number, optional): Number of Employees.
    * `annualrevenue` (number, optional): Annual Revenue.
    * `description` (string, optional): Description.
  </Accordion>

  <Accordion title="HUBSPOT_CREATE_RECORD_ANY">
    **Description:** Create a record for a specified object type in HubSpot.

    **Parameters:**

    * `recordType` (string, required): The object type ID of the custom object.
    * Additional parameters depend on the custom object's schema.
  </Accordion>

  <Accordion title="HUBSPOT_UPDATE_RECORD_CONTACTS">
    **Description:** Update an existing contact record in HubSpot.

    **Parameters:**

    * `recordId` (string, required): The ID of the contact to update.
    * `firstname` (string, optional): First Name.
    * `lastname` (string, optional): Last Name.
    * `email` (string, optional): Email address.
    * `phone` (string, optional): Phone Number.
    * `company` (string, optional): Company Name.
    * `jobtitle` (string, optional): Job Title.
    * `lifecyclestage` (string, optional): Lifecycle Stage.
  </Accordion>

  <Accordion title="HUBSPOT_UPDATE_RECORD_DEALS">
    **Description:** Update an existing deal record in HubSpot.

    **Parameters:**

    * `recordId` (string, required): The ID of the deal to update.
    * `dealname` (string, optional): Name of the deal.
    * `amount` (number, optional): The value of the deal.
    * `dealstage` (string, optional): The pipeline stage of the deal.
    * `pipeline` (string, optional): The pipeline the deal belongs to.
    * `closedate` (string, optional): The date the deal is expected to close.
    * `dealtype` (string, optional): The type of deal.
  </Accordion>

  <Accordion title="HUBSPOT_UPDATE_RECORD_ENGAGEMENTS">
    **Description:** Update an existing engagement in HubSpot.

    **Parameters:**

    * `recordId` (string, required): The ID of the engagement to update.
    * `hs_note_body` (string, optional): The body of the note.
    * `hs_task_subject` (string, optional): The title of the task.
    * `hs_task_body` (string, optional): The notes for the task.
    * `hs_task_status` (string, optional): The status of the task.
  </Accordion>

  <Accordion title="HUBSPOT_UPDATE_RECORD_ANY">
    **Description:** Update a record for a specified object type in HubSpot.

    **Parameters:**

    * `recordId` (string, required): The ID of the record to update.
    * `recordType` (string, required): The object type ID of the custom object.
    * Additional parameters depend on the custom object's schema.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORDS_COMPANIES">
    **Description:** Get a list of company records from HubSpot.

    **Parameters:**

    * `paginationParameters` (object, optional): Use `pageCursor` to fetch subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORDS_CONTACTS">
    **Description:** Get a list of contact records from HubSpot.

    **Parameters:**

    * `paginationParameters` (object, optional): Use `pageCursor` to fetch subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORDS_DEALS">
    **Description:** Get a list of deal records from HubSpot.

    **Parameters:**

    * `paginationParameters` (object, optional): Use `pageCursor` to fetch subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORDS_ENGAGEMENTS">
    **Description:** Get a list of engagement records from HubSpot.

    **Parameters:**

    * `objectName` (string, required): The type of engagement to fetch (e.g., "notes").
    * `paginationParameters` (object, optional): Use `pageCursor` to fetch subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORDS_ANY">
    **Description:** Get a list of records for any specified object type in HubSpot.

    **Parameters:**

    * `recordType` (string, required): The object type ID of the custom object.
    * `paginationParameters` (object, optional): Use `pageCursor` to fetch subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORD_BY_ID_COMPANIES">
    **Description:** Get a single company record by its ID.

    **Parameters:**

    * `recordId` (string, required): The ID of the company to retrieve.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORD_BY_ID_CONTACTS">
    **Description:** Get a single contact record by its ID.

    **Parameters:**

    * `recordId` (string, required): The ID of the contact to retrieve.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORD_BY_ID_DEALS">
    **Description:** Get a single deal record by its ID.

    **Parameters:**

    * `recordId` (string, required): The ID of the deal to retrieve.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORD_BY_ID_ENGAGEMENTS">
    **Description:** Get a single engagement record by its ID.

    **Parameters:**

    * `recordId` (string, required): The ID of the engagement to retrieve.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORD_BY_ID_ANY">
    **Description:** Get a single record of any specified object type by its ID.

    **Parameters:**

    * `recordType` (string, required): The object type ID of the custom object.
    * `recordId` (string, required): The ID of the record to retrieve.
  </Accordion>

  <Accordion title="HUBSPOT_SEARCH_RECORDS_COMPANIES">
    **Description:** Search for company records in HubSpot using a filter formula.

    **Parameters:**

    * `filterFormula` (object, optional): A filter in disjunctive normal form (OR of ANDs).
    * `paginationParameters` (object, optional): Use `pageCursor` to fetch subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_SEARCH_RECORDS_CONTACTS">
    **Description:** Search for contact records in HubSpot using a filter formula.

    **Parameters:**

    * `filterFormula` (object, optional): A filter in disjunctive normal form (OR of ANDs).
    * `paginationParameters` (object, optional): Use `pageCursor` to fetch subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_SEARCH_RECORDS_DEALS">
    **Description:** Search for deal records in HubSpot using a filter formula.

    **Parameters:**

    * `filterFormula` (object, optional): A filter in disjunctive normal form (OR of ANDs).
    * `paginationParameters` (object, optional): Use `pageCursor` to fetch subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_SEARCH_RECORDS_ENGAGEMENTS">
    **Description:** Search for engagement records in HubSpot using a filter formula.

    **Parameters:**

    * `engagementFilterFormula` (object, optional): A filter for engagements.
    * `paginationParameters` (object, optional): Use `pageCursor` to fetch subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_SEARCH_RECORDS_ANY">
    **Description:** Search for records of any specified object type in HubSpot.

    **Parameters:**

    * `recordType` (string, required): The object type ID to search.
    * `filterFormula` (string, optional): The filter formula to apply.
    * `paginationParameters` (object, optional): Use `pageCursor` to fetch subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_DELETE_RECORD_COMPANIES">
    **Description:** Delete a company record by its ID.

    **Parameters:**

    * `recordId` (string, required): The ID of the company to delete.
  </Accordion>

  <Accordion title="HUBSPOT_DELETE_RECORD_CONTACTS">
    **Description:** Delete a contact record by its ID.

    **Parameters:**

    * `recordId` (string, required): The ID of the contact to delete.
  </Accordion>

  <Accordion title="HUBSPOT_DELETE_RECORD_DEALS">
    **Description:** Delete a deal record by its ID.

    **Parameters:**

    * `recordId` (string, required): The ID of the deal to delete.
  </Accordion>

  <Accordion title="HUBSPOT_DELETE_RECORD_ENGAGEMENTS">
    **Description:** Delete an engagement record by its ID.

    **Parameters:**

    * `recordId` (string, required): The ID of the engagement to delete.
  </Accordion>

  <Accordion title="HUBSPOT_DELETE_RECORD_ANY">
    **Description:** Delete a record of any specified object type by its ID.

    **Parameters:**

    * `recordType` (string, required): The object type ID of the custom object.
    * `recordId` (string, required): The ID of the record to delete.
  </Accordion>

  <Accordion title="HUBSPOT_GET_CONTACTS_BY_LIST_ID">
    **Description:** Get contacts from a specific list by its ID.

    **Parameters:**

    * `listId` (string, required): The ID of the list to get contacts from.
    * `paginationParameters` (object, optional): Use `pageCursor` for subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_DESCRIBE_ACTION_SCHEMA">
    **Description:** Get the expected schema for a given object type and operation.

    **Parameters:**

    * `recordType` (string, required): The object type ID (e.g., 'companies').
    * `operation` (string, required): The operation type (e.g., 'CREATE\_RECORD').
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic HubSpot Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (HubSpot tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with HubSpot capabilities
hubspot_agent = Agent(
    role="CRM Manager",
    goal="Manage company and contact records in HubSpot",
    backstory="An AI assistant specialized in CRM management.",
    tools=[enterprise_tools]
)

# Task to create a new company
create_company_task = Task(
    description="Create a new company in HubSpot with name 'Innovate Corp' and domain 'innovatecorp.com'.",
    agent=hubspot_agent,
    expected_output="Company created successfully with confirmation"
)

# Run the task
crew = Crew(
    agents=[hubspot_agent],
    tasks=[create_company_task]
)

crew.kickoff()
```

### Filtering Specific HubSpot Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only the tool to create contacts
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["hubspot_create_record_contacts"]
)

contact_creator = Agent(
    role="Contact Creator",
    goal="Create new contacts in HubSpot",
    backstory="An AI assistant that focuses on creating new contact entries in the CRM.",
    tools=[enterprise_tools]
)

# Task to create a contact
create_contact = Task(
    description="Create a new contact for 'John Doe' with email 'john.doe@example.com'.",
    agent=contact_creator,
    expected_output="Contact created successfully in HubSpot."
)

crew = Crew(
    agents=[contact_creator],
    tasks=[create_contact]
)

crew.kickoff()
```

### Contact Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

crm_manager = Agent(
    role="CRM Manager",
    goal="Manage and organize HubSpot contacts efficiently.",
    backstory="An experienced CRM manager who maintains an organized contact database.",
    tools=[enterprise_tools]
)

# Task to manage contacts
contact_task = Task(
    description="Create a new contact for 'Jane Smith' at 'Global Tech Inc.' with email 'jane.smith@globaltech.com'.",
    agent=crm_manager,
    expected_output="Contact database updated with the new contact."
)

crew = Crew(
    agents=[crm_manager],
    tasks=[contact_task]
)

crew.kickoff()
```

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with HubSpot integration setup or troubleshooting.
</Card>


# Jira Integration
Source: https://docs.crewai.com/en/enterprise/integrations/jira

Issue tracking and project management with Jira integration for CrewAI.

## Overview

Enable your agents to manage issues, projects, and workflows through Jira. Create and update issues, track project progress, manage assignments, and streamline your project management with AI-powered automation.

## Prerequisites

Before using the Jira integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Jira account with appropriate project permissions
* Connected your Jira account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors)

## Setting Up Jira Integration

### 1. Connect Your Jira Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors)
2. Find **Jira** in the Authentication Integrations section
3. Click **Connect** and complete the OAuth flow
4. Grant the necessary permissions for issue and project management
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account)

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="JIRA_CREATE_ISSUE">
    **Description:** Create an issue in Jira.

    **Parameters:**

    * `summary` (string, required): Summary - A brief one-line summary of the issue. (example: "The printer stopped working").
    * `project` (string, optional): Project - The project which the issue belongs to. Defaults to the user's first project if not provided. Use Connect Portal Workflow Settings to allow users to select a Project.
    * `issueType` (string, optional): Issue type - Defaults to Task if not provided.
    * `jiraIssueStatus` (string, optional): Status - Defaults to the project's first status if not provided.
    * `assignee` (string, optional): Assignee - Defaults to the authenticated user if not provided.
    * `descriptionType` (string, optional): Description Type - Select the Description Type.
      * Options: `description`, `descriptionJSON`
    * `description` (string, optional): Description - A detailed description of the issue. This field appears only when 'descriptionType' = 'description'.
    * `additionalFields` (string, optional): Additional Fields - Specify any other fields that should be included in JSON format. Use Connect Portal Workflow Settings to allow users to select which Issue Fields to update.
      ```json
      {
        "customfield_10001": "value"
      }
      ```
  </Accordion>

  <Accordion title="JIRA_UPDATE_ISSUE">
    **Description:** Update an issue in Jira.

    **Parameters:**

    * `issueKey` (string, required): Issue Key (example: "TEST-1234").
    * `summary` (string, optional): Summary - A brief one-line summary of the issue. (example: "The printer stopped working").
    * `issueType` (string, optional): Issue type - Use Connect Portal Workflow Settings to allow users to select an Issue Type.
    * `jiraIssueStatus` (string, optional): Status - Use Connect Portal Workflow Settings to allow users to select a Status.
    * `assignee` (string, optional): Assignee - Use Connect Portal Workflow Settings to allow users to select an Assignee.
    * `descriptionType` (string, optional): Description Type - Select the Description Type.
      * Options: `description`, `descriptionJSON`
    * `description` (string, optional): Description - A detailed description of the issue. This field appears only when 'descriptionType' = 'description'.
    * `additionalFields` (string, optional): Additional Fields - Specify any other fields that should be included in JSON format.
  </Accordion>

  <Accordion title="JIRA_GET_ISSUE_BY_KEY">
    **Description:** Get an issue by key in Jira.

    **Parameters:**

    * `issueKey` (string, required): Issue Key (example: "TEST-1234").
  </Accordion>

  <Accordion title="JIRA_FILTER_ISSUES">
    **Description:** Search issues in Jira using filters.

    **Parameters:**

    * `jqlQuery` (object, optional): A filter in disjunctive normal form - OR of AND groups of single conditions.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "status",
                "operator": "$stringExactlyMatches",
                "value": "Open"
              }
            ]
          }
        ]
      }
      ```
      Available operators: `$stringExactlyMatches`, `$stringDoesNotExactlyMatch`, `$stringIsIn`, `$stringIsNotIn`, `$stringContains`, `$stringDoesNotContain`, `$stringGreaterThan`, `$stringLessThan`
    * `limit` (string, optional): Limit results - Limit the maximum number of issues to return. Defaults to 10 if left blank.
  </Accordion>

  <Accordion title="JIRA_SEARCH_BY_JQL">
    **Description:** Search issues by JQL in Jira.

    **Parameters:**

    * `jqlQuery` (string, required): JQL Query (example: "project = PROJECT").
    * `paginationParameters` (object, optional): Pagination parameters for paginated results.
      ```json
      {
        "pageCursor": "cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="JIRA_UPDATE_ISSUE_ANY">
    **Description:** Update any issue in Jira. Use DESCRIBE\_ACTION\_SCHEMA to get properties schema for this function.

    **Parameters:** No specific parameters - use JIRA\_DESCRIBE\_ACTION\_SCHEMA first to get the expected schema.
  </Accordion>

  <Accordion title="JIRA_DESCRIBE_ACTION_SCHEMA">
    **Description:** Get the expected schema for an issue type. Use this function first if no other function matches the issue type you want to operate on.

    **Parameters:**

    * `issueTypeId` (string, required): Issue Type ID.
    * `projectKey` (string, required): Project key.
    * `operation` (string, required): Operation Type value, for example CREATE\_ISSUE or UPDATE\_ISSUE.
  </Accordion>

  <Accordion title="JIRA_GET_PROJECTS">
    **Description:** Get Projects in Jira.

    **Parameters:**

    * `paginationParameters` (object, optional): Pagination Parameters.
      ```json
      {
        "pageCursor": "cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="JIRA_GET_ISSUE_TYPES_BY_PROJECT">
    **Description:** Get Issue Types by project in Jira.

    **Parameters:**

    * `project` (string, required): Project key.
  </Accordion>

  <Accordion title="JIRA_GET_ISSUE_TYPES">
    **Description:** Get all Issue Types in Jira.

    **Parameters:** None required.
  </Accordion>

  <Accordion title="JIRA_GET_ISSUE_STATUS_BY_PROJECT">
    **Description:** Get issue statuses for a given project.

    **Parameters:**

    * `project` (string, required): Project key.
  </Accordion>

  <Accordion title="JIRA_GET_ALL_ASSIGNEES_BY_PROJECT">
    **Description:** Get assignees for a given project.

    **Parameters:**

    * `project` (string, required): Project key.
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Jira Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Jira tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Jira capabilities
jira_agent = Agent(
    role="Issue Manager",
    goal="Manage Jira issues and track project progress efficiently",
    backstory="An AI assistant specialized in issue tracking and project management.",
    tools=[enterprise_tools]
)

# Task to create a bug report
create_bug_task = Task(
    description="Create a bug report for the login functionality with high priority and assign it to the development team",
    agent=jira_agent,
    expected_output="Bug report created successfully with issue key"
)

# Run the task
crew = Crew(
    agents=[jira_agent],
    tasks=[create_bug_task]
)

crew.kickoff()
```

### Filtering Specific Jira Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Jira tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["jira_create_issue", "jira_update_issue", "jira_search_by_jql"]
)

issue_coordinator = Agent(
    role="Issue Coordinator",
    goal="Create and manage Jira issues efficiently",
    backstory="An AI assistant that focuses on issue creation and management.",
    tools=enterprise_tools
)

# Task to manage issue workflow
issue_workflow = Task(
    description="Create a feature request issue and update the status of related issues",
    agent=issue_coordinator,
    expected_output="Feature request created and related issues updated"
)

crew = Crew(
    agents=[issue_coordinator],
    tasks=[issue_workflow]
)

crew.kickoff()
```

### Project Analysis and Reporting

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

project_analyst = Agent(
    role="Project Analyst",
    goal="Analyze project data and generate insights from Jira",
    backstory="An experienced project analyst who extracts insights from project management data.",
    tools=[enterprise_tools]
)

# Task to analyze project status
analysis_task = Task(
    description="""
    1. Get all projects and their issue types
    2. Search for all open issues across projects
    3. Analyze issue distribution by status and assignee
    4. Create a summary report issue with findings
    """,
    agent=project_analyst,
    expected_output="Project analysis completed with summary report created"
)

crew = Crew(
    agents=[project_analyst],
    tasks=[analysis_task]
)

crew.kickoff()
```

### Automated Issue Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

automation_manager = Agent(
    role="Automation Manager",
    goal="Automate issue management and workflow processes",
    backstory="An AI assistant that automates repetitive issue management tasks.",
    tools=[enterprise_tools]
)

# Task to automate issue management
automation_task = Task(
    description="""
    1. Search for all unassigned issues using JQL
    2. Get available assignees for each project
    3. Automatically assign issues based on workload and expertise
    4. Update issue priorities based on age and type
    5. Create weekly sprint planning issues
    """,
    agent=automation_manager,
    expected_output="Issues automatically assigned and sprint planning issues created"
)

crew = Crew(
    agents=[automation_manager],
    tasks=[automation_task]
)

crew.kickoff()
```

### Advanced Schema-Based Operations

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

schema_specialist = Agent(
    role="Schema Specialist",
    goal="Handle complex Jira operations using dynamic schemas",
    backstory="An AI assistant that can work with dynamic Jira schemas and custom issue types.",
    tools=[enterprise_tools]
)

# Task using schema-based operations
schema_task = Task(
    description="""
    1. Get all projects and their custom issue types
    2. For each custom issue type, describe the action schema
    3. Create issues using the dynamic schema for complex custom fields
    4. Update issues with custom field values based on business rules
    """,
    agent=schema_specialist,
    expected_output="Custom issues created and updated using dynamic schemas"
)

crew = Crew(
    agents=[schema_specialist],
    tasks=[schema_task]
)

crew.kickoff()
```

## Troubleshooting

### Common Issues

**Permission Errors**

* Ensure your Jira account has necessary permissions for the target projects
* Verify that the OAuth connection includes required scopes for Jira API
* Check if you have create/edit permissions for issues in the specified projects

**Invalid Project or Issue Keys**

* Double-check project keys and issue keys for correct format (e.g., "PROJ-123")
* Ensure projects exist and are accessible to your account
* Verify that issue keys reference existing issues

**Issue Type and Status Issues**

* Use JIRA\_GET\_ISSUE\_TYPES\_BY\_PROJECT to get valid issue types for a project
* Use JIRA\_GET\_ISSUE\_STATUS\_BY\_PROJECT to get valid statuses
* Ensure issue types and statuses are available in the target project

**JQL Query Problems**

* Test JQL queries in Jira's issue search before using in API calls
* Ensure field names in JQL are spelled correctly and exist in your Jira instance
* Use proper JQL syntax for complex queries

**Custom Fields and Schema Issues**

* Use JIRA\_DESCRIBE\_ACTION\_SCHEMA to get the correct schema for complex issue types
* Ensure custom field IDs are correct (e.g., "customfield\_10001")
* Verify that custom fields are available in the target project and issue type

**Filter Formula Issues**

* Ensure filter formulas follow the correct JSON structure for disjunctive normal form
* Use valid field names that exist in your Jira configuration
* Test simple filters before building complex multi-condition queries

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with Jira integration setup or troubleshooting.
</Card>


# Linear Integration
Source: https://docs.crewai.com/en/enterprise/integrations/linear

Software project and bug tracking with Linear integration for CrewAI.

## Overview

Enable your agents to manage issues, projects, and development workflows through Linear. Create and update issues, manage project timelines, organize teams, and streamline your software development process with AI-powered automation.

## Prerequisites

Before using the Linear integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Linear account with appropriate workspace permissions
* Connected your Linear account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors)

## Setting Up Linear Integration

### 1. Connect Your Linear Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors)
2. Find **Linear** in the Authentication Integrations section
3. Click **Connect** and complete the OAuth flow
4. Grant the necessary permissions for issue and project management
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account)

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="LINEAR_CREATE_ISSUE">
    **Description:** Create a new issue in Linear.

    **Parameters:**

    * `teamId` (string, required): Team ID - Specify the Team ID of the parent for this new issue. Use Connect Portal Workflow Settings to allow users to select a Team ID. (example: "a70bdf0f-530a-4887-857d-46151b52b47c").
    * `title` (string, required): Title - Specify a title for this issue.
    * `description` (string, optional): Description - Specify a description for this issue.
    * `statusId` (string, optional): Status - Specify the state or status of this issue.
    * `priority` (string, optional): Priority - Specify the priority of this issue as an integer.
    * `dueDate` (string, optional): Due Date - Specify the due date of this issue in ISO 8601 format.
    * `cycleId` (string, optional): Cycle ID - Specify the cycle associated with this issue.
    * `additionalFields` (object, optional): Additional Fields.
      ```json
      {
        "assigneeId": "a70bdf0f-530a-4887-857d-46151b52b47c",
        "labelIds": ["a70bdf0f-530a-4887-857d-46151b52b47c"]
      }
      ```
  </Accordion>

  <Accordion title="LINEAR_UPDATE_ISSUE">
    **Description:** Update an issue in Linear.

    **Parameters:**

    * `issueId` (string, required): Issue ID - Specify the Issue ID of the issue to update. (example: "90fbc706-18cd-42c9-ae66-6bd344cc8977").
    * `title` (string, optional): Title - Specify a title for this issue.
    * `description` (string, optional): Description - Specify a description for this issue.
    * `statusId` (string, optional): Status - Specify the state or status of this issue.
    * `priority` (string, optional): Priority - Specify the priority of this issue as an integer.
    * `dueDate` (string, optional): Due Date - Specify the due date of this issue in ISO 8601 format.
    * `cycleId` (string, optional): Cycle ID - Specify the cycle associated with this issue.
    * `additionalFields` (object, optional): Additional Fields.
      ```json
      {
        "assigneeId": "a70bdf0f-530a-4887-857d-46151b52b47c",
        "labelIds": ["a70bdf0f-530a-4887-857d-46151b52b47c"]
      }
      ```
  </Accordion>

  <Accordion title="LINEAR_GET_ISSUE_BY_ID">
    **Description:** Get an issue by ID in Linear.

    **Parameters:**

    * `issueId` (string, required): Issue ID - Specify the record ID of the issue to fetch. (example: "90fbc706-18cd-42c9-ae66-6bd344cc8977").
  </Accordion>

  <Accordion title="LINEAR_GET_ISSUE_BY_ISSUE_IDENTIFIER">
    **Description:** Get an issue by issue identifier in Linear.

    **Parameters:**

    * `externalId` (string, required): External ID - Specify the human-readable Issue identifier of the issue to fetch. (example: "ABC-1").
  </Accordion>

  <Accordion title="LINEAR_SEARCH_ISSUE">
    **Description:** Search issues in Linear.

    **Parameters:**

    * `queryTerm` (string, required): Query Term - The search term to look for.
    * `issueFilterFormula` (object, optional): A filter in disjunctive normal form - OR of AND groups of single conditions.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "title",
                "operator": "$stringContains",
                "value": "bug"
              }
            ]
          }
        ]
      }
      ```
      Available fields: `title`, `number`, `project`, `createdAt`
      Available operators: `$stringExactlyMatches`, `$stringDoesNotExactlyMatch`, `$stringIsIn`, `$stringIsNotIn`, `$stringStartsWith`, `$stringDoesNotStartWith`, `$stringEndsWith`, `$stringDoesNotEndWith`, `$stringContains`, `$stringDoesNotContain`, `$stringGreaterThan`, `$stringLessThan`, `$numberGreaterThanOrEqualTo`, `$numberLessThanOrEqualTo`, `$numberGreaterThan`, `$numberLessThan`, `$dateTimeAfter`, `$dateTimeBefore`
  </Accordion>

  <Accordion title="LINEAR_DELETE_ISSUE">
    **Description:** Delete an issue in Linear.

    **Parameters:**

    * `issueId` (string, required): Issue ID - Specify the record ID of the issue to delete. (example: "90fbc706-18cd-42c9-ae66-6bd344cc8977").
  </Accordion>

  <Accordion title="LINEAR_ARCHIVE_ISSUE">
    **Description:** Archive an issue in Linear.

    **Parameters:**

    * `issueId` (string, required): Issue ID - Specify the record ID of the issue to archive. (example: "90fbc706-18cd-42c9-ae66-6bd344cc8977").
  </Accordion>

  <Accordion title="LINEAR_CREATE_SUB_ISSUE">
    **Description:** Create a sub-issue in Linear.

    **Parameters:**

    * `parentId` (string, required): Parent ID - Specify the Issue ID for the parent of this new issue.
    * `teamId` (string, required): Team ID - Specify the Team ID of the parent for this new sub-issue. Use Connect Portal Workflow Settings to allow users to select a Team ID. (example: "a70bdf0f-530a-4887-857d-46151b52b47c").
    * `title` (string, required): Title - Specify a title for this issue.
    * `description` (string, optional): Description - Specify a description for this issue.
    * `additionalFields` (object, optional): Additional Fields.
      ```json
      {
        "lead": "linear_user_id"
      }
      ```
  </Accordion>

  <Accordion title="LINEAR_CREATE_PROJECT">
    **Description:** Create a new project in Linear.

    **Parameters:**

    * `teamIds` (object, required): Team ID - Specify the team ID(s) this project is associated with as a string or a JSON array. Use Connect Portal User Settings to allow your user to select a Team ID.
      ```json
      [
        "a70bdf0f-530a-4887-857d-46151b52b47c",
        "4ac7..."
      ]
      ```
    * `projectName` (string, required): Project Name - Specify the name of the project. (example: "My Linear Project").
    * `description` (string, optional): Project Description - Specify a description for this project.
    * `additionalFields` (object, optional): Additional Fields.
      ```json
      {
        "state": "planned",
        "description": ""
      }
      ```
  </Accordion>

  <Accordion title="LINEAR_UPDATE_PROJECT">
    **Description:** Update a project in Linear.

    **Parameters:**

    * `projectId` (string, required): Project ID - Specify the ID of the project to update. (example: "a6634484-6061-4ac7-9739-7dc5e52c796b").
    * `projectName` (string, optional): Project Name - Specify the name of the project to update. (example: "My Linear Project").
    * `description` (string, optional): Project Description - Specify a description for this project.
    * `additionalFields` (object, optional): Additional Fields.
      ```json
      {
        "state": "planned",
        "description": ""
      }
      ```
  </Accordion>

  <Accordion title="LINEAR_GET_PROJECT_BY_ID">
    **Description:** Get a project by ID in Linear.

    **Parameters:**

    * `projectId` (string, required): Project ID - Specify the Project ID of the project to fetch. (example: "a6634484-6061-4ac7-9739-7dc5e52c796b").
  </Accordion>

  <Accordion title="LINEAR_DELETE_PROJECT">
    **Description:** Delete a project in Linear.

    **Parameters:**

    * `projectId` (string, required): Project ID - Specify the Project ID of the project to delete. (example: "a6634484-6061-4ac7-9739-7dc5e52c796b").
  </Accordion>

  <Accordion title="LINEAR_SEARCH_TEAMS">
    **Description:** Search teams in Linear.

    **Parameters:**

    * `teamFilterFormula` (object, optional): A filter in disjunctive normal form - OR of AND groups of single conditions.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "name",
                "operator": "$stringContains",
                "value": "Engineering"
              }
            ]
          }
        ]
      }
      ```
      Available fields: `id`, `name`
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Linear Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Linear tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Linear capabilities
linear_agent = Agent(
    role="Development Manager",
    goal="Manage Linear issues and track development progress efficiently",
    backstory="An AI assistant specialized in software development project management.",
    tools=[enterprise_tools]
)

# Task to create a bug report
create_bug_task = Task(
    description="Create a high-priority bug report for the authentication system and assign it to the backend team",
    agent=linear_agent,
    expected_output="Bug report created successfully with issue ID"
)

# Run the task
crew = Crew(
    agents=[linear_agent],
    tasks=[create_bug_task]
)

crew.kickoff()
```

### Filtering Specific Linear Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Linear tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["linear_create_issue", "linear_update_issue", "linear_search_issue"]
)

issue_manager = Agent(
    role="Issue Manager",
    goal="Create and manage Linear issues efficiently",
    backstory="An AI assistant that focuses on issue creation and lifecycle management.",
    tools=enterprise_tools
)

# Task to manage issue workflow
issue_workflow = Task(
    description="Create a feature request issue and update the status of related issues to reflect current progress",
    agent=issue_manager,
    expected_output="Feature request created and related issues updated"
)

crew = Crew(
    agents=[issue_manager],
    tasks=[issue_workflow]
)

crew.kickoff()
```

### Project and Team Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

project_coordinator = Agent(
    role="Project Coordinator",
    goal="Coordinate projects and teams in Linear efficiently",
    backstory="An experienced project coordinator who manages development cycles and team workflows.",
    tools=[enterprise_tools]
)

# Task to coordinate project setup
project_coordination = Task(
    description="""
    1. Search for engineering teams in Linear
    2. Create a new project for Q2 feature development
    3. Associate the project with relevant teams
    4. Create initial project milestones as issues
    """,
    agent=project_coordinator,
    expected_output="Q2 project created with teams assigned and initial milestones established"
)

crew = Crew(
    agents=[project_coordinator],
    tasks=[project_coordination]
)

crew.kickoff()
```

### Issue Hierarchy and Sub-task Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

task_organizer = Agent(
    role="Task Organizer",
    goal="Organize complex issues into manageable sub-tasks",
    backstory="An AI assistant that breaks down complex development work into organized sub-tasks.",
    tools=[enterprise_tools]
)

# Task to create issue hierarchy
hierarchy_task = Task(
    description="""
    1. Search for large feature issues that need to be broken down
    2. For each complex issue, create sub-issues for different components
    3. Update the parent issues with proper descriptions and links to sub-issues
    4. Assign sub-issues to appropriate team members based on expertise
    """,
    agent=task_organizer,
    expected_output="Complex issues broken down into manageable sub-tasks with proper assignments"
)

crew = Crew(
    agents=[task_organizer],
    tasks=[hierarchy_task]
)

crew.kickoff()
```

### Automated Development Workflow

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

workflow_automator = Agent(
    role="Workflow Automator",
    goal="Automate development workflow processes in Linear",
    backstory="An AI assistant that automates repetitive development workflow tasks.",
    tools=[enterprise_tools]
)

# Complex workflow automation task
automation_task = Task(
    description="""
    1. Search for issues that have been in progress for more than 7 days
    2. Update their priorities based on due dates and project importance
    3. Create weekly sprint planning issues for each team
    4. Archive completed issues from the previous cycle
    5. Generate project status reports as new issues
    """,
    agent=workflow_automator,
    expected_output="Development workflow automated with updated priorities, sprint planning, and status reports"
)

crew = Crew(
    agents=[workflow_automator],
    tasks=[automation_task]
)

crew.kickoff()
```

## Troubleshooting

### Common Issues

**Permission Errors**

* Ensure your Linear account has necessary permissions for the target workspace
* Verify that the OAuth connection includes required scopes for Linear API
* Check if you have create/edit permissions for issues and projects in the workspace

**Invalid IDs and References**

* Double-check team IDs, issue IDs, and project IDs for correct UUID format
* Ensure referenced entities (teams, projects, cycles) exist and are accessible
* Verify that issue identifiers follow the correct format (e.g., "ABC-1")

**Team and Project Association Issues**

* Use LINEAR\_SEARCH\_TEAMS to get valid team IDs before creating issues or projects
* Ensure teams exist and are active in your workspace
* Verify that team IDs are properly formatted as UUIDs

**Issue Status and Priority Problems**

* Check that status IDs reference valid workflow states for the team
* Ensure priority values are within the valid range for your Linear configuration
* Verify that custom fields and labels exist before referencing them

**Date and Time Format Issues**

* Use ISO 8601 format for due dates and timestamps
* Ensure time zones are handled correctly for due date calculations
* Verify that date values are valid and in the future for due dates

**Search and Filter Issues**

* Ensure search queries are properly formatted and not empty
* Use valid field names in filter formulas: `title`, `number`, `project`, `createdAt`
* Test simple filters before building complex multi-condition queries
* Verify that operator types match the data types of the fields being filtered

**Sub-issue Creation Problems**

* Ensure parent issue IDs are valid and accessible
* Verify that the team ID for sub-issues matches or is compatible with the parent issue's team
* Check that parent issues are not already archived or deleted

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with Linear integration setup or troubleshooting.
</Card>


# Notion Integration
Source: https://docs.crewai.com/en/enterprise/integrations/notion

Page and database management with Notion integration for CrewAI.

## Overview

Enable your agents to manage pages, databases, and content through Notion. Create and update pages, manage content blocks, organize knowledge bases, and streamline your documentation workflows with AI-powered automation.

## Prerequisites

Before using the Notion integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Notion account with appropriate workspace permissions
* Connected your Notion account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors)

## Setting Up Notion Integration

### 1. Connect Your Notion Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors)
2. Find **Notion** in the Authentication Integrations section
3. Click **Connect** and complete the OAuth flow
4. Grant the necessary permissions for page and database management
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account)

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="NOTION_CREATE_PAGE">
    **Description:** Create a page in Notion.

    **Parameters:**

    * `parent` (object, required): Parent - The parent page or database where the new page is inserted, represented as a JSON object with a page\_id or database\_id key.
      ```json
      {
        "database_id": "DATABASE_ID"
      }
      ```
    * `properties` (object, required): Properties - The values of the page's properties. If the parent is a database, then the schema must match the parent database's properties.
      ```json
      {
        "title": [
          {
            "text": {
              "content": "My Page"
            }
          }
        ]
      }
      ```
    * `icon` (object, required): Icon - The page icon.
      ```json
      {
        "emoji": "🥬"
      }
      ```
    * `children` (object, optional): Children - Content blocks to add to the page.
      ```json
      [
        {
          "object": "block",
          "type": "heading_2",
          "heading_2": {
            "rich_text": [
              {
                "type": "text",
                "text": {
                  "content": "Lacinato kale"
                }
              }
            ]
          }
        }
      ]
      ```
    * `cover` (object, optional): Cover - The page cover image.
      ```json
      {
        "external": {
          "url": "https://upload.wikimedia.org/wikipedia/commons/6/62/Tuscankale.jpg"
        }
      }
      ```
  </Accordion>

  <Accordion title="NOTION_UPDATE_PAGE">
    **Description:** Update a page in Notion.

    **Parameters:**

    * `pageId` (string, required): Page ID - Specify the ID of the Page to Update. (example: "59833787-2cf9-4fdf-8782-e53db20768a5").
    * `icon` (object, required): Icon - The page icon.
      ```json
      {
        "emoji": "🥬"
      }
      ```
    * `archived` (boolean, optional): Archived - Whether the page is archived (deleted). Set to true to archive a page. Set to false to un-archive (restore) a page.
    * `properties` (object, optional): Properties - The property values to update for the page.
      ```json
      {
        "title": [
          {
            "text": {
              "content": "My Updated Page"
            }
          }
        ]
      }
      ```
    * `cover` (object, optional): Cover - The page cover image.
      ```json
      {
        "external": {
          "url": "https://upload.wikimedia.org/wikipedia/commons/6/62/Tuscankale.jpg"
        }
      }
      ```
  </Accordion>

  <Accordion title="NOTION_GET_PAGE_BY_ID">
    **Description:** Get a page by ID in Notion.

    **Parameters:**

    * `pageId` (string, required): Page ID - Specify the ID of the Page to Get. (example: "59833787-2cf9-4fdf-8782-e53db20768a5").
  </Accordion>

  <Accordion title="NOTION_ARCHIVE_PAGE">
    **Description:** Archive a page in Notion.

    **Parameters:**

    * `pageId` (string, required): Page ID - Specify the ID of the Page to Archive. (example: "59833787-2cf9-4fdf-8782-e53db20768a5").
  </Accordion>

  <Accordion title="NOTION_SEARCH_PAGES">
    **Description:** Search pages in Notion using filters.

    **Parameters:**

    * `searchByTitleFilterSearch` (object, optional): A filter in disjunctive normal form - OR of AND groups of single conditions.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "query",
                "operator": "$stringExactlyMatches",
                "value": "meeting notes"
              }
            ]
          }
        ]
      }
      ```
      Available fields: `query`, `filter.value`, `direction`, `page_size`
  </Accordion>

  <Accordion title="NOTION_GET_PAGE_CONTENT">
    **Description:** Get page content (blocks) in Notion.

    **Parameters:**

    * `blockId` (string, required): Page ID - Specify a Block or Page ID to receive all of its block's children in order. (example: "59833787-2cf9-4fdf-8782-e53db20768a5").
  </Accordion>

  <Accordion title="NOTION_UPDATE_BLOCK">
    **Description:** Update a block in Notion.

    **Parameters:**

    * `blockId` (string, required): Block ID - Specify the ID of the Block to Update. (example: "9bc30ad4-9373-46a5-84ab-0a7845ee52e6").
    * `archived` (boolean, optional): Archived - Set to true to archive (delete) a block. Set to false to un-archive (restore) a block.
    * `paragraph` (object, optional): Paragraph content.
      ```json
      {
        "rich_text": [
          {
            "type": "text",
            "text": {
              "content": "Lacinato kale",
              "link": null
            }
          }
        ],
        "color": "default"
      }
      ```
    * `image` (object, optional): Image block.
      ```json
      {
        "type": "external",
        "external": {
          "url": "https://website.domain/images/image.png"
        }
      }
      ```
    * `bookmark` (object, optional): Bookmark block.
      ```json
      {
        "caption": [],
        "url": "https://companywebsite.com"
      }
      ```
    * `code` (object, optional): Code block.
      ```json
      {
        "rich_text": [
          {
            "type": "text",
            "text": {
              "content": "const a = 3"
            }
          }
        ],
        "language": "javascript"
      }
      ```
    * `pdf` (object, optional): PDF block.
      ```json
      {
        "type": "external",
        "external": {
          "url": "https://website.domain/files/doc.pdf"
        }
      }
      ```
    * `table` (object, optional): Table block.
      ```json
      {
        "table_width": 2,
        "has_column_header": false,
        "has_row_header": false
      }
      ```
    * `tableOfContent` (object, optional): Table of Contents block.
      ```json
      {
        "color": "default"
      }
      ```
    * `additionalFields` (object, optional): Additional block types.
      ```json
      {
        "child_page": {
          "title": "Lacinato kale"
        },
        "child_database": {
          "title": "My database"
        }
      }
      ```
  </Accordion>

  <Accordion title="NOTION_GET_BLOCK_BY_ID">
    **Description:** Get a block by ID in Notion.

    **Parameters:**

    * `blockId` (string, required): Block ID - Specify the ID of the Block to Get. (example: "9bc30ad4-9373-46a5-84ab-0a7845ee52e6").
  </Accordion>

  <Accordion title="NOTION_DELETE_BLOCK">
    **Description:** Delete a block in Notion.

    **Parameters:**

    * `blockId` (string, required): Block ID - Specify the ID of the Block to Delete. (example: "9bc30ad4-9373-46a5-84ab-0a7845ee52e6").
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Notion Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Notion tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Notion capabilities
notion_agent = Agent(
    role="Documentation Manager",
    goal="Manage documentation and knowledge base in Notion efficiently",
    backstory="An AI assistant specialized in content management and documentation.",
    tools=[enterprise_tools]
)

# Task to create a meeting notes page
create_notes_task = Task(
    description="Create a new meeting notes page in the team database with today's date and agenda items",
    agent=notion_agent,
    expected_output="Meeting notes page created successfully with structured content"
)

# Run the task
crew = Crew(
    agents=[notion_agent],
    tasks=[create_notes_task]
)

crew.kickoff()
```

### Filtering Specific Notion Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Notion tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["notion_create_page", "notion_update_block", "notion_search_pages"]
)

content_manager = Agent(
    role="Content Manager",
    goal="Create and manage content pages efficiently",
    backstory="An AI assistant that focuses on content creation and management.",
    tools=enterprise_tools
)

# Task to manage content workflow
content_workflow = Task(
    description="Create a new project documentation page and add structured content blocks for requirements and specifications",
    agent=content_manager,
    expected_output="Project documentation created with organized content sections"
)

crew = Crew(
    agents=[content_manager],
    tasks=[content_workflow]
)

crew.kickoff()
```

### Knowledge Base Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

knowledge_curator = Agent(
    role="Knowledge Curator",
    goal="Curate and organize knowledge base content in Notion",
    backstory="An experienced knowledge manager who organizes and maintains comprehensive documentation.",
    tools=[enterprise_tools]
)

# Task to curate knowledge base
curation_task = Task(
    description="""
    1. Search for existing documentation pages related to our new product feature
    2. Create a comprehensive feature documentation page with proper structure
    3. Add code examples, images, and links to related resources
    4. Update existing pages with cross-references to the new documentation
    """,
    agent=knowledge_curator,
    expected_output="Feature documentation created and integrated with existing knowledge base"
)

crew = Crew(
    agents=[knowledge_curator],
    tasks=[curation_task]
)

crew.kickoff()
```

### Content Structure and Organization

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

content_organizer = Agent(
    role="Content Organizer",
    goal="Organize and structure content blocks for optimal readability",
    backstory="An AI assistant that specializes in content structure and user experience.",
    tools=[enterprise_tools]
)

# Task to organize content structure
organization_task = Task(
    description="""
    1. Get content from existing project pages
    2. Analyze the structure and identify improvement opportunities
    3. Update content blocks to use proper headings, tables, and formatting
    4. Add table of contents and improve navigation between related pages
    5. Create templates for future documentation consistency
    """,
    agent=content_organizer,
    expected_output="Content reorganized with improved structure and navigation"
)

crew = Crew(
    agents=[content_organizer],
    tasks=[organization_task]
)

crew.kickoff()
```

### Automated Documentation Workflows

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

doc_automator = Agent(
    role="Documentation Automator",
    goal="Automate documentation workflows and maintenance",
    backstory="An AI assistant that automates repetitive documentation tasks.",
    tools=[enterprise_tools]
)

# Complex documentation automation task
automation_task = Task(
    description="""
    1. Search for pages that haven't been updated in the last 30 days
    2. Review and update outdated content blocks
    3. Create weekly team update pages with consistent formatting
    4. Add status indicators and progress tracking to project pages
    5. Generate monthly documentation health reports
    6. Archive completed project pages and organize them in archive sections
    """,
    agent=doc_automator,
    expected_output="Documentation automated with updated content, weekly reports, and organized archives"
)

crew = Crew(
    agents=[doc_automator],
    tasks=[automation_task]
)

crew.kickoff()
```

## Troubleshooting

### Common Issues

**Permission Errors**

* Ensure your Notion account has edit access to the target workspace
* Verify that the OAuth connection includes required scopes for Notion API
* Check that pages and databases are shared with the authenticated integration

**Invalid Page and Block IDs**

* Double-check page IDs and block IDs for correct UUID format
* Ensure referenced pages and blocks exist and are accessible
* Verify that parent page or database IDs are valid when creating new pages

**Property Schema Issues**

* Ensure page properties match the database schema when creating pages in databases
* Verify that property names and types are correct for the target database
* Check that required properties are included when creating or updating pages

**Content Block Structure**

* Ensure block content follows Notion's rich text format specifications
* Verify that nested block structures are properly formatted
* Check that media URLs are accessible and properly formatted

**Search and Filter Issues**

* Ensure search queries are properly formatted and not empty
* Use valid field names in filter formulas: `query`, `filter.value`, `direction`, `page_size`
* Test simple searches before building complex filter conditions

**Parent-Child Relationships**

* Verify that parent page or database exists before creating child pages
* Ensure proper permissions exist for the parent container
* Check that database schemas allow the properties you're trying to set

**Rich Text and Media Content**

* Ensure URLs for external images, PDFs, and bookmarks are accessible
* Verify that rich text formatting follows Notion's API specifications
* Check that code block language types are supported by Notion

**Archive and Deletion Operations**

* Understand the difference between archiving (reversible) and deleting (permanent)
* Verify that you have permissions to archive or delete the target content
* Be cautious with bulk operations that might affect multiple pages or blocks

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with Notion integration setup or troubleshooting.
</Card>


# Salesforce Integration
Source: https://docs.crewai.com/en/enterprise/integrations/salesforce

CRM and sales automation with Salesforce integration for CrewAI.

## Overview

Enable your agents to manage customer relationships, sales processes, and data through Salesforce. Create and update records, manage leads and opportunities, execute SOQL queries, and streamline your CRM workflows with AI-powered automation.

## Prerequisites

Before using the Salesforce integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Salesforce account with appropriate permissions
* Connected your Salesforce account through the [Integrations page](https://app.crewai.com/integrations)

## Available Tools

### **Record Management**

<AccordionGroup>
  <Accordion title="SALESFORCE_CREATE_RECORD_CONTACT">
    **Description:** Create a new Contact record in Salesforce.

    **Parameters:**

    * `FirstName` (string, optional): First Name
    * `LastName` (string, required): Last Name - This field is required
    * `accountId` (string, optional): Account ID - The Account that the Contact belongs to
    * `Email` (string, optional): Email address
    * `Title` (string, optional): Title of the contact, such as CEO or Vice President
    * `Description` (string, optional): A description of the Contact
    * `additionalFields` (object, optional): Additional fields in JSON format for custom Contact fields
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_RECORD_LEAD">
    **Description:** Create a new Lead record in Salesforce.

    **Parameters:**

    * `FirstName` (string, optional): First Name
    * `LastName` (string, required): Last Name - This field is required
    * `Company` (string, required): Company - This field is required
    * `Email` (string, optional): Email address
    * `Phone` (string, optional): Phone number
    * `Website` (string, optional): Website URL
    * `Title` (string, optional): Title of the contact, such as CEO or Vice President
    * `Status` (string, optional): Lead Status - Use Connect Portal Workflow Settings to select Lead Status
    * `Description` (string, optional): A description of the Lead
    * `additionalFields` (object, optional): Additional fields in JSON format for custom Lead fields
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_RECORD_OPPORTUNITY">
    **Description:** Create a new Opportunity record in Salesforce.

    **Parameters:**

    * `Name` (string, required): The Opportunity name - This field is required
    * `StageName` (string, optional): Opportunity Stage - Use Connect Portal Workflow Settings to select stage
    * `CloseDate` (string, optional): Close Date in YYYY-MM-DD format - Defaults to 30 days from current date
    * `AccountId` (string, optional): The Account that the Opportunity belongs to
    * `Amount` (string, optional): Estimated total sale amount
    * `Description` (string, optional): A description of the Opportunity
    * `OwnerId` (string, optional): The Salesforce user assigned to work on this Opportunity
    * `NextStep` (string, optional): Description of next task in closing Opportunity
    * `additionalFields` (object, optional): Additional fields in JSON format for custom Opportunity fields
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_RECORD_TASK">
    **Description:** Create a new Task record in Salesforce.

    **Parameters:**

    * `whatId` (string, optional): Related to ID - The ID of the Account or Opportunity this Task is related to
    * `whoId` (string, optional): Name ID - The ID of the Contact or Lead this Task is related to
    * `subject` (string, required): Subject of the task
    * `activityDate` (string, optional): Activity Date in YYYY-MM-DD format
    * `description` (string, optional): A description of the Task
    * `taskSubtype` (string, required): Task Subtype - Options: task, email, listEmail, call
    * `Status` (string, optional): Status - Options: Not Started, In Progress, Completed
    * `ownerId` (string, optional): Assigned To ID - The Salesforce user assigned to this Task
    * `callDurationInSeconds` (string, optional): Call Duration in seconds
    * `isReminderSet` (boolean, optional): Whether reminder is set
    * `reminderDateTime` (string, optional): Reminder Date/Time in ISO format
    * `additionalFields` (object, optional): Additional fields in JSON format for custom Task fields
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_RECORD_ACCOUNT">
    **Description:** Create a new Account record in Salesforce.

    **Parameters:**

    * `Name` (string, required): The Account name - This field is required
    * `OwnerId` (string, optional): The Salesforce user assigned to this Account
    * `Website` (string, optional): Website URL
    * `Phone` (string, optional): Phone number
    * `Description` (string, optional): Account description
    * `additionalFields` (object, optional): Additional fields in JSON format for custom Account fields
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_RECORD_ANY">
    **Description:** Create a record of any object type in Salesforce.

    **Note:** This is a flexible tool for creating records of custom or unknown object types.
  </Accordion>
</AccordionGroup>

### **Record Updates**

<AccordionGroup>
  <Accordion title="SALESFORCE_UPDATE_RECORD_CONTACT">
    **Description:** Update an existing Contact record in Salesforce.

    **Parameters:**

    * `recordId` (string, required): The ID of the record to update
    * `FirstName` (string, optional): First Name
    * `LastName` (string, optional): Last Name
    * `accountId` (string, optional): Account ID - The Account that the Contact belongs to
    * `Email` (string, optional): Email address
    * `Title` (string, optional): Title of the contact
    * `Description` (string, optional): A description of the Contact
    * `additionalFields` (object, optional): Additional fields in JSON format for custom Contact fields
  </Accordion>

  <Accordion title="SALESFORCE_UPDATE_RECORD_LEAD">
    **Description:** Update an existing Lead record in Salesforce.

    **Parameters:**

    * `recordId` (string, required): The ID of the record to update
    * `FirstName` (string, optional): First Name
    * `LastName` (string, optional): Last Name
    * `Company` (string, optional): Company name
    * `Email` (string, optional): Email address
    * `Phone` (string, optional): Phone number
    * `Website` (string, optional): Website URL
    * `Title` (string, optional): Title of the contact
    * `Status` (string, optional): Lead Status
    * `Description` (string, optional): A description of the Lead
    * `additionalFields` (object, optional): Additional fields in JSON format for custom Lead fields
  </Accordion>

  <Accordion title="SALESFORCE_UPDATE_RECORD_OPPORTUNITY">
    **Description:** Update an existing Opportunity record in Salesforce.

    **Parameters:**

    * `recordId` (string, required): The ID of the record to update
    * `Name` (string, optional): The Opportunity name
    * `StageName` (string, optional): Opportunity Stage
    * `CloseDate` (string, optional): Close Date in YYYY-MM-DD format
    * `AccountId` (string, optional): The Account that the Opportunity belongs to
    * `Amount` (string, optional): Estimated total sale amount
    * `Description` (string, optional): A description of the Opportunity
    * `OwnerId` (string, optional): The Salesforce user assigned to work on this Opportunity
    * `NextStep` (string, optional): Description of next task in closing Opportunity
    * `additionalFields` (object, optional): Additional fields in JSON format for custom Opportunity fields
  </Accordion>

  <Accordion title="SALESFORCE_UPDATE_RECORD_TASK">
    **Description:** Update an existing Task record in Salesforce.

    **Parameters:**

    * `recordId` (string, required): The ID of the record to update
    * `whatId` (string, optional): Related to ID - The ID of the Account or Opportunity this Task is related to
    * `whoId` (string, optional): Name ID - The ID of the Contact or Lead this Task is related to
    * `subject` (string, optional): Subject of the task
    * `activityDate` (string, optional): Activity Date in YYYY-MM-DD format
    * `description` (string, optional): A description of the Task
    * `Status` (string, optional): Status - Options: Not Started, In Progress, Completed
    * `ownerId` (string, optional): Assigned To ID - The Salesforce user assigned to this Task
    * `callDurationInSeconds` (string, optional): Call Duration in seconds
    * `isReminderSet` (boolean, optional): Whether reminder is set
    * `reminderDateTime` (string, optional): Reminder Date/Time in ISO format
    * `additionalFields` (object, optional): Additional fields in JSON format for custom Task fields
  </Accordion>

  <Accordion title="SALESFORCE_UPDATE_RECORD_ACCOUNT">
    **Description:** Update an existing Account record in Salesforce.

    **Parameters:**

    * `recordId` (string, required): The ID of the record to update
    * `Name` (string, optional): The Account name
    * `OwnerId` (string, optional): The Salesforce user assigned to this Account
    * `Website` (string, optional): Website URL
    * `Phone` (string, optional): Phone number
    * `Description` (string, optional): Account description
    * `additionalFields` (object, optional): Additional fields in JSON format for custom Account fields
  </Accordion>

  <Accordion title="SALESFORCE_UPDATE_RECORD_ANY">
    **Description:** Update a record of any object type in Salesforce.

    **Note:** This is a flexible tool for updating records of custom or unknown object types.
  </Accordion>
</AccordionGroup>

### **Record Retrieval**

<AccordionGroup>
  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_CONTACT">
    **Description:** Get a Contact record by its ID.

    **Parameters:**

    * `recordId` (string, required): Record ID of the Contact
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_LEAD">
    **Description:** Get a Lead record by its ID.

    **Parameters:**

    * `recordId` (string, required): Record ID of the Lead
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_OPPORTUNITY">
    **Description:** Get an Opportunity record by its ID.

    **Parameters:**

    * `recordId` (string, required): Record ID of the Opportunity
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_TASK">
    **Description:** Get a Task record by its ID.

    **Parameters:**

    * `recordId` (string, required): Record ID of the Task
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_ACCOUNT">
    **Description:** Get an Account record by its ID.

    **Parameters:**

    * `recordId` (string, required): Record ID of the Account
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_ANY">
    **Description:** Get a record of any object type by its ID.

    **Parameters:**

    * `recordType` (string, required): Record Type (e.g., "CustomObject\_\_c")
    * `recordId` (string, required): Record ID
  </Accordion>
</AccordionGroup>

### **Record Search**

<AccordionGroup>
  <Accordion title="SALESFORCE_SEARCH_RECORDS_CONTACT">
    **Description:** Search for Contact records with advanced filtering.

    **Parameters:**

    * `filterFormula` (object, optional): Advanced filter in disjunctive normal form with field-specific operators
    * `sortBy` (string, optional): Sort field (e.g., "CreatedDate")
    * `sortDirection` (string, optional): Sort direction - Options: ASC, DESC
    * `includeAllFields` (boolean, optional): Include all fields in results
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_SEARCH_RECORDS_LEAD">
    **Description:** Search for Lead records with advanced filtering.

    **Parameters:**

    * `filterFormula` (object, optional): Advanced filter in disjunctive normal form with field-specific operators
    * `sortBy` (string, optional): Sort field (e.g., "CreatedDate")
    * `sortDirection` (string, optional): Sort direction - Options: ASC, DESC
    * `includeAllFields` (boolean, optional): Include all fields in results
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_SEARCH_RECORDS_OPPORTUNITY">
    **Description:** Search for Opportunity records with advanced filtering.

    **Parameters:**

    * `filterFormula` (object, optional): Advanced filter in disjunctive normal form with field-specific operators
    * `sortBy` (string, optional): Sort field (e.g., "CreatedDate")
    * `sortDirection` (string, optional): Sort direction - Options: ASC, DESC
    * `includeAllFields` (boolean, optional): Include all fields in results
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_SEARCH_RECORDS_TASK">
    **Description:** Search for Task records with advanced filtering.

    **Parameters:**

    * `filterFormula` (object, optional): Advanced filter in disjunctive normal form with field-specific operators
    * `sortBy` (string, optional): Sort field (e.g., "CreatedDate")
    * `sortDirection` (string, optional): Sort direction - Options: ASC, DESC
    * `includeAllFields` (boolean, optional): Include all fields in results
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_SEARCH_RECORDS_ACCOUNT">
    **Description:** Search for Account records with advanced filtering.

    **Parameters:**

    * `filterFormula` (object, optional): Advanced filter in disjunctive normal form with field-specific operators
    * `sortBy` (string, optional): Sort field (e.g., "CreatedDate")
    * `sortDirection` (string, optional): Sort direction - Options: ASC, DESC
    * `includeAllFields` (boolean, optional): Include all fields in results
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_SEARCH_RECORDS_ANY">
    **Description:** Search for records of any object type.

    **Parameters:**

    * `recordType` (string, required): Record Type to search
    * `filterFormula` (string, optional): Filter search criteria
    * `includeAllFields` (boolean, optional): Include all fields in results
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>
</AccordionGroup>

### **List View Retrieval**

<AccordionGroup>
  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_CONTACT">
    **Description:** Get Contact records from a specific List View.

    **Parameters:**

    * `listViewId` (string, required): List View ID
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_LEAD">
    **Description:** Get Lead records from a specific List View.

    **Parameters:**

    * `listViewId` (string, required): List View ID
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_OPPORTUNITY">
    **Description:** Get Opportunity records from a specific List View.

    **Parameters:**

    * `listViewId` (string, required): List View ID
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_TASK">
    **Description:** Get Task records from a specific List View.

    **Parameters:**

    * `listViewId` (string, required): List View ID
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_ACCOUNT">
    **Description:** Get Account records from a specific List View.

    **Parameters:**

    * `listViewId` (string, required): List View ID
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_ANY">
    **Description:** Get records of any object type from a specific List View.

    **Parameters:**

    * `recordType` (string, required): Record Type
    * `listViewId` (string, required): List View ID
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>
</AccordionGroup>

### **Custom Fields**

<AccordionGroup>
  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_CONTACT">
    **Description:** Deploy custom fields for Contact objects.

    **Parameters:**

    * `label` (string, required): Field Label for displays and internal reference
    * `type` (string, required): Field Type - Options: Checkbox, Currency, Date, Email, Number, Percent, Phone, Picklist, MultiselectPicklist, Text, TextArea, LongTextArea, Html, Time, Url
    * `defaultCheckboxValue` (boolean, optional): Default value for checkbox fields
    * `length` (string, required): Length for numeric/text fields
    * `decimalPlace` (string, required): Decimal places for numeric fields
    * `pickListValues` (string, required): Values for picklist fields (separated by new lines)
    * `visibleLines` (string, required): Visible lines for multiselect/text area fields
    * `description` (string, optional): Field description
    * `helperText` (string, optional): Helper text shown on hover
    * `defaultFieldValue` (string, optional): Default field value
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_LEAD">
    **Description:** Deploy custom fields for Lead objects.

    **Parameters:**

    * `label` (string, required): Field Label for displays and internal reference
    * `type` (string, required): Field Type - Options: Checkbox, Currency, Date, Email, Number, Percent, Phone, Picklist, MultiselectPicklist, Text, TextArea, LongTextArea, Html, Time, Url
    * `defaultCheckboxValue` (boolean, optional): Default value for checkbox fields
    * `length` (string, required): Length for numeric/text fields
    * `decimalPlace` (string, required): Decimal places for numeric fields
    * `pickListValues` (string, required): Values for picklist fields (separated by new lines)
    * `visibleLines` (string, required): Visible lines for multiselect/text area fields
    * `description` (string, optional): Field description
    * `helperText` (string, optional): Helper text shown on hover
    * `defaultFieldValue` (string, optional): Default field value
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_OPPORTUNITY">
    **Description:** Deploy custom fields for Opportunity objects.

    **Parameters:**

    * `label` (string, required): Field Label for displays and internal reference
    * `type` (string, required): Field Type - Options: Checkbox, Currency, Date, Email, Number, Percent, Phone, Picklist, MultiselectPicklist, Text, TextArea, LongTextArea, Html, Time, Url
    * `defaultCheckboxValue` (boolean, optional): Default value for checkbox fields
    * `length` (string, required): Length for numeric/text fields
    * `decimalPlace` (string, required): Decimal places for numeric fields
    * `pickListValues` (string, required): Values for picklist fields (separated by new lines)
    * `visibleLines` (string, required): Visible lines for multiselect/text area fields
    * `description` (string, optional): Field description
    * `helperText` (string, optional): Helper text shown on hover
    * `defaultFieldValue` (string, optional): Default field value
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_TASK">
    **Description:** Deploy custom fields for Task objects.

    **Parameters:**

    * `label` (string, required): Field Label for displays and internal reference
    * `type` (string, required): Field Type - Options: Checkbox, Currency, Date, Email, Number, Percent, Phone, Picklist, MultiselectPicklist, Text, TextArea, Time, Url
    * `defaultCheckboxValue` (boolean, optional): Default value for checkbox fields
    * `length` (string, required): Length for numeric/text fields
    * `decimalPlace` (string, required): Decimal places for numeric fields
    * `pickListValues` (string, required): Values for picklist fields (separated by new lines)
    * `visibleLines` (string, required): Visible lines for multiselect fields
    * `description` (string, optional): Field description
    * `helperText` (string, optional): Helper text shown on hover
    * `defaultFieldValue` (string, optional): Default field value
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_ACCOUNT">
    **Description:** Deploy custom fields for Account objects.

    **Parameters:**

    * `label` (string, required): Field Label for displays and internal reference
    * `type` (string, required): Field Type - Options: Checkbox, Currency, Date, Email, Number, Percent, Phone, Picklist, MultiselectPicklist, Text, TextArea, LongTextArea, Html, Time, Url
    * `defaultCheckboxValue` (boolean, optional): Default value for checkbox fields
    * `length` (string, required): Length for numeric/text fields
    * `decimalPlace` (string, required): Decimal places for numeric fields
    * `pickListValues` (string, required): Values for picklist fields (separated by new lines)
    * `visibleLines` (string, required): Visible lines for multiselect/text area fields
    * `description` (string, optional): Field description
    * `helperText` (string, optional): Helper text shown on hover
    * `defaultFieldValue` (string, optional): Default field value
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_ANY">
    **Description:** Deploy custom fields for any object type.

    **Note:** This is a flexible tool for creating custom fields on custom or unknown object types.
  </Accordion>
</AccordionGroup>

### **Advanced Operations**

<AccordionGroup>
  <Accordion title="SALESFORCE_WRITE_SOQL_QUERY">
    **Description:** Execute custom SOQL queries against your Salesforce data.

    **Parameters:**

    * `query` (string, required): SOQL Query (e.g., "SELECT Id, Name FROM Account WHERE Name = 'Example'")
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_OBJECT">
    **Description:** Deploy a new custom object in Salesforce.

    **Parameters:**

    * `label` (string, required): Object Label for tabs, page layouts, and reports
    * `pluralLabel` (string, required): Plural Label (e.g., "Accounts")
    * `description` (string, optional): A description of the Custom Object
    * `recordName` (string, required): Record Name that appears in layouts and searches (e.g., "Account Name")
  </Accordion>

  <Accordion title="SALESFORCE_DESCRIBE_ACTION_SCHEMA">
    **Description:** Get the expected schema for operations on specific object types.

    **Parameters:**

    * `recordType` (string, required): Record Type to describe
    * `operation` (string, required): Operation Type (e.g., "CREATE\_RECORD" or "UPDATE\_RECORD")

    **Note:** Use this function first when working with custom objects to understand their schema before performing operations.
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Salesforce Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Salesforce tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Salesforce capabilities
salesforce_agent = Agent(
    role="CRM Manager",
    goal="Manage customer relationships and sales processes efficiently",
    backstory="An AI assistant specialized in CRM operations and sales automation.",
    tools=[enterprise_tools]
)

# Task to create a new lead
create_lead_task = Task(
    description="Create a new lead for John Doe from Example Corp with email john.doe@example.com",
    agent=salesforce_agent,
    expected_output="Lead created successfully with lead ID"
)

# Run the task
crew = Crew(
    agents=[salesforce_agent],
    tasks=[create_lead_task]
)

crew.kickoff()
```

### Filtering Specific Salesforce Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Salesforce tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["salesforce_create_record_lead", "salesforce_update_record_opportunity", "salesforce_search_records_contact"]
)

sales_manager = Agent(
    role="Sales Manager",
    goal="Manage leads and opportunities in the sales pipeline",
    backstory="An experienced sales manager who handles lead qualification and opportunity management.",
    tools=enterprise_tools
)

# Task to manage sales pipeline
pipeline_task = Task(
    description="Create a qualified lead and convert it to an opportunity with $50,000 value",
    agent=sales_manager,
    expected_output="Lead created and opportunity established successfully"
)

crew = Crew(
    agents=[sales_manager],
    tasks=[pipeline_task]
)

crew.kickoff()
```

### Contact and Account Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

account_manager = Agent(
    role="Account Manager",
    goal="Manage customer accounts and maintain strong relationships",
    backstory="An AI assistant that specializes in account management and customer relationship building.",
    tools=[enterprise_tools]
)

# Task to manage customer accounts
account_task = Task(
    description="""
    1. Create a new account for TechCorp Inc.
    2. Add John Doe as the primary contact for this account
    3. Create a follow-up task for next week to check on their project status
    """,
    agent=account_manager,
    expected_output="Account, contact, and follow-up task created successfully"
)

crew = Crew(
    agents=[account_manager],
    tasks=[account_task]
)

crew.kickoff()
```

### Advanced SOQL Queries and Reporting

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

data_analyst = Agent(
    role="Sales Data Analyst",
    goal="Generate insights from Salesforce data using SOQL queries",
    backstory="An analytical AI that excels at extracting meaningful insights from CRM data.",
    tools=[enterprise_tools]
)

# Complex task involving SOQL queries and data analysis
analysis_task = Task(
    description="""
    1. Execute a SOQL query to find all opportunities closing this quarter
    2. Search for contacts at companies with opportunities over $100K
    3. Create a summary report of the sales pipeline status
    4. Update high-value opportunities with next steps
    """,
    agent=data_analyst,
    expected_output="Comprehensive sales pipeline analysis with actionable insights"
)

crew = Crew(
    agents=[data_analyst],
    tasks=[analysis_task]
)

crew.kickoff()
```

This comprehensive documentation covers all the Salesforce tools organized by functionality, making it easy for users to find the specific operations they need for their CRM automation tasks.

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with Salesforce integration setup or troubleshooting.
</Card>


# Shopify Integration
Source: https://docs.crewai.com/en/enterprise/integrations/shopify

E-commerce and online store management with Shopify integration for CrewAI.

## Overview

Enable your agents to manage e-commerce operations through Shopify. Handle customers, orders, products, inventory, and store analytics to streamline your online business with AI-powered automation.

## Prerequisites

Before using the Shopify integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Shopify store with appropriate admin permissions
* Connected your Shopify store through the [Integrations page](https://app.crewai.com/integrations)

## Available Tools

### **Customer Management**

<AccordionGroup>
  <Accordion title="SHOPIFY_GET_CUSTOMERS">
    **Description:** Retrieve a list of customers from your Shopify store.

    **Parameters:**

    * `customerIds` (string, optional): Comma-separated list of customer IDs to filter by (example: "207119551, 207119552")
    * `createdAtMin` (string, optional): Only return customers created after this date (ISO or Unix timestamp)
    * `createdAtMax` (string, optional): Only return customers created before this date (ISO or Unix timestamp)
    * `updatedAtMin` (string, optional): Only return customers updated after this date (ISO or Unix timestamp)
    * `updatedAtMax` (string, optional): Only return customers updated before this date (ISO or Unix timestamp)
    * `limit` (string, optional): Maximum number of customers to return (defaults to 250)
  </Accordion>

  <Accordion title="SHOPIFY_SEARCH_CUSTOMERS">
    **Description:** Search for customers using advanced filtering criteria.

    **Parameters:**

    * `filterFormula` (object, optional): Advanced filter in disjunctive normal form with field-specific operators
    * `limit` (string, optional): Maximum number of customers to return (defaults to 250)
  </Accordion>

  <Accordion title="SHOPIFY_CREATE_CUSTOMER">
    **Description:** Create a new customer in your Shopify store.

    **Parameters:**

    * `firstName` (string, required): Customer's first name
    * `lastName` (string, required): Customer's last name
    * `email` (string, required): Customer's email address
    * `company` (string, optional): Company name
    * `streetAddressLine1` (string, optional): Street address
    * `streetAddressLine2` (string, optional): Street address line 2
    * `city` (string, optional): City
    * `state` (string, optional): State or province code
    * `country` (string, optional): Country
    * `zipCode` (string, optional): Zip code
    * `phone` (string, optional): Phone number
    * `tags` (string, optional): Tags as array or comma-separated list
    * `note` (string, optional): Customer note
    * `sendEmailInvite` (boolean, optional): Whether to send email invitation
    * `metafields` (object, optional): Additional metafields in JSON format
  </Accordion>

  <Accordion title="SHOPIFY_UPDATE_CUSTOMER">
    **Description:** Update an existing customer in your Shopify store.

    **Parameters:**

    * `customerId` (string, required): The ID of the customer to update
    * `firstName` (string, optional): Customer's first name
    * `lastName` (string, optional): Customer's last name
    * `email` (string, optional): Customer's email address
    * `company` (string, optional): Company name
    * `streetAddressLine1` (string, optional): Street address
    * `streetAddressLine2` (string, optional): Street address line 2
    * `city` (string, optional): City
    * `state` (string, optional): State or province code
    * `country` (string, optional): Country
    * `zipCode` (string, optional): Zip code
    * `phone` (string, optional): Phone number
    * `tags` (string, optional): Tags as array or comma-separated list
    * `note` (string, optional): Customer note
    * `sendEmailInvite` (boolean, optional): Whether to send email invitation
    * `metafields` (object, optional): Additional metafields in JSON format
  </Accordion>
</AccordionGroup>

### **Order Management**

<AccordionGroup>
  <Accordion title="SHOPIFY_GET_ORDERS">
    **Description:** Retrieve a list of orders from your Shopify store.

    **Parameters:**

    * `orderIds` (string, optional): Comma-separated list of order IDs to filter by (example: "450789469, 450789470")
    * `createdAtMin` (string, optional): Only return orders created after this date (ISO or Unix timestamp)
    * `createdAtMax` (string, optional): Only return orders created before this date (ISO or Unix timestamp)
    * `updatedAtMin` (string, optional): Only return orders updated after this date (ISO or Unix timestamp)
    * `updatedAtMax` (string, optional): Only return orders updated before this date (ISO or Unix timestamp)
    * `limit` (string, optional): Maximum number of orders to return (defaults to 250)
  </Accordion>

  <Accordion title="SHOPIFY_CREATE_ORDER">
    **Description:** Create a new order in your Shopify store.

    **Parameters:**

    * `email` (string, required): Customer email address
    * `lineItems` (object, required): Order line items in JSON format with title, price, quantity, and variant\_id
    * `sendReceipt` (boolean, optional): Whether to send order receipt
    * `fulfillmentStatus` (string, optional): Fulfillment status - Options: fulfilled, null, partial, restocked
    * `financialStatus` (string, optional): Financial status - Options: pending, authorized, partially\_paid, paid, partially\_refunded, refunded, voided
    * `inventoryBehaviour` (string, optional): Inventory behavior - Options: bypass, decrement\_ignoring\_policy, decrement\_obeying\_policy
    * `note` (string, optional): Order note
  </Accordion>

  <Accordion title="SHOPIFY_UPDATE_ORDER">
    **Description:** Update an existing order in your Shopify store.

    **Parameters:**

    * `orderId` (string, required): The ID of the order to update
    * `email` (string, optional): Customer email address
    * `lineItems` (object, optional): Updated order line items in JSON format
    * `sendReceipt` (boolean, optional): Whether to send order receipt
    * `fulfillmentStatus` (string, optional): Fulfillment status - Options: fulfilled, null, partial, restocked
    * `financialStatus` (string, optional): Financial status - Options: pending, authorized, partially\_paid, paid, partially\_refunded, refunded, voided
    * `inventoryBehaviour` (string, optional): Inventory behavior - Options: bypass, decrement\_ignoring\_policy, decrement\_obeying\_policy
    * `note` (string, optional): Order note
  </Accordion>

  <Accordion title="SHOPIFY_GET_ABANDONED_CARTS">
    **Description:** Retrieve abandoned carts from your Shopify store.

    **Parameters:**

    * `createdWithInLast` (string, optional): Restrict results to checkouts created within specified time
    * `createdAfterId` (string, optional): Restrict results to after the specified ID
    * `status` (string, optional): Show checkouts with given status - Options: open, closed (defaults to open)
    * `createdAtMin` (string, optional): Only return carts created after this date (ISO or Unix timestamp)
    * `createdAtMax` (string, optional): Only return carts created before this date (ISO or Unix timestamp)
    * `limit` (string, optional): Maximum number of carts to return (defaults to 250)
  </Accordion>
</AccordionGroup>

### **Product Management (REST API)**

<AccordionGroup>
  <Accordion title="SHOPIFY_GET_PRODUCTS">
    **Description:** Retrieve a list of products from your Shopify store using REST API.

    **Parameters:**

    * `productIds` (string, optional): Comma-separated list of product IDs to filter by (example: "632910392, 632910393")
    * `title` (string, optional): Filter by product title
    * `productType` (string, optional): Filter by product type
    * `vendor` (string, optional): Filter by vendor
    * `status` (string, optional): Filter by status - Options: active, archived, draft
    * `createdAtMin` (string, optional): Only return products created after this date (ISO or Unix timestamp)
    * `createdAtMax` (string, optional): Only return products created before this date (ISO or Unix timestamp)
    * `updatedAtMin` (string, optional): Only return products updated after this date (ISO or Unix timestamp)
    * `updatedAtMax` (string, optional): Only return products updated before this date (ISO or Unix timestamp)
    * `limit` (string, optional): Maximum number of products to return (defaults to 250)
  </Accordion>

  <Accordion title="SHOPIFY_CREATE_PRODUCT">
    **Description:** Create a new product in your Shopify store using REST API.

    **Parameters:**

    * `title` (string, required): Product title
    * `productType` (string, required): Product type/category
    * `vendor` (string, required): Product vendor
    * `productDescription` (string, optional): Product description (accepts plain text or HTML)
    * `tags` (string, optional): Product tags as array or comma-separated list
    * `price` (string, optional): Product price
    * `inventoryPolicy` (string, optional): Inventory policy - Options: deny, continue
    * `imageUrl` (string, optional): Product image URL
    * `isPublished` (boolean, optional): Whether product is published
    * `publishToPointToSale` (boolean, optional): Whether to publish to point of sale
  </Accordion>

  <Accordion title="SHOPIFY_UPDATE_PRODUCT">
    **Description:** Update an existing product in your Shopify store using REST API.

    **Parameters:**

    * `productId` (string, required): The ID of the product to update
    * `title` (string, optional): Product title
    * `productType` (string, optional): Product type/category
    * `vendor` (string, optional): Product vendor
    * `productDescription` (string, optional): Product description (accepts plain text or HTML)
    * `tags` (string, optional): Product tags as array or comma-separated list
    * `price` (string, optional): Product price
    * `inventoryPolicy` (string, optional): Inventory policy - Options: deny, continue
    * `imageUrl` (string, optional): Product image URL
    * `isPublished` (boolean, optional): Whether product is published
    * `publishToPointToSale` (boolean, optional): Whether to publish to point of sale
  </Accordion>
</AccordionGroup>

### **Product Management (GraphQL)**

<AccordionGroup>
  <Accordion title="SHOPIFY_GET_PRODUCTS_GRAPHQL">
    **Description:** Retrieve products using advanced GraphQL filtering capabilities.

    **Parameters:**

    * `productFilterFormula` (object, optional): Advanced filter in disjunctive normal form with support for fields like id, title, vendor, status, handle, tag, created\_at, updated\_at, published\_at
  </Accordion>

  <Accordion title="SHOPIFY_CREATE_PRODUCT_GRAPHQL">
    **Description:** Create a new product using GraphQL API with enhanced media support.

    **Parameters:**

    * `title` (string, required): Product title
    * `productType` (string, required): Product type/category
    * `vendor` (string, required): Product vendor
    * `productDescription` (string, optional): Product description (accepts plain text or HTML)
    * `tags` (string, optional): Product tags as array or comma-separated list
    * `media` (object, optional): Media objects with alt text, content type, and source URL
    * `additionalFields` (object, optional): Additional product fields like status, requiresSellingPlan, giftCard
  </Accordion>

  <Accordion title="SHOPIFY_UPDATE_PRODUCT_GRAPHQL">
    **Description:** Update an existing product using GraphQL API with enhanced media support.

    **Parameters:**

    * `productId` (string, required): The GraphQL ID of the product to update (e.g., "gid://shopify/Product/913144112")
    * `title` (string, optional): Product title
    * `productType` (string, optional): Product type/category
    * `vendor` (string, optional): Product vendor
    * `productDescription` (string, optional): Product description (accepts plain text or HTML)
    * `tags` (string, optional): Product tags as array or comma-separated list
    * `media` (object, optional): Updated media objects with alt text, content type, and source URL
    * `additionalFields` (object, optional): Additional product fields like status, requiresSellingPlan, giftCard
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Shopify Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Shopify tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Shopify capabilities
shopify_agent = Agent(
    role="E-commerce Manager",
    goal="Manage online store operations and customer relationships efficiently",
    backstory="An AI assistant specialized in e-commerce operations and online store management.",
    tools=[enterprise_tools]
)

# Task to create a new customer
create_customer_task = Task(
    description="Create a new VIP customer Jane Smith with email jane.smith@example.com and phone +1-555-0123",
    agent=shopify_agent,
    expected_output="Customer created successfully with customer ID"
)

# Run the task
crew = Crew(
    agents=[shopify_agent],
    tasks=[create_customer_task]
)

crew.kickoff()
```

### Filtering Specific Shopify Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Shopify tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["shopify_create_customer", "shopify_create_order", "shopify_get_products"]
)

store_manager = Agent(
    role="Store Manager",
    goal="Manage customer orders and product catalog",
    backstory="An experienced store manager who handles customer relationships and inventory management.",
    tools=enterprise_tools
)

# Task to manage store operations
store_task = Task(
    description="Create a new customer and process their order for 2 Premium Coffee Mugs",
    agent=store_manager,
    expected_output="Customer created and order processed successfully"
)

crew = Crew(
    agents=[store_manager],
    tasks=[store_task]
)

crew.kickoff()
```

### Product Management with GraphQL

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

product_manager = Agent(
    role="Product Manager",
    goal="Manage product catalog and inventory with advanced GraphQL capabilities",
    backstory="An AI assistant that specializes in product management and catalog optimization.",
    tools=[enterprise_tools]
)

# Task to manage product catalog
catalog_task = Task(
    description="""
    1. Create a new product "Premium Coffee Mug" from Coffee Co vendor
    2. Add high-quality product images and descriptions
    3. Search for similar products from the same vendor
    4. Update product tags and pricing strategy
    """,
    agent=product_manager,
    expected_output="Product created and catalog optimized successfully"
)

crew = Crew(
    agents=[product_manager],
    tasks=[catalog_task]
)

crew.kickoff()
```

### Order and Customer Analytics

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

analytics_agent = Agent(
    role="E-commerce Analyst",
    goal="Analyze customer behavior and order patterns to optimize store performance",
    backstory="An analytical AI that excels at extracting insights from e-commerce data.",
    tools=[enterprise_tools]
)

# Complex task involving multiple operations
analytics_task = Task(
    description="""
    1. Retrieve recent customer data and order history
    2. Identify abandoned carts from the last 7 days
    3. Analyze product performance and inventory levels
    4. Generate recommendations for customer retention
    """,
    agent=analytics_agent,
    expected_output="Comprehensive e-commerce analytics report with actionable insights"
)

crew = Crew(
    agents=[analytics_agent],
    tasks=[analytics_task]
)

crew.kickoff()
```

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with Shopify integration setup or troubleshooting.
</Card>


# Slack Integration
Source: https://docs.crewai.com/en/enterprise/integrations/slack

Team communication and collaboration with Slack integration for CrewAI.

## Overview

Enable your agents to manage team communication through Slack. Send messages, search conversations, manage channels, and coordinate team activities to streamline your collaboration workflows with AI-powered automation.

## Prerequisites

Before using the Slack integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Slack workspace with appropriate permissions
* Connected your Slack workspace through the [Integrations page](https://app.crewai.com/integrations)

## Available Tools

### **User Management**

<AccordionGroup>
  <Accordion title="SLACK_LIST_MEMBERS">
    **Description:** List all members in a Slack channel.

    **Parameters:**

    * No parameters required - retrieves all channel members
  </Accordion>

  <Accordion title="SLACK_GET_USER_BY_EMAIL">
    **Description:** Find a user in your Slack workspace by their email address.

    **Parameters:**

    * `email` (string, required): The email address of a user in the workspace
  </Accordion>

  <Accordion title="SLACK_GET_USERS_BY_NAME">
    **Description:** Search for users by their name or display name.

    **Parameters:**

    * `name` (string, required): User's real name to search for
    * `displayName` (string, required): User's display name to search for
    * `paginationParameters` (object, optional): Pagination settings
      * `pageCursor` (string, optional): Page cursor for pagination
  </Accordion>
</AccordionGroup>

### **Channel Management**

<AccordionGroup>
  <Accordion title="SLACK_LIST_CHANNELS">
    **Description:** List all channels in your Slack workspace.

    **Parameters:**

    * No parameters required - retrieves all accessible channels
  </Accordion>
</AccordionGroup>

### **Messaging**

<AccordionGroup>
  <Accordion title="SLACK_SEND_MESSAGE">
    **Description:** Send a message to a Slack channel.

    **Parameters:**

    * `channel` (string, required): Channel name or ID - Use Connect Portal Workflow Settings to allow users to select a channel, or enter a channel name to create a new channel
    * `message` (string, required): The message text to send
    * `botName` (string, required): The name of the bot that sends this message
    * `botIcon` (string, required): Bot icon - Can be either an image URL or an emoji (e.g., ":dog:")
    * `blocks` (object, optional): Slack Block Kit JSON for rich message formatting with attachments and interactive elements
    * `authenticatedUser` (boolean, optional): If true, message appears to come from your authenticated Slack user instead of the application (defaults to false)
  </Accordion>

  <Accordion title="SLACK_SEND_DIRECT_MESSAGE">
    **Description:** Send a direct message to a specific user in Slack.

    **Parameters:**

    * `memberId` (string, required): Recipient user ID - Use Connect Portal Workflow Settings to allow users to select a workspace member
    * `message` (string, required): The message text to send
    * `botName` (string, required): The name of the bot that sends this message
    * `botIcon` (string, required): Bot icon - Can be either an image URL or an emoji (e.g., ":dog:")
    * `blocks` (object, optional): Slack Block Kit JSON for rich message formatting with attachments and interactive elements
    * `authenticatedUser` (boolean, optional): If true, message appears to come from your authenticated Slack user instead of the application (defaults to false)
  </Accordion>
</AccordionGroup>

### **Search & Discovery**

<AccordionGroup>
  <Accordion title="SLACK_SEARCH_MESSAGES">
    **Description:** Search for messages across your Slack workspace.

    **Parameters:**

    * `query` (string, required): Search query using Slack search syntax to find messages that match specified criteria

    **Search Query Examples:**

    * `"project update"` - Search for messages containing "project update"
    * `from:@john in:#general` - Search for messages from John in the #general channel
    * `has:link after:2023-01-01` - Search for messages with links after January 1, 2023
    * `in:@channel before:yesterday` - Search for messages in a specific channel before yesterday
  </Accordion>
</AccordionGroup>

## Block Kit Integration

Slack's Block Kit allows you to create rich, interactive messages. Here are some examples of how to use the `blocks` parameter:

### Simple Text with Attachment

```json
[
  {
    "text": "I am a test message",
    "attachments": [
      {
        "text": "And here's an attachment!"
      }
    ]
  }
]
```

### Rich Formatting with Sections

```json
[
  {
    "type": "section",
    "text": {
      "type": "mrkdwn",
      "text": "*Project Update*\nStatus: ✅ Complete"
    }
  },
  {
    "type": "divider"
  },
  {
    "type": "section",
    "text": {
      "type": "plain_text",
      "text": "All tasks have been completed successfully."
    }
  }
]
```

## Usage Examples

### Basic Slack Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Slack tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Slack capabilities
slack_agent = Agent(
    role="Team Communication Manager",
    goal="Facilitate team communication and coordinate collaboration efficiently",
    backstory="An AI assistant specialized in team communication and workspace coordination.",
    tools=[enterprise_tools]
)

# Task to send project updates
update_task = Task(
    description="Send a project status update to the #general channel with current progress",
    agent=slack_agent,
    expected_output="Project update message sent successfully to team channel"
)

# Run the task
crew = Crew(
    agents=[slack_agent],
    tasks=[update_task]
)

crew.kickoff()
```

### Filtering Specific Slack Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Slack tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["slack_send_message", "slack_send_direct_message", "slack_search_messages"]
)

communication_manager = Agent(
    role="Communication Coordinator",
    goal="Manage team communications and ensure important messages reach the right people",
    backstory="An experienced communication coordinator who handles team messaging and notifications.",
    tools=enterprise_tools
)

# Task to coordinate team communication
coordination_task = Task(
    description="Send task completion notifications to team members and update project channels",
    agent=communication_manager,
    expected_output="Team notifications sent and project channels updated successfully"
)

crew = Crew(
    agents=[communication_manager],
    tasks=[coordination_task]
)

crew.kickoff()
```

### Advanced Messaging with Block Kit

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

notification_agent = Agent(
    role="Notification Manager",
    goal="Create rich, interactive notifications and manage workspace communication",
    backstory="An AI assistant that specializes in creating engaging team notifications and updates.",
    tools=[enterprise_tools]
)

# Task to send rich notifications
notification_task = Task(
    description="""
    1. Send a formatted project completion message to #general with progress charts
    2. Send direct messages to team leads with task summaries
    3. Create interactive notification with action buttons for team feedback
    """,
    agent=notification_agent,
    expected_output="Rich notifications sent with interactive elements and formatted content"
)

crew = Crew(
    agents=[notification_agent],
    tasks=[notification_task]
)

crew.kickoff()
```

### Message Search and Analytics

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

analytics_agent = Agent(
    role="Communication Analyst",
    goal="Analyze team communication patterns and extract insights from conversations",
    backstory="An analytical AI that excels at understanding team dynamics through communication data.",
    tools=[enterprise_tools]
)

# Complex task involving search and analysis
analysis_task = Task(
    description="""
    1. Search for recent project-related messages across all channels
    2. Find users by email to identify team members
    3. Analyze communication patterns and response times
    4. Generate weekly team communication summary
    """,
    agent=analytics_agent,
    expected_output="Comprehensive communication analysis with team insights and recommendations"
)

crew = Crew(
    agents=[analytics_agent],
    tasks=[analysis_task]
)

crew.kickoff()
```

## Contact Support

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with Slack integration setup or troubleshooting.
</Card>


# Stripe Integration
Source: https://docs.crewai.com/en/enterprise/integrations/stripe

Payment processing and subscription management with Stripe integration for CrewAI.

## Overview

Enable your agents to manage payments, subscriptions, and customer billing through Stripe. Handle customer data, process subscriptions, manage products, and track financial transactions to streamline your payment workflows with AI-powered automation.

## Prerequisites

Before using the Stripe integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Stripe account with appropriate API permissions
* Connected your Stripe account through the [Integrations page](https://app.crewai.com/integrations)

## Available Tools

### **Customer Management**

<AccordionGroup>
  <Accordion title="STRIPE_CREATE_CUSTOMER">
    **Description:** Create a new customer in your Stripe account.

    **Parameters:**

    * `emailCreateCustomer` (string, required): Customer's email address
    * `name` (string, optional): Customer's full name
    * `description` (string, optional): Customer description for internal reference
    * `metadataCreateCustomer` (object, optional): Additional metadata as key-value pairs (e.g., `{"field1": 1, "field2": 2}`)
  </Accordion>

  <Accordion title="STRIPE_GET_CUSTOMER_BY_ID">
    **Description:** Retrieve a specific customer by their Stripe customer ID.

    **Parameters:**

    * `idGetCustomer` (string, required): The Stripe customer ID to retrieve
  </Accordion>

  <Accordion title="STRIPE_GET_CUSTOMERS">
    **Description:** Retrieve a list of customers with optional filtering.

    **Parameters:**

    * `emailGetCustomers` (string, optional): Filter customers by email address
    * `createdAfter` (string, optional): Filter customers created after this date (Unix timestamp)
    * `createdBefore` (string, optional): Filter customers created before this date (Unix timestamp)
    * `limitGetCustomers` (string, optional): Maximum number of customers to return (defaults to 10)
  </Accordion>

  <Accordion title="STRIPE_UPDATE_CUSTOMER">
    **Description:** Update an existing customer's information.

    **Parameters:**

    * `customerId` (string, required): The ID of the customer to update
    * `emailUpdateCustomer` (string, optional): Updated email address
    * `name` (string, optional): Updated customer name
    * `description` (string, optional): Updated customer description
    * `metadataUpdateCustomer` (object, optional): Updated metadata as key-value pairs
  </Accordion>
</AccordionGroup>

### **Subscription Management**

<AccordionGroup>
  <Accordion title="STRIPE_CREATE_SUBSCRIPTION">
    **Description:** Create a new subscription for a customer.

    **Parameters:**

    * `customerIdCreateSubscription` (string, required): The customer ID for whom the subscription will be created
    * `plan` (string, required): The plan ID for the subscription - Use Connect Portal Workflow Settings to allow users to select a plan
    * `metadataCreateSubscription` (object, optional): Additional metadata for the subscription
  </Accordion>

  <Accordion title="STRIPE_GET_SUBSCRIPTIONS">
    **Description:** Retrieve subscriptions with optional filtering.

    **Parameters:**

    * `customerIdGetSubscriptions` (string, optional): Filter subscriptions by customer ID
    * `subscriptionStatus` (string, optional): Filter by subscription status - Options: incomplete, incomplete\_expired, trialing, active, past\_due, canceled, unpaid
    * `limitGetSubscriptions` (string, optional): Maximum number of subscriptions to return (defaults to 10)
  </Accordion>
</AccordionGroup>

### **Product Management**

<AccordionGroup>
  <Accordion title="STRIPE_CREATE_PRODUCT">
    **Description:** Create a new product in your Stripe catalog.

    **Parameters:**

    * `productName` (string, required): The product name
    * `description` (string, optional): Product description
    * `metadataProduct` (object, optional): Additional product metadata as key-value pairs
  </Accordion>

  <Accordion title="STRIPE_GET_PRODUCT_BY_ID">
    **Description:** Retrieve a specific product by its Stripe product ID.

    **Parameters:**

    * `productId` (string, required): The Stripe product ID to retrieve
  </Accordion>

  <Accordion title="STRIPE_GET_PRODUCTS">
    **Description:** Retrieve a list of products with optional filtering.

    **Parameters:**

    * `createdAfter` (string, optional): Filter products created after this date (Unix timestamp)
    * `createdBefore` (string, optional): Filter products created before this date (Unix timestamp)
    * `limitGetProducts` (string, optional): Maximum number of products to return (defaults to 10)
  </Accordion>
</AccordionGroup>

### **Financial Operations**

<AccordionGroup>
  <Accordion title="STRIPE_GET_BALANCE_TRANSACTIONS">
    **Description:** Retrieve balance transactions from your Stripe account.

    **Parameters:**

    * `balanceTransactionType` (string, optional): Filter by transaction type - Options: charge, refund, payment, payment\_refund
    * `paginationParameters` (object, optional): Pagination settings
      * `pageCursor` (string, optional): Page cursor for pagination
  </Accordion>

  <Accordion title="STRIPE_GET_PLANS">
    **Description:** Retrieve subscription plans from your Stripe account.

    **Parameters:**

    * `isPlanActive` (boolean, optional): Filter by plan status - true for active plans, false for inactive plans
    * `paginationParameters` (object, optional): Pagination settings
      * `pageCursor` (string, optional): Page cursor for pagination
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Stripe Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Stripe tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Stripe capabilities
stripe_agent = Agent(
    role="Payment Manager",
    goal="Manage customer payments, subscriptions, and billing operations efficiently",
    backstory="An AI assistant specialized in payment processing and subscription management.",
    tools=[enterprise_tools]
)

# Task to create a new customer
create_customer_task = Task(
    description="Create a new premium customer John Doe with email john.doe@example.com",
    agent=stripe_agent,
    expected_output="Customer created successfully with customer ID"
)

# Run the task
crew = Crew(
    agents=[stripe_agent],
    tasks=[create_customer_task]
)

crew.kickoff()
```

### Filtering Specific Stripe Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Stripe tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["stripe_create_customer", "stripe_create_subscription", "stripe_get_balance_transactions"]
)

billing_manager = Agent(
    role="Billing Manager",
    goal="Handle customer billing, subscriptions, and payment processing",
    backstory="An experienced billing manager who handles subscription lifecycle and payment operations.",
    tools=enterprise_tools
)

# Task to manage billing operations
billing_task = Task(
    description="Create a new customer and set up their premium subscription plan",
    agent=billing_manager,
    expected_output="Customer created and subscription activated successfully"
)

crew = Crew(
    agents=[billing_manager],
    tasks=[billing_task]
)

crew.kickoff()
```

### Subscription Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

subscription_manager = Agent(
    role="Subscription Manager",
    goal="Manage customer subscriptions and optimize recurring revenue",
    backstory="An AI assistant that specializes in subscription lifecycle management and customer retention.",
    tools=[enterprise_tools]
)

# Task to manage subscription operations
subscription_task = Task(
    description="""
    1. Create a new product "Premium Service Plan" with advanced features
    2. Set up subscription plans with different tiers
    3. Create customers and assign them to appropriate plans
    4. Monitor subscription status and handle billing issues
    """,
    agent=subscription_manager,
    expected_output="Subscription management system configured with customers and active plans"
)

crew = Crew(
    agents=[subscription_manager],
    tasks=[subscription_task]
)

crew.kickoff()
```

### Financial Analytics and Reporting

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

financial_analyst = Agent(
    role="Financial Analyst",
    goal="Analyze payment data and generate financial insights",
    backstory="An analytical AI that excels at extracting insights from payment and subscription data.",
    tools=[enterprise_tools]
)

# Complex task involving financial analysis
analytics_task = Task(
    description="""
    1. Retrieve balance transactions for the current month
    2. Analyze customer payment patterns and subscription trends
    3. Identify high-value customers and subscription performance
    4. Generate monthly financial performance report
    """,
    agent=financial_analyst,
    expected_output="Comprehensive financial analysis with payment insights and recommendations"
)

crew = Crew(
    agents=[financial_analyst],
    tasks=[analytics_task]
)

crew.kickoff()
```

## Subscription Status Reference

Understanding subscription statuses:

* **incomplete** - Subscription requires payment method or payment confirmation
* **incomplete\_expired** - Subscription expired before payment was confirmed
* **trialing** - Subscription is in trial period
* **active** - Subscription is active and current
* **past\_due** - Payment failed but subscription is still active
* **canceled** - Subscription has been canceled
* **unpaid** - Payment failed and subscription is no longer active

## Metadata Usage

Metadata allows you to store additional information about customers, subscriptions, and products:

```json
{
  "customer_segment": "enterprise",
  "acquisition_source": "google_ads",
  "lifetime_value": "high",
  "custom_field_1": "value1"
}
```

This integration enables comprehensive payment and subscription management automation, allowing your AI agents to handle billing operations seamlessly within your Stripe ecosystem.


# Zendesk Integration
Source: https://docs.crewai.com/en/enterprise/integrations/zendesk

Customer support and helpdesk management with Zendesk integration for CrewAI.

## Overview

Enable your agents to manage customer support operations through Zendesk. Create and update tickets, manage users, track support metrics, and streamline your customer service workflows with AI-powered automation.

## Prerequisites

Before using the Zendesk integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Zendesk account with appropriate API permissions
* Connected your Zendesk account through the [Integrations page](https://app.crewai.com/integrations)

## Available Tools

### **Ticket Management**

<AccordionGroup>
  <Accordion title="ZENDESK_CREATE_TICKET">
    **Description:** Create a new support ticket in Zendesk.

    **Parameters:**

    * `ticketSubject` (string, required): Ticket subject line (e.g., "Help, my printer is on fire!")
    * `ticketDescription` (string, required): First comment that appears on the ticket (e.g., "The smoke is very colorful.")
    * `requesterName` (string, required): Name of the user requesting support (e.g., "Jane Customer")
    * `requesterEmail` (string, required): Email of the user requesting support (e.g., "[jane@example.com](mailto:jane@example.com)")
    * `assigneeId` (string, optional): Zendesk Agent ID assigned to this ticket - Use Connect Portal Workflow Settings to allow users to select an assignee
    * `ticketType` (string, optional): Ticket type - Options: problem, incident, question, task
    * `ticketPriority` (string, optional): Priority level - Options: urgent, high, normal, low
    * `ticketStatus` (string, optional): Ticket status - Options: new, open, pending, hold, solved, closed
    * `ticketDueAt` (string, optional): Due date for task-type tickets (ISO 8601 timestamp)
    * `ticketTags` (string, optional): Array of tags to apply (e.g., `["enterprise", "other_tag"]`)
    * `ticketExternalId` (string, optional): External ID to link tickets to local records
    * `ticketCustomFields` (object, optional): Custom field values in JSON format
  </Accordion>

  <Accordion title="ZENDESK_UPDATE_TICKET">
    **Description:** Update an existing support ticket in Zendesk.

    **Parameters:**

    * `ticketId` (string, required): ID of the ticket to update (e.g., "35436")
    * `ticketSubject` (string, optional): Updated ticket subject
    * `requesterName` (string, required): Name of the user who requested this ticket
    * `requesterEmail` (string, required): Email of the user who requested this ticket
    * `assigneeId` (string, optional): Updated assignee ID - Use Connect Portal Workflow Settings
    * `ticketType` (string, optional): Updated ticket type - Options: problem, incident, question, task
    * `ticketPriority` (string, optional): Updated priority - Options: urgent, high, normal, low
    * `ticketStatus` (string, optional): Updated status - Options: new, open, pending, hold, solved, closed
    * `ticketDueAt` (string, optional): Updated due date (ISO 8601 timestamp)
    * `ticketTags` (string, optional): Updated tags array
    * `ticketExternalId` (string, optional): Updated external ID
    * `ticketCustomFields` (object, optional): Updated custom field values
  </Accordion>

  <Accordion title="ZENDESK_GET_TICKET_BY_ID">
    **Description:** Retrieve a specific ticket by its ID.

    **Parameters:**

    * `ticketId` (string, required): The ticket ID to retrieve (e.g., "35436")
  </Accordion>

  <Accordion title="ZENDESK_ADD_COMMENT_TO_TICKET">
    **Description:** Add a comment or internal note to an existing ticket.

    **Parameters:**

    * `ticketId` (string, required): ID of the ticket to add comment to (e.g., "35436")
    * `commentBody` (string, required): Comment message (accepts plain text or HTML, e.g., "Thanks for your help!")
    * `isInternalNote` (boolean, optional): Set to true for internal notes instead of public replies (defaults to false)
    * `isPublic` (boolean, optional): True for public comments, false for internal notes
  </Accordion>

  <Accordion title="ZENDESK_SEARCH_TICKETS">
    **Description:** Search for tickets using various filters and criteria.

    **Parameters:**

    * `ticketSubject` (string, optional): Filter by text in ticket subject
    * `ticketDescription` (string, optional): Filter by text in ticket description and comments
    * `ticketStatus` (string, optional): Filter by status - Options: new, open, pending, hold, solved, closed
    * `ticketType` (string, optional): Filter by type - Options: problem, incident, question, task, no\_type
    * `ticketPriority` (string, optional): Filter by priority - Options: urgent, high, normal, low, no\_priority
    * `requesterId` (string, optional): Filter by requester user ID
    * `assigneeId` (string, optional): Filter by assigned agent ID
    * `recipientEmail` (string, optional): Filter by original recipient email address
    * `ticketTags` (string, optional): Filter by ticket tags
    * `ticketExternalId` (string, optional): Filter by external ID
    * `createdDate` (object, optional): Filter by creation date with operator (EQUALS, LESS\_THAN\_EQUALS, GREATER\_THAN\_EQUALS) and value
    * `updatedDate` (object, optional): Filter by update date with operator and value
    * `dueDate` (object, optional): Filter by due date with operator and value
    * `sort_by` (string, optional): Sort field - Options: created\_at, updated\_at, priority, status, ticket\_type
    * `sort_order` (string, optional): Sort direction - Options: asc, desc
  </Accordion>
</AccordionGroup>

### **User Management**

<AccordionGroup>
  <Accordion title="ZENDESK_CREATE_USER">
    **Description:** Create a new user in Zendesk.

    **Parameters:**

    * `name` (string, required): User's full name
    * `email` (string, optional): User's email address (e.g., "[jane@example.com](mailto:jane@example.com)")
    * `phone` (string, optional): User's phone number
    * `role` (string, optional): User role - Options: admin, agent, end-user
    * `externalId` (string, optional): Unique identifier from another system
    * `details` (string, optional): Additional user details
    * `notes` (string, optional): Internal notes about the user
  </Accordion>

  <Accordion title="ZENDESK_UPDATE_USER">
    **Description:** Update an existing user's information.

    **Parameters:**

    * `userId` (string, required): ID of the user to update
    * `name` (string, optional): Updated user name
    * `email` (string, optional): Updated email (adds as secondary email on update)
    * `phone` (string, optional): Updated phone number
    * `role` (string, optional): Updated role - Options: admin, agent, end-user
    * `externalId` (string, optional): Updated external ID
    * `details` (string, optional): Updated user details
    * `notes` (string, optional): Updated internal notes
  </Accordion>

  <Accordion title="ZENDESK_GET_USER_BY_ID">
    **Description:** Retrieve a specific user by their ID.

    **Parameters:**

    * `userId` (string, required): The user ID to retrieve
  </Accordion>

  <Accordion title="ZENDESK_SEARCH_USERS">
    **Description:** Search for users using various criteria.

    **Parameters:**

    * `name` (string, optional): Filter by user name
    * `email` (string, optional): Filter by user email (e.g., "[jane@example.com](mailto:jane@example.com)")
    * `role` (string, optional): Filter by role - Options: admin, agent, end-user
    * `externalId` (string, optional): Filter by external ID
    * `sort_by` (string, optional): Sort field - Options: created\_at, updated\_at
    * `sort_order` (string, optional): Sort direction - Options: asc, desc
  </Accordion>
</AccordionGroup>

### **Administrative Tools**

<AccordionGroup>
  <Accordion title="ZENDESK_GET_TICKET_FIELDS">
    **Description:** Retrieve all standard and custom fields available for tickets.

    **Parameters:**

    * `paginationParameters` (object, optional): Pagination settings
      * `pageCursor` (string, optional): Page cursor for pagination
  </Accordion>

  <Accordion title="ZENDESK_GET_TICKET_AUDITS">
    **Description:** Get audit records (read-only history) for tickets.

    **Parameters:**

    * `ticketId` (string, optional): Get audits for specific ticket (if empty, retrieves audits for all non-archived tickets, e.g., "1234")
    * `paginationParameters` (object, optional): Pagination settings
      * `pageCursor` (string, optional): Page cursor for pagination
  </Accordion>
</AccordionGroup>

## Custom Fields

Custom fields allow you to store additional information specific to your organization:

```json
[
  { "id": 27642, "value": "745" },
  { "id": 27648, "value": "yes" }
]
```

## Ticket Priority Levels

Understanding priority levels:

* **urgent** - Critical issues requiring immediate attention
* **high** - Important issues that should be addressed quickly
* **normal** - Standard priority for most tickets
* **low** - Minor issues that can be addressed when convenient

## Ticket Status Workflow

Standard ticket status progression:

* **new** - Recently created, not yet assigned
* **open** - Actively being worked on
* **pending** - Waiting for customer response or external action
* **hold** - Temporarily paused
* **solved** - Issue resolved, awaiting customer confirmation
* **closed** - Ticket completed and closed

## Usage Examples

### Basic Zendesk Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Zendesk tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Zendesk capabilities
zendesk_agent = Agent(
    role="Support Manager",
    goal="Manage customer support tickets and provide excellent customer service",
    backstory="An AI assistant specialized in customer support operations and ticket management.",
    tools=[enterprise_tools]
)

# Task to create a new support ticket
create_ticket_task = Task(
    description="Create a high-priority support ticket for John Smith who is unable to access his account after password reset",
    agent=zendesk_agent,
    expected_output="Support ticket created successfully with ticket ID"
)

# Run the task
crew = Crew(
    agents=[zendesk_agent],
    tasks=[create_ticket_task]
)

crew.kickoff()
```

### Filtering Specific Zendesk Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Zendesk tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["zendesk_create_ticket", "zendesk_update_ticket", "zendesk_add_comment_to_ticket"]
)

support_agent = Agent(
    role="Customer Support Agent",
    goal="Handle customer inquiries and resolve support issues efficiently",
    backstory="An experienced support agent who specializes in ticket resolution and customer communication.",
    tools=enterprise_tools
)

# Task to manage support workflow
support_task = Task(
    description="Create a ticket for login issues, add troubleshooting comments, and update status to resolved",
    agent=support_agent,
    expected_output="Support ticket managed through complete resolution workflow"
)

crew = Crew(
    agents=[support_agent],
    tasks=[support_task]
)

crew.kickoff()
```

### Advanced Ticket Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

ticket_manager = Agent(
    role="Ticket Manager",
    goal="Manage support ticket workflows and ensure timely resolution",
    backstory="An AI assistant that specializes in support ticket triage and workflow optimization.",
    tools=[enterprise_tools]
)

# Task to manage ticket lifecycle
ticket_workflow = Task(
    description="""
    1. Create a new support ticket for account access issues
    2. Add internal notes with troubleshooting steps
    3. Update ticket priority based on customer tier
    4. Add resolution comments and close the ticket
    """,
    agent=ticket_manager,
    expected_output="Complete ticket lifecycle managed from creation to resolution"
)

crew = Crew(
    agents=[ticket_manager],
    tasks=[ticket_workflow]
)

crew.kickoff()
```

### Support Analytics and Reporting

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

support_analyst = Agent(
    role="Support Analyst",
    goal="Analyze support metrics and generate insights for team performance",
    backstory="An analytical AI that excels at extracting insights from support data and ticket patterns.",
    tools=[enterprise_tools]
)

# Complex task involving analytics and reporting
analytics_task = Task(
    description="""
    1. Search for all open tickets from the last 30 days
    2. Analyze ticket resolution times and customer satisfaction
    3. Identify common issues and support patterns
    4. Generate weekly support performance report
    """,
    agent=support_analyst,
    expected_output="Comprehensive support analytics report with performance insights and recommendations"
)

crew = Crew(
    agents=[support_analyst],
    tasks=[analytics_task]
)

crew.kickoff()
```


# CrewAI Enterprise
Source: https://docs.crewai.com/en/enterprise/introduction

Deploy, monitor, and scale your AI agent workflows

## Introduction

CrewAI Enterprise provides a platform for deploying, monitoring, and scaling your crews and agents in a production environment.

<Frame>
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crewai-enterprise-dashboard.png" alt="CrewAI Enterprise Dashboard" />
</Frame>

CrewAI Enterprise extends the power of the open-source framework with features designed for production deployments, collaboration, and scalability. Deploy your crews to a managed infrastructure and monitor their execution in real-time.

## Key Features

<CardGroup cols={2}>
  <Card title="Crew Deployments" icon="rocket">
    Deploy your crews to a managed infrastructure with a few clicks
  </Card>

  <Card title="API Access" icon="code">
    Access your deployed crews via REST API for integration with existing systems
  </Card>

  <Card title="Observability" icon="chart-line">
    Monitor your crews with detailed execution traces and logs
  </Card>

  <Card title="Tool Repository" icon="toolbox">
    Publish and install tools to enhance your crews' capabilities
  </Card>

  <Card title="Webhook Streaming" icon="webhook">
    Stream real-time events and updates to your systems
  </Card>

  <Card title="Crew Studio" icon="paintbrush">
    Create and customize crews using a no-code/low-code interface
  </Card>
</CardGroup>

## Deployment Options

<CardGroup cols={3}>
  <Card title="GitHub Integration" icon="github">
    Connect directly to your GitHub repositories to deploy code
  </Card>

  <Card title="Crew Studio" icon="palette">
    Deploy crews created through the no-code Crew Studio interface
  </Card>

  <Card title="CLI Deployment" icon="terminal">
    Use the CrewAI CLI for more advanced deployment workflows
  </Card>
</CardGroup>

## Getting Started

<Steps>
  <Step title="Sign up for an account">
    Create your account at [app.crewai.com](https://app.crewai.com)

    <Card title="Sign Up" icon="user" href="https://app.crewai.com/signup">
      Sign Up
    </Card>
  </Step>

  <Step title="Build your first crew">
    Use code or Crew Studio to build your crew

    <Card title="Build Crew" icon="paintbrush" href="/en/enterprise/guides/build-crew">
      Build Crew
    </Card>
  </Step>

  <Step title="Deploy your crew">
    Deploy your crew to the Enterprise platform

    <Card title="Deploy Crew" icon="rocket" href="/en/enterprise/guides/deploy-crew">
      Deploy Crew
    </Card>
  </Step>

  <Step title="Access your crew">
    Integrate with your crew via the generated API endpoints

    <Card title="API Access" icon="code" href="/en/enterprise/guides/kickoff-crew">
      Use the Crew API
    </Card>
  </Step>
</Steps>

For detailed instructions, check out our [deployment guide](/en/enterprise/guides/deploy-crew) or click the button below to get started.


# FAQs
Source: https://docs.crewai.com/en/enterprise/resources/frequently-asked-questions

Frequently asked questions about CrewAI Enterprise

<AccordionGroup>
  <Accordion title="How is task execution handled in the hierarchical process?">
    In the hierarchical process, a manager agent is automatically created and coordinates the workflow, delegating tasks and validating outcomes for streamlined and effective execution. The manager agent utilizes tools to facilitate task delegation and execution by agents under the manager's guidance. The manager LLM is crucial for the hierarchical process and must be set up correctly for proper function.
  </Accordion>

  <Accordion title="Where can I get the latest CrewAI documentation?">
    The most up-to-date documentation for CrewAI is available on our official documentation website: [https://docs.crewai.com/](https://docs.crewai.com/)
    <Card href="https://docs.crewai.com/" icon="books">CrewAI Docs</Card>
  </Accordion>

  <Accordion title="What are the key differences between Hierarchical and Sequential Processes in CrewAI?">
    #### Hierarchical Process:

    * Tasks are delegated and executed based on a structured chain of command
    * A manager language model (`manager_llm`) must be specified for the manager agent
    * Manager agent oversees task execution, planning, delegation, and validation
    * Tasks are not pre-assigned; the manager allocates tasks to agents based on their capabilities

    #### Sequential Process:

    * Tasks are executed one after another, ensuring tasks are completed in an orderly progression
    * Output of one task serves as context for the next
    * Task execution follows the predefined order in the task list

    #### Which Process is Better for Complex Projects?

    The hierarchical process is better suited for complex projects because it allows for:

    * **Dynamic task allocation and delegation**: Manager agent can assign tasks based on agent capabilities
    * **Structured validation and oversight**: Manager agent reviews task outputs and ensures completion
    * **Complex task management**: Precise control over tool availability at the agent level
  </Accordion>

  <Accordion title="What are the benefits of using memory in the CrewAI framework?">
    * **Adaptive Learning**: Crews become more efficient over time, adapting to new information and refining their approach to tasks
    * **Enhanced Personalization**: Memory enables agents to remember user preferences and historical interactions, leading to personalized experiences
    * **Improved Problem Solving**: Access to a rich memory store aids agents in making more informed decisions, drawing on past learnings and contextual insights
  </Accordion>

  <Accordion title="What is the purpose of setting a maximum RPM limit for an agent?">
    Setting a maximum RPM limit for an agent prevents the agent from making too many requests to external services, which can help to avoid rate limits and improve performance.
  </Accordion>

  <Accordion title="What role does human input play in the execution of tasks within a CrewAI crew?">
    Human input allows agents to request additional information or clarification when necessary. This feature is crucial in complex decision-making processes or when agents require more details to complete a task effectively.

    To integrate human input into agent execution, set the `human_input` flag in the task definition. When enabled, the agent prompts the user for input before delivering its final answer. This input can provide extra context, clarify ambiguities, or validate the agent's output.

    For detailed implementation guidance, see our [Human-in-the-Loop guide](/en/how-to/human-in-the-loop).
  </Accordion>

  <Accordion title="What advanced customization options are available for tailoring and enhancing agent behavior and capabilities in CrewAI?">
    CrewAI provides a range of advanced customization options:

    * **Language Model Customization**: Agents can be customized with specific language models (`llm`) and function-calling language models (`function_calling_llm`)
    * **Performance and Debugging Settings**: Adjust an agent's performance and monitor its operations
    * **Verbose Mode**: Enables detailed logging of an agent's actions, useful for debugging and optimization
    * **RPM Limit**: Sets the maximum number of requests per minute (`max_rpm`)
    * **Maximum Iterations**: The `max_iter` attribute allows users to define the maximum number of iterations an agent can perform for a single task
    * **Delegation and Autonomy**: Control an agent's ability to delegate or ask questions with the `allow_delegation` attribute (default: True)
    * **Human Input Integration**: Agents can request additional information or clarification when necessary
  </Accordion>

  <Accordion title="In what scenarios is human input particularly useful in agent execution?">
    Human input is particularly useful when:

    * **Agents require additional information or clarification**: When agents encounter ambiguity or incomplete data
    * **Agents need to make complex or sensitive decisions**: Human input can assist in ethical or nuanced decision-making
    * **Oversight and validation of agent output**: Human input can help validate results and prevent errors
    * **Customizing agent behavior**: Human input can provide feedback to refine agent responses over time
    * **Identifying and resolving errors or limitations**: Human input helps address agent capability gaps
  </Accordion>

  <Accordion title="What are the different types of memory that are available in crewAI?">
    The different types of memory available in CrewAI are:

    * **Short-term memory**: Temporary storage for immediate context
    * **Long-term memory**: Persistent storage for learned patterns and information
    * **Entity memory**: Focused storage for specific entities and their attributes
    * **Contextual memory**: Memory that maintains context across interactions

    Learn more about the different types of memory:
    <Card href="https://docs.crewai.com/concepts/memory" icon="brain">CrewAI Memory</Card>
  </Accordion>

  <Accordion title="How do I use Output Pydantic in a Task?">
    To use Output Pydantic in a task, you need to define the expected output of the task as a Pydantic model. Here's a quick example:

    <Steps>
      <Step title="Define a Pydantic model">
        ```python
        from pydantic import BaseModel

        class User(BaseModel):
            name: str
            age: int
        ```
      </Step>

      <Step title="Create a task with Output Pydantic">
        ```python
        from crewai import Task, Crew, Agent
        from my_models import User

        task = Task(
            description="Create a user with the provided name and age",
            expected_output=User,  # This is the Pydantic model
            agent=agent,
            tools=[tool1, tool2]
        )
        ```
      </Step>

      <Step title="Set the output_pydantic attribute in your agent">
        ```python
        from crewai import Agent
        from my_models import User

        agent = Agent(
            role='User Creator',
            goal='Create users',
            backstory='I am skilled in creating user accounts',
            tools=[tool1, tool2],
            output_pydantic=User
        )
        ```
      </Step>
    </Steps>

    Here's a tutorial on how to consistently get structured outputs from your agents:

    <Frame>
      <iframe height="400" width="100%" src="https://www.youtube.com/embed/dNpKQk5uxHw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />
    </Frame>
  </Accordion>

  <Accordion title="How can I create custom tools for my CrewAI agents?">
    You can create custom tools by subclassing the `BaseTool` class provided by CrewAI or by using the tool decorator. Subclassing involves defining a new class that inherits from `BaseTool`, specifying the name, description, and the `_run` method for operational logic. The tool decorator allows you to create a `Tool` object directly with the required attributes and a functional logic.

    <Card href="https://docs.crewai.com/how-to/create-custom-tools" icon="code">CrewAI Tools Guide</Card>
  </Accordion>

  <Accordion title="How can you control the maximum number of requests per minute that the entire crew can perform?">
    The `max_rpm` attribute sets the maximum number of requests per minute the crew can perform to avoid rate limits and will override individual agents' `max_rpm` settings if you set it.
  </Accordion>
</AccordionGroup>


# CrewAI Examples
Source: https://docs.crewai.com/en/examples/example

A collection of examples that show how to use CrewAI framework to automate workflows.

<CardGroup cols={3}>
  <Card title="Marketing Strategy" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/marketing_strategy" icon="bullhorn" iconType="solid">
    Automate marketing strategy creation with CrewAI.
  </Card>

  <Card title="Surprise Trip" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/surprise_trip" icon="plane" iconType="duotone">
    Create a surprise trip itinerary with CrewAI.
  </Card>

  <Card title="Match Profile to Positions" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/match_profile_to_positions" icon="linkedin" iconType="duotone">
    Match a profile to jobpositions with CrewAI.
  </Card>

  <Card title="Create Job Posting" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/job-posting" icon="newspaper" iconType="duotone">
    Create a job posting with CrewAI.
  </Card>

  <Card title="Game Generator" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/game-builder-crew" icon="gamepad" iconType="duotone">
    Create a game with CrewAI.
  </Card>

  <Card title="Find Job Candidates" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/recruitment" icon="user-group" iconType="duotone">
    Find job candidates with CrewAI.
  </Card>
</CardGroup>


# Customizing Prompts
Source: https://docs.crewai.com/en/guides/advanced/customizing-prompts

Dive deeper into low-level prompt customization for CrewAI, enabling super custom and complex use cases for different models and languages.

## Why Customize Prompts?

Although CrewAI's default prompts work well for many scenarios, low-level customization opens the door to significantly more flexible and powerful agent behavior. Here's why you might want to take advantage of this deeper control:

1. **Optimize for specific LLMs** – Different models (such as GPT-4, Claude, or Llama) thrive with prompt formats tailored to their unique architectures.
2. **Change the language** – Build agents that operate exclusively in languages beyond English, handling nuances with precision.
3. **Specialize for complex domains** – Adapt prompts for highly specialized industries like healthcare, finance, or legal.
4. **Adjust tone and style** – Make agents more formal, casual, creative, or analytical.
5. **Support super custom use cases** – Utilize advanced prompt structures and formatting to meet intricate, project-specific requirements.

This guide explores how to tap into CrewAI's prompts at a lower level, giving you fine-grained control over how agents think and interact.

## Understanding CrewAI's Prompt System

Under the hood, CrewAI employs a modular prompt system that you can customize extensively:

* **Agent templates** – Govern each agent's approach to their assigned role.
* **Prompt slices** – Control specialized behaviors such as tasks, tool usage, and output structure.
* **Error handling** – Direct how agents respond to failures, exceptions, or timeouts.
* **Tool-specific prompts** – Define detailed instructions for how tools are invoked or utilized.

Check out the [original prompt templates in CrewAI's repository](https://github.com/crewAIInc/crewAI/blob/main/src/crewai/translations/en.json) to see how these elements are organized. From there, you can override or adapt them as needed to unlock advanced behaviors.

## Understanding Default System Instructions

<Warning>
  **Production Transparency Issue**: CrewAI automatically injects default instructions into your prompts that you might not be aware of. This section explains what's happening under the hood and how to gain full control.
</Warning>

When you define an agent with `role`, `goal`, and `backstory`, CrewAI automatically adds additional system instructions that control formatting and behavior. Understanding these default injections is crucial for production systems where you need full prompt transparency.

### What CrewAI Automatically Injects

Based on your agent configuration, CrewAI adds different default instructions:

#### For Agents Without Tools

```text
"I MUST use these formats, my job depends on it!"
```

#### For Agents With Tools

```text
"IMPORTANT: Use the following format in your response:

Thought: you should always think about what to do
Action: the action to take, only one name of [tool_names]
Action Input: the input to the action, just a simple JSON object...
```

#### For Structured Outputs (JSON/Pydantic)

````text
"Ensure your final answer contains only the content in the following format: {output_format}
Ensure the final output does not include any code block markers like ```json or ```python."
````

### Viewing the Complete System Prompt

To see exactly what prompt is being sent to your LLM, you can inspect the generated prompt:

```python
from crewai import Agent, Crew, Task
from crewai.utilities.prompts import Prompts

# Create your agent
agent = Agent(
    role="Data Analyst",
    goal="Analyze data and provide insights",
    backstory="You are an expert data analyst with 10 years of experience.",
    verbose=True
)

# Create a sample task
task = Task(
    description="Analyze the sales data and identify trends",
    expected_output="A detailed analysis with key insights and trends",
    agent=agent
)

# Create the prompt generator
prompt_generator = Prompts(
    agent=agent,
    has_tools=len(agent.tools) > 0,
    use_system_prompt=agent.use_system_prompt
)

# Generate and inspect the actual prompt
generated_prompt = prompt_generator.task_execution()

# Print the complete system prompt that will be sent to the LLM
if "system" in generated_prompt:
    print("=== SYSTEM PROMPT ===")
    print(generated_prompt["system"])
    print("\n=== USER PROMPT ===")
    print(generated_prompt["user"])
else:
    print("=== COMPLETE PROMPT ===")
    print(generated_prompt["prompt"])

# You can also see how the task description gets formatted
print("\n=== TASK CONTEXT ===")
print(f"Task Description: {task.description}")
print(f"Expected Output: {task.expected_output}")
```

### Overriding Default Instructions

You have several options to gain full control over the prompts:

#### Option 1: Custom Templates (Recommended)

```python
from crewai import Agent

# Define your own system template without default instructions
custom_system_template = """You are {role}. {backstory}
Your goal is: {goal}

Respond naturally and conversationally. Focus on providing helpful, accurate information."""

custom_prompt_template = """Task: {input}

Please complete this task thoughtfully."""

agent = Agent(
    role="Research Assistant",
    goal="Help users find accurate information",
    backstory="You are a helpful research assistant.",
    system_template=custom_system_template,
    prompt_template=custom_prompt_template,
    use_system_prompt=True  # Use separate system/user messages
)
```

#### Option 2: Custom Prompt File

Create a `custom_prompts.json` file to override specific prompt slices:

```json
{
  "slices": {
    "no_tools": "\nProvide your best answer in a natural, conversational way.",
    "tools": "\nYou have access to these tools: {tools}\n\nUse them when helpful, but respond naturally.",
    "formatted_task_instructions": "Format your response as: {output_format}"
  }
}
```

Then use it in your crew:

```python
crew = Crew(
    agents=[agent],
    tasks=[task],
    prompt_file="custom_prompts.json",
    verbose=True
)
```

#### Option 3: Disable System Prompts for o1 Models

```python
agent = Agent(
    role="Analyst",
    goal="Analyze data",
    backstory="Expert analyst",
    use_system_prompt=False  # Disables system prompt separation
)
```

### Debugging with Observability Tools

For production transparency, integrate with observability platforms to monitor all prompts and LLM interactions. This allows you to see exactly what prompts (including default instructions) are being sent to your LLMs.

See our [Observability documentation](/en/observability/overview) for detailed integration guides with various platforms including Langfuse, MLflow, Weights & Biases, and custom logging solutions.

### Best Practices for Production

1. **Always inspect generated prompts** before deploying to production
2. **Use custom templates** when you need full control over prompt content
3. **Integrate observability tools** for ongoing prompt monitoring (see [Observability docs](/en/observability/overview))
4. **Test with different LLMs** as default instructions may work differently across models
5. **Document your prompt customizations** for team transparency

<Tip>
  The default instructions exist to ensure consistent agent behavior, but they can interfere with domain-specific requirements. Use the customization options above to maintain full control over your agent's behavior in production systems.
</Tip>

## Best Practices for Managing Prompt Files

When engaging in low-level prompt customization, follow these guidelines to keep things organized and maintainable:

1. **Keep files separate** – Store your customized prompts in dedicated JSON files outside your main codebase.
2. **Version control** – Track changes within your repository, ensuring clear documentation of prompt adjustments over time.
3. **Organize by model or language** – Use naming schemes like `prompts_llama.json` or `prompts_es.json` to quickly identify specialized configurations.
4. **Document changes** – Provide comments or maintain a README detailing the purpose and scope of your customizations.
5. **Minimize alterations** – Only override the specific slices you genuinely need to adjust, keeping default functionality intact for everything else.

## The Simplest Way to Customize Prompts

One straightforward approach is to create a JSON file for the prompts you want to override and then point your Crew at that file:

1. Craft a JSON file with your updated prompt slices.
2. Reference that file via the `prompt_file` parameter in your Crew.

CrewAI then merges your customizations with the defaults, so you don't have to redefine every prompt. Here's how:

### Example: Basic Prompt Customization

Create a `custom_prompts.json` file with the prompts you want to modify. Ensure you list all top-level prompts it should contain, not just your changes:

```json
{
  "slices": {
    "format": "When responding, follow this structure:\n\nTHOUGHTS: Your step-by-step thinking\nACTION: Any tool you're using\nRESULT: Your final answer or conclusion"
  }
}
```

Then integrate it like so:

```python
from crewai import Agent, Crew, Task, Process

# Create agents and tasks as normal
researcher = Agent(
    role="Research Specialist",
    goal="Find information on quantum computing",
    backstory="You are a quantum physics expert",
    verbose=True
)

research_task = Task(
    description="Research quantum computing applications",
    expected_output="A summary of practical applications",
    agent=researcher
)

# Create a crew with your custom prompt file
crew = Crew(
    agents=[researcher],
    tasks=[research_task],
    prompt_file="path/to/custom_prompts.json",
    verbose=True
)

# Run the crew
result = crew.kickoff()
```

With these few edits, you gain low-level control over how your agents communicate and solve tasks.

## Optimizing for Specific Models

Different models thrive on differently structured prompts. Making deeper adjustments can significantly boost performance by aligning your prompts with a model's nuances.

### Example: Llama 3.3 Prompting Template

For instance, when dealing with Meta's Llama 3.3, deeper-level customization may reflect the recommended structure described at:
[https://www.llama.com/docs/model-cards-and-prompt-formats/llama3\_1/#prompt-template](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1/#prompt-template)

Here's an example to highlight how you might fine-tune an Agent to leverage Llama 3.3 in code:

```python
from crewai import Agent, Crew, Task, Process
from crewai_tools import DirectoryReadTool, FileReadTool

# Define templates for system, user (prompt), and assistant (response) messages
system_template = """<|begin_of_text|><|start_header_id|>system<|end_header_id|>{{ .System }}<|eot_id|>"""
prompt_template = """<|start_header_id|>user<|end_header_id|>{{ .Prompt }}<|eot_id|>"""
response_template = """<|start_header_id|>assistant<|end_header_id|>{{ .Response }}<|eot_id|>"""

# Create an Agent using Llama-specific layouts
principal_engineer = Agent(
    role="Principal Engineer",
    goal="Oversee AI architecture and make high-level decisions",
    backstory="You are the lead engineer responsible for critical AI systems",
    verbose=True,
    llm="groq/llama-3.3-70b-versatile",  # Using the Llama 3 model
    system_template=system_template,
    prompt_template=prompt_template,
    response_template=response_template,
    tools=[DirectoryReadTool(), FileReadTool()]
)

# Define a sample task
engineering_task = Task(
    description="Review AI implementation files for potential improvements",
    expected_output="A summary of key findings and recommendations",
    agent=principal_engineer
)

# Create a Crew for the task
llama_crew = Crew(
    agents=[principal_engineer],
    tasks=[engineering_task],
    process=Process.sequential,
    verbose=True
)

# Execute the crew
result = llama_crew.kickoff()
print(result.raw)
```

Through this deeper configuration, you can exercise comprehensive, low-level control over your Llama-based workflows without needing a separate JSON file.

## Conclusion

Low-level prompt customization in CrewAI opens the door to super custom, complex use cases. By establishing well-organized prompt files (or direct inline templates), you can accommodate various models, languages, and specialized domains. This level of flexibility ensures you can craft precisely the AI behavior you need, all while knowing CrewAI still provides reliable defaults when you don't override them.

<Check>
  You now have the foundation for advanced prompt customizations in CrewAI. Whether you're adapting for model-specific structures or domain-specific constraints, this low-level approach lets you shape agent interactions in highly specialized ways.
</Check>


# Fingerprinting
Source: https://docs.crewai.com/en/guides/advanced/fingerprinting

Learn how to use CrewAI's fingerprinting system to uniquely identify and track components throughout their lifecycle.

## Overview

Fingerprints in CrewAI provide a way to uniquely identify and track components throughout their lifecycle. Each `Agent`, `Crew`, and `Task` automatically receives a unique fingerprint when created, which cannot be manually overridden.

These fingerprints can be used for:

* Auditing and tracking component usage
* Ensuring component identity integrity
* Attaching metadata to components
* Creating a traceable chain of operations

## How Fingerprints Work

A fingerprint is an instance of the `Fingerprint` class from the `crewai.security` module. Each fingerprint contains:

* A UUID string: A unique identifier for the component that is automatically generated and cannot be manually set
* A creation timestamp: When the fingerprint was generated, automatically set and cannot be manually modified
* Metadata: A dictionary of additional information that can be customized

Fingerprints are automatically generated and assigned when a component is created. Each component exposes its fingerprint through a read-only property.

## Basic Usage

### Accessing Fingerprints

```python
from crewai import Agent, Crew, Task

# Create components - fingerprints are automatically generated
agent = Agent(
    role="Data Scientist",
    goal="Analyze data",
    backstory="Expert in data analysis"
)

crew = Crew(
    agents=[agent],
    tasks=[]
)

task = Task(
    description="Analyze customer data",
    expected_output="Insights from data analysis",
    agent=agent
)

# Access the fingerprints
agent_fingerprint = agent.fingerprint
crew_fingerprint = crew.fingerprint
task_fingerprint = task.fingerprint

# Print the UUID strings
print(f"Agent fingerprint: {agent_fingerprint.uuid_str}")
print(f"Crew fingerprint: {crew_fingerprint.uuid_str}")
print(f"Task fingerprint: {task_fingerprint.uuid_str}")
```

### Working with Fingerprint Metadata

You can add metadata to fingerprints for additional context:

```python
# Add metadata to the agent's fingerprint
agent.security_config.fingerprint.metadata = {
    "version": "1.0",
    "department": "Data Science",
    "project": "Customer Analysis"
}

# Access the metadata
print(f"Agent metadata: {agent.fingerprint.metadata}")
```

## Fingerprint Persistence

Fingerprints are designed to persist and remain unchanged throughout a component's lifecycle. If you modify a component, the fingerprint remains the same:

```python
original_fingerprint = agent.fingerprint.uuid_str

# Modify the agent
agent.goal = "New goal for analysis"

# The fingerprint remains unchanged
assert agent.fingerprint.uuid_str == original_fingerprint
```

## Deterministic Fingerprints

While you cannot directly set the UUID and creation timestamp, you can create deterministic fingerprints using the `generate` method with a seed:

```python
from crewai.security import Fingerprint

# Create a deterministic fingerprint using a seed string
deterministic_fingerprint = Fingerprint.generate(seed="my-agent-id")

# The same seed always produces the same fingerprint
same_fingerprint = Fingerprint.generate(seed="my-agent-id")
assert deterministic_fingerprint.uuid_str == same_fingerprint.uuid_str

# You can also set metadata
custom_fingerprint = Fingerprint.generate(
    seed="my-agent-id",
    metadata={"version": "1.0"}
)
```

## Advanced Usage

### Fingerprint Structure

Each fingerprint has the following structure:

```python
from crewai.security import Fingerprint

fingerprint = agent.fingerprint

# UUID string - the unique identifier (auto-generated)
uuid_str = fingerprint.uuid_str  # e.g., "123e4567-e89b-12d3-a456-426614174000"

# Creation timestamp (auto-generated)
created_at = fingerprint.created_at  # A datetime object

# Metadata - for additional information (can be customized)
metadata = fingerprint.metadata  # A dictionary, defaults to {}
```


# Crafting Effective Agents
Source: https://docs.crewai.com/en/guides/agents/crafting-effective-agents

Learn best practices for designing powerful, specialized AI agents that collaborate effectively to solve complex problems.

## The Art and Science of Agent Design

At the heart of CrewAI lies the agent - a specialized AI entity designed to perform specific roles within a collaborative framework. While creating basic agents is simple, crafting truly effective agents that produce exceptional results requires understanding key design principles and best practices.

This guide will help you master the art of agent design, enabling you to create specialized AI personas that collaborate effectively, think critically, and produce high-quality outputs tailored to your specific needs.

### Why Agent Design Matters

The way you define your agents significantly impacts:

1. **Output quality**: Well-designed agents produce more relevant, high-quality results
2. **Collaboration effectiveness**: Agents with complementary skills work together more efficiently
3. **Task performance**: Agents with clear roles and goals execute tasks more effectively
4. **System scalability**: Thoughtfully designed agents can be reused across multiple crews and contexts

Let's explore best practices for creating agents that excel in these dimensions.

## The 80/20 Rule: Focus on Tasks Over Agents

When building effective AI systems, remember this crucial principle: **80% of your effort should go into designing tasks, and only 20% into defining agents**.

Why? Because even the most perfectly defined agent will fail with poorly designed tasks, but well-designed tasks can elevate even a simple agent. This means:

* Spend most of your time writing clear task instructions
* Define detailed inputs and expected outputs
* Add examples and context to guide execution
* Dedicate the remaining time to agent role, goal, and backstory

This doesn't mean agent design isn't important - it absolutely is. But task design is where most execution failures occur, so prioritize accordingly.

## Core Principles of Effective Agent Design

### 1. The Role-Goal-Backstory Framework

The most powerful agents in CrewAI are built on a strong foundation of three key elements:

#### Role: The Agent's Specialized Function

The role defines what the agent does and their area of expertise. When crafting roles:

* **Be specific and specialized**: Instead of "Writer," use "Technical Documentation Specialist" or "Creative Storyteller"
* **Align with real-world professions**: Base roles on recognizable professional archetypes
* **Include domain expertise**: Specify the agent's field of knowledge (e.g., "Financial Analyst specializing in market trends")

**Examples of effective roles:**

```yaml
role: "Senior UX Researcher specializing in user interview analysis"
role: "Full-Stack Software Architect with expertise in distributed systems"
role: "Corporate Communications Director specializing in crisis management"
```

#### Goal: The Agent's Purpose and Motivation

The goal directs the agent's efforts and shapes their decision-making process. Effective goals should:

* **Be clear and outcome-focused**: Define what the agent is trying to achieve
* **Emphasize quality standards**: Include expectations about the quality of work
* **Incorporate success criteria**: Help the agent understand what "good" looks like

**Examples of effective goals:**

```yaml
goal: "Uncover actionable user insights by analyzing interview data and identifying recurring patterns, unmet needs, and improvement opportunities"
goal: "Design robust, scalable system architectures that balance performance, maintainability, and cost-effectiveness"
goal: "Craft clear, empathetic crisis communications that address stakeholder concerns while protecting organizational reputation"
```

#### Backstory: The Agent's Experience and Perspective

The backstory gives depth to the agent, influencing how they approach problems and interact with others. Good backstories:

* **Establish expertise and experience**: Explain how the agent gained their skills
* **Define working style and values**: Describe how the agent approaches their work
* **Create a cohesive persona**: Ensure all elements of the backstory align with the role and goal

**Examples of effective backstories:**

```yaml
backstory: "You have spent 15 years conducting and analyzing user research for top tech companies. You have a talent for reading between the lines and identifying patterns that others miss. You believe that good UX is invisible and that the best insights come from listening to what users don't say as much as what they do say."

backstory: "With 20+ years of experience building distributed systems at scale, you've developed a pragmatic approach to software architecture. You've seen both successful and failed systems and have learned valuable lessons from each. You balance theoretical best practices with practical constraints and always consider the maintenance and operational aspects of your designs."

backstory: "As a seasoned communications professional who has guided multiple organizations through high-profile crises, you understand the importance of transparency, speed, and empathy in crisis response. You have a methodical approach to crafting messages that address concerns while maintaining organizational credibility."
```

### 2. Specialists Over Generalists

Agents perform significantly better when given specialized roles rather than general ones. A highly focused agent delivers more precise, relevant outputs:

**Generic (Less Effective):**

```yaml
role: "Writer"
```

**Specialized (More Effective):**

```yaml
role: "Technical Blog Writer specializing in explaining complex AI concepts to non-technical audiences"
```

**Specialist Benefits:**

* Clearer understanding of expected output
* More consistent performance
* Better alignment with specific tasks
* Improved ability to make domain-specific judgments

### 3. Balancing Specialization and Versatility

Effective agents strike the right balance between specialization (doing one thing extremely well) and versatility (being adaptable to various situations):

* **Specialize in role, versatile in application**: Create agents with specialized skills that can be applied across multiple contexts
* **Avoid overly narrow definitions**: Ensure agents can handle variations within their domain of expertise
* **Consider the collaborative context**: Design agents whose specializations complement the other agents they'll work with

### 4. Setting Appropriate Expertise Levels

The expertise level you assign to your agent shapes how they approach tasks:

* **Novice agents**: Good for straightforward tasks, brainstorming, or initial drafts
* **Intermediate agents**: Suitable for most standard tasks with reliable execution
* **Expert agents**: Best for complex, specialized tasks requiring depth and nuance
* **World-class agents**: Reserved for critical tasks where exceptional quality is needed

Choose the appropriate expertise level based on task complexity and quality requirements. For most collaborative crews, a mix of expertise levels often works best, with higher expertise assigned to core specialized functions.

## Practical Examples: Before and After

Let's look at some examples of agent definitions before and after applying these best practices:

### Example 1: Content Creation Agent

**Before:**

```yaml
role: "Writer"
goal: "Write good content"
backstory: "You are a writer who creates content for websites."
```

**After:**

```yaml
role: "B2B Technology Content Strategist"
goal: "Create compelling, technically accurate content that explains complex topics in accessible language while driving reader engagement and supporting business objectives"
backstory: "You have spent a decade creating content for leading technology companies, specializing in translating technical concepts for business audiences. You excel at research, interviewing subject matter experts, and structuring information for maximum clarity and impact. You believe that the best B2B content educates first and sells second, building trust through genuine expertise rather than marketing hype."
```

### Example 2: Research Agent

**Before:**

```yaml
role: "Researcher"
goal: "Find information"
backstory: "You are good at finding information online."
```

**After:**

```yaml
role: "Academic Research Specialist in Emerging Technologies"
goal: "Discover and synthesize cutting-edge research, identifying key trends, methodologies, and findings while evaluating the quality and reliability of sources"
backstory: "With a background in both computer science and library science, you've mastered the art of digital research. You've worked with research teams at prestigious universities and know how to navigate academic databases, evaluate research quality, and synthesize findings across disciplines. You're methodical in your approach, always cross-referencing information and tracing claims to primary sources before drawing conclusions."
```

## Crafting Effective Tasks for Your Agents

While agent design is important, task design is critical for successful execution. Here are best practices for designing tasks that set your agents up for success:

### The Anatomy of an Effective Task

A well-designed task has two key components that serve different purposes:

#### Task Description: The Process

The description should focus on what to do and how to do it, including:

* Detailed instructions for execution
* Context and background information
* Scope and constraints
* Process steps to follow

#### Expected Output: The Deliverable

The expected output should define what the final result should look like:

* Format specifications (markdown, JSON, etc.)
* Structure requirements
* Quality criteria
* Examples of good outputs (when possible)

### Task Design Best Practices

#### 1. Single Purpose, Single Output

Tasks perform best when focused on one clear objective:

**Bad Example (Too Broad):**

```yaml
task_description: "Research market trends, analyze the data, and create a visualization."
```

**Good Example (Focused):**

```yaml
# Task 1
research_task:
  description: "Research the top 5 market trends in the AI industry for 2024."
  expected_output: "A markdown list of the 5 trends with supporting evidence."

# Task 2
analysis_task:
  description: "Analyze the identified trends to determine potential business impacts."
  expected_output: "A structured analysis with impact ratings (High/Medium/Low)."

# Task 3
visualization_task:
  description: "Create a visual representation of the analyzed trends."
  expected_output: "A description of a chart showing trends and their impact ratings."
```

#### 2. Be Explicit About Inputs and Outputs

Always clearly specify what inputs the task will use and what the output should look like:

**Example:**

```yaml
analysis_task:
  description: >
    Analyze the customer feedback data from the CSV file.
    Focus on identifying recurring themes related to product usability.
    Consider sentiment and frequency when determining importance.
  expected_output: >
    A markdown report with the following sections:
    1. Executive summary (3-5 bullet points)
    2. Top 3 usability issues with supporting data
    3. Recommendations for improvement
```

#### 3. Include Purpose and Context

Explain why the task matters and how it fits into the larger workflow:

**Example:**

```yaml
competitor_analysis_task:
  description: >
    Analyze our three main competitors' pricing strategies.
    This analysis will inform our upcoming pricing model revision.
    Focus on identifying patterns in how they price premium features
    and how they structure their tiered offerings.
```

#### 4. Use Structured Output Tools

For machine-readable outputs, specify the format clearly:

**Example:**

```yaml
data_extraction_task:
  description: "Extract key metrics from the quarterly report."
  expected_output: "JSON object with the following keys: revenue, growth_rate, customer_acquisition_cost, and retention_rate."
```

## Common Mistakes to Avoid

Based on lessons learned from real-world implementations, here are the most common pitfalls in agent and task design:

### 1. Unclear Task Instructions

**Problem:** Tasks lack sufficient detail, making it difficult for agents to execute effectively.

**Example of Poor Design:**

```yaml
research_task:
  description: "Research AI trends."
  expected_output: "A report on AI trends."
```

**Improved Version:**

```yaml
research_task:
  description: >
    Research the top emerging AI trends for 2024 with a focus on:
    1. Enterprise adoption patterns
    2. Technical breakthroughs in the past 6 months
    3. Regulatory developments affecting implementation

    For each trend, identify key companies, technologies, and potential business impacts.
  expected_output: >
    A comprehensive markdown report with:
    - Executive summary (5 bullet points)
    - 5-7 major trends with supporting evidence
    - For each trend: definition, examples, and business implications
    - References to authoritative sources
```

### 2. "God Tasks" That Try to Do Too Much

**Problem:** Tasks that combine multiple complex operations into one instruction set.

**Example of Poor Design:**

```yaml
comprehensive_task:
  description: "Research market trends, analyze competitor strategies, create a marketing plan, and design a launch timeline."
```

**Improved Version:**
Break this into sequential, focused tasks:

```yaml
# Task 1: Research
market_research_task:
  description: "Research current market trends in the SaaS project management space."
  expected_output: "A markdown summary of key market trends."

# Task 2: Competitive Analysis
competitor_analysis_task:
  description: "Analyze strategies of the top 3 competitors based on the market research."
  expected_output: "A comparison table of competitor strategies."
  context: [market_research_task]

# Continue with additional focused tasks...
```

### 3. Misaligned Description and Expected Output

**Problem:** The task description asks for one thing while the expected output specifies something different.

**Example of Poor Design:**

```yaml
analysis_task:
  description: "Analyze customer feedback to find areas of improvement."
  expected_output: "A marketing plan for the next quarter."
```

**Improved Version:**

```yaml
analysis_task:
  description: "Analyze customer feedback to identify the top 3 areas for product improvement."
  expected_output: "A report listing the 3 priority improvement areas with supporting customer quotes and data points."
```

### 4. Not Understanding the Process Yourself

**Problem:** Asking agents to execute tasks that you yourself don't fully understand.

**Solution:**

1. Try to perform the task manually first
2. Document your process, decision points, and information sources
3. Use this documentation as the basis for your task description

### 5. Premature Use of Hierarchical Structures

**Problem:** Creating unnecessarily complex agent hierarchies where sequential processes would work better.

**Solution:** Start with sequential processes and only move to hierarchical models when the workflow complexity truly requires it.

### 6. Vague or Generic Agent Definitions

**Problem:** Generic agent definitions lead to generic outputs.

**Example of Poor Design:**

```yaml
agent:
  role: "Business Analyst"
  goal: "Analyze business data"
  backstory: "You are good at business analysis."
```

**Improved Version:**

```yaml
agent:
  role: "SaaS Metrics Specialist focusing on growth-stage startups"
  goal: "Identify actionable insights from business data that can directly impact customer retention and revenue growth"
  backstory: "With 10+ years analyzing SaaS business models, you've developed a keen eye for the metrics that truly matter for sustainable growth. You've helped numerous companies identify the leverage points that turned around their business trajectory. You believe in connecting data to specific, actionable recommendations rather than general observations."
```

## Advanced Agent Design Strategies

### Designing for Collaboration

When creating agents that will work together in a crew, consider:

* **Complementary skills**: Design agents with distinct but complementary abilities
* **Handoff points**: Define clear interfaces for how work passes between agents
* **Constructive tension**: Sometimes, creating agents with slightly different perspectives can lead to better outcomes through productive dialogue

For example, a content creation crew might include:

```yaml
# Research Agent
role: "Research Specialist for technical topics"
goal: "Gather comprehensive, accurate information from authoritative sources"
backstory: "You are a meticulous researcher with a background in library science..."

# Writer Agent
role: "Technical Content Writer"
goal: "Transform research into engaging, clear content that educates and informs"
backstory: "You are an experienced writer who excels at explaining complex concepts..."

# Editor Agent
role: "Content Quality Editor"
goal: "Ensure content is accurate, well-structured, and polished while maintaining consistency"
backstory: "With years of experience in publishing, you have a keen eye for detail..."
```

### Creating Specialized Tool Users

Some agents can be designed specifically to leverage certain tools effectively:

```yaml
role: "Data Analysis Specialist"
goal: "Derive meaningful insights from complex datasets through statistical analysis"
backstory: "With a background in data science, you excel at working with structured and unstructured data..."
tools: [PythonREPLTool, DataVisualizationTool, CSVAnalysisTool]
```

### Tailoring Agents to LLM Capabilities

Different LLMs have different strengths. Design your agents with these capabilities in mind:

```yaml
# For complex reasoning tasks
analyst:
  role: "Data Insights Analyst"
  goal: "..."
  backstory: "..."
  llm: openai/gpt-4o

# For creative content
writer:
  role: "Creative Content Writer"
  goal: "..."
  backstory: "..."
  llm: anthropic/claude-3-opus
```

## Testing and Iterating on Agent Design

Agent design is often an iterative process. Here's a practical approach:

1. **Start with a prototype**: Create an initial agent definition
2. **Test with sample tasks**: Evaluate performance on representative tasks
3. **Analyze outputs**: Identify strengths and weaknesses
4. **Refine the definition**: Adjust role, goal, and backstory based on observations
5. **Test in collaboration**: Evaluate how the agent performs in a crew setting

## Conclusion

Crafting effective agents is both an art and a science. By carefully defining roles, goals, and backstories that align with your specific needs, and combining them with well-designed tasks, you can create specialized AI collaborators that produce exceptional results.

Remember that agent and task design is an iterative process. Start with these best practices, observe your agents in action, and refine your approach based on what you learn. And always keep in mind the 80/20 rule - focus most of your effort on creating clear, focused tasks to get the best results from your agents.

<Check>
  Congratulations! You now understand the principles and practices of effective agent design. Apply these techniques to create powerful, specialized agents that work together seamlessly to accomplish complex tasks.
</Check>

## Next Steps

* Experiment with different agent configurations for your specific use case
* Learn about [building your first crew](/en/guides/crews/first-crew) to see how agents work together
* Explore [CrewAI Flows](/en/guides/flows/first-flow) for more advanced orchestration


# Evaluating Use Cases for CrewAI
Source: https://docs.crewai.com/en/guides/concepts/evaluating-use-cases

Learn how to assess your AI application needs and choose the right approach between Crews and Flows based on complexity and precision requirements.

## Understanding the Decision Framework

When building AI applications with CrewAI, one of the most important decisions you'll make is choosing the right approach for your specific use case. Should you use a Crew? A Flow? A combination of both? This guide will help you evaluate your requirements and make informed architectural decisions.

At the heart of this decision is understanding the relationship between **complexity** and **precision** in your application:

<Frame caption="Complexity vs. Precision Matrix for CrewAI Applications">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/complexity_precision.png" alt="Complexity vs. Precision Matrix" />
</Frame>

This matrix helps visualize how different approaches align with varying requirements for complexity and precision. Let's explore what each quadrant means and how it guides your architectural choices.

## The Complexity-Precision Matrix Explained

### What is Complexity?

In the context of CrewAI applications, **complexity** refers to:

* The number of distinct steps or operations required
* The diversity of tasks that need to be performed
* The interdependencies between different components
* The need for conditional logic and branching
* The sophistication of the overall workflow

### What is Precision?

**Precision** in this context refers to:

* The accuracy required in the final output
* The need for structured, predictable results
* The importance of reproducibility
* The level of control needed over each step
* The tolerance for variation in outputs

### The Four Quadrants

#### 1. Low Complexity, Low Precision

**Characteristics:**

* Simple, straightforward tasks
* Tolerance for some variation in outputs
* Limited number of steps
* Creative or exploratory applications

**Recommended Approach:** Simple Crews with minimal agents

**Example Use Cases:**

* Basic content generation
* Idea brainstorming
* Simple summarization tasks
* Creative writing assistance

#### 2. Low Complexity, High Precision

**Characteristics:**

* Simple workflows that require exact, structured outputs
* Need for reproducible results
* Limited steps but high accuracy requirements
* Often involves data processing or transformation

**Recommended Approach:** Flows with direct LLM calls or simple Crews with structured outputs

**Example Use Cases:**

* Data extraction and transformation
* Form filling and validation
* Structured content generation (JSON, XML)
* Simple classification tasks

#### 3. High Complexity, Low Precision

**Characteristics:**

* Multi-stage processes with many steps
* Creative or exploratory outputs
* Complex interactions between components
* Tolerance for variation in final results

**Recommended Approach:** Complex Crews with multiple specialized agents

**Example Use Cases:**

* Research and analysis
* Content creation pipelines
* Exploratory data analysis
* Creative problem-solving

#### 4. High Complexity, High Precision

**Characteristics:**

* Complex workflows requiring structured outputs
* Multiple interdependent steps with strict accuracy requirements
* Need for both sophisticated processing and precise results
* Often mission-critical applications

**Recommended Approach:** Flows orchestrating multiple Crews with validation steps

**Example Use Cases:**

* Enterprise decision support systems
* Complex data processing pipelines
* Multi-stage document processing
* Regulated industry applications

## Choosing Between Crews and Flows

### When to Choose Crews

Crews are ideal when:

1. **You need collaborative intelligence** - Multiple agents with different specializations need to work together
2. **The problem requires emergent thinking** - The solution benefits from different perspectives and approaches
3. **The task is primarily creative or analytical** - The work involves research, content creation, or analysis
4. **You value adaptability over strict structure** - The workflow can benefit from agent autonomy
5. **The output format can be somewhat flexible** - Some variation in output structure is acceptable

```python
# Example: Research Crew for market analysis
from crewai import Agent, Crew, Process, Task

# Create specialized agents
researcher = Agent(
    role="Market Research Specialist",
    goal="Find comprehensive market data on emerging technologies",
    backstory="You are an expert at discovering market trends and gathering data."
)

analyst = Agent(
    role="Market Analyst",
    goal="Analyze market data and identify key opportunities",
    backstory="You excel at interpreting market data and spotting valuable insights."
)

# Define their tasks
research_task = Task(
    description="Research the current market landscape for AI-powered healthcare solutions",
    expected_output="Comprehensive market data including key players, market size, and growth trends",
    agent=researcher
)

analysis_task = Task(
    description="Analyze the market data and identify the top 3 investment opportunities",
    expected_output="Analysis report with 3 recommended investment opportunities and rationale",
    agent=analyst,
    context=[research_task]
)

# Create the crew
market_analysis_crew = Crew(
    agents=[researcher, analyst],
    tasks=[research_task, analysis_task],
    process=Process.sequential,
    verbose=True
)

# Run the crew
result = market_analysis_crew.kickoff()
```

### When to Choose Flows

Flows are ideal when:

1. **You need precise control over execution** - The workflow requires exact sequencing and state management
2. **The application has complex state requirements** - You need to maintain and transform state across multiple steps
3. **You need structured, predictable outputs** - The application requires consistent, formatted results
4. **The workflow involves conditional logic** - Different paths need to be taken based on intermediate results
5. **You need to combine AI with procedural code** - The solution requires both AI capabilities and traditional programming

```python
# Example: Customer Support Flow with structured processing
from crewai.flow.flow import Flow, listen, router, start
from pydantic import BaseModel
from typing import List, Dict

# Define structured state
class SupportTicketState(BaseModel):
    ticket_id: str = ""
    customer_name: str = ""
    issue_description: str = ""
    category: str = ""
    priority: str = "medium"
    resolution: str = ""
    satisfaction_score: int = 0

class CustomerSupportFlow(Flow[SupportTicketState]):
    @start()
    def receive_ticket(self):
        # In a real app, this might come from an API
        self.state.ticket_id = "TKT-12345"
        self.state.customer_name = "Alex Johnson"
        self.state.issue_description = "Unable to access premium features after payment"
        return "Ticket received"

    @listen(receive_ticket)
    def categorize_ticket(self, _):
        # Use a direct LLM call for categorization
        from crewai import LLM
        llm = LLM(model="openai/gpt-4o-mini")

        prompt = f"""
        Categorize the following customer support issue into one of these categories:
        - Billing
        - Account Access
        - Technical Issue
        - Feature Request
        - Other

        Issue: {self.state.issue_description}

        Return only the category name.
        """

        self.state.category = llm.call(prompt).strip()
        return self.state.category

    @router(categorize_ticket)
    def route_by_category(self, category):
        # Route to different handlers based on category
        return category.lower().replace(" ", "_")

    @listen("billing")
    def handle_billing_issue(self):
        # Handle billing-specific logic
        self.state.priority = "high"
        # More billing-specific processing...
        return "Billing issue handled"

    @listen("account_access")
    def handle_access_issue(self):
        # Handle access-specific logic
        self.state.priority = "high"
        # More access-specific processing...
        return "Access issue handled"

    # Additional category handlers...

    @listen("billing", "account_access", "technical_issue", "feature_request", "other")
    def resolve_ticket(self, resolution_info):
        # Final resolution step
        self.state.resolution = f"Issue resolved: {resolution_info}"
        return self.state.resolution

# Run the flow
support_flow = CustomerSupportFlow()
result = support_flow.kickoff()
```

### When to Combine Crews and Flows

The most sophisticated applications often benefit from combining Crews and Flows:

1. **Complex multi-stage processes** - Use Flows to orchestrate the overall process and Crews for complex subtasks
2. **Applications requiring both creativity and structure** - Use Crews for creative tasks and Flows for structured processing
3. **Enterprise-grade AI applications** - Use Flows to manage state and process flow while leveraging Crews for specialized work

```python
# Example: Content Production Pipeline combining Crews and Flows
from crewai.flow.flow import Flow, listen, start
from crewai import Agent, Crew, Process, Task
from pydantic import BaseModel
from typing import List, Dict

class ContentState(BaseModel):
    topic: str = ""
    target_audience: str = ""
    content_type: str = ""
    outline: Dict = {}
    draft_content: str = ""
    final_content: str = ""
    seo_score: int = 0

class ContentProductionFlow(Flow[ContentState]):
    @start()
    def initialize_project(self):
        # Set initial parameters
        self.state.topic = "Sustainable Investing"
        self.state.target_audience = "Millennial Investors"
        self.state.content_type = "Blog Post"
        return "Project initialized"

    @listen(initialize_project)
    def create_outline(self, _):
        # Use a research crew to create an outline
        researcher = Agent(
            role="Content Researcher",
            goal=f"Research {self.state.topic} for {self.state.target_audience}",
            backstory="You are an expert researcher with deep knowledge of content creation."
        )

        outliner = Agent(
            role="Content Strategist",
            goal=f"Create an engaging outline for a {self.state.content_type}",
            backstory="You excel at structuring content for maximum engagement."
        )

        research_task = Task(
            description=f"Research {self.state.topic} focusing on what would interest {self.state.target_audience}",
            expected_output="Comprehensive research notes with key points and statistics",
            agent=researcher
        )

        outline_task = Task(
            description=f"Create an outline for a {self.state.content_type} about {self.state.topic}",
            expected_output="Detailed content outline with sections and key points",
            agent=outliner,
            context=[research_task]
        )

        outline_crew = Crew(
            agents=[researcher, outliner],
            tasks=[research_task, outline_task],
            process=Process.sequential,
            verbose=True
        )

        # Run the crew and store the result
        result = outline_crew.kickoff()

        # Parse the outline (in a real app, you might use a more robust parsing approach)
        import json
        try:
            self.state.outline = json.loads(result.raw)
        except:
            # Fallback if not valid JSON
            self.state.outline = {"sections": result.raw}

        return "Outline created"

    @listen(create_outline)
    def write_content(self, _):
        # Use a writing crew to create the content
        writer = Agent(
            role="Content Writer",
            goal=f"Write engaging content for {self.state.target_audience}",
            backstory="You are a skilled writer who creates compelling content."
        )

        editor = Agent(
            role="Content Editor",
            goal="Ensure content is polished, accurate, and engaging",
            backstory="You have a keen eye for detail and a talent for improving content."
        )

        writing_task = Task(
            description=f"Write a {self.state.content_type} about {self.state.topic} following this outline: {self.state.outline}",
            expected_output="Complete draft content in markdown format",
            agent=writer
        )

        editing_task = Task(
            description="Edit and improve the draft content for clarity, engagement, and accuracy",
            expected_output="Polished final content in markdown format",
            agent=editor,
            context=[writing_task]
        )

        writing_crew = Crew(
            agents=[writer, editor],
            tasks=[writing_task, editing_task],
            process=Process.sequential,
            verbose=True
        )

        # Run the crew and store the result
        result = writing_crew.kickoff()
        self.state.final_content = result.raw

        return "Content created"

    @listen(write_content)
    def optimize_for_seo(self, _):
        # Use a direct LLM call for SEO optimization
        from crewai import LLM
        llm = LLM(model="openai/gpt-4o-mini")

        prompt = f"""
        Analyze this content for SEO effectiveness for the keyword "{self.state.topic}".
        Rate it on a scale of 1-100 and provide 3 specific recommendations for improvement.

        Content: {self.state.final_content[:1000]}... (truncated for brevity)

        Format your response as JSON with the following structure:
        {{
            "score": 85,
            "recommendations": [
                "Recommendation 1",
                "Recommendation 2",
                "Recommendation 3"
            ]
        }}
        """

        seo_analysis = llm.call(prompt)

        # Parse the SEO analysis
        import json
        try:
            analysis = json.loads(seo_analysis)
            self.state.seo_score = analysis.get("score", 0)
            return analysis
        except:
            self.state.seo_score = 50
            return {"score": 50, "recommendations": ["Unable to parse SEO analysis"]}

# Run the flow
content_flow = ContentProductionFlow()
result = content_flow.kickoff()
```

## Practical Evaluation Framework

To determine the right approach for your specific use case, follow this step-by-step evaluation framework:

### Step 1: Assess Complexity

Rate your application's complexity on a scale of 1-10 by considering:

1. **Number of steps**: How many distinct operations are required?
   * 1-3 steps: Low complexity (1-3)
   * 4-7 steps: Medium complexity (4-7)
   * 8+ steps: High complexity (8-10)

2. **Interdependencies**: How interconnected are the different parts?
   * Few dependencies: Low complexity (1-3)
   * Some dependencies: Medium complexity (4-7)
   * Many complex dependencies: High complexity (8-10)

3. **Conditional logic**: How much branching and decision-making is needed?
   * Linear process: Low complexity (1-3)
   * Some branching: Medium complexity (4-7)
   * Complex decision trees: High complexity (8-10)

4. **Domain knowledge**: How specialized is the knowledge required?
   * General knowledge: Low complexity (1-3)
   * Some specialized knowledge: Medium complexity (4-7)
   * Deep expertise in multiple domains: High complexity (8-10)

Calculate your average score to determine overall complexity.

### Step 2: Assess Precision Requirements

Rate your precision requirements on a scale of 1-10 by considering:

1. **Output structure**: How structured must the output be?
   * Free-form text: Low precision (1-3)
   * Semi-structured: Medium precision (4-7)
   * Strictly formatted (JSON, XML): High precision (8-10)

2. **Accuracy needs**: How important is factual accuracy?
   * Creative content: Low precision (1-3)
   * Informational content: Medium precision (4-7)
   * Critical information: High precision (8-10)

3. **Reproducibility**: How consistent must results be across runs?
   * Variation acceptable: Low precision (1-3)
   * Some consistency needed: Medium precision (4-7)
   * Exact reproducibility required: High precision (8-10)

4. **Error tolerance**: What is the impact of errors?
   * Low impact: Low precision (1-3)
   * Moderate impact: Medium precision (4-7)
   * High impact: High precision (8-10)

Calculate your average score to determine overall precision requirements.

### Step 3: Map to the Matrix

Plot your complexity and precision scores on the matrix:

* **Low Complexity (1-4), Low Precision (1-4)**: Simple Crews
* **Low Complexity (1-4), High Precision (5-10)**: Flows with direct LLM calls
* **High Complexity (5-10), Low Precision (1-4)**: Complex Crews
* **High Complexity (5-10), High Precision (5-10)**: Flows orchestrating Crews

### Step 4: Consider Additional Factors

Beyond complexity and precision, consider:

1. **Development time**: Crews are often faster to prototype
2. **Maintenance needs**: Flows provide better long-term maintainability
3. **Team expertise**: Consider your team's familiarity with different approaches
4. **Scalability requirements**: Flows typically scale better for complex applications
5. **Integration needs**: Consider how the solution will integrate with existing systems

## Conclusion

Choosing between Crews and Flows—or combining them—is a critical architectural decision that impacts the effectiveness, maintainability, and scalability of your CrewAI application. By evaluating your use case along the dimensions of complexity and precision, you can make informed decisions that align with your specific requirements.

Remember that the best approach often evolves as your application matures. Start with the simplest solution that meets your needs, and be prepared to refine your architecture as you gain experience and your requirements become clearer.

<Check>
  You now have a framework for evaluating CrewAI use cases and choosing the right approach based on complexity and precision requirements. This will help you build more effective, maintainable, and scalable AI applications.
</Check>

## Next Steps

* Learn more about [crafting effective agents](/en/guides/agents/crafting-effective-agents)
* Explore [building your first crew](/en/guides/crews/first-crew)
* Dive into [mastering flow state management](/en/guides/flows/mastering-flow-state)
* Check out the [core concepts](/en/concepts/agents) for deeper understanding


# Build Your First Crew
Source: https://docs.crewai.com/en/guides/crews/first-crew

Step-by-step tutorial to create a collaborative AI team that works together to solve complex problems.

## Unleashing the Power of Collaborative AI

Imagine having a team of specialized AI agents working together seamlessly to solve complex problems, each contributing their unique skills to achieve a common goal. This is the power of CrewAI - a framework that enables you to create collaborative AI systems that can accomplish tasks far beyond what a single AI could achieve alone.

In this guide, we'll walk through creating a research crew that will help us research and analyze a topic, then create a comprehensive report. This practical example demonstrates how AI agents can collaborate to accomplish complex tasks, but it's just the beginning of what's possible with CrewAI.

### What You'll Build and Learn

By the end of this guide, you'll have:

1. **Created a specialized AI research team** with distinct roles and responsibilities
2. **Orchestrated collaboration** between multiple AI agents
3. **Automated a complex workflow** that involves gathering information, analysis, and report generation
4. **Built foundational skills** that you can apply to more ambitious projects

While we're building a simple research crew in this guide, the same patterns and techniques can be applied to create much more sophisticated teams for tasks like:

* Multi-stage content creation with specialized writers, editors, and fact-checkers
* Complex customer service systems with tiered support agents
* Autonomous business analysts that gather data, create visualizations, and generate insights
* Product development teams that ideate, design, and plan implementation

Let's get started building your first crew!

### Prerequisites

Before starting, make sure you have:

1. Installed CrewAI following the [installation guide](/en/installation)
2. Set up your LLM API key in your environment, following the [LLM setup
   guide](/en/concepts/llms#setting-up-your-llm)
3. Basic understanding of Python

## Step 1: Create a New CrewAI Project

First, let's create a new CrewAI project using the CLI. This command will set up a complete project structure with all the necessary files, allowing you to focus on defining your agents and their tasks rather than setting up boilerplate code.

```bash
crewai create crew research_crew
cd research_crew
```

This will generate a project with the basic structure needed for your crew. The CLI automatically creates:

* A project directory with the necessary files
* Configuration files for agents and tasks
* A basic crew implementation
* A main script to run the crew

<Frame caption="CrewAI Framework Overview">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crews.png" alt="CrewAI Framework Overview" />
</Frame>

## Step 2: Explore the Project Structure

Let's take a moment to understand the project structure created by the CLI. CrewAI follows best practices for Python projects, making it easy to maintain and extend your code as your crews become more complex.

```
research_crew/
├── .gitignore
├── pyproject.toml
├── README.md
├── .env
└── src/
    └── research_crew/
        ├── __init__.py
        ├── main.py
        ├── crew.py
        ├── tools/
        │   ├── custom_tool.py
        │   └── __init__.py
        └── config/
            ├── agents.yaml
            └── tasks.yaml
```

This structure follows best practices for Python projects and makes it easy to organize your code. The separation of configuration files (in YAML) from implementation code (in Python) makes it easy to modify your crew's behavior without changing the underlying code.

## Step 3: Configure Your Agents

Now comes the fun part - defining your AI agents! In CrewAI, agents are specialized entities with specific roles, goals, and backstories that shape their behavior. Think of them as characters in a play, each with their own personality and purpose.

For our research crew, we'll create two agents:

1. A **researcher** who excels at finding and organizing information
2. An **analyst** who can interpret research findings and create insightful reports

Let's modify the `agents.yaml` file to define these specialized agents. Be sure
to set `llm` to the provider you are using.

```yaml
# src/research_crew/config/agents.yaml
researcher:
  role: >
    Senior Research Specialist for {topic}
  goal: >
    Find comprehensive and accurate information about {topic}
    with a focus on recent developments and key insights
  backstory: >
    You are an experienced research specialist with a talent for
    finding relevant information from various sources. You excel at
    organizing information in a clear and structured manner, making
    complex topics accessible to others.
  llm: provider/model-id  # e.g. openai/gpt-4o, google/gemini-2.0-flash, anthropic/claude...

analyst:
  role: >
    Data Analyst and Report Writer for {topic}
  goal: >
    Analyze research findings and create a comprehensive, well-structured
    report that presents insights in a clear and engaging way
  backstory: >
    You are a skilled analyst with a background in data interpretation
    and technical writing. You have a talent for identifying patterns
    and extracting meaningful insights from research data, then
    communicating those insights effectively through well-crafted reports.
  llm: provider/model-id  # e.g. openai/gpt-4o, google/gemini-2.0-flash, anthropic/claude...
```

Notice how each agent has a distinct role, goal, and backstory. These elements aren't just descriptive - they actively shape how the agent approaches its tasks. By crafting these carefully, you can create agents with specialized skills and perspectives that complement each other.

## Step 4: Define Your Tasks

With our agents defined, we now need to give them specific tasks to perform. Tasks in CrewAI represent the concrete work that agents will perform, with detailed instructions and expected outputs.

For our research crew, we'll define two main tasks:

1. A **research task** for gathering comprehensive information
2. An **analysis task** for creating an insightful report

Let's modify the `tasks.yaml` file:

```yaml
# src/research_crew/config/tasks.yaml
research_task:
  description: >
    Conduct thorough research on {topic}. Focus on:
    1. Key concepts and definitions
    2. Historical development and recent trends
    3. Major challenges and opportunities
    4. Notable applications or case studies
    5. Future outlook and potential developments

    Make sure to organize your findings in a structured format with clear sections.
  expected_output: >
    A comprehensive research document with well-organized sections covering
    all the requested aspects of {topic}. Include specific facts, figures,
    and examples where relevant.
  agent: researcher

analysis_task:
  description: >
    Analyze the research findings and create a comprehensive report on {topic}.
    Your report should:
    1. Begin with an executive summary
    2. Include all key information from the research
    3. Provide insightful analysis of trends and patterns
    4. Offer recommendations or future considerations
    5. Be formatted in a professional, easy-to-read style with clear headings
  expected_output: >
    A polished, professional report on {topic} that presents the research
    findings with added analysis and insights. The report should be well-structured
    with an executive summary, main sections, and conclusion.
  agent: analyst
  context:
    - research_task
  output_file: output/report.md
```

Note the `context` field in the analysis task - this is a powerful feature that allows the analyst to access the output of the research task. This creates a workflow where information flows naturally between agents, just as it would in a human team.

## Step 5: Configure Your Crew

Now it's time to bring everything together by configuring our crew. The crew is the container that orchestrates how agents work together to complete tasks.

Let's modify the `crew.py` file:

```python
# src/research_crew/crew.py
from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task
from crewai_tools import SerperDevTool
from crewai.agents.agent_builder.base_agent import BaseAgent
from typing import List

@CrewBase
class ResearchCrew():
    """Research crew for comprehensive topic analysis and reporting"""

    agents: List[BaseAgent]
    tasks: List[Task]

    @agent
    def researcher(self) -> Agent:
        return Agent(
            config=self.agents_config['researcher'], # type: ignore[index]
            verbose=True,
            tools=[SerperDevTool()]
        )

    @agent
    def analyst(self) -> Agent:
        return Agent(
            config=self.agents_config['analyst'], # type: ignore[index]
            verbose=True
        )

    @task
    def research_task(self) -> Task:
        return Task(
            config=self.tasks_config['research_task'] # type: ignore[index]
        )

    @task
    def analysis_task(self) -> Task:
        return Task(
            config=self.tasks_config['analysis_task'], # type: ignore[index]
            output_file='output/report.md'
        )

    @crew
    def crew(self) -> Crew:
        """Creates the research crew"""
        return Crew(
            agents=self.agents,
            tasks=self.tasks,
            process=Process.sequential,
            verbose=True,
        )
```

In this code, we're:

1. Creating the researcher agent and equipping it with the SerperDevTool to search the web
2. Creating the analyst agent
3. Setting up the research and analysis tasks
4. Configuring the crew to run tasks sequentially (the analyst will wait for the researcher to finish)

This is where the magic happens - with just a few lines of code, we've defined a collaborative AI system where specialized agents work together in a coordinated process.

## Step 6: Set Up Your Main Script

Now, let's set up the main script that will run our crew. This is where we provide the specific topic we want our crew to research.

```python
#!/usr/bin/env python
# src/research_crew/main.py
import os
from research_crew.crew import ResearchCrew

# Create output directory if it doesn't exist
os.makedirs('output', exist_ok=True)

def run():
    """
    Run the research crew.
    """
    inputs = {
        'topic': 'Artificial Intelligence in Healthcare'
    }

    # Create and run the crew
    result = ResearchCrew().crew().kickoff(inputs=inputs)

    # Print the result
    print("\n\n=== FINAL REPORT ===\n\n")
    print(result.raw)

    print("\n\nReport has been saved to output/report.md")

if __name__ == "__main__":
    run()
```

This script prepares the environment, specifies our research topic, and kicks off the crew's work. The power of CrewAI is evident in how simple this code is - all the complexity of managing multiple AI agents is handled by the framework.

## Step 7: Set Up Your Environment Variables

Create a `.env` file in your project root with your API keys:

```sh
SERPER_API_KEY=your_serper_api_key
# Add your provider's API key here too.
```

See the [LLM Setup guide](/en/concepts/llms#setting-up-your-llm) for details on configuring your provider of choice. You can get a Serper API key from [Serper.dev](https://serper.dev/).

## Step 8: Install Dependencies

Install the required dependencies using the CrewAI CLI:

```bash
crewai install
```

This command will:

1. Read the dependencies from your project configuration
2. Create a virtual environment if needed
3. Install all required packages

## Step 9: Run Your Crew

Now for the exciting moment - it's time to run your crew and see AI collaboration in action!

```bash
crewai run
```

When you run this command, you'll see your crew spring to life. The researcher will gather information about the specified topic, and the analyst will then create a comprehensive report based on that research. You'll see the agents' thought processes, actions, and outputs in real-time as they work together to complete their tasks.

## Step 10: Review the Output

Once the crew completes its work, you'll find the final report in the `output/report.md` file. The report will include:

1. An executive summary
2. Detailed information about the topic
3. Analysis and insights
4. Recommendations or future considerations

Take a moment to appreciate what you've accomplished - you've created a system where multiple AI agents collaborated on a complex task, each contributing their specialized skills to produce a result that's greater than what any single agent could achieve alone.

## Exploring Other CLI Commands

CrewAI offers several other useful CLI commands for working with crews:

```bash
# View all available commands
crewai --help

# Run the crew
crewai run

# Test the crew
crewai test

# Reset crew memories
crewai reset-memories

# Replay from a specific task
crewai replay -t <task_id>
```

## The Art of the Possible: Beyond Your First Crew

What you've built in this guide is just the beginning. The skills and patterns you've learned can be applied to create increasingly sophisticated AI systems. Here are some ways you could extend this basic research crew:

### Expanding Your Crew

You could add more specialized agents to your crew:

* A **fact-checker** to verify research findings
* A **data visualizer** to create charts and graphs
* A **domain expert** with specialized knowledge in a particular area
* A **critic** to identify weaknesses in the analysis

### Adding Tools and Capabilities

You could enhance your agents with additional tools:

* Web browsing tools for real-time research
* CSV/database tools for data analysis
* Code execution tools for data processing
* API connections to external services

### Creating More Complex Workflows

You could implement more sophisticated processes:

* Hierarchical processes where manager agents delegate to worker agents
* Iterative processes with feedback loops for refinement
* Parallel processes where multiple agents work simultaneously
* Dynamic processes that adapt based on intermediate results

### Applying to Different Domains

The same patterns can be applied to create crews for:

* **Content creation**: Writers, editors, fact-checkers, and designers working together
* **Customer service**: Triage agents, specialists, and quality control working together
* **Product development**: Researchers, designers, and planners collaborating
* **Data analysis**: Data collectors, analysts, and visualization specialists

## Next Steps

Now that you've built your first crew, you can:

1. Experiment with different agent configurations and personalities
2. Try more complex task structures and workflows
3. Implement custom tools to give your agents new capabilities
4. Apply your crew to different topics or problem domains
5. Explore [CrewAI Flows](/en/guides/flows/first-flow) for more advanced workflows with procedural programming

<Check>
  Congratulations! You've successfully built your first CrewAI crew that can research and analyze any topic you provide. This foundational experience has equipped you with the skills to create increasingly sophisticated AI systems that can tackle complex, multi-stage problems through collaborative intelligence.
</Check>


# Build Your First Flow
Source: https://docs.crewai.com/en/guides/flows/first-flow

Learn how to create structured, event-driven workflows with precise control over execution.

## Taking Control of AI Workflows with Flows

CrewAI Flows represent the next level in AI orchestration - combining the collaborative power of AI agent crews with the precision and flexibility of procedural programming. While crews excel at agent collaboration, flows give you fine-grained control over exactly how and when different components of your AI system interact.

In this guide, we'll walk through creating a powerful CrewAI Flow that generates a comprehensive learning guide on any topic. This tutorial will demonstrate how Flows provide structured, event-driven control over your AI workflows by combining regular code, direct LLM calls, and crew-based processing.

### What Makes Flows Powerful

Flows enable you to:

1. **Combine different AI interaction patterns** - Use crews for complex collaborative tasks, direct LLM calls for simpler operations, and regular code for procedural logic
2. **Build event-driven systems** - Define how components respond to specific events and data changes
3. **Maintain state across components** - Share and transform data between different parts of your application
4. **Integrate with external systems** - Seamlessly connect your AI workflow with databases, APIs, and user interfaces
5. **Create complex execution paths** - Design conditional branches, parallel processing, and dynamic workflows

### What You'll Build and Learn

By the end of this guide, you'll have:

1. **Created a sophisticated content generation system** that combines user input, AI planning, and multi-agent content creation
2. **Orchestrated the flow of information** between different components of your system
3. **Implemented event-driven architecture** where each step responds to the completion of previous steps
4. **Built a foundation for more complex AI applications** that you can expand and customize

This guide creator flow demonstrates fundamental patterns that can be applied to create much more advanced applications, such as:

* Interactive AI assistants that combine multiple specialized subsystems
* Complex data processing pipelines with AI-enhanced transformations
* Autonomous agents that integrate with external services and APIs
* Multi-stage decision-making systems with human-in-the-loop processes

Let's dive in and build your first flow!

## Prerequisites

Before starting, make sure you have:

1. Installed CrewAI following the [installation guide](/en/installation)
2. Set up your LLM API key in your environment, following the [LLM setup
   guide](/en/concepts/llms#setting-up-your-llm)
3. Basic understanding of Python

## Step 1: Create a New CrewAI Flow Project

First, let's create a new CrewAI Flow project using the CLI. This command sets up a scaffolded project with all the necessary directories and template files for your flow.

```bash
crewai create flow guide_creator_flow
cd guide_creator_flow
```

This will generate a project with the basic structure needed for your flow.

<Frame caption="CrewAI Framework Overview">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/flows.png" alt="CrewAI Framework Overview" />
</Frame>

## Step 2: Understanding the Project Structure

The generated project has the following structure. Take a moment to familiarize yourself with it, as understanding this structure will help you create more complex flows in the future.

```
guide_creator_flow/
├── .gitignore
├── pyproject.toml
├── README.md
├── .env
├── main.py
├── crews/
│   └── poem_crew/
│       ├── config/
│       │   ├── agents.yaml
│       │   └── tasks.yaml
│       └── poem_crew.py
└── tools/
    └── custom_tool.py
```

This structure provides a clear separation between different components of your flow:

* The main flow logic in the `main.py` file
* Specialized crews in the `crews` directory
* Custom tools in the `tools` directory

We'll modify this structure to create our guide creator flow, which will orchestrate the process of generating comprehensive learning guides.

## Step 3: Add a Content Writer Crew

Our flow will need a specialized crew to handle the content creation process. Let's use the CrewAI CLI to add a content writer crew:

```bash
crewai flow add-crew content-crew
```

This command automatically creates the necessary directories and template files for your crew. The content writer crew will be responsible for writing and reviewing sections of our guide, working within the overall flow orchestrated by our main application.

## Step 4: Configure the Content Writer Crew

Now, let's modify the generated files for the content writer crew. We'll set up two specialized agents - a writer and a reviewer - that will collaborate to create high-quality content for our guide.

1. First, update the agents configuration file to define our content creation team:

   Remember to set `llm` to the provider you are using.

```yaml
# src/guide_creator_flow/crews/content_crew/config/agents.yaml
content_writer:
  role: >
    Educational Content Writer
  goal: >
    Create engaging, informative content that thoroughly explains the assigned topic
    and provides valuable insights to the reader
  backstory: >
    You are a talented educational writer with expertise in creating clear, engaging
    content. You have a gift for explaining complex concepts in accessible language
    and organizing information in a way that helps readers build their understanding.
  llm: provider/model-id  # e.g. openai/gpt-4o, google/gemini-2.0-flash, anthropic/claude...

content_reviewer:
  role: >
    Educational Content Reviewer and Editor
  goal: >
    Ensure content is accurate, comprehensive, well-structured, and maintains
    consistency with previously written sections
  backstory: >
    You are a meticulous editor with years of experience reviewing educational
    content. You have an eye for detail, clarity, and coherence. You excel at
    improving content while maintaining the original author's voice and ensuring
    consistent quality across multiple sections.
  llm: provider/model-id  # e.g. openai/gpt-4o, google/gemini-2.0-flash, anthropic/claude...
```

These agent definitions establish the specialized roles and perspectives that will shape how our AI agents approach content creation. Notice how each agent has a distinct purpose and expertise.

2. Next, update the tasks configuration file to define the specific writing and reviewing tasks:

```yaml
# src/guide_creator_flow/crews/content_crew/config/tasks.yaml
write_section_task:
  description: >
    Write a comprehensive section on the topic: "{section_title}"

    Section description: {section_description}
    Target audience: {audience_level} level learners

    Your content should:
    1. Begin with a brief introduction to the section topic
    2. Explain all key concepts clearly with examples
    3. Include practical applications or exercises where appropriate
    4. End with a summary of key points
    5. Be approximately 500-800 words in length

    Format your content in Markdown with appropriate headings, lists, and emphasis.

    Previously written sections:
    {previous_sections}

    Make sure your content maintains consistency with previously written sections
    and builds upon concepts that have already been explained.
  expected_output: >
    A well-structured, comprehensive section in Markdown format that thoroughly
    explains the topic and is appropriate for the target audience.
  agent: content_writer

review_section_task:
  description: >
    Review and improve the following section on "{section_title}":

    {draft_content}

    Target audience: {audience_level} level learners

    Previously written sections:
    {previous_sections}

    Your review should:
    1. Fix any grammatical or spelling errors
    2. Improve clarity and readability
    3. Ensure content is comprehensive and accurate
    4. Verify consistency with previously written sections
    5. Enhance the structure and flow
    6. Add any missing key information

    Provide the improved version of the section in Markdown format.
  expected_output: >
    An improved, polished version of the section that maintains the original
    structure but enhances clarity, accuracy, and consistency.
  agent: content_reviewer
  context:
    - write_section_task
```

These task definitions provide detailed instructions to our agents, ensuring they produce content that meets our quality standards. Note how the `context` parameter in the review task creates a workflow where the reviewer has access to the writer's output.

3. Now, update the crew implementation file to define how our agents and tasks work together:

```python
# src/guide_creator_flow/crews/content_crew/content_crew.py
from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task
from crewai.agents.agent_builder.base_agent import BaseAgent
from typing import List

@CrewBase
class ContentCrew():
    """Content writing crew"""

    agents: List[BaseAgent]
    tasks: List[Task]

    @agent
    def content_writer(self) -> Agent:
        return Agent(
            config=self.agents_config['content_writer'], # type: ignore[index]
            verbose=True
        )

    @agent
    def content_reviewer(self) -> Agent:
        return Agent(
            config=self.agents_config['content_reviewer'], # type: ignore[index]
            verbose=True
        )

    @task
    def write_section_task(self) -> Task:
        return Task(
            config=self.tasks_config['write_section_task'] # type: ignore[index]
        )

    @task
    def review_section_task(self) -> Task:
        return Task(
            config=self.tasks_config['review_section_task'], # type: ignore[index]
            context=[self.write_section_task()]
        )

    @crew
    def crew(self) -> Crew:
        """Creates the content writing crew"""
        return Crew(
            agents=self.agents,
            tasks=self.tasks,
            process=Process.sequential,
            verbose=True,
        )
```

This crew definition establishes the relationship between our agents and tasks, setting up a sequential process where the content writer creates a draft and then the reviewer improves it. While this crew can function independently, in our flow it will be orchestrated as part of a larger system.

## Step 5: Create the Flow

Now comes the exciting part - creating the flow that will orchestrate the entire guide creation process. This is where we'll combine regular Python code, direct LLM calls, and our content creation crew into a cohesive system.

Our flow will:

1. Get user input for a topic and audience level
2. Make a direct LLM call to create a structured guide outline
3. Process each section sequentially using the content writer crew
4. Combine everything into a final comprehensive document

Let's create our flow in the `main.py` file:

```python
#!/usr/bin/env python
import json
import os
from typing import List, Dict
from pydantic import BaseModel, Field
from crewai import LLM
from crewai.flow.flow import Flow, listen, start
from guide_creator_flow.crews.content_crew.content_crew import ContentCrew

# Define our models for structured data
class Section(BaseModel):
    title: str = Field(description="Title of the section")
    description: str = Field(description="Brief description of what the section should cover")

class GuideOutline(BaseModel):
    title: str = Field(description="Title of the guide")
    introduction: str = Field(description="Introduction to the topic")
    target_audience: str = Field(description="Description of the target audience")
    sections: List[Section] = Field(description="List of sections in the guide")
    conclusion: str = Field(description="Conclusion or summary of the guide")

# Define our flow state
class GuideCreatorState(BaseModel):
    topic: str = ""
    audience_level: str = ""
    guide_outline: GuideOutline = None
    sections_content: Dict[str, str] = {}

class GuideCreatorFlow(Flow[GuideCreatorState]):
    """Flow for creating a comprehensive guide on any topic"""

    @start()
    def get_user_input(self):
        """Get input from the user about the guide topic and audience"""
        print("\n=== Create Your Comprehensive Guide ===\n")

        # Get user input
        self.state.topic = input("What topic would you like to create a guide for? ")

        # Get audience level with validation
        while True:
            audience = input("Who is your target audience? (beginner/intermediate/advanced) ").lower()
            if audience in ["beginner", "intermediate", "advanced"]:
                self.state.audience_level = audience
                break
            print("Please enter 'beginner', 'intermediate', or 'advanced'")

        print(f"\nCreating a guide on {self.state.topic} for {self.state.audience_level} audience...\n")
        return self.state

    @listen(get_user_input)
    def create_guide_outline(self, state):
        """Create a structured outline for the guide using a direct LLM call"""
        print("Creating guide outline...")

        # Initialize the LLM
        llm = LLM(model="openai/gpt-4o-mini", response_format=GuideOutline)

        # Create the messages for the outline
        messages = [
            {"role": "system", "content": "You are a helpful assistant designed to output JSON."},
            {"role": "user", "content": f"""
            Create a detailed outline for a comprehensive guide on "{state.topic}" for {state.audience_level} level learners.

            The outline should include:
            1. A compelling title for the guide
            2. An introduction to the topic
            3. 4-6 main sections that cover the most important aspects of the topic
            4. A conclusion or summary

            For each section, provide a clear title and a brief description of what it should cover.
            """}
        ]

        # Make the LLM call with JSON response format
        response = llm.call(messages=messages)

        # Parse the JSON response
        outline_dict = json.loads(response)
        self.state.guide_outline = GuideOutline(**outline_dict)

        # Ensure output directory exists before saving
        os.makedirs("output", exist_ok=True)

        # Save the outline to a file
        with open("output/guide_outline.json", "w") as f:
            json.dump(outline_dict, f, indent=2)

        print(f"Guide outline created with {len(self.state.guide_outline.sections)} sections")
        return self.state.guide_outline

    @listen(create_guide_outline)
    def write_and_compile_guide(self, outline):
        """Write all sections and compile the guide"""
        print("Writing guide sections and compiling...")
        completed_sections = []

        # Process sections one by one to maintain context flow
        for section in outline.sections:
            print(f"Processing section: {section.title}")

            # Build context from previous sections
            previous_sections_text = ""
            if completed_sections:
                previous_sections_text = "# Previously Written Sections\n\n"
                for title in completed_sections:
                    previous_sections_text += f"## {title}\n\n"
                    previous_sections_text += self.state.sections_content.get(title, "") + "\n\n"
            else:
                previous_sections_text = "No previous sections written yet."

            # Run the content crew for this section
            result = ContentCrew().crew().kickoff(inputs={
                "section_title": section.title,
                "section_description": section.description,
                "audience_level": self.state.audience_level,
                "previous_sections": previous_sections_text,
                "draft_content": ""
            })

            # Store the content
            self.state.sections_content[section.title] = result.raw
            completed_sections.append(section.title)
            print(f"Section completed: {section.title}")

        # Compile the final guide
        guide_content = f"# {outline.title}\n\n"
        guide_content += f"## Introduction\n\n{outline.introduction}\n\n"

        # Add each section in order
        for section in outline.sections:
            section_content = self.state.sections_content.get(section.title, "")
            guide_content += f"\n\n{section_content}\n\n"

        # Add conclusion
        guide_content += f"## Conclusion\n\n{outline.conclusion}\n\n"

        # Save the guide
        with open("output/complete_guide.md", "w") as f:
            f.write(guide_content)

        print("\nComplete guide compiled and saved to output/complete_guide.md")
        return "Guide creation completed successfully"

def kickoff():
    """Run the guide creator flow"""
    GuideCreatorFlow().kickoff()
    print("\n=== Flow Complete ===")
    print("Your comprehensive guide is ready in the output directory.")
    print("Open output/complete_guide.md to view it.")

def plot():
    """Generate a visualization of the flow"""
    flow = GuideCreatorFlow()
    flow.plot("guide_creator_flow")
    print("Flow visualization saved to guide_creator_flow.html")

if __name__ == "__main__":
    kickoff()
```

Let's analyze what's happening in this flow:

1. We define Pydantic models for structured data, ensuring type safety and clear data representation
2. We create a state class to maintain data across different steps of the flow
3. We implement three main flow steps:
   * Getting user input with the `@start()` decorator
   * Creating a guide outline with a direct LLM call
   * Processing sections with our content crew
4. We use the `@listen()` decorator to establish event-driven relationships between steps

This is the power of flows - combining different types of processing (user interaction, direct LLM calls, crew-based tasks) into a coherent, event-driven system.

## Step 6: Set Up Your Environment Variables

Create a `.env` file in your project root with your API keys. See the [LLM setup
guide](/en/concepts/llms#setting-up-your-llm) for details on configuring a provider.

```sh .env
OPENAI_API_KEY=your_openai_api_key
# or
GEMINI_API_KEY=your_gemini_api_key
# or
ANTHROPIC_API_KEY=your_anthropic_api_key
```

## Step 7: Install Dependencies

Install the required dependencies:

```bash
crewai install
```

## Step 8: Run Your Flow

Now it's time to see your flow in action! Run it using the CrewAI CLI:

```bash
crewai flow kickoff
```

When you run this command, you'll see your flow spring to life:

1. It will prompt you for a topic and audience level
2. It will create a structured outline for your guide
3. It will process each section, with the content writer and reviewer collaborating on each
4. Finally, it will compile everything into a comprehensive guide

This demonstrates the power of flows to orchestrate complex processes involving multiple components, both AI and non-AI.

## Step 9: Visualize Your Flow

One of the powerful features of flows is the ability to visualize their structure:

```bash
crewai flow plot
```

This will create an HTML file that shows the structure of your flow, including the relationships between different steps and the data that flows between them. This visualization can be invaluable for understanding and debugging complex flows.

## Step 10: Review the Output

Once the flow completes, you'll find two files in the `output` directory:

1. `guide_outline.json`: Contains the structured outline of the guide
2. `complete_guide.md`: The comprehensive guide with all sections

Take a moment to review these files and appreciate what you've built - a system that combines user input, direct AI interactions, and collaborative agent work to produce a complex, high-quality output.

## The Art of the Possible: Beyond Your First Flow

What you've learned in this guide provides a foundation for creating much more sophisticated AI systems. Here are some ways you could extend this basic flow:

### Enhancing User Interaction

You could create more interactive flows with:

* Web interfaces for input and output
* Real-time progress updates
* Interactive feedback and refinement loops
* Multi-stage user interactions

### Adding More Processing Steps

You could expand your flow with additional steps for:

* Research before outline creation
* Image generation for illustrations
* Code snippet generation for technical guides
* Final quality assurance and fact-checking

### Creating More Complex Flows

You could implement more sophisticated flow patterns:

* Conditional branching based on user preferences or content type
* Parallel processing of independent sections
* Iterative refinement loops with feedback
* Integration with external APIs and services

### Applying to Different Domains

The same patterns can be applied to create flows for:

* **Interactive storytelling**: Create personalized stories based on user input
* **Business intelligence**: Process data, generate insights, and create reports
* **Product development**: Facilitate ideation, design, and planning
* **Educational systems**: Create personalized learning experiences

## Key Features Demonstrated

This guide creator flow demonstrates several powerful features of CrewAI:

1. **User interaction**: The flow collects input directly from the user
2. **Direct LLM calls**: Uses the LLM class for efficient, single-purpose AI interactions
3. **Structured data with Pydantic**: Uses Pydantic models to ensure type safety
4. **Sequential processing with context**: Writes sections in order, providing previous sections for context
5. **Multi-agent crews**: Leverages specialized agents (writer and reviewer) for content creation
6. **State management**: Maintains state across different steps of the process
7. **Event-driven architecture**: Uses the `@listen` decorator to respond to events

## Understanding the Flow Structure

Let's break down the key components of flows to help you understand how to build your own:

### 1. Direct LLM Calls

Flows allow you to make direct calls to language models when you need simple, structured responses:

```python
llm = LLM(
    model="model-id-here",  # gpt-4o, gemini-2.0-flash, anthropic/claude...
    response_format=GuideOutline
)
response = llm.call(messages=messages)
```

This is more efficient than using a crew when you need a specific, structured output.

### 2. Event-Driven Architecture

Flows use decorators to establish relationships between components:

```python
@start()
def get_user_input(self):
    # First step in the flow
    # ...

@listen(get_user_input)
def create_guide_outline(self, state):
    # This runs when get_user_input completes
    # ...
```

This creates a clear, declarative structure for your application.

### 3. State Management

Flows maintain state across steps, making it easy to share data:

```python
class GuideCreatorState(BaseModel):
    topic: str = ""
    audience_level: str = ""
    guide_outline: GuideOutline = None
    sections_content: Dict[str, str] = {}
```

This provides a type-safe way to track and transform data throughout your flow.

### 4. Crew Integration

Flows can seamlessly integrate with crews for complex collaborative tasks:

```python
result = ContentCrew().crew().kickoff(inputs={
    "section_title": section.title,
    # ...
})
```

This allows you to use the right tool for each part of your application - direct LLM calls for simple tasks and crews for complex collaboration.

## Next Steps

Now that you've built your first flow, you can:

1. Experiment with more complex flow structures and patterns
2. Try using `@router()` to create conditional branches in your flows
3. Explore the `and_` and `or_` functions for more complex parallel execution
4. Connect your flow to external APIs, databases, or user interfaces
5. Combine multiple specialized crews in a single flow

<Check>
  Congratulations! You've successfully built your first CrewAI Flow that combines regular code, direct LLM calls, and crew-based processing to create a comprehensive guide. These foundational skills enable you to create increasingly sophisticated AI applications that can tackle complex, multi-stage problems through a combination of procedural control and collaborative intelligence.
</Check>


# Mastering Flow State Management
Source: https://docs.crewai.com/en/guides/flows/mastering-flow-state

A comprehensive guide to managing, persisting, and leveraging state in CrewAI Flows for building robust AI applications.

## Understanding the Power of State in Flows

State management is the backbone of any sophisticated AI workflow. In CrewAI Flows, the state system allows you to maintain context, share data between steps, and build complex application logic. Mastering state management is essential for creating reliable, maintainable, and powerful AI applications.

This guide will walk you through everything you need to know about managing state in CrewAI Flows, from basic concepts to advanced techniques, with practical code examples along the way.

### Why State Management Matters

Effective state management enables you to:

1. **Maintain context across execution steps** - Pass information seamlessly between different stages of your workflow
2. **Build complex conditional logic** - Make decisions based on accumulated data
3. **Create persistent applications** - Save and restore workflow progress
4. **Handle errors gracefully** - Implement recovery patterns for more robust applications
5. **Scale your applications** - Support complex workflows with proper data organization
6. **Enable conversational applications** - Store and access conversation history for context-aware AI interactions

Let's explore how to leverage these capabilities effectively.

## State Management Fundamentals

### The Flow State Lifecycle

In CrewAI Flows, the state follows a predictable lifecycle:

1. **Initialization** - When a flow is created, its state is initialized (either as an empty dictionary or a Pydantic model instance)
2. **Modification** - Flow methods access and modify the state as they execute
3. **Transmission** - State is passed automatically between flow methods
4. **Persistence** (optional) - State can be saved to storage and later retrieved
5. **Completion** - The final state reflects the cumulative changes from all executed methods

Understanding this lifecycle is crucial for designing effective flows.

### Two Approaches to State Management

CrewAI offers two ways to manage state in your flows:

1. **Unstructured State** - Using dictionary-like objects for flexibility
2. **Structured State** - Using Pydantic models for type safety and validation

Let's examine each approach in detail.

## Unstructured State Management

Unstructured state uses a dictionary-like approach, offering flexibility and simplicity for straightforward applications.

### How It Works

With unstructured state:

* You access state via `self.state` which behaves like a dictionary
* You can freely add, modify, or remove keys at any point
* All state is automatically available to all flow methods

### Basic Example

Here's a simple example of unstructured state management:

```python
from crewai.flow.flow import Flow, listen, start

class UnstructuredStateFlow(Flow):
    @start()
    def initialize_data(self):
        print("Initializing flow data")
        # Add key-value pairs to state
        self.state["user_name"] = "Alex"
        self.state["preferences"] = {
            "theme": "dark",
            "language": "English"
        }
        self.state["items"] = []

        # The flow state automatically gets a unique ID
        print(f"Flow ID: {self.state['id']}")

        return "Initialized"

    @listen(initialize_data)
    def process_data(self, previous_result):
        print(f"Previous step returned: {previous_result}")

        # Access and modify state
        user = self.state["user_name"]
        print(f"Processing data for {user}")

        # Add items to a list in state
        self.state["items"].append("item1")
        self.state["items"].append("item2")

        # Add a new key-value pair
        self.state["processed"] = True

        return "Processed"

    @listen(process_data)
    def generate_summary(self, previous_result):
        # Access multiple state values
        user = self.state["user_name"]
        theme = self.state["preferences"]["theme"]
        items = self.state["items"]
        processed = self.state.get("processed", False)

        summary = f"User {user} has {len(items)} items with {theme} theme. "
        summary += "Data is processed." if processed else "Data is not processed."

        return summary

# Run the flow
flow = UnstructuredStateFlow()
result = flow.kickoff()
print(f"Final result: {result}")
print(f"Final state: {flow.state}")
```

### When to Use Unstructured State

Unstructured state is ideal for:

* Quick prototyping and simple flows
* Dynamically evolving state needs
* Cases where the structure may not be known in advance
* Flows with simple state requirements

While flexible, unstructured state lacks type checking and schema validation, which can lead to errors in complex applications.

## Structured State Management

Structured state uses Pydantic models to define a schema for your flow's state, providing type safety, validation, and better developer experience.

### How It Works

With structured state:

* You define a Pydantic model that represents your state structure
* You pass this model type to your Flow class as a type parameter
* You access state via `self.state`, which behaves like a Pydantic model instance
* All fields are validated according to their defined types
* You get IDE autocompletion and type checking support

### Basic Example

Here's how to implement structured state management:

```python
from crewai.flow.flow import Flow, listen, start
from pydantic import BaseModel, Field
from typing import List, Dict, Optional

# Define your state model
class UserPreferences(BaseModel):
    theme: str = "light"
    language: str = "English"

class AppState(BaseModel):
    user_name: str = ""
    preferences: UserPreferences = UserPreferences()
    items: List[str] = []
    processed: bool = False
    completion_percentage: float = 0.0

# Create a flow with typed state
class StructuredStateFlow(Flow[AppState]):
    @start()
    def initialize_data(self):
        print("Initializing flow data")
        # Set state values (type-checked)
        self.state.user_name = "Taylor"
        self.state.preferences.theme = "dark"

        # The ID field is automatically available
        print(f"Flow ID: {self.state.id}")

        return "Initialized"

    @listen(initialize_data)
    def process_data(self, previous_result):
        print(f"Processing data for {self.state.user_name}")

        # Modify state (with type checking)
        self.state.items.append("item1")
        self.state.items.append("item2")
        self.state.processed = True
        self.state.completion_percentage = 50.0

        return "Processed"

    @listen(process_data)
    def generate_summary(self, previous_result):
        # Access state (with autocompletion)
        summary = f"User {self.state.user_name} has {len(self.state.items)} items "
        summary += f"with {self.state.preferences.theme} theme. "
        summary += "Data is processed." if self.state.processed else "Data is not processed."
        summary += f" Completion: {self.state.completion_percentage}%"

        return summary

# Run the flow
flow = StructuredStateFlow()
result = flow.kickoff()
print(f"Final result: {result}")
print(f"Final state: {flow.state}")
```

### Benefits of Structured State

Using structured state provides several advantages:

1. **Type Safety** - Catch type errors at development time
2. **Self-Documentation** - The state model clearly documents what data is available
3. **Validation** - Automatic validation of data types and constraints
4. **IDE Support** - Get autocomplete and inline documentation
5. **Default Values** - Easily define fallbacks for missing data

### When to Use Structured State

Structured state is recommended for:

* Complex flows with well-defined data schemas
* Team projects where multiple developers work on the same code
* Applications where data validation is important
* Flows that need to enforce specific data types and constraints

## The Automatic State ID

Both unstructured and structured states automatically receive a unique identifier (UUID) to help track and manage state instances.

### How It Works

* For unstructured state, the ID is accessible as `self.state["id"]`
* For structured state, the ID is accessible as `self.state.id`
* This ID is generated automatically when the flow is created
* The ID remains the same throughout the flow's lifecycle
* The ID can be used for tracking, logging, and retrieving persisted states

This UUID is particularly valuable when implementing persistence or tracking multiple flow executions.

## Dynamic State Updates

Regardless of whether you're using structured or unstructured state, you can update state dynamically throughout your flow's execution.

### Passing Data Between Steps

Flow methods can return values that are then passed as arguments to listening methods:

```python
from crewai.flow.flow import Flow, listen, start

class DataPassingFlow(Flow):
    @start()
    def generate_data(self):
        # This return value will be passed to listening methods
        return "Generated data"

    @listen(generate_data)
    def process_data(self, data_from_previous_step):
        print(f"Received: {data_from_previous_step}")
        # You can modify the data and pass it along
        processed_data = f"{data_from_previous_step} - processed"
        # Also update state
        self.state["last_processed"] = processed_data
        return processed_data

    @listen(process_data)
    def finalize_data(self, processed_data):
        print(f"Received processed data: {processed_data}")
        # Access both the passed data and state
        last_processed = self.state.get("last_processed", "")
        return f"Final: {processed_data} (from state: {last_processed})"
```

This pattern allows you to combine direct data passing with state updates for maximum flexibility.

## Persisting Flow State

One of CrewAI's most powerful features is the ability to persist flow state across executions. This enables workflows that can be paused, resumed, and even recovered after failures.

### The @persist() Decorator

The `@persist()` decorator automates state persistence, saving your flow's state at key points in execution.

#### Class-Level Persistence

When applied at the class level, `@persist()` saves state after every method execution:

```python
from crewai.flow.flow import Flow, listen, start
from crewai.flow.persistence import persist
from pydantic import BaseModel

class CounterState(BaseModel):
    value: int = 0

@persist()  # Apply to the entire flow class
class PersistentCounterFlow(Flow[CounterState]):
    @start()
    def increment(self):
        self.state.value += 1
        print(f"Incremented to {self.state.value}")
        return self.state.value

    @listen(increment)
    def double(self, value):
        self.state.value = value * 2
        print(f"Doubled to {self.state.value}")
        return self.state.value

# First run
flow1 = PersistentCounterFlow()
result1 = flow1.kickoff()
print(f"First run result: {result1}")

# Second run - state is automatically loaded
flow2 = PersistentCounterFlow()
result2 = flow2.kickoff()
print(f"Second run result: {result2}")  # Will be higher due to persisted state
```

#### Method-Level Persistence

For more granular control, you can apply `@persist()` to specific methods:

```python
from crewai.flow.flow import Flow, listen, start
from crewai.flow.persistence import persist

class SelectivePersistFlow(Flow):
    @start()
    def first_step(self):
        self.state["count"] = 1
        return "First step"

    @persist()  # Only persist after this method
    @listen(first_step)
    def important_step(self, prev_result):
        self.state["count"] += 1
        self.state["important_data"] = "This will be persisted"
        return "Important step completed"

    @listen(important_step)
    def final_step(self, prev_result):
        self.state["count"] += 1
        return f"Complete with count {self.state['count']}"
```

## Advanced State Patterns

### State-Based Conditional Logic

You can use state to implement complex conditional logic in your flows:

```python
from crewai.flow.flow import Flow, listen, router, start
from pydantic import BaseModel

class PaymentState(BaseModel):
    amount: float = 0.0
    is_approved: bool = False
    retry_count: int = 0

class PaymentFlow(Flow[PaymentState]):
    @start()
    def process_payment(self):
        # Simulate payment processing
        self.state.amount = 100.0
        self.state.is_approved = self.state.amount < 1000
        return "Payment processed"

    @router(process_payment)
    def check_approval(self, previous_result):
        if self.state.is_approved:
            return "approved"
        elif self.state.retry_count < 3:
            return "retry"
        else:
            return "rejected"

    @listen("approved")
    def handle_approval(self):
        return f"Payment of ${self.state.amount} approved!"

    @listen("retry")
    def handle_retry(self):
        self.state.retry_count += 1
        print(f"Retrying payment (attempt {self.state.retry_count})...")
        # Could implement retry logic here
        return "Retry initiated"

    @listen("rejected")
    def handle_rejection(self):
        return f"Payment of ${self.state.amount} rejected after {self.state.retry_count} retries."
```

### Handling Complex State Transformations

For complex state transformations, you can create dedicated methods:

```python
from crewai.flow.flow import Flow, listen, start
from pydantic import BaseModel
from typing import List, Dict

class UserData(BaseModel):
    name: str
    active: bool = True
    login_count: int = 0

class ComplexState(BaseModel):
    users: Dict[str, UserData] = {}
    active_user_count: int = 0

class TransformationFlow(Flow[ComplexState]):
    @start()
    def initialize(self):
        # Add some users
        self.add_user("alice", "Alice")
        self.add_user("bob", "Bob")
        self.add_user("charlie", "Charlie")
        return "Initialized"

    @listen(initialize)
    def process_users(self, _):
        # Increment login counts
        for user_id in self.state.users:
            self.increment_login(user_id)

        # Deactivate one user
        self.deactivate_user("bob")

        # Update active count
        self.update_active_count()

        return f"Processed {len(self.state.users)} users"

    # Helper methods for state transformations
    def add_user(self, user_id: str, name: str):
        self.state.users[user_id] = UserData(name=name)
        self.update_active_count()

    def increment_login(self, user_id: str):
        if user_id in self.state.users:
            self.state.users[user_id].login_count += 1

    def deactivate_user(self, user_id: str):
        if user_id in self.state.users:
            self.state.users[user_id].active = False
            self.update_active_count()

    def update_active_count(self):
        self.state.active_user_count = sum(
            1 for user in self.state.users.values() if user.active
        )
```

This pattern of creating helper methods keeps your flow methods clean while enabling complex state manipulations.

## State Management with Crews

One of the most powerful patterns in CrewAI is combining flow state management with crew execution.

### Passing State to Crews

You can use flow state to parameterize crews:

```python
from crewai.flow.flow import Flow, listen, start
from crewai import Agent, Crew, Process, Task
from pydantic import BaseModel

class ResearchState(BaseModel):
    topic: str = ""
    depth: str = "medium"
    results: str = ""

class ResearchFlow(Flow[ResearchState]):
    @start()
    def get_parameters(self):
        # In a real app, this might come from user input
        self.state.topic = "Artificial Intelligence Ethics"
        self.state.depth = "deep"
        return "Parameters set"

    @listen(get_parameters)
    def execute_research(self, _):
        # Create agents
        researcher = Agent(
            role="Research Specialist",
            goal=f"Research {self.state.topic} in {self.state.depth} detail",
            backstory="You are an expert researcher with a talent for finding accurate information."
        )

        writer = Agent(
            role="Content Writer",
            goal="Transform research into clear, engaging content",
            backstory="You excel at communicating complex ideas clearly and concisely."
        )

        # Create tasks
        research_task = Task(
            description=f"Research {self.state.topic} with {self.state.depth} analysis",
            expected_output="Comprehensive research notes in markdown format",
            agent=researcher
        )

        writing_task = Task(
            description=f"Create a summary on {self.state.topic} based on the research",
            expected_output="Well-written article in markdown format",
            agent=writer,
            context=[research_task]
        )

        # Create and run crew
        research_crew = Crew(
            agents=[researcher, writer],
            tasks=[research_task, writing_task],
            process=Process.sequential,
            verbose=True
        )

        # Run crew and store result in state
        result = research_crew.kickoff()
        self.state.results = result.raw

        return "Research completed"

    @listen(execute_research)
    def summarize_results(self, _):
        # Access the stored results
        result_length = len(self.state.results)
        return f"Research on {self.state.topic} completed with {result_length} characters of results."
```

### Handling Crew Outputs in State

When a crew completes, you can process its output and store it in your flow state:

```python
@listen(execute_crew)
def process_crew_results(self, _):
    # Parse the raw results (assuming JSON output)
    import json
    try:
        results_dict = json.loads(self.state.raw_results)
        self.state.processed_results = {
            "title": results_dict.get("title", ""),
            "main_points": results_dict.get("main_points", []),
            "conclusion": results_dict.get("conclusion", "")
        }
        return "Results processed successfully"
    except json.JSONDecodeError:
        self.state.error = "Failed to parse crew results as JSON"
        return "Error processing results"
```

## Best Practices for State Management

### 1. Keep State Focused

Design your state to contain only what's necessary:

```python
# Too broad
class BloatedState(BaseModel):
    user_data: Dict = {}
    system_settings: Dict = {}
    temporary_calculations: List = []
    debug_info: Dict = {}
    # ...many more fields

# Better: Focused state
class FocusedState(BaseModel):
    user_id: str
    preferences: Dict[str, str]
    completion_status: Dict[str, bool]
```

### 2. Use Structured State for Complex Flows

As your flows grow in complexity, structured state becomes increasingly valuable:

```python
# Simple flow can use unstructured state
class SimpleGreetingFlow(Flow):
    @start()
    def greet(self):
        self.state["name"] = "World"
        return f"Hello, {self.state['name']}!"

# Complex flow benefits from structured state
class UserRegistrationState(BaseModel):
    username: str
    email: str
    verification_status: bool = False
    registration_date: datetime = Field(default_factory=datetime.now)
    last_login: Optional[datetime] = None

class RegistrationFlow(Flow[UserRegistrationState]):
    # Methods with strongly-typed state access
```

### 3. Document State Transitions

For complex flows, document how state changes throughout the execution:

```python
@start()
def initialize_order(self):
    """
    Initialize order state with empty values.

    State before: {}
    State after: {order_id: str, items: [], status: 'new'}
    """
    self.state.order_id = str(uuid.uuid4())
    self.state.items = []
    self.state.status = "new"
    return "Order initialized"
```

### 4. Handle State Errors Gracefully

Implement error handling for state access:

```python
@listen(previous_step)
def process_data(self, _):
    try:
        # Try to access a value that might not exist
        user_preference = self.state.preferences.get("theme", "default")
    except (AttributeError, KeyError):
        # Handle the error gracefully
        self.state.errors = self.state.get("errors", [])
        self.state.errors.append("Failed to access preferences")
        user_preference = "default"

    return f"Used preference: {user_preference}"
```

### 5. Use State for Progress Tracking

Leverage state to track progress in long-running flows:

```python
class ProgressTrackingFlow(Flow):
    @start()
    def initialize(self):
        self.state["total_steps"] = 3
        self.state["current_step"] = 0
        self.state["progress"] = 0.0
        self.update_progress()
        return "Initialized"

    def update_progress(self):
        """Helper method to calculate and update progress"""
        if self.state.get("total_steps", 0) > 0:
            self.state["progress"] = (self.state.get("current_step", 0) /
                                    self.state["total_steps"]) * 100
            print(f"Progress: {self.state['progress']:.1f}%")

    @listen(initialize)
    def step_one(self, _):
        # Do work...
        self.state["current_step"] = 1
        self.update_progress()
        return "Step 1 complete"

    # Additional steps...
```

### 6. Use Immutable Operations When Possible

Especially with structured state, prefer immutable operations for clarity:

```python
# Instead of modifying lists in place:
self.state.items.append(new_item)  # Mutable operation

# Consider creating new state:
from pydantic import BaseModel
from typing import List

class ItemState(BaseModel):
    items: List[str] = []

class ImmutableFlow(Flow[ItemState]):
    @start()
    def add_item(self):
        # Create new list with the added item
        self.state.items = [*self.state.items, "new item"]
        return "Item added"
```

## Debugging Flow State

### Logging State Changes

When developing, add logging to track state changes:

```python
import logging
logging.basicConfig(level=logging.INFO)

class LoggingFlow(Flow):
    def log_state(self, step_name):
        logging.info(f"State after {step_name}: {self.state}")

    @start()
    def initialize(self):
        self.state["counter"] = 0
        self.log_state("initialize")
        return "Initialized"

    @listen(initialize)
    def increment(self, _):
        self.state["counter"] += 1
        self.log_state("increment")
        return f"Incremented to {self.state['counter']}"
```

### State Visualization

You can add methods to visualize your state for debugging:

```python
def visualize_state(self):
    """Create a simple visualization of the current state"""
    import json
    from rich.console import Console
    from rich.panel import Panel

    console = Console()

    if hasattr(self.state, "model_dump"):
        # Pydantic v2
        state_dict = self.state.model_dump()
    elif hasattr(self.state, "dict"):
        # Pydantic v1
        state_dict = self.state.dict()
    else:
        # Unstructured state
        state_dict = dict(self.state)

    # Remove id for cleaner output
    if "id" in state_dict:
        state_dict.pop("id")

    state_json = json.dumps(state_dict, indent=2, default=str)
    console.print(Panel(state_json, title="Current Flow State"))
```

## Conclusion

Mastering state management in CrewAI Flows gives you the power to build sophisticated, robust AI applications that maintain context, make complex decisions, and deliver consistent results.

Whether you choose unstructured or structured state, implementing proper state management practices will help you create flows that are maintainable, extensible, and effective at solving real-world problems.

As you develop more complex flows, remember that good state management is about finding the right balance between flexibility and structure, making your code both powerful and easy to understand.

<Check>
  You've now mastered the concepts and practices of state management in CrewAI Flows! With this knowledge, you can create robust AI workflows that effectively maintain context, share data between steps, and build sophisticated application logic.
</Check>

## Next Steps

* Experiment with both structured and unstructured state in your flows
* Try implementing state persistence for long-running workflows
* Explore [building your first crew](/en/guides/crews/first-crew) to see how crews and flows can work together
* Check out the [Flow reference documentation](/en/concepts/flows) for more advanced features


# Installation
Source: https://docs.crewai.com/en/installation

Get started with CrewAI - Install, configure, and build your first AI crew

## Video Tutorial

Watch this video tutorial for a step-by-step demonstration of the installation process:

<iframe width="100%" height="400" src="https://www.youtube.com/embed/-kSOTtYzgEw" title="CrewAI Installation Guide" frameborder="0" style={{ borderRadius: '10px' }} allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

## Text Tutorial

<Note>
  **Python Version Requirements**

  CrewAI requires `Python >=3.10 and <3.14`. Here's how to check your version:

  ```bash
  python3 --version
  ```

  If you need to update Python, visit [python.org/downloads](https://python.org/downloads)
</Note>

CrewAI uses the `uv` as its dependency management and package handling tool. It simplifies project setup and execution, offering a seamless experience.

If you haven't installed `uv` yet, follow **step 1** to quickly get it set up on your system, else you can skip to **step 2**.

<Steps>
  <Step title="Install uv">
    * **On macOS/Linux:**

      Use `curl` to download the script and execute it with `sh`:

      ```shell
      curl -LsSf https://astral.sh/uv/install.sh | sh
      ```

      If your system doesn't have `curl`, you can use `wget`:

      ```shell
      wget -qO- https://astral.sh/uv/install.sh | sh
      ```

    * **On Windows:**

      Use `irm` to download the script and `iex` to execute it:

      ```shell
      powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
      ```

      If you run into any issues, refer to [UV's installation guide](https://docs.astral.sh/uv/getting-started/installation/) for more information.
  </Step>

  <Step title="Install CrewAI 🚀">
    * Run the following command to install `crewai` CLI:

      ```shell
      uv tool install crewai
      ```

      <Warning>
        If you encounter a `PATH` warning, run this command to update your shell:

        ```shell
        uv tool update-shell
        ```
      </Warning>

      <Warning>
        If you encounter the `chroma-hnswlib==0.7.6` build error (`fatal error C1083: Cannot open include file: 'float.h'`) on Windows, install [Visual Studio Build Tools](https://visualstudio.microsoft.com/downloads/) with *Desktop development with C++*.
      </Warning>

    * To verify that `crewai` is installed, run:
      ```shell
      uv tool list
      ```

    * You should see something like:
      ```shell
      crewai v0.102.0
      - crewai
      ```

    * If you need to update `crewai`, run:
      ```shell
      uv tool install crewai --upgrade
      ```

    <Check>Installation successful! You're ready to create your first crew! 🎉</Check>
  </Step>
</Steps>

# Creating a CrewAI Project

We recommend using the `YAML` template scaffolding for a structured approach to defining agents and tasks. Here's how to get started:

<Steps>
  <Step title="Generate Project Scaffolding">
    * Run the `crewai` CLI command:
      ```shell
      crewai create crew <your_project_name>
      ```

    * This creates a new project with the following structure:
      ```
      my_project/
      ├── .gitignore
      ├── knowledge/
      ├── pyproject.toml
      ├── README.md
      ├── .env
      └── src/
          └── my_project/
              ├── __init__.py
              ├── main.py
              ├── crew.py
              ├── tools/
              │   ├── custom_tool.py
              │   └── __init__.py
              └── config/
                  ├── agents.yaml
                  └── tasks.yaml
      ```
  </Step>

  <Step title="Customize Your Project">
    * Your project will contain these essential files:
      | File          | Purpose                                  |
      | ------------- | ---------------------------------------- |
      | `agents.yaml` | Define your AI agents and their roles    |
      | `tasks.yaml`  | Set up agent tasks and workflows         |
      | `.env`        | Store API keys and environment variables |
      | `main.py`     | Project entry point and execution flow   |
      | `crew.py`     | Crew orchestration and coordination      |
      | `tools/`      | Directory for custom agent tools         |
      | `knowledge/`  | Directory for knowledge base             |

    * Start by editing `agents.yaml` and `tasks.yaml` to define your crew's behavior.

    * Keep sensitive information like API keys in `.env`.
  </Step>

  <Step title="Run your Crew">
    * Before you run your crew, make sure to run:
      ```bash
      crewai install
      ```
    * If you need to install additional packages, use:
      ```shell
      uv add <package-name>
      ```
    * To run your crew, execute the following command in the root of your project:
      ```bash
      crewai run
      ```
  </Step>
</Steps>

## Enterprise Installation Options

<Note type="info">
  For teams and organizations, CrewAI offers enterprise deployment options that eliminate setup complexity:

  ### CrewAI Enterprise (SaaS)

  * Zero installation required - just sign up for free at [app.crewai.com](https://app.crewai.com)
  * Automatic updates and maintenance
  * Managed infrastructure and scaling
  * Build Crews with no Code

  ### CrewAI Factory (Self-hosted)

  * Containerized deployment for your infrastructure
  * Supports any hyperscaler including on prem deployments
  * Integration with your existing security systems

  <Card title="Explore Enterprise Options" icon="building" href="https://crewai.com/enterprise">
    Learn about CrewAI's enterprise offerings and schedule a demo
  </Card>
</Note>

## Next Steps

<CardGroup cols={2}>
  <Card title="Build Your First Agent" icon="code" href="/en/quickstart">
    Follow our quickstart guide to create your first CrewAI agent and get hands-on experience.
  </Card>

  <Card title="Join the Community" icon="comments" href="https://community.crewai.com">
    Connect with other developers, get help, and share your CrewAI experiences.
  </Card>
</CardGroup>


# Introduction
Source: https://docs.crewai.com/en/introduction

Build AI agent teams that work together to tackle complex tasks

# What is CrewAI?

**CrewAI is a lean, lightning-fast Python framework built entirely from scratch—completely independent of LangChain or other agent frameworks.**

CrewAI empowers developers with both high-level simplicity and precise low-level control, ideal for creating autonomous AI agents tailored to any scenario:

* **[CrewAI Crews](/en/guides/crews/first-crew)**: Optimize for autonomy and collaborative intelligence, enabling you to create AI teams where each agent has specific roles, tools, and goals.
* **[CrewAI Flows](/en/guides/flows/first-flow)**: Enable granular, event-driven control, single LLM calls for precise task orchestration and supports Crews natively.

With over 100,000 developers certified through our community courses, CrewAI is rapidly becoming the standard for enterprise-ready AI automation.

## How Crews Work

<Note>
  Just like a company has departments (Sales, Engineering, Marketing) working together under leadership to achieve business goals, CrewAI helps you create an organization of AI agents with specialized roles collaborating to accomplish complex tasks.
</Note>

<Frame caption="CrewAI Framework Overview">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crews.png" alt="CrewAI Framework Overview" />
</Frame>

| Component     |         Description        | Key Features                                                                                                                      |
| :------------ | :------------------------: | :-------------------------------------------------------------------------------------------------------------------------------- |
| **Crew**      | The top-level organization | • Manages AI agent teams<br />• Oversees workflows<br />• Ensures collaboration<br />• Delivers outcomes                          |
| **AI Agents** |  Specialized team members  | • Have specific roles (researcher, writer)<br />• Use designated tools<br />• Can delegate tasks<br />• Make autonomous decisions |
| **Process**   | Workflow management system | • Defines collaboration patterns<br />• Controls task assignments<br />• Manages interactions<br />• Ensures efficient execution  |
| **Tasks**     |   Individual assignments   | • Have clear objectives<br />• Use specific tools<br />• Feed into larger process<br />• Produce actionable results               |

### How It All Works Together

1. The **Crew** organizes the overall operation
2. **AI Agents** work on their specialized tasks
3. The **Process** ensures smooth collaboration
4. **Tasks** get completed to achieve the goal

## Key Features

<CardGroup cols={2}>
  <Card title="Role-Based Agents" icon="users">
    Create specialized agents with defined roles, expertise, and goals - from researchers to analysts to writers
  </Card>

  <Card title="Flexible Tools" icon="screwdriver-wrench">
    Equip agents with custom tools and APIs to interact with external services and data sources
  </Card>

  <Card title="Intelligent Collaboration" icon="people-arrows">
    Agents work together, sharing insights and coordinating tasks to achieve complex objectives
  </Card>

  <Card title="Task Management" icon="list-check">
    Define sequential or parallel workflows, with agents automatically handling task dependencies
  </Card>
</CardGroup>

## How Flows Work

<Note>
  While Crews excel at autonomous collaboration, Flows provide structured automations, offering granular control over workflow execution. Flows ensure tasks are executed reliably, securely, and efficiently, handling conditional logic, loops, and dynamic state management with precision. Flows integrate seamlessly with Crews, enabling you to balance high autonomy with exacting control.
</Note>

<Frame caption="CrewAI Framework Overview">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/flows.png" alt="CrewAI Framework Overview" />
</Frame>

| Component        |            Description            | Key Features                                                                                                                                                         |
| :--------------- | :-------------------------------: | :------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Flow**         | Structured workflow orchestration | • Manages execution paths<br />• Handles state transitions<br />• Controls task sequencing<br />• Ensures reliable execution                                         |
| **Events**       |   Triggers for workflow actions   | • Initiate specific processes<br />• Enable dynamic responses<br />• Support conditional branching<br />• Allow for real-time adaptation                             |
| **States**       |    Workflow execution contexts    | • Maintain execution data<br />• Enable persistence<br />• Support resumability<br />• Ensure execution integrity                                                    |
| **Crew Support** |    Enhances workflow automation   | • Injects pockets of agency when needed<br />• Complements structured workflows<br />• Balances automation with intelligence<br />• Enables adaptive decision-making |

### Key Capabilities

<CardGroup cols={2}>
  <Card title="Event-Driven Orchestration" icon="bolt">
    Define precise execution paths responding dynamically to events
  </Card>

  <Card title="Fine-Grained Control" icon="sliders">
    Manage workflow states and conditional execution securely and efficiently
  </Card>

  <Card title="Native Crew Integration" icon="puzzle-piece">
    Effortlessly combine with Crews for enhanced autonomy and intelligence
  </Card>

  <Card title="Deterministic Execution" icon="route">
    Ensure predictable outcomes with explicit control flow and error handling
  </Card>
</CardGroup>

## When to Use Crews vs. Flows

<Note>
  Understanding when to use [Crews](/en/guides/crews/first-crew) versus [Flows](/en/guides/flows/first-flow) is key to maximizing the potential of CrewAI in your applications.
</Note>

| Use Case                | Recommended Approach                 | Why?                                                                                                                                        |
| :---------------------- | :----------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------ |
| **Open-ended research** | [Crews](/en/guides/crews/first-crew) | When tasks require creative thinking, exploration, and adaptation                                                                           |
| **Content generation**  | [Crews](/en/guides/crews/first-crew) | For collaborative creation of articles, reports, or marketing materials                                                                     |
| **Decision workflows**  | [Flows](/en/guides/flows/first-flow) | When you need predictable, auditable decision paths with precise control                                                                    |
| **API orchestration**   | [Flows](/en/guides/flows/first-flow) | For reliable integration with multiple external services in a specific sequence                                                             |
| **Hybrid applications** | Combined approach                    | Use [Flows](/en/guides/flows/first-flow) to orchestrate overall process with [Crews](/en/guides/crews/first-crew) handling complex subtasks |

### Decision Framework

* **Choose [Crews](/en/guides/crews/first-crew) when:** You need autonomous problem-solving, creative collaboration, or exploratory tasks
* **Choose [Flows](/en/guides/flows/first-flow) when:** You require deterministic outcomes, auditability, or precise control over execution
* **Combine both when:** Your application needs both structured processes and pockets of autonomous intelligence

## Why Choose CrewAI?

* 🧠 **Autonomous Operation**: Agents make intelligent decisions based on their roles and available tools
* 📝 **Natural Interaction**: Agents communicate and collaborate like human team members
* 🛠️ **Extensible Design**: Easy to add new tools, roles, and capabilities
* 🚀 **Production Ready**: Built for reliability and scalability in real-world applications
* 🔒 **Security-Focused**: Designed with enterprise security requirements in mind
* 💰 **Cost-Efficient**: Optimized to minimize token usage and API calls

## Ready to Start Building?

<CardGroup cols={2}>
  <Card title="Build Your First Crew" icon="users-gear" href="/en/guides/crews/first-crew">
    Step-by-step tutorial to create a collaborative AI team that works together to solve complex problems.
  </Card>

  <Card title="Build Your First Flow" icon="diagram-project" href="/en/guides/flows/first-flow">
    Learn how to create structured, event-driven workflows with precise control over execution.
  </Card>
</CardGroup>

<CardGroup cols={3}>
  <Card title="Install CrewAI" icon="wrench" href="/en/installation">
    Get started with CrewAI in your development environment.
  </Card>

  <Card title="Quick Start" icon="bolt" href="en/quickstart">
    Follow our quickstart guide to create your first CrewAI agent and get hands-on experience.
  </Card>

  <Card title="Join the Community" icon="comments" href="https://community.crewai.com">
    Connect with other developers, get help, and share your CrewAI experiences.
  </Card>
</CardGroup>


# Before and After Kickoff Hooks
Source: https://docs.crewai.com/en/learn/before-and-after-kickoff-hooks

Learn how to use before and after kickoff hooks in CrewAI

CrewAI provides hooks that allow you to execute code before and after a crew's kickoff. These hooks are useful for preprocessing inputs or post-processing results.

## Before Kickoff Hook

The before kickoff hook is executed before the crew starts its tasks. It receives the input dictionary and can modify it before passing it to the crew. You can use this hook to set up your environment, load necessary data, or preprocess your inputs. This is useful in scenarios where the input data might need enrichment or validation before being processed by the crew.

Here's an example of defining a before kickoff function in your `crew.py`:

```python
from crewai import CrewBase
from crewai.project import before_kickoff

@CrewBase
class MyCrew:
    @before_kickoff
    def prepare_data(self, inputs):
        # Preprocess or modify inputs
        inputs['processed'] = True
        return inputs

#...
```

In this example, the prepare\_data function modifies the inputs by adding a new key-value pair indicating that the inputs have been processed.

## After Kickoff Hook

The after kickoff hook is executed after the crew has completed its tasks. It receives the result object, which contains the outputs of the crew's execution. This hook is ideal for post-processing results, such as logging, data transformation, or further analysis.

Here's how you can define an after kickoff function in your `crew.py`:

```python
from crewai import CrewBase
from crewai.project import after_kickoff

@CrewBase
class MyCrew:
    @after_kickoff
    def log_results(self, result):
        # Log or modify the results
        print("Crew execution completed with result:", result)
        return result

# ...
```

In the `log_results` function, the results of the crew execution are simply printed out. You can extend this to perform more complex operations such as sending notifications or integrating with other services.

## Utilizing Both Hooks

Both hooks can be used together to provide a comprehensive setup and teardown process for your crew's execution. They are particularly useful in maintaining clean code architecture by separating concerns and enhancing the modularity of your CrewAI implementations.

## Conclusion

Before and after kickoff hooks in CrewAI offer powerful ways to interact with the lifecycle of a crew's execution. By understanding and utilizing these hooks, you can greatly enhance the robustness and flexibility of your AI agents.


# Bring your own agent
Source: https://docs.crewai.com/en/learn/bring-your-own-agent

Learn how to bring your own agents that work within a Crew.

Interoperability is a core concept in CrewAI. This guide will show you how to bring your own agents that work within a Crew.

## Adapter Guide for Bringing your own agents (Langgraph Agents, OpenAI Agents, etc...)

We require 3 adapters to turn any agent from different frameworks to work within crew.

1. BaseAgentAdapter
2. BaseToolAdapter
3. BaseConverter

## BaseAgentAdapter

This abstract class defines the common interface and functionality that all
agent adapters must implement. It extends BaseAgent to maintain compatibility
with the CrewAI framework while adding adapter-specific requirements.

Required Methods:

1. `def configure_tools`
2. `def configure_structured_output`

## Creating your own Adapter

To integrate an agent from a different framework (e.g., LangGraph, Autogen, OpenAI Assistants) into CrewAI, you need to create a custom adapter by inheriting from `BaseAgentAdapter`. This adapter acts as a compatibility layer, translating between the CrewAI interfaces and the specific requirements of your external agent.

Here's how you implement your custom adapter:

1. **Inherit from `BaseAgentAdapter`**:
   ```python
   from crewai.agents.agent_adapters.base_agent_adapter import BaseAgentAdapter
   from crewai.tools import BaseTool
   from typing import List, Optional, Any, Dict

   class MyCustomAgentAdapter(BaseAgentAdapter):
       # ... implementation details ...
   ```

2. **Implement `__init__`**:
   The constructor should call the parent class constructor `super().__init__(**kwargs)` and perform any initialization specific to your external agent. You can use the optional `agent_config` dictionary passed during CrewAI's `Agent` initialization to configure your adapter and the underlying agent.

   ```python
   def __init__(self, agent_config: Optional[Dict[str, Any]] = None, **kwargs: Any):
       super().__init__(agent_config=agent_config, **kwargs)
       # Initialize your external agent here, possibly using agent_config
       # Example: self.external_agent = initialize_my_agent(agent_config)
       print(f"Initializing MyCustomAgentAdapter with config: {agent_config}")
   ```

3. **Implement `configure_tools`**:
   This abstract method is crucial. It receives a list of CrewAI `BaseTool` instances. Your implementation must convert or adapt these tools into the format expected by your external agent framework. This might involve wrapping them, extracting specific attributes, or registering them with the external agent instance.

   ```python
   def configure_tools(self, tools: Optional[List[BaseTool]] = None) -> None:
       if tools:
           adapted_tools = []
           for tool in tools:
               # Adapt CrewAI BaseTool to the format your agent expects
               # Example: adapted_tool = adapt_to_my_framework(tool)
               # adapted_tools.append(adapted_tool)
               pass # Replace with your actual adaptation logic

           # Configure the external agent with the adapted tools
           # Example: self.external_agent.set_tools(adapted_tools)
           print(f"Configuring tools for MyCustomAgentAdapter: {adapted_tools}") # Placeholder
       else:
           # Handle the case where no tools are provided
           # Example: self.external_agent.set_tools([])
           print("No tools provided for MyCustomAgentAdapter.")
   ```

4. **Implement `configure_structured_output`**:
   This method is called when the CrewAI `Agent` is configured with structured output requirements (e.g., `output_json` or `output_pydantic`). Your adapter needs to ensure the external agent is set up to comply with these requirements. This might involve setting specific parameters on the external agent or ensuring its underlying model supports the requested format. If the external agent doesn't support structured output in a way compatible with CrewAI's expectations, you might need to handle the conversion or raise an appropriate error.

   ```python
   def configure_structured_output(self, structured_output: Any) -> None:
       # Configure your external agent to produce output in the specified format
       # Example: self.external_agent.set_output_format(structured_output)
       self.adapted_structured_output = True # Signal that structured output is handled
       print(f"Configuring structured output for MyCustomAgentAdapter: {structured_output}")
   ```

By implementing these methods, your `MyCustomAgentAdapter` will allow your custom agent implementation to function correctly within a CrewAI crew, interacting with tasks and tools seamlessly. Remember to replace the example comments and print statements with your actual adaptation logic specific to the external agent framework you are integrating.

## BaseToolAdapter implementation

The `BaseToolAdapter` class is responsible for converting CrewAI's native `BaseTool` objects into a format that your specific external agent framework can understand and utilize. Different agent frameworks (like LangGraph, OpenAI Assistants, etc.) have their own unique ways of defining and handling tools, and the `BaseToolAdapter` acts as the translator.

Here's how you implement your custom tool adapter:

1. **Inherit from `BaseToolAdapter`**:
   ```python
   from crewai.agents.agent_adapters.base_tool_adapter import BaseToolAdapter
   from crewai.tools import BaseTool
   from typing import List, Any

   class MyCustomToolAdapter(BaseToolAdapter):
       # ... implementation details ...
   ```

2. **Implement `configure_tools`**:
   This is the core abstract method you must implement. It receives a list of CrewAI `BaseTool` instances provided to the agent. Your task is to iterate through this list, adapt each `BaseTool` into the format expected by your external framework, and store the converted tools in the `self.converted_tools` list (which is initialized in the base class constructor).

   ```python
   def configure_tools(self, tools: List[BaseTool]) -> None:
       """Configure and convert CrewAI tools for the specific implementation."""
       self.converted_tools = [] # Reset in case it's called multiple times
       for tool in tools:
           # Sanitize the tool name if required by the target framework
           sanitized_name = self.sanitize_tool_name(tool.name)

           # --- Your Conversion Logic Goes Here ---
           # Example: Convert BaseTool to a dictionary format for LangGraph
           # converted_tool = {
           #     "name": sanitized_name,
           #     "description": tool.description,
           #     "parameters": tool.args_schema.schema() if tool.args_schema else {},
           #     # Add any other framework-specific fields
           # }

           # Example: Convert BaseTool to an OpenAI function definition
           # converted_tool = {
           #     "type": "function",
           #     "function": {
           #         "name": sanitized_name,
           #         "description": tool.description,
           #         "parameters": tool.args_schema.schema() if tool.args_schema else {"type": "object", "properties": {}},
           #     }
           # }

           # --- Replace above examples with your actual adaptation ---
           converted_tool = self.adapt_tool_to_my_framework(tool, sanitized_name) # Placeholder

           self.converted_tools.append(converted_tool)
           print(f"Adapted tool '{tool.name}' to '{sanitized_name}' for MyCustomToolAdapter") # Placeholder

       print(f"MyCustomToolAdapter finished configuring tools: {len(self.converted_tools)} adapted.") # Placeholder

   # --- Helper method for adaptation (Example) ---
   def adapt_tool_to_my_framework(self, tool: BaseTool, sanitized_name: str) -> Any:
       # Replace this with the actual logic to convert a CrewAI BaseTool
       # to the format needed by your specific external agent framework.
       # This will vary greatly depending on the target framework.
       adapted_representation = {
           "framework_specific_name": sanitized_name,
           "framework_specific_description": tool.description,
           "inputs": tool.args_schema.schema() if tool.args_schema else None,
           "implementation_reference": tool.run # Or however the framework needs to call it
       }
       # Also ensure the tool works both sync and async
       async def async_tool_wrapper(*args, **kwargs):
           output = tool.run(*args, **kwargs)
           if inspect.isawaitable(output):
               return await output
           else:
               return output

       adapted_tool = MyFrameworkTool(
           name=sanitized_name,
           description=tool.description,
           inputs=tool.args_schema.schema() if tool.args_schema else None,
           implementation_reference=async_tool_wrapper
       )

       return adapted_representation

   ```

3. **Using the Adapter**:
   Typically, you would instantiate your `MyCustomToolAdapter` within your `MyCustomAgentAdapter`'s `configure_tools` method and use it to process the tools before configuring your external agent.

   ```python
   # Inside MyCustomAgentAdapter.configure_tools
   def configure_tools(self, tools: Optional[List[BaseTool]] = None) -> None:
       if tools:
           tool_adapter = MyCustomToolAdapter() # Instantiate your tool adapter
           tool_adapter.configure_tools(tools)  # Convert the tools
           adapted_tools = tool_adapter.tools() # Get the converted tools

           # Now configure your external agent with the adapted_tools
           # Example: self.external_agent.set_tools(adapted_tools)
           print(f"Configuring external agent with adapted tools: {adapted_tools}") # Placeholder
       else:
           # Handle no tools case
           print("No tools provided for MyCustomAgentAdapter.")
   ```

By creating a `BaseToolAdapter`, you decouple the tool conversion logic from the agent adaptation, making the integration cleaner and more modular. Remember to replace the placeholder examples with the actual conversion logic required by your specific external agent framework.

## BaseConverter

The `BaseConverterAdapter` plays a crucial role when a CrewAI `Task` requires an agent to return its final output in a specific structured format, such as JSON or a Pydantic model. It bridges the gap between CrewAI's structured output requirements and the capabilities of your external agent.

Its primary responsibilities are:

1. **Configuring the Agent for Structured Output:** Based on the `Task`'s requirements (`output_json` or `output_pydantic`), it instructs the associated `BaseAgentAdapter` (and indirectly, the external agent) on what format is expected.
2. **Enhancing the System Prompt:** It modifies the agent's system prompt to include clear instructions on *how* to generate the output in the required structure.
3. **Post-processing the Result:** It takes the raw output from the agent and attempts to parse, validate, and format it according to the required structure, ultimately returning a string representation (e.g., a JSON string).

Here's how you implement your custom converter adapter:

1. **Inherit from `BaseConverterAdapter`**:
   ```python
   from crewai.agents.agent_adapters.base_converter_adapter import BaseConverterAdapter
   # Assuming you have your MyCustomAgentAdapter defined
   # from .my_custom_agent_adapter import MyCustomAgentAdapter
   from crewai.task import Task
   from typing import Any

   class MyCustomConverterAdapter(BaseConverterAdapter):
       # Store the expected output type (e.g., 'json', 'pydantic', 'text')
       _output_type: str = 'text'
       _output_schema: Any = None # Store JSON schema or Pydantic model

       # ... implementation details ...
   ```

2. **Implement `__init__`**:
   The constructor must accept the corresponding `agent_adapter` instance it will work with.

   ```python
   def __init__(self, agent_adapter: Any): # Use your specific AgentAdapter type hint
       self.agent_adapter = agent_adapter
       print(f"Initializing MyCustomConverterAdapter for agent adapter: {type(agent_adapter).__name__}")
   ```

3. **Implement `configure_structured_output`**:
   This method receives the CrewAI `Task` object. You need to check the task's `output_json` and `output_pydantic` attributes to determine the required output structure. Store this information (e.g., in `_output_type` and `_output_schema`) and potentially call configuration methods on your `self.agent_adapter` if the external agent needs specific setup for structured output (which might have been partially handled in the agent adapter's `configure_structured_output` already).

   ```python
   def configure_structured_output(self, task: Task) -> None:
       """Configure the expected structured output based on the task."""
       if task.output_pydantic:
           self._output_type = 'pydantic'
           self._output_schema = task.output_pydantic
           print(f"Converter: Configured for Pydantic output: {self._output_schema.__name__}")
       elif task.output_json:
           self._output_type = 'json'
           self._output_schema = task.output_json
           print(f"Converter: Configured for JSON output with schema: {self._output_schema}")
       else:
           self._output_type = 'text'
           self._output_schema = None
           print("Converter: Configured for standard text output.")

       # Optionally, inform the agent adapter if needed
       # self.agent_adapter.set_output_mode(self._output_type, self._output_schema)
   ```

4. **Implement `enhance_system_prompt`**:
   This method takes the agent's base system prompt string and should append instructions tailored to the currently configured `_output_type` and `_output_schema`. The goal is to guide the LLM powering the agent to produce output in the correct format.

   ````python
   def enhance_system_prompt(self, base_prompt: str) -> str:
       """Enhance the system prompt with structured output instructions."""
       if self._output_type == 'text':
           return base_prompt # No enhancement needed for plain text

       instructions = "\n\nYour final answer MUST be formatted as "
       if self._output_type == 'json':
           schema_str = json.dumps(self._output_schema, indent=2)
           instructions += f"a JSON object conforming to the following schema:\n```json\n{schema_str}\n```"
       elif self._output_type == 'pydantic':
           schema_str = json.dumps(self._output_schema.model_json_schema(), indent=2)
           instructions += f"a JSON object conforming to the Pydantic model '{self._output_schema.__name__}' with the following schema:\n```json\n{schema_str}\n```"

       instructions += "\nEnsure your entire response is ONLY the valid JSON object, without any introductory text, explanations, or concluding remarks."

       print(f"Converter: Enhancing prompt for {self._output_type} output.")
       return base_prompt + instructions
   ````

   *Note: The exact prompt engineering might need tuning based on the agent/LLM being used.*

5. **Implement `post_process_result`**:
   This method receives the raw string output from the agent. If structured output was requested (`json` or `pydantic`), you should attempt to parse the string into the expected format. Handle potential parsing errors (e.g., log them, attempt simple fixes, or raise an exception). Crucially, the method must **always return a string**, even if the intermediate format was a dictionary or Pydantic object (e.g., by serializing it back to a JSON string).

   ```python
   import json
   from pydantic import ValidationError

   def post_process_result(self, result: str) -> str:
       """Post-process the agent's result to ensure it matches the expected format."""
       print(f"Converter: Post-processing result for {self._output_type} output.")
       if self._output_type == 'json':
           try:
               # Attempt to parse and re-serialize to ensure validity and consistent format
               parsed_json = json.loads(result)
               # Optional: Validate against self._output_schema if it's a JSON schema dictionary
               # from jsonschema import validate
               # validate(instance=parsed_json, schema=self._output_schema)
               return json.dumps(parsed_json)
           except json.JSONDecodeError as e:
               print(f"Error: Failed to parse JSON output: {e}\nRaw output:\n{result}")
               # Handle error: return raw, raise exception, or try to fix
               return result # Example: return raw output on failure
           # except Exception as e: # Catch validation errors if using jsonschema
           #     print(f"Error: JSON output failed schema validation: {e}\nRaw output:\n{result}")
           #     return result
       elif self._output_type == 'pydantic':
           try:
               # Attempt to parse into the Pydantic model
               model_instance = self._output_schema.model_validate_json(result)
               # Return the model serialized back to JSON
               return model_instance.model_dump_json()
           except ValidationError as e:
               print(f"Error: Failed to validate Pydantic output: {e}\nRaw output:\n{result}")
               # Handle error
               return result # Example: return raw output on failure
           except json.JSONDecodeError as e:
                print(f"Error: Failed to parse JSON for Pydantic model: {e}\nRaw output:\n{result}")
                return result
       else: # 'text'
           return result # No processing needed for plain text
   ```

By implementing these methods, your `MyCustomConverterAdapter` ensures that structured output requests from CrewAI tasks are correctly handled by your integrated external agent, improving the reliability and usability of your custom agent within the CrewAI framework.

## Out of the Box Adapters

We provide out of the box adapters for the following frameworks:

1. LangGraph
2. OpenAI Agents

## Kicking off a crew with adapted agents:

```python
import json
import os
from typing import List

from crewai_tools import SerperDevTool
from src.crewai import Agent, Crew, Task
from langchain_openai import ChatOpenAI
from pydantic import BaseModel

from crewai.agents.agent_adapters.langgraph.langgraph_adapter import (
    LangGraphAgentAdapter,
)
from crewai.agents.agent_adapters.openai_agents.openai_adapter import OpenAIAgentAdapter

# CrewAI Agent
code_helper_agent = Agent(
    role="Code Helper",
    goal="Help users solve coding problems effectively and provide clear explanations.",
    backstory="You are an experienced programmer with deep knowledge across multiple programming languages and frameworks. You specialize in solving complex coding challenges and explaining solutions clearly.",
    allow_delegation=False,
    verbose=True,
)
# OpenAI Agent Adapter
link_finder_agent = OpenAIAgentAdapter(
    role="Link Finder",
    goal="Find the most relevant and high-quality resources for coding tasks.",
    backstory="You are a research specialist with a talent for finding the most helpful resources. You're skilled at using search tools to discover documentation, tutorials, and examples that directly address the user's coding needs.",
    tools=[SerperDevTool()],
    allow_delegation=False,
    verbose=True,
)

# LangGraph Agent Adapter
reporter_agent = LangGraphAgentAdapter(
    role="Reporter",
    goal="Report the results of the tasks.",
    backstory="You are a reporter who reports the results of the other tasks",
    llm=ChatOpenAI(model="gpt-4o"),
    allow_delegation=True,
    verbose=True,
)


class Code(BaseModel):
    code: str


task = Task(
    description="Give an answer to the coding question: {task}",
    expected_output="A thorough answer to the coding question: {task}",
    agent=code_helper_agent,
    output_json=Code,
)
task2 = Task(
    description="Find links to resources that can help with coding tasks. Use the serper tool to find resources that can help.",
    expected_output="A list of links to resources that can help with coding tasks",
    agent=link_finder_agent,
)


class Report(BaseModel):
    code: str
    links: List[str]


task3 = Task(
    description="Report the results of the tasks.",
    expected_output="A report of the results of the tasks. this is the code produced and then the links to the resources that can help with the coding task.",
    agent=reporter_agent,
    output_json=Report,
)
# Use in CrewAI
crew = Crew(
    agents=[code_helper_agent, link_finder_agent, reporter_agent],
    tasks=[task, task2, task3],
    verbose=True,
)

result = crew.kickoff(
    inputs={"task": "How do you implement an abstract class in python?"}
)

# Print raw result first
print("Raw result:", result)

# Handle result based on its type
if hasattr(result, "json_dict") and result.json_dict:
    json_result = result.json_dict
    print("\nStructured JSON result:")
    print(f"{json.dumps(json_result, indent=2)}")

    # Access fields safely
    if isinstance(json_result, dict):
        if "code" in json_result:
            print("\nCode:")
            print(
                json_result["code"][:200] + "..."
                if len(json_result["code"]) > 200
                else json_result["code"]
            )

        if "links" in json_result:
            print("\nLinks:")
            for link in json_result["links"][:5]:  # Print first 5 links
                print(f"- {link}")
            if len(json_result["links"]) > 5:
                print(f"...and {len(json_result['links']) - 5} more links")
elif hasattr(result, "pydantic") and result.pydantic:
    print("\nPydantic model result:")
    print(result.pydantic.model_dump_json(indent=2))
else:
    # Fallback to raw output
    print("\nNo structured result available, using raw output:")
    print(result.raw[:500] + "..." if len(result.raw) > 500 else result.raw)

```


# Coding Agents
Source: https://docs.crewai.com/en/learn/coding-agents

Learn how to enable your CrewAI Agents to write and execute code, and explore advanced features for enhanced functionality.

## Introduction

CrewAI Agents now have the powerful ability to write and execute code, significantly enhancing their problem-solving capabilities. This feature is particularly useful for tasks that require computational or programmatic solutions.

## Enabling Code Execution

To enable code execution for an agent, set the `allow_code_execution` parameter to `True` when creating the agent.

Here's an example:

```python Code
from crewai import Agent

coding_agent = Agent(
    role="Senior Python Developer",
    goal="Craft well-designed and thought-out code",
    backstory="You are a senior Python developer with extensive experience in software architecture and best practices.",
    allow_code_execution=True
)
```

<Note>
  Note that `allow_code_execution` parameter defaults to `False`.
</Note>

## Important Considerations

1. **Model Selection**: It is strongly recommended to use more capable models like Claude 3.5 Sonnet and GPT-4 when enabling code execution.
   These models have a better understanding of programming concepts and are more likely to generate correct and efficient code.

2. **Error Handling**: The code execution feature includes error handling. If executed code raises an exception, the agent will receive the error message and can attempt to correct the code or
   provide alternative solutions. The `max_retry_limit` parameter, which defaults to 2, controls the maximum number of retries for a task.

3. **Dependencies**: To use the code execution feature, you need to install the `crewai_tools` package. If not installed, the agent will log an info message:
   "Coding tools not available. Install crewai\_tools."

## Code Execution Process

When an agent with code execution enabled encounters a task requiring programming:

<Steps>
  <Step title="Task Analysis">
    The agent analyzes the task and determines that code execution is necessary.
  </Step>

  <Step title="Code Formulation">
    It formulates the Python code needed to solve the problem.
  </Step>

  <Step title="Code Execution">
    The code is sent to the internal code execution tool (`CodeInterpreterTool`).
  </Step>

  <Step title="Result Interpretation">
    The agent interprets the result and incorporates it into its response or uses it for further problem-solving.
  </Step>
</Steps>

## Example Usage

Here's a detailed example of creating an agent with code execution capabilities and using it in a task:

```python Code
from crewai import Agent, Task, Crew

# Create an agent with code execution enabled
coding_agent = Agent(
    role="Python Data Analyst",
    goal="Analyze data and provide insights using Python",
    backstory="You are an experienced data analyst with strong Python skills.",
    allow_code_execution=True
)

# Create a task that requires code execution
data_analysis_task = Task(
    description="Analyze the given dataset and calculate the average age of participants.",
    agent=coding_agent
)

# Create a crew and add the task
analysis_crew = Crew(
    agents=[coding_agent],
    tasks=[data_analysis_task]
)

# Execute the crew
result = analysis_crew.kickoff()

print(result)
```

In this example, the `coding_agent` can write and execute Python code to perform data analysis tasks.


# Conditional Tasks
Source: https://docs.crewai.com/en/learn/conditional-tasks

Learn how to use conditional tasks in a crewAI kickoff

## Introduction

Conditional Tasks in crewAI allow for dynamic workflow adaptation based on the outcomes of previous tasks.
This powerful feature enables crews to make decisions and execute tasks selectively, enhancing the flexibility and efficiency of your AI-driven processes.

## Example Usage

```python Code
from typing import List
from pydantic import BaseModel
from crewai import Agent, Crew
from crewai.tasks.conditional_task import ConditionalTask
from crewai.tasks.task_output import TaskOutput
from crewai.task import Task
from crewai_tools import SerperDevTool

# Define a condition function for the conditional task
# If false, the task will be skipped, if true, then execute the task.
def is_data_missing(output: TaskOutput) -> bool:
    return len(output.pydantic.events) < 10  # this will skip this task

# Define the agents
data_fetcher_agent = Agent(
    role="Data Fetcher",
    goal="Fetch data online using Serper tool",
    backstory="Backstory 1",
    verbose=True,
    tools=[SerperDevTool()]
)

data_processor_agent = Agent(
    role="Data Processor",
    goal="Process fetched data",
    backstory="Backstory 2",
    verbose=True
)

summary_generator_agent = Agent(
    role="Summary Generator",
    goal="Generate summary from fetched data",
    backstory="Backstory 3",
    verbose=True
)

class EventOutput(BaseModel):
    events: List[str]

task1 = Task(
    description="Fetch data about events in San Francisco using Serper tool",
    expected_output="List of 10 things to do in SF this week",
    agent=data_fetcher_agent,
    output_pydantic=EventOutput,
)

conditional_task = ConditionalTask(
    description="""
        Check if data is missing. If we have less than 10 events,
        fetch more events using Serper tool so that
        we have a total of 10 events in SF this week..
        """,
    expected_output="List of 10 Things to do in SF this week",
    condition=is_data_missing,
    agent=data_processor_agent,
)

task3 = Task(
    description="Generate summary of events in San Francisco from fetched data",
    expected_output="A complete report on the customer and their customers and competitors, including their demographics, preferences, market positioning and audience engagement.",
    agent=summary_generator_agent,
)

# Create a crew with the tasks
crew = Crew(
    agents=[data_fetcher_agent, data_processor_agent, summary_generator_agent],
    tasks=[task1, conditional_task, task3],
    verbose=True,
    planning=True
)

# Run the crew
result = crew.kickoff()
print("results", result)
```


# Create Custom Tools
Source: https://docs.crewai.com/en/learn/create-custom-tools

Comprehensive guide on crafting, using, and managing custom tools within the CrewAI framework, including new functionalities and error handling.

## Creating and Utilizing Tools in CrewAI

This guide provides detailed instructions on creating custom tools for the CrewAI framework and how to efficiently manage and utilize these tools,
incorporating the latest functionalities such as tool delegation, error handling, and dynamic tool calling. It also highlights the importance of collaboration tools,
enabling agents to perform a wide range of actions.

### Subclassing `BaseTool`

To create a personalized tool, inherit from `BaseTool` and define the necessary attributes, including the `args_schema` for input validation, and the `_run` method.

```python Code
from typing import Type
from crewai.tools import BaseTool
from pydantic import BaseModel, Field

class MyToolInput(BaseModel):
    """Input schema for MyCustomTool."""
    argument: str = Field(..., description="Description of the argument.")

class MyCustomTool(BaseTool):
    name: str = "Name of my tool"
    description: str = "What this tool does. It's vital for effective utilization."
    args_schema: Type[BaseModel] = MyToolInput

    def _run(self, argument: str) -> str:
        # Your tool's logic here
        return "Tool's result"
```

### Using the `tool` Decorator

Alternatively, you can use the tool decorator `@tool`. This approach allows you to define the tool's attributes and functionality directly within a function,
offering a concise and efficient way to create specialized tools tailored to your needs.

```python Code
from crewai.tools import tool

@tool("Tool Name")
def my_simple_tool(question: str) -> str:
    """Tool description for clarity."""
    # Tool logic here
    return "Tool output"
```

### Defining a Cache Function for the Tool

To optimize tool performance with caching, define custom caching strategies using the `cache_function` attribute.

```python Code
@tool("Tool with Caching")
def cached_tool(argument: str) -> str:
    """Tool functionality description."""
    return "Cacheable result"

def my_cache_strategy(arguments: dict, result: str) -> bool:
    # Define custom caching logic
    return True if some_condition else False

cached_tool.cache_function = my_cache_strategy
```

By adhering to these guidelines and incorporating new functionalities and collaboration tools into your tool creation and management processes,
you can leverage the full capabilities of the CrewAI framework, enhancing both the development experience and the efficiency of your AI agents.


# Custom LLM Implementation
Source: https://docs.crewai.com/en/learn/custom-llm

Learn how to create custom LLM implementations in CrewAI.

## Overview

CrewAI supports custom LLM implementations through the `BaseLLM` abstract base class. This allows you to integrate any LLM provider that doesn't have built-in support in LiteLLM, or implement custom authentication mechanisms.

## Quick Start

Here's a minimal custom LLM implementation:

```python
from crewai import BaseLLM
from typing import Any, Dict, List, Optional, Union
import requests

class CustomLLM(BaseLLM):
    def __init__(self, model: str, api_key: str, endpoint: str, temperature: Optional[float] = None):
        # IMPORTANT: Call super().__init__() with required parameters
        super().__init__(model=model, temperature=temperature)

        self.api_key = api_key
        self.endpoint = endpoint

    def call(
        self,
        messages: Union[str, List[Dict[str, str]]],
        tools: Optional[List[dict]] = None,
        callbacks: Optional[List[Any]] = None,
        available_functions: Optional[Dict[str, Any]] = None,
    ) -> Union[str, Any]:
        """Call the LLM with the given messages."""
        # Convert string to message format if needed
        if isinstance(messages, str):
            messages = [{"role": "user", "content": messages}]

        # Prepare request
        payload = {
            "model": self.model,
            "messages": messages,
            "temperature": self.temperature,
        }

        # Add tools if provided and supported
        if tools and self.supports_function_calling():
            payload["tools"] = tools

        # Make API call
        response = requests.post(
            self.endpoint,
            headers={
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            },
            json=payload,
            timeout=30
        )
        response.raise_for_status()

        result = response.json()
        return result["choices"][0]["message"]["content"]

    def supports_function_calling(self) -> bool:
        """Override if your LLM supports function calling."""
        return True  # Change to False if your LLM doesn't support tools

    def get_context_window_size(self) -> int:
        """Return the context window size of your LLM."""
        return 8192  # Adjust based on your model's actual context window
```

## Using Your Custom LLM

```python
from crewai import Agent, Task, Crew

# Assuming you have the CustomLLM class defined above
# Create your custom LLM
custom_llm = CustomLLM(
    model="my-custom-model",
    api_key="your-api-key",
    endpoint="https://api.example.com/v1/chat/completions",
    temperature=0.7
)

# Use with an agent
agent = Agent(
    role="Research Assistant",
    goal="Find and analyze information",
    backstory="You are a research assistant.",
    llm=custom_llm
)

# Create and execute tasks
task = Task(
    description="Research the latest developments in AI",
    expected_output="A comprehensive summary",
    agent=agent
)

crew = Crew(agents=[agent], tasks=[task])
result = crew.kickoff()
```

## Required Methods

### Constructor: `__init__()`

**Critical**: You must call `super().__init__(model, temperature)` with the required parameters:

```python
def __init__(self, model: str, api_key: str, temperature: Optional[float] = None):
    # REQUIRED: Call parent constructor with model and temperature
    super().__init__(model=model, temperature=temperature)

    # Your custom initialization
    self.api_key = api_key
```

### Abstract Method: `call()`

The `call()` method is the heart of your LLM implementation. It must:

* Accept messages (string or list of dicts with 'role' and 'content')
* Return a string response
* Handle tools and function calling if supported
* Raise appropriate exceptions for errors

### Optional Methods

```python
def supports_function_calling(self) -> bool:
    """Return True if your LLM supports function calling."""
    return True  # Default is True

def supports_stop_words(self) -> bool:
    """Return True if your LLM supports stop sequences."""
    return True  # Default is True

def get_context_window_size(self) -> int:
    """Return the context window size."""
    return 4096  # Default is 4096
```

## Common Patterns

### Error Handling

```python
import requests

def call(self, messages, tools=None, callbacks=None, available_functions=None):
    try:
        response = requests.post(
            self.endpoint,
            headers={"Authorization": f"Bearer {self.api_key}"},
            json=payload,
            timeout=30
        )
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]

    except requests.Timeout:
        raise TimeoutError("LLM request timed out")
    except requests.RequestException as e:
        raise RuntimeError(f"LLM request failed: {str(e)}")
    except (KeyError, IndexError) as e:
        raise ValueError(f"Invalid response format: {str(e)}")
```

### Custom Authentication

```python
from crewai import BaseLLM
from typing import Optional

class CustomAuthLLM(BaseLLM):
    def __init__(self, model: str, auth_token: str, endpoint: str, temperature: Optional[float] = None):
        super().__init__(model=model, temperature=temperature)
        self.auth_token = auth_token
        self.endpoint = endpoint

    def call(self, messages, tools=None, callbacks=None, available_functions=None):
        headers = {
            "Authorization": f"Custom {self.auth_token}",  # Custom auth format
            "Content-Type": "application/json"
        }
        # Rest of implementation...
```

### Stop Words Support

CrewAI automatically adds `"\nObservation:"` as a stop word to control agent behavior. If your LLM supports stop words:

```python
def call(self, messages, tools=None, callbacks=None, available_functions=None):
    payload = {
        "model": self.model,
        "messages": messages,
        "stop": self.stop  # Include stop words in API call
    }
    # Make API call...

def supports_stop_words(self) -> bool:
    return True  # Your LLM supports stop sequences
```

If your LLM doesn't support stop words natively:

```python
def call(self, messages, tools=None, callbacks=None, available_functions=None):
    response = self._make_api_call(messages, tools)
    content = response["choices"][0]["message"]["content"]

    # Manually truncate at stop words
    if self.stop:
        for stop_word in self.stop:
            if stop_word in content:
                content = content.split(stop_word)[0]
                break

    return content

def supports_stop_words(self) -> bool:
    return False  # Tell CrewAI we handle stop words manually
```

## Function Calling

If your LLM supports function calling, implement the complete flow:

```python
import json

def call(self, messages, tools=None, callbacks=None, available_functions=None):
    # Convert string to message format
    if isinstance(messages, str):
        messages = [{"role": "user", "content": messages}]

    # Make API call
    response = self._make_api_call(messages, tools)
    message = response["choices"][0]["message"]

    # Check for function calls
    if "tool_calls" in message and available_functions:
        return self._handle_function_calls(
            message["tool_calls"], messages, tools, available_functions
        )

    return message["content"]

def _handle_function_calls(self, tool_calls, messages, tools, available_functions):
    """Handle function calling with proper message flow."""
    for tool_call in tool_calls:
        function_name = tool_call["function"]["name"]

        if function_name in available_functions:
            # Parse and execute function
            function_args = json.loads(tool_call["function"]["arguments"])
            function_result = available_functions[function_name](**function_args)

            # Add function call and result to message history
            messages.append({
                "role": "assistant",
                "content": None,
                "tool_calls": [tool_call]
            })
            messages.append({
                "role": "tool",
                "tool_call_id": tool_call["id"],
                "name": function_name,
                "content": str(function_result)
            })

            # Call LLM again with updated context
            return self.call(messages, tools, None, available_functions)

    return "Function call failed"
```

## Troubleshooting

### Common Issues

**Constructor Errors**

```python
# ❌ Wrong - missing required parameters
def __init__(self, api_key: str):
    super().__init__()

# ✅ Correct
def __init__(self, model: str, api_key: str, temperature: Optional[float] = None):
    super().__init__(model=model, temperature=temperature)
```

**Function Calling Not Working**

* Ensure `supports_function_calling()` returns `True`
* Check that you handle `tool_calls` in the response
* Verify `available_functions` parameter is used correctly

**Authentication Failures**

* Verify API key format and permissions
* Check authentication header format
* Ensure endpoint URLs are correct

**Response Parsing Errors**

* Validate response structure before accessing nested fields
* Handle cases where content might be None
* Add proper error handling for malformed responses

## Testing Your Custom LLM

```python
from crewai import Agent, Task, Crew

def test_custom_llm():
    llm = CustomLLM(
        model="test-model",
        api_key="test-key",
        endpoint="https://api.test.com"
    )

    # Test basic call
    result = llm.call("Hello, world!")
    assert isinstance(result, str)
    assert len(result) > 0

    # Test with CrewAI agent
    agent = Agent(
        role="Test Agent",
        goal="Test custom LLM",
        backstory="A test agent.",
        llm=llm
    )

    task = Task(
        description="Say hello",
        expected_output="A greeting",
        agent=agent
    )

    crew = Crew(agents=[agent], tasks=[task])
    result = crew.kickoff()
    assert "hello" in result.raw.lower()
```

This guide covers the essentials of implementing custom LLMs in CrewAI.


# Custom Manager Agent
Source: https://docs.crewai.com/en/learn/custom-manager-agent

Learn how to set a custom agent as the manager in CrewAI, providing more control over task management and coordination.

# Setting a Specific Agent as Manager in CrewAI

CrewAI allows users to set a specific agent as the manager of the crew, providing more control over the management and coordination of tasks.
This feature enables the customization of the managerial role to better fit your project's requirements.

## Using the `manager_agent` Attribute

### Custom Manager Agent

The `manager_agent` attribute allows you to define a custom agent to manage the crew. This agent will oversee the entire process, ensuring that tasks are completed efficiently and to the highest standard.

### Example

```python Code
import os
from crewai import Agent, Task, Crew, Process

# Define your agents
researcher = Agent(
    role="Researcher",
    goal="Conduct thorough research and analysis on AI and AI agents",
    backstory="You're an expert researcher, specialized in technology, software engineering, AI, and startups. You work as a freelancer and are currently researching for a new client.",
    allow_delegation=False,
)

writer = Agent(
    role="Senior Writer",
    goal="Create compelling content about AI and AI agents",
    backstory="You're a senior writer, specialized in technology, software engineering, AI, and startups. You work as a freelancer and are currently writing content for a new client.",
    allow_delegation=False,
)

# Define your task
task = Task(
    description="Generate a list of 5 interesting ideas for an article, then write one captivating paragraph for each idea that showcases the potential of a full article on this topic. Return the list of ideas with their paragraphs and your notes.",
    expected_output="5 bullet points, each with a paragraph and accompanying notes.",
)

# Define the manager agent
manager = Agent(
    role="Project Manager",
    goal="Efficiently manage the crew and ensure high-quality task completion",
    backstory="You're an experienced project manager, skilled in overseeing complex projects and guiding teams to success. Your role is to coordinate the efforts of the crew members, ensuring that each task is completed on time and to the highest standard.",
    allow_delegation=True,
)

# Instantiate your crew with a custom manager
crew = Crew(
    agents=[researcher, writer],
    tasks=[task],
    manager_agent=manager,
    process=Process.hierarchical,
)

# Start the crew's work
result = crew.kickoff()
```

## Benefits of a Custom Manager Agent

* **Enhanced Control**: Tailor the management approach to fit the specific needs of your project.
* **Improved Coordination**: Ensure efficient task coordination and management by an experienced agent.
* **Customizable Management**: Define managerial roles and responsibilities that align with your project's goals.

## Setting a Manager LLM

If you're using the hierarchical process and don't want to set a custom manager agent, you can specify the language model for the manager:

```python Code
from crewai import LLM

manager_llm = LLM(model="gpt-4o")

crew = Crew(
    agents=[researcher, writer],
    tasks=[task],
    process=Process.hierarchical,
    manager_llm=manager_llm
)
```

<Note>
  Either `manager_agent` or `manager_llm` must be set when using the hierarchical process.
</Note>


# Customize Agents
Source: https://docs.crewai.com/en/learn/customizing-agents

A comprehensive guide to tailoring agents for specific roles, tasks, and advanced customizations within the CrewAI framework.

## Customizable Attributes

Crafting an efficient CrewAI team hinges on the ability to dynamically tailor your AI agents to meet the unique requirements of any project. This section covers the foundational attributes you can customize.

### Key Attributes for Customization

| Attribute                           | Description                                                                                                         |
| :---------------------------------- | :------------------------------------------------------------------------------------------------------------------ |
| **Role**                            | Specifies the agent's job within the crew, such as 'Analyst' or 'Customer Service Rep'.                             |
| **Goal**                            | Defines the agent’s objectives, aligned with its role and the crew’s overarching mission.                           |
| **Backstory**                       | Provides depth to the agent's persona, enhancing motivations and engagements within the crew.                       |
| **Tools** *(Optional)*              | Represents the capabilities or methods the agent uses for tasks, from simple functions to complex integrations.     |
| **Cache** *(Optional)*              | Determines if the agent should use a cache for tool usage.                                                          |
| **Max RPM**                         | Sets the maximum requests per minute (`max_rpm`). Can be set to `None` for unlimited requests to external services. |
| **Verbose** *(Optional)*            | Enables detailed logging for debugging and optimization, providing insights into execution processes.               |
| **Allow Delegation** *(Optional)*   | Controls task delegation to other agents, default is `False`.                                                       |
| **Max Iter** *(Optional)*           | Limits the maximum number of iterations (`max_iter`) for a task to prevent infinite loops, with a default of 25.    |
| **Max Execution Time** *(Optional)* | Sets the maximum time allowed for an agent to complete a task.                                                      |
| **System Template** *(Optional)*    | Defines the system format for the agent.                                                                            |
| **Prompt Template** *(Optional)*    | Defines the prompt format for the agent.                                                                            |
| **Response Template** *(Optional)*  | Defines the response format for the agent.                                                                          |
| **Use System Prompt** *(Optional)*  | Controls whether the agent will use a system prompt during task execution.                                          |
| **Respect Context Window**          | Enables a sliding context window by default, maintaining context size.                                              |
| **Max Retry Limit**                 | Sets the maximum number of retries (`max_retry_limit`) for an agent in case of errors.                              |

## Advanced Customization Options

Beyond the basic attributes, CrewAI allows for deeper customization to enhance an agent's behavior and capabilities significantly.

### Language Model Customization

Agents can be customized with specific language models (`llm`) and function-calling language models (`function_calling_llm`), offering advanced control over their processing and decision-making abilities.
It's important to note that setting the `function_calling_llm` allows for overriding the default crew function-calling language model, providing a greater degree of customization.

## Performance and Debugging Settings

Adjusting an agent's performance and monitoring its operations are crucial for efficient task execution.

### Verbose Mode and RPM Limit

* **Verbose Mode**: Enables detailed logging of an agent's actions, useful for debugging and optimization. Specifically, it provides insights into agent execution processes, aiding in the optimization of performance.
* **RPM Limit**: Sets the maximum number of requests per minute (`max_rpm`). This attribute is optional and can be set to `None` for no limit, allowing for unlimited queries to external services if needed.

### Maximum Iterations for Task Execution

The `max_iter` attribute allows users to define the maximum number of iterations an agent can perform for a single task, preventing infinite loops or excessively long executions.
The default value is set to 25, providing a balance between thoroughness and efficiency. Once the agent approaches this number, it will try its best to give a good answer.

## Customizing Agents and Tools

Agents are customized by defining their attributes and tools during initialization. Tools are critical for an agent's functionality, enabling them to perform specialized tasks.
The `tools` attribute should be an array of tools the agent can utilize, and it's initialized as an empty list by default. Tools can be added or modified post-agent initialization to adapt to new requirements.

```shell
pip install 'crewai[tools]'
```

### Example: Assigning Tools to an Agent

```python Code
import os
from crewai import Agent
from crewai_tools import SerperDevTool

# Set API keys for tool initialization
os.environ["OPENAI_API_KEY"] = "Your Key"
os.environ["SERPER_API_KEY"] = "Your Key"

# Initialize a search tool
search_tool = SerperDevTool()

# Initialize the agent with advanced options
agent = Agent(
  role='Research Analyst',
  goal='Provide up-to-date market analysis',
  backstory='An expert analyst with a keen eye for market trends.',
  tools=[search_tool],
  memory=True, # Enable memory
  verbose=True,
  max_rpm=None, # No limit on requests per minute
  max_iter=25, # Default value for maximum iterations
)
```

## Delegation and Autonomy

Controlling an agent's ability to delegate tasks or ask questions is vital for tailoring its autonomy and collaborative dynamics within the CrewAI framework. By default,
the `allow_delegation` attribute is now set to `False`, disabling agents to seek assistance or delegate tasks as needed. This default behavior can be changed to promote collaborative problem-solving and
efficiency within the CrewAI ecosystem. If needed, delegation can be enabled to suit specific operational requirements.

### Example: Disabling Delegation for an Agent

```python Code
agent = Agent(
  role='Content Writer',
  goal='Write engaging content on market trends',
  backstory='A seasoned writer with expertise in market analysis.',
  allow_delegation=True # Enabling delegation
)
```

## Conclusion

Customizing agents in CrewAI by setting their roles, goals, backstories, and tools, alongside advanced options like language model customization, memory, performance settings, and delegation preferences,
equips a nuanced and capable AI team ready for complex challenges.


# Image Generation with DALL-E
Source: https://docs.crewai.com/en/learn/dalle-image-generation

Learn how to use DALL-E for AI-powered image generation in your CrewAI projects

CrewAI supports integration with OpenAI's DALL-E, allowing your AI agents to generate images as part of their tasks. This guide will walk you through how to set up and use the DALL-E tool in your CrewAI projects.

## Prerequisites

* crewAI installed (latest version)
* OpenAI API key with access to DALL-E

## Setting Up the DALL-E Tool

<Steps>
  <Step title="Import the DALL-E tool">
    ```python
    from crewai_tools import DallETool
    ```
  </Step>

  <Step title="Add the DALL-E tool to your agent configuration">
    ```python
    @agent
    def researcher(self) -> Agent:
        return Agent(
            config=self.agents_config['researcher'],
            tools=[SerperDevTool(), DallETool()],  # Add DallETool to the list of tools
            allow_delegation=False,
            verbose=True
        )
    ```
  </Step>
</Steps>

## Using the DALL-E Tool

Once you've added the DALL-E tool to your agent, it can generate images based on text prompts. The tool will return a URL to the generated image, which can be used in the agent's output or passed to other agents for further processing.

### Example Agent Configuration

```yaml
role: >
    LinkedIn Profile Senior Data Researcher
goal: >
    Uncover detailed LinkedIn profiles based on provided name {name} and domain {domain}
    Generate a Dall-e image based on domain {domain}
backstory: >
    You're a seasoned researcher with a knack for uncovering the most relevant LinkedIn profiles.
    Known for your ability to navigate LinkedIn efficiently, you excel at gathering and presenting
    professional information clearly and concisely.
```

### Expected Output

The agent with the DALL-E tool will be able to generate the image and provide a URL in its response. You can then download the image.

<Frame>
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/dall-e-image.png" alt="DALL-E Image" />
</Frame>

## Best Practices

1. **Be specific in your image generation prompts** to get the best results.
2. **Consider generation time** - Image generation can take some time, so factor this into your task planning.
3. **Follow usage policies** - Always comply with OpenAI's usage policies when generating images.

## Troubleshooting

1. **Check API access** - Ensure your OpenAI API key has access to DALL-E.
2. **Version compatibility** - Check that you're using the latest version of crewAI and crewai-tools.
3. **Tool configuration** - Verify that the DALL-E tool is correctly added to the agent's tool list.


# Force Tool Output as Result
Source: https://docs.crewai.com/en/learn/force-tool-output-as-result

Learn how to force tool output as the result in an Agent's task in CrewAI.

## Introduction

In CrewAI, you can force the output of a tool as the result of an agent's task.
This feature is useful when you want to ensure that the tool output is captured and returned as the task result, avoiding any agent modification during the task execution.

## Forcing Tool Output as Result

To force the tool output as the result of an agent's task, you need to set the `result_as_answer` parameter to `True` when adding a tool to the agent.
This parameter ensures that the tool output is captured and returned as the task result, without any modifications by the agent.

Here's an example of how to force the tool output as the result of an agent's task:

```python Code
from crewai.agent import Agent
from my_tool import MyCustomTool

# Create a coding agent with the custom tool
coding_agent = Agent(
        role="Data Scientist",
        goal="Produce amazing reports on AI",
        backstory="You work with data and AI",
        tools=[MyCustomTool(result_as_answer=True)],
    )

# Assuming the tool's execution and result population occurs within the system
task_result = coding_agent.execute_task(task)
```

## Workflow in Action

<Steps>
  <Step title="Task Execution">
    The agent executes the task using the tool provided.
  </Step>

  <Step title="Tool Output">
    The tool generates the output, which is captured as the task result.
  </Step>

  <Step title="Agent Interaction">
    The agent may reflect and take learnings from the tool but the output is not modified.
  </Step>

  <Step title="Result Return">
    The tool output is returned as the task result without any modifications.
  </Step>
</Steps>


# Hierarchical Process
Source: https://docs.crewai.com/en/learn/hierarchical-process

A comprehensive guide to understanding and applying the hierarchical process within your CrewAI projects, updated to reflect the latest coding practices and functionalities.

## Introduction

The hierarchical process in CrewAI introduces a structured approach to task management, simulating traditional organizational hierarchies for efficient task delegation and execution.
This systematic workflow enhances project outcomes by ensuring tasks are handled with optimal efficiency and accuracy.

<Tip>
  The hierarchical process is designed to leverage advanced models like GPT-4, optimizing token usage while handling complex tasks with greater efficiency.
</Tip>

## Hierarchical Process Overview

By default, tasks in CrewAI are managed through a sequential process. However, adopting a hierarchical approach allows for a clear hierarchy in task management,
where a 'manager' agent coordinates the workflow, delegates tasks, and validates outcomes for streamlined and effective execution. This manager agent can now be either
automatically created by CrewAI or explicitly set by the user.

### Key Features

* **Task Delegation**: A manager agent allocates tasks among crew members based on their roles and capabilities.
* **Result Validation**: The manager evaluates outcomes to ensure they meet the required standards.
* **Efficient Workflow**: Emulates corporate structures, providing an organized approach to task management.
* **System Prompt Handling**: Optionally specify whether the system should use predefined prompts.
* **Stop Words Control**: Optionally specify whether stop words should be used, supporting various models including the o1 models.
* **Context Window Respect**: Prioritize important context by enabling respect of the context window, which is now the default behavior.
* **Delegation Control**: Delegation is now disabled by default to give users explicit control.
* **Max Requests Per Minute**: Configurable option to set the maximum number of requests per minute.
* **Max Iterations**: Limit the maximum number of iterations for obtaining a final answer.

## Implementing the Hierarchical Process

To utilize the hierarchical process, it's essential to explicitly set the process attribute to `Process.hierarchical`, as the default behavior is `Process.sequential`.
Define a crew with a designated manager and establish a clear chain of command.

<Tip>
  Assign tools at the agent level to facilitate task delegation and execution by the designated agents under the manager's guidance.
  Tools can also be specified at the task level for precise control over tool availability during task execution.
</Tip>

<Tip>
  Configuring the `manager_llm` parameter is crucial for the hierarchical process.
  The system requires a manager LLM to be set up for proper function, ensuring tailored decision-making.
</Tip>

```python Code
from crewai import Crew, Process, Agent

# Agents are defined with attributes for backstory, cache, and verbose mode
researcher = Agent(
    role='Researcher',
    goal='Conduct in-depth analysis',
    backstory='Experienced data analyst with a knack for uncovering hidden trends.',
)
writer = Agent(
    role='Writer',
    goal='Create engaging content',
    backstory='Creative writer passionate about storytelling in technical domains.',
)

# Establishing the crew with a hierarchical process and additional configurations
project_crew = Crew(
    tasks=[...],  # Tasks to be delegated and executed under the manager's supervision
    agents=[researcher, writer],
    manager_llm="gpt-4o",  # Specify which LLM the manager should use
    process=Process.hierarchical,
    planning=True,
)
```

### Using a Custom Manager Agent

Alternatively, you can create a custom manager agent with specific attributes tailored to your project's management needs. This gives you more control over the manager's behavior and capabilities.

```python
# Define a custom manager agent
manager = Agent(
    role="Project Manager",
    goal="Efficiently manage the crew and ensure high-quality task completion",
    backstory="You're an experienced project manager, skilled in overseeing complex projects and guiding teams to success.",
    allow_delegation=True,
)

# Use the custom manager in your crew
project_crew = Crew(
    tasks=[...],
    agents=[researcher, writer],
    manager_agent=manager,  # Use your custom manager agent
    process=Process.hierarchical,
    planning=True,
)
```

<Tip>
  For more details on creating and customizing a manager agent, check out the [Custom Manager Agent documentation](https://docs.crewai.com/how-to/custom-manager-agent#custom-manager-agent).
</Tip>

### Workflow in Action

1. **Task Assignment**: The manager assigns tasks strategically, considering each agent's capabilities and available tools.
2. **Execution and Review**: Agents complete their tasks with the option for asynchronous execution and callback functions for streamlined workflows.
3. **Sequential Task Progression**: Despite being a hierarchical process, tasks follow a logical order for smooth progression, facilitated by the manager's oversight.

## Conclusion

Adopting the hierarchical process in CrewAI, with the correct configurations and understanding of the system's capabilities, facilitates an organized and efficient approach to project management.
Utilize the advanced features and customizations to tailor the workflow to your specific needs, ensuring optimal task execution and project success.


# Human-in-the-Loop (HITL) Workflows
Source: https://docs.crewai.com/en/learn/human-in-the-loop

Learn how to implement Human-in-the-Loop workflows in CrewAI for enhanced decision-making

Human-in-the-Loop (HITL) is a powerful approach that combines artificial intelligence with human expertise to enhance decision-making and improve task outcomes. This guide shows you how to implement HITL within CrewAI.

## Setting Up HITL Workflows

<Steps>
  <Step title="Configure Your Task">
    Set up your task with human input enabled:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-human-input.png" alt="Crew Human Input" />
    </Frame>
  </Step>

  <Step title="Provide Webhook URL">
    When kicking off your crew, include a webhook URL for human input:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-webhook-url.png" alt="Crew Webhook URL" />
    </Frame>
  </Step>

  <Step title="Receive Webhook Notification">
    Once the crew completes the task requiring human input, you'll receive a webhook notification containing:

    * Execution ID
    * Task ID
    * Task output
  </Step>

  <Step title="Review Task Output">
    The system will pause in the `Pending Human Input` state. Review the task output carefully.
  </Step>

  <Step title="Submit Human Feedback">
    Call the resume endpoint of your crew with the following information:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-resume-endpoint.png" alt="Crew Resume Endpoint" />
    </Frame>

    <Warning>
      **Feedback Impact on Task Execution**:
      It's crucial to exercise care when providing feedback, as the entire feedback content will be incorporated as additional context for further task executions.
    </Warning>

    This means:

    * All information in your feedback becomes part of the task's context.
    * Irrelevant details may negatively influence it.
    * Concise, relevant feedback helps maintain task focus and efficiency.
    * Always review your feedback carefully before submission to ensure it contains only pertinent information that will positively guide the task's execution.
  </Step>

  <Step title="Handle Negative Feedback">
    If you provide negative feedback:

    * The crew will retry the task with added context from your feedback.
    * You'll receive another webhook notification for further review.
    * Repeat steps 4-6 until satisfied.
  </Step>

  <Step title="Execution Continuation">
    When you submit positive feedback, the execution will proceed to the next steps.
  </Step>
</Steps>

## Best Practices

* **Be Specific**: Provide clear, actionable feedback that directly addresses the task at hand
* **Stay Relevant**: Only include information that will help improve the task execution
* **Be Timely**: Respond to HITL prompts promptly to avoid workflow delays
* **Review Carefully**: Double-check your feedback before submitting to ensure accuracy

## Common Use Cases

HITL workflows are particularly valuable for:

* Quality assurance and validation
* Complex decision-making scenarios
* Sensitive or high-stakes operations
* Creative tasks requiring human judgment
* Compliance and regulatory reviews


# Human Input on Execution
Source: https://docs.crewai.com/en/learn/human-input-on-execution

Integrating CrewAI with human input during execution in complex decision-making processes and leveraging the full capabilities of the agent's attributes and tools.

## Human input in agent execution

Human input is critical in several agent execution scenarios, allowing agents to request additional information or clarification when necessary.
This feature is especially useful in complex decision-making processes or when agents require more details to complete a task effectively.

## Using human input with CrewAI

To integrate human input into agent execution, set the `human_input` flag in the task definition. When enabled, the agent prompts the user for input before delivering its final answer.
This input can provide extra context, clarify ambiguities, or validate the agent's output.

### Example:

```shell
pip install crewai
```

```python Code
import os
from crewai import Agent, Task, Crew
from crewai_tools import SerperDevTool

os.environ["SERPER_API_KEY"] = "Your Key"  # serper.dev API key
os.environ["OPENAI_API_KEY"] = "Your Key"

# Loading Tools
search_tool = SerperDevTool()

# Define your agents with roles, goals, tools, and additional attributes
researcher = Agent(
    role='Senior Research Analyst',
    goal='Uncover cutting-edge developments in AI and data science',
    backstory=(
        "You are a Senior Research Analyst at a leading tech think tank. "
        "Your expertise lies in identifying emerging trends and technologies in AI and data science. "
        "You have a knack for dissecting complex data and presenting actionable insights."
    ),
    verbose=True,
    allow_delegation=False,
    tools=[search_tool]
)
writer = Agent(
    role='Tech Content Strategist',
    goal='Craft compelling content on tech advancements',
    backstory=(
        "You are a renowned Tech Content Strategist, known for your insightful and engaging articles on technology and innovation. "
        "With a deep understanding of the tech industry, you transform complex concepts into compelling narratives."
    ),
    verbose=True,
    allow_delegation=True,
    tools=[search_tool],
    cache=False,  # Disable cache for this agent
)

# Create tasks for your agents
task1 = Task(
    description=(
        "Conduct a comprehensive analysis of the latest advancements in AI in 2025. "
        "Identify key trends, breakthrough technologies, and potential industry impacts. "
        "Compile your findings in a detailed report. "
        "Make sure to check with a human if the draft is good before finalizing your answer."
    ),
    expected_output='A comprehensive full report on the latest AI advancements in 2025, leave nothing out',
    agent=researcher,
    human_input=True
)

task2 = Task(
    description=(
        "Using the insights from the researcher\'s report, develop an engaging blog post that highlights the most significant AI advancements. "
        "Your post should be informative yet accessible, catering to a tech-savvy audience. "
        "Aim for a narrative that captures the essence of these breakthroughs and their implications for the future."
    ),
    expected_output='A compelling 3 paragraphs blog post formatted as markdown about the latest AI advancements in 2025',
    agent=writer,
    human_input=True
)

# Instantiate your crew with a sequential process
crew = Crew(
    agents=[researcher, writer],
    tasks=[task1, task2],
    verbose=True,
    memory=True,
    planning=True  # Enable planning feature for the crew
)

# Get your crew to work!
result = crew.kickoff()

print("######################")
print(result)
```


# Kickoff Crew Asynchronously
Source: https://docs.crewai.com/en/learn/kickoff-async

Kickoff a Crew Asynchronously

## Introduction

CrewAI provides the ability to kickoff a crew asynchronously, allowing you to start the crew execution in a non-blocking manner.
This feature is particularly useful when you want to run multiple crews concurrently or when you need to perform other tasks while the crew is executing.

## Asynchronous Crew Execution

To kickoff a crew asynchronously, use the `kickoff_async()` method. This method initiates the crew execution in a separate thread, allowing the main thread to continue executing other tasks.

### Method Signature

```python Code
def kickoff_async(self, inputs: dict) -> CrewOutput:
```

### Parameters

* `inputs` (dict): A dictionary containing the input data required for the tasks.

### Returns

* `CrewOutput`: An object representing the result of the crew execution.

## Potential Use Cases

* **Parallel Content Generation**: Kickoff multiple independent crews asynchronously, each responsible for generating content on different topics. For example, one crew might research and draft an article on AI trends, while another crew generates social media posts about a new product launch. Each crew operates independently, allowing content production to scale efficiently.

* **Concurrent Market Research Tasks**: Launch multiple crews asynchronously to conduct market research in parallel. One crew might analyze industry trends, while another examines competitor strategies, and yet another evaluates consumer sentiment. Each crew independently completes its task, enabling faster and more comprehensive insights.

* **Independent Travel Planning Modules**: Execute separate crews to independently plan different aspects of a trip. One crew might handle flight options, another handles accommodation, and a third plans activities. Each crew works asynchronously, allowing various components of the trip to be planned simultaneously and independently for faster results.

## Example: Single Asynchronous Crew Execution

Here's an example of how to kickoff a crew asynchronously using asyncio and awaiting the result:

```python Code
import asyncio
from crewai import Crew, Agent, Task

# Create an agent with code execution enabled
coding_agent = Agent(
    role="Python Data Analyst",
    goal="Analyze data and provide insights using Python",
    backstory="You are an experienced data analyst with strong Python skills.",
    allow_code_execution=True
)

# Create a task that requires code execution
data_analysis_task = Task(
    description="Analyze the given dataset and calculate the average age of participants. Ages: {ages}",
    agent=coding_agent,
    expected_output="The average age of the participants."
)

# Create a crew and add the task
analysis_crew = Crew(
    agents=[coding_agent],
    tasks=[data_analysis_task]
)

# Async function to kickoff the crew asynchronously
async def async_crew_execution():
    result = await analysis_crew.kickoff_async(inputs={"ages": [25, 30, 35, 40, 45]})
    print("Crew Result:", result)

# Run the async function
asyncio.run(async_crew_execution())
```

## Example: Multiple Asynchronous Crew Executions

In this example, we'll show how to kickoff multiple crews asynchronously and wait for all of them to complete using `asyncio.gather()`:

```python Code
import asyncio
from crewai import Crew, Agent, Task

# Create an agent with code execution enabled
coding_agent = Agent(
    role="Python Data Analyst",
    goal="Analyze data and provide insights using Python",
    backstory="You are an experienced data analyst with strong Python skills.",
    allow_code_execution=True
)

# Create tasks that require code execution
task_1 = Task(
    description="Analyze the first dataset and calculate the average age of participants. Ages: {ages}",
    agent=coding_agent,
    expected_output="The average age of the participants."
)

task_2 = Task(
    description="Analyze the second dataset and calculate the average age of participants. Ages: {ages}",
    agent=coding_agent,
    expected_output="The average age of the participants."
)

# Create two crews and add tasks
crew_1 = Crew(agents=[coding_agent], tasks=[task_1])
crew_2 = Crew(agents=[coding_agent], tasks=[task_2])

# Async function to kickoff multiple crews asynchronously and wait for all to finish
async def async_multiple_crews():
    # Create coroutines for concurrent execution
    result_1 = crew_1.kickoff_async(inputs={"ages": [25, 30, 35, 40, 45]})
    result_2 = crew_2.kickoff_async(inputs={"ages": [20, 22, 24, 28, 30]})

    # Wait for both crews to finish
    results = await asyncio.gather(result_1, result_2)

    for i, result in enumerate(results, 1):
        print(f"Crew {i} Result:", result)

# Run the async function
asyncio.run(async_multiple_crews())
```


# Kickoff Crew for Each
Source: https://docs.crewai.com/en/learn/kickoff-for-each

Kickoff Crew for Each Item in a List

## Introduction

CrewAI provides the ability to kickoff a crew for each item in a list, allowing you to execute the crew for each item in the list.
This feature is particularly useful when you need to perform the same set of tasks for multiple items.

## Kicking Off a Crew for Each Item

To kickoff a crew for each item in a list, use the `kickoff_for_each()` method.
This method executes the crew for each item in the list, allowing you to process multiple items efficiently.

Here's an example of how to kickoff a crew for each item in a list:

```python Code
from crewai import Crew, Agent, Task

# Create an agent with code execution enabled
coding_agent = Agent(
    role="Python Data Analyst",
    goal="Analyze data and provide insights using Python",
    backstory="You are an experienced data analyst with strong Python skills.",
    allow_code_execution=True
)

# Create a task that requires code execution
data_analysis_task = Task(
    description="Analyze the given dataset and calculate the average age of participants. Ages: {ages}",
    agent=coding_agent,
    expected_output="The average age calculated from the dataset"
)

# Create a crew and add the task
analysis_crew = Crew(
    agents=[coding_agent],
    tasks=[data_analysis_task],
    verbose=True,
    memory=False
)

datasets = [
  { "ages": [25, 30, 35, 40, 45] },
  { "ages": [20, 25, 30, 35, 40] },
  { "ages": [30, 35, 40, 45, 50] }
]

# Execute the crew
result = analysis_crew.kickoff_for_each(inputs=datasets)
```


# Connect to any LLM
Source: https://docs.crewai.com/en/learn/llm-connections

Comprehensive guide on integrating CrewAI with various Large Language Models (LLMs) using LiteLLM, including supported providers and configuration options.

## Connect CrewAI to LLMs

CrewAI uses LiteLLM to connect to a wide variety of Language Models (LLMs). This integration provides extensive versatility, allowing you to use models from numerous providers with a simple, unified interface.

<Note>
  By default, CrewAI uses the `gpt-4o-mini` model. This is determined by the `OPENAI_MODEL_NAME` environment variable, which defaults to "gpt-4o-mini" if not set.
  You can easily configure your agents to use a different model or provider as described in this guide.
</Note>

## Supported Providers

LiteLLM supports a wide range of providers, including but not limited to:

* OpenAI
* Anthropic
* Google (Vertex AI, Gemini)
* Azure OpenAI
* AWS (Bedrock, SageMaker)
* Cohere
* VoyageAI
* Hugging Face
* Ollama
* Mistral AI
* Replicate
* Together AI
* AI21
* Cloudflare Workers AI
* DeepInfra
* Groq
* SambaNova
* Nebius AI Studio
* [NVIDIA NIMs](https://docs.api.nvidia.com/nim/reference/models-1)
* And many more!

For a complete and up-to-date list of supported providers, please refer to the [LiteLLM Providers documentation](https://docs.litellm.ai/docs/providers).

## Changing the LLM

To use a different LLM with your CrewAI agents, you have several options:

<Tabs>
  <Tab title="Using a String Identifier">
    Pass the model name as a string when initializing the agent:

    <CodeGroup>
      ```python Code
      from crewai import Agent

      # Using OpenAI's GPT-4
      openai_agent = Agent(
          role='OpenAI Expert',
          goal='Provide insights using GPT-4',
          backstory="An AI assistant powered by OpenAI's latest model.",
          llm='gpt-4'
      )

      # Using Anthropic's Claude
      claude_agent = Agent(
          role='Anthropic Expert',
          goal='Analyze data using Claude',
          backstory="An AI assistant leveraging Anthropic's language model.",
          llm='claude-2'
      )
      ```
    </CodeGroup>
  </Tab>

  <Tab title="Using the LLM Class">
    For more detailed configuration, use the LLM class:

    <CodeGroup>
      ```python Code
      from crewai import Agent, LLM

      llm = LLM(
          model="gpt-4",
          temperature=0.7,
          base_url="https://api.openai.com/v1",
          api_key="your-api-key-here"
      )

      agent = Agent(
          role='Customized LLM Expert',
          goal='Provide tailored responses',
          backstory="An AI assistant with custom LLM settings.",
          llm=llm
      )
      ```
    </CodeGroup>
  </Tab>
</Tabs>

## Configuration Options

When configuring an LLM for your agent, you have access to a wide range of parameters:

| Parameter              |        Type        | Description                                                      |
| :--------------------- | :----------------: | :--------------------------------------------------------------- |
| **model**              |        `str`       | The name of the model to use (e.g., "gpt-4", "claude-2")         |
| **temperature**        |       `float`      | Controls randomness in output (0.0 to 1.0)                       |
| **max\_tokens**        |        `int`       | Maximum number of tokens to generate                             |
| **top\_p**             |       `float`      | Controls diversity of output (0.0 to 1.0)                        |
| **frequency\_penalty** |       `float`      | Penalizes new tokens based on their frequency in the text so far |
| **presence\_penalty**  |       `float`      | Penalizes new tokens based on their presence in the text so far  |
| **stop**               | `str`, `List[str]` | Sequence(s) to stop generation                                   |
| **base\_url**          |        `str`       | The base URL for the API endpoint                                |
| **api\_key**           |        `str`       | Your API key for authentication                                  |

For a complete list of parameters and their descriptions, refer to the LLM class documentation.

## Connecting to OpenAI-Compatible LLMs

You can connect to OpenAI-compatible LLMs using either environment variables or by setting specific attributes on the LLM class:

<Tabs>
  <Tab title="Using Environment Variables">
    <CodeGroup>
      ```python Generic
      import os

      os.environ["OPENAI_API_KEY"] = "your-api-key"
      os.environ["OPENAI_API_BASE"] = "https://api.your-provider.com/v1"
      os.environ["OPENAI_MODEL_NAME"] = "your-model-name"
      ```

      ```python Google
      import os

      # Example using Gemini's OpenAI-compatible API.
      os.environ["OPENAI_API_KEY"] = "your-gemini-key"  # Should start with AIza...
      os.environ["OPENAI_API_BASE"] = "https://generativelanguage.googleapis.com/v1beta/openai/"
      os.environ["OPENAI_MODEL_NAME"] = "openai/gemini-2.0-flash"  # Add your Gemini model here, under openai/
      ```
    </CodeGroup>
  </Tab>

  <Tab title="Using LLM Class Attributes">
    <CodeGroup>
      ```python Generic
      llm = LLM(
          model="custom-model-name",
          api_key="your-api-key",
          base_url="https://api.your-provider.com/v1"
      )
      agent = Agent(llm=llm, ...)
      ```

      ```python Google
      # Example using Gemini's OpenAI-compatible API
      llm = LLM(
          model="openai/gemini-2.0-flash",
          base_url="https://generativelanguage.googleapis.com/v1beta/openai/",
          api_key="your-gemini-key",  # Should start with AIza...
      )
      agent = Agent(llm=llm, ...)
      ```
    </CodeGroup>
  </Tab>
</Tabs>

## Using Local Models with Ollama

For local models like those provided by Ollama:

<Steps>
  <Step title="Download and install Ollama">
    [Click here to download and install Ollama](https://ollama.com/download)
  </Step>

  <Step title="Pull the desired model">
    For example, run `ollama pull llama3.2` to download the model.
  </Step>

  <Step title="Configure your agent">
    <CodeGroup>
      ```python Code
          agent = Agent(
              role='Local AI Expert',
              goal='Process information using a local model',
              backstory="An AI assistant running on local hardware.",
              llm=LLM(model="ollama/llama3.2", base_url="http://localhost:11434")
          )
      ```
    </CodeGroup>
  </Step>
</Steps>

## Changing the Base API URL

You can change the base API URL for any LLM provider by setting the `base_url` parameter:

```python Code
llm = LLM(
    model="custom-model-name",
    base_url="https://api.your-provider.com/v1",
    api_key="your-api-key"
)
agent = Agent(llm=llm, ...)
```

This is particularly useful when working with OpenAI-compatible APIs or when you need to specify a different endpoint for your chosen provider.

## Conclusion

By leveraging LiteLLM, CrewAI offers seamless integration with a vast array of LLMs. This flexibility allows you to choose the most suitable model for your specific needs, whether you prioritize performance, cost-efficiency, or local deployment. Remember to consult the [LiteLLM documentation](https://docs.litellm.ai/docs/) for the most up-to-date information on supported models and configuration options.


# Strategic LLM Selection Guide
Source: https://docs.crewai.com/en/learn/llm-selection-guide

Strategic framework for choosing the right LLM for your CrewAI AI agents and writing effective task and agent definitions

## The CrewAI Approach to LLM Selection

Rather than prescriptive model recommendations, we advocate for a **thinking framework** that helps you make informed decisions based on your specific use case, constraints, and requirements. The LLM landscape evolves rapidly, with new models emerging regularly and existing ones being updated frequently. What matters most is developing a systematic approach to evaluation that remains relevant regardless of which specific models are available.

<Note>
  This guide focuses on strategic thinking rather than specific model recommendations, as the LLM landscape evolves rapidly.
</Note>

## Quick Decision Framework

<Steps>
  <Step title="Analyze Your Tasks">
    Begin by deeply understanding what your tasks actually require. Consider the cognitive complexity involved, the depth of reasoning needed, the format of expected outputs, and the amount of context the model will need to process. This foundational analysis will guide every subsequent decision.
  </Step>

  <Step title="Map Model Capabilities">
    Once you understand your requirements, map them to model strengths. Different model families excel at different types of work; some are optimized for reasoning and analysis, others for creativity and content generation, and others for speed and efficiency.
  </Step>

  <Step title="Consider Constraints">
    Factor in your real-world operational constraints including budget limitations, latency requirements, data privacy needs, and infrastructure capabilities. The theoretically best model may not be the practically best choice for your situation.
  </Step>

  <Step title="Test and Iterate">
    Start with reliable, well-understood models and optimize based on actual performance in your specific use case. Real-world results often differ from theoretical benchmarks, so empirical testing is crucial.
  </Step>
</Steps>

## Core Selection Framework

### a. Task-First Thinking

The most critical step in LLM selection is understanding what your task actually demands. Too often, teams select models based on general reputation or benchmark scores without carefully analyzing their specific requirements. This approach leads to either over-engineering simple tasks with expensive, complex models, or under-powering sophisticated work with models that lack the necessary capabilities.

<Tabs>
  <Tab title="Reasoning Complexity">
    * **Simple Tasks** represent the majority of everyday AI work and include basic instruction following, straightforward data processing, and simple formatting operations. These tasks typically have clear inputs and outputs with minimal ambiguity. The cognitive load is low, and the model primarily needs to follow explicit instructions rather than engage in complex reasoning.

    * **Complex Tasks** require multi-step reasoning, strategic thinking, and the ability to handle ambiguous or incomplete information. These might involve analyzing multiple data sources, developing comprehensive strategies, or solving problems that require breaking down into smaller components. The model needs to maintain context across multiple reasoning steps and often must make inferences that aren't explicitly stated.

    * **Creative Tasks** demand a different type of cognitive capability focused on generating novel, engaging, and contextually appropriate content. This includes storytelling, marketing copy creation, and creative problem-solving. The model needs to understand nuance, tone, and audience while producing content that feels authentic and engaging rather than formulaic.
  </Tab>

  <Tab title="Output Requirements">
    * **Structured Data** tasks require precision and consistency in format adherence. When working with JSON, XML, or database formats, the model must reliably produce syntactically correct output that can be programmatically processed. These tasks often have strict validation requirements and little tolerance for format errors, making reliability more important than creativity.

    * **Creative Content** outputs demand a balance of technical competence and creative flair. The model needs to understand audience, tone, and brand voice while producing content that engages readers and achieves specific communication goals. Quality here is often subjective and requires models that can adapt their writing style to different contexts and purposes.

    * **Technical Content** sits between structured data and creative content, requiring both precision and clarity. Documentation, code generation, and technical analysis need to be accurate and comprehensive while remaining accessible to the intended audience. The model must understand complex technical concepts and communicate them effectively.
  </Tab>

  <Tab title="Context Needs">
    * **Short Context** scenarios involve focused, immediate tasks where the model needs to process limited information quickly. These are often transactional interactions where speed and efficiency matter more than deep understanding. The model doesn't need to maintain extensive conversation history or process large documents.

    * **Long Context** requirements emerge when working with substantial documents, extended conversations, or complex multi-part tasks. The model needs to maintain coherence across thousands of tokens while referencing earlier information accurately. This capability becomes crucial for document analysis, comprehensive research, and sophisticated dialogue systems.

    * **Very Long Context** scenarios push the boundaries of what's currently possible, involving massive document processing, extensive research synthesis, or complex multi-session interactions. These use cases require models specifically designed for extended context handling and often involve trade-offs between context length and processing speed.
  </Tab>
</Tabs>

### b. Model Capability Mapping

Understanding model capabilities requires looking beyond marketing claims and benchmark scores to understand the fundamental strengths and limitations of different model architectures and training approaches.

<AccordionGroup>
  <Accordion title="Reasoning Models" icon="brain">
    Reasoning models represent a specialized category designed specifically for complex, multi-step thinking tasks. These models excel when problems require careful analysis, strategic planning, or systematic problem decomposition. They typically employ techniques like chain-of-thought reasoning or tree-of-thought processing to work through complex problems step by step.

    The strength of reasoning models lies in their ability to maintain logical consistency across extended reasoning chains and to break down complex problems into manageable components. They're particularly valuable for strategic planning, complex analysis, and situations where the quality of reasoning matters more than speed of response.

    However, reasoning models often come with trade-offs in terms of speed and cost. They may also be less suitable for creative tasks or simple operations where their sophisticated reasoning capabilities aren't needed. Consider these models when your tasks involve genuine complexity that benefits from systematic, step-by-step analysis.
  </Accordion>

  <Accordion title="General Purpose Models" icon="microchip">
    General purpose models offer the most balanced approach to LLM selection, providing solid performance across a wide range of tasks without extreme specialization in any particular area. These models are trained on diverse datasets and optimized for versatility rather than peak performance in specific domains.

    The primary advantage of general purpose models is their reliability and predictability across different types of work. They handle most standard business tasks competently, from research and analysis to content creation and data processing. This makes them excellent choices for teams that need consistent performance across varied workflows.

    While general purpose models may not achieve the peak performance of specialized alternatives in specific domains, they offer operational simplicity and reduced complexity in model management. They're often the best starting point for new projects, allowing teams to understand their specific needs before potentially optimizing with more specialized models.
  </Accordion>

  <Accordion title="Fast & Efficient Models" icon="bolt">
    Fast and efficient models prioritize speed, cost-effectiveness, and resource efficiency over sophisticated reasoning capabilities. These models are optimized for high-throughput scenarios where quick responses and low operational costs are more important than nuanced understanding or complex reasoning.

    These models excel in scenarios involving routine operations, simple data processing, function calling, and high-volume tasks where the cognitive requirements are relatively straightforward. They're particularly valuable for applications that need to process many requests quickly or operate within tight budget constraints.

    The key consideration with efficient models is ensuring that their capabilities align with your task requirements. While they can handle many routine operations effectively, they may struggle with tasks requiring nuanced understanding, complex reasoning, or sophisticated content generation. They're best used for well-defined, routine operations where speed and cost matter more than sophistication.
  </Accordion>

  <Accordion title="Creative Models" icon="pen">
    Creative models are specifically optimized for content generation, writing quality, and creative thinking tasks. These models typically excel at understanding nuance, tone, and style while producing engaging, contextually appropriate content that feels natural and authentic.

    The strength of creative models lies in their ability to adapt writing style to different audiences, maintain consistent voice and tone, and generate content that engages readers effectively. They often perform better on tasks involving storytelling, marketing copy, brand communications, and other content where creativity and engagement are primary goals.

    When selecting creative models, consider not just their ability to generate text, but their understanding of audience, context, and purpose. The best creative models can adapt their output to match specific brand voices, target different audience segments, and maintain consistency across extended content pieces.
  </Accordion>

  <Accordion title="Open Source Models" icon="code">
    Open source models offer unique advantages in terms of cost control, customization potential, data privacy, and deployment flexibility. These models can be run locally or on private infrastructure, providing complete control over data handling and model behavior.

    The primary benefits of open source models include elimination of per-token costs, ability to fine-tune for specific use cases, complete data privacy, and independence from external API providers. They're particularly valuable for organizations with strict data privacy requirements, budget constraints, or specific customization needs.

    However, open source models require more technical expertise to deploy and maintain effectively. Teams need to consider infrastructure costs, model management complexity, and the ongoing effort required to keep models updated and optimized. The total cost of ownership may be higher than cloud-based alternatives when factoring in technical overhead.
  </Accordion>
</AccordionGroup>

## Strategic Configuration Patterns

### a. Multi-Model Approach

<Tip>
  Use different models for different purposes within the same crew to optimize both performance and cost.
</Tip>

The most sophisticated CrewAI implementations often employ multiple models strategically, assigning different models to different agents based on their specific roles and requirements. This approach allows teams to optimize for both performance and cost by using the most appropriate model for each type of work.

Planning agents benefit from reasoning models that can handle complex strategic thinking and multi-step analysis. These agents often serve as the "brain" of the operation, developing strategies and coordinating other agents' work. Content agents, on the other hand, perform best with creative models that excel at writing quality and audience engagement. Processing agents handling routine operations can use efficient models that prioritize speed and cost-effectiveness.

**Example: Research and Analysis Crew**

```python
from crewai import Agent, Task, Crew, LLM

# High-capability reasoning model for strategic planning
manager_llm = LLM(model="gemini-2.5-flash-preview-05-20", temperature=0.1)

# Creative model for content generation
content_llm = LLM(model="claude-3-5-sonnet-20241022", temperature=0.7)

# Efficient model for data processing
processing_llm = LLM(model="gpt-4o-mini", temperature=0)

research_manager = Agent(
    role="Research Strategy Manager",
    goal="Develop comprehensive research strategies and coordinate team efforts",
    backstory="Expert research strategist with deep analytical capabilities",
    llm=manager_llm,  # High-capability model for complex reasoning
    verbose=True
)

content_writer = Agent(
    role="Research Content Writer",
    goal="Transform research findings into compelling, well-structured reports",
    backstory="Skilled writer who excels at making complex topics accessible",
    llm=content_llm,  # Creative model for engaging content
    verbose=True
)

data_processor = Agent(
    role="Data Analysis Specialist",
    goal="Extract and organize key data points from research sources",
    backstory="Detail-oriented analyst focused on accuracy and efficiency",
    llm=processing_llm,  # Fast, cost-effective model for routine tasks
    verbose=True
)

crew = Crew(
    agents=[research_manager, content_writer, data_processor],
    tasks=[...],  # Your specific tasks
    manager_llm=manager_llm,  # Manager uses the reasoning model
    verbose=True
)
```

The key to successful multi-model implementation is understanding how different agents interact and ensuring that model capabilities align with agent responsibilities. This requires careful planning but can result in significant improvements in both output quality and operational efficiency.

### b. Component-Specific Selection

<Tabs>
  <Tab title="Manager LLM">
    The manager LLM plays a crucial role in hierarchical CrewAI processes, serving as the coordination point for multiple agents and tasks. This model needs to excel at delegation, task prioritization, and maintaining context across multiple concurrent operations.

    Effective manager LLMs require strong reasoning capabilities to make good delegation decisions, consistent performance to ensure predictable coordination, and excellent context management to track the state of multiple agents simultaneously. The model needs to understand the capabilities and limitations of different agents while optimizing task allocation for efficiency and quality.

    Cost considerations are particularly important for manager LLMs since they're involved in every operation. The model needs to provide sufficient capability for effective coordination while remaining cost-effective for frequent use. This often means finding models that offer good reasoning capabilities without the premium pricing of the most sophisticated options.
  </Tab>

  <Tab title="Function Calling LLM">
    Function calling LLMs handle tool usage across all agents, making them critical for crews that rely heavily on external tools and APIs. These models need to excel at understanding tool capabilities, extracting parameters accurately, and handling tool responses effectively.

    The most important characteristics for function calling LLMs are precision and reliability rather than creativity or sophisticated reasoning. The model needs to consistently extract the correct parameters from natural language requests and handle tool responses appropriately. Speed is also important since tool usage often involves multiple round trips that can impact overall performance.

    Many teams find that specialized function calling models or general purpose models with strong tool support work better than creative or reasoning-focused models for this role. The key is ensuring that the model can reliably bridge the gap between natural language instructions and structured tool calls.
  </Tab>

  <Tab title="Agent-Specific Overrides">
    Individual agents can override crew-level LLM settings when their specific needs differ significantly from the general crew requirements. This capability allows for fine-tuned optimization while maintaining operational simplicity for most agents.

    Consider agent-specific overrides when an agent's role requires capabilities that differ substantially from other crew members. For example, a creative writing agent might benefit from a model optimized for content generation, while a data analysis agent might perform better with a reasoning-focused model.

    The challenge with agent-specific overrides is balancing optimization with operational complexity. Each additional model adds complexity to deployment, monitoring, and cost management. Teams should focus overrides on agents where the performance improvement justifies the additional complexity.
  </Tab>
</Tabs>

## Task Definition Framework

### a. Focus on Clarity Over Complexity

Effective task definition is often more important than model selection in determining the quality of CrewAI outputs. Well-defined tasks provide clear direction and context that enable even modest models to perform well, while poorly defined tasks can cause even sophisticated models to produce unsatisfactory results.

<AccordionGroup>
  <Accordion title="Effective Task Descriptions" icon="list-check">
    The best task descriptions strike a balance between providing sufficient detail and maintaining clarity. They should define the specific objective clearly enough that there's no ambiguity about what success looks like, while explaining the approach or methodology in enough detail that the agent understands how to proceed.

    Effective task descriptions include relevant context and constraints that help the agent understand the broader purpose and any limitations they need to work within. They break complex work into focused steps that can be executed systematically, rather than presenting overwhelming, multi-faceted objectives that are difficult to approach systematically.

    Common mistakes include being too vague about objectives, failing to provide necessary context, setting unclear success criteria, or combining multiple unrelated tasks into a single description. The goal is to provide enough information for the agent to succeed while maintaining focus on a single, clear objective.
  </Accordion>

  <Accordion title="Expected Output Guidelines" icon="bullseye">
    Expected output guidelines serve as a contract between the task definition and the agent, clearly specifying what the deliverable should look like and how it will be evaluated. These guidelines should describe both the format and structure needed, as well as the key elements that must be included for the output to be considered complete.

    The best output guidelines provide concrete examples of quality indicators and define completion criteria clearly enough that both the agent and human reviewers can assess whether the task has been completed successfully. This reduces ambiguity and helps ensure consistent results across multiple task executions.

    Avoid generic output descriptions that could apply to any task, missing format specifications that leave agents guessing about structure, unclear quality standards that make evaluation difficult, or failing to provide examples or templates that help agents understand expectations.
  </Accordion>
</AccordionGroup>

### b. Task Sequencing Strategy

<Tabs>
  <Tab title="Sequential Dependencies">
    Sequential task dependencies are essential when tasks build upon previous outputs, information flows from one task to another, or quality depends on the completion of prerequisite work. This approach ensures that each task has access to the information and context it needs to succeed.

    Implementing sequential dependencies effectively requires using the context parameter to chain related tasks, building complexity gradually through task progression, and ensuring that each task produces outputs that serve as meaningful inputs for subsequent tasks. The goal is to maintain logical flow between dependent tasks while avoiding unnecessary bottlenecks.

    Sequential dependencies work best when there's a clear logical progression from one task to another and when the output of one task genuinely improves the quality or feasibility of subsequent tasks. However, they can create bottlenecks if not managed carefully, so it's important to identify which dependencies are truly necessary versus those that are merely convenient.
  </Tab>

  <Tab title="Parallel Execution">
    Parallel execution becomes valuable when tasks are independent of each other, time efficiency is important, or different expertise areas are involved that don't require coordination. This approach can significantly reduce overall execution time while allowing specialized agents to work on their areas of strength simultaneously.

    Successful parallel execution requires identifying tasks that can truly run independently, grouping related but separate work streams effectively, and planning for result integration when parallel tasks need to be combined into a final deliverable. The key is ensuring that parallel tasks don't create conflicts or redundancies that reduce overall quality.

    Consider parallel execution when you have multiple independent research streams, different types of analysis that don't depend on each other, or content creation tasks that can be developed simultaneously. However, be mindful of resource allocation and ensure that parallel execution doesn't overwhelm your available model capacity or budget.
  </Tab>
</Tabs>

## Optimizing Agent Configuration for LLM Performance

### a. Role-Driven LLM Selection

<Warning>
  Generic agent roles make it impossible to select the right LLM. Specific roles enable targeted model optimization.
</Warning>

The specificity of your agent roles directly determines which LLM capabilities matter most for optimal performance. This creates a strategic opportunity to match precise model strengths with agent responsibilities.

**Generic vs. Specific Role Impact on LLM Choice:**

When defining roles, think about the specific domain knowledge, working style, and decision-making frameworks that would be most valuable for the tasks the agent will handle. The more specific and contextual the role definition, the better the model can embody that role effectively.

```python
# ✅ Specific role - clear LLM requirements
specific_agent = Agent(
    role="SaaS Revenue Operations Analyst",  # Clear domain expertise needed
    goal="Analyze recurring revenue metrics and identify growth opportunities",
    backstory="Specialist in SaaS business models with deep understanding of ARR, churn, and expansion revenue",
    llm=LLM(model="gpt-4o")  # Reasoning model justified for complex analysis
)
```

**Role-to-Model Mapping Strategy:**

* **"Research Analyst"** → Reasoning model (GPT-4o, Claude Sonnet) for complex analysis
* **"Content Editor"** → Creative model (Claude, GPT-4o) for writing quality
* **"Data Processor"** → Efficient model (GPT-4o-mini, Gemini Flash) for structured tasks
* **"API Coordinator"** → Function-calling optimized model (GPT-4o, Claude) for tool usage

### b. Backstory as Model Context Amplifier

<Info>
  Strategic backstories multiply your chosen LLM's effectiveness by providing domain-specific context that generic prompting cannot achieve.
</Info>

A well-crafted backstory transforms your LLM choice from generic capability to specialized expertise. This is especially crucial for cost optimization - a well-contextualized efficient model can outperform a premium model without proper context.

**Context-Driven Performance Example:**

```python
# Context amplifies model effectiveness
domain_expert = Agent(
    role="B2B SaaS Marketing Strategist",
    goal="Develop comprehensive go-to-market strategies for enterprise software",
    backstory="""
    You have 10+ years of experience scaling B2B SaaS companies from Series A to IPO.
    You understand the nuances of enterprise sales cycles, the importance of product-market
    fit in different verticals, and how to balance growth metrics with unit economics.
    You've worked with companies like Salesforce, HubSpot, and emerging unicorns, giving
    you perspective on both established and disruptive go-to-market strategies.
    """,
    llm=LLM(model="claude-3-5-sonnet", temperature=0.3)  # Balanced creativity with domain knowledge
)

# This context enables Claude to perform like a domain expert
# Without it, even it would produce generic marketing advice
```

**Backstory Elements That Enhance LLM Performance:**

* **Domain Experience**: "10+ years in enterprise SaaS sales"
* **Specific Expertise**: "Specializes in technical due diligence for Series B+ rounds"
* **Working Style**: "Prefers data-driven decisions with clear documentation"
* **Quality Standards**: "Insists on citing sources and showing analytical work"

### c. Holistic Agent-LLM Optimization

The most effective agent configurations create synergy between role specificity, backstory depth, and LLM selection. Each element reinforces the others to maximize model performance.

**Optimization Framework:**

```python
# Example: Technical Documentation Agent
tech_writer = Agent(
    role="API Documentation Specialist",  # Specific role for clear LLM requirements
    goal="Create comprehensive, developer-friendly API documentation",
    backstory="""
    You're a technical writer with 8+ years documenting REST APIs, GraphQL endpoints,
    and SDK integration guides. You've worked with developer tools companies and
    understand what developers need: clear examples, comprehensive error handling,
    and practical use cases. You prioritize accuracy and usability over marketing fluff.
    """,
    llm=LLM(
        model="claude-3-5-sonnet",  # Excellent for technical writing
        temperature=0.1  # Low temperature for accuracy
    ),
    tools=[code_analyzer_tool, api_scanner_tool],
    verbose=True
)
```

**Alignment Checklist:**

* ✅ **Role Specificity**: Clear domain and responsibilities
* ✅ **LLM Match**: Model strengths align with role requirements
* ✅ **Backstory Depth**: Provides domain context the LLM can leverage
* ✅ **Tool Integration**: Tools support the agent's specialized function
* ✅ **Parameter Tuning**: Temperature and settings optimize for role needs

The key is creating agents where every configuration choice reinforces your LLM selection strategy, maximizing performance while optimizing costs.

## Practical Implementation Checklist

Rather than repeating the strategic framework, here's a tactical checklist for implementing your LLM selection decisions in CrewAI:

<Steps>
  <Step title="Audit Your Current Setup" icon="clipboard-check">
    **What to Review:**

    * Are all agents using the same LLM by default?
    * Which agents handle the most complex reasoning tasks?
    * Which agents primarily do data processing or formatting?
    * Are any agents heavily tool-dependent?

    **Action**: Document current agent roles and identify optimization opportunities.
  </Step>

  <Step title="Implement Crew-Level Strategy" icon="users-gear">
    **Set Your Baseline:**

    ```python
    # Start with a reliable default for the crew
    default_crew_llm = LLM(model="gpt-4o-mini")  # Cost-effective baseline

    crew = Crew(
        agents=[...],
        tasks=[...],
        memory=True
    )
    ```

    **Action**: Establish your crew's default LLM before optimizing individual agents.
  </Step>

  <Step title="Optimize High-Impact Agents" icon="star">
    **Identify and Upgrade Key Agents:**

    ```python
    # Manager or coordination agents
    manager_agent = Agent(
        role="Project Manager",
        llm=LLM(model="gemini-2.5-flash-preview-05-20"),  # Premium for coordination
        # ... rest of config
    )

    # Creative or customer-facing agents
    content_agent = Agent(
        role="Content Creator",
        llm=LLM(model="claude-3-5-sonnet"),  # Best for writing
        # ... rest of config
    )
    ```

    **Action**: Upgrade 20% of your agents that handle 80% of the complexity.
  </Step>

  <Step title="Validate with Enterprise Testing" icon="test-tube">
    **Once you deploy your agents to production:**

    * Use [CrewAI Enterprise platform](https://app.crewai.com) to A/B test your model selections
    * Run multiple iterations with real inputs to measure consistency and performance
    * Compare cost vs. performance across your optimized setup
    * Share results with your team for collaborative decision-making

    **Action**: Replace guesswork with data-driven validation using the testing platform.
  </Step>
</Steps>

### When to Use Different Model Types

<Tabs>
  <Tab title="Reasoning Models">
    Reasoning models become essential when tasks require genuine multi-step logical thinking, strategic planning, or high-level decision making that benefits from systematic analysis. These models excel when problems need to be broken down into components and analyzed systematically rather than handled through pattern matching or simple instruction following.

    Consider reasoning models for business strategy development, complex data analysis that requires drawing insights from multiple sources, multi-step problem solving where each step depends on previous analysis, and strategic planning tasks that require considering multiple variables and their interactions.

    However, reasoning models often come with higher costs and slower response times, so they're best reserved for tasks where their sophisticated capabilities provide genuine value rather than being used for simple operations that don't require complex reasoning.
  </Tab>

  <Tab title="Creative Models">
    Creative models become valuable when content generation is the primary output and the quality, style, and engagement level of that content directly impact success. These models excel when writing quality and style matter significantly, creative ideation or brainstorming is needed, or brand voice and tone are important considerations.

    Use creative models for blog post writing and article creation, marketing copy that needs to engage and persuade, creative storytelling and narrative development, and brand communications where voice and tone are crucial. These models often understand nuance and context better than general purpose alternatives.

    Creative models may be less suitable for technical or analytical tasks where precision and factual accuracy are more important than engagement and style. They're best used when the creative and communicative aspects of the output are primary success factors.
  </Tab>

  <Tab title="Efficient Models">
    Efficient models are ideal for high-frequency, routine operations where speed and cost optimization are priorities. These models work best when tasks have clear, well-defined parameters and don't require sophisticated reasoning or creative capabilities.

    Consider efficient models for data processing and transformation tasks, simple formatting and organization operations, function calling and tool usage where precision matters more than sophistication, and high-volume operations where cost per operation is a significant factor.

    The key with efficient models is ensuring that their capabilities align with task requirements. They can handle many routine operations effectively but may struggle with tasks requiring nuanced understanding, complex reasoning, or sophisticated content generation.
  </Tab>

  <Tab title="Open Source Models">
    Open source models become attractive when budget constraints are significant, data privacy requirements exist, customization needs are important, or local deployment is required for operational or compliance reasons.

    Consider open source models for internal company tools where data privacy is paramount, privacy-sensitive applications that can't use external APIs, cost-optimized deployments where per-token pricing is prohibitive, and situations requiring custom model modifications or fine-tuning.

    However, open source models require more technical expertise to deploy and maintain effectively. Consider the total cost of ownership including infrastructure, technical overhead, and ongoing maintenance when evaluating open source options.
  </Tab>
</Tabs>

## Common CrewAI Model Selection Pitfalls

<AccordionGroup>
  <Accordion title="The 'One Model Fits All' Trap" icon="triangle-exclamation">
    **The Problem**: Using the same LLM for all agents in a crew, regardless of their specific roles and responsibilities. This is often the default approach but rarely optimal.

    **Real Example**: Using GPT-4o for both a strategic planning manager and a data extraction agent. The manager needs reasoning capabilities worth the premium cost, but the data extractor could perform just as well with GPT-4o-mini at a fraction of the price.

    **CrewAI Solution**: Leverage agent-specific LLM configuration to match model capabilities with agent roles:

    ```python
    # Strategic agent gets premium model
    manager = Agent(role="Strategy Manager", llm=LLM(model="gpt-4o"))

    # Processing agent gets efficient model
    processor = Agent(role="Data Processor", llm=LLM(model="gpt-4o-mini"))
    ```
  </Accordion>

  <Accordion title="Ignoring Crew-Level vs Agent-Level LLM Hierarchy" icon="shuffle">
    **The Problem**: Not understanding how CrewAI's LLM hierarchy works - crew LLM, manager LLM, and agent LLM settings can conflict or be poorly coordinated.

    **Real Example**: Setting a crew to use Claude, but having agents configured with GPT models, creating inconsistent behavior and unnecessary model switching overhead.

    **CrewAI Solution**: Plan your LLM hierarchy strategically:

    ```python
    crew = Crew(
        agents=[agent1, agent2],
        tasks=[task1, task2],
        manager_llm=LLM(model="gpt-4o"),  # For crew coordination
        process=Process.hierarchical  # When using manager_llm
    )

    # Agents inherit crew LLM unless specifically overridden
    agent1 = Agent(llm=LLM(model="claude-3-5-sonnet"))  # Override for specific needs
    ```
  </Accordion>

  <Accordion title="Function Calling Model Mismatch" icon="screwdriver-wrench">
    **The Problem**: Choosing models based on general capabilities while ignoring function calling performance for tool-heavy CrewAI workflows.

    **Real Example**: Selecting a creative-focused model for an agent that primarily needs to call APIs, search tools, or process structured data. The agent struggles with tool parameter extraction and reliable function calls.

    **CrewAI Solution**: Prioritize function calling capabilities for tool-heavy agents:

    ```python
    # For agents that use many tools
    tool_agent = Agent(
        role="API Integration Specialist",
        tools=[search_tool, api_tool, data_tool],
        llm=LLM(model="gpt-4o"),  # Excellent function calling
        # OR
        llm=LLM(model="claude-3-5-sonnet")  # Also strong with tools
    )
    ```
  </Accordion>

  <Accordion title="Premature Optimization Without Testing" icon="gear">
    **The Problem**: Making complex model selection decisions based on theoretical performance without validating with actual CrewAI workflows and tasks.

    **Real Example**: Implementing elaborate model switching logic based on task types without testing if the performance gains justify the operational complexity.

    **CrewAI Solution**: Start simple, then optimize based on real performance data:

    ```python
    # Start with this
    crew = Crew(agents=[...], tasks=[...], llm=LLM(model="gpt-4o-mini"))

    # Test performance, then optimize specific agents as needed
    # Use Enterprise platform testing to validate improvements
    ```
  </Accordion>

  <Accordion title="Overlooking Context and Memory Limitations" icon="brain">
    **The Problem**: Not considering how model context windows interact with CrewAI's memory and context sharing between agents.

    **Real Example**: Using a short-context model for agents that need to maintain conversation history across multiple task iterations, or in crews with extensive agent-to-agent communication.

    **CrewAI Solution**: Match context capabilities to crew communication patterns.
  </Accordion>
</AccordionGroup>

## Testing and Iteration Strategy

<Steps>
  <Step title="Start Simple" icon="play">
    Begin with reliable, general-purpose models that are well-understood and widely supported. This provides a stable foundation for understanding your specific requirements and performance expectations before optimizing for specialized needs.
  </Step>

  <Step title="Measure What Matters" icon="chart-line">
    Develop metrics that align with your specific use case and business requirements rather than relying solely on general benchmarks. Focus on measuring outcomes that directly impact your success rather than theoretical performance indicators.
  </Step>

  <Step title="Iterate Based on Results" icon="arrows-rotate">
    Make model changes based on observed performance in your specific context rather than theoretical considerations or general recommendations. Real-world performance often differs significantly from benchmark results or general reputation.
  </Step>

  <Step title="Consider Total Cost" icon="calculator">
    Evaluate the complete cost of ownership including model costs, development time, maintenance overhead, and operational complexity. The cheapest model per token may not be the most cost-effective choice when considering all factors.
  </Step>
</Steps>

<Tip>
  Focus on understanding your requirements first, then select models that best match those needs. The best LLM choice is the one that consistently delivers the results you need within your operational constraints.
</Tip>

### Enterprise-Grade Model Validation

For teams serious about optimizing their LLM selection, the **CrewAI Enterprise platform** provides sophisticated testing capabilities that go far beyond basic CLI testing. The platform enables comprehensive model evaluation that helps you make data-driven decisions about your LLM strategy.

<Frame>
  ![Enterprise Testing Interface](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/enterprise-testing.png)
</Frame>

**Advanced Testing Features:**

* **Multi-Model Comparison**: Test multiple LLMs simultaneously across the same tasks and inputs. Compare performance between GPT-4o, Claude, Llama, Groq, Cerebras, and other leading models in parallel to identify the best fit for your specific use case.

* **Statistical Rigor**: Configure multiple iterations with consistent inputs to measure reliability and performance variance. This helps identify models that not only perform well but do so consistently across runs.

* **Real-World Validation**: Use your actual crew inputs and scenarios rather than synthetic benchmarks. The platform allows you to test with your specific industry context, company information, and real use cases for more accurate evaluation.

* **Comprehensive Analytics**: Access detailed performance metrics, execution times, and cost analysis across all tested models. This enables data-driven decision making rather than relying on general model reputation or theoretical capabilities.

* **Team Collaboration**: Share testing results and model performance data across your team, enabling collaborative decision-making and consistent model selection strategies across projects.

Go to [app.crewai.com](https://app.crewai.com) to get started!

<Info>
  The Enterprise platform transforms model selection from guesswork into a data-driven process, enabling you to validate the principles in this guide with your actual use cases and requirements.
</Info>

## Key Principles Summary

<CardGroup cols={2}>
  <Card title="Task-Driven Selection" icon="bullseye">
    Choose models based on what the task actually requires, not theoretical capabilities or general reputation.
  </Card>

  <Card title="Capability Matching" icon="puzzle-piece">
    Align model strengths with agent roles and responsibilities for optimal performance.
  </Card>

  <Card title="Strategic Consistency" icon="link">
    Maintain coherent model selection strategy across related components and workflows.
  </Card>

  <Card title="Practical Testing" icon="flask">
    Validate choices through real-world usage rather than benchmarks alone.
  </Card>

  <Card title="Iterative Improvement" icon="arrow-up">
    Start simple and optimize based on actual performance and needs.
  </Card>

  <Card title="Operational Balance" icon="scale-balanced">
    Balance performance requirements with cost and complexity constraints.
  </Card>
</CardGroup>

<Check>
  Remember: The best LLM choice is the one that consistently delivers the results you need within your operational constraints. Focus on understanding your requirements first, then select models that best match those needs.
</Check>

## Current Model Landscape (June 2025)

<Warning>
  **Snapshot in Time**: The following model rankings represent current leaderboard standings as of June 2025, compiled from [LMSys Arena](https://arena.lmsys.org/), [Artificial Analysis](https://artificialanalysis.ai/), and other leading benchmarks. LLM performance, availability, and pricing change rapidly. Always conduct your own evaluations with your specific use cases and data.
</Warning>

### Leading Models by Category

The tables below show a representative sample of current top-performing models across different categories, with guidance on their suitability for CrewAI agents:

<Note>
  These tables/metrics showcase selected leading models in each category and are not exhaustive. Many excellent models exist beyond those listed here. The goal is to illustrate the types of capabilities to look for rather than provide a complete catalog.
</Note>

<Tabs>
  <Tab title="Reasoning & Planning">
    **Best for Manager LLMs and Complex Analysis**

    | Model                      | Intelligence Score | Cost (\$/M tokens) | Speed    | Best Use in CrewAI                                  |
    | :------------------------- | :----------------- | :----------------- | :------- | :-------------------------------------------------- |
    | **o3**                     | 70                 | \$17.50            | Fast     | Manager LLM for complex multi-agent coordination    |
    | **Gemini 2.5 Pro**         | 69                 | \$3.44             | Fast     | Strategic planning agents, research coordination    |
    | **DeepSeek R1**            | 68                 | \$0.96             | Moderate | Cost-effective reasoning for budget-conscious crews |
    | **Claude 4 Sonnet**        | 53                 | \$6.00             | Fast     | Analysis agents requiring nuanced understanding     |
    | **Qwen3 235B (Reasoning)** | 62                 | \$2.63             | Moderate | Open-source alternative for reasoning tasks         |

    These models excel at multi-step reasoning and are ideal for agents that need to develop strategies, coordinate other agents, or analyze complex information.
  </Tab>

  <Tab title="Coding & Technical">
    **Best for Development and Tool-Heavy Workflows**

    | Model                 | Coding Performance | Tool Use Score | Cost (\$/M tokens) | Best Use in CrewAI                            |
    | :-------------------- | :----------------- | :------------- | :----------------- | :-------------------------------------------- |
    | **Claude 4 Sonnet**   | Excellent          | 72.7%          | \$6.00             | Primary coding agent, technical documentation |
    | **Claude 4 Opus**     | Excellent          | 72.5%          | \$30.00            | Complex software architecture, code review    |
    | **DeepSeek V3**       | Very Good          | High           | \$0.48             | Cost-effective coding for routine development |
    | **Qwen2.5 Coder 32B** | Very Good          | Medium         | \$0.15             | Budget-friendly coding agent                  |
    | **Llama 3.1 405B**    | Good               | 81.1%          | \$3.50             | Function calling LLM for tool-heavy workflows |

    These models are optimized for code generation, debugging, and technical problem-solving, making them ideal for development-focused crews.
  </Tab>

  <Tab title="Speed & Efficiency">
    **Best for High-Throughput and Real-Time Applications**

    | Model                   | Speed (tokens/s) | Latency (TTFT) | Cost (\$/M tokens) | Best Use in CrewAI                   |
    | :---------------------- | :--------------- | :------------- | :----------------- | :----------------------------------- |
    | **Llama 4 Scout**       | 2,600            | 0.33s          | \$0.27             | High-volume processing agents        |
    | **Gemini 2.5 Flash**    | 376              | 0.30s          | \$0.26             | Real-time response agents            |
    | **DeepSeek R1 Distill** | 383              | Variable       | \$0.04             | Cost-optimized high-speed processing |
    | **Llama 3.3 70B**       | 2,500            | 0.52s          | \$0.60             | Balanced speed and capability        |
    | **Nova Micro**          | High             | 0.30s          | \$0.04             | Simple, fast task execution          |

    These models prioritize speed and efficiency, perfect for agents handling routine operations or requiring quick responses. **Pro tip**: Pairing these models with fast inference providers like Groq can achieve even better performance, especially for open-source models like Llama.
  </Tab>

  <Tab title="Balanced Performance">
    **Best All-Around Models for General Crews**

    | Model                 | Overall Score | Versatility | Cost (\$/M tokens) | Best Use in CrewAI                |
    | :-------------------- | :------------ | :---------- | :----------------- | :-------------------------------- |
    | **GPT-4.1**           | 53            | Excellent   | \$3.50             | General-purpose crew LLM          |
    | **Claude 3.7 Sonnet** | 48            | Very Good   | \$6.00             | Balanced reasoning and creativity |
    | **Gemini 2.0 Flash**  | 48            | Good        | \$0.17             | Cost-effective general use        |
    | **Llama 4 Maverick**  | 51            | Good        | \$0.37             | Open-source general purpose       |
    | **Qwen3 32B**         | 44            | Good        | \$1.23             | Budget-friendly versatility       |

    These models offer good performance across multiple dimensions, suitable for crews with diverse task requirements.
  </Tab>
</Tabs>

### Selection Framework for Current Models

<AccordionGroup>
  <Accordion title="High-Performance Crews" icon="rocket">
    **When performance is the priority**: Use top-tier models like **o3**, **Gemini 2.5 Pro**, or **Claude 4 Sonnet** for manager LLMs and critical agents. These models excel at complex reasoning and coordination but come with higher costs.

    **Strategy**: Implement a multi-model approach where premium models handle strategic thinking while efficient models handle routine operations.
  </Accordion>

  <Accordion title="Cost-Conscious Crews" icon="dollar-sign">
    **When budget is a primary constraint**: Focus on models like **DeepSeek R1**, **Llama 4 Scout**, or **Gemini 2.0 Flash**. These provide strong performance at significantly lower costs.

    **Strategy**: Use cost-effective models for most agents, reserving premium models only for the most critical decision-making roles.
  </Accordion>

  <Accordion title="Specialized Workflows" icon="screwdriver-wrench">
    **For specific domain expertise**: Choose models optimized for your primary use case. **Claude 4** series for coding, **Gemini 2.5 Pro** for research, **Llama 405B** for function calling.

    **Strategy**: Select models based on your crew's primary function, ensuring the core capability aligns with model strengths.
  </Accordion>

  <Accordion title="Enterprise & Privacy" icon="shield">
    **For data-sensitive operations**: Consider open-source models like **Llama 4** series, **DeepSeek V3**, or **Qwen3** that can be deployed locally while maintaining competitive performance.

    **Strategy**: Deploy open-source models on private infrastructure, accepting potential performance trade-offs for data control.
  </Accordion>
</AccordionGroup>

### Key Considerations for Model Selection

* **Performance Trends**: The current landscape shows strong competition between reasoning-focused models (o3, Gemini 2.5 Pro) and balanced models (Claude 4, GPT-4.1). Specialized models like DeepSeek R1 offer excellent cost-performance ratios.

* **Speed vs. Intelligence Trade-offs**: Models like Llama 4 Scout prioritize speed (2,600 tokens/s) while maintaining reasonable intelligence, whereas models like o3 maximize reasoning capability at the cost of speed and price.

* **Open Source Viability**: The gap between open-source and proprietary models continues to narrow, with models like Llama 4 Maverick and DeepSeek V3 offering competitive performance at attractive price points. Fast inference providers particularly shine with open-source models, often delivering better speed-to-cost ratios than proprietary alternatives.

<Info>
  **Testing is Essential**: Leaderboard rankings provide general guidance, but your specific use case, prompting style, and evaluation criteria may produce different results. Always test candidate models with your actual tasks and data before making final decisions.
</Info>

### Practical Implementation Strategy

<Steps>
  <Step title="Start with Proven Models">
    Begin with well-established models like **GPT-4.1**, **Claude 3.7 Sonnet**, or **Gemini 2.0 Flash** that offer good performance across multiple dimensions and have extensive real-world validation.
  </Step>

  <Step title="Identify Specialized Needs">
    Determine if your crew has specific requirements (coding, reasoning, speed) that would benefit from specialized models like **Claude 4 Sonnet** for development or **o3** for complex analysis. For speed-critical applications, consider fast inference providers like **Groq** alongside model selection.
  </Step>

  <Step title="Implement Multi-Model Strategy">
    Use different models for different agents based on their roles. High-capability models for managers and complex tasks, efficient models for routine operations.
  </Step>

  <Step title="Monitor and Optimize">
    Track performance metrics relevant to your use case and be prepared to adjust model selections as new models are released or pricing changes.
  </Step>
</Steps>


# Using Multimodal Agents
Source: https://docs.crewai.com/en/learn/multimodal-agents

Learn how to enable and use multimodal capabilities in your agents for processing images and other non-text content within the CrewAI framework.

## Using Multimodal Agents

CrewAI supports multimodal agents that can process both text and non-text content like images. This guide will show you how to enable and use multimodal capabilities in your agents.

### Enabling Multimodal Capabilities

To create a multimodal agent, simply set the `multimodal` parameter to `True` when initializing your agent:

```python
from crewai import Agent

agent = Agent(
    role="Image Analyst",
    goal="Analyze and extract insights from images",
    backstory="An expert in visual content interpretation with years of experience in image analysis",
    multimodal=True  # This enables multimodal capabilities
)
```

When you set `multimodal=True`, the agent is automatically configured with the necessary tools for handling non-text content, including the `AddImageTool`.

### Working with Images

The multimodal agent comes pre-configured with the `AddImageTool`, which allows it to process images. You don't need to manually add this tool - it's automatically included when you enable multimodal capabilities.

Here's a complete example showing how to use a multimodal agent to analyze an image:

```python
from crewai import Agent, Task, Crew

# Create a multimodal agent
image_analyst = Agent(
    role="Product Analyst",
    goal="Analyze product images and provide detailed descriptions",
    backstory="Expert in visual product analysis with deep knowledge of design and features",
    multimodal=True
)

# Create a task for image analysis
task = Task(
    description="Analyze the product image at https://example.com/product.jpg and provide a detailed description",
    expected_output="A detailed description of the product image",
    agent=image_analyst
)

# Create and run the crew
crew = Crew(
    agents=[image_analyst],
    tasks=[task]
)

result = crew.kickoff()
```

### Advanced Usage with Context

You can provide additional context or specific questions about the image when creating tasks for multimodal agents. The task description can include specific aspects you want the agent to focus on:

```python
from crewai import Agent, Task, Crew

# Create a multimodal agent for detailed analysis
expert_analyst = Agent(
    role="Visual Quality Inspector",
    goal="Perform detailed quality analysis of product images",
    backstory="Senior quality control expert with expertise in visual inspection",
    multimodal=True  # AddImageTool is automatically included
)

# Create a task with specific analysis requirements
inspection_task = Task(
    description="""
    Analyze the product image at https://example.com/product.jpg with focus on:
    1. Quality of materials
    2. Manufacturing defects
    3. Compliance with standards
    Provide a detailed report highlighting any issues found.
    """,
    expected_output="A detailed report highlighting any issues found",
    agent=expert_analyst
)

# Create and run the crew
crew = Crew(
    agents=[expert_analyst],
    tasks=[inspection_task]
)

result = crew.kickoff()
```

### Tool Details

When working with multimodal agents, the `AddImageTool` is automatically configured with the following schema:

```python
class AddImageToolSchema:
    image_url: str  # Required: The URL or path of the image to process
    action: Optional[str] = None  # Optional: Additional context or specific questions about the image
```

The multimodal agent will automatically handle the image processing through its built-in tools, allowing it to:

* Access images via URLs or local file paths
* Process image content with optional context or specific questions
* Provide analysis and insights based on the visual information and task requirements

### Best Practices

When working with multimodal agents, keep these best practices in mind:

1. **Image Access**
   * Ensure your images are accessible via URLs that the agent can reach
   * For local images, consider hosting them temporarily or using absolute file paths
   * Verify that image URLs are valid and accessible before running tasks

2. **Task Description**
   * Be specific about what aspects of the image you want the agent to analyze
   * Include clear questions or requirements in the task description
   * Consider using the optional `action` parameter for focused analysis

3. **Resource Management**
   * Image processing may require more computational resources than text-only tasks
   * Some language models may require base64 encoding for image data
   * Consider batch processing for multiple images to optimize performance

4. **Environment Setup**
   * Verify that your environment has the necessary dependencies for image processing
   * Ensure your language model supports multimodal capabilities
   * Test with small images first to validate your setup

5. **Error Handling**
   * Implement proper error handling for image loading failures
   * Have fallback strategies for when image processing fails
   * Monitor and log image processing operations for debugging


# Overview
Source: https://docs.crewai.com/en/learn/overview

Learn how to build, customize, and optimize your CrewAI applications with comprehensive guides and tutorials

## Learn CrewAI

This section provides comprehensive guides and tutorials to help you master CrewAI, from basic concepts to advanced techniques. Whether you're just getting started or looking to optimize your existing implementations, these resources will guide you through every aspect of building powerful AI agent workflows.

## Getting Started Guides

### Core Concepts

<CardGroup cols={2}>
  <Card title="Sequential Process" icon="list-ol" href="/en/learn/sequential-process">
    Learn how to execute tasks in a sequential order for structured workflows.
  </Card>

  <Card title="Hierarchical Process" icon="sitemap" href="/en/learn/hierarchical-process">
    Implement hierarchical task execution with manager agents overseeing workflows.
  </Card>

  <Card title="Conditional Tasks" icon="code-branch" href="/en/learn/conditional-tasks">
    Create dynamic workflows with conditional task execution based on outcomes.
  </Card>

  <Card title="Async Kickoff" icon="bolt" href="/en/learn/kickoff-async">
    Execute crews asynchronously for improved performance and concurrency.
  </Card>
</CardGroup>

### Agent Development

<CardGroup cols={2}>
  <Card title="Customizing Agents" icon="user-gear" href="/en/learn/customizing-agents">
    Learn how to customize agent behavior, roles, and capabilities.
  </Card>

  <Card title="Coding Agents" icon="code" href="/en/learn/coding-agents">
    Build agents that can write, execute, and debug code automatically.
  </Card>

  <Card title="Multimodal Agents" icon="images" href="/en/learn/multimodal-agents">
    Create agents that can process text, images, and other media types.
  </Card>

  <Card title="Custom Manager Agent" icon="user-tie" href="/en/learn/custom-manager-agent">
    Implement custom manager agents for complex hierarchical workflows.
  </Card>
</CardGroup>

## Advanced Features

### Workflow Control

<CardGroup cols={2}>
  <Card title="Human in the Loop" icon="user-check" href="/en/learn/human-in-the-loop">
    Integrate human oversight and intervention into agent workflows.
  </Card>

  <Card title="Human Input on Execution" icon="hand-paper" href="/en/learn/human-input-on-execution">
    Allow human input during task execution for dynamic decision making.
  </Card>

  <Card title="Replay Tasks" icon="rotate-left" href="/en/learn/replay-tasks-from-latest-crew-kickoff">
    Replay and resume tasks from previous crew executions.
  </Card>

  <Card title="Kickoff for Each" icon="repeat" href="/en/learn/kickoff-for-each">
    Execute crews multiple times with different inputs efficiently.
  </Card>
</CardGroup>

### Customization & Integration

<CardGroup cols={2}>
  <Card title="Custom LLM" icon="brain" href="/en/learn/custom-llm">
    Integrate custom language models and providers with CrewAI.
  </Card>

  <Card title="LLM Connections" icon="link" href="/en/learn/llm-connections">
    Configure and manage connections to various LLM providers.
  </Card>

  <Card title="Create Custom Tools" icon="wrench" href="/en/learn/create-custom-tools">
    Build custom tools to extend agent capabilities.
  </Card>

  <Card title="Using Annotations" icon="at" href="/en/learn/using-annotations">
    Use Python annotations for cleaner, more maintainable code.
  </Card>
</CardGroup>

## Specialized Applications

### Content & Media

<CardGroup cols={2}>
  <Card title="DALL-E Image Generation" icon="image" href="/en/learn/dalle-image-generation">
    Generate images using DALL-E integration with your agents.
  </Card>

  <Card title="Bring Your Own Agent" icon="user-plus" href="/en/learn/bring-your-own-agent">
    Integrate existing agents and models into CrewAI workflows.
  </Card>
</CardGroup>

### Tool Management

<CardGroup cols={2}>
  <Card title="Force Tool Output as Result" icon="hammer" href="/en/learn/force-tool-output-as-result">
    Configure tools to return their output directly as task results.
  </Card>
</CardGroup>

## Learning Path Recommendations

### For Beginners

1. Start with **Sequential Process** to understand basic workflow execution
2. Learn **Customizing Agents** to create effective agent configurations
3. Explore **Create Custom Tools** to extend functionality
4. Try **Human in the Loop** for interactive workflows

### For Intermediate Users

1. Master **Hierarchical Process** for complex multi-agent systems
2. Implement **Conditional Tasks** for dynamic workflows
3. Use **Async Kickoff** for performance optimization
4. Integrate **Custom LLM** for specialized models

### For Advanced Users

1. Build **Multimodal Agents** for complex media processing
2. Create **Custom Manager Agents** for sophisticated orchestration
3. Implement **Bring Your Own Agent** for hybrid systems
4. Use **Replay Tasks** for robust error recovery

## Best Practices

### Development

* **Start Simple**: Begin with basic sequential workflows before adding complexity
* **Test Incrementally**: Test each component before integrating into larger systems
* **Use Annotations**: Leverage Python annotations for cleaner, more maintainable code
* **Custom Tools**: Build reusable tools that can be shared across different agents

### Production

* **Error Handling**: Implement robust error handling and recovery mechanisms
* **Performance**: Use async execution and optimize LLM calls for better performance
* **Monitoring**: Integrate observability tools to track agent performance
* **Human Oversight**: Include human checkpoints for critical decisions

### Optimization

* **Resource Management**: Monitor and optimize token usage and API costs
* **Workflow Design**: Design workflows that minimize unnecessary LLM calls
* **Tool Efficiency**: Create efficient tools that provide maximum value with minimal overhead
* **Iterative Improvement**: Use feedback and metrics to continuously improve agent performance

## Getting Help

* **Documentation**: Each guide includes detailed examples and explanations
* **Community**: Join the [CrewAI Forum](https://community.crewai.com) for discussions and support
* **Examples**: Check the Examples section for complete working implementations
* **Support**: Contact [support@crewai.com](mailto:support@crewai.com) for technical assistance

Start with the guides that match your current needs and gradually explore more advanced topics as you become comfortable with the fundamentals.


# Replay Tasks from Latest Crew Kickoff
Source: https://docs.crewai.com/en/learn/replay-tasks-from-latest-crew-kickoff

Replay tasks from the latest crew.kickoff(...)

## Introduction

CrewAI provides the ability to replay from a task specified from the latest crew kickoff. This feature is particularly useful when you've finished a kickoff and may want to retry certain tasks or don't need to refetch data over and your agents already have the context saved from the kickoff execution so you just need to replay the tasks you want to.

<Note>
  You must run `crew.kickoff()` before you can replay a task.
  Currently, only the latest kickoff is supported, so if you use `kickoff_for_each`, it will only allow you to replay from the most recent crew run.
</Note>

Here's an example of how to replay from a task:

### Replaying from Specific Task Using the CLI

To use the replay feature, follow these steps:

<Steps>
  <Step title="Open your terminal or command prompt." />

  <Step title="Navigate to the directory where your CrewAI project is located." />

  <Step title="Run the following commands:">
    To view the latest kickoff task\_ids use:

    ```shell
    crewai log-tasks-outputs
    ```

    Once you have your `task_id` to replay, use:

    ```shell
    crewai replay -t <task_id>
    ```
  </Step>
</Steps>

<Note>
  Ensure `crewai` is installed and configured correctly in your development environment.
</Note>

### Replaying from a Task Programmatically

To replay from a task programmatically, use the following steps:

<Steps>
  <Step title="Specify the `task_id` and input parameters for the replay process.">
    Specify the `task_id` and input parameters for the replay process.
  </Step>

  <Step title="Execute the replay command within a try-except block to handle potential errors.">
    Execute the replay command within a try-except block to handle potential errors.

    <CodeGroup>
      ```python Code
        def replay():
        """
        Replay the crew execution from a specific task.
        """
        task_id = '<task_id>'
        inputs = {"topic": "CrewAI Training"}  # This is optional; you can pass in the inputs you want to replay; otherwise, it uses the previous kickoff's inputs.
        try:
            YourCrewName_Crew().crew().replay(task_id=task_id, inputs=inputs)

        except subprocess.CalledProcessError as e:
            raise Exception(f"An error occurred while replaying the crew: {e}")

        except Exception as e:
            raise Exception(f"An unexpected error occurred: {e}")
      ```
    </CodeGroup>
  </Step>
</Steps>

## Conclusion

With the above enhancements and detailed functionality, replaying specific tasks in CrewAI has been made more efficient and robust.
Ensure you follow the commands and steps precisely to make the most of these features.


# Sequential Processes
Source: https://docs.crewai.com/en/learn/sequential-process

A comprehensive guide to utilizing the sequential processes for task execution in CrewAI projects.

## Introduction

CrewAI offers a flexible framework for executing tasks in a structured manner, supporting both sequential and hierarchical processes.
This guide outlines how to effectively implement these processes to ensure efficient task execution and project completion.

## Sequential Process Overview

The sequential process ensures tasks are executed one after the other, following a linear progression.
This approach is ideal for projects requiring tasks to be completed in a specific order.

### Key Features

* **Linear Task Flow**: Ensures orderly progression by handling tasks in a predetermined sequence.
* **Simplicity**: Best suited for projects with clear, step-by-step tasks.
* **Easy Monitoring**: Facilitates easy tracking of task completion and project progress.

## Implementing the Sequential Process

To use the sequential process, assemble your crew and define tasks in the order they need to be executed.

```python Code
from crewai import Crew, Process, Agent, Task, TaskOutput, CrewOutput

# Define your agents
researcher = Agent(
  role='Researcher',
  goal='Conduct foundational research',
  backstory='An experienced researcher with a passion for uncovering insights'
)
analyst = Agent(
  role='Data Analyst',
  goal='Analyze research findings',
  backstory='A meticulous analyst with a knack for uncovering patterns'
)
writer = Agent(
  role='Writer',
  goal='Draft the final report',
  backstory='A skilled writer with a talent for crafting compelling narratives'
)

# Define your tasks
research_task = Task(
  description='Gather relevant data...',
  agent=researcher,
  expected_output='Raw Data'
)
analysis_task = Task(
  description='Analyze the data...',
  agent=analyst,
  expected_output='Data Insights'
)
writing_task = Task(
  description='Compose the report...',
  agent=writer,
  expected_output='Final Report'
)

# Form the crew with a sequential process
report_crew = Crew(
  agents=[researcher, analyst, writer],
  tasks=[research_task, analysis_task, writing_task],
  process=Process.sequential
)

# Execute the crew
result = report_crew.kickoff()

# Accessing the type-safe output
task_output: TaskOutput = result.tasks[0].output
crew_output: CrewOutput = result.output
```

### Note:

Each task in a sequential process **must** have an agent assigned. Ensure that every `Task` includes an `agent` parameter.

### Workflow in Action

1. **Initial Task**: In a sequential process, the first agent completes their task and signals completion.
2. **Subsequent Tasks**: Agents pick up their tasks based on the process type, with outcomes of preceding tasks or directives guiding their execution.
3. **Completion**: The process concludes once the final task is executed, leading to project completion.

## Advanced Features

### Task Delegation

In sequential processes, if an agent has `allow_delegation` set to `True`, they can delegate tasks to other agents in the crew.
This feature is automatically set up when there are multiple agents in the crew.

### Asynchronous Execution

Tasks can be executed asynchronously, allowing for parallel processing when appropriate.
To create an asynchronous task, set `async_execution=True` when defining the task.

### Memory and Caching

CrewAI supports both memory and caching features:

* **Memory**: Enable by setting `memory=True` when creating the Crew. This allows agents to retain information across tasks.
* **Caching**: By default, caching is enabled. Set `cache=False` to disable it.

### Callbacks

You can set callbacks at both the task and step level:

* `task_callback`: Executed after each task completion.
* `step_callback`: Executed after each step in an agent's execution.

### Usage Metrics

CrewAI tracks token usage across all tasks and agents. You can access these metrics after execution.

## Best Practices for Sequential Processes

1. **Order Matters**: Arrange tasks in a logical sequence where each task builds upon the previous one.
2. **Clear Task Descriptions**: Provide detailed descriptions for each task to guide the agents effectively.
3. **Appropriate Agent Selection**: Match agents' skills and roles to the requirements of each task.
4. **Use Context**: Leverage the context from previous tasks to inform subsequent ones.

This updated documentation ensures that details accurately reflect the latest changes in the codebase and clearly describes how to leverage new features and configurations.
The content is kept simple and direct to ensure easy understanding.


# Using Annotations in crew.py
Source: https://docs.crewai.com/en/learn/using-annotations

Learn how to use annotations to properly structure agents, tasks, and components in CrewAI

This guide explains how to use annotations to properly reference **agents**, **tasks**, and other components in the `crew.py` file.

## Introduction

Annotations in the CrewAI framework are used to decorate classes and methods, providing metadata and functionality to various components of your crew. These annotations help in organizing and structuring your code, making it more readable and maintainable.

## Available Annotations

The CrewAI framework provides the following annotations:

* `@CrewBase`: Used to decorate the main crew class.
* `@agent`: Decorates methods that define and return Agent objects.
* `@task`: Decorates methods that define and return Task objects.
* `@crew`: Decorates the method that creates and returns the Crew object.
* `@llm`: Decorates methods that initialize and return Language Model objects.
* `@tool`: Decorates methods that initialize and return Tool objects.
* `@callback`: Used for defining callback methods.
* `@output_json`: Used for methods that output JSON data.
* `@output_pydantic`: Used for methods that output Pydantic models.
* `@cache_handler`: Used for defining cache handling methods.

## Usage Examples

Let's go through examples of how to use these annotations:

### 1. Crew Base Class

```python
@CrewBase
class LinkedinProfileCrew():
    """LinkedinProfile crew"""
    agents_config = 'config/agents.yaml'
    tasks_config = 'config/tasks.yaml'
```

The `@CrewBase` annotation is used to decorate the main crew class. This class typically contains configurations and methods for creating agents, tasks, and the crew itself.

### 2. Tool Definition

```python
@tool
def myLinkedInProfileTool(self):
    return LinkedInProfileTool()
```

The `@tool` annotation is used to decorate methods that return tool objects. These tools can be used by agents to perform specific tasks.

### 3. LLM Definition

```python
@llm
def groq_llm(self):
    api_key = os.getenv('api_key')
    return ChatGroq(api_key=api_key, temperature=0, model_name="mixtral-8x7b-32768")
```

The `@llm` annotation is used to decorate methods that initialize and return Language Model objects. These LLMs are used by agents for natural language processing tasks.

### 4. Agent Definition

```python
@agent
def researcher(self) -> Agent:
    return Agent(
        config=self.agents_config['researcher']
    )
```

The `@agent` annotation is used to decorate methods that define and return Agent objects.

### 5. Task Definition

```python
@task
def research_task(self) -> Task:
    return Task(
        config=self.tasks_config['research_linkedin_task'],
        agent=self.researcher()
    )
```

The `@task` annotation is used to decorate methods that define and return Task objects. These methods specify the task configuration and the agent responsible for the task.

### 6. Crew Creation

```python
@crew
def crew(self) -> Crew:
    """Creates the LinkedinProfile crew"""
    return Crew(
        agents=self.agents,
        tasks=self.tasks,
        process=Process.sequential,
        verbose=True
    )
```

The `@crew` annotation is used to decorate the method that creates and returns the `Crew` object. This method assembles all the components (agents and tasks) into a functional crew.

## YAML Configuration

The agent configurations are typically stored in a YAML file. Here's an example of how the `agents.yaml` file might look for the researcher agent:

```yaml
researcher:
    role: >
        LinkedIn Profile Senior Data Researcher
    goal: >
        Uncover detailed LinkedIn profiles based on provided name {name} and domain {domain}
        Generate a Dall-E image based on domain {domain}
    backstory: >
        You're a seasoned researcher with a knack for uncovering the most relevant LinkedIn profiles.
        Known for your ability to navigate LinkedIn efficiently, you excel at gathering and presenting
        professional information clearly and concisely.
    allow_delegation: False
    verbose: True
    llm: groq_llm
    tools:
        - myLinkedInProfileTool
        - mySerperDevTool
        - myDallETool
```

This YAML configuration corresponds to the researcher agent defined in the `LinkedinProfileCrew` class. The configuration specifies the agent's role, goal, backstory, and other properties such as the LLM and tools it uses.

Note how the `llm` and `tools` in the YAML file correspond to the methods decorated with `@llm` and `@tool` in the Python class.

## Best Practices

* **Consistent Naming**: Use clear and consistent naming conventions for your methods. For example, agent methods could be named after their roles (e.g., researcher, reporting\_analyst).
* **Environment Variables**: Use environment variables for sensitive information like API keys.
* **Flexibility**: Design your crew to be flexible by allowing easy addition or removal of agents and tasks.
* **YAML-Code Correspondence**: Ensure that the names and structures in your YAML files correspond correctly to the decorated methods in your Python code.

By following these guidelines and properly using annotations, you can create well-structured and maintainable crews using the CrewAI framework.


# Connecting to Multiple MCP Servers
Source: https://docs.crewai.com/en/mcp/multiple-servers

Learn how to use MCPServerAdapter in CrewAI to connect to multiple MCP servers simultaneously and aggregate their tools.

## Overview

`MCPServerAdapter` in `crewai-tools` allows you to connect to multiple MCP servers concurrently. This is useful when your agents need to access tools distributed across different services or environments. The adapter aggregates tools from all specified servers, making them available to your CrewAI agents.

## Configuration

To connect to multiple servers, you provide a list of server parameter dictionaries to `MCPServerAdapter`. Each dictionary in the list should define the parameters for one MCP server.

Supported transport types for each server in the list include `stdio`, `sse`, and `streamable-http`.

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter
from mcp import StdioServerParameters # Needed for Stdio example

# Define parameters for multiple MCP servers
server_params_list = [
    # Streamable HTTP Server
    {
        "url": "http://localhost:8001/mcp",
        "transport": "streamable-http"
    },
    # SSE Server
    {
        "url": "http://localhost:8000/sse",
        "transport": "sse"
    },
    # StdIO Server
    StdioServerParameters(
        command="python3",
        args=["servers/your_stdio_server.py"],
        env={"UV_PYTHON": "3.12", **os.environ},
    )
]

try:
    with MCPServerAdapter(server_params_list) as aggregated_tools:
        print(f"Available aggregated tools: {[tool.name for tool in aggregated_tools]}")

        multi_server_agent = Agent(
            role="Versatile Assistant",
            goal="Utilize tools from local Stdio, remote SSE, and remote HTTP MCP servers.",
            backstory="An AI agent capable of leveraging a diverse set of tools from multiple sources.",
            tools=aggregated_tools, # All tools are available here
            verbose=True,
        )

        ... # Your other agent, tasks, and crew code here

except Exception as e:
    print(f"Error connecting to or using multiple MCP servers (Managed): {e}")
    print("Ensure all MCP servers are running and accessible with correct configurations.")

```

## Connection Management

When using the context manager (`with` statement), `MCPServerAdapter` handles the lifecycle (start and stop) of all connections to the configured MCP servers. This simplifies resource management and ensures that all connections are properly closed when the context is exited.


# MCP Servers as Tools in CrewAI
Source: https://docs.crewai.com/en/mcp/overview

Learn how to integrate MCP servers as tools in your CrewAI agents using the `crewai-tools` library.

## Overview

The [Model Context Protocol](https://modelcontextprotocol.io/introduction) (MCP) provides a standardized way for AI agents to provide context to LLMs by communicating with external services, known as MCP Servers.
The `crewai-tools` library extends CrewAI's capabilities by allowing you to seamlessly integrate tools from these MCP servers into your agents.
This gives your crews access to a vast ecosystem of functionalities.

We currently support the following transport mechanisms:

* **Stdio**: for local servers (communication via standard input/output between processes on the same machine)
* **Server-Sent Events (SSE)**: for remote servers (unidirectional, real-time data streaming from server to client over HTTP)
* **Streamable HTTP**: for remote servers (flexible, potentially bi-directional communication over HTTP, often utilizing SSE for server-to-client streams)

## Video Tutorial

Watch this video tutorial for a comprehensive guide on MCP integration with CrewAI:

<iframe width="100%" height="400" src="https://www.youtube.com/embed/TpQ45lAZh48" title="CrewAI MCP Integration Guide" frameborder="0" style={{ borderRadius: '10px' }} allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

## Installation

Before you start using MCP with `crewai-tools`, you need to install the `mcp` extra `crewai-tools` dependency with the following command:

```shell
uv pip install 'crewai-tools[mcp]'
```

## Key Concepts & Getting Started

The `MCPServerAdapter` class from `crewai-tools` is the primary way to connect to an MCP server and make its tools available to your CrewAI agents. It supports different transport mechanisms and simplifies connection management.

Using a Python context manager (`with` statement) is the **recommended approach** for `MCPServerAdapter`. It automatically handles starting and stopping the connection to the MCP server.

```python
from crewai import Agent
from crewai_tools import MCPServerAdapter
from mcp import StdioServerParameters # For Stdio Server

# Example server_params (choose one based on your server type):
# 1. Stdio Server:
server_params=StdioServerParameters(
    command="python3",
    args=["servers/your_server.py"],
    env={"UV_PYTHON": "3.12", **os.environ},
)

# 2. SSE Server:
server_params = {
    "url": "http://localhost:8000/sse",
    "transport": "sse"
}

# 3. Streamable HTTP Server:
server_params = {
    "url": "http://localhost:8001/mcp",
    "transport": "streamable-http"
}

# Example usage (uncomment and adapt once server_params is set):
with MCPServerAdapter(server_params) as mcp_tools:
    print(f"Available tools: {[tool.name for tool in mcp_tools]}")

    my_agent = Agent(
        role="MCP Tool User",
        goal="Utilize tools from an MCP server.",
        backstory="I can connect to MCP servers and use their tools.",
        tools=mcp_tools, # Pass the loaded tools to your agent
        reasoning=True,
        verbose=True
    )
    # ... rest of your crew setup ...
```

This general pattern shows how to integrate tools. For specific examples tailored to each transport, refer to the detailed guides below.

## Filtering Tools

There are two ways to filter tools:

1. Accessing a specific tool using dictionary-style indexing.
2. Pass a list of tool names to the `MCPServerAdapter` constructor.

### Accessing a specific tool using dictionary-style indexing.

```python
with MCPServerAdapter(server_params) as mcp_tools:
    print(f"Available tools: {[tool.name for tool in mcp_tools]}")

    my_agent = Agent(
        role="MCP Tool User",
        goal="Utilize tools from an MCP server.",
        backstory="I can connect to MCP servers and use their tools.",
        tools=[mcp_tools["tool_name"]], # Pass the loaded tools to your agent
        reasoning=True,
        verbose=True
    )
    # ... rest of your crew setup ...
```

### Pass a list of tool names to the `MCPServerAdapter` constructor.

```python
with MCPServerAdapter(server_params, "tool_name") as mcp_tools:
    print(f"Available tools: {[tool.name for tool in mcp_tools]}")

    my_agent = Agent(
        role="MCP Tool User",
        goal="Utilize tools from an MCP server.",
        backstory="I can connect to MCP servers and use their tools.",
        tools=mcp_tools, # Pass the loaded tools to your agent
        reasoning=True,
        verbose=True
    )
    # ... rest of your crew setup ...
```

## Using with CrewBase

To use MCPServer tools within a CrewBase class, use the `mcp_tools` method. Server configurations should be provided via the mcp\_server\_params attribute. You can pass either a single configuration or a list of multiple server configurations.

```python
@CrewBase
class CrewWithMCP:
  # ... define your agents and tasks config file ...

  mcp_server_params = [
    # Streamable HTTP Server
    {
        "url": "http://localhost:8001/mcp",
        "transport": "streamable-http"
    },
    # SSE Server
    {
        "url": "http://localhost:8000/sse",
        "transport": "sse"
    },
    # StdIO Server
    StdioServerParameters(
        command="python3",
        args=["servers/your_stdio_server.py"],
        env={"UV_PYTHON": "3.12", **os.environ},
    )
  ]

  @agent
  def your_agent(self):
      return Agent(config=self.agents_config["your_agent"], tools=self.get_mcp_tools()) # get all available tools

    # ... rest of your crew setup ...
```

You can filter which tools are available to your agent by passing a list of tool names to the `get_mcp_tools` method.

```python
@agent
def another_agent(self):
    return Agent(
      config=self.agents_config["your_agent"],
      tools=self.get_mcp_tools("tool_1", "tool_2") # get specific tools
    )
```

## Explore MCP Integrations

<CardGroup cols={2}>
  <Card title="Stdio Transport" icon="server" href="/en/mcp/stdio" color="#3B82F6">
    Connect to local MCP servers via standard input/output. Ideal for scripts and local executables.
  </Card>

  <Card title="SSE Transport" icon="wifi" href="/en/mcp/sse" color="#10B981">
    Integrate with remote MCP servers using Server-Sent Events for real-time data streaming.
  </Card>

  <Card title="Streamable HTTP Transport" icon="globe" href="/en/mcp/streamable-http" color="#F59E0B">
    Utilize flexible Streamable HTTP for robust communication with remote MCP servers.
  </Card>

  <Card title="Connecting to Multiple Servers" icon="layer-group" href="/en/mcp/multiple-servers" color="#8B5CF6">
    Aggregate tools from several MCP servers simultaneously using a single adapter.
  </Card>

  <Card title="Security Considerations" icon="lock" href="/en/mcp/security" color="#EF4444">
    Review important security best practices for MCP integration to keep your agents safe.
  </Card>
</CardGroup>

Checkout this repository for full demos and examples of MCP integration with CrewAI! 👇

<Card title="GitHub Repository" icon="github" href="https://github.com/tonykipkemboi/crewai-mcp-demo" target="_blank">
  CrewAI MCP Demo
</Card>

## Staying Safe with MCP

<Warning>
  Always ensure that you trust an MCP Server before using it.
</Warning>

#### Security Warning: DNS Rebinding Attacks

SSE transports can be vulnerable to DNS rebinding attacks if not properly secured.
To prevent this:

1. **Always validate Origin headers** on incoming SSE connections to ensure they come from expected sources
2. **Avoid binding servers to all network interfaces** (0.0.0.0) when running locally - bind only to localhost (127.0.0.1) instead
3. **Implement proper authentication** for all SSE connections

Without these protections, attackers could use DNS rebinding to interact with local MCP servers from remote websites.

For more details, see the [Anthropic's MCP Transport Security docs](https://modelcontextprotocol.io/docs/concepts/transports#security-considerations).

### Limitations

* **Supported Primitives**: Currently, `MCPServerAdapter` primarily supports adapting MCP `tools`.
  Other MCP primitives like `prompts` or `resources` are not directly integrated as CrewAI components through this adapter at this time.
* **Output Handling**: The adapter typically processes the primary text output from an MCP tool (e.g., `.content[0].text`). Complex or multi-modal outputs might require custom handling if not fitting this pattern.


# MCP Security Considerations
Source: https://docs.crewai.com/en/mcp/security

Learn about important security best practices when integrating MCP servers with your CrewAI agents.

## Overview

<Warning>
  The most critical aspect of MCP security is **trust**. You should **only** connect your CrewAI agents to MCP servers that you fully trust.
</Warning>

When integrating external services like MCP (Model Context Protocol) servers into your CrewAI agents, security is paramount.
MCP servers can execute code, access data, or interact with other systems based on the tools they expose.
It's crucial to understand the implications and follow best practices to protect your applications and data.

### Risks

* Execute arbitrary code on the machine where the agent is running (especially with `Stdio` transport if the server can control the command executed).
* Expose sensitive data from your agent or its environment.
* Manipulate your agent's behavior in unintended ways, including making unauthorized API calls on your behalf.
* Hijack your agent's reasoning process through sophisticated prompt injection techniques (see below).

### 1. Trusting MCP Servers

<Warning>
  **Only connect to MCP servers that you trust.**
</Warning>

Before configuring `MCPServerAdapter` to connect to an MCP server, ensure you know:

* **Who operates the server?** Is it a known, reputable service, or an internal server under your control?
* **What tools does it expose?** Understand the capabilities of the tools. Could they be misused if an attacker gained control or if the server itself is malicious?
* **What data does it access or process?** Be aware of any sensitive information that might be sent to or handled by the MCP server.

Avoid connecting to unknown or unverified MCP servers, especially if your agents handle sensitive tasks or data.

### 2. Secure Prompt Injection via Tool Metadata: The "Model Control Protocol" Risk

A significant and subtle risk is the potential for prompt injection through tool metadata. Here's how it works:

1. When your CrewAI agent connects to an MCP server, it typically requests a list of available tools.
2. The MCP server responds with metadata for each tool, including its name, description, and parameter descriptions.
3. Your agent's underlying Language Model (LLM) uses this metadata to understand how and when to use the tools. This metadata is often incorporated into the LLM's system prompt or context.
4. A malicious MCP server can craft its tool metadata (names, descriptions) to include hidden or overt instructions. These instructions can act as a prompt injection, effectively telling your LLM to behave in a certain way, reveal sensitive information, or perform malicious actions.

**Crucially, this attack can occur simply by connecting to a malicious server and listing its tools, even if your agent never explicitly decides to *use* any of those tools.** The mere exposure to the malicious metadata can be enough to compromise the agent's behavior.

**Mitigation:**

* **Extreme Caution with Untrusted Servers:** Reiterate: *Do not connect to MCP servers you do not fully trust.* The risk of metadata injection makes this paramount.

### Stdio Transport Security

Stdio (Standard Input/Output) transport is typically used for local MCP servers running on the same machine as your CrewAI application.

* **Process Isolation**: While generally safer as it doesn't involve network exposure by default, ensure the script or command run by `StdioServerParameters` is from a trusted source and has appropriate file system permissions. A malicious Stdio server script could still harm your local system.
* **Input Sanitization**: If your Stdio server script takes complex inputs derived from agent interactions, ensure the script itself sanitizes these inputs to prevent command injection or other vulnerabilities within the script's logic.
* **Resource Limits**: Be mindful that a local Stdio server process consumes local resources (CPU, memory). Ensure it's well-behaved and won't exhaust system resources.

### Confused Deputy Attacks

The [Confused Deputy Problem](https://en.wikipedia.org/wiki/Confused_deputy_problem) is a classic security vulnerability that can manifest in MCP integrations, especially when an MCP server acts as a proxy to other third-party services (e.g., Google Calendar, GitHub) that use OAuth 2.0 for authorization.

**Scenario:**

1. An MCP server (let's call it `MCP-Proxy`) allows your agent to interact with `ThirdPartyAPI`.
2. `MCP-Proxy` uses its own single, static `client_id` when talking to `ThirdPartyAPI`'s authorization server.
3. You, as the user, legitimately authorize `MCP-Proxy` to access `ThirdPartyAPI` on your behalf. During this, `ThirdPartyAPI`'s auth server might set a cookie in your browser indicating your consent for `MCP-Proxy`'s `client_id`.
4. An attacker crafts a malicious link. This link initiates an OAuth flow with `MCP-Proxy`, but is designed to trick `ThirdPartyAPI`'s auth server.
5. If you click this link, and `ThirdPartyAPI`'s auth server sees your existing consent cookie for `MCP-Proxy`'s `client_id`, it might *skip* asking for your consent again.
6. `MCP-Proxy` might then be tricked into forwarding an authorization code (for `ThirdPartyAPI`) to the attacker, or an MCP authorization code that the attacker can use to impersonate you to `MCP-Proxy`.

**Mitigation (Primarily for MCP Server Developers):**

* MCP proxy servers using static client IDs for downstream services **must** obtain explicit user consent for *each client application or agent* connecting to them *before* initiating an OAuth flow with the third-party service. This means `MCP-Proxy` itself should show a consent screen.

**CrewAI User Implication:**

* Be cautious if an MCP server redirects you for multiple OAuth authentications, especially if it seems unexpected or if the permissions requested are overly broad.
* Prefer MCP servers that clearly delineate their own identity versus the third-party services they might proxy.

### Remote Transport Security (SSE & Streamable HTTP)

When connecting to remote MCP servers via Server-Sent Events (SSE) or Streamable HTTP, standard web security practices are essential.

### SSE Security Considerations

### a. DNS Rebinding Attacks (Especially for SSE)

<Critical>
  **Protect against DNS Rebinding Attacks.**
</Critical>

DNS rebinding allows an attacker-controlled website to bypass the same-origin policy and make requests to servers on the user's local network (e.g., `localhost`) or intranet. This is particularly risky if you run an MCP server locally (e.g., for development) and an agent in a browser-like environment (though less common for typical CrewAI backend setups) or if the MCP server is on an internal network.

**Mitigation Strategies for MCP Server Implementers:**

* **Validate `Origin` and `Host` Headers**: MCP servers (especially SSE ones) should validate the `Origin` and/or `Host` HTTP headers to ensure requests are coming from expected domains/clients.
* **Bind to `localhost` (127.0.0.1)**: When running MCP servers locally for development, bind them to `127.0.0.1` instead of `0.0.0.0`. This prevents them from being accessible from other machines on the network.
* **Authentication**: Require authentication for all connections to your MCP server if it's not intended for public anonymous access.

### b. Use HTTPS

* **Encrypt Data in Transit**: Always use HTTPS (HTTP Secure) for the URLs of remote MCP servers. This encrypts the communication between your CrewAI application and the MCP server, protecting against eavesdropping and man-in-the-middle attacks. `MCPServerAdapter` will respect the scheme (`http` or `https`) provided in the URL.

### c. Token Passthrough (Anti-Pattern)

This is primarily a concern for MCP server developers but understanding it helps in choosing secure servers.

"Token passthrough" is when an MCP server accepts an access token from your CrewAI agent (which might be a token for a *different* service, say `ServiceA`) and simply passes it through to another downstream API (`ServiceB`) without proper validation. Specifically, `ServiceB` (or the MCP server itself) should only accept tokens that were explicitly issued *for them* (i.e., the 'audience' claim in the token matches the server/service).

**Risks:**

* Bypasses security controls (like rate limiting or fine-grained permissions) on the MCP server or the downstream API.
* Breaks audit trails and accountability.
* Allows misuse of stolen tokens.

**Mitigation (For MCP Server Developers):**

* MCP servers **MUST NOT** accept tokens that were not explicitly issued for them. They must validate the token's audience claim.

**CrewAI User Implication:**

* While not directly controllable by the user, this highlights the importance of connecting to well-designed MCP servers that adhere to security best practices.

#### Authentication and Authorization

* **Verify Identity**: If the MCP server provides sensitive tools or access to private data, it MUST implement strong authentication mechanisms to verify the identity of the client (your CrewAI application). This could involve API keys, OAuth tokens, or other standard methods.
* **Principle of Least Privilege**: Ensure the credentials used by `MCPServerAdapter` (if any) have only the necessary permissions to access the required tools.

### d. Input Validation and Sanitization

* **Input Validation is Critical**: MCP servers **must** rigorously validate all inputs received from agents *before* processing them or passing them to tools. This is a primary defense against many common vulnerabilities:
  * **Command Injection:** If a tool constructs shell commands, SQL queries, or other interpreted language statements based on input, the server must meticulously sanitize this input to prevent malicious commands from being injected and executed.
  * **Path Traversal:** If a tool accesses files based on input parameters, the server must validate and sanitize these paths to prevent access to unauthorized files or directories (e.g., by blocking `../` sequences).
  * **Data Type & Range Checks:** Servers must ensure that input data conforms to the expected data types (e.g., string, number, boolean) and falls within acceptable ranges or adheres to defined formats (e.g., regex for URLs).
  * **JSON Schema Validation:** All tool parameters should be strictly validated against their defined JSON schema. This helps catch malformed requests early.
* **Client-Side Awareness**: While server-side validation is paramount, as a CrewAI user, be mindful of the data your agents are constructed to send to MCP tools, especially if interacting with less-trusted or new MCP servers.

### e. Rate Limiting and Resource Management

* **Prevent Abuse**: MCP servers should implement rate limiting to prevent abuse, whether intentional (Denial of Service attacks) or unintentional (e.g., a misconfigured agent making too many requests).
* **Client-Side Retries**: Implement sensible retry logic in your CrewAI tasks if transient network issues or server rate limits are expected, but avoid aggressive retries that could exacerbate server load.

## 4. Secure MCP Server Implementation Advice (For Developers)

If you are developing an MCP server that CrewAI agents might connect to, consider these best practices in addition to the points above:

* **Follow Secure Coding Practices**: Adhere to standard secure coding principles for your chosen language and framework (e.g., OWASP Top 10).
* **Principle of Least Privilege**: Ensure the process running the MCP server (especially for `Stdio`) has only the minimum necessary permissions. Tools themselves should also operate with the least privilege required to perform their function.
* **Dependency Management**: Keep all server-side dependencies, including operating system packages, language runtimes, and third-party libraries, up-to-date to patch known vulnerabilities. Use tools to scan for vulnerable dependencies.
* **Secure Defaults**: Design your server and its tools to be secure by default. For example, features that could be risky should be off by default or require explicit opt-in with clear warnings.
* **Access Control for Tools**: Implement robust mechanisms to control which authenticated and authorized agents or users can access specific tools, especially those that are powerful, sensitive, or incur costs.
* **Secure Error Handling**: Servers should not expose detailed internal error messages, stack traces, or debugging information to the client, as these can reveal internal workings or potential vulnerabilities. Log errors comprehensively on the server-side for diagnostics.
* **Comprehensive Logging and Monitoring**: Implement detailed logging of security-relevant events (e.g., authentication attempts, tool invocations, errors, authorization changes). Monitor these logs for suspicious activity or abuse patterns.
* **Adherence to MCP Authorization Spec**: If implementing authentication and authorization, strictly follow the [MCP Authorization specification](https://modelcontextprotocol.io/specification/draft/basic/authorization) and relevant [OAuth 2.0 security best practices](https://datatracker.ietf.org/doc/html/rfc9700).
* **Regular Security Audits**: If your MCP server handles sensitive data, performs critical operations, or is publicly exposed, consider periodic security audits by qualified professionals.

## 5. Further Reading

For more detailed information on MCP security, refer to the official documentation:

* **[MCP Transport Security](https://modelcontextprotocol.io/docs/concepts/transports#security-considerations)**

By understanding these security considerations and implementing best practices, you can safely leverage the power of MCP servers in your CrewAI projects.
These are by no means exhaustive, but they cover the most common and critical security concerns.
The threats will continue to evolve, so it's important to stay informed and adapt your security measures accordingly.


# SSE Transport
Source: https://docs.crewai.com/en/mcp/sse

Learn how to connect CrewAI to remote MCP servers using Server-Sent Events (SSE) for real-time communication.

## Overview

Server-Sent Events (SSE) provide a standard way for a web server to send updates to a client over a single, long-lived HTTP connection. In the context of MCP, SSE is used for remote servers to stream data (like tool responses) to your CrewAI application in real-time.

## Key Concepts

* **Remote Servers**: SSE is suitable for MCP servers hosted remotely.
* **Unidirectional Stream**: Typically, SSE is a one-way communication channel from server to client.
* **`MCPServerAdapter` Configuration**: For SSE, you'll provide the server's URL and specify the transport type.

## Connecting via SSE

You can connect to an SSE-based MCP server using two main approaches for managing the connection lifecycle:

### 1. Fully Managed Connection (Recommended)

Using a Python context manager (`with` statement) is the recommended approach. It automatically handles establishing and closing the connection to the SSE MCP server.

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter

server_params = {
    "url": "http://localhost:8000/sse", # Replace with your actual SSE server URL
    "transport": "sse"
}

# Using MCPServerAdapter with a context manager
try:
    with MCPServerAdapter(server_params) as tools:
        print(f"Available tools from SSE MCP server: {[tool.name for tool in tools]}")

        # Example: Using a tool from the SSE MCP server
        sse_agent = Agent(
            role="Remote Service User",
            goal="Utilize a tool provided by a remote SSE MCP server.",
            backstory="An AI agent that connects to external services via SSE.",
            tools=tools,
            reasoning=True,
            verbose=True,
        )

        sse_task = Task(
            description="Fetch real-time stock updates for 'AAPL' using an SSE tool.",
            expected_output="The latest stock price for AAPL.",
            agent=sse_agent,
            markdown=True
        )

        sse_crew = Crew(
            agents=[sse_agent],
            tasks=[sse_task],
            verbose=True,
            process=Process.sequential
        )

        if tools: # Only kickoff if tools were loaded
            result = sse_crew.kickoff() # Add inputs={'stock_symbol': 'AAPL'} if tool requires it
            print("\nCrew Task Result (SSE - Managed):\n", result)
        else:
            print("Skipping crew kickoff as tools were not loaded (check server connection).")

except Exception as e:
    print(f"Error connecting to or using SSE MCP server (Managed): {e}")
    print("Ensure the SSE MCP server is running and accessible at the specified URL.")

```

<Note>
  Replace `"http://localhost:8000/sse"` with the actual URL of your SSE MCP server.
</Note>

### 2. Manual Connection Lifecycle

If you need finer-grained control, you can manage the `MCPServerAdapter` connection lifecycle manually.

<Info>
  You **MUST** call `mcp_server_adapter.stop()` to ensure the connection is closed and resources are released. Using a `try...finally` block is highly recommended.
</Info>

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter

server_params = {
    "url": "http://localhost:8000/sse", # Replace with your actual SSE server URL
    "transport": "sse"
}

mcp_server_adapter = None
try:
    mcp_server_adapter = MCPServerAdapter(server_params)
    mcp_server_adapter.start()
    tools = mcp_server_adapter.tools
    print(f"Available tools (manual SSE): {[tool.name for tool in tools]}")

    manual_sse_agent = Agent(
        role="Remote Data Analyst",
        goal="Analyze data fetched from a remote SSE MCP server using manual connection management.",
        backstory="An AI skilled in handling SSE connections explicitly.",
        tools=tools,
        verbose=True
    )

    analysis_task = Task(
        description="Fetch and analyze the latest user activity trends from the SSE server.",
        expected_output="A summary report of user activity trends.",
        agent=manual_sse_agent
    )

    analysis_crew = Crew(
        agents=[manual_sse_agent],
        tasks=[analysis_task],
        verbose=True,
        process=Process.sequential
    )

    result = analysis_crew.kickoff()
    print("\nCrew Task Result (SSE - Manual):\n", result)

except Exception as e:
    print(f"An error occurred during manual SSE MCP integration: {e}")
    print("Ensure the SSE MCP server is running and accessible.")
finally:
    if mcp_server_adapter and mcp_server_adapter.is_connected:
        print("Stopping SSE MCP server connection (manual)...")
        mcp_server_adapter.stop()  # **Crucial: Ensure stop is called**
    elif mcp_server_adapter:
        print("SSE MCP server adapter was not connected. No stop needed or start failed.")

```

## Security Considerations for SSE

<Warning>
  **DNS Rebinding Attacks**: SSE transports can be vulnerable to DNS rebinding attacks if the MCP server is not properly secured. This could allow malicious websites to interact with local or intranet-based MCP servers.
</Warning>

To mitigate this risk:

* MCP server implementations should **validate `Origin` headers** on incoming SSE connections.
* When running local SSE MCP servers for development, **bind only to `localhost` (`127.0.0.1`)** rather than all network interfaces (`0.0.0.0`).
* Implement **proper authentication** for all SSE connections if they expose sensitive tools or data.

For a comprehensive overview of security best practices, please refer to our [Security Considerations](./security.mdx) page and the official [MCP Transport Security documentation](https://modelcontextprotocol.io/docs/concepts/transports#security-considerations).


# Stdio Transport
Source: https://docs.crewai.com/en/mcp/stdio

Learn how to connect CrewAI to local MCP servers using the Stdio (Standard Input/Output) transport mechanism.

## Overview

The Stdio (Standard Input/Output) transport is designed for connecting `MCPServerAdapter` to local MCP servers that communicate over their standard input and output streams. This is typically used when the MCP server is a script or executable running on the same machine as your CrewAI application.

## Key Concepts

* **Local Execution**: Stdio transport manages a locally running process for the MCP server.
* **`StdioServerParameters`**: This class from the `mcp` library is used to configure the command, arguments, and environment variables for launching the Stdio server.

## Connecting via Stdio

You can connect to an Stdio-based MCP server using two main approaches for managing the connection lifecycle:

### 1. Fully Managed Connection (Recommended)

Using a Python context manager (`with` statement) is the recommended approach. It automatically handles starting the MCP server process and stopping it when the context is exited.

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter
from mcp import StdioServerParameters
import os

# Create a StdioServerParameters object
server_params=StdioServerParameters(
    command="python3",
    args=["servers/your_stdio_server.py"],
    env={"UV_PYTHON": "3.12", **os.environ},
)

with MCPServerAdapter(server_params) as tools:
    print(f"Available tools from Stdio MCP server: {[tool.name for tool in tools]}")

    # Example: Using the tools from the Stdio MCP server in a CrewAI Agent
    research_agent = Agent(
        role="Local Data Processor",
        goal="Process data using a local Stdio-based tool.",
        backstory="An AI that leverages local scripts via MCP for specialized tasks.",
        tools=tools,
        reasoning=True,
        verbose=True,
    )

    processing_task = Task(
        description="Process the input data file 'data.txt' and summarize its contents.",
        expected_output="A summary of the processed data.",
        agent=research_agent,
        markdown=True
    )

    data_crew = Crew(
        agents=[research_agent],
        tasks=[processing_task],
        verbose=True,
        process=Process.sequential
    )

    result = data_crew.kickoff()
    print("\nCrew Task Result (Stdio - Managed):\n", result)

```

### 2. Manual Connection Lifecycle

If you need finer-grained control over when the Stdio MCP server process is started and stopped, you can manage the `MCPServerAdapter` lifecycle manually.

<Info>
  You **MUST** call `mcp_server_adapter.stop()` to ensure the server process is terminated and resources are released. Using a `try...finally` block is highly recommended.
</Info>

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter
from mcp import StdioServerParameters
import os

# Create a StdioServerParameters object
stdio_params=StdioServerParameters(
    command="python3",
    args=["servers/your_stdio_server.py"],
    env={"UV_PYTHON": "3.12", **os.environ},
)

mcp_server_adapter = MCPServerAdapter(server_params=stdio_params)
try:
    mcp_server_adapter.start()  # Manually start the connection and server process
    tools = mcp_server_adapter.tools
    print(f"Available tools (manual Stdio): {[tool.name for tool in tools]}")

    # Example: Using the tools with your Agent, Task, Crew setup
    manual_agent = Agent(
        role="Local Task Executor",
        goal="Execute a specific local task using a manually managed Stdio tool.",
        backstory="An AI proficient in controlling local processes via MCP.",
        tools=tools,
        verbose=True
    )

    manual_task = Task(
        description="Execute the 'perform_analysis' command via the Stdio tool.",
        expected_output="Results of the analysis.",
        agent=manual_agent
    )

    manual_crew = Crew(
        agents=[manual_agent],
        tasks=[manual_task],
        verbose=True,
        process=Process.sequential
    )


    result = manual_crew.kickoff() # Actual inputs depend on your tool
    print("\nCrew Task Result (Stdio - Manual):\n", result)

except Exception as e:
    print(f"An error occurred during manual Stdio MCP integration: {e}")
finally:
    if mcp_server_adapter and mcp_server_adapter.is_connected: # Check if connected before stopping
        print("Stopping Stdio MCP server connection (manual)...")
        mcp_server_adapter.stop()  # **Crucial: Ensure stop is called**
    elif mcp_server_adapter: # If adapter exists but not connected (e.g. start failed)
        print("Stdio MCP server adapter was not connected. No stop needed or start failed.")

```

Remember to replace placeholder paths and commands with your actual Stdio server details. The `env` parameter in `StdioServerParameters` can
be used to set environment variables for the server process, which can be useful for configuring its behavior or providing necessary paths (like `PYTHONPATH`).


# Streamable HTTP Transport
Source: https://docs.crewai.com/en/mcp/streamable-http

Learn how to connect CrewAI to remote MCP servers using the flexible Streamable HTTP transport.

## Overview

Streamable HTTP transport provides a flexible way to connect to remote MCP servers. It's often built upon HTTP and can support various communication patterns, including request-response and streaming, sometimes utilizing Server-Sent Events (SSE) for server-to-client streams within a broader HTTP interaction.

## Key Concepts

* **Remote Servers**: Designed for MCP servers hosted remotely.
* **Flexibility**: Can support more complex interaction patterns than plain SSE, potentially including bi-directional communication if the server implements it.
* **`MCPServerAdapter` Configuration**: You'll need to provide the server's base URL for MCP communication and specify `"streamable-http"` as the transport type.

## Connecting via Streamable HTTP

You have two primary methods for managing the connection lifecycle with a Streamable HTTP MCP server:

### 1. Fully Managed Connection (Recommended)

The recommended approach is to use a Python context manager (`with` statement), which handles the connection's setup and teardown automatically.

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter

server_params = {
    "url": "http://localhost:8001/mcp", # Replace with your actual Streamable HTTP server URL
    "transport": "streamable-http"
}

try:
    with MCPServerAdapter(server_params) as tools:
        print(f"Available tools from Streamable HTTP MCP server: {[tool.name for tool in tools]}")

        http_agent = Agent(
            role="HTTP Service Integrator",
            goal="Utilize tools from a remote MCP server via Streamable HTTP.",
            backstory="An AI agent adept at interacting with complex web services.",
            tools=tools,
            verbose=True,
        )

        http_task = Task(
            description="Perform a complex data query using a tool from the Streamable HTTP server.",
            expected_output="The result of the complex data query.",
            agent=http_agent,
        )

        http_crew = Crew(
            agents=[http_agent],
            tasks=[http_task],
            verbose=True,
            process=Process.sequential
        )

        result = http_crew.kickoff()
        print("\nCrew Task Result (Streamable HTTP - Managed):\n", result)

except Exception as e:
    print(f"Error connecting to or using Streamable HTTP MCP server (Managed): {e}")
    print("Ensure the Streamable HTTP MCP server is running and accessible at the specified URL.")

```

**Note:** Replace `"http://localhost:8001/mcp"` with the actual URL of your Streamable HTTP MCP server.

### 2. Manual Connection Lifecycle

For scenarios requiring more explicit control, you can manage the `MCPServerAdapter` connection manually.

<Info>
  It is **critical** to call `mcp_server_adapter.stop()` when you are done to close the connection and free up resources. A `try...finally` block is the safest way to ensure this.
</Info>

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter

server_params = {
    "url": "http://localhost:8001/mcp", # Replace with your actual Streamable HTTP server URL
    "transport": "streamable-http"
}

mcp_server_adapter = None
try:
    mcp_server_adapter = MCPServerAdapter(server_params)
    mcp_server_adapter.start()
    tools = mcp_server_adapter.tools
    print(f"Available tools (manual Streamable HTTP): {[tool.name for tool in tools]}")

    manual_http_agent = Agent(
        role="Advanced Web Service User",
        goal="Interact with an MCP server using manually managed Streamable HTTP connections.",
        backstory="An AI specialist in fine-tuning HTTP-based service integrations.",
        tools=tools,
        verbose=True
    )

    data_processing_task = Task(
        description="Submit data for processing and retrieve results via Streamable HTTP.",
        expected_output="Processed data or confirmation.",
        agent=manual_http_agent
    )

    data_crew = Crew(
        agents=[manual_http_agent],
        tasks=[data_processing_task],
        verbose=True,
        process=Process.sequential
    )

    result = data_crew.kickoff()
    print("\nCrew Task Result (Streamable HTTP - Manual):\n", result)

except Exception as e:
    print(f"An error occurred during manual Streamable HTTP MCP integration: {e}")
    print("Ensure the Streamable HTTP MCP server is running and accessible.")
finally:
    if mcp_server_adapter and mcp_server_adapter.is_connected:
        print("Stopping Streamable HTTP MCP server connection (manual)...")
        mcp_server_adapter.stop()  # **Crucial: Ensure stop is called**
    elif mcp_server_adapter:
        print("Streamable HTTP MCP server adapter was not connected. No stop needed or start failed.")
```

## Security Considerations

When using Streamable HTTP transport, general web security best practices are paramount:

* **Use HTTPS**: Always prefer HTTPS (HTTP Secure) for your MCP server URLs to encrypt data in transit.
* **Authentication**: Implement robust authentication mechanisms if your MCP server exposes sensitive tools or data.
* **Input Validation**: Ensure your MCP server validates all incoming requests and parameters.

For a comprehensive guide on securing your MCP integrations, please refer to our [Security Considerations](./security.mdx) page and the official [MCP Transport Security documentation](https://modelcontextprotocol.io/docs/concepts/transports#security-considerations).


# AgentOps Integration
Source: https://docs.crewai.com/en/observability/agentops

Understanding and logging your agent performance with AgentOps.

# Introduction

Observability is a key aspect of developing and deploying conversational AI agents. It allows developers to understand how their agents are performing,
how their agents are interacting with users, and how their agents use external tools and APIs.
AgentOps is a product independent of CrewAI that provides a comprehensive observability solution for agents.

## AgentOps

[AgentOps](https://agentops.ai/?=crew) provides session replays, metrics, and monitoring for agents.

At a high level, AgentOps gives you the ability to monitor cost, token usage, latency, agent failures, session-wide statistics, and more.
For more info, check out the [AgentOps Repo](https://github.com/AgentOps-AI/agentops).

### Overview

AgentOps provides monitoring for agents in development and production.
It provides a dashboard for tracking agent performance, session replays, and custom reporting.

Additionally, AgentOps provides session drilldowns for viewing Crew agent interactions, LLM calls, and tool usage in real-time.
This feature is useful for debugging and understanding how agents interact with users as well as other agents.

![Overview of a select series of agent session runs](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/agentops-overview.png)
![Overview of session drilldowns for examining agent runs](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/agentops-session.png)
![Viewing a step-by-step agent replay execution graph](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/agentops-replay.png)

### Features

* **LLM Cost Management and Tracking**: Track spend with foundation model providers.
* **Replay Analytics**: Watch step-by-step agent execution graphs.
* **Recursive Thought Detection**: Identify when agents fall into infinite loops.
* **Custom Reporting**: Create custom analytics on agent performance.
* **Analytics Dashboard**: Monitor high-level statistics about agents in development and production.
* **Public Model Testing**: Test your agents against benchmarks and leaderboards.
* **Custom Tests**: Run your agents against domain-specific tests.
* **Time Travel Debugging**: Restart your sessions from checkpoints.
* **Compliance and Security**: Create audit logs and detect potential threats such as profanity and PII leaks.
* **Prompt Injection Detection**: Identify potential code injection and secret leaks.

### Using AgentOps

<Steps>
  <Step title="Create an API Key">
    Create a user API key here: [Create API Key](https://app.agentops.ai/account)
  </Step>

  <Step title="Configure Your Environment">
    Add your API key to your environment variables:

    ```bash
    AGENTOPS_API_KEY=<YOUR_AGENTOPS_API_KEY>
    ```
  </Step>

  <Step title="Install AgentOps">
    Install AgentOps with:

    ```bash
    pip install 'crewai[agentops]'
    ```

    or

    ```bash
    pip install agentops
    ```
  </Step>

  <Step title="Initialize AgentOps">
    Before using `Crew` in your script, include these lines:

    ```python
    import agentops
    agentops.init()
    ```

    This will initiate an AgentOps session as well as automatically track Crew agents. For further info on how to outfit more complex agentic systems,
    check out the [AgentOps documentation](https://docs.agentops.ai) or join the [Discord](https://discord.gg/j4f3KbeH).
  </Step>
</Steps>

### Crew + AgentOps Examples

<CardGroup cols={3}>
  <Card title="Job Posting" color="#F3A78B" href="https://github.com/joaomdmoura/crewAI-examples/tree/main/job-posting" icon="briefcase" iconType="solid">
    Example of a Crew agent that generates job posts.
  </Card>

  <Card title="Markdown Validator" color="#F3A78B" href="https://github.com/joaomdmoura/crewAI-examples/tree/main/markdown_validator" icon="markdown" iconType="solid">
    Example of a Crew agent that validates Markdown files.
  </Card>

  <Card title="Instagram Post" color="#F3A78B" href="https://github.com/joaomdmoura/crewAI-examples/tree/main/instagram_post" icon="square-instagram" iconType="brands">
    Example of a Crew agent that generates Instagram posts.
  </Card>
</CardGroup>

### Further Information

To get started, create an [AgentOps account](https://agentops.ai/?=crew).

For feature requests or bug reports, please reach out to the AgentOps team on the [AgentOps Repo](https://github.com/AgentOps-AI/agentops).

#### Extra links

<a href="https://twitter.com/agentopsai/">🐦 Twitter</a>
<span>  •  </span>
<a href="https://discord.gg/JHPt4C7r">📢 Discord</a>
<span>  •  </span>
<a href="https://app.agentops.ai/?=crew">🖇️ AgentOps Dashboard</a>
<span>  •  </span>
<a href="https://docs.agentops.ai/introduction">📙 Documentation</a>


# Arize Phoenix
Source: https://docs.crewai.com/en/observability/arize-phoenix

Arize Phoenix integration for CrewAI with OpenTelemetry and OpenInference

# Arize Phoenix Integration

This guide demonstrates how to integrate **Arize Phoenix** with **CrewAI** using OpenTelemetry via the [OpenInference](https://github.com/openinference/openinference) SDK. By the end of this guide, you will be able to trace your CrewAI agents and easily debug your agents.

> **What is Arize Phoenix?** [Arize Phoenix](https://phoenix.arize.com) is an LLM observability platform that provides tracing and evaluation for AI applications.

[![Watch a Video Demo of Our Integration with Phoenix](https://storage.googleapis.com/arize-assets/fixtures/setup_crewai.png)](https://www.youtube.com/watch?v=Yc5q3l6F7Ww)

## Get Started

We'll walk through a simple example of using CrewAI and integrating it with Arize Phoenix via OpenTelemetry using OpenInference.

You can also access this guide on [Google Colab](https://colab.research.google.com/github/Arize-ai/phoenix/blob/main/tutorials/tracing/crewai_tracing_tutorial.ipynb).

### Step 1: Install Dependencies

```bash
pip install openinference-instrumentation-crewai crewai crewai-tools arize-phoenix-otel
```

### Step 2: Set Up Environment Variables

Setup Phoenix Cloud API keys and configure OpenTelemetry to send traces to Phoenix. Phoenix Cloud is a hosted version of Arize Phoenix, but it is not required to use this integration.

You can get your free Serper API key [here](https://serper.dev/).

```python
import os
from getpass import getpass

# Get your Phoenix Cloud credentials
PHOENIX_API_KEY = getpass("🔑 Enter your Phoenix Cloud API Key: ")

# Get API keys for services
OPENAI_API_KEY = getpass("🔑 Enter your OpenAI API key: ")
SERPER_API_KEY = getpass("🔑 Enter your Serper API key: ")

# Set environment variables
os.environ["PHOENIX_CLIENT_HEADERS"] = f"api_key={PHOENIX_API_KEY}"
os.environ["PHOENIX_COLLECTOR_ENDPOINT"] = "https://app.phoenix.arize.com" # Phoenix Cloud, change this to your own endpoint if you are using a self-hosted instance
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
os.environ["SERPER_API_KEY"] = SERPER_API_KEY
```

### Step 3: Initialize OpenTelemetry with Phoenix

Initialize the OpenInference OpenTelemetry instrumentation SDK to start capturing traces and send them to Phoenix.

```python
from phoenix.otel import register

tracer_provider = register(
    project_name="crewai-tracing-demo",
    auto_instrument=True,
)
```

### Step 4: Create a CrewAI Application

We'll create a CrewAI application where two agents collaborate to research and write a blog post about AI advancements.

```python
from crewai import Agent, Crew, Process, Task
from crewai_tools import SerperDevTool
from openinference.instrumentation.crewai import CrewAIInstrumentor
from phoenix.otel import register

# setup monitoring for your crew
tracer_provider = register(
    endpoint="http://localhost:6006/v1/traces")
CrewAIInstrumentor().instrument(skip_dep_check=True, tracer_provider=tracer_provider)
search_tool = SerperDevTool()

# Define your agents with roles and goals
researcher = Agent(
    role="Senior Research Analyst",
    goal="Uncover cutting-edge developments in AI and data science",
    backstory="""You work at a leading tech think tank.
    Your expertise lies in identifying emerging trends.
    You have a knack for dissecting complex data and presenting actionable insights.""",
    verbose=True,
    allow_delegation=False,
    # You can pass an optional llm attribute specifying what model you wanna use.
    # llm=ChatOpenAI(model_name="gpt-3.5", temperature=0.7),
    tools=[search_tool],
)
writer = Agent(
    role="Tech Content Strategist",
    goal="Craft compelling content on tech advancements",
    backstory="""You are a renowned Content Strategist, known for your insightful and engaging articles.
    You transform complex concepts into compelling narratives.""",
    verbose=True,
    allow_delegation=True,
)

# Create tasks for your agents
task1 = Task(
    description="""Conduct a comprehensive analysis of the latest advancements in AI in 2024.
    Identify key trends, breakthrough technologies, and potential industry impacts.""",
    expected_output="Full analysis report in bullet points",
    agent=researcher,
)

task2 = Task(
    description="""Using the insights provided, develop an engaging blog
    post that highlights the most significant AI advancements.
    Your post should be informative yet accessible, catering to a tech-savvy audience.
    Make it sound cool, avoid complex words so it doesn't sound like AI.""",
    expected_output="Full blog post of at least 4 paragraphs",
    agent=writer,
)

# Instantiate your crew with a sequential process
crew = Crew(
    agents=[researcher, writer], tasks=[task1, task2], verbose=1, process=Process.sequential
)

# Get your crew to work!
result = crew.kickoff()

print("######################")
print(result)
```

### Step 5: View Traces in Phoenix

After running the agent, you can view the traces generated by your CrewAI application in Phoenix. You should see detailed steps of the agent interactions and LLM calls, which can help you debug and optimize your AI agents.

Log into your Phoenix Cloud account and navigate to the project you specified in the `project_name` parameter. You'll see a timeline view of your trace with all the agent interactions, tool usages, and LLM calls.

![Example trace in Phoenix showing agent interactions](https://storage.googleapis.com/arize-assets/fixtures/crewai_traces.png)

### Version Compatibility Information

* Python 3.8+
* CrewAI >= 0.86.0
* Arize Phoenix >= 7.0.1
* OpenTelemetry SDK >= 1.31.0

### References

* [Phoenix Documentation](https://docs.arize.com/phoenix/) - Overview of the Phoenix platform.
* [CrewAI Documentation](https://docs.crewai.com/) - Overview of the CrewAI framework.
* [OpenTelemetry Docs](https://opentelemetry.io/docs/) - OpenTelemetry guide
* [OpenInference GitHub](https://github.com/openinference/openinference) - Source code for OpenInference SDK.


# Langfuse Integration
Source: https://docs.crewai.com/en/observability/langfuse

Learn how to integrate Langfuse with CrewAI via OpenTelemetry using OpenLit

# Integrate Langfuse with CrewAI

This notebook demonstrates how to integrate **Langfuse** with **CrewAI** using OpenTelemetry via the **OpenLit** SDK. By the end of this notebook, you will be able to trace your CrewAI applications with Langfuse for improved observability and debugging.

> **What is Langfuse?** [Langfuse](https://langfuse.com) is an open-source LLM engineering platform. It provides tracing and monitoring capabilities for LLM applications, helping developers debug, analyze, and optimize their AI systems. Langfuse integrates with various tools and frameworks via native integrations, OpenTelemetry, and APIs/SDKs.

[![Langfuse Overview Video](https://github.com/user-attachments/assets/3926b288-ff61-4b95-8aa1-45d041c70866)](https://langfuse.com/watch-demo)

## Get Started

We'll walk through a simple example of using CrewAI and integrating it with Langfuse via OpenTelemetry using OpenLit.

### Step 1: Install Dependencies

```python
%pip install langfuse openlit crewai crewai_tools
```

### Step 2: Set Up Environment Variables

Set your Langfuse API keys and configure OpenTelemetry export settings to send traces to Langfuse. Please refer to the [Langfuse OpenTelemetry Docs](https://langfuse.com/docs/opentelemetry/get-started) for more information on the Langfuse OpenTelemetry endpoint `/api/public/otel` and authentication.

```python
import os

# Get keys for your project from the project settings page: https://cloud.langfuse.com
os.environ["LANGFUSE_PUBLIC_KEY"] = "pk-lf-..."
os.environ["LANGFUSE_SECRET_KEY"] = "sk-lf-..."
os.environ["LANGFUSE_HOST"] = "https://cloud.langfuse.com" # 🇪🇺 EU region
# os.environ["LANGFUSE_HOST"] = "https://us.cloud.langfuse.com" # 🇺🇸 US region


# Your OpenAI key
os.environ["OPENAI_API_KEY"] = "sk-proj-..."
```

With the environment variables set, we can now initialize the Langfuse client. get\_client() initializes the Langfuse client using the credentials provided in the environment variables.

```python
from langfuse import get_client

langfuse = get_client()

# Verify connection
if langfuse.auth_check():
    print("Langfuse client is authenticated and ready!")
else:
    print("Authentication failed. Please check your credentials and host.")
```

### Step 3: Initialize OpenLit

Initialize the OpenLit OpenTelemetry instrumentation SDK to start capturing OpenTelemetry traces.

```python
import openlit

openlit.init()
```

### Step 4: Create a Simple CrewAI Application

We'll create a simple CrewAI application where multiple agents collaborate to answer a user's question.

```python
from crewai import Agent, Task, Crew

from crewai_tools import (
    WebsiteSearchTool
)

web_rag_tool = WebsiteSearchTool()

writer = Agent(
        role="Writer",
        goal="You make math engaging and understandable for young children through poetry",
        backstory="You're an expert in writing haikus but you know nothing of math.",
        tools=[web_rag_tool],
    )

task = Task(description=("What is {multiplication}?"),
            expected_output=("Compose a haiku that includes the answer."),
            agent=writer)

crew = Crew(
  agents=[writer],
  tasks=[task],
  share_crew=False
)
```

### Step 5: See Traces in Langfuse

After running the agent, you can view the traces generated by your CrewAI application in [Langfuse](https://cloud.langfuse.com). You should see detailed steps of the LLM interactions, which can help you debug and optimize your AI agent.

![CrewAI example trace in Langfuse](https://langfuse.com/images/cookbook/integration_crewai/crewai-example-trace.png)

*[Public example trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/e2cf380ffc8d47d28da98f136140642b?timestamp=2025-02-05T15%3A12%3A02.717Z\&observation=3b32338ee6a5d9af)*

## References

* [Langfuse OpenTelemetry Docs](https://langfuse.com/docs/opentelemetry/get-started)


# Langtrace Integration
Source: https://docs.crewai.com/en/observability/langtrace

How to monitor cost, latency, and performance of CrewAI Agents using Langtrace, an external observability tool.

# Langtrace Overview

Langtrace is an open-source, external tool that helps you set up observability and evaluations for Large Language Models (LLMs), LLM frameworks, and Vector Databases.
While not built directly into CrewAI, Langtrace can be used alongside CrewAI to gain deep visibility into the cost, latency, and performance of your CrewAI Agents.
This integration allows you to log hyperparameters, monitor performance regressions, and establish a process for continuous improvement of your Agents.

![Overview of a select series of agent session runs](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/langtrace1.png)
![Overview of agent traces](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/langtrace2.png)
![Overview of llm traces in details](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/langtrace3.png)

## Setup Instructions

<Steps>
  <Step title="Sign up for Langtrace">
    Sign up by visiting [https://langtrace.ai/signup](https://langtrace.ai/signup).
  </Step>

  <Step title="Create a project">
    Set the project type to `CrewAI` and generate an API key.
  </Step>

  <Step title="Install Langtrace in your CrewAI project">
    Use the following command:

    ```bash
    pip install langtrace-python-sdk
    ```
  </Step>

  <Step title="Import Langtrace">
    Import and initialize Langtrace at the beginning of your script, before any CrewAI imports:

    ```python
    from langtrace_python_sdk import langtrace
    langtrace.init(api_key='<LANGTRACE_API_KEY>')

    # Now import CrewAI modules
    from crewai import Agent, Task, Crew
    ```
  </Step>
</Steps>

### Features and Their Application to CrewAI

1. **LLM Token and Cost Tracking**

   * Monitor the token usage and associated costs for each CrewAI agent interaction.

2. **Trace Graph for Execution Steps**

   * Visualize the execution flow of your CrewAI tasks, including latency and logs.
   * Useful for identifying bottlenecks in your agent workflows.

3. **Dataset Curation with Manual Annotation**

   * Create datasets from your CrewAI task outputs for future training or evaluation.

4. **Prompt Versioning and Management**

   * Keep track of different versions of prompts used in your CrewAI agents.
   * Useful for A/B testing and optimizing agent performance.

5. **Prompt Playground with Model Comparisons**

   * Test and compare different prompts and models for your CrewAI agents before deployment.

6. **Testing and Evaluations**

   * Set up automated tests for your CrewAI agents and tasks.


# Maxim Integration
Source: https://docs.crewai.com/en/observability/maxim

Start Agent monitoring, evaluation, and observability

# Maxim Overview

Maxim AI provides comprehensive agent monitoring, evaluation, and observability for your CrewAI applications. With Maxim's one-line integration, you can easily trace and analyse agent interactions, performance metrics, and more.

## Features

### Prompt Management

Maxim's Prompt Management capabilities enable you to create, organize, and optimize prompts for your CrewAI agents. Rather than hardcoding instructions, leverage Maxim’s SDK to dynamically retrieve and apply version-controlled prompts.

<Tabs>
  <Tab title="Prompt Playground">
    Create, refine, experiment and deploy your prompts via the playground. Organize of your prompts using folders and versions, experimenting with the real world cases by linking tools and context, and deploying based on custom logic.

    Easily experiment across models by [**configuring models**](https://www.getmaxim.ai/docs/introduction/quickstart/setting-up-workspace#add-model-api-keys) and selecting the relevant model from the dropdown at the top of the prompt playground.

    <img src="https://raw.githubusercontent.com/akmadan/crewAI/docs_maxim_observability/docs/images/maxim_playground.png" />
  </Tab>

  <Tab title="Prompt Versions">
    As teams build their AI applications, a big part of experimentation is iterating on the prompt structure. In order to collaborate effectively and organize your changes clearly, Maxim allows prompt versioning and comparison runs across versions.

    <img src="https://raw.githubusercontent.com/akmadan/crewAI/docs_maxim_observability/docs/images/maxim_versions.png" />
  </Tab>

  <Tab title="Prompt Comparisons">
    Iterating on Prompts as you evolve your AI application would need experiments across models, prompt structures, etc. In order to compare versions and make informed decisions about changes, the comparison playground allows a side by side view of results.

    ## **Why use Prompt comparison?**

    Prompt comparison combines multiple single Prompts into one view, enabling a streamlined approach for various workflows:

    1. **Model comparison**: Evaluate the performance of different models on the same Prompt.
    2. **Prompt optimization**: Compare different versions of a Prompt to identify the most effective formulation.
    3. **Cross-Model consistency**: Ensure consistent outputs across various models for the same Prompt.
    4. **Performance benchmarking**: Analyze metrics like latency, cost, and token count across different models and Prompts.
  </Tab>
</Tabs>

### Observability & Evals

Maxim AI provides comprehensive observability & evaluation for your CrewAI agents, helping you understand exactly what's happening during each execution.

<Tabs>
  <Tab title="Agent Tracing">
    Track your agent’s complete lifecycle, including tool calls, agent trajectories, and decision flows effortlessly.

    <img src="https://raw.githubusercontent.com/akmadan/crewAI/docs_maxim_observability/docs/images/maxim_agent_tracking.png" />
  </Tab>

  <Tab title="Analytics + Evals">
    Run detailed evaluations on full traces or individual nodes with support for:

    * Multi-step interactions and granular trace analysis
    * Session Level Evaluations
    * Simulations for real-world testing

    <img src="https://raw.githubusercontent.com/akmadan/crewAI/docs_maxim_observability/docs/images/maxim_trace_eval.png" />

    <CardGroup cols={3}>
      <Card title="Auto Evals on Logs" icon="e" href="https://www.getmaxim.ai/docs/observe/how-to/evaluate-logs/auto-evaluation">
        <p>
          Evaluate captured logs automatically from the UI based on filters and sampling
        </p>
      </Card>

      <Card title="Human Evals on Logs" icon="hand" href="https://www.getmaxim.ai/docs/observe/how-to/evaluate-logs/human-evaluation">
        <p>
          Use human evaluation or rating to assess the quality of your logs and evaluate them.
        </p>
      </Card>

      <Card title="Node Level Evals" icon="road" href="https://www.getmaxim.ai/docs/observe/how-to/evaluate-logs/node-level-evaluation">
        <p>
          Evaluate any component of your trace or log to gain insights into your agent’s behavior.
        </p>
      </Card>
    </CardGroup>

    ***
  </Tab>

  <Tab title="Alerting">
    Set thresholds on **error**, **cost, token usage, user feedback, latency** and get real-time alerts via Slack or PagerDuty.

    <img src="https://raw.githubusercontent.com/akmadan/crewAI/docs_maxim_observability/docs/images/maxim_alerts_1.png" />
  </Tab>

  <Tab title="Dashboards">
    Visualize Traces over time, usage metrics, latency & error rates with ease.

    <img src="https://raw.githubusercontent.com/akmadan/crewAI/docs_maxim_observability/docs/images/maxim_dashboard_1.png" />
  </Tab>
</Tabs>

## Getting Started

### Prerequisites

* Python version >=3.10
* A Maxim account ([sign up here](https://getmaxim.ai/))
* Generate Maxim API Key
* A CrewAI project

### Installation

Install the Maxim SDK via pip:

```python
pip install maxim-py
```

Or add it to your `requirements.txt`:

```
maxim-py
```

### Basic Setup

### 1. Set up environment variables

```python
### Environment Variables Setup

# Create a `.env` file in your project root:

# Maxim API Configuration
MAXIM_API_KEY=your_api_key_here
MAXIM_LOG_REPO_ID=your_repo_id_here
```

### 2. Import the required packages

```python
from crewai import Agent, Task, Crew, Process
from maxim import Maxim
from maxim.logger.crewai import instrument_crewai
```

### 3. Initialise Maxim with your API key

```python {8}
# Instrument CrewAI with just one line
instrument_crewai(Maxim().logger())
```

### 4. Create and run your CrewAI application as usual

```python
# Create your agent
researcher = Agent(
    role='Senior Research Analyst',
    goal='Uncover cutting-edge developments in AI',
    backstory="You are an expert researcher at a tech think tank...",
    verbose=True,
    llm=llm
)

# Define the task
research_task = Task(
    description="Research the latest AI advancements...",
    expected_output="",
    agent=researcher
)

# Configure and run the crew
crew = Crew(
    agents=[researcher],
    tasks=[research_task],
    verbose=True
)

try:
    result = crew.kickoff()
finally:
    maxim.cleanup()  # Ensure cleanup happens even if errors occur
```

That's it! All your CrewAI agent interactions will now be logged and available in your Maxim dashboard.

Check this Google Colab Notebook for a quick reference - [Notebook](https://colab.research.google.com/drive/1ZKIZWsmgQQ46n8TH9zLsT1negKkJA6K8?usp=sharing)

## Viewing Your Traces

After running your CrewAI application:

1. Log in to your [Maxim Dashboard](https://app.getmaxim.ai/login)
2. Navigate to your repository
3. View detailed agent traces, including:

   * Agent conversations
   * Tool usage patterns
   * Performance metrics
   * Cost analytics

   <img src="https://raw.githubusercontent.com/akmadan/crewAI/docs_maxim_observability/docs/images/crewai_traces.gif" />

## Troubleshooting

### Common Issues

* **No traces appearing**: Ensure your API key and repository ID are correct
* Ensure you've **`called instrument_crewai()`** ***before*** running your crew. This initializes logging hooks correctly.
* Set `debug=True` in your `instrument_crewai()` call to surface any internal errors:

  ```python
  instrument_crewai(logger, debug=True)
  ```
* Configure your agents with `verbose=True` to capture detailed logs:

  ```python
  agent = CrewAgent(..., verbose=True)
  ```
* Double-check that `instrument_crewai()` is called **before** creating or executing agents. This might be obvious, but it's a common oversight.

## Resources

<CardGroup cols="3">
  <Card title="CrewAI Docs" icon="book" href="https://docs.crewai.com/">
    Official CrewAI documentation
  </Card>

  <Card title="Maxim Docs" icon="book" href="https://getmaxim.ai/docs">
    Official Maxim documentation
  </Card>

  <Card title="Maxim Github" icon="github" href="https://github.com/maximhq">
    Maxim Github
  </Card>
</CardGroup>


# MLflow Integration
Source: https://docs.crewai.com/en/observability/mlflow

Quickly start monitoring your Agents with MLflow.

# MLflow Overview

[MLflow](https://mlflow.org/) is an open-source platform to assist machine learning practitioners and teams in handling the complexities of the machine learning process.

It provides a tracing feature that enhances LLM observability in your Generative AI applications by capturing detailed information about the execution of your application’s services.
Tracing provides a way to record the inputs, outputs, and metadata associated with each intermediate step of a request, enabling you to easily pinpoint the source of bugs and unexpected behaviors.

![Overview of MLflow crewAI tracing usage](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/mlflow-tracing.gif)

### Features

* **Tracing Dashboard**: Monitor activities of your crewAI agents with detailed dashboards that include inputs, outputs and metadata of spans.
* **Automated Tracing**: A fully automated integration with crewAI, which can be enabled by running `mlflow.crewai.autolog()`.
* **Manual Trace Instrumentation with minor efforts**: Customize trace instrumentation through MLflow's high-level fluent APIs such as decorators, function wrappers and context managers.
* **OpenTelemetry Compatibility**: MLflow Tracing supports exporting traces to an OpenTelemetry Collector, which can then be used to export traces to various backends such as Jaeger, Zipkin, and AWS X-Ray.
* **Package and Deploy Agents**: Package and deploy your crewAI agents to an inference server with a variety of deployment targets.
* **Securely Host LLMs**: Host multiple LLM from various providers in one unified endpoint through MFflow gateway.
* **Evaluation**: Evaluate your crewAI agents with a wide range of metrics using a convenient API `mlflow.evaluate()`.

## Setup Instructions

<Steps>
  <Step title="Install MLflow package">
    ```shell
    # The crewAI integration is available in mlflow>=2.19.0
    pip install mlflow
    ```
  </Step>

  <Step title="Start MFflow tracking server">
    ```shell
    # This process is optional, but it is recommended to use MLflow tracking server for better visualization and broader features.
    mlflow server
    ```
  </Step>

  <Step title="Initialize MLflow in Your Application">
    Add the following two lines to your application code:

    ```python
    import mlflow

    mlflow.crewai.autolog()

    # Optional: Set a tracking URI and an experiment name if you have a tracking server
    mlflow.set_tracking_uri("http://localhost:5000")
    mlflow.set_experiment("CrewAI")
    ```

    Example Usage for tracing CrewAI Agents:

    ```python
    from crewai import Agent, Crew, Task
    from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource
    from crewai_tools import SerperDevTool, WebsiteSearchTool

    from textwrap import dedent

    content = "Users name is John. He is 30 years old and lives in San Francisco."
    string_source = StringKnowledgeSource(
        content=content, metadata={"preference": "personal"}
    )

    search_tool = WebsiteSearchTool()


    class TripAgents:
        def city_selection_agent(self):
            return Agent(
                role="City Selection Expert",
                goal="Select the best city based on weather, season, and prices",
                backstory="An expert in analyzing travel data to pick ideal destinations",
                tools=[
                    search_tool,
                ],
                verbose=True,
            )

        def local_expert(self):
            return Agent(
                role="Local Expert at this city",
                goal="Provide the BEST insights about the selected city",
                backstory="""A knowledgeable local guide with extensive information
            about the city, it's attractions and customs""",
                tools=[search_tool],
                verbose=True,
            )


    class TripTasks:
        def identify_task(self, agent, origin, cities, interests, range):
            return Task(
                description=dedent(
                    f"""
                    Analyze and select the best city for the trip based
                    on specific criteria such as weather patterns, seasonal
                    events, and travel costs. This task involves comparing
                    multiple cities, considering factors like current weather
                    conditions, upcoming cultural or seasonal events, and
                    overall travel expenses.
                    Your final answer must be a detailed
                    report on the chosen city, and everything you found out
                    about it, including the actual flight costs, weather
                    forecast and attractions.

                    Traveling from: {origin}
                    City Options: {cities}
                    Trip Date: {range}
                    Traveler Interests: {interests}
                """
                ),
                agent=agent,
                expected_output="Detailed report on the chosen city including flight costs, weather forecast, and attractions",
            )

        def gather_task(self, agent, origin, interests, range):
            return Task(
                description=dedent(
                    f"""
                    As a local expert on this city you must compile an
                    in-depth guide for someone traveling there and wanting
                    to have THE BEST trip ever!
                    Gather information about key attractions, local customs,
                    special events, and daily activity recommendations.
                    Find the best spots to go to, the kind of place only a
                    local would know.
                    This guide should provide a thorough overview of what
                    the city has to offer, including hidden gems, cultural
                    hotspots, must-visit landmarks, weather forecasts, and
                    high level costs.
                    The final answer must be a comprehensive city guide,
                    rich in cultural insights and practical tips,
                    tailored to enhance the travel experience.

                    Trip Date: {range}
                    Traveling from: {origin}
                    Traveler Interests: {interests}
                """
                ),
                agent=agent,
                expected_output="Comprehensive city guide including hidden gems, cultural hotspots, and practical travel tips",
            )


    class TripCrew:
        def __init__(self, origin, cities, date_range, interests):
            self.cities = cities
            self.origin = origin
            self.interests = interests
            self.date_range = date_range

        def run(self):
            agents = TripAgents()
            tasks = TripTasks()

            city_selector_agent = agents.city_selection_agent()
            local_expert_agent = agents.local_expert()

            identify_task = tasks.identify_task(
                city_selector_agent,
                self.origin,
                self.cities,
                self.interests,
                self.date_range,
            )
            gather_task = tasks.gather_task(
                local_expert_agent, self.origin, self.interests, self.date_range
            )

            crew = Crew(
                agents=[city_selector_agent, local_expert_agent],
                tasks=[identify_task, gather_task],
                verbose=True,
                memory=True,
                knowledge={
                    "sources": [string_source],
                    "metadata": {"preference": "personal"},
                },
            )

            result = crew.kickoff()
            return result


    trip_crew = TripCrew("California", "Tokyo", "Dec 12 - Dec 20", "sports")
    result = trip_crew.run()

    print(result)
    ```

    Refer to [MLflow Tracing Documentation](https://mlflow.org/docs/latest/llms/tracing/index.html) for more configurations and use cases.
  </Step>

  <Step title="Visualize Activities of Agents">
    Now traces for your crewAI agents are captured by MLflow.
    Let's visit MLflow tracking server to view the traces and get insights into your Agents.

    Open `127.0.0.1:5000` on your browser to visit MLflow tracking server.

    <Frame caption="MLflow Tracing Dashboard">
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/mlflow1.png" alt="MLflow tracing example with crewai" />
    </Frame>
  </Step>
</Steps>


# OpenLIT Integration
Source: https://docs.crewai.com/en/observability/openlit

Quickly start monitoring your Agents in just a single line of code with OpenTelemetry.

# OpenLIT Overview

[OpenLIT](https://github.com/openlit/openlit?src=crewai-docs) is an open-source tool that makes it simple to monitor the performance of AI agents, LLMs, VectorDBs, and GPUs with just **one** line of code.

It provides OpenTelemetry-native tracing and metrics to track important parameters like cost, latency, interactions and task sequences.
This setup enables you to track hyperparameters and monitor for performance issues, helping you find ways to enhance and fine-tune your agents over time.

<Frame caption="OpenLIT Dashboard">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/openlit1.png" alt="Overview Agent usage including cost and tokens" />

  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/openlit2.png" alt="Overview of agent otel traces and metrics" />

  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/openlit3.png" alt="Overview of agent traces in details" />
</Frame>

### Features

* **Analytics Dashboard**: Monitor your Agents health and performance with detailed dashboards that track metrics, costs, and user interactions.
* **OpenTelemetry-native Observability SDK**: Vendor-neutral SDKs to send traces and metrics to your existing observability tools like Grafana, DataDog and more.
* **Cost Tracking for Custom and Fine-Tuned Models**: Tailor cost estimations for specific models using custom pricing files for precise budgeting.
* **Exceptions Monitoring Dashboard**: Quickly spot and resolve issues by tracking common exceptions and errors with a monitoring dashboard.
* **Compliance and Security**: Detect potential threats such as profanity and PII leaks.
* **Prompt Injection Detection**: Identify potential code injection and secret leaks.
* **API Keys and Secrets Management**: Securely handle your LLM API keys and secrets centrally, avoiding insecure practices.
* **Prompt Management**: Manage and version Agent prompts using PromptHub for consistent and easy access across Agents.
* **Model Playground** Test and compare different models for your CrewAI agents before deployment.

## Setup Instructions

<Steps>
  <Step title="Deploy OpenLIT">
    <Steps>
      <Step title="Git Clone OpenLIT Repository">
        ```shell
        git clone git@github.com:openlit/openlit.git
        ```
      </Step>

      <Step title="Start Docker Compose">
        From the root directory of the [OpenLIT Repo](https://github.com/openlit/openlit), Run the below command:

        ```shell
        docker compose up -d
        ```
      </Step>
    </Steps>
  </Step>

  <Step title="Install OpenLIT SDK">
    ```shell
    pip install openlit
    ```
  </Step>

  <Step title="Initialize OpenLIT in Your Application">
    Add the following two lines to your application code:

    <Tabs>
      <Tab title="Setup using function arguments">
        ```python
        import openlit
        openlit.init(otlp_endpoint="http://127.0.0.1:4318")
        ```

        Example Usage for monitoring a CrewAI Agent:

        ```python
        from crewai import Agent, Task, Crew, Process
        import openlit

        openlit.init(disable_metrics=True)
        # Define your agents
        researcher = Agent(
            role="Researcher",
            goal="Conduct thorough research and analysis on AI and AI agents",
            backstory="You're an expert researcher, specialized in technology, software engineering, AI, and startups. You work as a freelancer and are currently researching for a new client.",
            allow_delegation=False,
            llm='command-r'
        )


        # Define your task
        task = Task(
            description="Generate a list of 5 interesting ideas for an article, then write one captivating paragraph for each idea that showcases the potential of a full article on this topic. Return the list of ideas with their paragraphs and your notes.",
            expected_output="5 bullet points, each with a paragraph and accompanying notes.",
        )

        # Define the manager agent
        manager = Agent(
            role="Project Manager",
            goal="Efficiently manage the crew and ensure high-quality task completion",
            backstory="You're an experienced project manager, skilled in overseeing complex projects and guiding teams to success. Your role is to coordinate the efforts of the crew members, ensuring that each task is completed on time and to the highest standard.",
            allow_delegation=True,
            llm='command-r'
        )

        # Instantiate your crew with a custom manager
        crew = Crew(
            agents=[researcher],
            tasks=[task],
            manager_agent=manager,
            process=Process.hierarchical,
        )

        # Start the crew's work
        result = crew.kickoff()

        print(result)
        ```
      </Tab>

      <Tab title="Setup using Environment Variables">
        Add the following two lines to your application code:

        ```python
        import openlit

        openlit.init()
        ```

        Run the following command to configure the OTEL export endpoint:

        ```shell
        export OTEL_EXPORTER_OTLP_ENDPOINT = "http://127.0.0.1:4318"
        ```

        Example Usage for monitoring a CrewAI Async Agent:

        ```python
        import asyncio
        from crewai import Crew, Agent, Task
        import openlit

        openlit.init(otlp_endpoint="http://127.0.0.1:4318")

        # Create an agent with code execution enabled
        coding_agent = Agent(
          role="Python Data Analyst",
          goal="Analyze data and provide insights using Python",
          backstory="You are an experienced data analyst with strong Python skills.",
          allow_code_execution=True,
          llm="command-r"
        )

        # Create a task that requires code execution
        data_analysis_task = Task(
          description="Analyze the given dataset and calculate the average age of participants. Ages: {ages}",
          agent=coding_agent,
          expected_output="5 bullet points, each with a paragraph and accompanying notes.",
        )

        # Create a crew and add the task
        analysis_crew = Crew(
          agents=[coding_agent],
          tasks=[data_analysis_task]
        )

        # Async function to kickoff the crew asynchronously
        async def async_crew_execution():
            result = await analysis_crew.kickoff_async(inputs={"ages": [25, 30, 35, 40, 45]})
            print("Crew Result:", result)

        # Run the async function
        asyncio.run(async_crew_execution())
        ```
      </Tab>
    </Tabs>

    Refer to OpenLIT [Python SDK repository](https://github.com/openlit/openlit/tree/main/sdk/python) for more advanced configurations and use cases.
  </Step>

  <Step title="Visualize and Analyze">
    With the Agent Observability data now being collected and sent to OpenLIT, the next step is to visualize and analyze this data to get insights into your Agent's performance, behavior, and identify areas of improvement.

    Just head over to OpenLIT at `127.0.0.1:3000` on your browser to start exploring. You can login using the default credentials

    * **Email**: `user@openlit.io`
    * **Password**: `openlituser`

    <Frame caption="OpenLIT Dashboard">
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/openlit1.png" alt="Overview Agent usage including cost and tokens" />

      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/openlit2.png" alt="Overview of agent otel traces and metrics" />
    </Frame>
  </Step>
</Steps>


# Opik Integration
Source: https://docs.crewai.com/en/observability/opik

Learn how to use Comet Opik to debug, evaluate, and monitor your CrewAI applications with comprehensive tracing, automated evaluations, and production-ready dashboards.

# Opik Overview

With [Comet Opik](https://www.comet.com/docs/opik/), debug, evaluate, and monitor your LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards.

<Frame caption="Opik Agent Dashboard">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/opik-crewai-dashboard.png" alt="Opik agent monitoring example with CrewAI" />
</Frame>

Opik provides comprehensive support for every stage of your CrewAI application development:

* **Log Traces and Spans**: Automatically track LLM calls and application logic to debug and analyze development and production systems. Manually or programmatically annotate, view, and compare responses across projects.
* **Evaluate Your LLM Application's Performance**: Evaluate against a custom test set and run built-in evaluation metrics or define your own metrics in the SDK or UI.
* **Test Within Your CI/CD Pipeline**: Establish reliable performance baselines with Opik's LLM unit tests, built on PyTest. Run online evaluations for continuous monitoring in production.
* **Monitor & Analyze Production Data**: Understand your models' performance on unseen data in production and generate datasets for new dev iterations.

## Setup

Comet provides a hosted version of the Opik platform, or you can run the platform locally.

To use the hosted version, simply [create a free Comet account](https://www.comet.com/signup?utm_medium=github\&utm_source=crewai_docs) and grab you API Key.

To run the Opik platform locally, see our [installation guide](https://www.comet.com/docs/opik/self-host/overview/) for more information.

For this guide we will use CrewAI’s quickstart example.

<Steps>
  <Step title="Install required packages">
    ```shell
    pip install crewai crewai-tools opik --upgrade
    ```
  </Step>

  <Step title="Configure Opik">
    ```python
    import opik
    opik.configure(use_local=False)
    ```
  </Step>

  <Step title="Prepare environment">
    First, we set up our API keys for our LLM-provider as environment variables:

    ```python
    import os
    import getpass

    if "OPENAI_API_KEY" not in os.environ:
    os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter your OpenAI API key: ")
    ```
  </Step>

  <Step title="Using CrewAI">
    The first step is to create our project. We will use an example from CrewAI’s documentation:

    ```python
    from crewai import Agent, Crew, Task, Process


    class YourCrewName:
        def agent_one(self) -> Agent:
            return Agent(
                role="Data Analyst",
                goal="Analyze data trends in the market",
                backstory="An experienced data analyst with a background in economics",
                verbose=True,
            )

        def agent_two(self) -> Agent:
            return Agent(
                role="Market Researcher",
                goal="Gather information on market dynamics",
                backstory="A diligent researcher with a keen eye for detail",
                verbose=True,
            )

        def task_one(self) -> Task:
            return Task(
                name="Collect Data Task",
                description="Collect recent market data and identify trends.",
                expected_output="A report summarizing key trends in the market.",
                agent=self.agent_one(),
            )

        def task_two(self) -> Task:
            return Task(
                name="Market Research Task",
                description="Research factors affecting market dynamics.",
                expected_output="An analysis of factors influencing the market.",
                agent=self.agent_two(),
            )

        def crew(self) -> Crew:
            return Crew(
                agents=[self.agent_one(), self.agent_two()],
                tasks=[self.task_one(), self.task_two()],
                process=Process.sequential,
                verbose=True,
            )

    ```

    Now we can import Opik’s tracker and run our crew:

    ```python
    from opik.integrations.crewai import track_crewai

    track_crewai(project_name="crewai-integration-demo")

    my_crew = YourCrewName().crew()
    result = my_crew.kickoff()

    print(result)
    ```

    After running your CrewAI application, visit the Opik app to view:

    * LLM traces, spans, and their metadata
    * Agent interactions and task execution flow
    * Performance metrics like latency and token usage
    * Evaluation metrics (built-in or custom)
  </Step>
</Steps>

## Resources

* [🦉 Opik Documentation](https://www.comet.com/docs/opik/)
* [👉 Opik + CrewAI Colab](https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/crewai.ipynb)
* [🐦 X](https://x.com/cometml)
* [💬 Slack](https://slack.comet.com/)


# Overview
Source: https://docs.crewai.com/en/observability/overview

Monitor, evaluate, and optimize your CrewAI agents with comprehensive observability tools

## Observability for CrewAI

Observability is crucial for understanding how your CrewAI agents perform, identifying bottlenecks, and ensuring reliable operation in production environments. This section covers various tools and platforms that provide monitoring, evaluation, and optimization capabilities for your agent workflows.

## Why Observability Matters

* **Performance Monitoring**: Track agent execution times, token usage, and resource consumption
* **Quality Assurance**: Evaluate output quality and consistency across different scenarios
* **Debugging**: Identify and resolve issues in agent behavior and task execution
* **Cost Management**: Monitor LLM API usage and associated costs
* **Continuous Improvement**: Gather insights to optimize agent performance over time

## Available Observability Tools

### Monitoring & Tracing Platforms

<CardGroup cols={2}>
  <Card title="AgentOps" icon="paperclip" href="/en/observability/agentops">
    Session replays, metrics, and monitoring for agent development and production.
  </Card>

  <Card title="OpenLIT" icon="magnifying-glass-chart" href="/en/observability/openlit">
    OpenTelemetry-native monitoring with cost tracking and performance analytics.
  </Card>

  <Card title="MLflow" icon="bars-staggered" href="/en/observability/mlflow">
    Machine learning lifecycle management with tracing and evaluation capabilities.
  </Card>

  <Card title="Langfuse" icon="link" href="/en/observability/langfuse">
    LLM engineering platform with detailed tracing and analytics.
  </Card>

  <Card title="Langtrace" icon="chart-line" href="/en/observability/langtrace">
    Open-source observability for LLMs and agent frameworks.
  </Card>

  <Card title="Arize Phoenix" icon="meteor" href="/en/observability/arize-phoenix">
    AI observability platform for monitoring and troubleshooting.
  </Card>

  <Card title="Portkey" icon="key" href="/en/observability/portkey">
    AI gateway with comprehensive monitoring and reliability features.
  </Card>

  <Card title="Opik" icon="meteor" href="/en/observability/opik">
    Debug, evaluate, and monitor LLM applications with comprehensive tracing.
  </Card>

  <Card title="Weave" icon="network-wired" href="/en/observability/weave">
    Weights & Biases platform for tracking and evaluating AI applications.
  </Card>
</CardGroup>

### Evaluation & Quality Assurance

<CardGroup cols={2}>
  <Card title="Patronus AI" icon="shield-check" href="/en/observability/patronus-evaluation">
    Comprehensive evaluation platform for LLM outputs and agent behaviors.
  </Card>
</CardGroup>

## Key Observability Metrics

### Performance Metrics

* **Execution Time**: How long agents take to complete tasks
* **Token Usage**: Input/output tokens consumed by LLM calls
* **API Latency**: Response times from external services
* **Success Rate**: Percentage of successfully completed tasks

### Quality Metrics

* **Output Accuracy**: Correctness of agent responses
* **Consistency**: Reliability across similar inputs
* **Relevance**: How well outputs match expected results
* **Safety**: Compliance with content policies and guidelines

### Cost Metrics

* **API Costs**: Expenses from LLM provider usage
* **Resource Utilization**: Compute and memory consumption
* **Cost per Task**: Economic efficiency of agent operations
* **Budget Tracking**: Monitoring against spending limits

## Getting Started

1. **Choose Your Tools**: Select observability platforms that match your needs
2. **Instrument Your Code**: Add monitoring to your CrewAI applications
3. **Set Up Dashboards**: Configure visualizations for key metrics
4. **Define Alerts**: Create notifications for important events
5. **Establish Baselines**: Measure initial performance for comparison
6. **Iterate and Improve**: Use insights to optimize your agents

## Best Practices

### Development Phase

* Use detailed tracing to understand agent behavior
* Implement evaluation metrics early in development
* Monitor resource usage during testing
* Set up automated quality checks

### Production Phase

* Implement comprehensive monitoring and alerting
* Track performance trends over time
* Monitor for anomalies and degradation
* Maintain cost visibility and control

### Continuous Improvement

* Regular performance reviews and optimization
* A/B testing of different agent configurations
* Feedback loops for quality improvement
* Documentation of lessons learned

Choose the observability tools that best fit your use case, infrastructure, and monitoring requirements to ensure your CrewAI agents perform reliably and efficiently.


# Patronus AI Evaluation
Source: https://docs.crewai.com/en/observability/patronus-evaluation

Monitor and evaluate CrewAI agent performance using Patronus AI's comprehensive evaluation platform for LLM outputs and agent behaviors.

# Patronus AI Evaluation

## Overview

[Patronus AI](https://patronus.ai) provides comprehensive evaluation and monitoring capabilities for CrewAI agents, enabling you to assess model outputs, agent behaviors, and overall system performance. This integration allows you to implement continuous evaluation workflows that help maintain quality and reliability in production environments.

## Key Features

* **Automated Evaluation**: Real-time assessment of agent outputs and behaviors
* **Custom Criteria**: Define specific evaluation criteria tailored to your use cases
* **Performance Monitoring**: Track agent performance metrics over time
* **Quality Assurance**: Ensure consistent output quality across different scenarios
* **Safety & Compliance**: Monitor for potential issues and policy violations

## Evaluation Tools

Patronus provides three main evaluation tools for different use cases:

1. **PatronusEvalTool**: Allows agents to select the most appropriate evaluator and criteria for the evaluation task.
2. **PatronusPredefinedCriteriaEvalTool**: Uses predefined evaluator and criteria specified by the user.
3. **PatronusLocalEvaluatorTool**: Uses custom function evaluators defined by the user.

## Installation

To use these tools, you need to install the Patronus package:

```shell
uv add patronus
```

You'll also need to set up your Patronus API key as an environment variable:

```shell
export PATRONUS_API_KEY="your_patronus_api_key"
```

## Steps to Get Started

To effectively use the Patronus evaluation tools, follow these steps:

1. **Install Patronus**: Install the Patronus package using the command above.
2. **Set Up API Key**: Set your Patronus API key as an environment variable.
3. **Choose the Right Tool**: Select the appropriate Patronus evaluation tool based on your needs.
4. **Configure the Tool**: Configure the tool with the necessary parameters.

## Examples

### Using PatronusEvalTool

The following example demonstrates how to use the `PatronusEvalTool`, which allows agents to select the most appropriate evaluator and criteria:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import PatronusEvalTool

# Initialize the tool
patronus_eval_tool = PatronusEvalTool()

# Define an agent that uses the tool
coding_agent = Agent(
    role="Coding Agent",
    goal="Generate high quality code and verify that the output is code",
    backstory="An experienced coder who can generate high quality python code.",
    tools=[patronus_eval_tool],
    verbose=True,
)

# Example task to generate and evaluate code
generate_code_task = Task(
    description="Create a simple program to generate the first N numbers in the Fibonacci sequence. Select the most appropriate evaluator and criteria for evaluating your output.",
    expected_output="Program that generates the first N numbers in the Fibonacci sequence.",
    agent=coding_agent,
)

# Create and run the crew
crew = Crew(agents=[coding_agent], tasks=[generate_code_task])
result = crew.kickoff()
```

### Using PatronusPredefinedCriteriaEvalTool

The following example demonstrates how to use the `PatronusPredefinedCriteriaEvalTool`, which uses predefined evaluator and criteria:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import PatronusPredefinedCriteriaEvalTool

# Initialize the tool with predefined criteria
patronus_eval_tool = PatronusPredefinedCriteriaEvalTool(
    evaluators=[{"evaluator": "judge", "criteria": "contains-code"}]
)

# Define an agent that uses the tool
coding_agent = Agent(
    role="Coding Agent",
    goal="Generate high quality code",
    backstory="An experienced coder who can generate high quality python code.",
    tools=[patronus_eval_tool],
    verbose=True,
)

# Example task to generate code
generate_code_task = Task(
    description="Create a simple program to generate the first N numbers in the Fibonacci sequence.",
    expected_output="Program that generates the first N numbers in the Fibonacci sequence.",
    agent=coding_agent,
)

# Create and run the crew
crew = Crew(agents=[coding_agent], tasks=[generate_code_task])
result = crew.kickoff()
```

### Using PatronusLocalEvaluatorTool

The following example demonstrates how to use the `PatronusLocalEvaluatorTool`, which uses custom function evaluators:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import PatronusLocalEvaluatorTool
from patronus import Client, EvaluationResult
import random

# Initialize the Patronus client
client = Client()

# Register a custom evaluator
@client.register_local_evaluator("random_evaluator")
def random_evaluator(**kwargs):
    score = random.random()
    return EvaluationResult(
        score_raw=score,
        pass_=score >= 0.5,
        explanation="example explanation",
    )

# Initialize the tool with the custom evaluator
patronus_eval_tool = PatronusLocalEvaluatorTool(
    patronus_client=client,
    evaluator="random_evaluator",
    evaluated_model_gold_answer="example label",
)

# Define an agent that uses the tool
coding_agent = Agent(
    role="Coding Agent",
    goal="Generate high quality code",
    backstory="An experienced coder who can generate high quality python code.",
    tools=[patronus_eval_tool],
    verbose=True,
)

# Example task to generate code
generate_code_task = Task(
    description="Create a simple program to generate the first N numbers in the Fibonacci sequence.",
    expected_output="Program that generates the first N numbers in the Fibonacci sequence.",
    agent=coding_agent,
)

# Create and run the crew
crew = Crew(agents=[coding_agent], tasks=[generate_code_task])
result = crew.kickoff()
```

## Parameters

### PatronusEvalTool

The `PatronusEvalTool` does not require any parameters during initialization. It automatically fetches available evaluators and criteria from the Patronus API.

### PatronusPredefinedCriteriaEvalTool

The `PatronusPredefinedCriteriaEvalTool` accepts the following parameters during initialization:

* **evaluators**: Required. A list of dictionaries containing the evaluator and criteria to use. For example: `[{"evaluator": "judge", "criteria": "contains-code"}]`.

### PatronusLocalEvaluatorTool

The `PatronusLocalEvaluatorTool` accepts the following parameters during initialization:

* **patronus\_client**: Required. The Patronus client instance.
* **evaluator**: Optional. The name of the registered local evaluator to use. Default is an empty string.
* **evaluated\_model\_gold\_answer**: Optional. The gold answer to use for evaluation. Default is an empty string.

## Usage

When using the Patronus evaluation tools, you provide the model input, output, and context, and the tool returns the evaluation results from the Patronus API.

For the `PatronusEvalTool` and `PatronusPredefinedCriteriaEvalTool`, the following parameters are required when calling the tool:

* **evaluated\_model\_input**: The agent's task description in simple text.
* **evaluated\_model\_output**: The agent's output of the task.
* **evaluated\_model\_retrieved\_context**: The agent's context.

For the `PatronusLocalEvaluatorTool`, the same parameters are required, but the evaluator and gold answer are specified during initialization.

## Conclusion

The Patronus evaluation tools provide a powerful way to evaluate and score model inputs and outputs using the Patronus AI platform. By enabling agents to evaluate their own outputs or the outputs of other agents, these tools can help improve the quality and reliability of CrewAI workflows.


# Portkey Integration
Source: https://docs.crewai.com/en/observability/portkey

How to use Portkey with CrewAI

<img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/main/Portkey-CrewAI.png" alt="Portkey CrewAI Header Image" width="70%" />

## Introduction

Portkey enhances CrewAI with production-readiness features, turning your experimental agent crews into robust systems by providing:

* **Complete observability** of every agent step, tool use, and interaction
* **Built-in reliability** with fallbacks, retries, and load balancing
* **Cost tracking and optimization** to manage your AI spend
* **Access to 200+ LLMs** through a single integration
* **Guardrails** to keep agent behavior safe and compliant
* **Version-controlled prompts** for consistent agent performance

### Installation & Setup

<Steps>
  <Step title="Install the required packages">
    ```bash
    pip install -U crewai portkey-ai
    ```
  </Step>

  <Step title="Generate API Key" icon="lock">
    Create a Portkey API key with optional budget/rate limits from the [Portkey dashboard](https://app.portkey.ai/). You can also attach configurations for reliability, caching, and more to this key. More on this later.
  </Step>

  <Step title="Configure CrewAI with Portkey">
    The integration is simple - you just need to update the LLM configuration in your CrewAI setup:

    ```python
    from crewai import LLM
    from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

    # Create an LLM instance with Portkey integration
    gpt_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",  # We are using a Virtual key, so this is a placeholder
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_LLM_VIRTUAL_KEY",
            trace_id="unique-trace-id",               # Optional, for request tracing
        )
    )

    #Use them in your Crew Agents like this:

    	@agent
    	def lead_market_analyst(self) -> Agent:
    		return Agent(
    			config=self.agents_config['lead_market_analyst'],
    			verbose=True,
    			memory=False,
    			llm=gpt_llm
    		)

    ```

    <Info>
      **What are Virtual Keys?** Virtual keys in Portkey securely store your LLM provider API keys (OpenAI, Anthropic, etc.) in an encrypted vault. They allow for easier key rotation and budget management. [Learn more about virtual keys here](https://portkey.ai/docs/product/ai-gateway/virtual-keys).
    </Info>
  </Step>
</Steps>

## Production Features

### 1. Enhanced Observability

Portkey provides comprehensive observability for your CrewAI agents, helping you understand exactly what's happening during each execution.

<Tabs>
  <Tab title="Traces">
    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20Product%2011.1.webp" />
    </Frame>

    Traces provide a hierarchical view of your crew's execution, showing the sequence of LLM calls, tool invocations, and state transitions.

    ```python
    # Add trace_id to enable hierarchical tracing in Portkey
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
            trace_id="unique-session-id"  # Add unique trace ID
        )
    )
    ```
  </Tab>

  <Tab title="Logs">
    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20Portkey%20Docs%20Metadata.png" />
    </Frame>

    Portkey logs every interaction with LLMs, including:

    * Complete request and response payloads
    * Latency and token usage metrics
    * Cost calculations
    * Tool calls and function executions

    All logs can be filtered by metadata, trace IDs, models, and more, making it easy to debug specific crew runs.
  </Tab>

  <Tab title="Metrics & Dashboards">
    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20Dashboard.png" />
    </Frame>

    Portkey provides built-in dashboards that help you:

    * Track cost and token usage across all crew runs
    * Analyze performance metrics like latency and success rates
    * Identify bottlenecks in your agent workflows
    * Compare different crew configurations and LLMs

    You can filter and segment all metrics by custom metadata to analyze specific crew types, user groups, or use cases.
  </Tab>

  <Tab title="Metadata Filtering">
    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/Metadata%20Filters%20from%20CrewAI.png" alt="Analytics with metadata filters" />
    </Frame>

    Add custom metadata to your CrewAI LLM configuration to enable powerful filtering and segmentation:

    ```python
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
            metadata={
                "crew_type": "research_crew",
                "environment": "production",
                "_user": "user_123",   # Special _user field for user analytics
                "request_source": "mobile_app"
            }
        )
    )
    ```

    This metadata can be used to filter logs, traces, and metrics on the Portkey dashboard, allowing you to analyze specific crew runs, users, or environments.
  </Tab>
</Tabs>

### 2. Reliability - Keep Your Crews Running Smoothly

When running crews in production, things can go wrong - API rate limits, network issues, or provider outages. Portkey's reliability features ensure your agents keep running smoothly even when problems occur.

It's simple to enable fallback in your CrewAI setup by using a Portkey Config:

```python
from crewai import LLM
from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

# Create LLM with fallback configuration
portkey_llm = LLM(
    model="gpt-4o",
    max_tokens=1000,
    base_url=PORTKEY_GATEWAY_URL,
    api_key="dummy",
    extra_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        config={
            "strategy": {
                "mode": "fallback"
            },
            "targets": [
                {
                    "provider": "openai",
                    "api_key": "YOUR_OPENAI_API_KEY",
                    "override_params": {"model": "gpt-4o"}
                },
                {
                    "provider": "anthropic",
                    "api_key": "YOUR_ANTHROPIC_API_KEY",
                    "override_params": {"model": "claude-3-opus-20240229"}
                }
            ]
        }
    )
)

# Use this LLM configuration with your agents
```

This configuration will automatically try Claude if the GPT-4o request fails, ensuring your crew can continue operating.

<CardGroup cols="2">
  <Card title="Automatic Retries" icon="rotate" href="https://portkey.ai/docs/product/ai-gateway/automatic-retries">
    Handles temporary failures automatically. If an LLM call fails, Portkey will retry the same request for the specified number of times - perfect for rate limits or network blips.
  </Card>

  <Card title="Request Timeouts" icon="clock" href="https://portkey.ai/docs/product/ai-gateway/request-timeouts">
    Prevent your agents from hanging. Set timeouts to ensure you get responses (or can fail gracefully) within your required timeframes.
  </Card>

  <Card title="Conditional Routing" icon="route" href="https://portkey.ai/docs/product/ai-gateway/conditional-routing">
    Send different requests to different providers. Route complex reasoning to GPT-4, creative tasks to Claude, and quick responses to Gemini based on your needs.
  </Card>

  <Card title="Fallbacks" icon="shield" href="https://portkey.ai/docs/product/ai-gateway/fallbacks">
    Keep running even if your primary provider fails. Automatically switch to backup providers to maintain availability.
  </Card>

  <Card title="Load Balancing" icon="scale-balanced" href="https://portkey.ai/docs/product/ai-gateway/load-balancing">
    Spread requests across multiple API keys or providers. Great for high-volume crew operations and staying within rate limits.
  </Card>
</CardGroup>

### 3. Prompting in CrewAI

Portkey's Prompt Engineering Studio helps you create, manage, and optimize the prompts used in your CrewAI agents. Instead of hardcoding prompts or instructions, use Portkey's prompt rendering API to dynamically fetch and apply your versioned prompts.

<Frame caption="Manage prompts in Portkey's Prompt Library">
  ![Prompt Playground Interface](https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20Portkey%20Docs.webp)
</Frame>

<Tabs>
  <Tab title="Prompt Playground">
    Prompt Playground is a place to compare, test and deploy perfect prompts for your AI application. It's where you experiment with different models, test variables, compare outputs, and refine your prompt engineering strategy before deploying to production. It allows you to:

    1. Iteratively develop prompts before using them in your agents
    2. Test prompts with different variables and models
    3. Compare outputs between different prompt versions
    4. Collaborate with team members on prompt development

    This visual environment makes it easier to craft effective prompts for each step in your CrewAI agents' workflow.
  </Tab>

  <Tab title="Using Prompt Templates">
    The Prompt Render API retrieves your prompt templates with all parameters configured:

    ```python
    from crewai import Agent, LLM
    from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL, Portkey

    # Initialize Portkey admin client
    portkey_admin = Portkey(api_key="YOUR_PORTKEY_API_KEY")

    # Retrieve prompt using the render API
    prompt_data = portkey_client.prompts.render(
        prompt_id="YOUR_PROMPT_ID",
        variables={
            "agent_role": "Senior Research Scientist",
        }
    )

    backstory_agent_prompt=prompt_data.data.messages[0]["content"]


    # Set up LLM with Portkey integration
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_OPENAI_VIRTUAL_KEY"
        )
    )

    # Create agent using the rendered prompt
    researcher = Agent(
        role="Senior Research Scientist",
        goal="Discover groundbreaking insights about the assigned topic",
        backstory=backstory_agent,  # Use the rendered prompt
        verbose=True,
        llm=portkey_llm
    )
    ```
  </Tab>

  <Tab title="Prompt Versioning">
    You can:

    * Create multiple versions of the same prompt
    * Compare performance between versions
    * Roll back to previous versions if needed
    * Specify which version to use in your code:

    ```python
    # Use a specific prompt version
    prompt_data = portkey_admin.prompts.render(
        prompt_id="YOUR_PROMPT_ID@version_number",
        variables={
            "agent_role": "Senior Research Scientist",
            "agent_goal": "Discover groundbreaking insights"
        }
    )
    ```
  </Tab>

  <Tab title="Mustache Templating for variables">
    Portkey prompts use Mustache-style templating for easy variable substitution:

    ```
    You are a {{agent_role}} with expertise in {{domain}}.

    Your mission is to {{agent_goal}} by leveraging your knowledge
    and experience in the field.

    Always maintain a {{tone}} tone and focus on providing {{focus_area}}.
    ```

    When rendering, simply pass the variables:

    ```python
    prompt_data = portkey_admin.prompts.render(
        prompt_id="YOUR_PROMPT_ID",
        variables={
            "agent_role": "Senior Research Scientist",
            "domain": "artificial intelligence",
            "agent_goal": "discover groundbreaking insights",
            "tone": "professional",
            "focus_area": "practical applications"
        }
    )
    ```
  </Tab>
</Tabs>

<Card title="Prompt Engineering Studio" icon="wand-magic-sparkles" href="https://portkey.ai/docs/product/prompt-library">
  Learn more about Portkey's prompt management features
</Card>

### 4. Guardrails for Safe Crews

Guardrails ensure your CrewAI agents operate safely and respond appropriately in all situations.

**Why Use Guardrails?**

CrewAI agents can experience various failure modes:

* Generating harmful or inappropriate content
* Leaking sensitive information like PII
* Hallucinating incorrect information
* Generating outputs in incorrect formats

Portkey's guardrails add protections for both inputs and outputs.

**Implementing Guardrails**

```python
from crewai import Agent, LLM
from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

# Create LLM with guardrails
portkey_llm = LLM(
    model="gpt-4o",
    base_url=PORTKEY_GATEWAY_URL,
    api_key="dummy",
    extra_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
        config={
            "input_guardrails": ["guardrails-id-xxx", "guardrails-id-yyy"],
            "output_guardrails": ["guardrails-id-zzz"]
        }
    )
)

# Create agent with guardrailed LLM
researcher = Agent(
    role="Senior Research Scientist",
    goal="Discover groundbreaking insights about the assigned topic",
    backstory="You are an expert researcher with deep domain knowledge.",
    verbose=True,
    llm=portkey_llm
)
```

Portkey's guardrails can:

* Detect and redact PII in both inputs and outputs
* Filter harmful or inappropriate content
* Validate response formats against schemas
* Check for hallucinations against ground truth
* Apply custom business logic and rules

<Card title="Learn More About Guardrails" icon="shield-check" href="https://portkey.ai/docs/product/guardrails">
  Explore Portkey's guardrail features to enhance agent safety
</Card>

### 5. User Tracking with Metadata

Track individual users through your CrewAI agents using Portkey's metadata system.

**What is Metadata in Portkey?**

Metadata allows you to associate custom data with each request, enabling filtering, segmentation, and analytics. The special `_user` field is specifically designed for user tracking.

```python
from crewai import Agent, LLM
from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

# Configure LLM with user tracking
portkey_llm = LLM(
    model="gpt-4o",
    base_url=PORTKEY_GATEWAY_URL,
    api_key="dummy",
    extra_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
        metadata={
            "_user": "user_123",  # Special _user field for user analytics
            "user_tier": "premium",
            "user_company": "Acme Corp",
            "session_id": "abc-123"
        }
    )
)

# Create agent with tracked LLM
researcher = Agent(
    role="Senior Research Scientist",
    goal="Discover groundbreaking insights about the assigned topic",
    backstory="You are an expert researcher with deep domain knowledge.",
    verbose=True,
    llm=portkey_llm
)
```

**Filter Analytics by User**

With metadata in place, you can filter analytics by user and analyze performance metrics on a per-user basis:

<Frame caption="Filter analytics by user">
  <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/Metadata%20Filters%20from%20CrewAI.png" />
</Frame>

This enables:

* Per-user cost tracking and budgeting
* Personalized user analytics
* Team or organization-level metrics
* Environment-specific monitoring (staging vs. production)

<Card title="Learn More About Metadata" icon="tags" href="https://portkey.ai/docs/product/observability/metadata">
  Explore how to use custom metadata to enhance your analytics
</Card>

### 6. Caching for Efficient Crews

Implement caching to make your CrewAI agents more efficient and cost-effective:

<Tabs>
  <Tab title="Simple Caching">
    ```python
    from crewai import Agent, LLM
    from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

    # Configure LLM with simple caching
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
            config={
                "cache": {
                    "mode": "simple"
                }
            }
        )
    )

    # Create agent with cached LLM
    researcher = Agent(
        role="Senior Research Scientist",
        goal="Discover groundbreaking insights about the assigned topic",
        backstory="You are an expert researcher with deep domain knowledge.",
        verbose=True,
        llm=portkey_llm
    )
    ```

    Simple caching performs exact matches on input prompts, caching identical requests to avoid redundant model executions.
  </Tab>

  <Tab title="Semantic Caching">
    ```python
    from crewai import Agent, LLM
    from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

    # Configure LLM with semantic caching
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
            config={
                "cache": {
                    "mode": "semantic"
                }
            }
        )
    )

    # Create agent with semantically cached LLM
    researcher = Agent(
        role="Senior Research Scientist",
        goal="Discover groundbreaking insights about the assigned topic",
        backstory="You are an expert researcher with deep domain knowledge.",
        verbose=True,
        llm=portkey_llm
    )
    ```

    Semantic caching considers the contextual similarity between input requests, caching responses for semantically similar inputs.
  </Tab>
</Tabs>

### 7. Model Interoperability

CrewAI supports multiple LLM providers, and Portkey extends this capability by providing access to over 200 LLMs through a unified interface. You can easily switch between different models without changing your core agent logic:

```python
from crewai import Agent, LLM
from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

# Set up LLMs with different providers
openai_llm = LLM(
    model="gpt-4o",
    base_url=PORTKEY_GATEWAY_URL,
    api_key="dummy",
    extra_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        virtual_key="YOUR_OPENAI_VIRTUAL_KEY"
    )
)

anthropic_llm = LLM(
    model="claude-3-5-sonnet-latest",
    max_tokens=1000,
    base_url=PORTKEY_GATEWAY_URL,
    api_key="dummy",
    extra_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        virtual_key="YOUR_ANTHROPIC_VIRTUAL_KEY"
    )
)

# Choose which LLM to use for each agent based on your needs
researcher = Agent(
    role="Senior Research Scientist",
    goal="Discover groundbreaking insights about the assigned topic",
    backstory="You are an expert researcher with deep domain knowledge.",
    verbose=True,
    llm=openai_llm  # Use anthropic_llm for Anthropic
)
```

Portkey provides access to LLMs from providers including:

* OpenAI (GPT-4o, GPT-4 Turbo, etc.)
* Anthropic (Claude 3.5 Sonnet, Claude 3 Opus, etc.)
* Mistral AI (Mistral Large, Mistral Medium, etc.)
* Google Vertex AI (Gemini 1.5 Pro, etc.)
* Cohere (Command, Command-R, etc.)
* AWS Bedrock (Claude, Titan, etc.)
* Local/Private Models

<Card title="Supported Providers" icon="server" href="https://portkey.ai/docs/integrations/llms">
  See the full list of LLM providers supported by Portkey
</Card>

## Set Up Enterprise Governance for CrewAI

**Why Enterprise Governance?**
If you are using CrewAI inside your organization, you need to consider several governance aspects:

* **Cost Management**: Controlling and tracking AI spending across teams
* **Access Control**: Managing which teams can use specific models
* **Usage Analytics**: Understanding how AI is being used across the organization
* **Security & Compliance**: Maintaining enterprise security standards
* **Reliability**: Ensuring consistent service across all users

Portkey adds a comprehensive governance layer to address these enterprise needs. Let's implement these controls step by step.

<Steps>
  <Step title="Create Virtual Key">
    Virtual Keys are Portkey's secure way to manage your LLM provider API keys. They provide essential controls like:

    * Budget limits for API usage
    * Rate limiting capabilities
    * Secure API key storage

    To create a virtual key:
    Go to [Virtual Keys](https://app.portkey.ai/virtual-keys) in the Portkey App. Save and copy the virtual key ID

    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/Virtual%20Key%20from%20Portkey%20Docs.png" width="500" />
    </Frame>

    <Note>
      Save your virtual key ID - you'll need it for the next step.
    </Note>
  </Step>

  <Step title="Create Default Config">
    Configs in Portkey define how your requests are routed, with features like advanced routing, fallbacks, and retries.

    To create your config:

    1. Go to [Configs](https://app.portkey.ai/configs) in Portkey dashboard
    2. Create new config with:
       ```json
       {
           "virtual_key": "YOUR_VIRTUAL_KEY_FROM_STEP1",
          	"override_params": {
             "model": "gpt-4o" // Your preferred model name
           }
       }
       ```
    3. Save and note the Config name for the next step

    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20Portkey%20Docs%20Config.png" width="500" />
    </Frame>
  </Step>

  <Step title="Configure Portkey API Key">
    Now create a Portkey API key and attach the config you created in Step 2:

    1. Go to [API Keys](https://app.portkey.ai/api-keys) in Portkey and Create new API key
    2. Select your config from `Step 2`
    3. Generate and save your API key

    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20API%20Key.png" width="500" />
    </Frame>
  </Step>

  <Step title="Connect to CrewAI">
    After setting up your Portkey API key with the attached config, connect it to your CrewAI agents:

    ```python
    from crewai import Agent, LLM
    from portkey_ai import PORTKEY_GATEWAY_URL

    # Configure LLM with your API key
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="YOUR_PORTKEY_API_KEY"
    )

    # Create agent with Portkey-enabled LLM
    researcher = Agent(
        role="Senior Research Scientist",
        goal="Discover groundbreaking insights about the assigned topic",
        backstory="You are an expert researcher with deep domain knowledge.",
        verbose=True,
        llm=portkey_llm
    )
    ```
  </Step>
</Steps>

<AccordionGroup>
  <Accordion title="Step 1: Implement Budget Controls & Rate Limits">
    ### Step 1: Implement Budget Controls & Rate Limits

    Virtual Keys enable granular control over LLM access at the team/department level. This helps you:

    * Set up [budget limits](https://portkey.ai/docs/product/ai-gateway/virtual-keys/budget-limits)
    * Prevent unexpected usage spikes using Rate limits
    * Track departmental spending

    #### Setting Up Department-Specific Controls:

    1. Navigate to [Virtual Keys](https://app.portkey.ai/virtual-keys) in Portkey dashboard
    2. Create new Virtual Key for each department with budget limits and rate limits
    3. Configure department-specific limits

    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/Virtual%20Key%20from%20Portkey%20Docs.png" width="500" />
    </Frame>
  </Accordion>

  <Accordion title="Step 2: Define Model Access Rules">
    ### Step 2: Define Model Access Rules

    As your AI usage scales, controlling which teams can access specific models becomes crucial. Portkey Configs provide this control layer with features like:

    #### Access Control Features:

    * **Model Restrictions**: Limit access to specific models
    * **Data Protection**: Implement guardrails for sensitive data
    * **Reliability Controls**: Add fallbacks and retry logic

    #### Example Configuration:

    Here's a basic configuration to route requests to OpenAI, specifically using GPT-4o:

    ```json
    {
    	"strategy": {
    		"mode": "single"
    	},
    	"targets": [
    		{
    			"virtual_key": "YOUR_OPENAI_VIRTUAL_KEY",
    			"override_params": {
    				"model": "gpt-4o"
    			}
    		}
    	]
    }
    ```

    Create your config on the [Configs page](https://app.portkey.ai/configs) in your Portkey dashboard.

    <Note>
      Configs can be updated anytime to adjust controls without affecting running applications.
    </Note>
  </Accordion>

  <Accordion title="Step 3: Implement Access Controls">
    ### Step 3: Implement Access Controls

    Create User-specific API keys that automatically:

    * Track usage per user/team with the help of virtual keys
    * Apply appropriate configs to route requests
    * Collect relevant metadata to filter logs
    * Enforce access permissions

    Create API keys through:

    * [Portkey App](https://app.portkey.ai/)
    * [API Key Management API](/en/api-reference/admin-api/control-plane/api-keys/create-api-key)

    Example using Python SDK:

    ```python
    from portkey_ai import Portkey

    portkey = Portkey(api_key="YOUR_ADMIN_API_KEY")

    api_key = portkey.api_keys.create(
        name="engineering-team",
        type="organisation",
        workspace_id="YOUR_WORKSPACE_ID",
        defaults={
            "config_id": "your-config-id",
            "metadata": {
                "environment": "production",
                "department": "engineering"
            }
        },
        scopes=["logs.view", "configs.read"]
    )
    ```

    For detailed key management instructions, see our [API Keys documentation](/en/api-reference/admin-api/control-plane/api-keys/create-api-key).
  </Accordion>

  <Accordion title="Step 4: Deploy & Monitor">
    ### Step 4: Deploy & Monitor

    After distributing API keys to your team members, your enterprise-ready CrewAI setup is ready to go. Each team member can now use their designated API keys with appropriate access levels and budget controls.

    Monitor usage in Portkey dashboard:

    * Cost tracking by department
    * Model usage patterns
    * Request volumes
    * Error rates
  </Accordion>
</AccordionGroup>

<Note>
  ### Enterprise Features Now Available

  **Your CrewAI integration now has:**

  * Departmental budget controls
  * Model access governance
  * Usage tracking & attribution
  * Security guardrails
  * Reliability features
</Note>

## Frequently Asked Questions

<AccordionGroup>
  <Accordion title="How does Portkey enhance CrewAI?">
    Portkey adds production-readiness to CrewAI through comprehensive observability (traces, logs, metrics), reliability features (fallbacks, retries, caching), and access to 200+ LLMs through a unified interface. This makes it easier to debug, optimize, and scale your agent applications.
  </Accordion>

  <Accordion title="Can I use Portkey with existing CrewAI applications?">
    Yes! Portkey integrates seamlessly with existing CrewAI applications. You just need to update your LLM configuration code with the Portkey-enabled version. The rest of your agent and crew code remains unchanged.
  </Accordion>

  <Accordion title="Does Portkey work with all CrewAI features?">
    Portkey supports all CrewAI features, including agents, tools, human-in-the-loop workflows, and all task process types (sequential, hierarchical, etc.). It adds observability and reliability without limiting any of the framework's functionality.
  </Accordion>

  <Accordion title="Can I track usage across multiple agents in a crew?">
    Yes, Portkey allows you to use a consistent `trace_id` across multiple agents in a crew to track the entire workflow. This is especially useful for complex crews where you want to understand the full execution path across multiple agents.
  </Accordion>

  <Accordion title="How do I filter logs and traces for specific crew runs?">
    Portkey allows you to add custom metadata to your LLM configuration, which you can then use for filtering. Add fields like `crew_name`, `crew_type`, or `session_id` to easily find and analyze specific crew executions.
  </Accordion>

  <Accordion title="Can I use my own API keys with Portkey?">
    Yes! Portkey uses your own API keys for the various LLM providers. It securely stores them as virtual keys, allowing you to easily manage and rotate keys without changing your code.
  </Accordion>
</AccordionGroup>

## Resources

<CardGroup cols="3">
  <Card title="CrewAI Docs" icon="book" href="https://docs.crewai.com/">
    <p>Official CrewAI documentation</p>
  </Card>

  <Card title="Book a Demo" icon="calendar" href="https://calendly.com/portkey-ai">
    <p>Get personalized guidance on implementing this integration</p>
  </Card>
</CardGroup>


# Weave Integration
Source: https://docs.crewai.com/en/observability/weave

Learn how to use Weights & Biases (W&B) Weave to track, experiment with, evaluate, and improve your CrewAI applications.

# Weave Overview

[Weights & Biases (W\&B) Weave](https://weave-docs.wandb.ai/) is a framework for tracking, experimenting with, evaluating, deploying, and improving LLM-based applications.

![Overview of W\&B Weave CrewAI tracing usage](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/weave-tracing.gif)

Weave provides comprehensive support for every stage of your CrewAI application development:

* **Tracing & Monitoring**: Automatically track LLM calls and application logic to debug and analyze production systems
* **Systematic Iteration**: Refine and iterate on prompts, datasets, and models
* **Evaluation**: Use custom or pre-built scorers to systematically assess and enhance agent performance
* **Guardrails**: Protect your agents with pre- and post-safeguards for content moderation and prompt safety

Weave automatically captures traces for your CrewAI applications, enabling you to monitor and analyze your agents' performance, interactions, and execution flow. This helps you build better evaluation datasets and optimize your agent workflows.

## Setup Instructions

<Steps>
  <Step title="Install required packages">
    ```shell
    pip install crewai weave
    ```
  </Step>

  <Step title="Set up W&B Account">
    Sign up for a [Weights & Biases account](https://wandb.ai) if you haven't already. You'll need this to view your traces and metrics.
  </Step>

  <Step title="Initialize Weave in Your Application">
    Add the following code to your application:

    ```python
    import weave

    # Initialize Weave with your project name
    weave.init(project_name="crewai_demo")
    ```

    After initialization, Weave will provide a URL where you can view your traces and metrics.
  </Step>

  <Step title="Create your Crews/Flows">
    ```python
    from crewai import Agent, Task, Crew, LLM, Process

    # Create an LLM with a temperature of 0 to ensure deterministic outputs
    llm = LLM(model="gpt-4o", temperature=0)

    # Create agents
    researcher = Agent(
        role='Research Analyst',
        goal='Find and analyze the best investment opportunities',
        backstory='Expert in financial analysis and market research',
        llm=llm,
        verbose=True,
        allow_delegation=False,
    )

    writer = Agent(
        role='Report Writer',
        goal='Write clear and concise investment reports',
        backstory='Experienced in creating detailed financial reports',
        llm=llm,
        verbose=True,
        allow_delegation=False,
    )

    # Create tasks
    research_task = Task(
        description='Deep research on the {topic}',
        expected_output='Comprehensive market data including key players, market size, and growth trends.',
        agent=researcher
    )

    writing_task = Task(
        description='Write a detailed report based on the research',
        expected_output='The report should be easy to read and understand. Use bullet points where applicable.',
        agent=writer
    )

    # Create a crew
    crew = Crew(
        agents=[researcher, writer],
        tasks=[research_task, writing_task],
        verbose=True,
        process=Process.sequential,
    )

    # Run the crew
    result = crew.kickoff(inputs={"topic": "AI in material science"})
    print(result)
    ```
  </Step>

  <Step title="View Traces in Weave">
    After running your CrewAI application, visit the Weave URL provided during initialization to view:

    * LLM calls and their metadata
    * Agent interactions and task execution flow
    * Performance metrics like latency and token usage
    * Any errors or issues that occurred during execution

    <Frame caption="Weave Tracing Dashboard">
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/weave-tracing.png" alt="Weave tracing example with CrewAI" />
    </Frame>
  </Step>
</Steps>

## Features

* Weave automatically captures all CrewAI operations: agent interactions and task executions; LLM calls with metadata and token usage; tool usage and results.
* The integration supports all CrewAI execution methods: `kickoff()`, `kickoff_for_each()`, `kickoff_async()`, and `kickoff_for_each_async()`.
* Automatic tracing of all [crewAI-tools](https://github.com/crewAIInc/crewAI-tools).
* Flow feature support with decorator patching (`@start`, `@listen`, `@router`, `@or_`, `@and_`).
* Track custom guardrails passed to CrewAI `Task` with `@weave.op()`.

For detailed information on what's supported, visit the [Weave CrewAI documentation](https://weave-docs.wandb.ai/guides/integrations/crewai/#getting-started-with-flow).

## Resources

* [📘 Weave Documentation](https://weave-docs.wandb.ai)
* [📊 Example Weave x CrewAI dashboard](https://wandb.ai/ayut/crewai_demo/weave/traces?cols=%7B%22wb_run_id%22%3Afalse%2C%22attributes.weave.client_version%22%3Afalse%2C%22attributes.weave.os_name%22%3Afalse%2C%22attributes.weave.os_release%22%3Afalse%2C%22attributes.weave.os_version%22%3Afalse%2C%22attributes.weave.source%22%3Afalse%2C%22attributes.weave.sys_version%22%3Afalse%7D\&peekPath=%2Fayut%2Fcrewai_demo%2Fcalls%2F0195c838-38cb-71a2-8a15-651ecddf9d89)
* [🐦 X](https://x.com/weave_wb)


# Quickstart
Source: https://docs.crewai.com/en/quickstart

Build your first AI agent with CrewAI in under 5 minutes.

## Build your first CrewAI Agent

Let's create a simple crew that will help us `research` and `report` on the `latest AI developments` for a given topic or subject.

Before we proceed, make sure you have finished installing CrewAI.
If you haven't installed them yet, you can do so by following the [installation guide](/en/installation).

Follow the steps below to get Crewing! 🚣‍♂️

<Steps>
  <Step title="Create your crew">
    Create a new crew project by running the following command in your terminal.
    This will create a new directory called `latest-ai-development` with the basic structure for your crew.

    <CodeGroup>
      ```shell Terminal
      crewai create crew latest-ai-development
      ```
    </CodeGroup>
  </Step>

  <Step title="Navigate to your new crew project">
    <CodeGroup>
      ```shell Terminal
      cd latest-ai-development
      ```
    </CodeGroup>
  </Step>

  <Step title="Modify your `agents.yaml` file">
    <Tip>
      You can also modify the agents as needed to fit your use case or copy and paste as is to your project.
      Any variable interpolated in your `agents.yaml` and `tasks.yaml` files like `{topic}` will be replaced by the value of the variable in the `main.py` file.
    </Tip>

    ```yaml agents.yaml
    # src/latest_ai_development/config/agents.yaml
    researcher:
      role: >
        {topic} Senior Data Researcher
      goal: >
        Uncover cutting-edge developments in {topic}
      backstory: >
        You're a seasoned researcher with a knack for uncovering the latest
        developments in {topic}. Known for your ability to find the most relevant
        information and present it in a clear and concise manner.

    reporting_analyst:
      role: >
        {topic} Reporting Analyst
      goal: >
        Create detailed reports based on {topic} data analysis and research findings
      backstory: >
        You're a meticulous analyst with a keen eye for detail. You're known for
        your ability to turn complex data into clear and concise reports, making
        it easy for others to understand and act on the information you provide.
    ```
  </Step>

  <Step title="Modify your `tasks.yaml` file">
    ````yaml tasks.yaml
    # src/latest_ai_development/config/tasks.yaml
    research_task:
      description: >
        Conduct a thorough research about {topic}
        Make sure you find any interesting and relevant information given
        the current year is 2025.
      expected_output: >
        A list with 10 bullet points of the most relevant information about {topic}
      agent: researcher

    reporting_task:
      description: >
        Review the context you got and expand each topic into a full section for a report.
        Make sure the report is detailed and contains any and all relevant information.
      expected_output: >
        A fully fledge reports with the mains topics, each with a full section of information.
        Formatted as markdown without '```'
      agent: reporting_analyst
      output_file: report.md
    ````
  </Step>

  <Step title="Modify your `crew.py` file">
    ```python crew.py
    # src/latest_ai_development/crew.py
    from crewai import Agent, Crew, Process, Task
    from crewai.project import CrewBase, agent, crew, task
    from crewai_tools import SerperDevTool
    from crewai.agents.agent_builder.base_agent import BaseAgent
    from typing import List

    @CrewBase
    class LatestAiDevelopmentCrew():
      """LatestAiDevelopment crew"""

      agents: List[BaseAgent]
      tasks: List[Task]

      @agent
      def researcher(self) -> Agent:
        return Agent(
          config=self.agents_config['researcher'], # type: ignore[index]
          verbose=True,
          tools=[SerperDevTool()]
        )

      @agent
      def reporting_analyst(self) -> Agent:
        return Agent(
          config=self.agents_config['reporting_analyst'], # type: ignore[index]
          verbose=True
        )

      @task
      def research_task(self) -> Task:
        return Task(
          config=self.tasks_config['research_task'], # type: ignore[index]
        )

      @task
      def reporting_task(self) -> Task:
        return Task(
          config=self.tasks_config['reporting_task'], # type: ignore[index]
          output_file='output/report.md' # This is the file that will be contain the final report.
        )

      @crew
      def crew(self) -> Crew:
        """Creates the LatestAiDevelopment crew"""
        return Crew(
          agents=self.agents, # Automatically created by the @agent decorator
          tasks=self.tasks, # Automatically created by the @task decorator
          process=Process.sequential,
          verbose=True,
        )
    ```
  </Step>

  <Step title="[Optional] Add before and after crew functions">
    ```python crew.py
    # src/latest_ai_development/crew.py
    from crewai import Agent, Crew, Process, Task
    from crewai.project import CrewBase, agent, crew, task, before_kickoff, after_kickoff
    from crewai_tools import SerperDevTool

    @CrewBase
    class LatestAiDevelopmentCrew():
      """LatestAiDevelopment crew"""

      @before_kickoff
      def before_kickoff_function(self, inputs):
        print(f"Before kickoff function with inputs: {inputs}")
        return inputs # You can return the inputs or modify them as needed

      @after_kickoff
      def after_kickoff_function(self, result):
        print(f"After kickoff function with result: {result}")
        return result # You can return the result or modify it as needed

      # ... remaining code
    ```
  </Step>

  <Step title="Feel free to pass custom inputs to your crew">
    For example, you can pass the `topic` input to your crew to customize the research and reporting.

    ```python main.py
    #!/usr/bin/env python
    # src/latest_ai_development/main.py
    import sys
    from latest_ai_development.crew import LatestAiDevelopmentCrew

    def run():
      """
      Run the crew.
      """
      inputs = {
        'topic': 'AI Agents'
      }
      LatestAiDevelopmentCrew().crew().kickoff(inputs=inputs)
    ```
  </Step>

  <Step title="Set your environment variables">
    Before running your crew, make sure you have the following keys set as environment variables in your `.env` file:

    * A [Serper.dev](https://serper.dev/) API key: `SERPER_API_KEY=YOUR_KEY_HERE`
    * The configuration for your choice of model, such as an API key. See the
      [LLM setup guide](/en/concepts/llms#setting-up-your-llm) to learn how to configure models from any provider.
  </Step>

  <Step title="Lock and install the dependencies">
    * Lock the dependencies and install them by using the CLI command:
      <CodeGroup>
        ```shell Terminal
        crewai install
        ```
      </CodeGroup>
    * If you have additional packages that you want to install, you can do so by running:
      <CodeGroup>
        ```shell Terminal
        uv add <package-name>
        ```
      </CodeGroup>
  </Step>

  <Step title="Run your crew">
    * To run your crew, execute the following command in the root of your project:
      <CodeGroup>
        ```bash Terminal
        crewai run
        ```
      </CodeGroup>
  </Step>

  <Step title="Enterprise Alternative: Create in Crew Studio">
    For CrewAI Enterprise users, you can create the same crew without writing code:

    1. Log in to your CrewAI Enterprise account (create a free account at [app.crewai.com](https://app.crewai.com))
    2. Open Crew Studio
    3. Type what is the automation you're trying to build
    4. Create your tasks visually and connect them in sequence
    5. Configure your inputs and click "Download Code" or "Deploy"

    ![Crew Studio Quickstart](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-studio-interface.png)

    <Card title="Try CrewAI Enterprise" icon="rocket" href="https://app.crewai.com">
      Start your free account at CrewAI Enterprise
    </Card>
  </Step>

  <Step title="View your final report">
    You should see the output in the console and the `report.md` file should be created in the root of your project with the final report.

    Here's an example of what the report should look like:

    <CodeGroup>
      ```markdown output/report.md
      # Comprehensive Report on the Rise and Impact of AI Agents in 2025

      ## 1. Introduction to AI Agents
      In 2025, Artificial Intelligence (AI) agents are at the forefront of innovation across various industries. As intelligent systems that can perform tasks typically requiring human cognition, AI agents are paving the way for significant advancements in operational efficiency, decision-making, and overall productivity within sectors like Human Resources (HR) and Finance. This report aims to detail the rise of AI agents, their frameworks, applications, and potential implications on the workforce.

      ## 2. Benefits of AI Agents
      AI agents bring numerous advantages that are transforming traditional work environments. Key benefits include:

      - **Task Automation**: AI agents can carry out repetitive tasks such as data entry, scheduling, and payroll processing without human intervention, greatly reducing the time and resources spent on these activities.
      - **Improved Efficiency**: By quickly processing large datasets and performing analyses that would take humans significantly longer, AI agents enhance operational efficiency. This allows teams to focus on strategic tasks that require higher-level thinking.
      - **Enhanced Decision-Making**: AI agents can analyze trends and patterns in data, provide insights, and even suggest actions, helping stakeholders make informed decisions based on factual data rather than intuition alone.

      ## 3. Popular AI Agent Frameworks
      Several frameworks have emerged to facilitate the development of AI agents, each with its own unique features and capabilities. Some of the most popular frameworks include:

      - **Autogen**: A framework designed to streamline the development of AI agents through automation of code generation.
      - **Semantic Kernel**: Focuses on natural language processing and understanding, enabling agents to comprehend user intentions better.
      - **Promptflow**: Provides tools for developers to create conversational agents that can navigate complex interactions seamlessly.
      - **Langchain**: Specializes in leveraging various APIs to ensure agents can access and utilize external data effectively.
      - **CrewAI**: Aimed at collaborative environments, CrewAI strengthens teamwork by facilitating communication through AI-driven insights.
      - **MemGPT**: Combines memory-optimized architectures with generative capabilities, allowing for more personalized interactions with users.

      These frameworks empower developers to build versatile and intelligent agents that can engage users, perform advanced analytics, and execute various tasks aligned with organizational goals.

      ## 4. AI Agents in Human Resources
      AI agents are revolutionizing HR practices by automating and optimizing key functions:

      - **Recruiting**: AI agents can screen resumes, schedule interviews, and even conduct initial assessments, thus accelerating the hiring process while minimizing biases.
      - **Succession Planning**: AI systems analyze employee performance data and potential, helping organizations identify future leaders and plan appropriate training.
      - **Employee Engagement**: Chatbots powered by AI can facilitate feedback loops between employees and management, promoting an open culture and addressing concerns promptly.

      As AI continues to evolve, HR departments leveraging these agents can realize substantial improvements in both efficiency and employee satisfaction.

      ## 5. AI Agents in Finance
      The finance sector is seeing extensive integration of AI agents that enhance financial practices:

      - **Expense Tracking**: Automated systems manage and monitor expenses, flagging anomalies and offering recommendations based on spending patterns.
      - **Risk Assessment**: AI models assess credit risk and uncover potential fraud by analyzing transaction data and behavioral patterns.
      - **Investment Decisions**: AI agents provide stock predictions and analytics based on historical data and current market conditions, empowering investors with informative insights.

      The incorporation of AI agents into finance is fostering a more responsive and risk-aware financial landscape.

      ## 6. Market Trends and Investments
      The growth of AI agents has attracted significant investment, especially amidst the rising popularity of chatbots and generative AI technologies. Companies and entrepreneurs are eager to explore the potential of these systems, recognizing their ability to streamline operations and improve customer engagement.

      Conversely, corporations like Microsoft are taking strides to integrate AI agents into their product offerings, with enhancements to their Copilot 365 applications. This strategic move emphasizes the importance of AI literacy in the modern workplace and indicates the stabilizing of AI agents as essential business tools.

      ## 7. Future Predictions and Implications
      Experts predict that AI agents will transform essential aspects of work life. As we look toward the future, several anticipated changes include:

      - Enhanced integration of AI agents across all business functions, creating interconnected systems that leverage data from various departmental silos for comprehensive decision-making.
      - Continued advancement of AI technologies, resulting in smarter, more adaptable agents capable of learning and evolving from user interactions.
      - Increased regulatory scrutiny to ensure ethical use, especially concerning data privacy and employee surveillance as AI agents become more prevalent.

      To stay competitive and harness the full potential of AI agents, organizations must remain vigilant about latest developments in AI technology and consider continuous learning and adaptation in their strategic planning.

      ## 8. Conclusion
      The emergence of AI agents is undeniably reshaping the workplace landscape in 5. With their ability to automate tasks, enhance efficiency, and improve decision-making, AI agents are critical in driving operational success. Organizations must embrace and adapt to AI developments to thrive in an increasingly digital business environment.
      ```
    </CodeGroup>
  </Step>
</Steps>

<Check>
  Congratulations!

  You have successfully set up your crew project and are ready to start building your own agentic workflows!
</Check>

### Note on Consistency in Naming

The names you use in your YAML files (`agents.yaml` and `tasks.yaml`) should match the method names in your Python code.
For example, you can reference the agent for specific tasks from `tasks.yaml` file.
This naming consistency allows CrewAI to automatically link your configurations with your code; otherwise, your task won't recognize the reference properly.

#### Example References

<Tip>
  Note how we use the same name for the agent in the `agents.yaml` (`email_summarizer`) file as the method name in the `crew.py` (`email_summarizer`) file.
</Tip>

```yaml agents.yaml
email_summarizer:
    role: >
      Email Summarizer
    goal: >
      Summarize emails into a concise and clear summary
    backstory: >
      You will create a 5 bullet point summary of the report
    llm: provider/model-id  # Add your choice of model here
```

<Tip>
  Note how we use the same name for the task in the `tasks.yaml` (`email_summarizer_task`) file as the method name in the `crew.py` (`email_summarizer_task`) file.
</Tip>

```yaml tasks.yaml
email_summarizer_task:
    description: >
      Summarize the email into a 5 bullet point summary
    expected_output: >
      A 5 bullet point summary of the email
    agent: email_summarizer
    context:
      - reporting_task
      - research_task
```

## Deploying Your Crew

The easiest way to deploy your crew to production is through [CrewAI Enterprise](http://app.crewai.com).

Watch this video tutorial for a step-by-step demonstration of deploying your crew to [CrewAI Enterprise](http://app.crewai.com) using the CLI.

<iframe width="100%" height="400" src="https://www.youtube.com/embed/3EqSV-CYDZA" title="CrewAI Deployment Guide" frameborder="0" style={{ borderRadius: '10px' }} allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

<CardGroup cols={2}>
  <Card title="Deploy on Enterprise" icon="rocket" href="http://app.crewai.com">
    Get started with CrewAI Enterprise and deploy your crew in a production environment with just a few clicks.
  </Card>

  <Card title="Join the Community" icon="comments" href="https://community.crewai.com">
    Join our open source community to discuss ideas, share your projects, and connect with other CrewAI developers.
  </Card>
</CardGroup>


# null
Source: https://docs.crewai.com/en/snippets/snippet-intro



One of the core principles of software development is DRY (Don't Repeat
Yourself). This is a principle that apply to documentation as
well. If you find yourself repeating the same content in multiple places, you
should consider creating a custom snippet to keep your content in sync.


# Telemetry
Source: https://docs.crewai.com/en/telemetry

Understanding the telemetry data collected by CrewAI and how it contributes to the enhancement of the library.

## Telemetry

<Note>
  By default, we collect no data that would be considered personal information under GDPR and other privacy regulations.
  We do collect Tool's names and Agent's roles, so be advised not to include any personal information in the tool's names or the Agent's roles.
  Because no personal information is collected, it's not necessary to worry about data residency.
  When `share_crew` is enabled, additional data is collected which may contain personal information if included by the user.
  Users should exercise caution when enabling this feature to ensure compliance with privacy regulations.
</Note>

CrewAI utilizes anonymous telemetry to gather usage statistics with the primary goal of enhancing the library.
Our focus is on improving and developing the features, integrations, and tools most utilized by our users.

It's pivotal to understand that by default, **NO personal data is collected** concerning prompts, task descriptions, agents' backstories or goals,
usage of tools, API calls, responses, any data processed by the agents, or secrets and environment variables.
When the `share_crew` feature is enabled, detailed data including task descriptions, agents' backstories or goals, and other specific attributes are collected
to provide deeper insights. This expanded data collection may include personal information if users have incorporated it into their crews or tasks.
Users should carefully consider the content of their crews and tasks before enabling `share_crew`.
Users can disable telemetry by setting the environment variable `CREWAI_DISABLE_TELEMETRY` to `true` or by setting `OTEL_SDK_DISABLED` to `true` (note that the latter disables all OpenTelemetry instrumentation globally).

### Examples:

```python
# Disable CrewAI telemetry only
os.environ['CREWAI_DISABLE_TELEMETRY'] = 'true'

# Disable all OpenTelemetry (including CrewAI)
os.environ['OTEL_SDK_DISABLED'] = 'true'
```

### Data Explanation:

| Defaulted | Data                                     | Reason and Specifics                                                                                                                                                                                                                                                                                             |
| --------- | ---------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Yes       | CrewAI and Python Version                | Tracks software versions. Example: CrewAI v1.2.3, Python 3.8.10. No personal data.                                                                                                                                                                                                                               |
| Yes       | Crew Metadata                            | Includes: randomly generated key and ID, process type (e.g., 'sequential', 'parallel'), boolean flag for memory usage (true/false), count of tasks, count of agents. All non-personal.                                                                                                                           |
| Yes       | Agent Data                               | Includes: randomly generated key and ID, role name (should not include personal info), boolean settings (verbose, delegation enabled, code execution allowed), max iterations, max RPM, max retry limit, LLM info (see LLM Attributes), list of tool names (should not include personal info). No personal data. |
| Yes       | Task Metadata                            | Includes: randomly generated key and ID, boolean execution settings (async\_execution, human\_input), associated agent's role and key, list of tool names. All non-personal.                                                                                                                                     |
| Yes       | Tool Usage Statistics                    | Includes: tool name (should not include personal info), number of usage attempts (integer), LLM attributes used. No personal data.                                                                                                                                                                               |
| Yes       | Test Execution Data                      | Includes: crew's randomly generated key and ID, number of iterations, model name used, quality score (float), execution time (in seconds). All non-personal.                                                                                                                                                     |
| Yes       | Task Lifecycle Data                      | Includes: creation and execution start/end times, crew and task identifiers. Stored as spans with timestamps. No personal data.                                                                                                                                                                                  |
| Yes       | LLM Attributes                           | Includes: name, model\_name, model, top\_k, temperature, and class name of the LLM. All technical, non-personal data.                                                                                                                                                                                            |
| Yes       | Crew Deployment attempt using crewAI CLI | Includes: The fact a deploy is being made and crew id, and if it's trying to pull logs, no other data.                                                                                                                                                                                                           |
| No        | Agent's Expanded Data                    | Includes: goal description, backstory text, i18n prompt file identifier. Users should ensure no personal info is included in text fields.                                                                                                                                                                        |
| No        | Detailed Task Information                | Includes: task description, expected output description, context references. Users should ensure no personal info is included in these fields.                                                                                                                                                                   |
| No        | Environment Information                  | Includes: platform, release, system, version, and CPU count. Example: 'Windows 10', 'x86\_64'. No personal data.                                                                                                                                                                                                 |
| No        | Crew and Task Inputs and Outputs         | Includes: input parameters and output results as non-identifiable data. Users should ensure no personal info is included.                                                                                                                                                                                        |
| No        | Comprehensive Crew Execution Data        | Includes: detailed logs of crew operations, all agents and tasks data, final output. All non-personal and technical in nature.                                                                                                                                                                                   |

<Note>
  "No" in the "Defaulted" column indicates that this data is only collected when `share_crew` is set to `true`.
</Note>

### Opt-In Further Telemetry Sharing

Users can choose to share their complete telemetry data by enabling the `share_crew` attribute to `True` in their crew configurations.
Enabling `share_crew` results in the collection of detailed crew and task execution data, including `goal`, `backstory`, `context`, and `output` of tasks.
This enables a deeper insight into usage patterns.

<Warning>
  If you enable `share_crew`, the collected data may include personal information if it has been incorporated into crew configurations, task descriptions, or outputs.
  Users should carefully review their data and ensure compliance with GDPR and other applicable privacy regulations before enabling this feature.
</Warning>


# AI Mind Tool
Source: https://docs.crewai.com/en/tools/ai-ml/aimindtool

The `AIMindTool` is designed to query data sources in natural language.

# `AIMindTool`

## Description

The `AIMindTool` is a wrapper around [AI-Minds](https://mindsdb.com/minds) provided by [MindsDB](https://mindsdb.com/). It allows you to query data sources in natural language by simply configuring their connection parameters. This tool is useful when you need answers to questions from your data stored in various data sources including PostgreSQL, MySQL, MariaDB, ClickHouse, Snowflake, and Google BigQuery.

Minds are AI systems that work similarly to large language models (LLMs) but go beyond by answering any question from any data. This is accomplished by:

* Selecting the most relevant data for an answer using parametric search
* Understanding the meaning and providing responses within the correct context through semantic search
* Delivering precise answers by analyzing data and using machine learning (ML) models

## Installation

To incorporate this tool into your project, you need to install the Minds SDK:

```shell
uv add minds-sdk
```

## Steps to Get Started

To effectively use the `AIMindTool`, follow these steps:

1. **Package Installation**: Confirm that the `crewai[tools]` and `minds-sdk` packages are installed in your Python environment.
2. **API Key Acquisition**: Sign up for a Minds account [here](https://mdb.ai/register), and obtain an API key.
3. **Environment Configuration**: Store your obtained API key in an environment variable named `MINDS_API_KEY` to facilitate its use by the tool.

## Example

The following example demonstrates how to initialize the tool and execute a query:

```python Code
from crewai_tools import AIMindTool

# Initialize the AIMindTool
aimind_tool = AIMindTool(
    datasources=[
        {
            "description": "house sales data",
            "engine": "postgres",
            "connection_data": {
                "user": "demo_user",
                "password": "demo_password",
                "host": "samples.mindsdb.com",
                "port": 5432,
                "database": "demo",
                "schema": "demo_data"
            },
            "tables": ["house_sales"]
        }
    ]
)

# Run a natural language query
result = aimind_tool.run("How many 3 bedroom houses were sold in 2008?")
print(result)
```

## Parameters

The `AIMindTool` accepts the following parameters:

* **api\_key**: Optional. Your Minds API key. If not provided, it will be read from the `MINDS_API_KEY` environment variable.
* **datasources**: A list of dictionaries, each containing the following keys:
  * **description**: A description of the data contained in the datasource.
  * **engine**: The engine (or type) of the datasource.
  * **connection\_data**: A dictionary containing the connection parameters for the datasource.
  * **tables**: A list of tables that the data source will use. This is optional and can be omitted if all tables in the data source are to be used.

A list of supported data sources and their connection parameters can be found [here](https://docs.mdb.ai/docs/data_sources).

## Agent Integration Example

Here's how to integrate the `AIMindTool` with a CrewAI agent:

```python Code
from crewai import Agent
from crewai.project import agent
from crewai_tools import AIMindTool

# Initialize the tool
aimind_tool = AIMindTool(
    datasources=[
        {
            "description": "sales data",
            "engine": "postgres",
            "connection_data": {
                "user": "your_user",
                "password": "your_password",
                "host": "your_host",
                "port": 5432,
                "database": "your_db",
                "schema": "your_schema"
            },
            "tables": ["sales"]
        }
    ]
)

# Define an agent with the AIMindTool
@agent
def data_analyst(self) -> Agent:
    return Agent(
        config=self.agents_config["data_analyst"],
        allow_delegation=False,
        tools=[aimind_tool]
    )
```

## Conclusion

The `AIMindTool` provides a powerful way to query your data sources using natural language, making it easier to extract insights without writing complex SQL queries. By connecting to various data sources and leveraging AI-Minds technology, this tool enables agents to access and analyze data efficiently.


# Code Interpreter
Source: https://docs.crewai.com/en/tools/ai-ml/codeinterpretertool

The `CodeInterpreterTool` is a powerful tool designed for executing Python 3 code within a secure, isolated environment.

# `CodeInterpreterTool`

## Description

The `CodeInterpreterTool` enables CrewAI agents to execute Python 3 code that they generate autonomously. This functionality is particularly valuable as it allows agents to create code, execute it, obtain the results, and utilize that information to inform subsequent decisions and actions.

There are several ways to use this tool:

### Docker Container (Recommended)

This is the primary option. The code runs in a secure, isolated Docker container, ensuring safety regardless of its content.
Make sure Docker is installed and running on your system. If you don’t have it, you can install it from [here](https://docs.docker.com/get-docker/).

### Sandbox environment

If Docker is unavailable — either not installed or not accessible for any reason — the code will be executed in a restricted Python environment - called sandbox.
This environment is very limited, with strict restrictions on many modules and built-in functions.

### Unsafe Execution

**NOT RECOMMENDED FOR PRODUCTION**
This mode allows execution of any Python code, including dangerous calls to `sys, os..` and similar modules. [Check out](/en/tools/ai-ml/codeinterpretertool#enabling-unsafe-mode) how to enable this mode

## Logging

The `CodeInterpreterTool` logs the selected execution strategy to STDOUT

## Installation

To use this tool, you need to install the CrewAI tools package:

```shell
pip install 'crewai[tools]'
```

## Example

The following example demonstrates how to use the `CodeInterpreterTool` with a CrewAI agent:

```python Code
from crewai import Agent, Task, Crew, Process
from crewai_tools import CodeInterpreterTool

# Initialize the tool
code_interpreter = CodeInterpreterTool()

# Define an agent that uses the tool
programmer_agent = Agent(
    role="Python Programmer",
    goal="Write and execute Python code to solve problems",
    backstory="An expert Python programmer who can write efficient code to solve complex problems.",
    tools=[code_interpreter],
    verbose=True,
)

# Example task to generate and execute code
coding_task = Task(
    description="Write a Python function to calculate the Fibonacci sequence up to the 10th number and print the result.",
    expected_output="The Fibonacci sequence up to the 10th number.",
    agent=programmer_agent,
)

# Create and run the crew
crew = Crew(
    agents=[programmer_agent],
    tasks=[coding_task],
    verbose=True,
    process=Process.sequential,
)
result = crew.kickoff()
```

You can also enable code execution directly when creating an agent:

```python Code
from crewai import Agent

# Create an agent with code execution enabled
programmer_agent = Agent(
    role="Python Programmer",
    goal="Write and execute Python code to solve problems",
    backstory="An expert Python programmer who can write efficient code to solve complex problems.",
    allow_code_execution=True,  # This automatically adds the CodeInterpreterTool
    verbose=True,
)
```

### Enabling `unsafe_mode`

```python Code
from crewai_tools import CodeInterpreterTool

code = """
import os
os.system("ls -la")
"""

CodeInterpreterTool(unsafe_mode=True).run(code=code)
```

## Parameters

The `CodeInterpreterTool` accepts the following parameters during initialization:

* **user\_dockerfile\_path**: Optional. Path to a custom Dockerfile to use for the code interpreter container.
* **user\_docker\_base\_url**: Optional. URL to the Docker daemon to use for running the container.
* **unsafe\_mode**: Optional. Whether to run code directly on the host machine instead of in a Docker container or sandbox. Default is `False`. Use with caution!
* **default\_image\_tag**: Optional. Default Docker image tag. Default is `code-interpreter:latest`

When using the tool with an agent, the agent will need to provide:

* **code**: Required. The Python 3 code to execute.
* **libraries\_used**: Optional. A list of libraries used in the code that need to be installed. Default is `[]`

## Agent Integration Example

Here's a more detailed example of how to integrate the `CodeInterpreterTool` with a CrewAI agent:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import CodeInterpreterTool

# Initialize the tool
code_interpreter = CodeInterpreterTool()

# Define an agent that uses the tool
data_analyst = Agent(
    role="Data Analyst",
    goal="Analyze data using Python code",
    backstory="""You are an expert data analyst who specializes in using Python
    to analyze and visualize data. You can write efficient code to process
    large datasets and extract meaningful insights.""",
    tools=[code_interpreter],
    verbose=True,
)

# Create a task for the agent
analysis_task = Task(
    description="""
    Write Python code to:
    1. Generate a random dataset of 100 points with x and y coordinates
    2. Calculate the correlation coefficient between x and y
    3. Create a scatter plot of the data
    4. Print the correlation coefficient and save the plot as 'scatter.png'

    Make sure to handle any necessary imports and print the results.
    """,
    expected_output="The correlation coefficient and confirmation that the scatter plot has been saved.",
    agent=data_analyst,
)

# Run the task
crew = Crew(
    agents=[data_analyst],
    tasks=[analysis_task],
    verbose=True,
    process=Process.sequential,
)
result = crew.kickoff()
```

## Implementation Details

The `CodeInterpreterTool` uses Docker to create a secure environment for code execution:

```python Code
class CodeInterpreterTool(BaseTool):
    name: str = "Code Interpreter"
    description: str = "Interprets Python3 code strings with a final print statement."
    args_schema: Type[BaseModel] = CodeInterpreterSchema
    default_image_tag: str = "code-interpreter:latest"

    def _run(self, **kwargs) -> str:
        code = kwargs.get("code", self.code)
        libraries_used = kwargs.get("libraries_used", [])

        if self.unsafe_mode:
            return self.run_code_unsafe(code, libraries_used)
        else:
            return self.run_code_safety(code, libraries_used)
```

The tool performs the following steps:

1. Verifies that the Docker image exists or builds it if necessary
2. Creates a Docker container with the current working directory mounted
3. Installs any required libraries specified by the agent
4. Executes the Python code in the container
5. Returns the output of the code execution
6. Cleans up by stopping and removing the container

## Security Considerations

By default, the `CodeInterpreterTool` runs code in an isolated Docker container, which provides a layer of security. However, there are still some security considerations to keep in mind:

1. The Docker container has access to the current working directory, so sensitive files could potentially be accessed.
2. If the Docker container is unavailable and the code needs to run safely, it will be executed in a sandbox environment. For security reasons, installing arbitrary libraries is not allowed
3. The `unsafe_mode` parameter allows code to be executed directly on the host machine, which should only be used in trusted environments.
4. Be cautious when allowing agents to install arbitrary libraries, as they could potentially include malicious code.

## Conclusion

The `CodeInterpreterTool` provides a powerful way for CrewAI agents to execute Python code in a relatively secure environment. By enabling agents to write and run code, it significantly expands their problem-solving capabilities, especially for tasks involving data analysis, calculations, or other computational work. This tool is particularly useful for agents that need to perform complex operations that are more efficiently expressed in code than in natural language.


# DALL-E Tool
Source: https://docs.crewai.com/en/tools/ai-ml/dalletool

The `DallETool` is a powerful tool designed for generating images from textual descriptions.

# `DallETool`

## Description

This tool is used to give the Agent the ability to generate images using the DALL-E model. It is a transformer-based model that generates images from textual descriptions.
This tool allows the Agent to generate images based on the text input provided by the user.

## Installation

Install the crewai\_tools package

```shell
pip install 'crewai[tools]'
```

## Example

Remember that when using this tool, the text must be generated by the Agent itself. The text must be a description of the image you want to generate.

```python Code
from crewai_tools import DallETool

Agent(
    ...
    tools=[DallETool()],
)
```

If needed you can also tweak the parameters of the DALL-E model by passing them as arguments to the `DallETool` class. For example:

```python Code
from crewai_tools import DallETool

dalle_tool = DallETool(model="dall-e-3",
                       size="1024x1024",
                       quality="standard",
                       n=1)

Agent(
    ...
    tools=[dalle_tool]
)
```

The parameters are based on the `client.images.generate` method from the OpenAI API. For more information on the parameters,
please refer to the [OpenAI API documentation](https://platform.openai.com/docs/guides/images/introduction?lang=python).


# LangChain Tool
Source: https://docs.crewai.com/en/tools/ai-ml/langchaintool

The `LangChainTool` is a wrapper for LangChain tools and query engines.

## `LangChainTool`

<Info>
  CrewAI seamlessly integrates with LangChain's comprehensive [list of tools](https://python.langchain.com/docs/integrations/tools/), all of which can be used with CrewAI.
</Info>

```python Code
import os
from dotenv import load_dotenv
from crewai import Agent, Task, Crew
from crewai.tools import BaseTool
from pydantic import Field
from langchain_community.utilities import GoogleSerperAPIWrapper

# Set up your SERPER_API_KEY key in an .env file, eg:
# SERPER_API_KEY=<your api key>
load_dotenv()

search = GoogleSerperAPIWrapper()

class SearchTool(BaseTool):
    name: str = "Search"
    description: str = "Useful for search-based queries. Use this to find current information about markets, companies, and trends."
    search: GoogleSerperAPIWrapper = Field(default_factory=GoogleSerperAPIWrapper)

    def _run(self, query: str) -> str:
        """Execute the search query and return results"""
        try:
            return self.search.run(query)
        except Exception as e:
            return f"Error performing search: {str(e)}"

# Create Agents
researcher = Agent(
    role='Research Analyst',
    goal='Gather current market data and trends',
    backstory="""You are an expert research analyst with years of experience in
    gathering market intelligence. You're known for your ability to find
    relevant and up-to-date market information and present it in a clear,
    actionable format.""",
    tools=[SearchTool()],
    verbose=True
)

# rest of the code ...
```

## Conclusion

Tools are pivotal in extending the capabilities of CrewAI agents, enabling them to undertake a broad spectrum of tasks and collaborate effectively.
When building solutions with CrewAI, leverage both custom and existing tools to empower your agents and enhance the AI ecosystem. Consider utilizing error handling, caching mechanisms,
and the flexibility of tool arguments to optimize your agents' performance and capabilities.


# LlamaIndex Tool
Source: https://docs.crewai.com/en/tools/ai-ml/llamaindextool

The `LlamaIndexTool` is a wrapper for LlamaIndex tools and query engines.

# `LlamaIndexTool`

## Description

The `LlamaIndexTool` is designed to be a general wrapper around LlamaIndex tools and query engines, enabling you to leverage LlamaIndex resources in terms of RAG/agentic pipelines as tools to plug into CrewAI agents. This tool allows you to seamlessly integrate LlamaIndex's powerful data processing and retrieval capabilities into your CrewAI workflows.

## Installation

To use this tool, you need to install LlamaIndex:

```shell
uv add llama-index
```

## Steps to Get Started

To effectively use the `LlamaIndexTool`, follow these steps:

1. **Install LlamaIndex**: Install the LlamaIndex package using the command above.
2. **Set Up LlamaIndex**: Follow the [LlamaIndex documentation](https://docs.llamaindex.ai/) to set up a RAG/agent pipeline.
3. **Create a Tool or Query Engine**: Create a LlamaIndex tool or query engine that you want to use with CrewAI.

## Example

The following examples demonstrate how to initialize the tool from different LlamaIndex components:

### From a LlamaIndex Tool

```python Code
from crewai_tools import LlamaIndexTool
from crewai import Agent
from llama_index.core.tools import FunctionTool

# Example 1: Initialize from FunctionTool
def search_data(query: str) -> str:
    """Search for information in the data."""
    # Your implementation here
    return f"Results for: {query}"

# Create a LlamaIndex FunctionTool
og_tool = FunctionTool.from_defaults(
    search_data,
    name="DataSearchTool",
    description="Search for information in the data"
)

# Wrap it with LlamaIndexTool
tool = LlamaIndexTool.from_tool(og_tool)

# Define an agent that uses the tool
@agent
def researcher(self) -> Agent:
    '''
    This agent uses the LlamaIndexTool to search for information.
    '''
    return Agent(
        config=self.agents_config["researcher"],
        tools=[tool]
    )
```

### From LlamaHub Tools

```python Code
from crewai_tools import LlamaIndexTool
from llama_index.tools.wolfram_alpha import WolframAlphaToolSpec

# Initialize from LlamaHub Tools
wolfram_spec = WolframAlphaToolSpec(app_id="your_app_id")
wolfram_tools = wolfram_spec.to_tool_list()
tools = [LlamaIndexTool.from_tool(t) for t in wolfram_tools]
```

### From a LlamaIndex Query Engine

```python Code
from crewai_tools import LlamaIndexTool
from llama_index.core import VectorStoreIndex
from llama_index.core.readers import SimpleDirectoryReader

# Load documents
documents = SimpleDirectoryReader("./data").load_data()

# Create an index
index = VectorStoreIndex.from_documents(documents)

# Create a query engine
query_engine = index.as_query_engine()

# Create a LlamaIndexTool from the query engine
query_tool = LlamaIndexTool.from_query_engine(
    query_engine,
    name="Company Data Query Tool",
    description="Use this tool to lookup information in company documents"
)
```

## Class Methods

The `LlamaIndexTool` provides two main class methods for creating instances:

### from\_tool

Creates a `LlamaIndexTool` from a LlamaIndex tool.

```python Code
@classmethod
def from_tool(cls, tool: Any, **kwargs: Any) -> "LlamaIndexTool":
    # Implementation details
```

### from\_query\_engine

Creates a `LlamaIndexTool` from a LlamaIndex query engine.

```python Code
@classmethod
def from_query_engine(
    cls,
    query_engine: Any,
    name: Optional[str] = None,
    description: Optional[str] = None,
    return_direct: bool = False,
    **kwargs: Any,
) -> "LlamaIndexTool":
    # Implementation details
```

## Parameters

The `from_query_engine` method accepts the following parameters:

* **query\_engine**: Required. The LlamaIndex query engine to wrap.
* **name**: Optional. The name of the tool.
* **description**: Optional. The description of the tool.
* **return\_direct**: Optional. Whether to return the response directly. Default is `False`.

## Conclusion

The `LlamaIndexTool` provides a powerful way to integrate LlamaIndex's capabilities into CrewAI agents. By wrapping LlamaIndex tools and query engines, it enables agents to leverage sophisticated data retrieval and processing functionalities, enhancing their ability to work with complex information sources.


# Overview
Source: https://docs.crewai.com/en/tools/ai-ml/overview

Leverage AI services, generate images, process vision, and build intelligent systems

These tools integrate with AI and machine learning services to enhance your agents with advanced capabilities like image generation, vision processing, and intelligent code execution.

## **Available Tools**

<CardGroup cols={2}>
  <Card title="DALL-E Tool" icon="image" href="/en/tools/ai-ml/dalletool">
    Generate AI images using OpenAI's DALL-E model.
  </Card>

  <Card title="Vision Tool" icon="eye" href="/en/tools/ai-ml/visiontool">
    Process and analyze images with computer vision capabilities.
  </Card>

  <Card title="AI Mind Tool" icon="brain" href="/en/tools/ai-ml/aimindtool">
    Advanced AI reasoning and decision-making capabilities.
  </Card>

  <Card title="LlamaIndex Tool" icon="llama" href="/en/tools/ai-ml/llamaindextool">
    Build knowledge bases and retrieval systems with LlamaIndex.
  </Card>

  <Card title="LangChain Tool" icon="link" href="/en/tools/ai-ml/langchaintool">
    Integrate with LangChain for complex AI workflows.
  </Card>

  <Card title="RAG Tool" icon="database" href="/en/tools/ai-ml/ragtool">
    Implement Retrieval-Augmented Generation systems.
  </Card>

  <Card title="Code Interpreter Tool" icon="code" href="/en/tools/ai-ml/codeinterpretertool">
    Execute Python code and perform data analysis.
  </Card>
</CardGroup>

## **Common Use Cases**

* **Content Generation**: Create images, text, and multimedia content
* **Data Analysis**: Execute code and analyze complex datasets
* **Knowledge Systems**: Build RAG systems and intelligent databases
* **Computer Vision**: Process and understand visual content
* **AI Safety**: Implement content moderation and safety checks

```python
from crewai_tools import DallETool, VisionTool, CodeInterpreterTool

# Create AI tools
image_generator = DallETool()
vision_processor = VisionTool()
code_executor = CodeInterpreterTool()

# Add to your agent
agent = Agent(
    role="AI Specialist",
    tools=[image_generator, vision_processor, code_executor],
    goal="Create and analyze content using AI capabilities"
)
```


# RAG Tool
Source: https://docs.crewai.com/en/tools/ai-ml/ragtool

The `RagTool` is a dynamic knowledge base tool for answering questions using Retrieval-Augmented Generation.

# `RagTool`

## Description

The `RagTool` is designed to answer questions by leveraging the power of Retrieval-Augmented Generation (RAG) through EmbedChain.
It provides a dynamic knowledge base that can be queried to retrieve relevant information from various data sources.
This tool is particularly useful for applications that require access to a vast array of information and need to provide contextually relevant answers.

## Example

The following example demonstrates how to initialize the tool and use it with different data sources:

```python Code
from crewai_tools import RagTool

# Create a RAG tool with default settings
rag_tool = RagTool()

# Add content from a file
rag_tool.add(data_type="file", path="path/to/your/document.pdf")

# Add content from a web page
rag_tool.add(data_type="web_page", url="https://example.com")

# Define an agent with the RagTool
@agent
def knowledge_expert(self) -> Agent:
    '''
    This agent uses the RagTool to answer questions about the knowledge base.
    '''
    return Agent(
        config=self.agents_config["knowledge_expert"],
        allow_delegation=False,
        tools=[rag_tool]
    )
```

## Supported Data Sources

The `RagTool` can be used with a wide variety of data sources, including:

* 📰 PDF files
* 📊 CSV files
* 📃 JSON files
* 📝 Text
* 📁 Directories/Folders
* 🌐 HTML Web pages
* 📽️ YouTube Channels
* 📺 YouTube Videos
* 📚 Documentation websites
* 📝 MDX files
* 📄 DOCX files
* 🧾 XML files
* 📬 Gmail
* 📝 GitHub repositories
* 🐘 PostgreSQL databases
* 🐬 MySQL databases
* 🤖 Slack conversations
* 💬 Discord messages
* 🗨️ Discourse forums
* 📝 Substack newsletters
* 🐝 Beehiiv content
* 💾 Dropbox files
* 🖼️ Images
* ⚙️ Custom data sources

## Parameters

The `RagTool` accepts the following parameters:

* **summarize**: Optional. Whether to summarize the retrieved content. Default is `False`.
* **adapter**: Optional. A custom adapter for the knowledge base. If not provided, an EmbedchainAdapter will be used.
* **config**: Optional. Configuration for the underlying EmbedChain App.

## Adding Content

You can add content to the knowledge base using the `add` method:

```python Code
# Add a PDF file
rag_tool.add(data_type="file", path="path/to/your/document.pdf")

# Add a web page
rag_tool.add(data_type="web_page", url="https://example.com")

# Add a YouTube video
rag_tool.add(data_type="youtube_video", url="https://www.youtube.com/watch?v=VIDEO_ID")

# Add a directory of files
rag_tool.add(data_type="directory", path="path/to/your/directory")
```

## Agent Integration Example

Here's how to integrate the `RagTool` with a CrewAI agent:

```python Code
from crewai import Agent
from crewai.project import agent
from crewai_tools import RagTool

# Initialize the tool and add content
rag_tool = RagTool()
rag_tool.add(data_type="web_page", url="https://docs.crewai.com")
rag_tool.add(data_type="file", path="company_data.pdf")

# Define an agent with the RagTool
@agent
def knowledge_expert(self) -> Agent:
    return Agent(
        config=self.agents_config["knowledge_expert"],
        allow_delegation=False,
        tools=[rag_tool]
    )
```

## Advanced Configuration

You can customize the behavior of the `RagTool` by providing a configuration dictionary:

```python Code
from crewai_tools import RagTool

# Create a RAG tool with custom configuration
config = {
    "app": {
        "name": "custom_app",
    },
    "llm": {
        "provider": "openai",
        "config": {
            "model": "gpt-4",
        }
    },
    "embedding_model": {
        "provider": "openai",
        "config": {
            "model": "text-embedding-ada-002"
        }
    },
    "vectordb": {
        "provider": "elasticsearch",
        "config": {
            "collection_name": "my-collection",
            "cloud_id": "deployment-name:xxxx",
            "api_key": "your-key",
            "verify_certs": False
        }
    },
    "chunker": {
        "chunk_size": 400,
        "chunk_overlap": 100,
        "length_function": "len",
        "min_chunk_size": 0
    }
}

rag_tool = RagTool(config=config, summarize=True)
```

The internal RAG tool utilizes the Embedchain adapter, allowing you to pass any configuration options that are supported by Embedchain.
You can refer to the [Embedchain documentation](https://docs.embedchain.ai/components/introduction) for details.
Make sure to review the configuration options available in the .yaml file.

## Conclusion

The `RagTool` provides a powerful way to create and query knowledge bases from various data sources. By leveraging Retrieval-Augmented Generation, it enables agents to access and retrieve relevant information efficiently, enhancing their ability to provide accurate and contextually appropriate responses.


# Vision Tool
Source: https://docs.crewai.com/en/tools/ai-ml/visiontool

The `VisionTool` is designed to extract text from images.

# `VisionTool`

## Description

This tool is used to extract text from images. When passed to the agent it will extract the text from the image and then use it to generate a response, report or any other output.
The URL or the PATH of the image should be passed to the Agent.

## Installation

Install the crewai\_tools package

```shell
pip install 'crewai[tools]'
```

## Usage

In order to use the VisionTool, the OpenAI API key should be set in the environment variable `OPENAI_API_KEY`.

```python Code
from crewai_tools import VisionTool

vision_tool = VisionTool()

@agent
def researcher(self) -> Agent:
    '''
    This agent uses the VisionTool to extract text from images.
    '''
    return Agent(
        config=self.agents_config["researcher"],
        allow_delegation=False,
        tools=[vision_tool]
    )
```

## Arguments

The VisionTool requires the following arguments:

| Argument             | Type     | Description                                                                      |
| :------------------- | :------- | :------------------------------------------------------------------------------- |
| **image\_path\_url** | `string` | **Mandatory**. The path to the image file from which text needs to be extracted. |


# Apify Actors
Source: https://docs.crewai.com/en/tools/automation/apifyactorstool

`ApifyActorsTool` lets you call Apify Actors to provide your CrewAI workflows with web scraping, crawling, data extraction, and web automation capabilities.

# `ApifyActorsTool`

Integrate [Apify Actors](https://apify.com/actors) into your CrewAI workflows.

## Description

The `ApifyActorsTool` connects [Apify Actors](https://apify.com/actors), cloud-based programs for web scraping and automation, to your CrewAI workflows.
Use any of the 4,000+ Actors on [Apify Store](https://apify.com/store) for use cases such as extracting data from social media, search engines, online maps, e-commerce sites, travel portals, or general websites.

For details, see the [Apify CrewAI integration](https://docs.apify.com/platform/integrations/crewai) in Apify documentation.

## Steps to get started

<Steps>
  <Step title="Install dependencies">
    Install `crewai[tools]` and `langchain-apify` using pip: `pip install 'crewai[tools]' langchain-apify`.
  </Step>

  <Step title="Obtain an Apify API token">
    Sign up to [Apify Console](https://console.apify.com/) and get your [Apify API token](https://console.apify.com/settings/integrations)..
  </Step>

  <Step title="Configure environment">
    Set your Apify API token as the `APIFY_API_TOKEN` environment variable to enable the tool's functionality.
  </Step>
</Steps>

## Usage example

Use the `ApifyActorsTool` manually to run the [RAG Web Browser Actor](https://apify.com/apify/rag-web-browser) to perform a web search:

```python
from crewai_tools import ApifyActorsTool

# Initialize the tool with an Apify Actor
tool = ApifyActorsTool(actor_name="apify/rag-web-browser")

# Run the tool with input parameters
results = tool.run(run_input={"query": "What is CrewAI?", "maxResults": 5})

# Process the results
for result in results:
    print(f"URL: {result['metadata']['url']}")
    print(f"Content: {result.get('markdown', 'N/A')[:100]}...")
```

### Expected output

Here is the output from running the code above:

```text
URL: https://www.example.com/crewai-intro
Content: CrewAI is a framework for building AI-powered workflows...
URL: https://docs.crewai.com/
Content: Official documentation for CrewAI...
```

The `ApifyActorsTool` automatically fetches the Actor definition and input schema from Apify using the provided `actor_name` and then constructs the tool description and argument schema. This means you need to specify only a valid `actor_name`, and the tool handles the rest when used with agents—no need to specify the `run_input`. Here's how it works:

```python
from crewai import Agent
from crewai_tools import ApifyActorsTool

rag_browser = ApifyActorsTool(actor_name="apify/rag-web-browser")

agent = Agent(
    role="Research Analyst",
    goal="Find and summarize information about specific topics",
    backstory="You are an experienced researcher with attention to detail",
    tools=[rag_browser],
)
```

You can run other Actors from [Apify Store](https://apify.com/store) simply by changing the `actor_name` and, when using it manually, adjusting the `run_input` based on the Actor input schema.

For an example of usage with agents, see the [CrewAI Actor template](https://apify.com/templates/python-crewai).

## Configuration

The `ApifyActorsTool` requires these inputs to work:

* **`actor_name`**
  The ID of the Apify Actor to run, e.g., `"apify/rag-web-browser"`. Browse all Actors on [Apify Store](https://apify.com/store).
* **`run_input`**
  A dictionary of input parameters for the Actor when running the tool manually.
  * For example, for the `apify/rag-web-browser` Actor: `{"query": "search term", "maxResults": 5}`
  * See the Actor's [input schema](https://apify.com/apify/rag-web-browser/input-schema) for the list of input parameters.

## Resources

* **[Apify](https://apify.com/)**: Explore the Apify platform.
* **[How to build an AI agent on Apify](https://blog.apify.com/how-to-build-an-ai-agent/)** - A complete step-by-step guide to creating, publishing, and monetizing AI agents on the Apify platform.
* **[RAG Web Browser Actor](https://apify.com/apify/rag-web-browser)**: A popular Actor for web search for LLMs.
* **[CrewAI Integration Guide](https://docs.apify.com/platform/integrations/crewai)**: Follow the official guide for integrating Apify and CrewAI.


# Composio Tool
Source: https://docs.crewai.com/en/tools/automation/composiotool

Composio provides 250+ production-ready tools for AI agents with flexible authentication management.

# `ComposioToolSet`

## Description

Composio is an integration platform that allows you to connect your AI agents to 250+ tools. Key features include:

* **Enterprise-Grade Authentication**: Built-in support for OAuth, API Keys, JWT with automatic token refresh
* **Full Observability**: Detailed tool usage logs, execution timestamps, and more

## Installation

To incorporate Composio tools into your project, follow the instructions below:

```shell
pip install composio-crewai
pip install crewai
```

After the installation is complete, either run `composio login` or export your composio API key as `COMPOSIO_API_KEY`. Get your Composio API key from [here](https://app.composio.dev)

## Example

The following example demonstrates how to initialize the tool and execute a github action:

1. Initialize Composio toolset

```python Code
from composio_crewai import ComposioToolSet, App, Action
from crewai import Agent, Task, Crew

toolset = ComposioToolSet()
```

2. Connect your GitHub account

<CodeGroup>
  ```shell CLI
  composio add github
  ```

  ```python Code
  request = toolset.initiate_connection(app=App.GITHUB)
  print(f"Open this URL to authenticate: {request.redirectUrl}")
  ```
</CodeGroup>

3. Get Tools

* Retrieving all the tools from an app (not recommended for production):

```python Code
tools = toolset.get_tools(apps=[App.GITHUB])
```

* Filtering tools based on tags:

```python Code
tag = "users"

filtered_action_enums = toolset.find_actions_by_tags(
    App.GITHUB,
    tags=[tag],
)

tools = toolset.get_tools(actions=filtered_action_enums)
```

* Filtering tools based on use case:

```python Code
use_case = "Star a repository on GitHub"

filtered_action_enums = toolset.find_actions_by_use_case(
    App.GITHUB, use_case=use_case, advanced=False
)

tools = toolset.get_tools(actions=filtered_action_enums)
```

<Tip>Set `advanced` to True to get actions for complex use cases</Tip>

* Using specific tools:

In this demo, we will use the `GITHUB_STAR_A_REPOSITORY_FOR_THE_AUTHENTICATED_USER` action from the GitHub app.

```python Code
tools = toolset.get_tools(
    actions=[Action.GITHUB_STAR_A_REPOSITORY_FOR_THE_AUTHENTICATED_USER]
)
```

Learn more about filtering actions [here](https://docs.composio.dev/patterns/tools/use-tools/use-specific-actions)

4. Define agent

```python Code
crewai_agent = Agent(
    role="GitHub Agent",
    goal="You take action on GitHub using GitHub APIs",
    backstory="You are AI agent that is responsible for taking actions on GitHub on behalf of users using GitHub APIs",
    verbose=True,
    tools=tools,
    llm= # pass an llm
)
```

5. Execute task

```python Code
task = Task(
    description="Star a repo composiohq/composio on GitHub",
    agent=crewai_agent,
    expected_output="Status of the operation",
)

crew = Crew(agents=[crewai_agent], tasks=[task])

crew.kickoff()
```

* More detailed list of tools can be found [here](https://app.composio.dev)


# MultiOn Tool
Source: https://docs.crewai.com/en/tools/automation/multiontool

The `MultiOnTool` empowers CrewAI agents with the capability to navigate and interact with the web through natural language instructions.

## Overview

The `MultiOnTool` is designed to wrap [MultiOn's](https://docs.multion.ai/welcome) web browsing capabilities, enabling CrewAI agents to control web browsers using natural language instructions. This tool facilitates seamless web browsing, making it an essential asset for projects requiring dynamic web data interaction and automation of web-based tasks.

## Installation

To use this tool, you need to install the MultiOn package:

```shell
uv add multion
```

You'll also need to install the MultiOn browser extension and enable API usage.

## Steps to Get Started

To effectively use the `MultiOnTool`, follow these steps:

1. **Install CrewAI**: Ensure that the `crewai[tools]` package is installed in your Python environment.
2. **Install and use MultiOn**: Follow [MultiOn documentation](https://docs.multion.ai/learn/browser-extension) for installing the MultiOn Browser Extension.
3. **Enable API Usage**: Click on the MultiOn extension in the extensions folder of your browser (not the hovering MultiOn icon on the web page) to open the extension configurations. Click the API Enabled toggle to enable the API.

## Example

The following example demonstrates how to initialize the tool and execute a web browsing task:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import MultiOnTool

# Initialize the tool
multion_tool = MultiOnTool(api_key="YOUR_MULTION_API_KEY", local=False)

# Define an agent that uses the tool
browser_agent = Agent(
    role="Browser Agent",
    goal="Control web browsers using natural language",
    backstory="An expert browsing agent.",
    tools=[multion_tool],
    verbose=True,
)

# Example task to search and summarize news
browse_task = Task(
    description="Summarize the top 3 trending AI News headlines",
    expected_output="A summary of the top 3 trending AI News headlines",
    agent=browser_agent,
)

# Create and run the crew
crew = Crew(agents=[browser_agent], tasks=[browse_task])
result = crew.kickoff()
```

## Parameters

The `MultiOnTool` accepts the following parameters during initialization:

* **api\_key**: Optional. Specifies the MultiOn API key. If not provided, it will look for the `MULTION_API_KEY` environment variable.
* **local**: Optional. Set to `True` to run the agent locally on your browser. Make sure the MultiOn browser extension is installed and API Enabled is checked. Default is `False`.
* **max\_steps**: Optional. Sets the maximum number of steps the MultiOn agent can take for a command. Default is `3`.

## Usage

When using the `MultiOnTool`, the agent will provide natural language instructions that the tool translates into web browsing actions. The tool returns the results of the browsing session along with a status.

```python Code
# Example of using the tool with an agent
browser_agent = Agent(
    role="Web Browser Agent",
    goal="Search for and summarize information from the web",
    backstory="An expert at finding and extracting information from websites.",
    tools=[multion_tool],
    verbose=True,
)

# Create a task for the agent
search_task = Task(
    description="Search for the latest AI news on TechCrunch and summarize the top 3 headlines",
    expected_output="A summary of the top 3 AI news headlines from TechCrunch",
    agent=browser_agent,
)

# Run the task
crew = Crew(agents=[browser_agent], tasks=[search_task])
result = crew.kickoff()
```

If the status returned is `CONTINUE`, the agent should be instructed to reissue the same instruction to continue execution.

## Implementation Details

The `MultiOnTool` is implemented as a subclass of `BaseTool` from CrewAI. It wraps the MultiOn client to provide web browsing capabilities:

```python Code
class MultiOnTool(BaseTool):
    """Tool to wrap MultiOn Browse Capabilities."""

    name: str = "Multion Browse Tool"
    description: str = """Multion gives the ability for LLMs to control web browsers using natural language instructions.
            If the status is 'CONTINUE', reissue the same instruction to continue execution
        """

    # Implementation details...

    def _run(self, cmd: str, *args: Any, **kwargs: Any) -> str:
        """
        Run the Multion client with the given command.

        Args:
            cmd (str): The detailed and specific natural language instruction for web browsing
            *args (Any): Additional arguments to pass to the Multion client
            **kwargs (Any): Additional keyword arguments to pass to the Multion client
        """
        # Implementation details...
```

## Conclusion

The `MultiOnTool` provides a powerful way to integrate web browsing capabilities into CrewAI agents. By enabling agents to interact with websites through natural language instructions, it opens up a wide range of possibilities for web-based tasks, from data collection and research to automated interactions with web services.


# Overview
Source: https://docs.crewai.com/en/tools/automation/overview

Automate workflows and integrate with external platforms and services

These tools enable your agents to automate workflows, integrate with external platforms, and connect with various third-party services for enhanced functionality.

## **Available Tools**

<CardGroup cols={2}>
  <Card title="Apify Actor Tool" icon="spider" href="/en/tools/automation/apifyactorstool">
    Run Apify actors for web scraping and automation tasks.
  </Card>

  <Card title="Composio Tool" icon="puzzle-piece" href="/en/tools/automation/composiotool">
    Integrate with hundreds of apps and services through Composio.
  </Card>

  <Card title="Multion Tool" icon="window-restore" href="/en/tools/automation/multiontool">
    Automate browser interactions and web-based workflows.
  </Card>
</CardGroup>

## **Common Use Cases**

* **Workflow Automation**: Automate repetitive tasks and processes
* **API Integration**: Connect with external APIs and services
* **Data Synchronization**: Sync data between different platforms
* **Process Orchestration**: Coordinate complex multi-step workflows
* **Third-party Services**: Leverage external tools and platforms

```python
from crewai_tools import ApifyActorTool, ComposioTool, MultiOnTool

# Create automation tools
apify_automation = ApifyActorTool()
platform_integration = ComposioTool()
browser_automation = MultiOnTool()

# Add to your agent
agent = Agent(
    role="Automation Specialist",
    tools=[apify_automation, platform_integration, browser_automation],
    goal="Automate workflows and integrate systems"
)
```

## **Integration Benefits**

* **Efficiency**: Reduce manual work through automation
* **Scalability**: Handle increased workloads automatically
* **Reliability**: Consistent execution of workflows
* **Connectivity**: Bridge different systems and platforms
* **Productivity**: Focus on high-value tasks while automation handles routine work


# Bedrock Invoke Agent Tool
Source: https://docs.crewai.com/en/tools/cloud-storage/bedrockinvokeagenttool

Enables CrewAI agents to invoke Amazon Bedrock Agents and leverage their capabilities within your workflows

# `BedrockInvokeAgentTool`

The `BedrockInvokeAgentTool` enables CrewAI agents to invoke Amazon Bedrock Agents and leverage their capabilities within your workflows.

## Installation

```bash
uv pip install 'crewai[tools]'
```

## Requirements

* AWS credentials configured (either through environment variables or AWS CLI)
* `boto3` and `python-dotenv` packages
* Access to Amazon Bedrock Agents

## Usage

Here's how to use the tool with a CrewAI agent:

```python {2, 4-8}
from crewai import Agent, Task, Crew
from crewai_tools.aws.bedrock.agents.invoke_agent_tool import BedrockInvokeAgentTool

# Initialize the tool
agent_tool = BedrockInvokeAgentTool(
    agent_id="your-agent-id",
    agent_alias_id="your-agent-alias-id"
)

# Create a CrewAI agent that uses the tool
aws_expert = Agent(
    role='AWS Service Expert',
    goal='Help users understand AWS services and quotas',
    backstory='I am an expert in AWS services and can provide detailed information about them.',
    tools=[agent_tool],
    verbose=True
)

# Create a task for the agent
quota_task = Task(
    description="Find out the current service quotas for EC2 in us-west-2 and explain any recent changes.",
    agent=aws_expert
)

# Create a crew with the agent
crew = Crew(
    agents=[aws_expert],
    tasks=[quota_task],
    verbose=2
)

# Run the crew
result = crew.kickoff()
print(result)
```

## Tool Arguments

| Argument             | Type   | Required | Default   | Description                                 |
| :------------------- | :----- | :------- | :-------- | :------------------------------------------ |
| **agent\_id**        | `str`  | Yes      | None      | The unique identifier of the Bedrock agent  |
| **agent\_alias\_id** | `str`  | Yes      | None      | The unique identifier of the agent alias    |
| **session\_id**      | `str`  | No       | timestamp | The unique identifier of the session        |
| **enable\_trace**    | `bool` | No       | False     | Whether to enable trace for debugging       |
| **end\_session**     | `bool` | No       | False     | Whether to end the session after invocation |
| **description**      | `str`  | No       | None      | Custom description for the tool             |

## Environment Variables

```bash
BEDROCK_AGENT_ID=your-agent-id           # Alternative to passing agent_id
BEDROCK_AGENT_ALIAS_ID=your-agent-alias-id # Alternative to passing agent_alias_id
AWS_REGION=your-aws-region               # Defaults to us-west-2
AWS_ACCESS_KEY_ID=your-access-key        # Required for AWS authentication
AWS_SECRET_ACCESS_KEY=your-secret-key    # Required for AWS authentication
```

## Advanced Usage

### Multi-Agent Workflow with Session Management

```python {2, 4-22}
from crewai import Agent, Task, Crew, Process
from crewai_tools.aws.bedrock.agents.invoke_agent_tool import BedrockInvokeAgentTool

# Initialize tools with session management
initial_tool = BedrockInvokeAgentTool(
    agent_id="your-agent-id",
    agent_alias_id="your-agent-alias-id",
    session_id="custom-session-id"
)

followup_tool = BedrockInvokeAgentTool(
    agent_id="your-agent-id",
    agent_alias_id="your-agent-alias-id",
    session_id="custom-session-id"
)

final_tool = BedrockInvokeAgentTool(
    agent_id="your-agent-id",
    agent_alias_id="your-agent-alias-id",
    session_id="custom-session-id",
    end_session=True
)

# Create agents for different stages
researcher = Agent(
    role='AWS Service Researcher',
    goal='Gather information about AWS services',
    backstory='I am specialized in finding detailed AWS service information.',
    tools=[initial_tool]
)

analyst = Agent(
    role='Service Compatibility Analyst',
    goal='Analyze service compatibility and requirements',
    backstory='I analyze AWS services for compatibility and integration possibilities.',
    tools=[followup_tool]
)

summarizer = Agent(
    role='Technical Documentation Writer',
    goal='Create clear technical summaries',
    backstory='I specialize in creating clear, concise technical documentation.',
    tools=[final_tool]
)

# Create tasks
research_task = Task(
    description="Find all available AWS services in us-west-2 region.",
    agent=researcher
)

analysis_task = Task(
    description="Analyze which services support IPv6 and their implementation requirements.",
    agent=analyst
)

summary_task = Task(
    description="Create a summary of IPv6-compatible services and their key features.",
    agent=summarizer
)

# Create a crew with the agents and tasks
crew = Crew(
    agents=[researcher, analyst, summarizer],
    tasks=[research_task, analysis_task, summary_task],
    process=Process.sequential,
    verbose=2
)

# Run the crew
result = crew.kickoff()
```

## Use Cases

### Hybrid Multi-Agent Collaborations

* Create workflows where CrewAI agents collaborate with managed Bedrock agents running as services in AWS
* Enable scenarios where sensitive data processing happens within your AWS environment while other agents operate externally
* Bridge on-premises CrewAI agents with cloud-based Bedrock agents for distributed intelligence workflows

### Data Sovereignty and Compliance

* Keep data-sensitive agentic workflows within your AWS environment while allowing external CrewAI agents to orchestrate tasks
* Maintain compliance with data residency requirements by processing sensitive information only within your AWS account
* Enable secure multi-agent collaborations where some agents cannot access your organization's private data

### Seamless AWS Service Integration

* Access any AWS service through Amazon Bedrock Actions without writing complex integration code
* Enable CrewAI agents to interact with AWS services through natural language requests
* Leverage pre-built Bedrock agent capabilities to interact with AWS services like Bedrock Knowledge Bases, Lambda, and more

### Scalable Hybrid Agent Architectures

* Offload computationally intensive tasks to managed Bedrock agents while lightweight tasks run in CrewAI
* Scale agent processing by distributing workloads between local CrewAI agents and cloud-based Bedrock agents

### Cross-Organizational Agent Collaboration

* Enable secure collaboration between your organization's CrewAI agents and partner organizations' Bedrock agents
* Create workflows where external expertise from Bedrock agents can be incorporated without exposing sensitive data
* Build agent ecosystems that span organizational boundaries while maintaining security and data control


# Bedrock Knowledge Base Retriever
Source: https://docs.crewai.com/en/tools/cloud-storage/bedrockkbretriever

Retrieve information from Amazon Bedrock Knowledge Bases using natural language queries

# `BedrockKBRetrieverTool`

The `BedrockKBRetrieverTool` enables CrewAI agents to retrieve information from Amazon Bedrock Knowledge Bases using natural language queries.

## Installation

```bash
uv pip install 'crewai[tools]'
```

## Requirements

* AWS credentials configured (either through environment variables or AWS CLI)
* `boto3` and `python-dotenv` packages
* Access to Amazon Bedrock Knowledge Base

## Usage

Here's how to use the tool with a CrewAI agent:

```python {2, 4-17}
from crewai import Agent, Task, Crew
from crewai_tools.aws.bedrock.knowledge_base.retriever_tool import BedrockKBRetrieverTool

# Initialize the tool
kb_tool = BedrockKBRetrieverTool(
    knowledge_base_id="your-kb-id",
    number_of_results=5
)

# Create a CrewAI agent that uses the tool
researcher = Agent(
    role='Knowledge Base Researcher',
    goal='Find information about company policies',
    backstory='I am a researcher specialized in retrieving and analyzing company documentation.',
    tools=[kb_tool],
    verbose=True
)

# Create a task for the agent
research_task = Task(
    description="Find our company's remote work policy and summarize the key points.",
    agent=researcher
)

# Create a crew with the agent
crew = Crew(
    agents=[researcher],
    tasks=[research_task],
    verbose=2
)

# Run the crew
result = crew.kickoff()
print(result)
```

## Tool Arguments

| Argument                     | Type   | Required | Default | Description                                                                |
| :--------------------------- | :----- | :------- | :------ | :------------------------------------------------------------------------- |
| **knowledge\_base\_id**      | `str`  | Yes      | None    | The unique identifier of the knowledge base (0-10 alphanumeric characters) |
| **number\_of\_results**      | `int`  | No       | 5       | Maximum number of results to return                                        |
| **retrieval\_configuration** | `dict` | No       | None    | Custom configurations for the knowledge base query                         |
| **guardrail\_configuration** | `dict` | No       | None    | Content filtering settings                                                 |
| **next\_token**              | `str`  | No       | None    | Token for pagination                                                       |

## Environment Variables

```bash
BEDROCK_KB_ID=your-knowledge-base-id  # Alternative to passing knowledge_base_id
AWS_REGION=your-aws-region            # Defaults to us-east-1
AWS_ACCESS_KEY_ID=your-access-key     # Required for AWS authentication
AWS_SECRET_ACCESS_KEY=your-secret-key # Required for AWS authentication
```

## Response Format

The tool returns results in JSON format:

```json
{
  "results": [
    {
      "content": "Retrieved text content",
      "content_type": "text",
      "source_type": "S3",
      "source_uri": "s3://bucket/document.pdf",
      "score": 0.95,
      "metadata": {
        "additional": "metadata"
      }
    }
  ],
  "nextToken": "pagination-token",
  "guardrailAction": "NONE"
}
```

## Advanced Usage

### Custom Retrieval Configuration

```python
kb_tool = BedrockKBRetrieverTool(
    knowledge_base_id="your-kb-id",
    retrieval_configuration={
        "vectorSearchConfiguration": {
            "numberOfResults": 10,
            "overrideSearchType": "HYBRID"
        }
    }
)

policy_expert = Agent(
    role='Policy Expert',
    goal='Analyze company policies in detail',
    backstory='I am an expert in corporate policy analysis with deep knowledge of regulatory requirements.',
    tools=[kb_tool]
)
```

## Supported Data Sources

* Amazon S3
* Confluence
* Salesforce
* SharePoint
* Web pages
* Custom document locations
* Amazon Kendra
* SQL databases

## Use Cases

### Enterprise Knowledge Integration

* Enable CrewAI agents to access your organization's proprietary knowledge without exposing sensitive data
* Allow agents to make decisions based on your company's specific policies, procedures, and documentation
* Create agents that can answer questions based on your internal documentation while maintaining data security

### Specialized Domain Knowledge

* Connect CrewAI agents to domain-specific knowledge bases (legal, medical, technical) without retraining models
* Leverage existing knowledge repositories that are already maintained in your AWS environment
* Combine CrewAI's reasoning with domain-specific information from your knowledge bases

### Data-Driven Decision Making

* Ground CrewAI agent responses in your actual company data rather than general knowledge
* Ensure agents provide recommendations based on your specific business context and documentation
* Reduce hallucinations by retrieving factual information from your knowledge bases

### Scalable Information Access

* Access terabytes of organizational knowledge without embedding it all into your models
* Dynamically query only the relevant information needed for specific tasks
* Leverage AWS's scalable infrastructure to handle large knowledge bases efficiently

### Compliance and Governance

* Ensure CrewAI agents provide responses that align with your company's approved documentation
* Create auditable trails of information sources used by your agents
* Maintain control over what information sources your agents can access


# Overview
Source: https://docs.crewai.com/en/tools/cloud-storage/overview

Interact with cloud services, storage systems, and cloud-based AI platforms

These tools enable your agents to interact with cloud services, access cloud storage, and leverage cloud-based AI platforms for scalable operations.

## **Available Tools**

<CardGroup cols={2}>
  <Card title="S3 Reader Tool" icon="cloud" href="/en/tools/cloud-storage/s3readertool">
    Read files and data from Amazon S3 buckets.
  </Card>

  <Card title="S3 Writer Tool" icon="cloud-arrow-up" href="/en/tools/cloud-storage/s3writertool">
    Write and upload files to Amazon S3 storage.
  </Card>

  <Card title="Bedrock Invoke Agent" icon="aws" href="/en/tools/cloud-storage/bedrockinvokeagenttool">
    Invoke Amazon Bedrock agents for AI-powered tasks.
  </Card>

  <Card title="Bedrock KB Retriever" icon="database" href="/en/tools/cloud-storage/bedrockkbretriever">
    Retrieve information from Amazon Bedrock knowledge bases.
  </Card>
</CardGroup>

## **Common Use Cases**

* **File Storage**: Store and retrieve files from cloud storage systems
* **Data Backup**: Backup important data to cloud storage
* **AI Services**: Access cloud-based AI models and services
* **Knowledge Retrieval**: Query cloud-hosted knowledge bases
* **Scalable Operations**: Leverage cloud infrastructure for processing

```python
from crewai_tools import S3ReaderTool, S3WriterTool, BedrockInvokeAgentTool

# Create cloud tools
s3_reader = S3ReaderTool()
s3_writer = S3WriterTool()
bedrock_agent = BedrockInvokeAgentTool()

# Add to your agent
agent = Agent(
    role="Cloud Operations Specialist",
    tools=[s3_reader, s3_writer, bedrock_agent],
    goal="Manage cloud resources and AI services"
)
```


# S3 Reader Tool
Source: https://docs.crewai.com/en/tools/cloud-storage/s3readertool

The `S3ReaderTool` enables CrewAI agents to read files from Amazon S3 buckets.

# `S3ReaderTool`

## Description

The `S3ReaderTool` is designed to read files from Amazon S3 buckets. This tool allows CrewAI agents to access and retrieve content stored in S3, making it ideal for workflows that require reading data, configuration files, or any other content stored in AWS S3 storage.

## Installation

To use this tool, you need to install the required dependencies:

```shell
uv add boto3
```

## Steps to Get Started

To effectively use the `S3ReaderTool`, follow these steps:

1. **Install Dependencies**: Install the required packages using the command above.
2. **Configure AWS Credentials**: Set up your AWS credentials as environment variables.
3. **Initialize the Tool**: Create an instance of the tool.
4. **Specify S3 Path**: Provide the S3 path to the file you want to read.

## Example

The following example demonstrates how to use the `S3ReaderTool` to read a file from an S3 bucket:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools.aws.s3 import S3ReaderTool

# Initialize the tool
s3_reader_tool = S3ReaderTool()

# Define an agent that uses the tool
file_reader_agent = Agent(
    role="File Reader",
    goal="Read files from S3 buckets",
    backstory="An expert in retrieving and processing files from cloud storage.",
    tools=[s3_reader_tool],
    verbose=True,
)

# Example task to read a configuration file
read_task = Task(
    description="Read the configuration file from {my_bucket} and summarize its contents.",
    expected_output="A summary of the configuration file contents.",
    agent=file_reader_agent,
)

# Create and run the crew
crew = Crew(agents=[file_reader_agent], tasks=[read_task])
result = crew.kickoff(inputs={"my_bucket": "s3://my-bucket/config/app-config.json"})
```

## Parameters

The `S3ReaderTool` accepts the following parameter when used by an agent:

* **file\_path**: Required. The S3 file path in the format `s3://bucket-name/file-name`.

## AWS Credentials

The tool requires AWS credentials to access S3 buckets. You can configure these credentials using environment variables:

* **CREW\_AWS\_REGION**: The AWS region where your S3 bucket is located. Default is `us-east-1`.
* **CREW\_AWS\_ACCESS\_KEY\_ID**: Your AWS access key ID.
* **CREW\_AWS\_SEC\_ACCESS\_KEY**: Your AWS secret access key.

## Usage

When using the `S3ReaderTool` with an agent, the agent will need to provide the S3 file path:

```python Code
# Example of using the tool with an agent
file_reader_agent = Agent(
    role="File Reader",
    goal="Read files from S3 buckets",
    backstory="An expert in retrieving and processing files from cloud storage.",
    tools=[s3_reader_tool],
    verbose=True,
)

# Create a task for the agent to read a specific file
read_config_task = Task(
    description="Read the application configuration file from {my_bucket} and extract the database connection settings.",
    expected_output="The database connection settings from the configuration file.",
    agent=file_reader_agent,
)

# Run the task
crew = Crew(agents=[file_reader_agent], tasks=[read_config_task])
result = crew.kickoff(inputs={"my_bucket": "s3://my-bucket/config/app-config.json"})
```

## Error Handling

The `S3ReaderTool` includes error handling for common S3 issues:

* Invalid S3 path format
* Missing or inaccessible files
* Permission issues
* AWS credential problems

When an error occurs, the tool will return an error message that includes details about the issue.

## Implementation Details

The `S3ReaderTool` uses the AWS SDK for Python (boto3) to interact with S3:

```python Code
class S3ReaderTool(BaseTool):
    name: str = "S3 Reader Tool"
    description: str = "Reads a file from Amazon S3 given an S3 file path"

    def _run(self, file_path: str) -> str:
        try:
            bucket_name, object_key = self._parse_s3_path(file_path)

            s3 = boto3.client(
                's3',
                region_name=os.getenv('CREW_AWS_REGION', 'us-east-1'),
                aws_access_key_id=os.getenv('CREW_AWS_ACCESS_KEY_ID'),
                aws_secret_access_key=os.getenv('CREW_AWS_SEC_ACCESS_KEY')
            )

            # Read file content from S3
            response = s3.get_object(Bucket=bucket_name, Key=object_key)
            file_content = response['Body'].read().decode('utf-8')

            return file_content
        except ClientError as e:
            return f"Error reading file from S3: {str(e)}"
```

## Conclusion

The `S3ReaderTool` provides a straightforward way to read files from Amazon S3 buckets. By enabling agents to access content stored in S3, it facilitates workflows that require cloud-based file access. This tool is particularly useful for data processing, configuration management, and any task that involves retrieving information from AWS S3 storage.


# S3 Writer Tool
Source: https://docs.crewai.com/en/tools/cloud-storage/s3writertool

The `S3WriterTool` enables CrewAI agents to write content to files in Amazon S3 buckets.

# `S3WriterTool`

## Description

The `S3WriterTool` is designed to write content to files in Amazon S3 buckets. This tool allows CrewAI agents to create or update files in S3, making it ideal for workflows that require storing data, saving configuration files, or persisting any other content to AWS S3 storage.

## Installation

To use this tool, you need to install the required dependencies:

```shell
uv add boto3
```

## Steps to Get Started

To effectively use the `S3WriterTool`, follow these steps:

1. **Install Dependencies**: Install the required packages using the command above.
2. **Configure AWS Credentials**: Set up your AWS credentials as environment variables.
3. **Initialize the Tool**: Create an instance of the tool.
4. **Specify S3 Path and Content**: Provide the S3 path where you want to write the file and the content to be written.

## Example

The following example demonstrates how to use the `S3WriterTool` to write content to a file in an S3 bucket:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools.aws.s3 import S3WriterTool

# Initialize the tool
s3_writer_tool = S3WriterTool()

# Define an agent that uses the tool
file_writer_agent = Agent(
    role="File Writer",
    goal="Write content to files in S3 buckets",
    backstory="An expert in storing and managing files in cloud storage.",
    tools=[s3_writer_tool],
    verbose=True,
)

# Example task to write a report
write_task = Task(
    description="Generate a summary report of the quarterly sales data and save it to {my_bucket}.",
    expected_output="Confirmation that the report was successfully saved to S3.",
    agent=file_writer_agent,
)

# Create and run the crew
crew = Crew(agents=[file_writer_agent], tasks=[write_task])
result = crew.kickoff(inputs={"my_bucket": "s3://my-bucket/reports/quarterly-summary.txt"})
```

## Parameters

The `S3WriterTool` accepts the following parameters when used by an agent:

* **file\_path**: Required. The S3 file path in the format `s3://bucket-name/file-name`.
* **content**: Required. The content to write to the file.

## AWS Credentials

The tool requires AWS credentials to access S3 buckets. You can configure these credentials using environment variables:

* **CREW\_AWS\_REGION**: The AWS region where your S3 bucket is located. Default is `us-east-1`.
* **CREW\_AWS\_ACCESS\_KEY\_ID**: Your AWS access key ID.
* **CREW\_AWS\_SEC\_ACCESS\_KEY**: Your AWS secret access key.

## Usage

When using the `S3WriterTool` with an agent, the agent will need to provide both the S3 file path and the content to write:

```python Code
# Example of using the tool with an agent
file_writer_agent = Agent(
    role="File Writer",
    goal="Write content to files in S3 buckets",
    backstory="An expert in storing and managing files in cloud storage.",
    tools=[s3_writer_tool],
    verbose=True,
)

# Create a task for the agent to write a specific file
write_config_task = Task(
    description="""
    Create a configuration file with the following database settings:
    - host: db.example.com
    - port: 5432
    - username: app_user
    - password: secure_password

    Save this configuration as JSON to {my_bucket}.
    """,
    expected_output="Confirmation that the configuration file was successfully saved to S3.",
    agent=file_writer_agent,
)

# Run the task
crew = Crew(agents=[file_writer_agent], tasks=[write_config_task])
result = crew.kickoff(inputs={"my_bucket": "s3://my-bucket/config/db-config.json"})
```

## Error Handling

The `S3WriterTool` includes error handling for common S3 issues:

* Invalid S3 path format
* Permission issues (e.g., no write access to the bucket)
* AWS credential problems
* Bucket does not exist

When an error occurs, the tool will return an error message that includes details about the issue.

## Implementation Details

The `S3WriterTool` uses the AWS SDK for Python (boto3) to interact with S3:

```python Code
class S3WriterTool(BaseTool):
    name: str = "S3 Writer Tool"
    description: str = "Writes content to a file in Amazon S3 given an S3 file path"

    def _run(self, file_path: str, content: str) -> str:
        try:
            bucket_name, object_key = self._parse_s3_path(file_path)

            s3 = boto3.client(
                's3',
                region_name=os.getenv('CREW_AWS_REGION', 'us-east-1'),
                aws_access_key_id=os.getenv('CREW_AWS_ACCESS_KEY_ID'),
                aws_secret_access_key=os.getenv('CREW_AWS_SEC_ACCESS_KEY')
            )

            s3.put_object(Bucket=bucket_name, Key=object_key, Body=content.encode('utf-8'))
            return f"Successfully wrote content to {file_path}"
        except ClientError as e:
            return f"Error writing file to S3: {str(e)}"
```

## Conclusion

The `S3WriterTool` provides a straightforward way to write content to files in Amazon S3 buckets. By enabling agents to create and update files in S3, it facilitates workflows that require cloud-based file storage. This tool is particularly useful for data persistence, configuration management, report generation, and any task that involves storing information in AWS S3 storage.


# MySQL RAG Search
Source: https://docs.crewai.com/en/tools/database-data/mysqltool

The `MySQLSearchTool` is designed to search MySQL databases and return the most relevant results.

## Overview

This tool is designed to facilitate semantic searches within MySQL database tables. Leveraging the RAG (Retrieve and Generate) technology,
the MySQLSearchTool provides users with an efficient means of querying database table content, specifically tailored for MySQL databases.
It simplifies the process of finding relevant data through semantic search queries, making it an invaluable resource for users needing
to perform advanced queries on extensive datasets within a MySQL database.

## Installation

To install the `crewai_tools` package and utilize the MySQLSearchTool, execute the following command in your terminal:

```shell
pip install 'crewai[tools]'
```

## Example

Below is an example showcasing how to use the MySQLSearchTool to conduct a semantic search on a table within a MySQL database:

```python Code
from crewai_tools import MySQLSearchTool

# Initialize the tool with the database URI and the target table name
tool = MySQLSearchTool(
    db_uri='mysql://user:password@localhost:3306/mydatabase',
    table_name='employees'
)
```

## Arguments

The MySQLSearchTool requires the following arguments for its operation:

* `db_uri`: A string representing the URI of the MySQL database to be queried. This argument is mandatory and must include the necessary authentication details and the location of the database.
* `table_name`: A string specifying the name of the table within the database on which the semantic search will be performed. This argument is mandatory.

## Custom model and embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python Code
tool = MySQLSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google",
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# NL2SQL Tool
Source: https://docs.crewai.com/en/tools/database-data/nl2sqltool

The `NL2SQLTool` is designed to convert natural language to SQL queries.

## Overview

This tool is used to convert natural language to SQL queries. When passed to the agent it will generate queries and then use them to interact with the database.

This enables multiple workflows like having an Agent to access the database fetch information based on the goal and then use the information to generate a response, report or any other output.
Along with that provides the ability for the Agent to update the database based on its goal.

**Attention**: Make sure that the Agent has access to a Read-Replica or that is okay for the Agent to run insert/update queries on the database.

## Requirements

* SqlAlchemy
* Any DB compatible library (e.g. psycopg2, mysql-connector-python)

## Installation

Install the crewai\_tools package

```shell
pip install 'crewai[tools]'
```

## Usage

In order to use the NL2SQLTool, you need to pass the database URI to the tool. The URI should be in the format `dialect+driver://username:password@host:port/database`.

```python Code
from crewai_tools import NL2SQLTool

# psycopg2 was installed to run this example with PostgreSQL
nl2sql = NL2SQLTool(db_uri="postgresql://example@localhost:5432/test_db")

@agent
def researcher(self) -> Agent:
    return Agent(
        config=self.agents_config["researcher"],
        allow_delegation=False,
        tools=[nl2sql]
    )
```

## Example

The primary task goal was:

"Retrieve the average, maximum, and minimum monthly revenue for each city, but only include cities that have more than one user. Also, count the number of user in each city and
sort the results by the average monthly revenue in descending order"

So the Agent tried to get information from the DB, the first one is wrong so the Agent tries again and gets the correct information and passes to the next agent.

![alt text](https://github.com/crewAIInc/crewAI-tools/blob/main/crewai_tools/tools/nl2sql/images/image-2.png?raw=true)
![alt text](https://github.com/crewAIInc/crewAI-tools/raw/main/crewai_tools/tools/nl2sql/images/image-3.png)

The second task goal was:

"Review the data and create a detailed report, and then create the table on the database with the fields based on the data provided.
Include information on the average, maximum, and minimum monthly revenue for each city, but only include cities that have more than one user. Also, count the number of users in each city and sort the results by the average monthly revenue in descending order."

Now things start to get interesting, the Agent generates the SQL query to not only create the table but also insert the data into the table. And in the end the Agent still returns the final report which is exactly what was in the database.

![alt text](https://github.com/crewAIInc/crewAI-tools/raw/main/crewai_tools/tools/nl2sql/images/image-4.png)
![alt text](https://github.com/crewAIInc/crewAI-tools/raw/main/crewai_tools/tools/nl2sql/images/image-5.png)

![alt text](https://github.com/crewAIInc/crewAI-tools/raw/main/crewai_tools/tools/nl2sql/images/image-9.png)
![alt text](https://github.com/crewAIInc/crewAI-tools/raw/main/crewai_tools/tools/nl2sql/images/image-7.png)

This is a simple example of how the NL2SQLTool can be used to interact with the database and generate reports based on the data in the database.

The Tool provides endless possibilities on the logic of the Agent and how it can interact with the database.

```md
 DB -> Agent -> ... -> Agent -> DB
```


# Overview
Source: https://docs.crewai.com/en/tools/database-data/overview

Connect to databases, vector stores, and data warehouses for comprehensive data access

These tools enable your agents to interact with various database systems, from traditional SQL databases to modern vector stores and data warehouses.

## **Available Tools**

<CardGroup cols={2}>
  <Card title="MySQL Tool" icon="database" href="/en/tools/database-data/mysqltool">
    Connect to and query MySQL databases with SQL operations.
  </Card>

  <Card title="PostgreSQL Search" icon="elephant" href="/en/tools/database-data/pgsearchtool">
    Search and query PostgreSQL databases efficiently.
  </Card>

  <Card title="Snowflake Search" icon="snowflake" href="/en/tools/database-data/snowflakesearchtool">
    Access Snowflake data warehouse for analytics and reporting.
  </Card>

  <Card title="NL2SQL Tool" icon="language" href="/en/tools/database-data/nl2sqltool">
    Convert natural language queries to SQL statements automatically.
  </Card>

  <Card title="Qdrant Vector Search" icon="vector-square" href="/en/tools/database-data/qdrantvectorsearchtool">
    Search vector embeddings using Qdrant vector database.
  </Card>

  <Card title="Weaviate Vector Search" icon="network-wired" href="/en/tools/database-data/weaviatevectorsearchtool">
    Perform semantic search with Weaviate vector database.
  </Card>
</CardGroup>

## **Common Use Cases**

* **Data Analysis**: Query databases for business intelligence and reporting
* **Vector Search**: Find similar content using semantic embeddings
* **ETL Operations**: Extract, transform, and load data between systems
* **Real-time Analytics**: Access live data for decision making

```python
from crewai_tools import MySQLTool, QdrantVectorSearchTool, NL2SQLTool

# Create database tools
mysql_db = MySQLTool()
vector_search = QdrantVectorSearchTool()
nl_to_sql = NL2SQLTool()

# Add to your agent
agent = Agent(
    role="Data Analyst",
    tools=[mysql_db, vector_search, nl_to_sql],
    goal="Extract insights from various data sources"
)
```


# PG RAG Search
Source: https://docs.crewai.com/en/tools/database-data/pgsearchtool

The `PGSearchTool` is designed to search PostgreSQL databases and return the most relevant results.

## Overview

<Note>
  The PGSearchTool is currently under development. This document outlines the intended functionality and interface.
  As development progresses, please be aware that some features may not be available or could change.
</Note>

## Description

The PGSearchTool is envisioned as a powerful tool for facilitating semantic searches within PostgreSQL database tables. By leveraging advanced Retrieve and Generate (RAG) technology,
it aims to provide an efficient means for querying database table content, specifically tailored for PostgreSQL databases.
The tool's goal is to simplify the process of finding relevant data through semantic search queries, offering a valuable resource for users needing to conduct advanced queries on
extensive datasets within a PostgreSQL environment.

## Installation

The `crewai_tools` package, which will include the PGSearchTool upon its release, can be installed using the following command:

```shell
pip install 'crewai[tools]'
```

<Note>
  The PGSearchTool is not yet available in the current version of the `crewai_tools` package. This installation command will be updated once the tool is released.
</Note>

## Example Usage

Below is a proposed example showcasing how to use the PGSearchTool for conducting a semantic search on a table within a PostgreSQL database:

```python Code
from crewai_tools import PGSearchTool

# Initialize the tool with the database URI and the target table name
tool = PGSearchTool(
    db_uri='postgresql://user:password@localhost:5432/mydatabase',
    table_name='employees'
)
```

## Arguments

The PGSearchTool is designed to require the following arguments for its operation:

| Argument        | Type     | Description                                                                                                                                                                                                    |
| :-------------- | :------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **db\_uri**     | `string` | **Mandatory**. A string representing the URI of the PostgreSQL database to be queried. This argument will be mandatory and must include the necessary authentication details and the location of the database. |
| **table\_name** | `string` | **Mandatory**. A string specifying the name of the table within the database on which the semantic search will be performed. This argument will also be mandatory.                                             |

## Custom Model and Embeddings

The tool intends to use OpenAI for both embeddings and summarization by default. Users will have the option to customize the model using a config dictionary as follows:

```python Code
tool = PGSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Qdrant Vector Search Tool
Source: https://docs.crewai.com/en/tools/database-data/qdrantvectorsearchtool

Semantic search capabilities for CrewAI agents using Qdrant vector database

## Overview

The Qdrant Vector Search Tool enables semantic search capabilities in your CrewAI agents by leveraging [Qdrant](https://qdrant.tech/), a vector similarity search engine. This tool allows your agents to search through documents stored in a Qdrant collection using semantic similarity.

## Installation

Install the required packages:

```bash
uv add qdrant-client
```

## Basic Usage

Here's a minimal example of how to use the tool:

```python
from crewai import Agent
from crewai_tools import QdrantVectorSearchTool

# Initialize the tool
qdrant_tool = QdrantVectorSearchTool(
    qdrant_url="your_qdrant_url",
    qdrant_api_key="your_qdrant_api_key",
    collection_name="your_collection"
)

# Create an agent that uses the tool
agent = Agent(
    role="Research Assistant",
    goal="Find relevant information in documents",
    tools=[qdrant_tool]
)

# The tool will automatically use OpenAI embeddings
# and return the 3 most relevant results with scores > 0.35
```

## Complete Working Example

Here's a complete example showing how to:

1. Extract text from a PDF
2. Generate embeddings using OpenAI
3. Store in Qdrant
4. Create a CrewAI agentic RAG workflow for semantic search

```python
import os
import uuid
import pdfplumber
from openai import OpenAI
from dotenv import load_dotenv
from crewai import Agent, Task, Crew, Process, LLM
from crewai_tools import QdrantVectorSearchTool
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct, Distance, VectorParams

# Load environment variables
load_dotenv()

# Initialize OpenAI client
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Extract text from PDF
def extract_text_from_pdf(pdf_path):
    text = []
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text.append(page_text.strip())
    return text

# Generate OpenAI embeddings
def get_openai_embedding(text):
    response = client.embeddings.create(
        input=text,
        model="text-embedding-3-small"
    )
    return response.data[0].embedding

# Store text and embeddings in Qdrant
def load_pdf_to_qdrant(pdf_path, qdrant, collection_name):
    # Extract text from PDF
    text_chunks = extract_text_from_pdf(pdf_path)

    # Create Qdrant collection
    if qdrant.collection_exists(collection_name):
        qdrant.delete_collection(collection_name)
    qdrant.create_collection(
        collection_name=collection_name,
        vectors_config=VectorParams(size=1536, distance=Distance.COSINE)
    )

    # Store embeddings
    points = []
    for chunk in text_chunks:
        embedding = get_openai_embedding(chunk)
        points.append(PointStruct(
            id=str(uuid.uuid4()),
            vector=embedding,
            payload={"text": chunk}
        ))
    qdrant.upsert(collection_name=collection_name, points=points)

# Initialize Qdrant client and load data
qdrant = QdrantClient(
    url=os.getenv("QDRANT_URL"),
    api_key=os.getenv("QDRANT_API_KEY")
)
collection_name = "example_collection"
pdf_path = "path/to/your/document.pdf"
load_pdf_to_qdrant(pdf_path, qdrant, collection_name)

# Initialize Qdrant search tool
qdrant_tool = QdrantVectorSearchTool(
    qdrant_url=os.getenv("QDRANT_URL"),
    qdrant_api_key=os.getenv("QDRANT_API_KEY"),
    collection_name=collection_name,
    limit=3,
    score_threshold=0.35
)

# Create CrewAI agents
search_agent = Agent(
    role="Senior Semantic Search Agent",
    goal="Find and analyze documents based on semantic search",
    backstory="""You are an expert research assistant who can find relevant
    information using semantic search in a Qdrant database.""",
    tools=[qdrant_tool],
    verbose=True
)

answer_agent = Agent(
    role="Senior Answer Assistant",
    goal="Generate answers to questions based on the context provided",
    backstory="""You are an expert answer assistant who can generate
    answers to questions based on the context provided.""",
    tools=[qdrant_tool],
    verbose=True
)

# Define tasks
search_task = Task(
    description="""Search for relevant documents about the {query}.
    Your final answer should include:
    - The relevant information found
    - The similarity scores of the results
    - The metadata of the relevant documents""",
    agent=search_agent
)

answer_task = Task(
    description="""Given the context and metadata of relevant documents,
    generate a final answer based on the context.""",
    agent=answer_agent
)

# Run CrewAI workflow
crew = Crew(
    agents=[search_agent, answer_agent],
    tasks=[search_task, answer_task],
    process=Process.sequential,
    verbose=True
)

result = crew.kickoff(
    inputs={"query": "What is the role of X in the document?"}
)
print(result)
```

## Tool Parameters

### Required Parameters

* `qdrant_url` (str): The URL of your Qdrant server
* `qdrant_api_key` (str): API key for authentication with Qdrant
* `collection_name` (str): Name of the Qdrant collection to search

### Optional Parameters

* `limit` (int): Maximum number of results to return (default: 3)
* `score_threshold` (float): Minimum similarity score threshold (default: 0.35)
* `custom_embedding_fn` (Callable\[\[str], list\[float]]): Custom function for text vectorization

## Search Parameters

The tool accepts these parameters in its schema:

* `query` (str): The search query to find similar documents
* `filter_by` (str, optional): Metadata field to filter on
* `filter_value` (str, optional): Value to filter by

## Return Format

The tool returns results in JSON format:

```json
[
  {
    "metadata": {
      // Any metadata stored with the document
    },
    "context": "The actual text content of the document",
    "distance": 0.95  // Similarity score
  }
]
```

## Default Embedding

By default, the tool uses OpenAI's `text-embedding-3-small` model for vectorization. This requires:

* OpenAI API key set in environment: `OPENAI_API_KEY`

## Custom Embeddings

Instead of using the default embedding model, you might want to use your own embedding function in cases where you:

1. Want to use a different embedding model (e.g., Cohere, HuggingFace, Ollama models)
2. Need to reduce costs by using open-source embedding models
3. Have specific requirements for vector dimensions or embedding quality
4. Want to use domain-specific embeddings (e.g., for medical or legal text)

Here's an example using a HuggingFace model:

```python
from transformers import AutoTokenizer, AutoModel
import torch

# Load model and tokenizer
tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')
model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')

def custom_embeddings(text: str) -> list[float]:
    # Tokenize and get model outputs
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True)
    outputs = model(**inputs)

    # Use mean pooling to get text embedding
    embeddings = outputs.last_hidden_state.mean(dim=1)

    # Convert to list of floats and return
    return embeddings[0].tolist()

# Use custom embeddings with the tool
tool = QdrantVectorSearchTool(
    qdrant_url="your_url",
    qdrant_api_key="your_key",
    collection_name="your_collection",
    custom_embedding_fn=custom_embeddings  # Pass your custom function
)
```

## Error Handling

The tool handles these specific errors:

* Raises ImportError if `qdrant-client` is not installed (with option to auto-install)
* Raises ValueError if `QDRANT_URL` is not set
* Prompts to install `qdrant-client` if missing using `uv add qdrant-client`

## Environment Variables

Required environment variables:

```bash
export QDRANT_URL="your_qdrant_url"  # If not provided in constructor
export QDRANT_API_KEY="your_api_key"  # If not provided in constructor
export OPENAI_API_KEY="your_openai_key"  # If using default embeddings
```


# Snowflake Search Tool
Source: https://docs.crewai.com/en/tools/database-data/snowflakesearchtool

The `SnowflakeSearchTool` enables CrewAI agents to execute SQL queries and perform semantic search on Snowflake data warehouses.

# `SnowflakeSearchTool`

## Description

The `SnowflakeSearchTool` is designed to connect to Snowflake data warehouses and execute SQL queries with advanced features like connection pooling, retry logic, and asynchronous execution. This tool allows CrewAI agents to interact with Snowflake databases, making it ideal for data analysis, reporting, and business intelligence tasks that require access to enterprise data stored in Snowflake.

## Installation

To use this tool, you need to install the required dependencies:

```shell
uv add cryptography snowflake-connector-python snowflake-sqlalchemy
```

Or alternatively:

```shell
uv sync --extra snowflake
```

## Steps to Get Started

To effectively use the `SnowflakeSearchTool`, follow these steps:

1. **Install Dependencies**: Install the required packages using one of the commands above.
2. **Configure Snowflake Connection**: Create a `SnowflakeConfig` object with your Snowflake credentials.
3. **Initialize the Tool**: Create an instance of the tool with the necessary configuration.
4. **Execute Queries**: Use the tool to run SQL queries against your Snowflake database.

## Example

The following example demonstrates how to use the `SnowflakeSearchTool` to query data from a Snowflake database:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import SnowflakeSearchTool, SnowflakeConfig

# Create Snowflake configuration
config = SnowflakeConfig(
    account="your_account",
    user="your_username",
    password="your_password",
    warehouse="COMPUTE_WH",
    database="your_database",
    snowflake_schema="your_schema"
)

# Initialize the tool
snowflake_tool = SnowflakeSearchTool(config=config)

# Define an agent that uses the tool
data_analyst_agent = Agent(
    role="Data Analyst",
    goal="Analyze data from Snowflake database",
    backstory="An expert data analyst who can extract insights from enterprise data.",
    tools=[snowflake_tool],
    verbose=True,
)

# Example task to query sales data
query_task = Task(
    description="Query the sales data for the last quarter and summarize the top 5 products by revenue.",
    expected_output="A summary of the top 5 products by revenue for the last quarter.",
    agent=data_analyst_agent,
)

# Create and run the crew
crew = Crew(agents=[data_analyst_agent],
            tasks=[query_task])
result = crew.kickoff()
```

You can also customize the tool with additional parameters:

```python Code
# Initialize the tool with custom parameters
snowflake_tool = SnowflakeSearchTool(
    config=config,
    pool_size=10,
    max_retries=5,
    retry_delay=2.0,
    enable_caching=True
)
```

## Parameters

### SnowflakeConfig Parameters

The `SnowflakeConfig` class accepts the following parameters:

* **account**: Required. Snowflake account identifier.
* **user**: Required. Snowflake username.
* **password**: Optional\*. Snowflake password.
* **private\_key\_path**: Optional\*. Path to private key file (alternative to password).
* **warehouse**: Required. Snowflake warehouse name.
* **database**: Required. Default database.
* **snowflake\_schema**: Required. Default schema.
* **role**: Optional. Snowflake role.
* **session\_parameters**: Optional. Custom session parameters as a dictionary.

\*Either `password` or `private_key_path` must be provided.

### SnowflakeSearchTool Parameters

The `SnowflakeSearchTool` accepts the following parameters during initialization:

* **config**: Required. A `SnowflakeConfig` object containing connection details.
* **pool\_size**: Optional. Number of connections in the pool. Default is 5.
* **max\_retries**: Optional. Maximum retry attempts for failed queries. Default is 3.
* **retry\_delay**: Optional. Delay between retries in seconds. Default is 1.0.
* **enable\_caching**: Optional. Whether to enable query result caching. Default is True.

## Usage

When using the `SnowflakeSearchTool`, you need to provide the following parameters:

* **query**: Required. The SQL query to execute.
* **database**: Optional. Override the default database specified in the config.
* **snowflake\_schema**: Optional. Override the default schema specified in the config.
* **timeout**: Optional. Query timeout in seconds. Default is 300.

The tool will return the query results as a list of dictionaries, where each dictionary represents a row with column names as keys.

```python Code
# Example of using the tool with an agent
data_analyst = Agent(
    role="Data Analyst",
    goal="Analyze sales data from Snowflake",
    backstory="An expert data analyst with experience in SQL and data visualization.",
    tools=[snowflake_tool],
    verbose=True
)

# The agent will use the tool with parameters like:
# query="SELECT product_name, SUM(revenue) as total_revenue FROM sales GROUP BY product_name ORDER BY total_revenue DESC LIMIT 5"
# timeout=600

# Create a task for the agent
analysis_task = Task(
    description="Query the sales database and identify the top 5 products by revenue for the last quarter.",
    expected_output="A detailed analysis of the top 5 products by revenue.",
    agent=data_analyst
)

# Run the task
crew = Crew(
    agents=[data_analyst],
    tasks=[analysis_task]
)
result = crew.kickoff()
```

## Advanced Features

### Connection Pooling

The `SnowflakeSearchTool` implements connection pooling to improve performance by reusing database connections. You can control the pool size with the `pool_size` parameter.

### Automatic Retries

The tool automatically retries failed queries with exponential backoff. You can configure the retry behavior with the `max_retries` and `retry_delay` parameters.

### Query Result Caching

To improve performance for repeated queries, the tool can cache query results. This feature is enabled by default but can be disabled by setting `enable_caching=False`.

### Key-Pair Authentication

In addition to password authentication, the tool supports key-pair authentication for enhanced security:

```python Code
config = SnowflakeConfig(
    account="your_account",
    user="your_username",
    private_key_path="/path/to/your/private/key.p8",
    warehouse="COMPUTE_WH",
    database="your_database",
    snowflake_schema="your_schema"
)
```

## Error Handling

The `SnowflakeSearchTool` includes comprehensive error handling for common Snowflake issues:

* Connection failures
* Query timeouts
* Authentication errors
* Database and schema errors

When an error occurs, the tool will attempt to retry the operation (if configured) and provide detailed error information.

## Conclusion

The `SnowflakeSearchTool` provides a powerful way to integrate Snowflake data warehouses with CrewAI agents. With features like connection pooling, automatic retries, and query caching, it enables efficient and reliable access to enterprise data. This tool is particularly useful for data analysis, reporting, and business intelligence tasks that require access to structured data stored in Snowflake.


# Weaviate Vector Search
Source: https://docs.crewai.com/en/tools/database-data/weaviatevectorsearchtool

The `WeaviateVectorSearchTool` is designed to search a Weaviate vector database for semantically similar documents.

## Overview

The `WeaviateVectorSearchTool` is specifically crafted for conducting semantic searches within documents stored in a Weaviate vector database. This tool allows you to find semantically similar documents to a given query, leveraging the power of vector embeddings for more accurate and contextually relevant search results.

[Weaviate](https://weaviate.io/) is a vector database that stores and queries vector embeddings, enabling semantic search capabilities.

## Installation

To incorporate this tool into your project, you need to install the Weaviate client:

```shell
uv add weaviate-client
```

## Steps to Get Started

To effectively use the `WeaviateVectorSearchTool`, follow these steps:

1. **Package Installation**: Confirm that the `crewai[tools]` and `weaviate-client` packages are installed in your Python environment.
2. **Weaviate Setup**: Set up a Weaviate cluster. You can follow the [Weaviate documentation](https://weaviate.io/developers/wcs/manage-clusters/connect) for instructions.
3. **API Keys**: Obtain your Weaviate cluster URL and API key.
4. **OpenAI API Key**: Ensure you have an OpenAI API key set in your environment variables as `OPENAI_API_KEY`.

## Example

The following example demonstrates how to initialize the tool and execute a search:

```python Code
from crewai_tools import WeaviateVectorSearchTool

# Initialize the tool
tool = WeaviateVectorSearchTool(
    collection_name='example_collections',
    limit=3,
    weaviate_cluster_url="https://your-weaviate-cluster-url.com",
    weaviate_api_key="your-weaviate-api-key",
)

@agent
def search_agent(self) -> Agent:
    '''
    This agent uses the WeaviateVectorSearchTool to search for
    semantically similar documents in a Weaviate vector database.
    '''
    return Agent(
        config=self.agents_config["search_agent"],
        tools=[tool]
    )
```

## Parameters

The `WeaviateVectorSearchTool` accepts the following parameters:

* **collection\_name**: Required. The name of the collection to search within.
* **weaviate\_cluster\_url**: Required. The URL of the Weaviate cluster.
* **weaviate\_api\_key**: Required. The API key for the Weaviate cluster.
* **limit**: Optional. The number of results to return. Default is `3`.
* **vectorizer**: Optional. The vectorizer to use. If not provided, it will use `text2vec_openai` with the `nomic-embed-text` model.
* **generative\_model**: Optional. The generative model to use. If not provided, it will use OpenAI's `gpt-4o`.

## Advanced Configuration

You can customize the vectorizer and generative model used by the tool:

```python Code
from crewai_tools import WeaviateVectorSearchTool
from weaviate.classes.config import Configure

# Setup custom model for vectorizer and generative model
tool = WeaviateVectorSearchTool(
    collection_name='example_collections',
    limit=3,
    vectorizer=Configure.Vectorizer.text2vec_openai(model="nomic-embed-text"),
    generative_model=Configure.Generative.openai(model="gpt-4o-mini"),
    weaviate_cluster_url="https://your-weaviate-cluster-url.com",
    weaviate_api_key="your-weaviate-api-key",
)
```

## Preloading Documents

You can preload your Weaviate database with documents before using the tool:

```python Code
import os
from crewai_tools import WeaviateVectorSearchTool
import weaviate
from weaviate.classes.init import Auth

# Connect to Weaviate
client = weaviate.connect_to_weaviate_cloud(
    cluster_url="https://your-weaviate-cluster-url.com",
    auth_credentials=Auth.api_key("your-weaviate-api-key"),
    headers={"X-OpenAI-Api-Key": "your-openai-api-key"}
)

# Get or create collection
test_docs = client.collections.get("example_collections")
if not test_docs:
    test_docs = client.collections.create(
        name="example_collections",
        vectorizer_config=Configure.Vectorizer.text2vec_openai(model="nomic-embed-text"),
        generative_config=Configure.Generative.openai(model="gpt-4o"),
    )

# Load documents
docs_to_load = os.listdir("knowledge")
with test_docs.batch.dynamic() as batch:
    for d in docs_to_load:
        with open(os.path.join("knowledge", d), "r") as f:
            content = f.read()
        batch.add_object(
            {
                "content": content,
                "year": d.split("_")[0],
            }
        )

# Initialize the tool
tool = WeaviateVectorSearchTool(
    collection_name='example_collections',
    limit=3,
    weaviate_cluster_url="https://your-weaviate-cluster-url.com",
    weaviate_api_key="your-weaviate-api-key",
)
```

## Agent Integration Example

Here's how to integrate the `WeaviateVectorSearchTool` with a CrewAI agent:

```python Code
from crewai import Agent
from crewai_tools import WeaviateVectorSearchTool

# Initialize the tool
weaviate_tool = WeaviateVectorSearchTool(
    collection_name='example_collections',
    limit=3,
    weaviate_cluster_url="https://your-weaviate-cluster-url.com",
    weaviate_api_key="your-weaviate-api-key",
)

# Create an agent with the tool
rag_agent = Agent(
    name="rag_agent",
    role="You are a helpful assistant that can answer questions with the help of the WeaviateVectorSearchTool.",
    llm="gpt-4o-mini",
    tools=[weaviate_tool],
)
```

## Conclusion

The `WeaviateVectorSearchTool` provides a powerful way to search for semantically similar documents in a Weaviate vector database. By leveraging vector embeddings, it enables more accurate and contextually relevant search results compared to traditional keyword-based searches. This tool is particularly useful for applications that require finding information based on meaning rather than exact matches.


# CSV RAG Search
Source: https://docs.crewai.com/en/tools/file-document/csvsearchtool

The `CSVSearchTool` is a powerful RAG (Retrieval-Augmented Generation) tool designed for semantic searches within a CSV file's content.

# `CSVSearchTool`

<Note>
  **Experimental**: We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

This tool is used to perform a RAG (Retrieval-Augmented Generation) search within a CSV file's content. It allows users to semantically search for queries in the content of a specified CSV file.
This feature is particularly useful for extracting information from large CSV datasets where traditional search methods might be inefficient. All tools with "Search" in their name, including CSVSearchTool,
are RAG tools designed for searching different sources of data.

## Installation

Install the crewai\_tools package

```shell
pip install 'crewai[tools]'
```

## Example

```python Code
from crewai_tools import CSVSearchTool

# Initialize the tool with a specific CSV file.
# This setup allows the agent to only search the given CSV file.
tool = CSVSearchTool(csv='path/to/your/csvfile.csv')

# OR

# Initialize the tool without a specific CSV file.
# Agent will need to provide the CSV path at runtime.
tool = CSVSearchTool()
```

## Arguments

The following parameters can be used to customize the `CSVSearchTool`'s behavior:

| Argument | Type     | Description                                                                                                                                                               |
| :------- | :------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **csv**  | `string` | *Optional*. The path to the CSV file you want to search. This is a mandatory argument if the tool was initialized without a specific CSV file; otherwise, it is optional. |

## Custom model and embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python Code
tool = CSVSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Directory Read
Source: https://docs.crewai.com/en/tools/file-document/directoryreadtool

The `DirectoryReadTool` is a powerful utility designed to provide a comprehensive listing of directory contents.

# `DirectoryReadTool`

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

The DirectoryReadTool is a powerful utility designed to provide a comprehensive listing of directory contents.
It can recursively navigate through the specified directory, offering users a detailed enumeration of all files, including those within subdirectories.
This tool is crucial for tasks that require a thorough inventory of directory structures or for validating the organization of files within directories.

## Installation

To utilize the DirectoryReadTool in your project, install the `crewai_tools` package. If this package is not yet part of your environment, you can install it using pip with the command below:

```shell
pip install 'crewai[tools]'
```

This command installs the latest version of the `crewai_tools` package, granting access to the DirectoryReadTool among other utilities.

## Example

Employing the DirectoryReadTool is straightforward. The following code snippet demonstrates how to set it up and use the tool to list the contents of a specified directory:

```python Code
from crewai_tools import DirectoryReadTool

# Initialize the tool so the agent can read any directory's content
# it learns about during execution
tool = DirectoryReadTool()

# OR

# Initialize the tool with a specific directory,
# so the agent can only read the content of the specified directory
tool = DirectoryReadTool(directory='/path/to/your/directory')
```

## Arguments

The following parameters can be used to customize the `DirectoryReadTool`'s behavior:

| Argument      | Type     | Description                                                                                                                                                                                                   |
| :------------ | :------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **directory** | `string` | *Optional*. An argument that specifies the path to the directory whose contents you wish to list. It accepts both absolute and relative paths, guiding the tool to the desired directory for content listing. |


# Directory RAG Search
Source: https://docs.crewai.com/en/tools/file-document/directorysearchtool

The `DirectorySearchTool` is a powerful RAG (Retrieval-Augmented Generation) tool designed for semantic searches within a directory's content.

# `DirectorySearchTool`

<Note>
  **Experimental**: The DirectorySearchTool is under continuous development. Features and functionalities might evolve, and unexpected behavior may occur as we refine the tool.
</Note>

## Description

The DirectorySearchTool enables semantic search within the content of specified directories, leveraging the Retrieval-Augmented Generation (RAG) methodology for efficient navigation through files. Designed for flexibility, it allows users to dynamically specify search directories at runtime or set a fixed directory during initial setup.

## Installation

To use the DirectorySearchTool, begin by installing the crewai\_tools package. Execute the following command in your terminal:

```shell
pip install 'crewai[tools]'
```

## Initialization and Usage

Import the DirectorySearchTool from the `crewai_tools` package to start. You can initialize the tool without specifying a directory, enabling the setting of the search directory at runtime. Alternatively, the tool can be initialized with a predefined directory.

```python Code
from crewai_tools import DirectorySearchTool

# For dynamic directory specification at runtime
tool = DirectorySearchTool()

# For fixed directory searches
tool = DirectorySearchTool(directory='/path/to/directory')
```

## Arguments

* `directory`: A string argument that specifies the search directory. This is optional during initialization but required for searches if not set initially.

## Custom Model and Embeddings

The DirectorySearchTool uses OpenAI for embeddings and summarization by default. Customization options for these settings include changing the model provider and configuration, enhancing flexibility for advanced users.

```python Code
tool = DirectorySearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # Options include ollama, google, anthropic, llama2, and more
            config=dict(
                model="llama2",
                # Additional configurations here
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# DOCX RAG Search
Source: https://docs.crewai.com/en/tools/file-document/docxsearchtool

The `DOCXSearchTool` is a RAG tool designed for semantic searching within DOCX documents.

# `DOCXSearchTool`

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

The `DOCXSearchTool` is a RAG tool designed for semantic searching within DOCX documents.
It enables users to effectively search and extract relevant information from DOCX files using query-based searches.
This tool is invaluable for data analysis, information management, and research tasks,
streamlining the process of finding specific information within large document collections.

## Installation

Install the crewai\_tools package by running the following command in your terminal:

```shell
uv pip install docx2txt 'crewai[tools]'
```

## Example

The following example demonstrates initializing the DOCXSearchTool to search within any DOCX file's content or with a specific DOCX file path.

```python Code
from crewai_tools import DOCXSearchTool

# Initialize the tool to search within any DOCX file's content
tool = DOCXSearchTool()

# OR

# Initialize the tool with a specific DOCX file,
# so the agent can only search the content of the specified DOCX file
tool = DOCXSearchTool(docx='path/to/your/document.docx')
```

## Arguments

The following parameters can be used to customize the `DOCXSearchTool`'s behavior:

| Argument | Type     | Description                                                                                                                                                                                                        |
| :------- | :------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **docx** | `string` | *Optional*. An argument that specifies the path to the DOCX file you want to search. If not provided during initialization, the tool allows for later specification of any DOCX file's content path for searching. |

## Custom model and embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python Code
tool = DOCXSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# File Read
Source: https://docs.crewai.com/en/tools/file-document/filereadtool

The `FileReadTool` is designed to read files from the local file system.

## Overview

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

The FileReadTool conceptually represents a suite of functionalities within the crewai\_tools package aimed at facilitating file reading and content retrieval.
This suite includes tools for processing batch text files, reading runtime configuration files, and importing data for analytics.
It supports a variety of text-based file formats such as `.txt`, `.csv`, `.json`, and more. Depending on the file type, the suite offers specialized functionality,
such as converting JSON content into a Python dictionary for ease of use.

## Installation

To utilize the functionalities previously attributed to the FileReadTool, install the crewai\_tools package:

```shell
pip install 'crewai[tools]'
```

## Usage Example

To get started with the FileReadTool:

```python Code
from crewai_tools import FileReadTool

# Initialize the tool to read any files the agents knows or lean the path for
file_read_tool = FileReadTool()

# OR

# Initialize the tool with a specific file path, so the agent can only read the content of the specified file
file_read_tool = FileReadTool(file_path='path/to/your/file.txt')
```

## Arguments

* `file_path`: The path to the file you want to read. It accepts both absolute and relative paths. Ensure the file exists and you have the necessary permissions to access it.


# File Write
Source: https://docs.crewai.com/en/tools/file-document/filewritetool

The `FileWriterTool` is designed to write content to files.

# `FileWriterTool`

## Description

The `FileWriterTool` is a component of the crewai\_tools package, designed to simplify the process of writing content to files with cross-platform compatibility (Windows, Linux, macOS).
It is particularly useful in scenarios such as generating reports, saving logs, creating configuration files, and more.
This tool handles path differences across operating systems, supports UTF-8 encoding, and automatically creates directories if they don't exist, making it easier to organize your output reliably across different platforms.

## Installation

Install the crewai\_tools package to use the `FileWriterTool` in your projects:

```shell
pip install 'crewai[tools]'
```

## Example

To get started with the `FileWriterTool`:

```python Code
from crewai_tools import FileWriterTool

# Initialize the tool
file_writer_tool = FileWriterTool()

# Write content to a file in a specified directory
result = file_writer_tool._run('example.txt', 'This is a test content.', 'test_directory')
print(result)
```

## Arguments

* `filename`: The name of the file you want to create or overwrite.
* `content`: The content to write into the file.
* `directory` (optional): The path to the directory where the file will be created. Defaults to the current directory (`.`). If the directory does not exist, it will be created.

## Conclusion

By integrating the `FileWriterTool` into your crews, the agents can reliably write content to files across different operating systems.
This tool is essential for tasks that require saving output data, creating structured file systems, and handling cross-platform file operations.
It's particularly recommended for Windows users who may encounter file writing issues with standard Python file operations.

By adhering to the setup and usage guidelines provided, incorporating this tool into projects is straightforward and ensures consistent file writing behavior across all platforms.


# JSON RAG Search
Source: https://docs.crewai.com/en/tools/file-document/jsonsearchtool

The `JSONSearchTool` is designed to search JSON files and return the most relevant results.

# `JSONSearchTool`

<Note>
  The JSONSearchTool is currently in an experimental phase. This means the tool
  is under active development, and users might encounter unexpected behavior or
  changes. We highly encourage feedback on any issues or suggestions for
  improvements.
</Note>

## Description

The JSONSearchTool is designed to facilitate efficient and precise searches within JSON file contents. It utilizes a RAG (Retrieve and Generate) search mechanism, allowing users to specify a JSON path for targeted searches within a particular JSON file. This capability significantly improves the accuracy and relevance of search results.

## Installation

To install the JSONSearchTool, use the following pip command:

```shell
pip install 'crewai[tools]'
```

## Usage Examples

Here are updated examples on how to utilize the JSONSearchTool effectively for searching within JSON files. These examples take into account the current implementation and usage patterns identified in the codebase.

```python Code
from crewai_tools import JSONSearchTool

# General JSON content search
# This approach is suitable when the JSON path is either known beforehand or can be dynamically identified.
tool = JSONSearchTool()

# Restricting search to a specific JSON file
# Use this initialization method when you want to limit the search scope to a specific JSON file.
tool = JSONSearchTool(json_path='./path/to/your/file.json')
```

## Arguments

* `json_path` (str, optional): Specifies the path to the JSON file to be searched. This argument is not required if the tool is initialized for a general search. When provided, it confines the search to the specified JSON file.

## Configuration Options

The JSONSearchTool supports extensive customization through a configuration dictionary. This allows users to select different models for embeddings and summarization based on their requirements.

```python Code
tool = JSONSearchTool(
    config={
        "llm": {
            "provider": "ollama",  # Other options include google, openai, anthropic, llama2, etc.
            "config": {
                "model": "llama2",
                # Additional optional configurations can be specified here.
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            },
        },
        "embedding_model": {
            "provider": "google", # or openai, ollama, ...
            "config": {
                "model": "models/embedding-001",
                "task_type": "retrieval_document",
                # Further customization options can be added here.
            },
        },
    }
)
```


# MDX RAG Search
Source: https://docs.crewai.com/en/tools/file-document/mdxsearchtool

The `MDXSearchTool` is designed to search MDX files and return the most relevant results.

# `MDXSearchTool`

<Note>
  The MDXSearchTool is in continuous development. Features may be added or removed, and functionality could change unpredictably as we refine the tool.
</Note>

## Description

The MDX Search Tool is a component of the `crewai_tools` package aimed at facilitating advanced markdown language extraction. It enables users to effectively search and extract relevant information from MD files using query-based searches. This tool is invaluable for data analysis, information management, and research tasks, streamlining the process of finding specific information within large document collections.

## Installation

Before using the MDX Search Tool, ensure the `crewai_tools` package is installed. If it is not, you can install it with the following command:

```shell
pip install 'crewai[tools]'
```

## Usage Example

To use the MDX Search Tool, you must first set up the necessary environment variables. Then, integrate the tool into your crewAI project to begin your market research. Below is a basic example of how to do this:

```python Code
from crewai_tools import MDXSearchTool

# Initialize the tool to search any MDX content it learns about during execution
tool = MDXSearchTool()

# OR

# Initialize the tool with a specific MDX file path for an exclusive search within that document
tool = MDXSearchTool(mdx='path/to/your/document.mdx')
```

## Parameters

* mdx: **Optional**. Specifies the MDX file path for the search. It can be provided during initialization.

## Customization of Model and Embeddings

The tool defaults to using OpenAI for embeddings and summarization. For customization, utilize a configuration dictionary as shown below:

```python Code
tool = MDXSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # Options include google, openai, anthropic, llama2, etc.
            config=dict(
                model="llama2",
                # Optional parameters can be included here.
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # Optional title for the embeddings can be added here.
                # title="Embeddings",
            ),
        ),
    )
)
```


# Overview
Source: https://docs.crewai.com/en/tools/file-document/overview

Read, write, and search through various file formats with CrewAI's document processing tools

These tools enable your agents to work with various file formats and document types. From reading PDFs to processing JSON data, these tools handle all your document processing needs.

## **Available Tools**

<CardGroup cols={2}>
  <Card title="File Read Tool" icon="folders" href="/en/tools/file-document/filereadtool">
    Read content from any file type including text, markdown, and more.
  </Card>

  <Card title="File Write Tool" icon="file-pen" href="/en/tools/file-document/filewritetool">
    Write content to files, create new documents, and save processed data.
  </Card>

  <Card title="PDF Search Tool" icon="file-pdf" href="/en/tools/file-document/pdfsearchtool">
    Search and extract text content from PDF documents efficiently.
  </Card>

  <Card title="DOCX Search Tool" icon="file-word" href="/en/tools/file-document/docxsearchtool">
    Search through Microsoft Word documents and extract relevant content.
  </Card>

  <Card title="JSON Search Tool" icon="brackets-curly" href="/en/tools/file-document/jsonsearchtool">
    Parse and search through JSON files with advanced query capabilities.
  </Card>

  <Card title="CSV Search Tool" icon="table" href="/en/tools/file-document/csvsearchtool">
    Process and search through CSV files, extract specific rows and columns.
  </Card>

  <Card title="XML Search Tool" icon="code" href="/en/tools/file-document/xmlsearchtool">
    Parse XML files and search for specific elements and attributes.
  </Card>

  <Card title="MDX Search Tool" icon="markdown" href="/en/tools/file-document/mdxsearchtool">
    Search through MDX files and extract content from documentation.
  </Card>

  <Card title="TXT Search Tool" icon="file-lines" href="/en/tools/file-document/txtsearchtool">
    Search through plain text files with pattern matching capabilities.
  </Card>

  <Card title="Directory Search Tool" icon="folder-open" href="/en/tools/file-document/directorysearchtool">
    Search for files and folders within directory structures.
  </Card>

  <Card title="Directory Read Tool" icon="folder" href="/en/tools/file-document/directoryreadtool">
    Read and list directory contents, file structures, and metadata.
  </Card>
</CardGroup>

## **Common Use Cases**

* **Document Processing**: Extract and analyze content from various file formats
* **Data Import**: Read structured data from CSV, JSON, and XML files
* **Content Search**: Find specific information within large document collections
* **File Management**: Organize and manipulate files and directories
* **Data Export**: Save processed results to various file formats

## **Quick Start Example**

```python
from crewai_tools import FileReadTool, PDFSearchTool, JSONSearchTool

# Create tools
file_reader = FileReadTool()
pdf_searcher = PDFSearchTool()
json_processor = JSONSearchTool()

# Add to your agent
agent = Agent(
    role="Document Analyst",
    tools=[file_reader, pdf_searcher, json_processor],
    goal="Process and analyze various document types"
)
```

## **Tips for Document Processing**

* **File Permissions**: Ensure your agent has proper read/write permissions
* **Large Files**: Consider chunking for very large documents
* **Format Support**: Check tool documentation for supported file formats
* **Error Handling**: Implement proper error handling for corrupted or inaccessible files


# PDF RAG Search
Source: https://docs.crewai.com/en/tools/file-document/pdfsearchtool

The `PDFSearchTool` is designed to search PDF files and return the most relevant results.

# `PDFSearchTool`

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

The PDFSearchTool is a RAG tool designed for semantic searches within PDF content. It allows for inputting a search query and a PDF document, leveraging advanced search techniques to find relevant content efficiently.
This capability makes it especially useful for extracting specific information from large PDF files quickly.

## Installation

To get started with the PDFSearchTool, first, ensure the crewai\_tools package is installed with the following command:

```shell
pip install 'crewai[tools]'
```

## Example

Here's how to use the PDFSearchTool to search within a PDF document:

```python Code
from crewai_tools import PDFSearchTool

# Initialize the tool allowing for any PDF content search if the path is provided during execution
tool = PDFSearchTool()

# OR

# Initialize the tool with a specific PDF path for exclusive search within that document
tool = PDFSearchTool(pdf='path/to/your/document.pdf')
```

## Arguments

* `pdf`: **Optional** The PDF path for the search. Can be provided at initialization or within the `run` method's arguments. If provided at initialization, the tool confines its search to the specified document.

## Custom model and embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python Code
tool = PDFSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# TXT RAG Search
Source: https://docs.crewai.com/en/tools/file-document/txtsearchtool

The `TXTSearchTool` is designed to perform a RAG (Retrieval-Augmented Generation) search within the content of a text file.

## Overview

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

This tool is used to perform a RAG (Retrieval-Augmented Generation) search within the content of a text file.
It allows for semantic searching of a query within a specified text file's content,
making it an invaluable resource for quickly extracting information or finding specific sections of text based on the query provided.

## Installation

To use the `TXTSearchTool`, you first need to install the `crewai_tools` package.
This can be done using pip, a package manager for Python.
Open your terminal or command prompt and enter the following command:

```shell
pip install 'crewai[tools]'
```

This command will download and install the TXTSearchTool along with any necessary dependencies.

## Example

The following example demonstrates how to use the TXTSearchTool to search within a text file.
This example shows both the initialization of the tool with a specific text file and the subsequent search within that file's content.

```python Code
from crewai_tools import TXTSearchTool

# Initialize the tool to search within any text file's content
# the agent learns about during its execution
tool = TXTSearchTool()

# OR

# Initialize the tool with a specific text file,
# so the agent can search within the given text file's content
tool = TXTSearchTool(txt='path/to/text/file.txt')
```

## Arguments

* `txt` (str): **Optional**. The path to the text file you want to search.
  This argument is only required if the tool was not initialized with a specific text file;
  otherwise, the search will be conducted within the initially provided text file.

## Custom model and embeddings

By default, the tool uses OpenAI for both embeddings and summarization.
To customize the model, you can use a config dictionary as follows:

```python Code
tool = TXTSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# XML RAG Search
Source: https://docs.crewai.com/en/tools/file-document/xmlsearchtool

The `XMLSearchTool` is designed to perform a RAG (Retrieval-Augmented Generation) search within the content of a XML file.

# `XMLSearchTool`

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

The XMLSearchTool is a cutting-edge RAG tool engineered for conducting semantic searches within XML files.
Ideal for users needing to parse and extract information from XML content efficiently, this tool supports inputting a search query and an optional XML file path.
By specifying an XML path, users can target their search more precisely to the content of that file, thereby obtaining more relevant search outcomes.

## Installation

To start using the XMLSearchTool, you must first install the crewai\_tools package. This can be easily done with the following command:

```shell
pip install 'crewai[tools]'
```

## Example

Here are two examples demonstrating how to use the XMLSearchTool.
The first example shows searching within a specific XML file, while the second example illustrates initiating a search without predefining an XML path, providing flexibility in search scope.

```python Code
from crewai_tools import XMLSearchTool

# Allow agents to search within any XML file's content
#as it learns about their paths during execution
tool = XMLSearchTool()

# OR

# Initialize the tool with a specific XML file path
#for exclusive search within that document
tool = XMLSearchTool(xml='path/to/your/xmlfile.xml')
```

## Arguments

* `xml`: This is the path to the XML file you wish to search.
  It is an optional parameter during the tool's initialization but must be provided either at initialization or as part of the `run` method's arguments to execute a search.

## Custom model and embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python Code
tool = XMLSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Tools Overview
Source: https://docs.crewai.com/en/tools/overview

Discover CrewAI's extensive library of 40+ tools to supercharge your AI agents

CrewAI provides an extensive library of pre-built tools to enhance your agents' capabilities. From file processing to web scraping, database queries to AI services - we've got you covered.

## **Tool Categories**

<CardGroup cols={2}>
  <Card title="File & Document" icon="file-check" href="/en/tools/file-document/overview" color="#3B82F6">
    Read, write, and search through various file formats including PDF, DOCX, JSON, CSV, and more. Perfect for document processing workflows.
  </Card>

  <Card title="Web Scraping & Browsing" icon="globe" href="/en/tools/web-scraping/overview" color="#10B981">
    Extract data from websites, automate browser interactions, and scrape content at scale with tools like Firecrawl, Selenium, and more.
  </Card>

  <Card title="Search & Research" icon="magnifying-glass" href="/en/tools/search-research/overview" color="#F59E0B">
    Perform web searches, find code repositories, research YouTube content, and discover information across the internet.
  </Card>

  <Card title="Database & Data" icon="database" href="/en/tools/database-data/overview" color="#8B5CF6">
    Connect to SQL databases, vector stores, and data warehouses. Query MySQL, PostgreSQL, Snowflake, Qdrant, and Weaviate.
  </Card>

  <Card title="AI & Machine Learning" icon="brain" href="/en/tools/ai-ml/overview" color="#EF4444">
    Generate images with DALL-E, process vision tasks, integrate with LangChain, build RAG systems, and leverage code interpreters.
  </Card>

  <Card title="Cloud & Storage" icon="cloud" href="/en/tools/cloud-storage/overview" color="#06B6D4">
    Interact with cloud services including AWS S3, Amazon Bedrock, and other cloud storage and AI services.
  </Card>

  <Card title="Automation & Integration" icon="bolt" href="/en/tools/automation/overview" color="#84CC16">
    Automate workflows with Apify, Composio, and other integration platforms to connect your agents with external services.
  </Card>
</CardGroup>

## **Quick Access**

Need a specific tool? Here are some popular choices:

<CardGroup cols={3}>
  <Card title="RAG Tool" icon="image" href="/en/tools/ai-ml/ragtool">
    Implement Retrieval-Augmented Generation
  </Card>

  <Card title="Serper Dev" icon="book-atlas" href="/en/tools/search-research/serperdevtool">
    Google search API
  </Card>

  <Card title="File Read" icon="file" href="/en/tools/file-document/filereadtool">
    Read any file type
  </Card>

  <Card title="Scrape Website" icon="globe" href="/en/tools/web-scraping/scrapewebsitetool">
    Extract web content
  </Card>

  <Card title="Code Interpreter" icon="code" href="/en/tools/ai-ml/codeinterpretertool">
    Execute Python code
  </Card>

  <Card title="S3 Reader" icon="cloud" href="/en/tools/cloud-storage/s3readertool">
    Access AWS S3 files
  </Card>
</CardGroup>

## **Getting Started**

To use any tool in your CrewAI project:

1. **Import** the tool in your crew configuration
2. **Add** it to your agent's tools list
3. **Configure** any required API keys or settings

```python
from crewai_tools import FileReadTool, SerperDevTool

# Add tools to your agent
agent = Agent(
    role="Research Analyst",
    tools=[FileReadTool(), SerperDevTool()],
    # ... other configuration
)
```

Ready to explore? Pick a category above to discover tools that fit your use case!


# Brave Search
Source: https://docs.crewai.com/en/tools/search-research/bravesearchtool

The `BraveSearchTool` is designed to search the internet using the Brave Search API.

# `BraveSearchTool`

## Description

This tool is designed to perform web searches using the Brave Search API. It allows you to search the internet with a specified query and retrieve relevant results. The tool supports customizable result counts and country-specific searches.

## Installation

To incorporate this tool into your project, follow the installation instructions below:

```shell
pip install 'crewai[tools]'
```

## Steps to Get Started

To effectively use the `BraveSearchTool`, follow these steps:

1. **Package Installation**: Confirm that the `crewai[tools]` package is installed in your Python environment.
2. **API Key Acquisition**: Acquire a Brave Search API key by registering at [Brave Search API](https://api.search.brave.com/app/keys).
3. **Environment Configuration**: Store your obtained API key in an environment variable named `BRAVE_API_KEY` to facilitate its use by the tool.

## Example

The following example demonstrates how to initialize the tool and execute a search with a given query:

```python Code
from crewai_tools import BraveSearchTool

# Initialize the tool for internet searching capabilities
tool = BraveSearchTool()

# Execute a search
results = tool.run(search_query="CrewAI agent framework")
print(results)
```

## Parameters

The `BraveSearchTool` accepts the following parameters:

* **search\_query**: Mandatory. The search query you want to use to search the internet.
* **country**: Optional. Specify the country for the search results. Default is empty string.
* **n\_results**: Optional. Number of search results to return. Default is `10`.
* **save\_file**: Optional. Whether to save the search results to a file. Default is `False`.

## Example with Parameters

Here is an example demonstrating how to use the tool with additional parameters:

```python Code
from crewai_tools import BraveSearchTool

# Initialize the tool with custom parameters
tool = BraveSearchTool(
    country="US",
    n_results=5,
    save_file=True
)

# Execute a search
results = tool.run(search_query="Latest AI developments")
print(results)
```

## Agent Integration Example

Here's how to integrate the `BraveSearchTool` with a CrewAI agent:

```python Code
from crewai import Agent
from crewai.project import agent
from crewai_tools import BraveSearchTool

# Initialize the tool
brave_search_tool = BraveSearchTool()

# Define an agent with the BraveSearchTool
@agent
def researcher(self) -> Agent:
    return Agent(
        config=self.agents_config["researcher"],
        allow_delegation=False,
        tools=[brave_search_tool]
    )
```

## Conclusion

By integrating the `BraveSearchTool` into Python projects, users gain the ability to conduct real-time, relevant searches across the internet directly from their applications. The tool provides a simple interface to the powerful Brave Search API, making it easy to retrieve and process search results programmatically. By adhering to the setup and usage guidelines provided, incorporating this tool into projects is streamlined and straightforward.


# Code Docs RAG Search
Source: https://docs.crewai.com/en/tools/search-research/codedocssearchtool

The `CodeDocsSearchTool` is a powerful RAG (Retrieval-Augmented Generation) tool designed for semantic searches within code documentation.

# `CodeDocsSearchTool`

<Note>
  **Experimental**: We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

The CodeDocsSearchTool is a powerful RAG (Retrieval-Augmented Generation) tool designed for semantic searches within code documentation.
It enables users to efficiently find specific information or topics within code documentation. By providing a `docs_url` during initialization,
the tool narrows down the search to that particular documentation site. Alternatively, without a specific `docs_url`,
it searches across a wide array of code documentation known or discovered throughout its execution, making it versatile for various documentation search needs.

## Installation

To start using the CodeDocsSearchTool, first, install the crewai\_tools package via pip:

```shell
pip install 'crewai[tools]'
```

## Example

Utilize the CodeDocsSearchTool as follows to conduct searches within code documentation:

```python Code
from crewai_tools import CodeDocsSearchTool

# To search any code documentation content
# if the URL is known or discovered during its execution:
tool = CodeDocsSearchTool()

# OR

# To specifically focus your search on a given documentation site
# by providing its URL:
tool = CodeDocsSearchTool(docs_url='https://docs.example.com/reference')
```

<Note>
  Substitute '[https://docs.example.com/reference](https://docs.example.com/reference)' with your target documentation URL
  and 'How to use search tool' with the search query relevant to your needs.
</Note>

## Arguments

The following parameters can be used to customize the `CodeDocsSearchTool`'s behavior:

| Argument      | Type     | Description                                                             |
| :------------ | :------- | :---------------------------------------------------------------------- |
| **docs\_url** | `string` | *Optional*. Specifies the URL of the code documentation to be searched. |

## Custom model and embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python Code
tool = CodeDocsSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# EXA Search Web Loader
Source: https://docs.crewai.com/en/tools/search-research/exasearchtool

The `EXASearchTool` is designed to perform a semantic search for a specified query from a text's content across the internet.

# `EXASearchTool`

## Description

The EXASearchTool is designed to perform a semantic search for a specified query from a text's content across the internet.
It utilizes the [exa.ai](https://exa.ai/) API to fetch and display the most relevant search results based on the query provided by the user.

## Installation

To incorporate this tool into your project, follow the installation instructions below:

```shell
pip install 'crewai[tools]'
```

## Example

The following example demonstrates how to initialize the tool and execute a search with a given query:

```python Code
from crewai_tools import EXASearchTool

# Initialize the tool for internet searching capabilities
tool = EXASearchTool()
```

## Steps to Get Started

To effectively use the EXASearchTool, follow these steps:

<Steps>
  <Step title="Package Installation">
    Confirm that the `crewai[tools]` package is installed in your Python environment.
  </Step>

  <Step title="API Key Acquisition">
    Acquire a [exa.ai](https://exa.ai/) API key by registering for a free account at [exa.ai](https://exa.ai/).
  </Step>

  <Step title="Environment Configuration">
    Store your obtained API key in an environment variable named `EXA_API_KEY` to facilitate its use by the tool.
  </Step>
</Steps>

## Conclusion

By integrating the `EXASearchTool` into Python projects, users gain the ability to conduct real-time, relevant searches across the internet directly from their applications.
By adhering to the setup and usage guidelines provided, incorporating this tool into projects is streamlined and straightforward.


# Github Search
Source: https://docs.crewai.com/en/tools/search-research/githubsearchtool

The `GithubSearchTool` is designed to search websites and convert them into clean markdown or structured data.

# `GithubSearchTool`

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

The GithubSearchTool is a Retrieval-Augmented Generation (RAG) tool specifically designed for conducting semantic searches within GitHub repositories. Utilizing advanced semantic search capabilities, it sifts through code, pull requests, issues, and repositories, making it an essential tool for developers, researchers, or anyone in need of precise information from GitHub.

## Installation

To use the GithubSearchTool, first ensure the crewai\_tools package is installed in your Python environment:

```shell
pip install 'crewai[tools]'
```

This command installs the necessary package to run the GithubSearchTool along with any other tools included in the crewai\_tools package.

## Example

Here’s how you can use the GithubSearchTool to perform semantic searches within a GitHub repository:

```python Code
from crewai_tools import GithubSearchTool

# Initialize the tool for semantic searches within a specific GitHub repository
tool = GithubSearchTool(
	github_repo='https://github.com/example/repo',
	gh_token='your_github_personal_access_token',
	content_types=['code', 'issue'] # Options: code, repo, pr, issue
)

# OR

# Initialize the tool for semantic searches within a specific GitHub repository, so the agent can search any repository if it learns about during its execution
tool = GithubSearchTool(
	gh_token='your_github_personal_access_token',
	content_types=['code', 'issue'] # Options: code, repo, pr, issue
)
```

## Arguments

* `github_repo` : The URL of the GitHub repository where the search will be conducted. This is a mandatory field and specifies the target repository for your search.
* `gh_token` : Your GitHub Personal Access Token (PAT) required for authentication. You can create one in your GitHub account settings under Developer Settings > Personal Access Tokens.
* `content_types` : Specifies the types of content to include in your search. You must provide a list of content types from the following options: `code` for searching within the code,
  `repo` for searching within the repository's general information, `pr` for searching within pull requests, and `issue` for searching within issues.
  This field is mandatory and allows tailoring the search to specific content types within the GitHub repository.

## Custom model and embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python Code
tool = GithubSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Linkup Search Tool
Source: https://docs.crewai.com/en/tools/search-research/linkupsearchtool

The `LinkupSearchTool` enables querying the Linkup API for contextual information.

# `LinkupSearchTool`

## Description

The `LinkupSearchTool` provides the ability to query the Linkup API for contextual information and retrieve structured results. This tool is ideal for enriching workflows with up-to-date and reliable information from Linkup, allowing agents to access relevant data during their tasks.

## Installation

To use this tool, you need to install the Linkup SDK:

```shell
uv add linkup-sdk
```

## Steps to Get Started

To effectively use the `LinkupSearchTool`, follow these steps:

1. **API Key**: Obtain a Linkup API key.
2. **Environment Setup**: Set up your environment with the API key.
3. **Install SDK**: Install the Linkup SDK using the command above.

## Example

The following example demonstrates how to initialize the tool and use it in an agent:

```python Code
from crewai_tools import LinkupSearchTool
from crewai import Agent
import os

# Initialize the tool with your API key
linkup_tool = LinkupSearchTool(api_key=os.getenv("LINKUP_API_KEY"))

# Define an agent that uses the tool
@agent
def researcher(self) -> Agent:
    '''
    This agent uses the LinkupSearchTool to retrieve contextual information
    from the Linkup API.
    '''
    return Agent(
        config=self.agents_config["researcher"],
        tools=[linkup_tool]
    )
```

## Parameters

The `LinkupSearchTool` accepts the following parameters:

### Constructor Parameters

* **api\_key**: Required. Your Linkup API key.

### Run Parameters

* **query**: Required. The search term or phrase.
* **depth**: Optional. The search depth. Default is "standard".
* **output\_type**: Optional. The type of output. Default is "searchResults".

## Advanced Usage

You can customize the search parameters for more specific results:

```python Code
# Perform a search with custom parameters
results = linkup_tool.run(
    query="Women Nobel Prize Physics",
    depth="deep",
    output_type="searchResults"
)
```

## Return Format

The tool returns results in the following format:

```json
{
  "success": true,
  "results": [
    {
      "name": "Result Title",
      "url": "https://example.com/result",
      "content": "Content of the result..."
    },
    // Additional results...
  ]
}
```

If an error occurs, the response will be:

```json
{
  "success": false,
  "error": "Error message"
}
```

## Error Handling

The tool gracefully handles API errors and provides structured feedback. If the API request fails, the tool will return a dictionary with `success: false` and an error message.

## Conclusion

The `LinkupSearchTool` provides a seamless way to integrate Linkup's contextual information retrieval capabilities into your CrewAI agents. By leveraging this tool, agents can access relevant and up-to-date information to enhance their decision-making and task execution.


# Overview
Source: https://docs.crewai.com/en/tools/search-research/overview

Perform web searches, find repositories, and research information across the internet

These tools enable your agents to search the web, research topics, and find information across various platforms including search engines, GitHub, and YouTube.

## **Available Tools**

<CardGroup cols={2}>
  <Card title="Serper Dev Tool" icon="google" href="/en/tools/search-research/serperdevtool">
    Google search API integration for comprehensive web search capabilities.
  </Card>

  <Card title="Brave Search Tool" icon="shield" href="/en/tools/search-research/bravesearchtool">
    Privacy-focused search with Brave's independent search index.
  </Card>

  <Card title="Exa Search Tool" icon="magnifying-glass" href="/en/tools/search-research/exasearchtool">
    AI-powered search for finding specific and relevant content.
  </Card>

  <Card title="LinkUp Search Tool" icon="link" href="/en/tools/search-research/linkupsearchtool">
    Real-time web search with fresh content indexing.
  </Card>

  <Card title="GitHub Search Tool" icon="github" href="/en/tools/search-research/githubsearchtool">
    Search GitHub repositories, code, issues, and documentation.
  </Card>

  <Card title="Website Search Tool" icon="globe" href="/en/tools/search-research/websitesearchtool">
    Search within specific websites and domains.
  </Card>

  <Card title="Code Docs Search Tool" icon="code" href="/en/tools/search-research/codedocssearchtool">
    Search through code documentation and technical resources.
  </Card>

  <Card title="YouTube Channel Search" icon="youtube" href="/en/tools/search-research/youtubechannelsearchtool">
    Search YouTube channels for specific content and creators.
  </Card>

  <Card title="YouTube Video Search" icon="play" href="/en/tools/search-research/youtubevideosearchtool">
    Find and analyze YouTube videos by topic, keyword, or criteria.
  </Card>
</CardGroup>

## **Common Use Cases**

* **Market Research**: Search for industry trends and competitor analysis
* **Content Discovery**: Find relevant articles, videos, and resources
* **Code Research**: Search repositories and documentation for solutions
* **Lead Generation**: Research companies and individuals
* **Academic Research**: Find scholarly articles and technical papers

```python
from crewai_tools import SerperDevTool, GitHubSearchTool, YoutubeVideoSearchTool

# Create research tools
web_search = SerperDevTool()
code_search = GitHubSearchTool()
video_research = YoutubeVideoSearchTool()

# Add to your agent
agent = Agent(
    role="Research Analyst",
    tools=[web_search, code_search, video_research],
    goal="Gather comprehensive information on any topic"
)
```


# Google Serper Search
Source: https://docs.crewai.com/en/tools/search-research/serperdevtool

The `SerperDevTool` is designed to search the internet and return the most relevant results.

# `SerperDevTool`

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

This tool is designed to perform a semantic search for a specified query from a text's content across the internet. It utilizes the [serper.dev](https://serper.dev) API
to fetch and display the most relevant search results based on the query provided by the user.

## Installation

To incorporate this tool into your project, follow the installation instructions below:

```shell
pip install 'crewai[tools]'
```

## Example

The following example demonstrates how to initialize the tool and execute a search with a given query:

```python Code
from crewai_tools import SerperDevTool

# Initialize the tool for internet searching capabilities
tool = SerperDevTool()
```

## Steps to Get Started

To effectively use the `SerperDevTool`, follow these steps:

1. **Package Installation**: Confirm that the `crewai[tools]` package is installed in your Python environment.
2. **API Key Acquisition**: Acquire a `serper.dev` API key by registering for a free account at `serper.dev`.
3. **Environment Configuration**: Store your obtained API key in an environment variable named `SERPER_API_KEY` to facilitate its use by the tool.

## Parameters

The `SerperDevTool` comes with several parameters that will be passed to the API :

* **search\_url**: The URL endpoint for the search API. (Default is `https://google.serper.dev/search`)

* **country**: Optional. Specify the country for the search results.

* **location**: Optional. Specify the location for the search results.

* **locale**: Optional. Specify the locale for the search results.

* **n\_results**: Number of search results to return. Default is `10`.

The values for `country`, `location`, `locale` and `search_url` can be found on the [Serper Playground](https://serper.dev/playground).

## Example with Parameters

Here is an example demonstrating how to use the tool with additional parameters:

```python Code
from crewai_tools import SerperDevTool

tool = SerperDevTool(
    search_url="https://google.serper.dev/scholar",
    n_results=2,
)

print(tool.run(search_query="ChatGPT"))

# Using Tool: Search the internet

# Search results: Title: Role of chat gpt in public health
# Link: https://link.springer.com/article/10.1007/s10439-023-03172-7
# Snippet: … ChatGPT in public health. In this overview, we will examine the potential uses of ChatGPT in
# ---
# Title: Potential use of chat gpt in global warming
# Link: https://link.springer.com/article/10.1007/s10439-023-03171-8
# Snippet: … as ChatGPT, have the potential to play a critical role in advancing our understanding of climate
# ---

```

```python Code
from crewai_tools import SerperDevTool

tool = SerperDevTool(
    country="fr",
    locale="fr",
    location="Paris, Paris, Ile-de-France, France",
    n_results=2,
)

print(tool.run(search_query="Jeux Olympiques"))

# Using Tool: Search the internet

# Search results: Title: Jeux Olympiques de Paris 2024 - Actualités, calendriers, résultats
# Link: https://olympics.com/fr/paris-2024
# Snippet: Quels sont les sports présents aux Jeux Olympiques de Paris 2024 ? · Athlétisme · Aviron · Badminton · Basketball · Basketball 3x3 · Boxe · Breaking · Canoë ...
# ---
# Title: Billetterie Officielle de Paris 2024 - Jeux Olympiques et Paralympiques
# Link: https://tickets.paris2024.org/
# Snippet: Achetez vos billets exclusivement sur le site officiel de la billetterie de Paris 2024 pour participer au plus grand événement sportif au monde.
# ---
```

## Conclusion

By integrating the `SerperDevTool` into Python projects, users gain the ability to conduct real-time, relevant searches across the internet directly from their applications.
The updated parameters allow for more customized and localized search results. By adhering to the setup and usage guidelines provided, incorporating this tool into projects is streamlined and straightforward.


# Website RAG Search
Source: https://docs.crewai.com/en/tools/search-research/websitesearchtool

The `WebsiteSearchTool` is designed to perform a RAG (Retrieval-Augmented Generation) search within the content of a website.

# `WebsiteSearchTool`

<Note>
  The WebsiteSearchTool is currently in an experimental phase. We are actively working on incorporating this tool into our suite of offerings and will update the documentation accordingly.
</Note>

## Description

The WebsiteSearchTool is designed as a concept for conducting semantic searches within the content of websites.
It aims to leverage advanced machine learning models like Retrieval-Augmented Generation (RAG) to navigate and extract information from specified URLs efficiently.
This tool intends to offer flexibility, allowing users to perform searches across any website or focus on specific websites of interest.
Please note, the current implementation details of the WebsiteSearchTool are under development, and its functionalities as described may not yet be accessible.

## Installation

To prepare your environment for when the WebsiteSearchTool becomes available, you can install the foundational package with:

```shell
pip install 'crewai[tools]'
```

This command installs the necessary dependencies to ensure that once the tool is fully integrated, users can start using it immediately.

## Example Usage

Below are examples of how the WebsiteSearchTool could be utilized in different scenarios. Please note, these examples are illustrative and represent planned functionality:

```python Code
from crewai_tools import WebsiteSearchTool

# Example of initiating tool that agents can use
# to search across any discovered websites
tool = WebsiteSearchTool()

# Example of limiting the search to the content of a specific website,
# so now agents can only search within that website
tool = WebsiteSearchTool(website='https://example.com')
```

## Arguments

* `website`: An optional argument intended to specify the website URL for focused searches. This argument is designed to enhance the tool's flexibility by allowing targeted searches when necessary.

## Customization Options

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python Code
tool = WebsiteSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# YouTube Channel RAG Search
Source: https://docs.crewai.com/en/tools/search-research/youtubechannelsearchtool

The `YoutubeChannelSearchTool` is designed to perform a RAG (Retrieval-Augmented Generation) search within the content of a Youtube channel.

# `YoutubeChannelSearchTool`

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

This tool is designed to perform semantic searches within a specific Youtube channel's content.
Leveraging the RAG (Retrieval-Augmented Generation) methodology, it provides relevant search results,
making it invaluable for extracting information or finding specific content without the need to manually sift through videos.
It streamlines the search process within Youtube channels, catering to researchers, content creators, and viewers seeking specific information or topics.

## Installation

To utilize the YoutubeChannelSearchTool, the `crewai_tools` package must be installed. Execute the following command in your shell to install:

```shell
pip install 'crewai[tools]'
```

## Example

The following example demonstrates how to use the `YoutubeChannelSearchTool` with a CrewAI agent:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import YoutubeChannelSearchTool

# Initialize the tool for general YouTube channel searches
youtube_channel_tool = YoutubeChannelSearchTool()

# Define an agent that uses the tool
channel_researcher = Agent(
    role="Channel Researcher",
    goal="Extract relevant information from YouTube channels",
    backstory="An expert researcher who specializes in analyzing YouTube channel content.",
    tools=[youtube_channel_tool],
    verbose=True,
)

# Example task to search for information in a specific channel
research_task = Task(
    description="Search for information about machine learning tutorials in the YouTube channel {youtube_channel_handle}",
    expected_output="A summary of the key machine learning tutorials available on the channel.",
    agent=channel_researcher,
)

# Create and run the crew
crew = Crew(agents=[channel_researcher], tasks=[research_task])
result = crew.kickoff(inputs={"youtube_channel_handle": "@exampleChannel"})
```

You can also initialize the tool with a specific YouTube channel handle:

```python Code
# Initialize the tool with a specific YouTube channel handle
youtube_channel_tool = YoutubeChannelSearchTool(
    youtube_channel_handle='@exampleChannel'
)

# Define an agent that uses the tool
channel_researcher = Agent(
    role="Channel Researcher",
    goal="Extract relevant information from a specific YouTube channel",
    backstory="An expert researcher who specializes in analyzing YouTube channel content.",
    tools=[youtube_channel_tool],
    verbose=True,
)
```

## Parameters

The `YoutubeChannelSearchTool` accepts the following parameters:

* **youtube\_channel\_handle**: Optional. The handle of the YouTube channel to search within. If provided during initialization, the agent won't need to specify it when using the tool. If the handle doesn't start with '@', it will be automatically added.
* **config**: Optional. Configuration for the underlying RAG system, including LLM and embedder settings.
* **summarize**: Optional. Whether to summarize the retrieved content. Default is `False`.

When using the tool with an agent, the agent will need to provide:

* **search\_query**: Required. The search query to find relevant information in the channel content.
* **youtube\_channel\_handle**: Required only if not provided during initialization. The handle of the YouTube channel to search within.

## Custom Model and Embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python Code
youtube_channel_tool = YoutubeChannelSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```

## Agent Integration Example

Here's a more detailed example of how to integrate the `YoutubeChannelSearchTool` with a CrewAI agent:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import YoutubeChannelSearchTool

# Initialize the tool
youtube_channel_tool = YoutubeChannelSearchTool()

# Define an agent that uses the tool
channel_researcher = Agent(
    role="Channel Researcher",
    goal="Extract and analyze information from YouTube channels",
    backstory="""You are an expert channel researcher who specializes in extracting
    and analyzing information from YouTube channels. You have a keen eye for detail
    and can quickly identify key points and insights from video content across an entire channel.""",
    tools=[youtube_channel_tool],
    verbose=True,
)

# Create a task for the agent
research_task = Task(
    description="""
    Search for information about data science projects and tutorials
    in the YouTube channel {youtube_channel_handle}.

    Focus on:
    1. Key data science techniques covered
    2. Popular tutorial series
    3. Most viewed or recommended videos

    Provide a comprehensive summary of these points.
    """,
    expected_output="A detailed summary of data science content available on the channel.",
    agent=channel_researcher,
)

# Run the task
crew = Crew(agents=[channel_researcher], tasks=[research_task])
result = crew.kickoff(inputs={"youtube_channel_handle": "@exampleDataScienceChannel"})
```

## Implementation Details

The `YoutubeChannelSearchTool` is implemented as a subclass of `RagTool`, which provides the base functionality for Retrieval-Augmented Generation:

```python Code
class YoutubeChannelSearchTool(RagTool):
    name: str = "Search a Youtube Channels content"
    description: str = "A tool that can be used to semantic search a query from a Youtube Channels content."
    args_schema: Type[BaseModel] = YoutubeChannelSearchToolSchema

    def __init__(self, youtube_channel_handle: Optional[str] = None, **kwargs):
        super().__init__(**kwargs)
        if youtube_channel_handle is not None:
            kwargs["data_type"] = DataType.YOUTUBE_CHANNEL
            self.add(youtube_channel_handle)
            self.description = f"A tool that can be used to semantic search a query the {youtube_channel_handle} Youtube Channels content."
            self.args_schema = FixedYoutubeChannelSearchToolSchema
            self._generate_description()

    def add(
        self,
        youtube_channel_handle: str,
        **kwargs: Any,
    ) -> None:
        if not youtube_channel_handle.startswith("@"):
            youtube_channel_handle = f"@{youtube_channel_handle}"
        super().add(youtube_channel_handle, **kwargs)
```

## Conclusion

The `YoutubeChannelSearchTool` provides a powerful way to search and extract information from YouTube channel content using RAG techniques. By enabling agents to search across an entire channel's videos, it facilitates information extraction and analysis tasks that would otherwise be difficult to perform. This tool is particularly useful for research, content analysis, and knowledge extraction from YouTube channels.


# YouTube Video RAG Search
Source: https://docs.crewai.com/en/tools/search-research/youtubevideosearchtool

The `YoutubeVideoSearchTool` is designed to perform a RAG (Retrieval-Augmented Generation) search within the content of a Youtube video.

# `YoutubeVideoSearchTool`

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

This tool is part of the `crewai_tools` package and is designed to perform semantic searches within Youtube video content, utilizing Retrieval-Augmented Generation (RAG) techniques.
It is one of several "Search" tools in the package that leverage RAG for different sources.
The YoutubeVideoSearchTool allows for flexibility in searches; users can search across any Youtube video content without specifying a video URL,
or they can target their search to a specific Youtube video by providing its URL.

## Installation

To utilize the `YoutubeVideoSearchTool`, you must first install the `crewai_tools` package.
This package contains the `YoutubeVideoSearchTool` among other utilities designed to enhance your data analysis and processing tasks.
Install the package by executing the following command in your terminal:

```shell
pip install 'crewai[tools]'
```

## Example

The following example demonstrates how to use the `YoutubeVideoSearchTool` with a CrewAI agent:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import YoutubeVideoSearchTool

# Initialize the tool for general YouTube video searches
youtube_search_tool = YoutubeVideoSearchTool()

# Define an agent that uses the tool
video_researcher = Agent(
    role="Video Researcher",
    goal="Extract relevant information from YouTube videos",
    backstory="An expert researcher who specializes in analyzing video content.",
    tools=[youtube_search_tool],
    verbose=True,
)

# Example task to search for information in a specific video
research_task = Task(
    description="Search for information about machine learning frameworks in the YouTube video at {youtube_video_url}",
    expected_output="A summary of the key machine learning frameworks mentioned in the video.",
    agent=video_researcher,
)

# Create and run the crew
crew = Crew(agents=[video_researcher], tasks=[research_task])
result = crew.kickoff(inputs={"youtube_video_url": "https://youtube.com/watch?v=example"})
```

You can also initialize the tool with a specific YouTube video URL:

```python Code
# Initialize the tool with a specific YouTube video URL
youtube_search_tool = YoutubeVideoSearchTool(
    youtube_video_url='https://youtube.com/watch?v=example'
)

# Define an agent that uses the tool
video_researcher = Agent(
    role="Video Researcher",
    goal="Extract relevant information from a specific YouTube video",
    backstory="An expert researcher who specializes in analyzing video content.",
    tools=[youtube_search_tool],
    verbose=True,
)
```

## Parameters

The `YoutubeVideoSearchTool` accepts the following parameters:

* **youtube\_video\_url**: Optional. The URL of the YouTube video to search within. If provided during initialization, the agent won't need to specify it when using the tool.
* **config**: Optional. Configuration for the underlying RAG system, including LLM and embedder settings.
* **summarize**: Optional. Whether to summarize the retrieved content. Default is `False`.

When using the tool with an agent, the agent will need to provide:

* **search\_query**: Required. The search query to find relevant information in the video content.
* **youtube\_video\_url**: Required only if not provided during initialization. The URL of the YouTube video to search within.

## Custom Model and Embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python Code
youtube_search_tool = YoutubeVideoSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```

## Agent Integration Example

Here's a more detailed example of how to integrate the `YoutubeVideoSearchTool` with a CrewAI agent:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import YoutubeVideoSearchTool

# Initialize the tool
youtube_search_tool = YoutubeVideoSearchTool()

# Define an agent that uses the tool
video_researcher = Agent(
    role="Video Researcher",
    goal="Extract and analyze information from YouTube videos",
    backstory="""You are an expert video researcher who specializes in extracting
    and analyzing information from YouTube videos. You have a keen eye for detail
    and can quickly identify key points and insights from video content.""",
    tools=[youtube_search_tool],
    verbose=True,
)

# Create a task for the agent
research_task = Task(
    description="""
    Search for information about recent advancements in artificial intelligence
    in the YouTube video at {youtube_video_url}.

    Focus on:
    1. Key AI technologies mentioned
    2. Real-world applications discussed
    3. Future predictions made by the speaker

    Provide a comprehensive summary of these points.
    """,
    expected_output="A detailed summary of AI advancements, applications, and future predictions from the video.",
    agent=video_researcher,
)

# Run the task
crew = Crew(agents=[video_researcher], tasks=[research_task])
result = crew.kickoff(inputs={"youtube_video_url": "https://youtube.com/watch?v=example"})
```

## Implementation Details

The `YoutubeVideoSearchTool` is implemented as a subclass of `RagTool`, which provides the base functionality for Retrieval-Augmented Generation:

```python Code
class YoutubeVideoSearchTool(RagTool):
    name: str = "Search a Youtube Video content"
    description: str = "A tool that can be used to semantic search a query from a Youtube Video content."
    args_schema: Type[BaseModel] = YoutubeVideoSearchToolSchema

    def __init__(self, youtube_video_url: Optional[str] = None, **kwargs):
        super().__init__(**kwargs)
        if youtube_video_url is not None:
            kwargs["data_type"] = DataType.YOUTUBE_VIDEO
            self.add(youtube_video_url)
            self.description = f"A tool that can be used to semantic search a query the {youtube_video_url} Youtube Video content."
            self.args_schema = FixedYoutubeVideoSearchToolSchema
            self._generate_description()
```

## Conclusion

The `YoutubeVideoSearchTool` provides a powerful way to search and extract information from YouTube video content using RAG techniques. By enabling agents to search within video content, it facilitates information extraction and analysis tasks that would otherwise be difficult to perform. This tool is particularly useful for research, content analysis, and knowledge extraction from video sources.


# Browserbase Web Loader
Source: https://docs.crewai.com/en/tools/web-scraping/browserbaseloadtool

Browserbase is a developer platform to reliably run, manage, and monitor headless browsers.

# `BrowserbaseLoadTool`

## Description

[Browserbase](https://browserbase.com) is a developer platform to reliably run, manage, and monitor headless browsers.

Power your AI data retrievals with:

* [Serverless Infrastructure](https://docs.browserbase.com/under-the-hood) providing reliable browsers to extract data from complex UIs
* [Stealth Mode](https://docs.browserbase.com/features/stealth-mode) with included fingerprinting tactics and automatic captcha solving
* [Session Debugger](https://docs.browserbase.com/features/sessions) to inspect your Browser Session with networks timeline and logs
* [Live Debug](https://docs.browserbase.com/guides/session-debug-connection/browser-remote-control) to quickly debug your automation

## Installation

* Get an API key and Project ID from [browserbase.com](https://browserbase.com) and set it in environment variables (`BROWSERBASE_API_KEY`, `BROWSERBASE_PROJECT_ID`).
* Install the [Browserbase SDK](http://github.com/browserbase/python-sdk) along with `crewai[tools]` package:

```shell
pip install browserbase 'crewai[tools]'
```

## Example

Utilize the BrowserbaseLoadTool as follows to allow your agent to load websites:

```python Code
from crewai_tools import BrowserbaseLoadTool

# Initialize the tool with the Browserbase API key and Project ID
tool = BrowserbaseLoadTool()
```

## Arguments

The following parameters can be used to customize the `BrowserbaseLoadTool`'s behavior:

| Argument          | Type     | Description                                                                           |
| :---------------- | :------- | :------------------------------------------------------------------------------------ |
| **api\_key**      | `string` | *Optional*. Browserbase API key. Default is `BROWSERBASE_API_KEY` env variable.       |
| **project\_id**   | `string` | *Optional*. Browserbase Project ID. Default is `BROWSERBASE_PROJECT_ID` env variable. |
| **text\_content** | `bool`   | *Optional*. Retrieve only text content. Default is `False`.                           |
| **session\_id**   | `string` | *Optional*. Provide an existing Session ID.                                           |
| **proxy**         | `bool`   | *Optional*. Enable/Disable Proxies. Default is `False`.                               |


# Firecrawl Crawl Website
Source: https://docs.crewai.com/en/tools/web-scraping/firecrawlcrawlwebsitetool

The `FirecrawlCrawlWebsiteTool` is designed to crawl and convert websites into clean markdown or structured data.

# `FirecrawlCrawlWebsiteTool`

## Description

[Firecrawl](https://firecrawl.dev) is a platform for crawling and convert any website into clean markdown or structured data.

## Installation

* Get an API key from [firecrawl.dev](https://firecrawl.dev) and set it in environment variables (`FIRECRAWL_API_KEY`).
* Install the [Firecrawl SDK](https://github.com/mendableai/firecrawl) along with `crewai[tools]` package:

```shell
pip install firecrawl-py 'crewai[tools]'
```

## Example

Utilize the FirecrawlScrapeFromWebsiteTool as follows to allow your agent to load websites:

```python Code
from crewai_tools import FirecrawlCrawlWebsiteTool

tool = FirecrawlCrawlWebsiteTool(url='firecrawl.dev')
```

## Arguments

* `api_key`: Optional. Specifies Firecrawl API key. Defaults is the `FIRECRAWL_API_KEY` environment variable.
* `url`: The base URL to start crawling from.
* `page_options`: Optional.
  * `onlyMainContent`: Optional. Only return the main content of the page excluding headers, navs, footers, etc.
  * `includeHtml`: Optional. Include the raw HTML content of the page. Will output a html key in the response.
* `crawler_options`: Optional. Options for controlling the crawling behavior.
  * `includes`: Optional. URL patterns to include in the crawl.
  * `exclude`: Optional. URL patterns to exclude from the crawl.
  * `generateImgAltText`: Optional. Generate alt text for images using LLMs (requires a paid plan).
  * `returnOnlyUrls`: Optional. If true, returns only the URLs as a list in the crawl status. Note: the response will be a list of URLs inside the data, not a list of documents.
  * `maxDepth`: Optional. Maximum depth to crawl. Depth 1 is the base URL, depth 2 includes the base URL and its direct children, and so on.
  * `mode`: Optional. The crawling mode to use. Fast mode crawls 4x faster on websites without a sitemap but may not be as accurate and shouldn't be used on heavily JavaScript-rendered websites.
  * `limit`: Optional. Maximum number of pages to crawl.
  * `timeout`: Optional. Timeout in milliseconds for the crawling operation.


# Firecrawl Scrape Website
Source: https://docs.crewai.com/en/tools/web-scraping/firecrawlscrapewebsitetool

The `FirecrawlScrapeWebsiteTool` is designed to scrape websites and convert them into clean markdown or structured data.

# `FirecrawlScrapeWebsiteTool`

## Description

[Firecrawl](https://firecrawl.dev) is a platform for crawling and convert any website into clean markdown or structured data.

## Installation

* Get an API key from [firecrawl.dev](https://firecrawl.dev) and set it in environment variables (`FIRECRAWL_API_KEY`).
* Install the [Firecrawl SDK](https://github.com/mendableai/firecrawl) along with `crewai[tools]` package:

```shell
pip install firecrawl-py 'crewai[tools]'
```

## Example

Utilize the FirecrawlScrapeWebsiteTool as follows to allow your agent to load websites:

```python Code
from crewai_tools import FirecrawlScrapeWebsiteTool

tool = FirecrawlScrapeWebsiteTool(url='firecrawl.dev')
```

## Arguments

* `api_key`: Optional. Specifies Firecrawl API key. Defaults is the `FIRECRAWL_API_KEY` environment variable.
* `url`: The URL to scrape.
* `page_options`: Optional.
  * `onlyMainContent`: Optional. Only return the main content of the page excluding headers, navs, footers, etc.
  * `includeHtml`: Optional. Include the raw HTML content of the page. Will output a html key in the response.
* `extractor_options`: Optional. Options for LLM-based extraction of structured information from the page content
  * `mode`: The extraction mode to use, currently supports 'llm-extraction'
  * `extractionPrompt`: Optional. A prompt describing what information to extract from the page
  * `extractionSchema`: Optional. The schema for the data to be extracted
* `timeout`: Optional. Timeout in milliseconds for the request


# Firecrawl Search
Source: https://docs.crewai.com/en/tools/web-scraping/firecrawlsearchtool

The `FirecrawlSearchTool` is designed to search websites and convert them into clean markdown or structured data.

# `FirecrawlSearchTool`

## Description

[Firecrawl](https://firecrawl.dev) is a platform for crawling and convert any website into clean markdown or structured data.

## Installation

* Get an API key from [firecrawl.dev](https://firecrawl.dev) and set it in environment variables (`FIRECRAWL_API_KEY`).
* Install the [Firecrawl SDK](https://github.com/mendableai/firecrawl) along with `crewai[tools]` package:

```shell
pip install firecrawl-py 'crewai[tools]'
```

## Example

Utilize the FirecrawlSearchTool as follows to allow your agent to load websites:

```python Code
from crewai_tools import FirecrawlSearchTool

tool = FirecrawlSearchTool(query='what is firecrawl?')
```

## Arguments

* `api_key`: Optional. Specifies Firecrawl API key. Defaults is the `FIRECRAWL_API_KEY` environment variable.
* `query`: The search query string to be used for searching.
* `page_options`: Optional. Options for result formatting.
  * `onlyMainContent`: Optional. Only return the main content of the page excluding headers, navs, footers, etc.
  * `includeHtml`: Optional. Include the raw HTML content of the page. Will output a html key in the response.
  * `fetchPageContent`: Optional. Fetch the full content of the page.
* `search_options`: Optional. Options for controlling the crawling behavior.
  * `limit`: Optional. Maximum number of pages to crawl.


# Hyperbrowser Load Tool
Source: https://docs.crewai.com/en/tools/web-scraping/hyperbrowserloadtool

The `HyperbrowserLoadTool` enables web scraping and crawling using Hyperbrowser.

# `HyperbrowserLoadTool`

## Description

The `HyperbrowserLoadTool` enables web scraping and crawling using [Hyperbrowser](https://hyperbrowser.ai), a platform for running and scaling headless browsers. This tool allows you to scrape a single page or crawl an entire site, returning the content in properly formatted markdown or HTML.

Key Features:

* Instant Scalability - Spin up hundreds of browser sessions in seconds without infrastructure headaches
* Simple Integration - Works seamlessly with popular tools like Puppeteer and Playwright
* Powerful APIs - Easy to use APIs for scraping/crawling any site
* Bypass Anti-Bot Measures - Built-in stealth mode, ad blocking, automatic CAPTCHA solving, and rotating proxies

## Installation

To use this tool, you need to install the Hyperbrowser SDK:

```shell
uv add hyperbrowser
```

## Steps to Get Started

To effectively use the `HyperbrowserLoadTool`, follow these steps:

1. **Sign Up**: Head to [Hyperbrowser](https://app.hyperbrowser.ai/) to sign up and generate an API key.
2. **API Key**: Set the `HYPERBROWSER_API_KEY` environment variable or pass it directly to the tool constructor.
3. **Install SDK**: Install the Hyperbrowser SDK using the command above.

## Example

The following example demonstrates how to initialize the tool and use it to scrape a website:

```python Code
from crewai_tools import HyperbrowserLoadTool
from crewai import Agent

# Initialize the tool with your API key
tool = HyperbrowserLoadTool(api_key="your_api_key")  # Or use environment variable

# Define an agent that uses the tool
@agent
def web_researcher(self) -> Agent:
    '''
    This agent uses the HyperbrowserLoadTool to scrape websites
    and extract information.
    '''
    return Agent(
        config=self.agents_config["web_researcher"],
        tools=[tool]
    )
```

## Parameters

The `HyperbrowserLoadTool` accepts the following parameters:

### Constructor Parameters

* **api\_key**: Optional. Your Hyperbrowser API key. If not provided, it will be read from the `HYPERBROWSER_API_KEY` environment variable.

### Run Parameters

* **url**: Required. The website URL to scrape or crawl.
* **operation**: Optional. The operation to perform on the website. Either 'scrape' or 'crawl'. Default is 'scrape'.
* **params**: Optional. Additional parameters for the scrape or crawl operation.

## Supported Parameters

For detailed information on all supported parameters, visit:

* [Scrape Parameters](https://docs.hyperbrowser.ai/reference/sdks/python/scrape#start-scrape-job-and-wait)
* [Crawl Parameters](https://docs.hyperbrowser.ai/reference/sdks/python/crawl#start-crawl-job-and-wait)

## Return Format

The tool returns content in the following format:

* For **scrape** operations: The content of the page in markdown or HTML format.
* For **crawl** operations: The content of each page separated by dividers, including the URL of each page.

## Conclusion

The `HyperbrowserLoadTool` provides a powerful way to scrape and crawl websites, handling complex scenarios like anti-bot measures, CAPTCHAs, and more. By leveraging Hyperbrowser's platform, this tool enables agents to access and extract web content efficiently.


# Overview
Source: https://docs.crewai.com/en/tools/web-scraping/overview

Extract data from websites and automate browser interactions with powerful scraping tools

These tools enable your agents to interact with the web, extract data from websites, and automate browser-based tasks. From simple web scraping to complex browser automation, these tools cover all your web interaction needs.

## **Available Tools**

<CardGroup cols={2}>
  <Card title="Scrape Website Tool" icon="globe" href="/en/tools/web-scraping/scrapewebsitetool">
    General-purpose web scraping tool for extracting content from any website.
  </Card>

  <Card title="Scrape Element Tool" icon="crosshairs" href="/en/tools/web-scraping/scrapeelementfromwebsitetool">
    Target specific elements on web pages with precision scraping capabilities.
  </Card>

  <Card title="Firecrawl Crawl Tool" icon="spider" href="/en/tools/web-scraping/firecrawlcrawlwebsitetool">
    Crawl entire websites systematically with Firecrawl's powerful engine.
  </Card>

  <Card title="Firecrawl Scrape Tool" icon="fire" href="/en/tools/web-scraping/firecrawlscrapewebsitetool">
    High-performance web scraping with Firecrawl's advanced capabilities.
  </Card>

  <Card title="Firecrawl Search Tool" icon="magnifying-glass" href="/en/tools/web-scraping/firecrawlsearchtool">
    Search and extract specific content using Firecrawl's search features.
  </Card>

  <Card title="Selenium Scraping Tool" icon="robot" href="/en/tools/web-scraping/seleniumscrapingtool">
    Browser automation and scraping with Selenium WebDriver capabilities.
  </Card>

  <Card title="ScrapFly Tool" icon="plane" href="/en/tools/web-scraping/scrapflyscrapetool">
    Professional web scraping with ScrapFly's premium scraping service.
  </Card>

  <Card title="ScrapGraph Tool" icon="network-wired" href="/en/tools/web-scraping/scrapegraphscrapetool">
    Graph-based web scraping for complex data relationships.
  </Card>

  <Card title="Spider Tool" icon="spider" href="/en/tools/web-scraping/spidertool">
    Comprehensive web crawling and data extraction capabilities.
  </Card>

  <Card title="BrowserBase Tool" icon="browser" href="/en/tools/web-scraping/browserbaseloadtool">
    Cloud-based browser automation with BrowserBase infrastructure.
  </Card>

  <Card title="HyperBrowser Tool" icon="window-maximize" href="/en/tools/web-scraping/hyperbrowserloadtool">
    Fast browser interactions with HyperBrowser's optimized engine.
  </Card>

  <Card title="Stagehand Tool" icon="hand" href="/en/tools/web-scraping/stagehandtool">
    Intelligent browser automation with natural language commands.
  </Card>

  <Card title="Oxylabs Scraper Tool" icon="globe" href="/en/tools/web-scraping/oxylabsscraperstool">
    Access web data at scale with Oxylabs.
  </Card>
</CardGroup>

## **Common Use Cases**

* **Data Extraction**: Scrape product information, prices, and reviews
* **Content Monitoring**: Track changes on websites and news sources
* **Lead Generation**: Extract contact information and business data
* **Market Research**: Gather competitive intelligence and market data
* **Testing & QA**: Automate browser testing and validation workflows
* **Social Media**: Extract posts, comments, and social media analytics

## **Quick Start Example**

```python
from crewai_tools import ScrapeWebsiteTool, FirecrawlScrapeWebsiteTool, SeleniumScrapingTool

# Create scraping tools
simple_scraper = ScrapeWebsiteTool()
advanced_scraper = FirecrawlScrapeWebsiteTool()
browser_automation = SeleniumScrapingTool()

# Add to your agent
agent = Agent(
    role="Web Research Specialist",
    tools=[simple_scraper, advanced_scraper, browser_automation],
    goal="Extract and analyze web data efficiently"
)
```

## **Scraping Best Practices**

* **Respect robots.txt**: Always check and follow website scraping policies
* **Rate Limiting**: Implement delays between requests to avoid overwhelming servers
* **User Agents**: Use appropriate user agent strings to identify your bot
* **Legal Compliance**: Ensure your scraping activities comply with terms of service
* **Error Handling**: Implement robust error handling for network issues and blocked requests
* **Data Quality**: Validate and clean extracted data before processing

## **Tool Selection Guide**

* **Simple Tasks**: Use `ScrapeWebsiteTool` for basic content extraction
* **JavaScript-Heavy Sites**: Use `SeleniumScrapingTool` for dynamic content
* **Scale & Performance**: Use `FirecrawlScrapeWebsiteTool` for high-volume scraping
* **Cloud Infrastructure**: Use `BrowserBaseLoadTool` for scalable browser automation
* **Complex Workflows**: Use `StagehandTool` for intelligent browser interactions


# Oxylabs Scrapers
Source: https://docs.crewai.com/en/tools/web-scraping/oxylabsscraperstool

Oxylabs Scrapers allow to easily access the information from the respective sources. Please see the list of available sources below:
  - `Amazon Product`
  - `Amazon Search`
  - `Google Seach`
  - `Universal`


## Installation

Get the credentials by creating an Oxylabs Account [here](https://oxylabs.io).

```shell
pip install 'crewai[tools]' oxylabs
```

Check [Oxylabs Documentation](https://developers.oxylabs.io/scraping-solutions/web-scraper-api/targets) to get more information about API parameters.

# `OxylabsAmazonProductScraperTool`

### Example

```python
from crewai_tools import OxylabsAmazonProductScraperTool

# make sure OXYLABS_USERNAME and OXYLABS_PASSWORD variables are set
tool = OxylabsAmazonProductScraperTool()

result = tool.run(query="AAAAABBBBCC")

print(result)
```

### Parameters

* `query` - 10-symbol ASIN code.
* `domain` - domain localization for Amazon.
* `geo_location` - the *Deliver to* location.
* `user_agent_type` - device type and browser.
* `render` - enables JavaScript rendering when set to `html`.
* `callback_url` - URL to your callback endpoint.
* `context` - Additional advanced settings and controls for specialized requirements.
* `parse` - returns parsed data when set to true.
* `parsing_instructions` - define your own parsing and data transformation logic that will be executed on an HTML scraping result.

### Advanced example

```python
from crewai_tools import OxylabsAmazonProductScraperTool

# make sure OXYLABS_USERNAME and OXYLABS_PASSWORD variables are set
tool = OxylabsAmazonProductScraperTool(
    config={
        "domain": "com",
        "parse": True,
        "context": [
            {
                "key": "autoselect_variant",
                "value": True
            }
        ]
    }
)

result = tool.run(query="AAAAABBBBCC")

print(result)
```

# `OxylabsAmazonSearchScraperTool`

### Example

```python
from crewai_tools import OxylabsAmazonSearchScraperTool

# make sure OXYLABS_USERNAME and OXYLABS_PASSWORD variables are set
tool = OxylabsAmazonSearchScraperTool()

result = tool.run(query="headsets")

print(result)
```

### Parameters

* `query` - Amazon search term.
* `domain` - Domain localization for Bestbuy.
* `start_page` - starting page number.
* `pages` - number of pages to retrieve.
* `geo_location` - the *Deliver to* location.
* `user_agent_type` - device type and browser.
* `render` - enables JavaScript rendering when set to `html`.
* `callback_url` - URL to your callback endpoint.
* `context` - Additional advanced settings and controls for specialized requirements.
* `parse` - returns parsed data when set to true.
* `parsing_instructions` - define your own parsing and data transformation logic that will be executed on an HTML scraping result.

### Advanced example

```python
from crewai_tools import OxylabsAmazonSearchScraperTool

# make sure OXYLABS_USERNAME and OXYLABS_PASSWORD variables are set
tool = OxylabsAmazonSearchScraperTool(
    config={
        "domain": 'nl',
        "start_page": 2,
        "pages": 2,
        "parse": True,
        "context": [
            {'key': 'category_id', 'value': 16391693031}
        ],
    }
)

result = tool.run(query='nirvana tshirt')

print(result)
```

# `OxylabsGoogleSearchScraperTool`

### Example

```python
from crewai_tools import OxylabsGoogleSearchScraperTool

# make sure OXYLABS_USERNAME and OXYLABS_PASSWORD variables are set
tool = OxylabsGoogleSearchScraperTool()

result = tool.run(query="iPhone 16")

print(result)
```

### Parameters

* `query` - search keyword.
* `domain` - domain localization for Google.
* `start_page` - starting page number.
* `pages` - number of pages to retrieve.
* `limit` - number of results to retrieve in each page.
* `locale` - `Accept-Language` header value which changes your Google search page web interface language.
* `geo_location` - the geographical location that the result should be adapted for. Using this parameter correctly is extremely important to get the right data.
* `user_agent_type` - device type and browser.
* `render` - enables JavaScript rendering when set to `html`.
* `callback_url` - URL to your callback endpoint.
* `context` - Additional advanced settings and controls for specialized requirements.
* `parse` - returns parsed data when set to true.
* `parsing_instructions` - define your own parsing and data transformation logic that will be executed on an HTML scraping result.

### Advanced example

```python
from crewai_tools import OxylabsGoogleSearchScraperTool

# make sure OXYLABS_USERNAME and OXYLABS_PASSWORD variables are set
tool = OxylabsGoogleSearchScraperTool(
    config={
        "parse": True,
        "geo_location": "Paris, France",
        "user_agent_type": "tablet",
    }
)

result = tool.run(query="iPhone 16")

print(result)
```

# `OxylabsUniversalScraperTool`

### Example

```python
from crewai_tools import OxylabsUniversalScraperTool

# make sure OXYLABS_USERNAME and OXYLABS_PASSWORD variables are set
tool = OxylabsUniversalScraperTool()

result = tool.run(url="https://ip.oxylabs.io")

print(result)
```

### Parameters

* `url` - website url to scrape.
* `user_agent_type` - device type and browser.
* `geo_location` - sets the proxy's geolocation to retrieve data.
* `render` - enables JavaScript rendering when set to `html`.
* `callback_url` - URL to your callback endpoint.
* `context` - Additional advanced settings and controls for specialized requirements.
* `parse` - returns parsed data when set to `true`, as long as a dedicated parser exists for the submitted URL's page type.
* `parsing_instructions` - define your own parsing and data transformation logic that will be executed on an HTML scraping result.

### Advanced example

```python
from crewai_tools import OxylabsUniversalScraperTool

# make sure OXYLABS_USERNAME and OXYLABS_PASSWORD variables are set
tool = OxylabsUniversalScraperTool(
    config={
        "render": "html",
        "user_agent_type": "mobile",
        "context": [
            {"key": "force_headers", "value": True},
            {"key": "force_cookies", "value": True},
            {
                "key": "headers",
                "value": {
                    "Custom-Header-Name": "custom header content",
                },
            },
            {
                "key": "cookies",
                "value": [
                    {"key": "NID", "value": "1234567890"},
                    {"key": "1P JAR", "value": "0987654321"},
                ],
            },
            {"key": "http_method", "value": "get"},
            {"key": "follow_redirects", "value": True},
            {"key": "successful_status_codes", "value": [808, 909]},
        ],
    }
)

result = tool.run(url="https://ip.oxylabs.io")

print(result)
```


# Scrape Element From Website Tool
Source: https://docs.crewai.com/en/tools/web-scraping/scrapeelementfromwebsitetool

The `ScrapeElementFromWebsiteTool` enables CrewAI agents to extract specific elements from websites using CSS selectors.

# `ScrapeElementFromWebsiteTool`

## Description

The `ScrapeElementFromWebsiteTool` is designed to extract specific elements from websites using CSS selectors. This tool allows CrewAI agents to scrape targeted content from web pages, making it useful for data extraction tasks where only specific parts of a webpage are needed.

## Installation

To use this tool, you need to install the required dependencies:

```shell
uv add requests beautifulsoup4
```

## Steps to Get Started

To effectively use the `ScrapeElementFromWebsiteTool`, follow these steps:

1. **Install Dependencies**: Install the required packages using the command above.
2. **Identify CSS Selectors**: Determine the CSS selectors for the elements you want to extract from the website.
3. **Initialize the Tool**: Create an instance of the tool with the necessary parameters.

## Example

The following example demonstrates how to use the `ScrapeElementFromWebsiteTool` to extract specific elements from a website:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import ScrapeElementFromWebsiteTool

# Initialize the tool
scrape_tool = ScrapeElementFromWebsiteTool()

# Define an agent that uses the tool
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract specific information from websites",
    backstory="An expert in web scraping who can extract targeted content from web pages.",
    tools=[scrape_tool],
    verbose=True,
)

# Example task to extract headlines from a news website
scrape_task = Task(
    description="Extract the main headlines from the CNN homepage. Use the CSS selector '.headline' to target the headline elements.",
    expected_output="A list of the main headlines from CNN.",
    agent=web_scraper_agent,
)

# Create and run the crew
crew = Crew(agents=[web_scraper_agent], tasks=[scrape_task])
result = crew.kickoff()
```

You can also initialize the tool with predefined parameters:

```python Code
# Initialize the tool with predefined parameters
scrape_tool = ScrapeElementFromWebsiteTool(
    website_url="https://www.example.com",
    css_element=".main-content"
)
```

## Parameters

The `ScrapeElementFromWebsiteTool` accepts the following parameters during initialization:

* **website\_url**: Optional. The URL of the website to scrape. If provided during initialization, the agent won't need to specify it when using the tool.
* **css\_element**: Optional. The CSS selector for the elements to extract. If provided during initialization, the agent won't need to specify it when using the tool.
* **cookies**: Optional. A dictionary containing cookies to be sent with the request. This can be useful for websites that require authentication.

## Usage

When using the `ScrapeElementFromWebsiteTool` with an agent, the agent will need to provide the following parameters (unless they were specified during initialization):

* **website\_url**: The URL of the website to scrape.
* **css\_element**: The CSS selector for the elements to extract.

The tool will return the text content of all elements matching the CSS selector, joined by newlines.

```python Code
# Example of using the tool with an agent
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract specific elements from websites",
    backstory="An expert in web scraping who can extract targeted content using CSS selectors.",
    tools=[scrape_tool],
    verbose=True,
)

# Create a task for the agent to extract specific elements
extract_task = Task(
    description="""
    Extract all product titles from the featured products section on example.com.
    Use the CSS selector '.product-title' to target the title elements.
    """,
    expected_output="A list of product titles from the website",
    agent=web_scraper_agent,
)

# Run the task through a crew
crew = Crew(agents=[web_scraper_agent], tasks=[extract_task])
result = crew.kickoff()
```

## Implementation Details

The `ScrapeElementFromWebsiteTool` uses the `requests` library to fetch the web page and `BeautifulSoup` to parse the HTML and extract the specified elements:

```python Code
class ScrapeElementFromWebsiteTool(BaseTool):
    name: str = "Read a website content"
    description: str = "A tool that can be used to read a website content."

    # Implementation details...

    def _run(self, **kwargs: Any) -> Any:
        website_url = kwargs.get("website_url", self.website_url)
        css_element = kwargs.get("css_element", self.css_element)
        page = requests.get(
            website_url,
            headers=self.headers,
            cookies=self.cookies if self.cookies else {},
        )
        parsed = BeautifulSoup(page.content, "html.parser")
        elements = parsed.select(css_element)
        return "\n".join([element.get_text() for element in elements])
```

## Conclusion

The `ScrapeElementFromWebsiteTool` provides a powerful way to extract specific elements from websites using CSS selectors. By enabling agents to target only the content they need, it makes web scraping tasks more efficient and focused. This tool is particularly useful for data extraction, content monitoring, and research tasks where specific information needs to be extracted from web pages.


# Scrapegraph Scrape Tool
Source: https://docs.crewai.com/en/tools/web-scraping/scrapegraphscrapetool

The `ScrapegraphScrapeTool` leverages Scrapegraph AI's SmartScraper API to intelligently extract content from websites.

# `ScrapegraphScrapeTool`

## Description

The `ScrapegraphScrapeTool` is designed to leverage Scrapegraph AI's SmartScraper API to intelligently extract content from websites. This tool provides advanced web scraping capabilities with AI-powered content extraction, making it ideal for targeted data collection and content analysis tasks. Unlike traditional web scrapers, it can understand the context and structure of web pages to extract the most relevant information based on natural language prompts.

## Installation

To use this tool, you need to install the Scrapegraph Python client:

```shell
uv add scrapegraph-py
```

You'll also need to set up your Scrapegraph API key as an environment variable:

```shell
export SCRAPEGRAPH_API_KEY="your_api_key"
```

You can obtain an API key from [Scrapegraph AI](https://scrapegraphai.com).

## Steps to Get Started

To effectively use the `ScrapegraphScrapeTool`, follow these steps:

1. **Install Dependencies**: Install the required package using the command above.
2. **Set Up API Key**: Set your Scrapegraph API key as an environment variable or provide it during initialization.
3. **Initialize the Tool**: Create an instance of the tool with the necessary parameters.
4. **Define Extraction Prompts**: Create natural language prompts to guide the extraction of specific content.

## Example

The following example demonstrates how to use the `ScrapegraphScrapeTool` to extract content from a website:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import ScrapegraphScrapeTool

# Initialize the tool
scrape_tool = ScrapegraphScrapeTool(api_key="your_api_key")

# Define an agent that uses the tool
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract specific information from websites",
    backstory="An expert in web scraping who can extract targeted content from web pages.",
    tools=[scrape_tool],
    verbose=True,
)

# Example task to extract product information from an e-commerce site
scrape_task = Task(
    description="Extract product names, prices, and descriptions from the featured products section of example.com.",
    expected_output="A structured list of product information including names, prices, and descriptions.",
    agent=web_scraper_agent,
)

# Create and run the crew
crew = Crew(agents=[web_scraper_agent], tasks=[scrape_task])
result = crew.kickoff()
```

You can also initialize the tool with predefined parameters:

```python Code
# Initialize the tool with predefined parameters
scrape_tool = ScrapegraphScrapeTool(
    website_url="https://www.example.com",
    user_prompt="Extract all product prices and descriptions",
    api_key="your_api_key"
)
```

## Parameters

The `ScrapegraphScrapeTool` accepts the following parameters during initialization:

* **api\_key**: Optional. Your Scrapegraph API key. If not provided, it will look for the `SCRAPEGRAPH_API_KEY` environment variable.
* **website\_url**: Optional. The URL of the website to scrape. If provided during initialization, the agent won't need to specify it when using the tool.
* **user\_prompt**: Optional. Custom instructions for content extraction. If provided during initialization, the agent won't need to specify it when using the tool.
* **enable\_logging**: Optional. Whether to enable logging for the Scrapegraph client. Default is `False`.

## Usage

When using the `ScrapegraphScrapeTool` with an agent, the agent will need to provide the following parameters (unless they were specified during initialization):

* **website\_url**: The URL of the website to scrape.
* **user\_prompt**: Optional. Custom instructions for content extraction. Default is "Extract the main content of the webpage".

The tool will return the extracted content based on the provided prompt.

```python Code
# Example of using the tool with an agent
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract specific information from websites",
    backstory="An expert in web scraping who can extract targeted content from web pages.",
    tools=[scrape_tool],
    verbose=True,
)

# Create a task for the agent to extract specific content
extract_task = Task(
    description="Extract the main heading and summary from example.com",
    expected_output="The main heading and summary from the website",
    agent=web_scraper_agent,
)

# Run the task
crew = Crew(agents=[web_scraper_agent], tasks=[extract_task])
result = crew.kickoff()
```

## Error Handling

The `ScrapegraphScrapeTool` may raise the following exceptions:

* **ValueError**: When API key is missing or URL format is invalid.
* **RateLimitError**: When API rate limits are exceeded.
* **RuntimeError**: When scraping operation fails (network issues, API errors).

It's recommended to instruct agents to handle potential errors gracefully:

```python Code
# Create a task that includes error handling instructions
robust_extract_task = Task(
    description="""
    Extract the main heading from example.com.
    Be aware that you might encounter errors such as:
    - Invalid URL format
    - Missing API key
    - Rate limit exceeded
    - Network or API errors

    If you encounter any errors, provide a clear explanation of what went wrong
    and suggest possible solutions.
    """,
    expected_output="Either the extracted heading or a clear error explanation",
    agent=web_scraper_agent,
)
```

## Rate Limiting

The Scrapegraph API has rate limits that vary based on your subscription plan. Consider the following best practices:

* Implement appropriate delays between requests when processing multiple URLs.
* Handle rate limit errors gracefully in your application.
* Check your API plan limits on the Scrapegraph dashboard.

## Implementation Details

The `ScrapegraphScrapeTool` uses the Scrapegraph Python client to interact with the SmartScraper API:

```python Code
class ScrapegraphScrapeTool(BaseTool):
    """
    A tool that uses Scrapegraph AI to intelligently scrape website content.
    """

    # Implementation details...

    def _run(self, **kwargs: Any) -> Any:
        website_url = kwargs.get("website_url", self.website_url)
        user_prompt = (
            kwargs.get("user_prompt", self.user_prompt)
            or "Extract the main content of the webpage"
        )

        if not website_url:
            raise ValueError("website_url is required")

        # Validate URL format
        self._validate_url(website_url)

        try:
            # Make the SmartScraper request
            response = self._client.smartscraper(
                website_url=website_url,
                user_prompt=user_prompt,
            )

            return response
        # Error handling...
```

## Conclusion

The `ScrapegraphScrapeTool` provides a powerful way to extract content from websites using AI-powered understanding of web page structure. By enabling agents to target specific information using natural language prompts, it makes web scraping tasks more efficient and focused. This tool is particularly useful for data extraction, content monitoring, and research tasks where specific information needs to be extracted from web pages.


# Scrape Website
Source: https://docs.crewai.com/en/tools/web-scraping/scrapewebsitetool

The `ScrapeWebsiteTool` is designed to extract and read the content of a specified website.

# `ScrapeWebsiteTool`

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

A tool designed to extract and read the content of a specified website. It is capable of handling various types of web pages by making HTTP requests and parsing the received HTML content.
This tool can be particularly useful for web scraping tasks, data collection, or extracting specific information from websites.

## Installation

Install the crewai\_tools package

```shell
pip install 'crewai[tools]'
```

## Example

```python
from crewai_tools import ScrapeWebsiteTool

# To enable scrapping any website it finds during it's execution
tool = ScrapeWebsiteTool()

# Initialize the tool with the website URL,
# so the agent can only scrap the content of the specified website
tool = ScrapeWebsiteTool(website_url='https://www.example.com')

# Extract the text from the site
text = tool.run()
print(text)
```

## Arguments

| Argument         | Type     | Description                                                                                                                                        |
| :--------------- | :------- | :------------------------------------------------------------------------------------------------------------------------------------------------- |
| **website\_url** | `string` | **Mandatory** website URL to read the file. This is the primary input for the tool, specifying which website's content should be scraped and read. |


# Scrapfly Scrape Website Tool
Source: https://docs.crewai.com/en/tools/web-scraping/scrapflyscrapetool

The `ScrapflyScrapeWebsiteTool` leverages Scrapfly's web scraping API to extract content from websites in various formats.

# `ScrapflyScrapeWebsiteTool`

## Description

The `ScrapflyScrapeWebsiteTool` is designed to leverage [Scrapfly](https://scrapfly.io/)'s web scraping API to extract content from websites. This tool provides advanced web scraping capabilities with headless browser support, proxies, and anti-bot bypass features. It allows for extracting web page data in various formats, including raw HTML, markdown, and plain text, making it ideal for a wide range of web scraping tasks.

## Installation

To use this tool, you need to install the Scrapfly SDK:

```shell
uv add scrapfly-sdk
```

You'll also need to obtain a Scrapfly API key by registering at [scrapfly.io/register](https://www.scrapfly.io/register/).

## Steps to Get Started

To effectively use the `ScrapflyScrapeWebsiteTool`, follow these steps:

1. **Install Dependencies**: Install the Scrapfly SDK using the command above.
2. **Obtain API Key**: Register at Scrapfly to get your API key.
3. **Initialize the Tool**: Create an instance of the tool with your API key.
4. **Configure Scraping Parameters**: Customize the scraping parameters based on your needs.

## Example

The following example demonstrates how to use the `ScrapflyScrapeWebsiteTool` to extract content from a website:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import ScrapflyScrapeWebsiteTool

# Initialize the tool
scrape_tool = ScrapflyScrapeWebsiteTool(api_key="your_scrapfly_api_key")

# Define an agent that uses the tool
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract information from websites",
    backstory="An expert in web scraping who can extract content from any website.",
    tools=[scrape_tool],
    verbose=True,
)

# Example task to extract content from a website
scrape_task = Task(
    description="Extract the main content from the product page at https://web-scraping.dev/products and summarize the available products.",
    expected_output="A summary of the products available on the website.",
    agent=web_scraper_agent,
)

# Create and run the crew
crew = Crew(agents=[web_scraper_agent], tasks=[scrape_task])
result = crew.kickoff()
```

You can also customize the scraping parameters:

```python Code
# Example with custom scraping parameters
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract information from websites with custom parameters",
    backstory="An expert in web scraping who can extract content from any website.",
    tools=[scrape_tool],
    verbose=True,
)

# The agent will use the tool with parameters like:
# url="https://web-scraping.dev/products"
# scrape_format="markdown"
# ignore_scrape_failures=True
# scrape_config={
#     "asp": True,  # Bypass scraping blocking solutions, like Cloudflare
#     "render_js": True,  # Enable JavaScript rendering with a cloud headless browser
#     "proxy_pool": "public_residential_pool",  # Select a proxy pool
#     "country": "us",  # Select a proxy location
#     "auto_scroll": True,  # Auto scroll the page
# }

scrape_task = Task(
    description="Extract the main content from the product page at https://web-scraping.dev/products using advanced scraping options including JavaScript rendering and proxy settings.",
    expected_output="A detailed summary of the products with all available information.",
    agent=web_scraper_agent,
)
```

## Parameters

The `ScrapflyScrapeWebsiteTool` accepts the following parameters:

### Initialization Parameters

* **api\_key**: Required. Your Scrapfly API key.

### Run Parameters

* **url**: Required. The URL of the website to scrape.
* **scrape\_format**: Optional. The format in which to extract the web page content. Options are "raw" (HTML), "markdown", or "text". Default is "markdown".
* **scrape\_config**: Optional. A dictionary containing additional Scrapfly scraping configuration options.
* **ignore\_scrape\_failures**: Optional. Whether to ignore failures during scraping. If set to `True`, the tool will return `None` instead of raising an exception when scraping fails.

## Scrapfly Configuration Options

The `scrape_config` parameter allows you to customize the scraping behavior with the following options:

* **asp**: Enable anti-scraping protection bypass.
* **render\_js**: Enable JavaScript rendering with a cloud headless browser.
* **proxy\_pool**: Select a proxy pool (e.g., "public\_residential\_pool", "datacenter").
* **country**: Select a proxy location (e.g., "us", "uk").
* **auto\_scroll**: Automatically scroll the page to load lazy-loaded content.
* **js**: Execute custom JavaScript code by the headless browser.

For a complete list of configuration options, refer to the [Scrapfly API documentation](https://scrapfly.io/docs/scrape-api/getting-started).

## Usage

When using the `ScrapflyScrapeWebsiteTool` with an agent, the agent will need to provide the URL of the website to scrape and can optionally specify the format and additional configuration options:

```python Code
# Example of using the tool with an agent
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract information from websites",
    backstory="An expert in web scraping who can extract content from any website.",
    tools=[scrape_tool],
    verbose=True,
)

# Create a task for the agent
scrape_task = Task(
    description="Extract the main content from example.com in markdown format.",
    expected_output="The main content of example.com in markdown format.",
    agent=web_scraper_agent,
)

# Run the task
crew = Crew(agents=[web_scraper_agent], tasks=[scrape_task])
result = crew.kickoff()
```

For more advanced usage with custom configuration:

```python Code
# Create a task with more specific instructions
advanced_scrape_task = Task(
    description="""
    Extract content from example.com with the following requirements:
    - Convert the content to plain text format
    - Enable JavaScript rendering
    - Use a US-based proxy
    - Handle any scraping failures gracefully
    """,
    expected_output="The extracted content from example.com",
    agent=web_scraper_agent,
)
```

## Error Handling

By default, the `ScrapflyScrapeWebsiteTool` will raise an exception if scraping fails. Agents can be instructed to handle failures gracefully by specifying the `ignore_scrape_failures` parameter:

```python Code
# Create a task that instructs the agent to handle errors
error_handling_task = Task(
    description="""
    Extract content from a potentially problematic website and make sure to handle any
    scraping failures gracefully by setting ignore_scrape_failures to True.
    """,
    expected_output="Either the extracted content or a graceful error message",
    agent=web_scraper_agent,
)
```

## Implementation Details

The `ScrapflyScrapeWebsiteTool` uses the Scrapfly SDK to interact with the Scrapfly API:

```python Code
class ScrapflyScrapeWebsiteTool(BaseTool):
    name: str = "Scrapfly web scraping API tool"
    description: str = (
        "Scrape a webpage url using Scrapfly and return its content as markdown or text"
    )

    # Implementation details...

    def _run(
        self,
        url: str,
        scrape_format: str = "markdown",
        scrape_config: Optional[Dict[str, Any]] = None,
        ignore_scrape_failures: Optional[bool] = None,
    ):
        from scrapfly import ScrapeApiResponse, ScrapeConfig

        scrape_config = scrape_config if scrape_config is not None else {}
        try:
            response: ScrapeApiResponse = self.scrapfly.scrape(
                ScrapeConfig(url, format=scrape_format, **scrape_config)
            )
            return response.scrape_result["content"]
        except Exception as e:
            if ignore_scrape_failures:
                logger.error(f"Error fetching data from {url}, exception: {e}")
                return None
            else:
                raise e
```

## Conclusion

The `ScrapflyScrapeWebsiteTool` provides a powerful way to extract content from websites using Scrapfly's advanced web scraping capabilities. With features like headless browser support, proxies, and anti-bot bypass, it can handle complex websites and extract content in various formats. This tool is particularly useful for data extraction, content monitoring, and research tasks where reliable web scraping is required.


# Selenium Scraper
Source: https://docs.crewai.com/en/tools/web-scraping/seleniumscrapingtool

The `SeleniumScrapingTool` is designed to extract and read the content of a specified website using Selenium.

# `SeleniumScrapingTool`

<Note>
  This tool is currently in development. As we refine its capabilities, users may encounter unexpected behavior.
  Your feedback is invaluable to us for making improvements.
</Note>

## Description

The `SeleniumScrapingTool` is crafted for high-efficiency web scraping tasks.
It allows for precise extraction of content from web pages by using CSS selectors to target specific elements.
Its design caters to a wide range of scraping needs, offering flexibility to work with any provided website URL.

## Installation

To use this tool, you need to install the CrewAI tools package and Selenium:

```shell
pip install 'crewai[tools]'
uv add selenium webdriver-manager
```

You'll also need to have Chrome installed on your system, as the tool uses Chrome WebDriver for browser automation.

## Example

The following example demonstrates how to use the `SeleniumScrapingTool` with a CrewAI agent:

```python Code
from crewai import Agent, Task, Crew, Process
from crewai_tools import SeleniumScrapingTool

# Initialize the tool
selenium_tool = SeleniumScrapingTool()

# Define an agent that uses the tool
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract information from websites using Selenium",
    backstory="An expert web scraper who can extract content from dynamic websites.",
    tools=[selenium_tool],
    verbose=True,
)

# Example task to scrape content from a website
scrape_task = Task(
    description="Extract the main content from the homepage of example.com. Use the CSS selector 'main' to target the main content area.",
    expected_output="The main content from example.com's homepage.",
    agent=web_scraper_agent,
)

# Create and run the crew
crew = Crew(
    agents=[web_scraper_agent],
    tasks=[scrape_task],
    verbose=True,
    process=Process.sequential,
)
result = crew.kickoff()
```

You can also initialize the tool with predefined parameters:

```python Code
# Initialize the tool with predefined parameters
selenium_tool = SeleniumScrapingTool(
    website_url='https://example.com',
    css_element='.main-content',
    wait_time=5
)

# Define an agent that uses the tool
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract information from websites using Selenium",
    backstory="An expert web scraper who can extract content from dynamic websites.",
    tools=[selenium_tool],
    verbose=True,
)
```

## Parameters

The `SeleniumScrapingTool` accepts the following parameters during initialization:

* **website\_url**: Optional. The URL of the website to scrape. If provided during initialization, the agent won't need to specify it when using the tool.
* **css\_element**: Optional. The CSS selector for the elements to extract. If provided during initialization, the agent won't need to specify it when using the tool.
* **cookie**: Optional. A dictionary containing cookie information, useful for simulating a logged-in session to access restricted content.
* **wait\_time**: Optional. Specifies the delay (in seconds) before scraping, allowing the website and any dynamic content to fully load. Default is `3` seconds.
* **return\_html**: Optional. Whether to return the HTML content instead of just the text. Default is `False`.

When using the tool with an agent, the agent will need to provide the following parameters (unless they were specified during initialization):

* **website\_url**: Required. The URL of the website to scrape.
* **css\_element**: Required. The CSS selector for the elements to extract.

## Agent Integration Example

Here's a more detailed example of how to integrate the `SeleniumScrapingTool` with a CrewAI agent:

```python Code
from crewai import Agent, Task, Crew, Process
from crewai_tools import SeleniumScrapingTool

# Initialize the tool
selenium_tool = SeleniumScrapingTool()

# Define an agent that uses the tool
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract and analyze information from dynamic websites",
    backstory="""You are an expert web scraper who specializes in extracting
    content from dynamic websites that require browser automation. You have
    extensive knowledge of CSS selectors and can identify the right selectors
    to target specific content on any website.""",
    tools=[selenium_tool],
    verbose=True,
)

# Create a task for the agent
scrape_task = Task(
    description="""
    Extract the following information from the news website at {website_url}:

    1. The headlines of all featured articles (CSS selector: '.headline')
    2. The publication dates of these articles (CSS selector: '.pub-date')
    3. The author names where available (CSS selector: '.author')

    Compile this information into a structured format with each article's details grouped together.
    """,
    expected_output="A structured list of articles with their headlines, publication dates, and authors.",
    agent=web_scraper_agent,
)

# Run the task
crew = Crew(
    agents=[web_scraper_agent],
    tasks=[scrape_task],
    verbose=True,
    process=Process.sequential,
)
result = crew.kickoff(inputs={"website_url": "https://news-example.com"})
```

## Implementation Details

The `SeleniumScrapingTool` uses Selenium WebDriver to automate browser interactions:

```python Code
class SeleniumScrapingTool(BaseTool):
    name: str = "Read a website content"
    description: str = "A tool that can be used to read a website content."
    args_schema: Type[BaseModel] = SeleniumScrapingToolSchema

    def _run(self, **kwargs: Any) -> Any:
        website_url = kwargs.get("website_url", self.website_url)
        css_element = kwargs.get("css_element", self.css_element)
        return_html = kwargs.get("return_html", self.return_html)
        driver = self._create_driver(website_url, self.cookie, self.wait_time)

        content = self._get_content(driver, css_element, return_html)
        driver.close()

        return "\n".join(content)
```

The tool performs the following steps:

1. Creates a headless Chrome browser instance
2. Navigates to the specified URL
3. Waits for the specified time to allow the page to load
4. Adds any cookies if provided
5. Extracts content based on the CSS selector
6. Returns the extracted content as text or HTML
7. Closes the browser instance

## Handling Dynamic Content

The `SeleniumScrapingTool` is particularly useful for scraping websites with dynamic content that is loaded via JavaScript. By using a real browser instance, it can:

1. Execute JavaScript on the page
2. Wait for dynamic content to load
3. Interact with elements if needed
4. Extract content that would not be available with simple HTTP requests

You can adjust the `wait_time` parameter to ensure that all dynamic content has loaded before extraction.

## Conclusion

The `SeleniumScrapingTool` provides a powerful way to extract content from websites using browser automation. By enabling agents to interact with websites as a real user would, it facilitates scraping of dynamic content that would be difficult or impossible to extract using simpler methods. This tool is particularly useful for research, data collection, and monitoring tasks that involve modern web applications with JavaScript-rendered content.


# Spider Scraper
Source: https://docs.crewai.com/en/tools/web-scraping/spidertool

The `SpiderTool` is designed to extract and read the content of a specified website using Spider.

# `SpiderTool`

## Description

[Spider](https://spider.cloud/?ref=crewai) is the [fastest](https://github.com/spider-rs/spider/blob/main/benches/BENCHMARKS.md#benchmark-results)
open source scraper and crawler that returns LLM-ready data.
It converts any website into pure HTML, markdown, metadata or text while enabling you to crawl with custom actions using AI.

## Installation

To use the `SpiderTool` you need to download the [Spider SDK](https://pypi.org/project/spider-client/)
and the `crewai[tools]` SDK too:

```shell
pip install spider-client 'crewai[tools]'
```

## Example

This example shows you how you can use the `SpiderTool` to enable your agent to scrape and crawl websites.
The data returned from the Spider API is already LLM-ready, so no need to do any cleaning there.

```python Code
from crewai_tools import SpiderTool

def main():
    spider_tool = SpiderTool()

    searcher = Agent(
        role="Web Research Expert",
        goal="Find related information from specific URL's",
        backstory="An expert web researcher that uses the web extremely well",
        tools=[spider_tool],
        verbose=True,
    )

    return_metadata = Task(
        description="Scrape https://spider.cloud with a limit of 1 and enable metadata",
        expected_output="Metadata and 10 word summary of spider.cloud",
        agent=searcher
    )

    crew = Crew(
        agents=[searcher],
        tasks=[
            return_metadata,
        ],
        verbose=2
    )

    crew.kickoff()

if __name__ == "__main__":
    main()
```

## Arguments

| Argument                | Type     | Description                                                                                                                       |
| :---------------------- | :------- | :-------------------------------------------------------------------------------------------------------------------------------- |
| **api\_key**            | `string` | Specifies Spider API key. If not specified, it looks for `SPIDER_API_KEY` in environment variables.                               |
| **params**              | `object` | Optional parameters for the request. Defaults to `{"return_format": "markdown"}` to optimize content for LLMs.                    |
| **request**             | `string` | Type of request to perform (`http`, `chrome`, `smart`). `smart` defaults to HTTP, switching to JavaScript rendering if needed.    |
| **limit**               | `int`    | Max pages to crawl per website. Set to `0` or omit for unlimited.                                                                 |
| **depth**               | `int`    | Max crawl depth. Set to `0` for no limit.                                                                                         |
| **cache**               | `bool`   | Enables HTTP caching to speed up repeated runs. Default is `true`.                                                                |
| **budget**              | `object` | Sets path-based limits for crawled pages, e.g., `{"*":1}` for root page only.                                                     |
| **locale**              | `string` | Locale for the request, e.g., `en-US`.                                                                                            |
| **cookies**             | `string` | HTTP cookies for the request.                                                                                                     |
| **stealth**             | `bool`   | Enables stealth mode for Chrome requests to avoid detection. Default is `true`.                                                   |
| **headers**             | `object` | HTTP headers as a map of key-value pairs for all requests.                                                                        |
| **metadata**            | `bool`   | Stores metadata about pages and content, aiding AI interoperability. Defaults to `false`.                                         |
| **viewport**            | `object` | Sets Chrome viewport dimensions. Default is `800x600`.                                                                            |
| **encoding**            | `string` | Specifies encoding type, e.g., `UTF-8`, `SHIFT_JIS`.                                                                              |
| **subdomains**          | `bool`   | Includes subdomains in the crawl. Default is `false`.                                                                             |
| **user\_agent**         | `string` | Custom HTTP user agent. Defaults to a random agent.                                                                               |
| **store\_data**         | `bool`   | Enables data storage for the request. Overrides `storageless` when set. Default is `false`.                                       |
| **gpt\_config**         | `object` | Allows AI to generate crawl actions, with optional chaining steps via an array for `"prompt"`.                                    |
| **fingerprint**         | `bool`   | Enables advanced fingerprinting for Chrome.                                                                                       |
| **storageless**         | `bool`   | Prevents all data storage, including AI embeddings. Default is `false`.                                                           |
| **readability**         | `bool`   | Pre-processes content for reading via [Mozilla’s readability](https://github.com/mozilla/readability). Improves content for LLMs. |
| **return\_format**      | `string` | Format to return data: `markdown`, `raw`, `text`, `html2text`. Use `raw` for default page format.                                 |
| **proxy\_enabled**      | `bool`   | Enables high-performance proxies to avoid network-level blocking.                                                                 |
| **query\_selector**     | `string` | CSS query selector for content extraction from markup.                                                                            |
| **full\_resources**     | `bool`   | Downloads all resources linked to the website.                                                                                    |
| **request\_timeout**    | `int`    | Timeout in seconds for requests (5-60). Default is `30`.                                                                          |
| **run\_in\_background** | `bool`   | Runs the request in the background, useful for data storage and triggering dashboard crawls. No effect if `storageless` is set.   |


# Stagehand Tool
Source: https://docs.crewai.com/en/tools/web-scraping/stagehandtool

Web automation tool that integrates Stagehand with CrewAI for browser interaction and automation

# Overview

The `StagehandTool` integrates the [Stagehand](https://docs.stagehand.dev/get_started/introduction) framework with CrewAI, enabling agents to interact with websites and automate browser tasks using natural language instructions.

## Overview

Stagehand is a powerful browser automation framework built by Browserbase that allows AI agents to:

* Navigate to websites
* Click buttons, links, and other elements
* Fill in forms
* Extract data from web pages
* Observe and identify elements
* Perform complex workflows

The StagehandTool wraps the Stagehand Python SDK to provide CrewAI agents with browser control capabilities through three core primitives:

1. **Act**: Perform actions like clicking, typing, or navigating
2. **Extract**: Extract structured data from web pages
3. **Observe**: Identify and analyze elements on the page

## Prerequisites

Before using this tool, ensure you have:

1. A [Browserbase](https://www.browserbase.com/) account with API key and project ID
2. An API key for an LLM (OpenAI or Anthropic Claude)
3. The Stagehand Python SDK installed

Install the required dependency:

```bash
pip install stagehand-py
```

## Usage

### Basic Implementation

The StagehandTool can be implemented in two ways:

#### 1. Using Context Manager (Recommended)

<Tip>
  The context manager approach is recommended as it ensures proper cleanup of resources even if exceptions occur.
</Tip>

```python
from crewai import Agent, Task, Crew
from crewai_tools import StagehandTool
from stagehand.schemas import AvailableModel

# Initialize the tool with your API keys using a context manager
with StagehandTool(
    api_key="your-browserbase-api-key",
    project_id="your-browserbase-project-id",
    model_api_key="your-llm-api-key",  # OpenAI or Anthropic API key
    model_name=AvailableModel.CLAUDE_3_7_SONNET_LATEST,  # Optional: specify which model to use
) as stagehand_tool:
    # Create an agent with the tool
    researcher = Agent(
        role="Web Researcher",
        goal="Find and summarize information from websites",
        backstory="I'm an expert at finding information online.",
        verbose=True,
        tools=[stagehand_tool],
    )

    # Create a task that uses the tool
    research_task = Task(
        description="Go to https://www.example.com and tell me what you see on the homepage.",
        agent=researcher,
    )

    # Run the crew
    crew = Crew(
        agents=[researcher],
        tasks=[research_task],
        verbose=True,
    )

    result = crew.kickoff()
    print(result)
```

#### 2. Manual Resource Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import StagehandTool
from stagehand.schemas import AvailableModel

# Initialize the tool with your API keys
stagehand_tool = StagehandTool(
    api_key="your-browserbase-api-key",
    project_id="your-browserbase-project-id",
    model_api_key="your-llm-api-key",
    model_name=AvailableModel.CLAUDE_3_7_SONNET_LATEST,
)

try:
    # Create an agent with the tool
    researcher = Agent(
        role="Web Researcher",
        goal="Find and summarize information from websites",
        backstory="I'm an expert at finding information online.",
        verbose=True,
        tools=[stagehand_tool],
    )

    # Create a task that uses the tool
    research_task = Task(
        description="Go to https://www.example.com and tell me what you see on the homepage.",
        agent=researcher,
    )

    # Run the crew
    crew = Crew(
        agents=[researcher],
        tasks=[research_task],
        verbose=True,
    )

    result = crew.kickoff()
    print(result)
finally:
    # Explicitly clean up resources
    stagehand_tool.close()
```

## Command Types

The StagehandTool supports three different command types for specific web automation tasks:

### 1. Act Command

The `act` command type (default) enables webpage interactions like clicking buttons, filling forms, and navigation.

```python
# Perform an action (default behavior)
result = stagehand_tool.run(
    instruction="Click the login button",
    url="https://example.com",
    command_type="act"  # Default, so can be omitted
)

# Fill out a form
result = stagehand_tool.run(
    instruction="Fill the contact form with name 'John Doe', email 'john@example.com', and message 'Hello world'",
    url="https://example.com/contact"
)
```

### 2. Extract Command

The `extract` command type retrieves structured data from webpages.

```python
# Extract all product information
result = stagehand_tool.run(
    instruction="Extract all product names, prices, and descriptions",
    url="https://example.com/products",
    command_type="extract"
)

# Extract specific information with a selector
result = stagehand_tool.run(
    instruction="Extract the main article title and content",
    url="https://example.com/blog/article",
    command_type="extract",
    selector=".article-container"  # Optional CSS selector
)
```

### 3. Observe Command

The `observe` command type identifies and analyzes webpage elements.

```python
# Find interactive elements
result = stagehand_tool.run(
    instruction="Find all interactive elements in the navigation menu",
    url="https://example.com",
    command_type="observe"
)

# Identify form fields
result = stagehand_tool.run(
    instruction="Identify all the input fields in the registration form",
    url="https://example.com/register",
    command_type="observe",
    selector="#registration-form"
)
```

## Configuration Options

Customize the StagehandTool behavior with these parameters:

```python
stagehand_tool = StagehandTool(
    api_key="your-browserbase-api-key",
    project_id="your-browserbase-project-id",
    model_api_key="your-llm-api-key",
    model_name=AvailableModel.CLAUDE_3_7_SONNET_LATEST,
    dom_settle_timeout_ms=5000,  # Wait longer for DOM to settle
    headless=True,  # Run browser in headless mode
    self_heal=True,  # Attempt to recover from errors
    wait_for_captcha_solves=True,  # Wait for CAPTCHA solving
    verbose=1,  # Control logging verbosity (0-3)
)
```

## Best Practices

1. **Be Specific**: Provide detailed instructions for better results
2. **Choose Appropriate Command Type**: Select the right command type for your task
3. **Use Selectors**: Leverage CSS selectors to improve accuracy
4. **Break Down Complex Tasks**: Split complex workflows into multiple tool calls
5. **Implement Error Handling**: Add error handling for potential issues

## Troubleshooting

Common issues and solutions:

* **Session Issues**: Verify API keys for both Browserbase and LLM provider
* **Element Not Found**: Increase `dom_settle_timeout_ms` for slower pages
* **Action Failures**: Use `observe` to identify correct elements first
* **Incomplete Data**: Refine instructions or provide specific selectors

## Additional Resources

For questions about the CrewAI integration:

* Join Stagehand's [Slack community](https://stagehand.dev/slack)
* Open an issue in the [Stagehand repository](https://github.com/browserbase/stagehand)
* Visit [Stagehand documentation](https://docs.stagehand.dev/)


# Introdução
Source: https://docs.crewai.com/pt-BR/api-reference/introduction

Referência completa para a API REST do CrewAI Enterprise

# CrewAI Enterprise API

Bem-vindo à referência da API do CrewAI Enterprise. Esta API permite que você interaja programaticamente com seus crews implantados, possibilitando a integração com seus aplicativos, fluxos de trabalho e serviços.

## Início Rápido

<Steps>
  <Step title="Obtenha suas credenciais de API">
    Navegue até a página de detalhes do seu crew no painel do CrewAI Enterprise e copie seu Bearer Token na aba Status.
  </Step>

  <Step title="Descubra os Inputs Necessários">
    Use o endpoint `GET /inputs` para ver quais parâmetros seu crew espera.
  </Step>

  <Step title="Inicie uma Execução de Crew">
    Chame `POST /kickoff` com seus inputs para iniciar a execução do crew e receber um `kickoff_id`.
  </Step>

  <Step title="Monitore o Progresso">
    Use `GET /status/{kickoff_id}` para checar o status da execução e recuperar os resultados.
  </Step>
</Steps>

## Autenticação

Todas as requisições à API exigem autenticação usando um Bearer token. Inclua seu token no header `Authorization`:

```bash
curl -H "Authorization: Bearer YOUR_CREW_TOKEN" \
  https://your-crew-url.crewai.com/inputs
```

### Tipos de Token

| Tipo de Token         | Escopo                         | Caso de Uso                                                          |
| :-------------------- | :----------------------------- | :------------------------------------------------------------------- |
| **Bearer Token**      | Acesso em nível de organização | Operações completas de crew, ideal para integração server-to-server  |
| **User Bearer Token** | Acesso com escopo de usuário   | Permissões limitadas, adequado para operações específicas de usuário |

<Tip>
  Você pode encontrar ambos os tipos de token na aba Status da página de detalhes do seu crew no painel do CrewAI Enterprise.
</Tip>

## URL Base

Cada crew implantado possui um endpoint de API único:

```
https://your-crew-name.crewai.com
```

Substitua `your-crew-name` pela URL real do seu crew no painel.

## Fluxo Típico

1. **Descoberta**: Chame `GET /inputs` para entender o que seu crew precisa
2. **Execução**: Envie os inputs via `POST /kickoff` para iniciar o processamento
3. **Monitoramento**: Faça polling em `GET /status/{kickoff_id}` até a conclusão
4. **Resultados**: Extraia o output final da resposta concluída

## Tratamento de Erros

A API utiliza códigos de status HTTP padrão:

| Código | Significado                                      |
| ------ | :----------------------------------------------- |
| `200`  | Sucesso                                          |
| `400`  | Requisição Inválida - Formato de input inválido  |
| `401`  | Não Autorizado - Bearer token inválido           |
| `404`  | Não Encontrado - Recurso não existe              |
| `422`  | Erro de Validação - Inputs obrigatórios ausentes |
| `500`  | Erro no Servidor - Contate o suporte             |

## Testes Interativos

<Info>
  **Por que não há botão "Enviar"?** Como cada usuário do CrewAI Enterprise possui sua própria URL de crew, utilizamos o **modo referência** em vez de um playground interativo para evitar confusão. Isso mostra exatamente como as requisições devem ser feitas, sem botões de envio não funcionais.
</Info>

Cada página de endpoint mostra para você:

* ✅ **Formato exato da requisição** com todos os parâmetros
* ✅ **Exemplos de resposta** para casos de sucesso e erro
* ✅ **Exemplos de código** em várias linguagens (cURL, Python, JavaScript, etc.)
* ✅ **Exemplos de autenticação** com o formato adequado de Bearer token

### **Para testar sua API de verdade:**

<CardGroup cols={2}>
  <Card title="Copie Exemplos cURL" icon="terminal">
    Copie os exemplos cURL e substitua a URL + token por seus valores reais
  </Card>

  <Card title="Use Postman/Insomnia" icon="play">
    Importe os exemplos na sua ferramenta de testes de API preferida
  </Card>
</CardGroup>

**Exemplo de fluxo:**

1. **Copie este exemplo cURL** de qualquer página de endpoint
2. **Substitua `your-actual-crew-name.crewai.com`** pela URL real do seu crew
3. **Substitua o Bearer token** pelo seu token real do painel
4. **Execute a requisição** no seu terminal ou cliente de API

## Precisa de Ajuda?

<CardGroup cols={2}>
  <Card title="Suporte Enterprise" icon="headset" href="mailto:support@crewai.com">
    Obtenha ajuda com integração da API e resolução de problemas
  </Card>

  <Card title="Painel Enterprise" icon="chart-line" href="https://app.crewai.com">
    Gerencie seus crews e visualize logs de execução
  </Card>
</CardGroup>


# Agentes
Source: https://docs.crewai.com/pt-BR/concepts/agents

Guia detalhado sobre como criar e gerenciar agentes no framework CrewAI.

## Visão Geral de um Agente

No framework CrewAI, um `Agent` é uma unidade autônoma que pode:

* Executar tarefas específicas
* Tomar decisões com base em seu papel e objetivo
* Utilizar ferramentas para alcançar objetivos
* Comunicar e colaborar com outros agentes
* Manter a memória de interações
* Delegar tarefas, quando permitido

<Tip>
  Pense em um agente como um membro especializado da equipe com habilidades, competências e responsabilidades específicas. Por exemplo, um agente `Researcher` pode ser excelente em coletar e analisar informações, enquanto um agente `Writer` pode ser melhor na criação de conteúdo.
</Tip>

<Note type="info" title="Aprimoramento Empresarial: Construtor Visual de Agentes">
  O CrewAI Enterprise inclui um Construtor Visual de Agentes, que simplifica a criação e configuração de agentes sem escrever código. Projete seus agentes visualmente e teste-os em tempo real.

  ![Visual Agent Builder Screenshot](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-studio-interface.png)

  O Construtor Visual de Agentes permite:

  * Configuração intuitiva de agentes com interfaces baseadas em formulários
  * Testes e validação em tempo real
  * Biblioteca de modelos com tipos de agentes pré-configurados
  * Fácil personalização de atributos e comportamentos do agente
</Note>

## Atributos do Agente

| Atributo                                | Parâmetro                | Tipo                                  | Descrição                                                                                                 |
| :-------------------------------------- | :----------------------- | :------------------------------------ | :-------------------------------------------------------------------------------------------------------- |
| **Role (Função)**                       | `role`                   | `str`                                 | Define a função e a área de especialização do agente dentro da equipe.                                    |
| **Goal (Objetivo)**                     | `goal`                   | `str`                                 | O objetivo individual que guia a tomada de decisão do agente.                                             |
| **Backstory (História de fundo)**       | `backstory`              | `str`                                 | Fornece contexto e personalidade ao agente, enriquecendo as interações.                                   |
| **LLM** *(opcional)*                    | `llm`                    | `Union[str, LLM, Any]`                | Modelo de linguagem que alimenta o agente. Padrão: modelo especificado em `OPENAI_MODEL_NAME` ou "gpt-4". |
| **Tools (Ferramentas)** *(opcional)*    | `tools`                  | `List[BaseTool]`                      | Capacidades ou funções disponíveis para o agente. Padrão: lista vazia.                                    |
| **Function Calling LLM** *(opcional)*   | `function_calling_llm`   | `Optional[Any]`                       | Modelo de linguagem usado para chamada de ferramentas, sobrescreve LLM principal se especificado.         |
| **Max Iterations** *(opcional)*         | `max_iter`               | `int`                                 | Número máximo de iterações antes do agente fornecer sua melhor resposta. Padrão: 20.                      |
| **Max RPM** *(opcional)*                | `max_rpm`                | `Optional[int]`                       | Quantidade máxima de requisições por minuto para evitar limites de taxa.                                  |
| **Max Execution Time** *(opcional)*     | `max_execution_time`     | `Optional[int]`                       | Tempo máximo (em segundos) de execução da tarefa.                                                         |
| **Verbose** *(opcional)*                | `verbose`                | `bool`                                | Habilita logs detalhados de execução para depuração. Padrão: False.                                       |
| **Allow Delegation** *(opcional)*       | `allow_delegation`       | `bool`                                | Permite que o agente delegue tarefas para outros agentes. Padrão: False.                                  |
| **Step Callback** *(opcional)*          | `step_callback`          | `Optional[Any]`                       | Função chamada após cada passo do agente, sobrescreve callback da equipe.                                 |
| **Cache** *(opcional)*                  | `cache`                  | `bool`                                | Ativa cache para o uso de ferramentas. Padrão: True.                                                      |
| **System Template** *(opcional)*        | `system_template`        | `Optional[str]`                       | Template personalizado de prompt de sistema para o agente.                                                |
| **Prompt Template** *(opcional)*        | `prompt_template`        | `Optional[str]`                       | Template de prompt personalizado para o agente.                                                           |
| **Response Template** *(opcional)*      | `response_template`      | `Optional[str]`                       | Template de resposta personalizado para o agente.                                                         |
| **Allow Code Execution** *(opcional)*   | `allow_code_execution`   | `Optional[bool]`                      | Ativa execução de código pelo agente. Padrão: False.                                                      |
| **Max Retry Limit** *(opcional)*        | `max_retry_limit`        | `int`                                 | Número máximo de tentativas (retries) em caso de erro. Padrão: 2.                                         |
| **Respect Context Window** *(opcional)* | `respect_context_window` | `bool`                                | Mantém as mensagens dentro do tamanho da janela de contexto, resumindo quando necessário. Padrão: True.   |
| **Code Execution Mode** *(opcional)*    | `code_execution_mode`    | `Literal["safe", "unsafe"]`           | Modo de execução de código: 'safe' (usando Docker) ou 'unsafe' (direto). Padrão: 'safe'.                  |
| **Multimodal** *(opcional)*             | `multimodal`             | `bool`                                | Se o agente suporta capacidades multimodais. Padrão: False.                                               |
| **Inject Date** *(opcional)*            | `inject_date`            | `bool`                                | Se deve injetar automaticamente a data atual nas tarefas. Padrão: False.                                  |
| **Date Format** *(opcional)*            | `date_format`            | `str`                                 | Formato de data utilizado quando `inject_date` está ativo. Padrão: "%Y-%m-%d" (formato ISO).              |
| **Reasoning** *(opcional)*              | `reasoning`              | `bool`                                | Se o agente deve refletir e criar um plano antes de executar uma tarefa. Padrão: False.                   |
| **Max Reasoning Attempts** *(opcional)* | `max_reasoning_attempts` | `Optional[int]`                       | Número máximo de tentativas de raciocínio antes de executar a tarefa. Se None, tentará até estar pronto.  |
| **Embedder** *(opcional)*               | `embedder`               | `Optional[Dict[str, Any]]`            | Configuração do embedder utilizado pelo agente.                                                           |
| **Knowledge Sources** *(opcional)*      | `knowledge_sources`      | `Optional[List[BaseKnowledgeSource]]` | Fontes de conhecimento disponíveis para o agente.                                                         |
| **Use System Prompt** *(opcional)*      | `use_system_prompt`      | `Optional[bool]`                      | Se deve usar o system prompt (suporte para modelo o1). Padrão: True.                                      |

## Criando Agentes

Existem duas maneiras de criar agentes no CrewAI: usando **configuração YAML (recomendado)** ou definindo-os **diretamente em código**.

### Configuração em YAML (Recomendado)

Usar configuração em YAML proporciona uma maneira mais limpa e fácil de manter para definir agentes. Recomendamos fortemente esse método em seus projetos CrewAI.

Depois de criar seu projeto CrewAI conforme descrito na seção de [Instalação](/pt-BR/installation), navegue até o arquivo `src/latest_ai_development/config/agents.yaml` e edite o template para atender aos seus requisitos.

<Note>
  Variáveis em seus arquivos YAML (como `{topic}`) serão substituídas pelos valores fornecidos em seus inputs ao executar o crew:

  ```python Code
  crew.kickoff(inputs={'topic': 'AI Agents'})
  ```
</Note>

Veja um exemplo de como configurar agentes usando YAML:

```yaml agents.yaml
# src/latest_ai_development/config/agents.yaml
researcher:
  role: >
    {topic} Senior Data Researcher
  goal: >
    Uncover cutting-edge developments in {topic}
  backstory: >
    You're a seasoned researcher with a knack for uncovering the latest
    developments in {topic}. Known for your ability to find the most relevant
    information and present it in a clear and concise manner.

reporting_analyst:
  role: >
    {topic} Reporting Analyst
  goal: >
    Create detailed reports based on {topic} data analysis and research findings
  backstory: >
    You're a meticulous analyst with a keen eye for detail. You're known for
    your ability to turn complex data into clear and concise reports, making
    it easy for others to understand and act on the information you provide.
```

Para usar essa configuração YAML no seu código, crie uma classe de crew que herda de `CrewBase`:

```python Code
# src/latest_ai_development/crew.py
from crewai import Agent, Crew, Process
from crewai.project import CrewBase, agent, crew
from crewai_tools import SerperDevTool

@CrewBase
class LatestAiDevelopmentCrew():
  """LatestAiDevelopment crew"""

  agents_config = "config/agents.yaml"

  @agent
  def researcher(self) -> Agent:
    return Agent(
      config=self.agents_config['researcher'], # type: ignore[index]
      verbose=True,
      tools=[SerperDevTool()]
    )

  @agent
  def reporting_analyst(self) -> Agent:
    return Agent(
      config=self.agents_config['reporting_analyst'], # type: ignore[index]
      verbose=True
    )
```

<Note>
  Os nomes utilizados em seus arquivos YAML (`agents.yaml`) devem ser iguais aos nomes dos métodos no seu código Python.
</Note>

### Definição Direta em Código

Você pode criar agentes diretamente em código instanciando a classe `Agent`. Veja um exemplo abrangente mostrando todos os parâmetros disponíveis:

```python Code
from crewai import Agent
from crewai_tools import SerperDevTool

# Crie um agente com todos os parâmetros disponíveis
agent = Agent(
    role="Cientista de Dados Sênior",
    goal="Analisar e interpretar conjuntos de dados complexos para fornecer insights acionáveis",
    backstory="Com mais de 10 anos de experiência em ciência de dados e aprendizado de máquina, você é especialista em encontrar padrões em grandes volumes de dados.",
    llm="gpt-4",  # Padrão: OPENAI_MODEL_NAME ou "gpt-4"
    function_calling_llm=None,  # Opcional: LLM separado para chamadas de ferramentas
    verbose=False,  # Padrão: False
    allow_delegation=False,  # Padrão: False
    max_iter=20,  # Padrão: 20 iterações
    max_rpm=None,  # Opcional: Limite de requisições por minuto
    max_execution_time=None,  # Opcional: Tempo máximo de execução em segundos
    max_retry_limit=2,  # Padrão: 2 tentativas em caso de erro
    allow_code_execution=False,  # Padrão: False
    code_execution_mode="safe",  # Padrão: "safe" (opções: "safe", "unsafe")
    respect_context_window=True,  # Padrão: True
    use_system_prompt=True,  # Padrão: True
    multimodal=False,  # Padrão: False
    inject_date=False,  # Padrão: False
    date_format="%Y-%m-%d",  # Padrão: formato ISO
    reasoning=False,  # Padrão: False
    max_reasoning_attempts=None,  # Padrão: None
    tools=[SerperDevTool()],  # Opcional: Lista de ferramentas
    knowledge_sources=None,  # Opcional: Lista de fontes de conhecimento
    embedder=None,  # Opcional: Configuração de embedder customizado
    system_template=None,  # Opcional: Template de prompt de sistema
    prompt_template=None,  # Opcional: Template de prompt customizado
    response_template=None,  # Opcional: Template de resposta customizado
    step_callback=None,  # Opcional: Função de callback para monitoramento
)
```

Vamos detalhar algumas combinações de parâmetros-chave para casos de uso comuns:

#### Agente de Pesquisa Básico

```python Code
research_agent = Agent(
    role="Analista de Pesquisa",
    goal="Encontrar e resumir informações sobre tópicos específicos",
    backstory="Você é um pesquisador experiente com atenção aos detalhes",
    tools=[SerperDevTool()],
    verbose=True  # Ativa logs para depuração
)
```

#### Agente de Desenvolvimento de Código

```python Code
dev_agent = Agent(
    role="Desenvolvedor Python Sênior",
    goal="Escrever e depurar códigos Python",
    backstory="Desenvolvedor Python especialista com 10 anos de experiência",
    allow_code_execution=True,
    code_execution_mode="safe",  # Usa Docker para segurança
    max_execution_time=300,  # Limite de 5 minutos
    max_retry_limit=3  # Mais tentativas para tarefas complexas
)
```

#### Agente de Análise de Longa Duração

```python Code
analysis_agent = Agent(
    role="Analista de Dados",
    goal="Realizar análise aprofundada de grandes conjuntos de dados",
    backstory="Especialista em análise de big data e reconhecimento de padrões",
    memory=True,
    respect_context_window=True,
    max_rpm=10,  # Limite de requisições por minuto
    function_calling_llm="gpt-4o-mini"  # Modelo mais econômico para chamadas de ferramentas
)
```

#### Agente com Template Personalizado

```python Code
custom_agent = Agent(
    role="Atendente de Suporte ao Cliente",
    goal="Auxiliar clientes com suas dúvidas e solicitações",
    backstory="Experiente em atendimento ao cliente com foco em satisfação",
    system_template="""<|start_header_id|>system<|end_header_id|>\n                        {{ .System }}<|eot_id|>""",
    prompt_template="""<|start_header_id|>user<|end_header_id|>\n                        {{ .Prompt }}<|eot_id|>""",
    response_template="""<|start_header_id|>assistant<|end_header_id|>\n                        {{ .Response }}<|eot_id|>""",
)
```

#### Agente Ciente de Data, com Raciocínio

```python Code
strategic_agent = Agent(
    role="Analista de Mercado",
    goal="Acompanhar movimentos do mercado com referências de datas precisas e planejamento estratégico",
    backstory="Especialista em análise financeira sensível ao tempo e relatórios estratégicos",
    inject_date=True,  # Injeta automaticamente a data atual nas tarefas
    date_format="%d de %B de %Y",  # Exemplo: "21 de maio de 2025"
    reasoning=True,  # Ativa planejamento estratégico
    max_reasoning_attempts=2,  # Limite de iterações de planejamento
    verbose=True
)
```

#### Agente de Raciocínio

```python Code
reasoning_agent = Agent(
    role="Planejador Estratégico",
    goal="Analisar problemas complexos e criar planos de execução detalhados",
    backstory="Especialista em planejamento estratégico que desmembra desafios complexos metodicamente",
    reasoning=True,  # Ativa raciocínio e planejamento
    max_reasoning_attempts=3,  # Limite de tentativas de raciocínio
    max_iter=30,  # Permite mais iterações para planejamento complexo
    verbose=True
)
```

#### Agente Multimodal

```python Code
multimodal_agent = Agent(
    role="Analista de Conteúdo Visual",
    goal="Analisar e processar tanto conteúdo textual quanto visual",
    backstory="Especialista em análise multimodal combinando compreensão de texto e imagem",
    multimodal=True,  # Ativa capacidades multimodais
    verbose=True
)
```

### Detalhes dos Parâmetros

#### Parâmetros Críticos

* `role`, `goal` e `backstory` são obrigatórios e definem o comportamento do agente
* `llm` determina o modelo de linguagem utilizado (padrão: GPT-4 da OpenAI)

#### Memória e Contexto

* `memory`: Ative para manter o histórico de conversas
* `respect_context_window`: Evita problemas com limites de tokens
* `knowledge_sources`: Adicione bases de conhecimento específicas do domínio

#### Controle de Execução

* `max_iter`: Número máximo de tentativas antes da melhor resposta
* `max_execution_time`: Tempo limite em segundos
* `max_rpm`: Limite de requisições por minuto
* `max_retry_limit`: Tentativas de correção em erros

#### Execução de Código

* `allow_code_execution`: Deve ser True para permitir execução de código
* `code_execution_mode`:
  * `"safe"`: Usa Docker (recomendado para produção)
  * `"unsafe"`: Execução direta (apenas em ambientes confiáveis)

<Note>
  Isso executa uma imagem Docker padrão. Se você deseja configurar a imagem Docker, veja a ferramenta Code Interpreter na seção de ferramentas.
  Adicione a ferramenta de interpretação de código como um parâmetro em ferramentas no agente.
</Note>

#### Funcionalidades Avançadas

* `multimodal`: Habilita capacidades multimodais para processar texto e conteúdo visual
* `reasoning`: Permite que o agente reflita e crie planos antes de executar tarefas
* `inject_date`: Injeta a data atual automaticamente nas descrições das tarefas

#### Templates

* `system_template`: Define o comportamento central do agente
* `prompt_template`: Estrutura o formato da entrada
* `response_template`: Formata as respostas do agente

<Note>
  Ao usar templates personalizados, assegure-se de definir tanto `system_template` quanto `prompt_template`. O `response_template` é opcional, mas recomendado para formatação consistente de saída.
</Note>

<Note>
  Ao usar templates personalizados, você pode usar variáveis como `{role}`, `{goal}` e `{backstory}` em seus templates. Elas serão automaticamente preenchidas durante a execução.
</Note>

## Ferramentas do Agente

Agentes podem ser equipados com diversas ferramentas para ampliar suas capacidades. O CrewAI suporta ferramentas do:

* [CrewAI Toolkit](https://github.com/joaomdmoura/crewai-tools)
* [LangChain Tools](https://python.langchain.com/docs/integrations/tools)

Veja como adicionar ferramentas a um agente:

```python Code
from crewai import Agent
from crewai_tools import SerperDevTool, WikipediaTools

# Criar ferramentas
search_tool = SerperDevTool()
wiki_tool = WikipediaTools()

# Adicionar ferramentas ao agente
researcher = Agent(
    role="Pesquisador de Tecnologia em IA",
    goal="Pesquisar os últimos avanços em IA",
    tools=[search_tool, wiki_tool],
    verbose=True
)
```

## Memória e Contexto do Agente

Agentes podem manter a memória de suas interações e usar contexto de tarefas anteriores. Isto é especialmente útil para fluxos de trabalho complexos onde é necessário reter informações ao longo de várias tarefas.

```python Code
from crewai import Agent

analyst = Agent(
    role="Analista de Dados",
    goal="Analisar e memorizar padrões complexos de dados",
    memory=True,  # Ativa memória
    verbose=True
)
```

<Note>
  Quando `memory` está ativo, o agente manterá o contexto ao longo de múltiplas interações, melhorando a capacidade de lidar com tarefas complexas, em múltiplos passos.
</Note>

## Gerenciamento da Janela de Contexto

O CrewAI inclui um gerenciamento automático sofisticado de janela de contexto para lidar com situações onde as conversas excedem o limite de tokens do modelo de linguagem. Esse poderoso recurso é controlado pelo parâmetro `respect_context_window`.

### Como Funciona o Gerenciamento de Janela de Contexto

Quando o histórico de conversas de um agente se torna muito grande para a janela de contexto do LLM, o CrewAI detecta essa situação automaticamente e pode:

1. **Resumir o conteúdo automaticamente** (com `respect_context_window=True`)
2. **Parar a execução com erro** (com `respect_context_window=False`)

### Manipulação Automática de Contexto (`respect_context_window=True`)

Esta é a **configuração padrão e recomendada** para a maioria dos casos. Quando ativada, CrewAI irá:

```python Code
# Agente com gerenciamento automático de contexto (padrão)
smart_agent = Agent(
    role="Analista de Pesquisa",
    goal="Analisar grandes documentos e conjuntos de dados",
    backstory="Especialista em processar informações extensas",
    respect_context_window=True,  # 🔑 Padrão: gerencia limites de contexto automaticamente
    verbose=True
)
```

**O que acontece quando os limites de contexto são excedidos:**

* ⚠️ **Mensagem de aviso**: `"Context length exceeded. Summarizing content to fit the model context window."`
* 🔄 **Resumir automaticamente**: O CrewAI resume o histórico da conversa de forma inteligente
* ✅ **Execução contínua**: A execução da tarefa prossegue normalmente com o contexto resumido
* 📝 **Informação preservada**: Informações-chave são mantidas enquanto reduz a contagem de tokens

### Limites Estritos de Contexto (`respect_context_window=False`)

Quando você precisa de controle total e prefere que a execução pare a perder qualquer informação:

```python Code
# Agente com limites estritos de contexto
strict_agent = Agent(
    role="Legal Document Reviewer",
    goal="Provide precise legal analysis without information loss",
    backstory="Legal expert requiring complete context for accurate analysis",
    respect_context_window=False,  # ❌ Stop execution on context limit
    verbose=True
)
```

**O que acontece quando os limites de contexto são excedidos:**

* ❌ **Mensagem de erro**: `"Context length exceeded. Consider using smaller text or RAG tools from crewai_tools."`
* 🛑 **Execução interrompida**: A execução da tarefa é parada imediatamente
* 🔧 **Intervenção manual necessária**: Você precisará modificar sua abordagem

### Como Escolher a Melhor Configuração

#### Use `respect_context_window=True` (padrão) quando:

* **Processar documentos grandes** que podem ultrapassar os limites de contexto
* **Conversas longas** onde certo grau de resumo é aceitável
* **Tarefas de pesquisa** onde o contexto geral é mais importante que detalhes exatos
* **Prototipagem e desenvolvimento** quando se deseja execução robusta

```python Code
# Ideal para processamento de documentos
document_processor = Agent(
    role="Document Analyst",
    goal="Extract insights from large research papers",
    backstory="Expert at analyzing extensive documentation",
    respect_context_window=True,  # Lida com documentos grandes sem problemas
    max_iter=50,  # Permite mais iterações para análises complexas
    verbose=True
)
```

#### Use `respect_context_window=False` quando:

* **Precisão é crítica** e perda de informação é inaceitável
* **Tarefas jurídicas ou médicas** que requerem contexto completo
* **Revisão de código** onde detalhes perdidos podem causar bugs
* **Análise financeira** onde precisão é fundamental

```python Code
# Ideal para tarefas de precisão
precision_agent = Agent(
    role="Code Security Auditor",
    goal="Identify security vulnerabilities in code",
    backstory="Security expert requiring complete code context",
    respect_context_window=False,  # Prefere falhar do que análise incompleta
    max_retry_limit=1,  # Falha rápida em caso de problemas de contexto
    verbose=True
)
```

### Abordagens Alternativas para Grandes Volumes de Dados

Ao lidar com conjuntos de dados muito grandes, considere as seguintes estratégias:

#### 1. Use Ferramentas RAG

```python Code
from crewai_tools import RagTool

# Crie uma ferramenta RAG para processamento de documentos grandes
rag_tool = RagTool()

rag_agent = Agent(
    role="Research Assistant",
    goal="Query large knowledge bases efficiently",
    backstory="Expert at using RAG tools for information retrieval",
    tools=[rag_tool],  # Usar RAG ao invés de grandes janelas de contexto
    respect_context_window=True,
    verbose=True
)
```

#### 2. Use Fontes de Conhecimento

```python Code
# Use fontes de conhecimento ao invés de prompts grandes
knowledge_agent = Agent(
    role="Knowledge Expert",
    goal="Answer questions using curated knowledge",
    backstory="Expert at leveraging structured knowledge sources",
    knowledge_sources=[your_knowledge_sources],  # Conhecimento pré-processado
    respect_context_window=True,
    verbose=True
)
```

### Boas Práticas para Janela de Contexto

1. **Monitore o uso de contexto**: Ative `verbose=True` para visualizar o gerenciamento de contexto em ação
2. **Otimize para eficiência**: Estruture tarefas para minimizar o acúmulo de contexto
3. **Use modelos apropriados**: Escolha LLMs com janelas de contexto adequadas à sua tarefa
4. **Teste ambos os modos**: Experimente `True` e `False` para descobrir o que funciona melhor para seu caso
5. **Combine com RAG**: Utilize ferramentas RAG para grandes conjuntos de dados ao invés de depender apenas da janela de contexto

### Solucionando Problemas de Contexto

**Se você receber erros de limite de contexto:**

```python Code
# Solução rápida: Habilite manipulação automática
agent.respect_context_window = True

# Solução melhor: Use ferramentas RAG para dados volumosos
from crewai_tools import RagTool
agent.tools = [RagTool()]

# Alternativa: Divida as tarefas em partes menores
# Ou use fontes de conhecimento no lugar de prompts extensos
```

**Se o resumo automático perder informações importantes:**

```python Code
# Desative o resumo automático e use RAG
agent = Agent(
    role="Detailed Analyst",
    goal="Maintain complete information accuracy",
    backstory="Expert requiring full context",
    respect_context_window=False,  # Sem resumo automático
    tools=[RagTool()],  # Use RAG para grandes volumes de dados
    verbose=True
)
```

<Note>
  O recurso de gerenciamento da janela de contexto funciona automaticamente em segundo plano. Você não precisa chamar funções especiais – basta definir `respect_context_window` conforme deseja e o CrewAI cuida do resto!
</Note>

## Considerações e Boas Práticas Importantes

### Segurança e Execução de Código

* Ao usar `allow_code_execution`, seja cauteloso com entradas do usuário e sempre as valide
* Use `code_execution_mode: "safe"` (Docker) em ambientes de produção
* Considere definir limites adequados de `max_execution_time` para evitar loops infinitos

### Otimização de Performance

* Use `respect_context_window: true` para evitar problemas com limite de tokens
* Ajuste `max_rpm` para evitar rate limiting
* Ative `cache: true` para melhorar performance em tarefas repetitivas
* Ajuste `max_iter` e `max_retry_limit` conforme a complexidade da tarefa

### Gerenciamento de Memória e Contexto

* Considere `knowledge_sources` para informações específicas de domínio
* Configure `embedder` ao usar modelos de embedding personalizados
* Use templates personalizados (`system_template`, `prompt_template`, `response_template`) para controle fino do comportamento do agente

### Funcionalidades Avançadas

* Ative `reasoning: true` para agentes que precisam planejar e refletir antes de tarefas complexas
* Defina `max_reasoning_attempts` para controlar as iterações de planejamento (`None` para ilimitadas)
* Use `inject_date: true` para dar consciência temporal a agentes em tarefas que dependem de datas
* Personalize o formato de data com `date_format` usando códigos padrões do Python datetime
* Ative `multimodal: true` para agentes que precisam processar texto e imagem

### Colaboração entre Agentes

* Ative `allow_delegation: true` quando agentes precisarem trabalhar juntos
* Use `step_callback` para monitorar e registrar interações dos agentes
* Considere usar LLMs diferentes para propósitos distintos:
  * `llm` principal para raciocínio complexo
  * `function_calling_llm` para uso eficiente de ferramentas

### Consciência de Data e Raciocínio

* Use `inject_date: true` para fornecer consciência temporal aos agentes em tarefas sensíveis ao tempo
* Customize o formato de data com `date_format` usando códigos standards de datetime do Python
* Códigos válidos incluem: %Y (ano), %m (mês), %d (dia), %B (nome completo do mês), etc.
* Formatos de data inválidos serão registrados como avisos e não modificarão a descrição da tarefa
* Ative `reasoning: true` para tarefas complexas que se beneficiam de planejamento e reflexão antecipados

### Compatibilidade de Modelos

* Defina `use_system_prompt: false` para modelos antigos que não suportam mensagens de sistema
* Certifique-se que o `llm` escolhido suporta as funcionalidades necessárias (como function calling)

## Solução de Problemas Comuns

1. **Limite de Taxa (Rate Limiting)**: Se atingir limites de API:
   * Implemente o `max_rpm` adequado
   * Use cache para operações repetitivas
   * Considere agrupar requisições em lote

2. **Erros de Janela de Contexto**: Se exceder limites de contexto:
   * Habilite `respect_context_window`
   * Otimize seus prompts
   * Limpe periodicamente a memória do agente

3. **Problemas de Execução de Código**: Se a execução de código falhar:
   * Verifique se o Docker está instalado para o modo seguro
   * Cheque permissões de execução
   * Revise as configurações do sandbox de código

4. **Problemas de Memória**: Se as respostas do agente parecerem inconsistentes:
   * Cheque a configuração das fontes de conhecimento
   * Analise o gerenciamento do histórico de conversas

Lembre-se de que agentes são mais eficientes quando configurados de acordo com o caso de uso específico. Reserve um tempo para entender seus requisitos e ajustar esses parâmetros conforme necessário.


# CLI
Source: https://docs.crewai.com/pt-BR/concepts/cli

Aprenda a usar o CLI do CrewAI para interagir com o CrewAI.

## Visão Geral

O CLI do CrewAI fornece um conjunto de comandos para interagir com o CrewAI, permitindo que você crie, treine, execute e gerencie crews & flows.

## Instalação

Para usar o CLI do CrewAI, certifique-se de que o CrewAI está instalado:

```shell Terminal
pip install crewai
```

## Uso Básico

A estrutura básica de um comando CLI do CrewAI é:

```shell Terminal
crewai [COMMAND] [OPTIONS] [ARGUMENTS]
```

## Comandos Disponíveis

### 1. Create

Crie um novo crew ou flow.

```shell Terminal
crewai create [OPTIONS] TYPE NAME
```

* `TYPE`: Escolha entre "crew" ou "flow"
* `NAME`: Nome do crew ou flow

Exemplo:

```shell Terminal
crewai create crew my_new_crew
crewai create flow my_new_flow
```

### 2. Version

Mostre a versão instalada do CrewAI.

```shell Terminal
crewai version [OPTIONS]
```

* `--tools`: (Opcional) Mostra a versão instalada das ferramentas do CrewAI

Exemplo:

```shell Terminal
crewai version
crewai version --tools
```

### 3. Train

Treine o crew por um número específico de iterações.

```shell Terminal
crewai train [OPTIONS]
```

* `-n, --n_iterations INTEGER`: Número de iterações para treinar o crew (padrão: 5)
* `-f, --filename TEXT`: Caminho para um arquivo customizado para treinamento (padrão: "trained\_agents\_data.pkl")

Exemplo:

```shell Terminal
crewai train -n 10 -f my_training_data.pkl
```

### 4. Replay

Reexecute a execução do crew a partir de uma tarefa específica.

```shell Terminal
crewai replay [OPTIONS]
```

* `-t, --task_id TEXT`: Reexecuta o crew a partir deste task ID, incluindo todas as tarefas subsequentes

Exemplo:

```shell Terminal
crewai replay -t task_123456
```

### 5. Log-tasks-outputs

Recupere as saídas mais recentes das tarefas crew\.kickoff() do seu crew.

```shell Terminal
crewai log-tasks-outputs
```

### 6. Reset-memories

Redefine as memórias do crew (longa, curta, de entidades, latest\_crew\_kickoff\_outputs).

```shell Terminal
crewai reset-memories [OPTIONS]
```

* `-l, --long`: Redefine a memória de LONGO PRAZO
* `-s, --short`: Redefine a memória de CURTO PRAZO
* `-e, --entities`: Redefine a memória de ENTIDADES
* `-k, --kickoff-outputs`: Redefine as OUTPUTS DA TAREFA KICKOFF MAIS RECENTE
* `-kn, --knowledge`: Redefine o armazenamento de CONHECIMENTO
* `-akn, --agent-knowledge`: Redefine o armazenamento de CONHECIMENTO DOS AGENTES
* `-a, --all`: Redefine TODAS as memórias

Exemplo:

```shell Terminal
crewai reset-memories --long --short
crewai reset-memories --all
```

### 7. Test

Teste o crew e avalie os resultados.

```shell Terminal
crewai test [OPTIONS]
```

* `-n, --n_iterations INTEGER`: Número de iterações para testar o crew (padrão: 3)
* `-m, --model TEXT`: Modelo LLM para executar os testes no Crew (padrão: "gpt-4o-mini")

Exemplo:

```shell Terminal
crewai test -n 5 -m gpt-3.5-turbo
```

### 8. Run

Execute o crew ou flow.

```shell Terminal
crewai run
```

<Note>
  A partir da versão 0.103.0, o comando `crewai run` pode ser usado para executar tanto crews padrão quanto flows. Para flows, ele detecta automaticamente o tipo a partir do pyproject.toml e executa o comando apropriado. Este é agora o modo recomendado de executar tanto crews quanto flows.
</Note>

<Note>
  Certifique-se de executar estes comandos a partir do diretório onde seu projeto CrewAI está configurado.
  Alguns comandos podem exigir configuração ou ajustes adicionais dentro da estrutura do seu projeto.
</Note>

### 9. Chat

A partir da versão `0.98.0`, ao rodar o comando `crewai chat`, você inicia uma sessão interativa com seu crew. O assistente de IA irá guiá-lo solicitando as entradas necessárias para executar o crew. Uma vez que todas as entradas são fornecidas, o crew executará suas tarefas.

Depois de receber os resultados, você pode continuar interagindo com o assistente para instruções ou perguntas adicionais.

```shell Terminal
crewai chat
```

<Note>
  Garanta que você execute estes comandos a partir do diretório raiz do seu projeto CrewAI.
</Note>

<Note>
  IMPORTANTE: Defina a propriedade `chat_llm` no seu arquivo `crew.py` para habilitar este comando.

  ```python
  @crew
  def crew(self) -> Crew:
      return Crew(
          agents=self.agents,
          tasks=self.tasks,
          process=Process.sequential,
          verbose=True,
          chat_llm="gpt-4o",  # LLM para orquestração de chat
      )
  ```
</Note>

### 10. Deploy

Implemente o crew ou flow no [CrewAI Enterprise](https://app.crewai.com).

* **Autenticação**: Você precisa estar autenticado para implementar no CrewAI Enterprise.
  ```shell Terminal
  crewai signup
  ```
  Caso já tenha uma conta, você pode fazer login com:
  ```shell Terminal
  crewai login
  ```

* **Criar um deployment**: Depois de autenticado, você pode criar um deployment para seu crew ou flow a partir da raiz do seu projeto local.
  ```shell Terminal
  crewai deploy create
  ```
  * Lê a configuração do seu projeto local.
  * Solicita a confirmação das variáveis de ambiente (como `OPENAI_API_KEY`, `SERPER_API_KEY`) encontradas localmente. Elas serão armazenadas de forma segura junto ao deployment na plataforma Enterprise. Verifique se suas chaves sensíveis estão corretamente configuradas localmente (por exemplo, em um arquivo `.env`) antes de executar este comando.

### 11. Gerenciamento de Organização

Gerencie suas organizações no CrewAI Enterprise.

```shell Terminal
crewai org [COMMAND] [OPTIONS]
```

#### Comandos:

* `list`: Liste todas as organizações das quais você faz parte

```shell Terminal
crewai org list
```

* `current`: Exibe sua organização ativa atualmente

```shell Terminal
crewai org current
```

* `switch`: Mude para uma organização específica

```shell Terminal
crewai org switch <organization_id>
```

<Note>
  Você deve estar autenticado no CrewAI Enterprise para usar estes comandos de gerenciamento de organização.
</Note>

* **Criar um deployment** (continuação):
  * Vincula o deployment ao respectivo repositório remoto do GitHub (normalmente detectado automaticamente).

* **Implantar o Crew**: Depois de autenticado, você pode implantar seu crew ou flow no CrewAI Enterprise.
  ```shell Terminal
  crewai deploy push
  ```
  * Inicia o processo de deployment na plataforma CrewAI Enterprise.
  * Após a iniciação bem-sucedida, será exibida a mensagem Deployment created successfully! juntamente com o Nome do Deployment e um Deployment ID (UUID) único.

* **Status do Deployment**: Você pode verificar o status do seu deployment com:
  ```shell Terminal
  crewai deploy status
  ```
  Isso retorna o status mais recente do último deployment iniciado (por exemplo, `Building Images for Crew`, `Deploy Enqueued`, `Online`).

* **Logs do Deployment**: Você pode checar os logs do seu deployment com:
  ```shell Terminal
  crewai deploy logs
  ```
  Isso faz o streaming dos logs do deployment para seu terminal.

* **Listar deployments**: Você pode listar todos os seus deployments com:
  ```shell Terminal
  crewai deploy list
  ```
  Isto lista todos os seus deployments.

* **Deletar um deployment**: Você pode deletar um deployment com:
  ```shell Terminal
  crewai deploy remove
  ```
  Isto exclui o deployment da plataforma CrewAI Enterprise.

* **Comando de Ajuda**: Você pode obter ajuda sobre o CLI com:
  ```shell Terminal
  crewai deploy --help
  ```
  Isto exibe a mensagem de ajuda para o CLI CrewAI Deploy.

Assista ao vídeo tutorial para uma demonstração passo-a-passo de implantação do seu crew no [CrewAI Enterprise](http://app.crewai.com) usando o CLI.

<iframe width="100%" height="400" src="https://www.youtube.com/embed/3EqSV-CYDZA" title="CrewAI Deployment Guide" frameborder="0" style={{ borderRadius: '10px' }} allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

### 11. Chaves de API

Ao executar o comando `crewai create crew`, o CLI primeiro mostrará os 5 provedores de LLM mais comuns e pedirá para você selecionar um.

Após selecionar um provedor de LLM, será solicitado que você informe as chaves de API.

#### Provedores iniciais de chave de API

Inicialmente, o CLI solicitará as chaves de API para os seguintes serviços:

* OpenAI
* Groq
* Anthropic
* Google Gemini
* SambaNova

Ao selecionar um provedor, o CLI solicitará que você insira sua chave de API.

#### Outras opções

Se você selecionar a opção 6, será possível escolher de uma lista de provedores suportados pelo LiteLLM.

Ao escolher um provedor, o CLI solicitará que você informe o nome da chave e a chave de API.

Veja o seguinte link para o nome de chave de cada provedor:

* [LiteLLM Providers](https://docs.litellm.ai/docs/providers)


# Colaboração
Source: https://docs.crewai.com/pt-BR/concepts/collaboration

Como permitir que agentes trabalhem juntos, deleguem tarefas e se comuniquem de forma eficaz em equipes CrewAI.

## Visão Geral

A colaboração no CrewAI permite que agentes trabalhem juntos como uma equipe, delegando tarefas e fazendo perguntas para aproveitar a expertise uns dos outros. Quando `allow_delegation=True`, os agentes automaticamente têm acesso a poderosas ferramentas de colaboração.

## Guia Rápido: Habilite a Colaboração

```python
from crewai import Agent, Crew, Task

# Enable collaboration for agents
researcher = Agent(
    role="Especialista em Pesquisa",
    goal="Realizar pesquisas aprofundadas sobre qualquer tema",
    backstory="Pesquisador especialista com acesso a diversas fontes",
    allow_delegation=True,  # 🔑 Configuração chave para colaboração
    verbose=True
)

writer = Agent(
    role="Redator de Conteúdo",
    goal="Criar conteúdo envolvente com base em pesquisas",
    backstory="Redator habilidoso que transforma pesquisas em conteúdo atraente",
    allow_delegation=True,  # 🔑 Permite fazer perguntas a outros agentes
    verbose=True
)

# Agents can now collaborate automatically
crew = Crew(
    agents=[researcher, writer],
    tasks=[...],
    verbose=True
)
```

## Como Funciona a Colaboração entre Agentes

Quando `allow_delegation=True`, o CrewAI automaticamente fornece aos agentes duas ferramentas poderosas:

### 1. **Ferramenta de Delegação de Trabalho**

Permite que agentes designem tarefas para colegas com expertise específica.

```python
# Agent automatically gets this tool:
# Delegate work to coworker(task: str, context: str, coworker: str)
```

### 2. **Ferramenta de Fazer Pergunta**

Permite que agentes façam perguntas específicas para obter informações de colegas.

```python
# Agent automatically gets this tool:
# Ask question to coworker(question: str, context: str, coworker: str)
```

## Colaboração em Ação

Veja um exemplo completo onde agentes colaboram em uma tarefa de criação de conteúdo:

```python
from crewai import Agent, Crew, Task, Process

# Create collaborative agents
researcher = Agent(
    role="Especialista em Pesquisa",
    goal="Realizar pesquisas aprofundadas sobre qualquer tema",
    backstory="Pesquisador especialista com acesso a diversas fontes",
    allow_delegation=True,
    verbose=True
)

writer = Agent(
    role="Redator de Conteúdo",
    goal="Criar conteúdo envolvente com base em pesquisas",
    backstory="Redator habilidoso que transforma pesquisas em conteúdo atraente",
    allow_delegation=True,
    verbose=True
)

editor = Agent(
    role="Content Editor",
    goal="Ensure content quality and consistency",
    backstory="""You're an experienced editor with an eye for detail,
    ensuring content meets high standards for clarity and accuracy.""",
    allow_delegation=True,
    verbose=True
)

# Create a task that encourages collaboration
article_task = Task(
    description="""Escreva um artigo abrangente de 1000 palavras sobre 'O Futuro da IA na Saúde'.

O artigo deve incluir:
- Aplicações atuais de IA na saúde
- Tendências e tecnologias emergentes
- Desafios potenciais e considerações éticas
- Previsões de especialistas para os próximos 5 anos

Colabore com seus colegas para garantir precisão e qualidade.""",
    expected_output="Um artigo bem pesquisado, envolvente, com 1000 palavras, estrutura adequada e citações",
    agent=writer  # O redator lidera, mas pode delegar pesquisa ao pesquisador
)

# Create collaborative crew
crew = Crew(
    agents=[researcher, writer, editor],
    tasks=[article_task],
    process=Process.sequential,
    verbose=True
)

result = crew.kickoff()
```

## Padrões de Colaboração

### Padrão 1: Pesquisa → Redação → Edição

```python
research_task = Task(
    description="Pesquise os últimos avanços em computação quântica",
    expected_output="Resumo abrangente da pesquisa com principais descobertas e fontes",
    agent=researcher
)

writing_task = Task(
    description="Escreva um artigo com base nos achados da pesquisa",
    expected_output="Artigo envolvente de 800 palavras sobre computação quântica",
    agent=writer,
    context=[research_task]  # Recebe a saída da pesquisa como contexto
)

editing_task = Task(
    description="Edite e revise o artigo para publicação",
    expected_output="Artigo pronto para publicação, com clareza e fluidez aprimoradas",
    agent=editor,
    context=[writing_task]  # Recebe o rascunho do artigo como contexto
)
```

### Padrão 2: Tarefa Única Colaborativa

```python
collaborative_task = Task(
    description="""Crie uma estratégia de marketing para um novo produto de IA.

Redator: Foque em mensagens e estratégia de conteúdo
Pesquisador: Forneça análise de mercado e insights de concorrentes

Trabalhem juntos para criar uma estratégia abrangente.""",
    expected_output="Estratégia de marketing completa com embasamento em pesquisa",
    agent=writer  # Agente líder, mas pode delegar ao pesquisador
)
```

## Colaboração Hierárquica

Para projetos complexos, utilize um processo hierárquico com um agente gerente:

```python
from crewai import Agent, Crew, Task, Process

# Manager agent coordinates the team
manager = Agent(
    role="Gerente de Projetos",
    goal="Coordenar esforços da equipe e garantir o sucesso do projeto",
    backstory="Gerente de projetos experiente, habilidoso em delegação e controle de qualidade",
    allow_delegation=True,
    verbose=True
)

# Specialist agents
researcher = Agent(
    role="Pesquisador",
    goal="Fornecer pesquisa e análise precisas",
    backstory="Pesquisador especialista com habilidades analíticas profundas",
    allow_delegation=False,  # Especialistas focam em sua expertise
    verbose=True
)

writer = Agent(
    role="Redator",
    goal="Criar conteúdo envolvente",
    backstory="Redator habilidoso que cria conteúdo atraente",
    allow_delegation=False,
    verbose=True
)

# Manager-led task
project_task = Task(
    description="Crie um relatório de análise de mercado completo com recomendações",
    expected_output="Resumo executivo, análise detalhada e recomendações estratégicas",
    agent=manager  # O gerente delega para especialistas
)

# Hierarchical crew
crew = Crew(
    agents=[manager, researcher, writer],
    tasks=[project_task],
    process=Process.hierarchical,  # Manager coordinates everything
    manager_llm="gpt-4o",  # Specify LLM for manager
    verbose=True
)
```

## Melhores Práticas para Colaboração

### 1. **Definição Clara de Papéis**

```python
# ✅ Bom: papéis específicos e complementares
researcher = Agent(role="Market Research Analyst", ...)
writer = Agent(role="Technical Content Writer", ...)

# ❌ Evite: Papéis sobrepostos ou vagos
agent1 = Agent(role="General Assistant", ...)
agent2 = Agent(role="Helper", ...)
```

### 2. **Delegação Estratégica Habilitada**

```python
# ✅ Habilite delegação para coordenadores e generalistas
lead_agent = Agent(
    role="Content Lead",
    allow_delegation=True,  # Can delegate to specialists
    ...
)

# ✅ Desative para especialistas focados (opcional)
specialist_agent = Agent(
    role="Data Analyst",
    allow_delegation=False,  # Focuses on core expertise
    ...
)
```

### 3. **Compartilhamento de Contexto**

```python
# ✅ Use o parâmetro context para dependências entre tarefas
writing_task = Task(
    description="Write article based on research",
    agent=writer,
    context=[research_task],  # Shares research results
    ...
)
```

### 4. **Descrições Claras de Tarefas**

```python
# ✅ Descrições específicas e acionáveis
Task(
    description="""Research competitors in the AI chatbot space.
    Focus on: pricing models, key features, target markets.
    Provide data in a structured format.""",
    ...
)

# ❌ Descrições vagas que não orientam a colaboração
Task(description="Do some research about chatbots", ...)
```

## Solução de Problemas em Colaboração

### Problema: Agentes Não Colaboram

**Sintomas:** Agentes trabalham isoladamente, sem ocorrer delegação

```python
# ✅ Solução: Certifique-se que a delegação está habilitada
agent = Agent(
    role="...",
    allow_delegation=True,  # This is required!
    ...
)
```

### Problema: Troca Excessiva de Perguntas

**Sintomas:** Agentes fazem perguntas em excesso, progresso lento

```python
# ✅ Solução: Forneça melhor contexto e papéis específicos
Task(
    description="""Write a technical blog post about machine learning.

    Context: Target audience is software developers with basic ML knowledge.
    Length: 1200 words
    Include: code examples, practical applications, best practices

    If you need specific technical details, delegate research to the researcher.""",
    ...
)
```

### Problema: Loops de Delegação

**Sintomas:** Agentes delegam tarefas repetidamente uns para os outros indefinidamente

```python
# ✅ Solução: Hierarquia e responsabilidades bem definidas
manager = Agent(role="Manager", allow_delegation=True)
specialist1 = Agent(role="Specialist A", allow_delegation=False)  # No re-delegation
specialist2 = Agent(role="Specialist B", allow_delegation=False)
```

## Recursos Avançados de Colaboração

### Regras Personalizadas de Colaboração

```python
# Set specific collaboration guidelines in agent backstory
agent = Agent(
    role="Senior Developer",
    backstory="""You lead development projects and coordinate with team members.

    Collaboration guidelines:
    - Delegate research tasks to the Research Analyst
    - Ask the Designer for UI/UX guidance
    - Consult the QA Engineer for testing strategies
    - Only escalate blocking issues to the Project Manager""",
    allow_delegation=True
)
```

### Monitoramento da Colaboração

```python
def track_collaboration(output):
    """Track collaboration patterns"""
    if "Delegate work to coworker" in output.raw:
        print("🤝 Delegation occurred")
    if "Ask question to coworker" in output.raw:
        print("❓ Question asked")

crew = Crew(
    agents=[...],
    tasks=[...],
    step_callback=track_collaboration,  # Monitor collaboration
    verbose=True
)
```

## Memória e Aprendizado

Permita que agentes se lembrem de colaborações passadas:

```python
agent = Agent(
    role="Content Lead",
    memory=True,  # Remembers past interactions
    allow_delegation=True,
    verbose=True
)
```

Com a memória ativada, os agentes aprendem com colaborações anteriores e aprimoram suas decisões de delegação ao longo do tempo.

## Próximos Passos

* **Teste os exemplos**: Comece pelo exemplo básico de colaboração
* **Experimente diferentes papéis**: Teste combinações variadas de papéis de agentes
* **Monitore as interações**: Use `verbose=True` para ver a colaboração em ação
* **Otimize descrições de tarefas**: Tarefas claras geram melhor colaboração
* **Escale**: Experimente processos hierárquicos para projetos complexos

A colaboração transforma agentes de IA individuais em equipes poderosas capazes de enfrentar desafios complexos e multifacetados juntos.


# Crews
Source: https://docs.crewai.com/pt-BR/concepts/crews

Compreendendo e utilizando crews no framework crewAI com atributos e funcionalidades abrangentes.

## Visão Geral

Uma crew no crewAI representa um grupo colaborativo de agentes trabalhando em conjunto para alcançar um conjunto de tarefas. Cada crew define a estratégia de execução de tarefas, colaboração entre agentes e o fluxo de trabalho geral.

## Atributos de Crew

| Atributo                              | Parâmetros             | Descrição                                                                                                                                                                                                               |
| :------------------------------------ | :--------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Tasks**                             | `tasks`                | Uma lista de tasks atribuídas à crew.                                                                                                                                                                                   |
| **Agents**                            | `agents`               | Uma lista de agentes que fazem parte da crew.                                                                                                                                                                           |
| **Process** *(opcional)*              | `process`              | O fluxo de processo (por exemplo, sequencial, hierárquico) seguido pela crew. O padrão é `sequential`.                                                                                                                  |
| **Verbose** *(opcional)*              | `verbose`              | O nível de verbosidade para logging durante a execução. O padrão é `False`.                                                                                                                                             |
| **Manager LLM** *(opcional)*          | `manager_llm`          | O modelo de linguagem utilizado pelo agente gerenciador em um processo hierárquico. **Obrigatório ao usar um processo hierárquico.**                                                                                    |
| **Function Calling LLM** *(opcional)* | `function_calling_llm` | Se definido, a crew utilizará este LLM para invocar funções das ferramentas para todos os agentes da crew. Cada agente pode ter seu próprio LLM, que substitui o LLM da crew para chamadas de função.                   |
| **Config** *(opcional)*               | `config`               | Configurações opcionais para a crew, no formato `Json` ou `Dict[str, Any]`.                                                                                                                                             |
| **Max RPM** *(opcional)*              | `max_rpm`              | Número máximo de requisições por minuto que a crew respeita durante a execução. O padrão é `None`.                                                                                                                      |
| **Memory** *(opcional)*               | `memory`               | Utilizada para armazenar memórias de execução (curto prazo, longo prazo, memória de entidade).                                                                                                                          |
| **Memory Config** *(opcional)*        | `memory_config`        | Configuração para o provedor de memória a ser utilizada pela crew.                                                                                                                                                      |
| **Cache** *(opcional)*                | `cache`                | Especifica se deve usar cache para armazenar os resultados da execução de ferramentas. O padrão é `True`.                                                                                                               |
| **Embedder** *(opcional)*             | `embedder`             | Configuração do embedder a ser utilizado pela crew. Atualmente mais usado por memory. O padrão é `{"provider": "openai"}`.                                                                                              |
| **Step Callback** *(opcional)*        | `step_callback`        | Uma função chamada após cada etapa de cada agente. Pode ser usada para registrar as ações do agente ou executar outras operações; não sobrescreve o `step_callback` específico do agente.                               |
| **Task Callback** *(opcional)*        | `task_callback`        | Uma função chamada após a conclusão de cada tarefa. Útil para monitoramento ou para operações adicionais pós-execução da task.                                                                                          |
| **Share Crew** *(opcional)*           | `share_crew`           | Se deseja compartilhar as informações completas da crew e execução com a equipe do crewAI para melhorar a biblioteca e nos permitir treinar modelos.                                                                    |
| **Output Log File** *(opcional)*      | `output_log_file`      | Defina como True para salvar logs como logs.txt no diretório atual ou forneça um caminho de arquivo. Os logs estarão em formato JSON se o nome terminar com .json, caso contrário .txt. O padrão é `None`.              |
| **Manager Agent** *(opcional)*        | `manager_agent`        | `manager` define um agente customizado que será utilizado como gerente.                                                                                                                                                 |
| **Prompt File** *(opcional)*          | `prompt_file`          | Caminho para o arquivo JSON de prompt a ser utilizado pela crew.                                                                                                                                                        |
| **Planning** *(opcional)*             | `planning`             | Adiciona habilidade de planejamento à Crew. Quando ativado, antes de cada iteração, todos os dados da Crew são enviados a um AgentPlanner que planejará as tasks e este plano será adicionado à descrição de cada task. |
| **Planning LLM** *(opcional)*         | `planning_llm`         | O modelo de linguagem usado pelo AgentPlanner em um processo de planejamento.                                                                                                                                           |

<Tip>
  **Crew Max RPM**: O atributo `max_rpm` define o número máximo de requisições por minuto que a crew pode executar para evitar limites de taxa e irá sobrescrever as configurações de `max_rpm` dos agentes individuais se você o definir.
</Tip>

## Criando Crews

Existem duas maneiras de criar crews no CrewAI: utilizando **configuração YAML (recomendado)** ou definindo diretamente **em código**.

### Configuração YAML (Recomendado)

O uso da configuração YAML proporciona uma forma mais limpa e fácil de manter para definir crews, sendo consistente com a definição de agentes e tasks em projetos CrewAI.

Após criar seu projeto CrewAI conforme descrito na seção [Instalação](/pt-BR/installation), você pode definir sua crew em uma classe que herda de `CrewBase` e utiliza decorators para definir agentes, tarefas e a própria crew.

#### Exemplo de Classe Crew com Decorators

```python code
from crewai import Agent, Crew, Task, Process
from crewai.project import CrewBase, agent, task, crew, before_kickoff, after_kickoff
from crewai.agents.agent_builder.base_agent import BaseAgent
from typing import List

@CrewBase
class YourCrewName:
    """Descrição da sua crew"""

    agents: List[BaseAgent]
    tasks: List[Task]

    # Caminhos para seus arquivos de configuração YAML
    # Para um exemplo de agente e tarefa definidos em YAML, confira:
    # - Task: https://docs.crewai.com/concepts/tasks#yaml-configuration-recommended
    # - Agents: https://docs.crewai.com/concepts/agents#yaml-configuration-recommended
    agents_config = 'config/agents.yaml'
    tasks_config = 'config/tasks.yaml'

    @before_kickoff
    def prepare_inputs(self, inputs):
        # Modifique inputs antes da crew iniciar
        inputs['additional_data'] = "Alguma informação extra"
        return inputs

    @after_kickoff
    def process_output(self, output):
        # Modifique a saída após a crew finalizar
        output.raw += "\nProcessado após kickoff."
        return output

    @agent
    def agent_one(self) -> Agent:
        return Agent(
            config=self.agents_config['agent_one'], # type: ignore[index]
            verbose=True
        )

    @agent
    def agent_two(self) -> Agent:
        return Agent(
            config=self.agents_config['agent_two'], # type: ignore[index]
            verbose=True
        )

    @task
    def task_one(self) -> Task:
        return Task(
            config=self.tasks_config['task_one'] # type: ignore[index]
        )

    @task
    def task_two(self) -> Task:
        return Task(
            config=self.tasks_config['task_two'] # type: ignore[index]
        )

    @crew
    def crew(self) -> Crew:
        return Crew(
            agents=self.agents,  # Coletado automaticamente pelo decorator @agent
            tasks=self.tasks,    # Coletado automaticamente pelo decorator @task
            process=Process.sequential,
            verbose=True,
        )
```

Como executar o código acima:

```python code
YourCrewName().crew().kickoff(inputs={"any": "input here"})
```

<Note>
  As tarefas serão executadas na ordem em que forem definidas.
</Note>

A classe `CrewBase`, junto com esses decorators, automatiza a coleta de agentes e tarefas, reduzindo a necessidade de gerenciamento manual.

#### Visão geral dos Decorators de `annotations.py`

O CrewAI fornece vários decorators no arquivo `annotations.py` que são usados para marcar métodos dentro de sua classe crew para tratamento especial:

* `@CrewBase`: Marca a classe como classe base de crew.
* `@agent`: Denota um método que retorna um objeto `Agent`.
* `@task`: Denota um método que retorna um objeto `Task`.
* `@crew`: Denota o método que retorna o objeto `Crew`.
* `@before_kickoff`: (Opcional) Marca um método a ser executado antes da crew iniciar.
* `@after_kickoff`: (Opcional) Marca um método a ser executado após a crew finalizar.

Esses decorators ajudam na organização da estrutura da sua crew e coletam automaticamente agentes e tasks sem precisar listá-los manualmente.

### Definição Direta em Código (Alternativa)

Como alternativa, você pode definir a crew diretamente em código sem utilizar arquivos de configuração YAML.

```python code
from crewai import Agent, Crew, Task, Process
from crewai_tools import YourCustomTool

class YourCrewName:
    def agent_one(self) -> Agent:
        return Agent(
            role="Analista de Dados",
            goal="Analisar tendências de dados no mercado brasileiro",
            backstory="Analista experiente com formação em economia",
            verbose=True,
            tools=[YourCustomTool()]
        )

    def agent_two(self) -> Agent:
        return Agent(
            role="Pesquisador de Mercado",
            goal="Coletar informações sobre a dinâmica do mercado nacional",
            backstory="Pesquisador dedicado com olhar atento aos detalhes",
            verbose=True
        )

    def task_one(self) -> Task:
        return Task(
            description="Coletar dados recentes do mercado brasileiro e identificar tendências.",
            expected_output="Um relatório resumido com as principais tendências do mercado.",
            agent=self.agent_one()
        )

    def task_two(self) -> Task:
        return Task(
            description="Pesquisar fatores que afetam a dinâmica do mercado nacional.",
            expected_output="Uma análise dos fatores que influenciam o mercado.",
            agent=self.agent_two()
        )

    def crew(self) -> Crew:
        return Crew(
            agents=[self.agent_one(), self.agent_two()],
            tasks=[self.task_one(), self.task_two()],
            process=Process.sequential,
            verbose=True
        )
```

Como executar o código acima:

```python code
YourCrewName().crew().kickoff(inputs={})
```

Neste exemplo:

* Agentes e tarefas são definidos diretamente dentro da classe, sem decorators.
* Criamos e gerenciamos manualmente a lista de agentes e tasks.
* Essa abordagem fornece mais controle, mas pode ser menos sustentável para projetos maiores.

## Saída da Crew

A saída de uma crew no framework CrewAI é encapsulada na classe `CrewOutput`.
Essa classe fornece uma forma estruturada de acessar os resultados da execução da crew, incluindo vários formatos como string bruta, JSON e modelos Pydantic.
O `CrewOutput` inclui os resultados da tarefa final, uso de tokens e as saídas das tasks individuais.

### Atributos do Crew Output

| Atributo         | Parâmetros     | Tipo                       | Descrição                                                                                      |
| :--------------- | :------------- | :------------------------- | :--------------------------------------------------------------------------------------------- |
| **Raw**          | `raw`          | `str`                      | A saída bruta da crew. Este é o formato padrão da saída.                                       |
| **Pydantic**     | `pydantic`     | `Optional[BaseModel]`      | Um objeto modelo Pydantic representando a saída estruturada da crew.                           |
| **JSON Dict**    | `json_dict`    | `Optional[Dict[str, Any]]` | Um dicionário representando a saída da crew em formato JSON.                                   |
| **Tasks Output** | `tasks_output` | `List[TaskOutput]`         | Uma lista de objetos `TaskOutput`, cada um representando a saída de uma task na crew.          |
| **Token Usage**  | `token_usage`  | `Dict[str, Any]`           | Um resumo do uso de tokens, oferecendo informações sobre a performance do modelo de linguagem. |

### Métodos e Propriedades do Crew Output

| Método/Propriedade | Descrição                                                                                              |
| :----------------- | :----------------------------------------------------------------------------------------------------- |
| **json**           | Retorna a representação em string JSON da saída da crew caso o formato seja JSON.                      |
| **to\_dict**       | Converte as saídas JSON e Pydantic em um dicionário.                                                   |
| ****str****        | Retorna a representação em string do resultado da crew, priorizando Pydantic, depois JSON, depois raw. |

### Acessando a Saída da Crew

Após executar uma crew, sua saída pode ser acessada pelo atributo `output` do objeto `Crew`. A classe `CrewOutput` oferece várias formas de interagir com esta saída.

#### Exemplo

```python Code
# Execução de exemplo da crew
crew = Crew(
    agents=[research_agent, writer_agent],
    tasks=[research_task, write_article_task],
    verbose=True
)

crew_output = crew.kickoff()

# Acessando a saída da crew
print(f"Raw Output: {crew_output.raw}")
if crew_output.json_dict:
    print(f"JSON Output: {json.dumps(crew_output.json_dict, indent=2)}")
if crew_output.pydantic:
    print(f"Pydantic Output: {crew_output.pydantic}")
print(f"Tasks Output: {crew_output.tasks_output}")
print(f"Token Usage: {crew_output.token_usage}")
```

## Acessando Logs da Crew

Você pode visualizar o log em tempo real da execução da crew, definindo `output_log_file` como `True(Boolean)` ou um `file_name(str)`. Suporta logging de eventos como tanto `file_name.txt` quanto `file_name.json`.
Se for `True(Boolean)`, salvará como `logs.txt`.

Caso `output_log_file` seja `False(Boolean)` ou `None`, os logs não serão gerados.

```python Code
# Salvar logs da crew
crew = Crew(output_log_file = True)  # Logs serão salvos como logs.txt
crew = Crew(output_log_file = file_name)  # Logs serão salvos como file_name.txt
crew = Crew(output_log_file = file_name.txt)  # Logs serão salvos como file_name.txt
crew = Crew(output_log_file = file_name.json)  # Logs serão salvos como file_name.json
```

## Utilização de Memória

As crews podem utilizar memória (curto prazo, longo prazo e memória de entidade) para potencializar sua execução e aprendizado ao longo do tempo. Este recurso permite que as crews armazenem e recuperem memórias de execução, auxiliando na tomada de decisão e nas estratégias de execução de tasks.

## Utilização de Cache

Caches podem ser utilizados para armazenar resultados de execuções de ferramentas, tornando o processo mais eficiente ao evitar a reexecução de tasks idênticas.

## Métricas de Uso da Crew

Após a execução da crew, você pode acessar o atributo `usage_metrics` para visualizar as métricas de uso do modelo de linguagem (LLM) para todas as tasks executadas pela crew. Isso fornece insights sobre eficiência operacional e oportunidades de melhoria.

```python Code
# Acessar as métricas de uso da crew
crew = Crew(agents=[agent1, agent2], tasks=[task1, task2])
crew.kickoff()
print(crew.usage_metrics)
```

## Processo de Execução da Crew

* **Sequential Process**: As tasks são executadas uma após a outra, permitindo um fluxo de trabalho linear.
* **Hierarchical Process**: Um agente gerente coordena a crew, delegando tarefas e validando resultados antes de prosseguir. **Nota**: Um `manager_llm` ou `manager_agent` é necessário para este processo e é essencial para validar o fluxo.

### Iniciando uma Crew

Uma vez que sua crew esteja montada, inicie o workflow com o método `kickoff()`. Isso inicia a execução conforme o fluxo de processo definido.

```python Code
# Iniciar execução das tasks da crew
result = my_crew.kickoff()
print(result)
```

### Diferentes Formas de Iniciar uma Crew

Assim que sua crew estiver definida, inicie o fluxo de trabalho com o método kickoff apropriado. O CrewAI oferece vários métodos para melhor controle do processo: `kickoff()`, `kickoff_for_each()`, `kickoff_async()` e `kickoff_for_each_async()`.

* `kickoff()`: Inicia o processo de execução seguindo o fluxo definido.
* `kickoff_for_each()`: Executa tasks sequencialmente para cada evento de entrada ou item da coleção fornecida.
* `kickoff_async()`: Inicia o workflow de forma assíncrona.
* `kickoff_for_each_async()`: Executa as tasks concorrentemente para cada entrada, aproveitando o processamento assíncrono.

```python Code
# Iniciar execução das tasks da crew
result = my_crew.kickoff()
print(result)

# Exemplo com kickoff_for_each
inputs_array = [{'topic': 'AI in healthcare'}, {'topic': 'AI in finance'}]
results = my_crew.kickoff_for_each(inputs=inputs_array)
for result in results:
    print(result)

# Exemplo com kickoff_async
inputs = {'topic': 'AI in healthcare'}
async_result = await my_crew.kickoff_async(inputs=inputs)
print(async_result)

# Exemplo com kickoff_for_each_async
inputs_array = [{'topic': 'AI in healthcare'}, {'topic': 'AI in finance'}]
async_results = await my_crew.kickoff_for_each_async(inputs=inputs_array)
for async_result in async_results:
    print(async_result)
```

Esses métodos fornecem flexibilidade para gerenciar e executar tasks dentro de sua crew, permitindo fluxos de trabalho síncronos e assíncronos de acordo com sua necessidade.

### Repetindo Execução a partir de uma Task Específica

Agora é possível reiniciar a execução a partir de uma task específica usando o comando CLI `replay`.

O recurso de replay no CrewAI permite reexecutar a partir de uma task específica através da interface de linha de comando (CLI). Rodando o comando `crewai replay -t <task_id>`, você pode especificar o `task_id` para o processo de replay.

Kickoffs agora salvam localmente as saídas das tasks dos kickoffs recentes para permitir replay posteriormente.

### Repetindo a Partir de uma Task Específica Usando o CLI

Para usar o recurso de replay, siga estes passos:

1. Abra seu terminal ou prompt de comando.
2. Navegue até o diretório do seu projeto CrewAI.
3. Execute o seguinte comando:

Para visualizar os IDs das últimas tasks do kickoff, utilize:

```shell
crewai log-tasks-outputs
```

Depois, para repetir a partir de uma task específica, utilize:

```shell
crewai replay -t <task_id>
```

Esses comandos permitem repetir tasks dos seus últimos kickoffs, mantendo o contexto das tasks já executadas anteriormente.


# Listeners de Evento
Source: https://docs.crewai.com/pt-BR/concepts/event-listener

Acesse eventos do CrewAI para criar integrações e monitoramento personalizados

## Visão Geral

O CrewAI oferece um sistema de eventos poderoso que permite escutar e reagir a diversos eventos que ocorrem durante a execução do seu Crew. Esse recurso possibilita a criação de integrações personalizadas, soluções de monitoramento, sistemas de log ou qualquer outra funcionalidade que precise ser acionada com base nos eventos internos do CrewAI.

## Como Funciona

O CrewAI utiliza uma arquitetura de event bus para emitir eventos ao longo do ciclo de vida da execução. O sistema de eventos é construído a partir dos seguintes componentes:

1. **CrewAIEventsBus**: Um event bus singleton que gerencia o registro e emissão de eventos
2. **BaseEvent**: Classe base para todos os eventos do sistema
3. **BaseEventListener**: Classe base abstrata para criar listeners de evento personalizados

Quando ações específicas ocorrem no CrewAI (como a inicialização de um Crew, um Agent concluindo uma tarefa ou o uso de uma ferramenta), o sistema emite os eventos correspondentes. Você pode registrar handlers para esses eventos para executar código personalizado quando eles acontecerem.

<Note type="info" title="Aprimoramento Enterprise: Prompt Tracing">
  O CrewAI Enterprise fornece o recurso Prompt Tracing, que aproveita o sistema de eventos para rastrear, armazenar e visualizar todos os prompts, respostas e metadados associados. Isso proporciona poderosas capacidades de depuração e transparência nas operações dos seus agentes.

  ![Prompt Tracing Dashboard](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/traces-overview.png)

  Com o Prompt Tracing você pode:

  * Visualizar o histórico completo de todos os prompts enviados ao seu LLM
  * Monitorar o uso de tokens e custos
  * Depurar falhas de raciocínio dos agentes
  * Compartilhar sequências de prompts com sua equipe
  * Comparar diferentes estratégias de prompts
  * Exportar rastreamentos para compliance e auditoria
</Note>

## Criando um Listener de Evento Personalizado

Para criar um listener de evento personalizado, você precisa:

1. Criar uma classe que herde de `BaseEventListener`
2. Implementar o método `setup_listeners`
3. Registrar handles para os eventos de seu interesse
4. Instanciar seu listener no arquivo apropriado

Veja um exemplo simples de uma classe de listener de evento personalizado:

```python
from crewai.utilities.events import (
    CrewKickoffStartedEvent,
    CrewKickoffCompletedEvent,
    AgentExecutionCompletedEvent,
)
from crewai.utilities.events.base_event_listener import BaseEventListener

class MeuListenerPersonalizado(BaseEventListener):
    def __init__(self):
        super().__init__()

    def setup_listeners(self, crewai_event_bus):
        @crewai_event_bus.on(CrewKickoffStartedEvent)
        def ao_iniciar_crew(source, event):
            print(f"Crew '{event.crew_name}' iniciou a execução!")

        @crewai_event_bus.on(CrewKickoffCompletedEvent)
        def ao_finalizar_crew(source, event):
            print(f"Crew '{event.crew_name}' finalizou a execução!")
            print(f"Saída: {event.output}")

        @crewai_event_bus.on(AgentExecutionCompletedEvent)
        def ao_finalizar_execucao_agente(source, event):
            print(f"Agente '{event.agent.role}' concluiu a tarefa")
            print(f"Saída: {event.output}")
```

## Registrando Corretamente Seu Listener

Apenas definir sua classe de listener não é suficiente. É necessário criar uma instância dela e garantir que ela seja importada na sua aplicação. Isso garante que:

1. Os event handlers estejam registrados no event bus
2. A instância do listener permaneça em memória (não seja coletada pelo garbage collector)
3. O listener esteja ativo quando os eventos forem emitidos

### Opção 1: Importar e Instanciar no Seu Crew ou Implementação de Flow

O mais importante é criar uma instância do seu listener no arquivo onde seu Crew ou Flow está definido e executado:

#### Para Aplicações Baseadas em Crew

Crie e importe seu listener no início do arquivo de implementação do seu Crew:

```python
# No seu arquivo crew.py
from crewai import Agent, Crew, Task
from my_listeners import MyCustomListener

# Crie uma instância do seu listener
my_listener = MyCustomListener()

class MyCustomCrew:
    # Sua implementação do crew...

    def crew(self):
        return Crew(
            agents=[...],
            tasks=[...],
            # ...
        )
```

#### Para Aplicações Baseadas em Flow

Crie e importe seu listener no início do arquivo de implementação do seu Flow:

```python
# Em seu arquivo main.py ou flow.py
from crewai.flow import Flow, listen, start
from my_listeners import MyCustomListener

# Crie uma instância do seu listener
my_listener = MyCustomListener()

class MyCustomFlow(Flow):
    # Sua implementação do flow...

    @start()
    def first_step(self):
        # ...
```

Isso assegura que seu listener será carregado e estará ativo quando seu Crew ou Flow for executado.

### Opção 2: Criar um Pacote para Seus Listeners

Para uma abordagem mais estruturada, especialmente se houver múltiplos listeners:

1. Crie um pacote para seus listeners:

```
my_project/
  ├── listeners/
  │   ├── __init__.py
  │   ├── my_custom_listener.py
  │   └── another_listener.py
```

2. Em `my_custom_listener.py`, defina sua classe de listener e crie uma instância:

```python
# my_custom_listener.py
from crewai.utilities.events.base_event_listener import BaseEventListener
# ... importe events ...

class MyCustomListener(BaseEventListener):
    # ... implementação ...

# Crie uma instância do seu listener
my_custom_listener = MyCustomListener()
```

3. Em `__init__.py`, importe as instâncias dos listeners para garantir seu carregamento:

```python
# __init__.py
from .my_custom_listener import my_custom_listener
from .another_listener import another_listener

# Opcionalmente exporte-os se precisar acessá-los em outros lugares
__all__ = ['my_custom_listener', 'another_listener']
```

4. Importe seu pacote de listeners no arquivo do seu Crew ou Flow:

```python
# No seu arquivo crew.py ou flow.py
import my_project.listeners  # Isso carrega todos os seus listeners

class MyCustomCrew:
    # Sua implementação do crew...
```

É exatamente assim que o `agentops_listener` integrado do CrewAI é registrado. No código-fonte do CrewAI, você encontrará:

```python
# src/crewai/utilities/events/third_party/__init__.py
from .agentops_listener import agentops_listener
```

Isso garante que o `agentops_listener` seja carregado quando o pacote `crewai.utilities.events` for importado.

## Tipos de Eventos Disponíveis

O CrewAI fornece uma ampla variedade de eventos para escuta:

### Eventos de Crew

* **CrewKickoffStartedEvent**: Emitido quando um Crew inicia a execução
* **CrewKickoffCompletedEvent**: Emitido quando um Crew conclui a execução
* **CrewKickoffFailedEvent**: Emitido quando um Crew falha ao concluir a execução
* **CrewTestStartedEvent**: Emitido ao iniciar o teste de um Crew
* **CrewTestCompletedEvent**: Emitido ao concluir o teste de um Crew
* **CrewTestFailedEvent**: Emitido ao falhar no teste de um Crew
* **CrewTrainStartedEvent**: Emitido ao iniciar o treinamento de um Crew
* **CrewTrainCompletedEvent**: Emitido ao concluir o treinamento de um Crew
* **CrewTrainFailedEvent**: Emitido ao falhar no treinamento de um Crew

### Eventos de Agent

* **AgentExecutionStartedEvent**: Emitido quando um Agent inicia a execução de uma tarefa
* **AgentExecutionCompletedEvent**: Emitido quando um Agent conclui a execução de uma tarefa
* **AgentExecutionErrorEvent**: Emitido quando um Agent encontra um erro durante a execução

### Eventos de Task

* **TaskStartedEvent**: Emitido ao iniciar a execução de uma Task
* **TaskCompletedEvent**: Emitido ao concluir a execução de uma Task
* **TaskFailedEvent**: Emitido ao falhar na execução de uma Task
* **TaskEvaluationEvent**: Emitido quando uma Task é avaliada

### Eventos de Uso de Ferramentas

* **ToolUsageStartedEvent**: Emitido ao iniciar a execução de uma ferramenta
* **ToolUsageFinishedEvent**: Emitido ao concluir a execução de uma ferramenta
* **ToolUsageErrorEvent**: Emitido quando ocorre erro na execução de uma ferramenta
* **ToolValidateInputErrorEvent**: Emitido ao ocorrer erro de validação de entrada na ferramenta
* **ToolExecutionErrorEvent**: Emitido quando ocorre erro na execução de uma ferramenta
* **ToolSelectionErrorEvent**: Emitido ao ocorrer erro na seleção de uma ferramenta

### Eventos de Knowledge

* **KnowledgeRetrievalStartedEvent**: Emitido ao iniciar recuperação de conhecimento
* **KnowledgeRetrievalCompletedEvent**: Emitido ao concluir recuperação de conhecimento
* **KnowledgeQueryStartedEvent**: Emitido ao iniciar consulta de conhecimento
* **KnowledgeQueryCompletedEvent**: Emitido ao concluir consulta de conhecimento
* **KnowledgeQueryFailedEvent**: Emitido ao falhar consulta de conhecimento
* **KnowledgeSearchQueryFailedEvent**: Emitido ao falhar consulta de busca de conhecimento

### Eventos de Guardrail do LLM

* **LLMGuardrailStartedEvent**: Emitido ao iniciar validação dos guardrails. Contém detalhes do guardrail aplicado e tentativas.
* **LLMGuardrailCompletedEvent**: Emitido ao concluir validação dos guardrails. Contém detalhes sobre sucesso/falha na validação, resultados e mensagens de erro, se houver.

### Eventos de Flow

* **FlowCreatedEvent**: Emitido ao criar um Flow
* **FlowStartedEvent**: Emitido ao iniciar a execução de um Flow
* **FlowFinishedEvent**: Emitido ao concluir a execução de um Flow
* **FlowPlotEvent**: Emitido ao plotar um Flow
* **MethodExecutionStartedEvent**: Emitido ao iniciar a execução de um método do Flow
* **MethodExecutionFinishedEvent**: Emitido ao concluir a execução de um método do Flow
* **MethodExecutionFailedEvent**: Emitido ao falhar na execução de um método do Flow

### Eventos de LLM

* **LLMCallStartedEvent**: Emitido ao iniciar uma chamada LLM
* **LLMCallCompletedEvent**: Emitido ao concluir uma chamada LLM
* **LLMCallFailedEvent**: Emitido ao falhar uma chamada LLM
* **LLMStreamChunkEvent**: Emitido para cada chunk recebido durante respostas em streaming do LLM

## Estrutura dos Handlers de Evento

Cada handler de evento recebe dois parâmetros:

1. **source**: O objeto que emitiu o evento
2. **event**: A instância do evento, contendo dados específicos do evento

A estrutura do objeto de evento depende do tipo do evento, mas todos herdam de `BaseEvent` e incluem:

* **timestamp**: O horário em que o evento foi emitido
* **type**: Identificador do tipo do evento

Campos adicionais variam pelo tipo de evento. Por exemplo, `CrewKickoffCompletedEvent` inclui os campos `crew_name` e `output`.

## Exemplo Real: Integração com AgentOps

O CrewAI inclui um exemplo de integração com [AgentOps](https://github.com/AgentOps-AI/agentops), uma plataforma de monitoramento e observabilidade para agentes de IA. Veja como é implementado:

```python
from typing import Optional

from crewai.utilities.events import (
    CrewKickoffCompletedEvent,
    ToolUsageErrorEvent,
    ToolUsageStartedEvent,
)
from crewai.utilities.events.base_event_listener import BaseEventListener
from crewai.utilities.events.crew_events import CrewKickoffStartedEvent
from crewai.utilities.events.task_events import TaskEvaluationEvent

try:
    import agentops
    AGENTOPS_INSTALLED = True
except ImportError:
    AGENTOPS_INSTALLED = False

class AgentOpsListener(BaseEventListener):
    tool_event: Optional["agentops.ToolEvent"] = None
    session: Optional["agentops.Session"] = None

    def __init__(self):
        super().__init__()

    def setup_listeners(self, crewai_event_bus):
        if not AGENTOPS_INSTALLED:
            return

        @crewai_event_bus.on(CrewKickoffStartedEvent)
        def on_crew_kickoff_started(source, event: CrewKickoffStartedEvent):
            self.session = agentops.init()
            for agent in source.agents:
                if self.session:
                    self.session.create_agent(
                        name=agent.role,
                        agent_id=str(agent.id),
                    )

        @crewai_event_bus.on(CrewKickoffCompletedEvent)
        def on_crew_kickoff_completed(source, event: CrewKickoffCompletedEvent):
            if self.session:
                self.session.end_session(
                    end_state="Success",
                    end_state_reason="Finished Execution",
                )

        @crewai_event_bus.on(ToolUsageStartedEvent)
        def on_tool_usage_started(source, event: ToolUsageStartedEvent):
            self.tool_event = agentops.ToolEvent(name=event.tool_name)
            if self.session:
                self.session.record(self.tool_event)

        @crewai_event_bus.on(ToolUsageErrorEvent)
        def on_tool_usage_error(source, event: ToolUsageErrorEvent):
            agentops.ErrorEvent(exception=event.error, trigger_event=self.tool_event)
```

Esse listener inicializa uma sessão do AgentOps quando um Crew inicia, cadastra agentes no AgentOps, rastreia o uso de ferramentas e finaliza a sessão quando o Crew é concluído.

O listener AgentOps é registrado no sistema de eventos do CrewAI via importação em `src/crewai/utilities/events/third_party/__init__.py`:

```python
from .agentops_listener import agentops_listener
```

Isso garante que o `agentops_listener` seja carregado quando o pacote `crewai.utilities.events` for importado.

## Uso Avançado: Handlers Escopados

Para lidar temporariamente com eventos (útil para testes ou operações específicas), você pode usar o context manager `scoped_handlers`:

```python
from crewai.utilities.events import crewai_event_bus, CrewKickoffStartedEvent

with crewai_event_bus.scoped_handlers():
    @crewai_event_bus.on(CrewKickoffStartedEvent)
    def temp_handler(source, event):
        print("Este handler só existe neste contexto")

    # Faça algo que emita eventos

# Fora do contexto, o handler temporário é removido
```

## Casos de Uso

Listeners de evento podem ser usados para várias finalidades:

1. **Log e Monitoramento**: Monitore a execução do seu Crew e registre eventos importantes
2. **Analytics**: Colete dados sobre o desempenho e comportamento do seu Crew
3. **Depuração**: Configure listeners temporários para debugar problemas específicos
4. **Integração**: Conecte o CrewAI a sistemas externos como plataformas de monitoramento, bancos de dados ou serviços de notificação
5. **Comportamento Personalizado**: Dispare ações personalizadas com base em eventos específicos

## Boas Práticas

1. **Mantenha Handlers Leves**: Handlers de eventos devem ser leves e evitar operações bloqueantes
2. **Tratamento de Erros**: Implemente tratamento de erros adequado nos event handlers para evitar que exceções afetem a execução principal
3. **Limpeza**: Se seu listener alocar recursos, garanta o devido fechamento/liberação
4. **Escuta Seletiva**: Escute apenas eventos que realmente precisa tratar
5. **Testes**: Teste seus listeners de evento isoladamente para garantir que se comportam conforme esperado

Aproveitando o sistema de eventos do CrewAI, é possível estender a funcionalidade e integrá-lo facilmente à sua infraestrutura existente.


# Flows
Source: https://docs.crewai.com/pt-BR/concepts/flows

Saiba como criar e gerenciar fluxos de trabalho de IA usando CrewAI Flows.

## Visão Geral

O CrewAI Flows é um recurso poderoso projetado para simplificar a criação e o gerenciamento de fluxos de trabalho de IA. Os flows permitem que desenvolvedores combinem e coordenem tarefas de codificação e crews de forma eficiente, proporcionando uma estrutura robusta para a construção de automações de IA sofisticadas.

Os flows permitem que você crie fluxos de trabalho estruturados e orientados por eventos. Eles oferecem uma forma integrada de conectar múltiplas tarefas, gerenciar estado e controlar o fluxo de execução nas suas aplicações de IA. Com flows, você pode facilmente projetar e implementar processos de múltiplas etapas que exploram todo o potencial das capacidades do CrewAI.

1. **Criação Simplificada de Fluxos de Trabalho**: Conecte facilmente múltiplas crews e tarefas para criar workflows de IA complexos.

2. **Gerenciamento de Estado**: Flows facilitam muito o gerenciamento e o compartilhamento de estados entre diferentes tarefas do seu fluxo de trabalho.

3. **Arquitetura Orientada a Eventos**: Construído sobre um modelo orientado a eventos, permitindo fluxos dinâmicos e responsivos.

4. **Controle de Fluxo Flexível**: Implemente lógica condicional, loops e ramificações dentro dos seus fluxos.

## Primeiros Passos

Vamos criar um Flow simples no qual você usará a OpenAI para gerar uma cidade aleatória em uma tarefa e, em seguida, usará essa cidade para gerar uma curiosidade em outra tarefa.

```python Code
# (O código não é traduzido)
```

Na ilustração acima, criamos um Flow simples que gera uma cidade aleatória usando a OpenAI e depois cria uma curiosidade sobre essa cidade. O Flow consiste em duas tarefas: `generate_city` e `generate_fun_fact`. A tarefa `generate_city` é o ponto de início do Flow, enquanto a tarefa `generate_fun_fact` fica escutando o resultado da tarefa `generate_city`.

Cada instância de Flow recebe automaticamente um identificador único (UUID) em seu estado, que auxilia no rastreamento e gerenciamento das execuções. O estado também pode armazenar dados adicionais (como a cidade gerada e a curiosidade) que permanecem durante toda a execução do flow.

Ao executar o Flow, ele irá:

1. Gerar um ID único para o estado do flow
2. Gerar uma cidade aleatória e armazená-la no estado
3. Gerar uma curiosidade sobre essa cidade e armazená-la no estado
4. Imprimir os resultados no console

O ID único do estado e os dados armazenados podem ser úteis para rastrear execuções do flow e manter contexto entre as tarefas.

**Nota:** Certifique-se de configurar seu arquivo `.env` para armazenar sua `OPENAI_API_KEY`. Essa chave é necessária para autenticar as requisições à API da OpenAI.

### @start()

O decorador `@start()` é utilizado para marcar um método como ponto inicial de um Flow. Quando um Flow é iniciado, todos os métodos decorados com `@start()` são executados em paralelo. É possível ter múltiplos métodos start em um Flow, e todos eles serão executados quando o Flow iniciar.

### @listen()

O decorador `@listen()` é utilizado para marcar um método como ouvinte da saída de outra tarefa do Flow. O método decorado com `@listen()` será executado quando a tarefa especificada emitir uma saída. O método pode acessar a saída da tarefa à qual está escutando como argumento.

#### Utilização

O decorador `@listen()` pode ser usado de várias formas:

1. **Escutando um Método pelo Nome**: Você pode passar o nome do método ao qual deseja escutar como string. Quando esse método concluir, o método ouvinte será chamado.

   ```python Code
   # (O código não é traduzido)
   ```

2. **Escutando um Método Diretamente**: Você pode passar o próprio método. Quando esse método concluir, o método ouvinte será chamado.
   ```python Code
   # (O código não é traduzido)
   ```

### Saída de um Flow

Acessar e manipular a saída de um Flow é essencial para integrar seus workflows de IA a aplicações ou sistemas maiores. O CrewAI Flows fornece mecanismos fáceis para recuperar a saída final, acessar resultados intermediários e gerenciar o estado geral do seu Flow.

#### Recuperando a Saída Final

Ao executar um Flow, a saída final é determinada pelo último método concluído. O método `kickoff()` retorna a saída desse método final.

Veja como acessar a saída final:

<CodeGroup>
  ```python Code
  # (O código não é traduzido)
  ```

  ```text Output
  ---- Final Output ----
  Second method received: Output from first_method
  ```
</CodeGroup>

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-2.png)

Neste exemplo, o `second_method` é o último método a ser concluído, logo sua saída será a saída final do Flow.
O método `kickoff()` retorna essa saída, que é impressa no console. O método `plot()` irá gerar o arquivo HTML para visualizar o fluxo.

#### Acessando e Atualizando o Estado

Além de recuperar a saída final, você pode acessar e atualizar o estado dentro do seu Flow. O estado pode ser usado para armazenar e compartilhar dados entre diferentes métodos do Flow. Após a execução do Flow, você pode acessar o estado para recuperar informações adicionadas ou alteradas durante o processo.

Veja um exemplo de como atualizar e acessar o estado:

<CodeGroup>
  ```python Code
  # (O código não é traduzido)
  ```

  ```text Output
  Final Output: Hello from first_method - updated by second_method
  Final State:
  counter=2 message='Hello from first_method - updated by second_method'
  ```
</CodeGroup>

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-2.png)

Neste exemplo, o estado é atualizado tanto por `first_method` quanto por `second_method`.
Após o término da execução, é possível acessar o estado final e observar as atualizações realizadas por esses métodos.

Ao garantir que a saída do método final seja retornada e oferecer acesso ao estado, o CrewAI Flows facilita a integração dos resultados dos seus workflows de IA em aplicações maiores,
além de permitir o gerenciamento e o acesso ao estado durante toda a execução do Flow.

## Gerenciamento de Estado em Flows

Gerenciar o estado de forma eficaz é fundamental para construir fluxos de trabalho de IA confiáveis e de fácil manutenção. O CrewAI Flows oferece mecanismos robustos para o gerenciamento de estado tanto não estruturado quanto estruturado,
permitindo que o desenvolvedor escolha a abordagem que melhor se adapta à sua aplicação.

### Gerenciamento de Estado Não Estruturado

No gerenciamento de estado não estruturado, todo o estado é armazenado no atributo `state` da classe `Flow`.
Essa abordagem oferece flexibilidade, permitindo que o desenvolvedor adicione ou modifique atributos do estado conforme necessário sem precisar definir um esquema rígido.
Mesmo com estados não estruturados, os flows do CrewAI geram e mantêm automaticamente um identificador único (UUID) para cada instância de estado.

```python Code
# (O código não é traduzido)
```

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-3.png)

**Nota:** O campo `id` é gerado e preservado automaticamente durante toda a execução do flow. Não é necessário gerenciá-lo ou defini-lo manualmente, e ele permanecerá mesmo ao atualizar o estado com novos dados.

**Pontos-Chave:**

* **Flexibilidade:** É possível adicionar atributos dinamicamente ao `self.state` sem restrições pré-definidas.
* **Simplicidade:** Ideal para fluxos de trabalho diretos em que a estrutura do estado é mínima ou varia bastante.

### Gerenciamento de Estado Estruturado

No gerenciamento de estado estruturado, utilizam-se esquemas pré-definidos para garantir consistência e segurança de tipos em todo o workflow.
Ao usar modelos como o `BaseModel` da Pydantic, os desenvolvedores podem definir a forma exata do estado, melhorando a validação e fornecendo auto-complete nos ambientes de desenvolvimento.

Cada estado nos flows do CrewAI recebe automaticamente um identificador único (UUID) para ajudar no rastreamento e gerenciamento. Esse ID é gerado e mantido automaticamente pelo sistema de flows.

```python Code
# (O código não é traduzido)
```

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-3.png)

**Pontos-Chave:**

* **Esquema Definido:** `ExampleState` deixa claro a estrutura do estado, aumentando a legibilidade e a manutenção do código.
* **Segurança de Tipos:** O uso da Pydantic garante que os atributos do estado tenham os tipos certos, reduzindo os erros em tempo de execução.
* **Auto-Completar:** IDEs conseguem oferecer auto-completar e checagem de erros, graças ao modelo definido do estado.

### Escolhendo entre Estado Não Estruturado e Estruturado

* **Use Estado Não Estruturado quando:**
  * O estado do fluxo é simples ou altamente dinâmico.
  * Flexibilidade é mais importante do que uma definição rígida do estado.
  * Prototipagem rápida é necessária sem a sobrecarga de definição de esquemas.

* **Use Estado Estruturado quando:**
  * O flow exige uma estrutura de estado bem definida e consistente.
  * Segurança de tipos e validação são importantes para a confiabilidade da aplicação.
  * É desejado usar recursos da IDE como auto-completar e checagem de tipos para uma melhor experiência de desenvolvimento.

Ao oferecer as duas opções de gerenciamento de estado, o CrewAI Flows permite que desenvolvedores criem fluxos de IA que sejam ao mesmo tempo flexíveis e robustos, atendendo a uma ampla variedade de requisitos de aplicação.

## Persistência de Flow

O decorador @persist permite a persistência automática do estado nos flows do CrewAI, garantindo que você mantenha o estado do flow entre reinicializações ou execuções diferentes do workflow. Esse decorador pode ser aplicado tanto ao nível de classe, quanto ao nível de método, oferecendo flexibilidade sobre como gerenciar a persistência do estado.

### Persistência no Nível de Classe

Quando aplicado no nível da classe, o decorador @persist garante a persistência automática de todos os estados dos métodos do flow:

```python
# (O código não é traduzido)
```

### Persistência no Nível de Método

Para um controle mais granular, você pode aplicar @persist em métodos específicos:

```python
# (O código não é traduzido)
```

### Como Funciona

1. **Identificação Única do Estado**
   * Cada estado do flow recebe automaticamente um UUID único
   * O ID é preservado entre atualizações do estado e chamadas de métodos
   * Suporta tanto estados estruturados (Pydantic BaseModel) quanto não estruturados (dicionário)

2. **Backend SQLite Padrão**
   * O SQLiteFlowPersistence é o backend de armazenamento padrão
   * Os estados são salvos automaticamente em um banco de dados SQLite local
   * O tratamento de erros é robusto, oferecendo mensagens claras caso ocorram falhas nas operações de banco de dados

3. **Tratamento de Erros**
   * Mensagens de erro abrangentes para operações de banco de dados
   * Validação automática do estado ao salvar e carregar
   * Feedback claro quando houver problemas de persistência

### Considerações Importantes

* **Tipos de Estado**: São suportados tanto estados estruturados (Pydantic BaseModel) quanto não estruturados (dicionário)
* **ID Automático**: O campo `id` é adicionado automaticamente se não estiver presente
* **Recuperação de Estado**: Flows que falharem ou forem reiniciados podem recarregar automaticamente seu estado anterior
* **Implementação Personalizada**: Você pode fornecer sua própria implementação de FlowPersistence para necessidades de armazenamento especializadas

### Vantagens Técnicas

1. **Controle Preciso Através de Acesso de Baixo Nível**
   * Acesso direto às operações de persistência para casos avançados
   * Controle detalhado via decoradores de persistência no nível do método
   * Inspeção de estado e recursos de depuração embutidos
   * Visibilidade total das mudanças e operações de persistência do estado

2. **Maior Confiabilidade**
   * Recuperação automática do estado após falhas no sistema ou reinicializações
   * Atualizações de estado baseadas em transações para garantir integridade dos dados
   * Mensagens de erro abrangentes e claras
   * Validação robusta durante operações de salvar e carregar estado

3. **Arquitetura Extensível**
   * Backend de persistência personalizável através da interface FlowPersistence
   * Suporte para soluções de armazenamento especializadas além do SQLite
   * Compatibilidade tanto com estados estruturados (Pydantic) quanto não estruturados (dict)
   * Integração perfeita com os padrões de flow existentes no CrewAI

A arquitetura de persistência enfatiza precisão técnica e opções de personalização, permitindo que desenvolvedores mantenham controle total sobre o gerenciamento de estado enquanto se beneficiam dos recursos de confiabilidade integrados.

## Controle de Flow

### Lógica Condicional: `or`

A função `or_` nos flows permite escutar múltiplos métodos e acionar o método ouvinte quando qualquer um dos métodos especificados gerar uma saída.

<CodeGroup>
  ```python Code
  # (O código não é traduzido)
  ```

  ```text Output
  Logger: Hello from the start method
  Logger: Hello from the second method
  ```
</CodeGroup>

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-4.png)

Ao executar esse Flow, o método `logger` será acionado pela saída tanto do `start_method` quanto do `second_method`.
A função `or_` serve para escutar vários métodos e disparar o método ouvinte quando qualquer um emitir um resultado.

### Lógica Condicional: `and`

A função `and_` nos flows permite escutar múltiplos métodos e acionar o método ouvinte apenas quando todos os métodos especificados emitirem uma saída.

<CodeGroup>
  ```python Code
  # (O código não é traduzido)
  ```

  ```text Output
  ---- Logger ----
  {'greeting': 'Hello from the start method', 'joke': 'What do computers eat? Microchips.'}
  ```
</CodeGroup>

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-5.png)

Ao executar esse Flow, o método `logger` só será disparado quando ambos `start_method` e `second_method` emitirem uma saída.
A função `and_` é usada para escutar vários métodos e acionar o método ouvinte apenas quando todas as condições forem atendidas.

### Router

O decorador `@router()` nos flows permite definir lógica de roteamento condicional baseada na saída de um método.
Você pode especificar diferentes rotas conforme a saída do método, permitindo controlar o fluxo de execução de forma dinâmica.

<CodeGroup>
  ```python Code
  # (O código não é traduzido)
  ```

  ```text Output
  Starting the structured flow
  Third method running
  Fourth method running
  ```
</CodeGroup>

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-6.png)

No exemplo, o `start_method` gera um valor booleano aleatório e armazena no estado.
O `second_method` usa o decorador `@router()` para decidir o roteamento conforme o valor booleano.
Se o valor for `True`, retorna `"success"`, senão retorna `"failed"`.
Os métodos `third_method` e `fourth_method` escutam a saída do `second_method` e executam com base no valor retornado.

Ao executar esse Flow, a saída será diferente dependendo do valor booleano aleatório gerado pelo `start_method`.

## Adicionando Agentes aos Flows

Os agentes podem ser integrados facilmente aos seus flows, oferecendo uma alternativa leve às crews completas quando você precisar executar tarefas simples e focadas. Veja um exemplo de como utilizar um agente em um flow para realizar uma pesquisa de mercado:

```python
# (O código não é traduzido)
```

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-7.png)

Esse exemplo demonstra diversos recursos fundamentais do uso de agentes em flows:

1. **Saída Estruturada**: O uso de modelos Pydantic para definir o formato esperado da saída (`MarketAnalysis`) garante segurança de tipos e dados estruturados em todo o flow.

2. **Gerenciamento de Estado**: O estado do flow (`MarketResearchState`) mantém o contexto entre as etapas e armazena entradas e saídas.

3. **Integração de Ferramentas**: Os agentes podem usar ferramentas (como `WebsiteSearchTool`) para potencializar suas habilidades.

## Adicionando Crews aos Flows

Criar um flow com múltiplas crews no CrewAI é simples.

Você pode gerar um novo projeto CrewAI que já inclui toda a estrutura para criar um flow com várias crews executando o seguinte comando:

```bash
crewai create flow name_of_flow
```

Esse comando irá gerar um novo projeto CrewAI com a estrutura de pastas necessária. O projeto gerado inclui uma crew pré-criada chamada `poem_crew`, já funcional. Você pode usar essa crew como modelo, copiando, colando e editando para criar outras crews.

### Estrutura de Pastas

Após rodar o comando `crewai create flow name_of_flow`, você verá uma estrutura parecida com:

| Diretório/Arquivo      | Descrição                                                  |
| :--------------------- | :--------------------------------------------------------- |
| `name_of_flow/`        | Diretório raiz do flow.                                    |
| ├── `crews/`           | Contém diretórios para crews específicas.                  |
| │ └── `poem_crew/`     | Diretório da "poem\_crew" com configurações e scripts.     |
| │ ├── `config/`        | Arquivos de configuração da "poem\_crew".                  |
| │ │ ├── `agents.yaml`  | YAML que define os agentes da "poem\_crew".                |
| │ │ └── `tasks.yaml`   | YAML que define as tarefas da "poem\_crew".                |
| │ ├── `poem_crew.py`   | Script da funcionalidade da "poem\_crew".                  |
| ├── `tools/`           | Ferramentas adicionais usadas no flow.                     |
| │ └── `custom_tool.py` | Implementação de ferramenta customizada.                   |
| ├── `main.py`          | Script principal do flow.                                  |
| ├── `README.md`        | Descrição do projeto e instruções.                         |
| ├── `pyproject.toml`   | Arquivo de configurações e dependências do projeto.        |
| └── `.gitignore`       | Arquivos e pastas a serem ignorados no controle de versão. |

### Construindo suas Crews

Na pasta `crews`, você pode definir múltiplas crews. Cada crew tem sua própria pasta, com arquivos de configuração e o arquivo de definição da crew. Por exemplo, a pasta `poem_crew` contém:

* `config/agents.yaml`: Define os agentes da crew.
* `config/tasks.yaml`: Define as tarefas da crew.
* `poem_crew.py`: Contém a definição da crew, incluindo agentes, tarefas, etc.

Você pode copiar, colar e editar a `poem_crew` para criar outras crews.

### Conectando Crews no `main.py`

No arquivo `main.py`, você cria seu flow e conecta as crews. É possível definir o fluxo usando a classe `Flow` e os decoradores `@start` e `@listen` para definir a ordem de execução.

Veja um exemplo de como conectar a `poem_crew` no arquivo `main.py`:

```python Code
# (O código não é traduzido)
```

Neste exemplo, a classe `PoemFlow` define um fluxo que gera a quantidade de frases, usa a `PoemCrew` para gerar um poema e, depois, salva o poema em um arquivo. O flow inicia com o método `kickoff()`, e o gráfico é gerado pelo método `plot()`.

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-8.png)

### Executando o Flow

(Opcional) Antes de rodar o flow, instale as dependências executando:

```bash
crewai install
```

Após instalar as dependências, ative o ambiente virtual com:

```bash
source .venv/bin/activate
```

Com o ambiente ativado, execute o flow usando um dos comandos:

```bash
crewai flow kickoff
```

ou

```bash
uv run kickoff
```

O flow será executado, e você verá a saída no console.

## Plotando Flows

Visualizar seus fluxos de trabalho de IA proporciona insights valiosos sobre a estrutura e os caminhos de execução dos flows. O CrewAI oferece uma ferramenta de visualização poderosa que permite gerar plots interativos dos flows, facilitando o entendimento e a otimização dos workflows de IA.

### O que são Plots?

No CrewAI, plots são representações gráficas dos fluxos de trabalho de IA. Eles mostram as tarefas, suas conexões e o fluxo de dados entre elas. Essa visualização ajuda a compreender a sequência de operações, identificar gargalos e garantir que a lógica do workflow está alinhada com o esperado.

### Como Gerar um Plot

O CrewAI oferece duas formas práticas de gerar plots dos seus flows:

#### Opção 1: Usando o método `plot()`

Se estiver trabalhando diretamente com uma instância do flow, basta chamar o método `plot()` do objeto. Isso criará um arquivo HTML com o plot interativo do seu flow.

```python Code
# (O código não é traduzido)
```

Esse comando gera um arquivo chamado `my_flow_plot.html` no diretório atual. Abra esse arquivo em um navegador para visualizar o plot interativo.

#### Opção 2: Usando a Linha de Comando

Em projetos CrewAI estruturados, é possível gerar um plot pela linha de comando. Isso é útil para projetos maiores, onde você deseja visualizar toda a configuração do flow.

```bash
crewai flow plot
```

O comando gera um arquivo HTML com o plot do flow, semelhante ao método `plot()`. Basta abrir o arquivo no navegador para explorar o workflow.

### Entendendo o Plot

O plot gerado mostra nós representando as tarefas do seu flow, com setas indicando o fluxo de execução. A visualização é interativa, permitindo zoom, navegação e detalhes ao passar o mouse nos nós.

Ao visualizar seus flows, você tem clareza do formato do workflow, facilitando debug, otimização e comunicação dos seus processos de IA para outras pessoas.

### Conclusão

A plotagem dos flows é um recurso poderoso do CrewAI para aprimorar o design e o gerenciamento de fluxos de IA complexos. Usando o método `plot()` ou a linha de comando, você obtém uma visão visual dos workflows, benefício tanto para desenvolvimento quanto para apresentação.

## Próximos Passos

Se você deseja explorar exemplos adicionais de flows, acompanhe alguns exemplos em nosso repositório de exemplos. Aqui estão quatro sugestões específicas de flows, cada uma demonstrando casos de uso distintos para você escolher conforme seu problema:

1. **Email Auto Responder Flow**: Este exemplo demonstra um loop infinito, onde um job de background roda continuamente automatizando respostas de email. É ideal para tarefas rotineiras sem intervenção manual. [Ver Exemplo](https://github.com/crewAIInc/crewAI-examples/tree/main/email_auto_responder_flow)

2. **Lead Score Flow**: Destaca como adicionar feedback humano e manipular diferentes ramos condicionais usando router. Um ótimo aprendizado para workflows com decisão dinâmica e supervisão humana. [Ver Exemplo](https://github.com/crewAIInc/crewAI-examples/tree/main/lead-score-flow)

3. **Write a Book Flow**: Exemplo ideal para encadear múltiplas crews, onde a saída de uma é usada por outra. Uma crew faz um sumário do livro inteiro, outra gera capítulos... Tudo conectado para entregar um livro completo. Perfeito para processos longos e coordenados. [Ver Exemplo](https://github.com/crewAIInc/crewAI-examples/tree/main/write_a_book_with_flows)

4. **Meeting Assistant Flow**: Demonstra como transmitir um evento para desencadear múltiplas ações posteriores. Exemplo: ao finalizar uma reunião, atualizar um Trello, enviar mensagem no Slack e salvar resultados ao mesmo tempo. Indicado para gerenciamento completo de tarefas e notificações. [Ver Exemplo](https://github.com/crewAIInc/crewAI-examples/tree/main/meeting_assistant_flow)

Explore esses exemplos para descobrir como aproveitar CrewAI Flows em diferentes contextos – desde automação de tarefas repetitivas até o gerenciamento de processos dinâmicos com decisões e feedback humano.

Além disso, confira nosso vídeo no YouTube sobre como utilizar flows no CrewAI abaixo!

<iframe width="560" height="315" src="https://www.youtube.com/embed/MTb5my6VOT8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen />

## Executando Flows

Existem duas formas de executar um flow:

### Usando a API do Flow

Você pode executar um flow programaticamente criando uma instância da sua classe de flow e chamando o método `kickoff()`:

```python
# Exemplo de execução de flow em português
flow = ExemploFlow()
resultado = flow.kickoff()
```

### Usando a CLI

A partir da versão 0.103.0, é possível executar flows usando o comando `crewai run`:

```shell
crewai run
```

O comando detecta automaticamente se seu projeto é um flow (com base na configuração `type = "flow"` no pyproject.toml) e executa conforme o esperado. Esse é o método recomendado para executar flows pelo terminal.

Por compatibilidade retroativa, também é possível usar:

```shell
crewai flow kickoff
```

No entanto, o comando `crewai run` é agora o preferido, pois funciona tanto para crews quanto para flows.


# Knowledge
Source: https://docs.crewai.com/pt-BR/concepts/knowledge

O que é knowledge em CrewAI e como usá-lo.

## Visão Geral

Knowledge no CrewAI é um sistema poderoso que permite que agentes de IA acessem e utilizem fontes de informação externas durante suas tarefas.
Pense nisso como dar aos seus agentes uma biblioteca de referência que eles podem consultar enquanto trabalham.

<Info>
  Principais benefícios de usar Knowledge:

  * Aprimorar agentes com informações específicas do domínio
  * Apoiar decisões com dados do mundo real
  * Manter contexto entre conversas
  * Fundamentar respostas em informações factuais
</Info>

## Exemplos de Início Rápido

<Tip>
  Para Fontes de Knowledge baseadas em arquivos, certifique-se de colocar seus arquivos em um diretório `knowledge` na raiz do seu projeto.
  Além disso, use caminhos relativos do diretório `knowledge` ao criar a fonte.
</Tip>

### Exemplo Básico de Knowledge com String

```python Code
from crewai import Agent, Task, Crew, Process, LLM
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# Create a knowledge source
content = "Users name is John. He is 30 years old and lives in San Francisco."
string_source = StringKnowledgeSource(content=content)

# Create an LLM with a temperature of 0 to ensure deterministic outputs
llm = LLM(model="gpt-4o-mini", temperature=0)

# Create an agent with the knowledge store
agent = Agent(
    role="Sobre o Usuário",
    goal="Você sabe tudo sobre o usuário.",
    backstory="Você é mestre em entender pessoas e suas preferências.",
    verbose=True,
    allow_delegation=False,
    llm=llm,
)

task = Task(
    description="Responda às seguintes perguntas sobre o usuário: {question}",
    expected_output="Uma resposta para a pergunta.",
    agent=agent,
)

crew = Crew(
    agents=[agent],
    tasks=[task],
    verbose=True,
    process=Process.sequential,
    knowledge_sources=[string_source], # Enable knowledge by adding the sources here
)

result = crew.kickoff(inputs={"question": "What city does John live in and how old is he?"})
```

### Exemplo de Knowledge com Conteúdo Web

<Note>
  Você precisa instalar `docling` para o seguinte exemplo funcionar: `uv add docling`
</Note>

```python Code
from crewai import LLM, Agent, Crew, Process, Task
from crewai.knowledge.source.crew_docling_source import CrewDoclingSource

# Create a knowledge source from web content
content_source = CrewDoclingSource(
    file_paths=[
        "https://lilianweng.github.io/posts/2024-11-28-reward-hacking",
        "https://lilianweng.github.io/posts/2024-07-07-hallucination",
    ],
)

# Create an LLM with a temperature of 0 to ensure deterministic outputs
llm = LLM(model="gpt-4o-mini", temperature=0)

# Create an agent with the knowledge store
agent = Agent(
    role="Sobre artigos",
    goal="Você sabe tudo sobre os artigos.",
    backstory="Você é mestre em entender artigos e seus conteúdos.",
    verbose=True,
    allow_delegation=False,
    llm=llm,
)

task = Task(
    description="Responda às seguintes perguntas sobre os artigos: {question}",
    expected_output="Uma resposta para a pergunta.",
    agent=agent,
)

crew = Crew(
    agents=[agent],
    tasks=[task],
    verbose=True,
    process=Process.sequential,
    knowledge_sources=[content_source],
)

result = crew.kickoff(
    inputs={"question": "What is the reward hacking paper about? Be sure to provide sources."}
)
```

## Fontes de Knowledge Suportadas

O CrewAI suporta vários tipos de fontes de knowledge prontas para uso:

<CardGroup cols={2}>
  <Card title="Fontes de Texto" icon="text">
    * Strings brutas
    * Arquivos de texto (.txt)
    * Documentos PDF
  </Card>

  <Card title="Dados Estruturados" icon="table">
    * Arquivos CSV
    * Planilhas Excel
    * Documentos JSON
  </Card>
</CardGroup>

### Fonte de Knowledge de Arquivo de Texto

```python
from crewai.knowledge.source.text_file_knowledge_source import TextFileKnowledgeSource

text_source = TextFileKnowledgeSource(
    file_paths=["document.txt", "another.txt"]
)
```

### Fonte de Knowledge PDF

```python
from crewai.knowledge.source.pdf_knowledge_source import PDFKnowledgeSource

pdf_source = PDFKnowledgeSource(
    file_paths=["document.pdf", "another.pdf"]
)
```

### Fonte de Knowledge CSV

```python
from crewai.knowledge.source.csv_knowledge_source import CSVKnowledgeSource

csv_source = CSVKnowledgeSource(
    file_paths=["data.csv"]
)
```

### Fonte de Knowledge Excel

```python
from crewai.knowledge.source.excel_knowledge_source import ExcelKnowledgeSource

excel_source = ExcelKnowledgeSource(
    file_paths=["spreadsheet.xlsx"]
)
```

### Fonte de Knowledge JSON

```python
from crewai.knowledge.source.json_knowledge_source import JSONKnowledgeSource

json_source = JSONKnowledgeSource(
    file_paths=["data.json"]
)
```

<Note>
  Certifique-se de criar a pasta ./knowledge. Todos os arquivos de origem (ex: .txt, .pdf, .xlsx, .json) devem ser colocados nesta pasta para gerenciamento centralizado.
</Note>

## Knowledge de Agente vs Crew: Guia Completo

<Info>
  **Entendendo os Níveis de Knowledge**: O CrewAI suporta knowledge tanto no nível de agente quanto de crew. Esta seção esclarece exatamente como cada um funciona, quando são inicializados, e aborda equívocos comuns sobre dependências.
</Info>

### Como a Inicialização de Knowledge Realmente Funciona

Aqui está exatamente o que acontece quando você usa knowledge:

#### Knowledge no Nível do Agente (Independente)

```python
from crewai import Agent, Task, Crew
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# Agent with its own knowledge - NO crew knowledge needed
specialist_knowledge = StringKnowledgeSource(
    content="Specialized technical information for this agent only"
)

specialist_agent = Agent(
    role="Especialista Técnico",
    goal="Fornecer expertise técnica",
    backstory="Especialista em domínios técnicos especializados",
    knowledge_sources=[specialist_knowledge]  # Conhecimento específico do agente
)

task = Task(
    description="Responda perguntas técnicas",
    agent=specialist_agent,
    expected_output="Resposta técnica"
)

# No crew-level knowledge required
crew = Crew(
    agents=[specialist_agent],
    tasks=[task]
)

result = crew.kickoff()  # Agent knowledge works independently
```

#### O Que Acontece Durante `crew.kickoff()`

Quando você chama `crew.kickoff()`, aqui está a sequência exata:

```python
# During kickoff
for agent in self.agents:
    agent.crew = self  # Agent gets reference to crew
    agent.set_knowledge(crew_embedder=self.embedder)  # Agent knowledge initialized
    agent.create_agent_executor()
```

#### Independência de Armazenamento

Cada nível de knowledge usa coleções de armazenamento independentes:

```python
# Agent knowledge storage
agent_collection_name = agent.role  # e.g., "Especialista Técnico"

# Crew knowledge storage
crew_collection_name = "crew"

# Both stored in same ChromaDB instance but different collections
# Path: ~/.local/share/CrewAI/{project}/knowledge/
#   ├── crew/                    # Crew knowledge collection
#   ├── Especialista Técnico/    # Agent knowledge collection
#   └── Another Agent Role/      # Another agent's collection
```

### Exemplos Completos Funcionais

#### Exemplo 1: Knowledge Apenas do Agente

```python
from crewai import Agent, Task, Crew
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# Agent-specific knowledge
agent_knowledge = StringKnowledgeSource(
    content="Agent-specific information that only this agent needs"
)

agent = Agent(
    role="Especialista",
    goal="Use specialized knowledge",
    backstory="Expert with specific knowledge",
    knowledge_sources=[agent_knowledge],
    embedder={  # Agent can have its own embedder
        "provider": "openai",
        "config": {"model": "text-embedding-3-small"}
    }
)

task = Task(
    description="Answer using your specialized knowledge",
    agent=agent,
    expected_output="Answer based on agent knowledge"
)

# No crew knowledge needed
crew = Crew(agents=[agent], tasks=[task])
result = crew.kickoff()  # Works perfectly
```

#### Exemplo 2: Knowledge Tanto do Agente Quanto da Crew

```python
# Crew-wide knowledge (shared by all agents)
crew_knowledge = StringKnowledgeSource(
    content="Company policies and general information for all agents"
)

# Agent-specific knowledge
specialist_knowledge = StringKnowledgeSource(
    content="Technical specifications only the specialist needs"
)

specialist = Agent(
    role="Especialista Técnico",
    goal="Fornecer expertise técnica",
    backstory="Especialista em domínios técnicos especializados",
    knowledge_sources=[specialist_knowledge]  # Conhecimento específico do agente
)

generalist = Agent(
    role="General Assistant",
    goal="Provide general assistance",
    backstory="General helper"
    # No agent-specific knowledge
)

crew = Crew(
    agents=[specialist, generalist],
    tasks=[...],
    knowledge_sources=[crew_knowledge]  # Crew-wide knowledge
)

# Result:
# - specialist gets: crew_knowledge + specialist_knowledge
# - generalist gets: crew_knowledge only
```

#### Exemplo 3: Múltiplos Agentes com Knowledge Diferente

```python
# Different knowledge for different agents
sales_knowledge = StringKnowledgeSource(content="Sales procedures and pricing")
tech_knowledge = StringKnowledgeSource(content="Technical documentation")
support_knowledge = StringKnowledgeSource(content="Support procedures")

sales_agent = Agent(
    role="Sales Representative",
    knowledge_sources=[sales_knowledge],
    embedder={"provider": "openai", "config": {"model": "text-embedding-3-small"}}
)

tech_agent = Agent(
    role="Technical Expert",
    knowledge_sources=[tech_knowledge],
    embedder={"provider": "ollama", "config": {"model": "mxbai-embed-large"}}
)

support_agent = Agent(
    role="Support Specialist",
    knowledge_sources=[support_knowledge]
    # Will use crew embedder as fallback
)

crew = Crew(
    agents=[sales_agent, tech_agent, support_agent],
    tasks=[...],
    embedder={  # Fallback embedder for agents without their own
        "provider": "google",
        "config": {"model": "text-embedding-004"}
    }
)

# Each agent gets only their specific knowledge
# Each can use different embedding providers
```

<Tip>
  Diferente da recuperação de um banco de dados vetorial usando uma ferramenta, agentes pré-carregados com knowledge não precisarão de uma persona de recuperação ou tarefa.
  Simplesmente adicione as fontes de knowledge relevantes que seu agente ou crew precisa para funcionar.

  As fontes de knowledge podem ser adicionadas no nível do agente ou da crew.
  As fontes de knowledge no nível da crew serão usadas por **todos os agentes** na crew.
  As fontes de knowledge no nível do agente serão usadas pelo **agente específico** que é pré-carregado com o knowledge.
</Tip>

## Configuração de Knowledge

Você pode configurar a configuração de knowledge para a crew ou agente.

```python Code
from crewai.knowledge.knowledge_config import KnowledgeConfig

knowledge_config = KnowledgeConfig(results_limit=10, score_threshold=0.5)

agent = Agent(
    ...
    knowledge_config=knowledge_config
)
```

<Tip>
  `results_limit`: é o número de documentos relevantes a retornar. Padrão é 3.
  `score_threshold`: é a pontuação mínima para um documento ser considerado relevante. Padrão é 0.35.
</Tip>

## Parâmetros de Knowledge Suportados

<ParamField body="sources" type="List[BaseKnowledgeSource]" required="Yes">
  Lista de fontes de knowledge que fornecem conteúdo para ser armazenado e consultado. Pode incluir PDF, CSV, Excel, JSON, arquivos de texto ou conteúdo de string.
</ParamField>

<ParamField body="collection_name" type="str">
  Nome da coleção onde o knowledge será armazenado. Usado para identificar diferentes conjuntos de knowledge. Padrão é "knowledge" se não fornecido.
</ParamField>

<ParamField body="storage" type="Optional[KnowledgeStorage]">
  Configuração de armazenamento personalizada para gerenciar como o knowledge é armazenado e recuperado. Se não fornecido, um armazenamento padrão será criado.
</ParamField>

## Transparência do Armazenamento de Knowledge

<Info>
  **Entendendo o Armazenamento de Knowledge**: O CrewAI armazena automaticamente as fontes de knowledge em diretórios específicos da plataforma usando ChromaDB para armazenamento vetorial. Entender essas localizações e padrões ajuda com implantações de produção, depuração e gerenciamento de armazenamento.
</Info>

### Onde o CrewAI Armazena Arquivos de Knowledge

Por padrão, o CrewAI usa o mesmo sistema de armazenamento que a memória, armazenando knowledge em diretórios específicos da plataforma:

#### Localizações de Armazenamento Padrão por Plataforma

**macOS:**

```
~/Library/Application Support/CrewAI/{project_name}/
└── knowledge/                    # Knowledge ChromaDB files
    ├── chroma.sqlite3           # ChromaDB metadata
    ├── {collection_id}/         # Vector embeddings
    └── knowledge_{collection}/  # Named collections
```

**Linux:**

```
~/.local/share/CrewAI/{project_name}/
└── knowledge/
    ├── chroma.sqlite3
    ├── {collection_id}/
    └── knowledge_{collection}/
```

**Windows:**

```
C:\Users\{username}\AppData\Local\CrewAI\{project_name}\
└── knowledge\
    ├── chroma.sqlite3
    ├── {collection_id}\
    └── knowledge_{collection}\
```

### Encontrando Sua Localização de Armazenamento de Knowledge

Para ver exatamente onde o CrewAI está armazenando seus arquivos de knowledge:

```python
from crewai.utilities.paths import db_storage_path
import os

# Get the knowledge storage path
knowledge_path = os.path.join(db_storage_path(), "knowledge")
print(f"Knowledge storage location: {knowledge_path}")

# List knowledge collections and files
if os.path.exists(knowledge_path):
    print("\nKnowledge storage contents:")
    for item in os.listdir(knowledge_path):
        item_path = os.path.join(knowledge_path, item)
        if os.path.isdir(item_path):
            print(f"📁 Collection: {item}/")
            # Show collection contents
            try:
                for subitem in os.listdir(item_path):
                    print(f"   └── {subitem}")
            except PermissionError:
                print(f"   └── (permission denied)")
        else:
            print(f"📄 {item}")
else:
    print("No knowledge storage found yet.")
```

### Controlando Localizações de Armazenamento de Knowledge

#### Opção 1: Variável de Ambiente (Recomendado)

```python
import os
from crewai import Crew

# Set custom storage location for all CrewAI data
os.environ["CREWAI_STORAGE_DIR"] = "./my_project_storage"

# All knowledge will now be stored in ./my_project_storage/knowledge/
crew = Crew(
    agents=[...],
    tasks=[...],
    knowledge_sources=[...]
)
```

#### Opção 2: Armazenamento de Knowledge Personalizado

```python
from crewai.knowledge.storage.knowledge_storage import KnowledgeStorage
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# Create custom storage with specific embedder
custom_storage = KnowledgeStorage(
    embedder={
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    },
    collection_name="my_custom_knowledge"
)

# Use with knowledge sources
knowledge_source = StringKnowledgeSource(
    content="Your knowledge content here"
)
knowledge_source.storage = custom_storage
```

#### Opção 3: Armazenamento de Knowledge Específico do Projeto

```python
import os
from pathlib import Path

# Store knowledge in project directory
project_root = Path(__file__).parent
knowledge_dir = project_root / "knowledge_storage"

os.environ["CREWAI_STORAGE_DIR"] = str(knowledge_dir)

# Now all knowledge will be stored in your project directory
```

### Comportamento Padrão do Provedor de Embedding

<Info>
  **Provedor de Embedding Padrão**: O CrewAI usa por padrão embeddings da OpenAI (`text-embedding-3-small`) para armazenamento de knowledge, mesmo quando usa diferentes provedores de LLM. Você pode facilmente personalizar isso para corresponder à sua configuração.
</Info>

#### Entendendo o Comportamento Padrão

```python
from crewai import Agent, Crew, LLM
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# When using Claude as your LLM...
agent = Agent(
    role="Researcher",
    goal="Research topics",
    backstory="Expert researcher",
    llm=LLM(provider="anthropic", model="claude-3-sonnet")  # Using Claude
)

# CrewAI will still use OpenAI embeddings by default for knowledge
# This ensures consistency but may not match your LLM provider preference
knowledge_source = StringKnowledgeSource(content="Research data...")

crew = Crew(
    agents=[agent],
    tasks=[...],
    knowledge_sources=[knowledge_source]
    # Default: Uses OpenAI embeddings even with Claude LLM
)
```

#### Personalizando Provedores de Embedding de Knowledge

```python
# Option 1: Use Voyage AI (recommended by Anthropic for Claude users)
crew = Crew(
    agents=[agent],
    tasks=[...],
    knowledge_sources=[knowledge_source],
    embedder={
        "provider": "voyageai",  # Recommended for Claude users
        "config": {
            "api_key": "your-voyage-api-key",
            "model": "voyage-3"  # or "voyage-3-large" for best quality
        }
    }
)

# Option 2: Use local embeddings (no external API calls)
crew = Crew(
    agents=[agent],
    tasks=[...],
    knowledge_sources=[knowledge_source],
    embedder={
        "provider": "ollama",
        "config": {
            "model": "mxbai-embed-large",
            "url": "http://localhost:11434/api/embeddings"
        }
    }
)

# Option 3: Agent-level embedding customization
agent = Agent(
    role="Researcher",
    goal="Research topics",
    backstory="Expert researcher",
    knowledge_sources=[knowledge_source],
    embedder={
        "provider": "google",
        "config": {
            "model": "models/text-embedding-004",
            "api_key": "your-google-key"
        }
    }
)
```

#### Configurando Embeddings do Azure OpenAI

Ao usar embeddings do Azure OpenAI:

1. Certifique-se de implantar o modelo de embedding na plataforma Azure primeiro
2. Então você precisa usar a seguinte configuração:

```python
agent = Agent(
    role="Researcher",
    goal="Research topics",
    backstory="Expert researcher",
    knowledge_sources=[knowledge_source],
    embedder={
        "provider": "azure",
        "config": {
            "api_key": "your-azure-api-key",
            "model": "text-embedding-ada-002", # change to the model you are using and is deployed in Azure
            "api_base": "https://your-azure-endpoint.openai.azure.com/",
            "api_version": "2024-02-01"
        }
    }
)
```

## Recursos Avançados

### Reescrita de Consulta

O CrewAI implementa um mecanismo inteligente de reescrita de consulta para otimizar a recuperação de knowledge. Quando um agente precisa pesquisar nas fontes de knowledge, o prompt da tarefa bruto é automaticamente transformado em uma consulta de pesquisa mais eficaz.

#### Como a Reescrita de Consulta Funciona

1. Quando um agente executa uma tarefa com fontes de knowledge disponíveis, o método `_get_knowledge_search_query` é acionado
2. O LLM do agente é usado para transformar o prompt original da tarefa em uma consulta de pesquisa otimizada
3. Esta consulta otimizada é então usada para recuperar informações relevantes das fontes de knowledge

#### Benefícios da Reescrita de Consulta

<CardGroup cols={2}>
  <Card title="Precisão de Recuperação Melhorada" icon="bullseye-arrow">
    Ao focar em conceitos-chave e remover conteúdo irrelevante, a reescrita de consulta ajuda a recuperar informações mais relevantes.
  </Card>

  <Card title="Consciência de Contexto" icon="brain">
    As consultas reescritas são projetadas para ser mais específicas e conscientes do contexto para recuperação de banco de dados vetorial.
  </Card>
</CardGroup>

#### Exemplo

```python
# Original task prompt
task_prompt = "Answer the following questions about the user's favorite movies: What movie did John watch last week? Format your answer in JSON."

# Behind the scenes, this might be rewritten as:
rewritten_query = "What movies did John watch last week?"
```

A consulta reescrita é mais focada na necessidade de informação principal e remove instruções irrelevantes sobre formatação de saída.

<Tip>
  Este mecanismo é totalmente automático e não requer configuração dos usuários. O LLM do agente é usado para realizar a reescrita da consulta, então usar um LLM mais capaz pode melhorar a qualidade das consultas reescritas.
</Tip>

### Eventos de Knowledge

O CrewAI emite eventos durante o processo de recuperação de knowledge que você pode escutar usando o sistema de eventos. Esses eventos permitem que você monitore, depure e analise como o knowledge está sendo recuperado e usado pelos seus agentes.

#### Eventos de Knowledge Disponíveis

* **KnowledgeRetrievalStartedEvent**: Emitido quando um agente começa a recuperar knowledge das fontes
* **KnowledgeRetrievalCompletedEvent**: Emitido quando a recuperação de knowledge é concluída, incluindo a consulta usada e o conteúdo recuperado
* **KnowledgeQueryStartedEvent**: Emitido quando uma consulta às fontes de knowledge começa
* **KnowledgeQueryCompletedEvent**: Emitido quando uma consulta é concluída com sucesso
* **KnowledgeQueryFailedEvent**: Emitido quando uma consulta às fontes de knowledge falha
* **KnowledgeSearchQueryFailedEvent**: Emitido quando uma consulta de pesquisa falha

#### Exemplo: Monitorando Recuperação de Knowledge

```python
from crewai.utilities.events import (
    KnowledgeRetrievalStartedEvent,
    KnowledgeRetrievalCompletedEvent,
)
from crewai.utilities.events.base_event_listener import BaseEventListener

class KnowledgeMonitorListener(BaseEventListener):
    def setup_listeners(self, crewai_event_bus):
        @crewai_event_bus.on(KnowledgeRetrievalStartedEvent)
        def on_knowledge_retrieval_started(source, event):
            print(f"Agent '{event.agent.role}' started retrieving knowledge")

        @crewai_event_bus.on(KnowledgeRetrievalCompletedEvent)
        def on_knowledge_retrieval_completed(source, event):
            print(f"Agent '{event.agent.role}' completed knowledge retrieval")
            print(f"Query: {event.query}")
            print(f"Retrieved {len(event.retrieved_knowledge)} knowledge chunks")

# Create an instance of your listener
knowledge_monitor = KnowledgeMonitorListener()
```

Para mais informações sobre como usar eventos, consulte a documentação [Event Listeners](https://docs.crewai.com/concepts/event-listener).

### Fontes de Knowledge Personalizadas

O CrewAI permite que você crie fontes de knowledge personalizadas para qualquer tipo de dados estendendo a classe `BaseKnowledgeSource`. Vamos criar um exemplo prático que busca e processa artigos de notícias espaciais.

#### Exemplo de Fonte de Knowledge de Notícias Espaciais

<CodeGroup>
  ```python Code
  from crewai import Agent, Task, Crew, Process, LLM
  from crewai.knowledge.source.base_knowledge_source import BaseKnowledgeSource
  import requests
  from datetime import datetime
  from typing import Dict, Any
  from pydantic import BaseModel, Field

  class SpaceNewsKnowledgeSource(BaseKnowledgeSource):
      """Knowledge source that fetches data from Space News API."""

      api_endpoint: str = Field(description="API endpoint URL")
      limit: int = Field(default=10, description="Number of articles to fetch")

      def load_content(self) -> Dict[Any, str]:
          """Fetch and format space news articles."""
          try:
              response = requests.get(
                  f"{self.api_endpoint}?limit={self.limit}"
              )
              response.raise_for_status()

              data = response.json()
              articles = data.get('results', [])

              formatted_data = self.validate_content(articles)
              return {self.api_endpoint: formatted_data}
          except Exception as e:
              raise ValueError(f"Failed to fetch space news: {str(e)}")

      def validate_content(self, articles: list) -> str:
          """Format articles into readable text."""
          formatted = "Space News Articles:\n\n"
          for article in articles:
              formatted += f"""
                  Title: {article['title']}
                  Published: {article['published_at']}
                  Summary: {article['summary']}
                  News Site: {article['news_site']}
                  URL: {article['url']}
                  -------------------"""
          return formatted

      def add(self) -> None:
          """Process and store the articles."""
          content = self.load_content()
          for _, text in content.items():
              chunks = self._chunk_text(text)
              self.chunks.extend(chunks)

          self._save_documents()

  # Create knowledge source
  recent_news = SpaceNewsKnowledgeSource(
      api_endpoint="https://api.spaceflightnewsapi.net/v4/articles",
      limit=10,
  )

  # Create specialized agent
  space_analyst = Agent(
      role="Space News Analyst",
      goal="Answer questions about space news accurately and comprehensively",
      backstory="""You are a space industry analyst with expertise in space exploration,
      satellite technology, and space industry trends. You excel at answering questions
      about space news and providing detailed, accurate information.""",
      knowledge_sources=[recent_news],
      llm=LLM(model="gpt-4", temperature=0.0)
  )

  # Create task that handles user questions
  analysis_task = Task(
      description="Answer this question about space news: {user_question}",
      expected_output="A detailed answer based on the recent space news articles",
      agent=space_analyst
  )

  # Create and run the crew
  crew = Crew(
      agents=[space_analyst],
      tasks=[analysis_task],
      verbose=True,
      process=Process.sequential
  )

  # Example usage
  result = crew.kickoff(
      inputs={"user_question": "What are the latest developments in space exploration?"}
  )
  ```

  ```output Output
  # Agent: Space News Analyst
  ## Task: Answer this question about space news: What are the latest developments in space exploration?


  # Agent: Space News Analyst
  ## Final Answer:
  The latest developments in space exploration, based on recent space news articles, include the following:

  1. SpaceX has received the final regulatory approvals to proceed with the second integrated Starship/Super Heavy launch, scheduled for as soon as the morning of Nov. 17, 2023. This is a significant step in SpaceX's ambitious plans for space exploration and colonization. [Source: SpaceNews](https://spacenews.com/starship-cleared-for-nov-17-launch/)

  2. SpaceX has also informed the US Federal Communications Commission (FCC) that it plans to begin launching its first next-generation Starlink Gen2 satellites. This represents a major upgrade to the Starlink satellite internet service, which aims to provide high-speed internet access worldwide. [Source: Teslarati](https://www.teslarati.com/spacex-first-starlink-gen2-satellite-launch-2022/)

  3. AI startup Synthetaic has raised $15 million in Series B funding. The company uses artificial intelligence to analyze data from space and air sensors, which could have significant applications in space exploration and satellite technology. [Source: SpaceNews](https://spacenews.com/ai-startup-synthetaic-raises-15-million-in-series-b-funding/)

  4. The Space Force has formally established a unit within the U.S. Indo-Pacific Command, marking a permanent presence in the Indo-Pacific region. This could have significant implications for space security and geopolitics. [Source: SpaceNews](https://spacenews.com/space-force-establishes-permanent-presence-in-indo-pacific-region/)

  5. Slingshot Aerospace, a space tracking and data analytics company, is expanding its network of ground-based optical telescopes to increase coverage of low Earth orbit. This could improve our ability to track and analyze objects in low Earth orbit, including satellites and space debris. [Source: SpaceNews](https://spacenews.com/slingshots-space-tracking-network-to-extend-coverage-of-low-earth-orbit/)

  6. The National Natural Science Foundation of China has outlined a five-year project for researchers to study the assembly of ultra-large spacecraft. This could lead to significant advancements in spacecraft technology and space exploration capabilities. [Source: SpaceNews](https://spacenews.com/china-researching-challenges-of-kilometer-scale-ultra-large-spacecraft/)

  7. The Center for AEroSpace Autonomy Research (CAESAR) at Stanford University is focusing on spacecraft autonomy. The center held a kickoff event on May 22, 2024, to highlight the industry, academia, and government collaboration it seeks to foster. This could lead to significant advancements in autonomous spacecraft technology. [Source: SpaceNews](https://spacenews.com/stanford-center-focuses-on-spacecraft-autonomy/)
  ```
</CodeGroup>

## Depuração e Solução de Problemas

### Depurando Problemas de Knowledge

#### Verificar Inicialização de Knowledge do Agente

```python
from crewai import Agent, Crew, Task
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

knowledge_source = StringKnowledgeSource(content="Test knowledge")

agent = Agent(
    role="Test Agent",
    goal="Test knowledge",
    backstory="Testing",
    knowledge_sources=[knowledge_source]
)

crew = Crew(agents=[agent], tasks=[Task(...)])

# Before kickoff - knowledge not initialized
print(f"Before kickoff - Agent knowledge: {getattr(agent, 'knowledge', None)}")

crew.kickoff()

# After kickoff - knowledge initialized
print(f"After kickoff - Agent knowledge: {agent.knowledge}")
print(f"Agent knowledge collection: {agent.knowledge.storage.collection_name}")
print(f"Number of sources: {len(agent.knowledge.sources)}")
```

#### Verificar Localizações de Armazenamento de Knowledge

```python
import os
from crewai.utilities.paths import db_storage_path

# Check storage structure
storage_path = db_storage_path()
knowledge_path = os.path.join(storage_path, "knowledge")

if os.path.exists(knowledge_path):
    print("Knowledge collections found:")
    for collection in os.listdir(knowledge_path):
        collection_path = os.path.join(knowledge_path, collection)
        if os.path.isdir(collection_path):
            print(f"  - {collection}/")
            # Show collection contents
            for item in os.listdir(collection_path):
                print(f"    └── {item}")
```

#### Testar Recuperação de Knowledge

```python
# Test agent knowledge retrieval
if hasattr(agent, 'knowledge') and agent.knowledge:
    test_query = ["test query"]
    results = agent.knowledge.query(test_query)
    print(f"Agent knowledge results: {len(results)} documents found")

    # Test crew knowledge retrieval (if exists)
    if hasattr(crew, 'knowledge') and crew.knowledge:
        crew_results = crew.query_knowledge(test_query)
        print(f"Crew knowledge results: {len(crew_results)} documents found")
```

#### Inspecionar Coleções de Knowledge

```python
import chromadb
from crewai.utilities.paths import db_storage_path
import os

# Connect to CrewAI's knowledge ChromaDB
knowledge_path = os.path.join(db_storage_path(), "knowledge")

if os.path.exists(knowledge_path):
    client = chromadb.PersistentClient(path=knowledge_path)
    collections = client.list_collections()

    print("Knowledge Collections:")
    for collection in collections:
        print(f"  - {collection.name}: {collection.count()} documents")

        # Sample a few documents to verify content
        if collection.count() > 0:
            sample = collection.peek(limit=2)
            print(f"    Sample content: {sample['documents'][0][:100]}...")
else:
    print("No knowledge storage found")
```

#### Verificar Processamento de Knowledge

```python
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# Create a test knowledge source
test_source = StringKnowledgeSource(
    content="Test knowledge content for debugging",
    chunk_size=100,  # Small chunks for testing
    chunk_overlap=20
)

# Check chunking behavior
print(f"Original content length: {len(test_source.content)}")
print(f"Chunk size: {test_source.chunk_size}")
print(f"Chunk overlap: {test_source.chunk_overlap}")

# Process and inspect chunks
test_source.add()
print(f"Number of chunks created: {len(test_source.chunks)}")
for i, chunk in enumerate(test_source.chunks[:3]):  # Show first 3 chunks
    print(f"Chunk {i+1}: {chunk[:50]}...")
```

### Problemas Comuns de Armazenamento de Knowledge

**Erros "Arquivo não encontrado":**

```python
# Ensure files are in the correct location
from crewai.utilities.constants import KNOWLEDGE_DIRECTORY
import os

knowledge_dir = KNOWLEDGE_DIRECTORY  # Usually "knowledge"
file_path = os.path.join(knowledge_dir, "your_file.pdf")

if not os.path.exists(file_path):
    print(f"File not found: {file_path}")
    print(f"Current working directory: {os.getcwd()}")
    print(f"Expected knowledge directory: {os.path.abspath(knowledge_dir)}")
```

**Erros "Incompatibilidade de dimensão de embedding":**

```python
# This happens when switching embedding providers
# Reset knowledge storage to clear old embeddings
crew.reset_memories(command_type='knowledge')

# Or use consistent embedding providers
crew = Crew(
    agents=[...],
    tasks=[...],
    knowledge_sources=[...],
    embedder={"provider": "openai", "config": {"model": "text-embedding-3-small"}}
)
```

**Erros "ChromaDB permissão negada":**

```bash
# Fix storage permissions
chmod -R 755 ~/.local/share/CrewAI/
```

**Knowledge não persistindo entre execuções:**

```python
# Verify storage location consistency
import os
from crewai.utilities.paths import db_storage_path

print("CREWAI_STORAGE_DIR:", os.getenv("CREWAI_STORAGE_DIR"))
print("Computed storage path:", db_storage_path())
print("Knowledge path:", os.path.join(db_storage_path(), "knowledge"))
```

### Comandos de Reset de Knowledge

```python
# Reset only agent-specific knowledge
crew.reset_memories(command_type='agent_knowledge')

# Reset both crew and agent knowledge
crew.reset_memories(command_type='knowledge')

# CLI commands
# crewai reset-memories --agent-knowledge  # Agent knowledge only
# crewai reset-memories --knowledge        # All knowledge
```

### Limpando Knowledge

Se você precisar limpar o knowledge armazenado no CrewAI, você pode usar o comando `crewai reset-memories` com a opção `--knowledge`.

```bash Command
crewai reset-memories --knowledge
```

Isso é útil quando você atualizou suas fontes de knowledge e quer garantir que os agentes estejam usando as informações mais recentes.

## Melhores Práticas

<AccordionGroup>
  <Accordion title="Organização de Conteúdo">
    * Mantenha tamanhos de chunk apropriados para seu tipo de conteúdo
    * Considere sobreposição de conteúdo para preservação de contexto
    * Organize informações relacionadas em fontes de knowledge separadas
  </Accordion>

  <Accordion title="Dicas de Performance">
    * Ajuste tamanhos de chunk baseado na complexidade do conteúdo
    * Configure modelos de embedding apropriados
    * Considere usar provedores de embedding locais para processamento mais rápido
  </Accordion>

  <Accordion title="Knowledge de Uma Vez">
    * Com a estrutura de arquivo típica fornecida pelo CrewAI, as fontes de knowledge são incorporadas toda vez que o kickoff é acionado.
    * Se as fontes de knowledge são grandes, isso leva à ineficiência e latência aumentada, pois os mesmos dados são incorporados cada vez.
    * Para resolver isso, inicialize diretamente o parâmetro knowledge em vez do parâmetro knowledge\_sources.
    * Link para a issue para ter a ideia completa [Github Issue](https://github.com/crewAIInc/crewAI/issues/2755)
  </Accordion>

  <Accordion title="Gerenciamento de Knowledge">
    * Use knowledge no nível do agente para informações específicas do papel
    * Use knowledge no nível da crew para informações compartilhadas que todos os agentes precisam
    * Configure embedders no nível do agente se você precisar de estratégias de embedding diferentes
    * Use nomenclatura consistente de coleção mantendo papéis de agente descritivos
    * Teste a inicialização de knowledge verificando agent.knowledge após o kickoff
    * Monitore localizações de armazenamento para entender onde o knowledge está armazenado
    * Reset knowledge apropriadamente usando os tipos de comando corretos
  </Accordion>

  <Accordion title="Melhores Práticas de Produção">
    * Configure `CREWAI_STORAGE_DIR` para uma localização conhecida em produção
    * Escolha provedores de embedding explícitos para corresponder à sua configuração de LLM e evitar conflitos de chave de API
    * Monitore o tamanho do armazenamento de knowledge conforme ele cresce com adições de documentos
    * Organize fontes de knowledge por domínio ou propósito usando nomes de coleção
    * Inclua diretórios de knowledge em suas estratégias de backup e implantação
    * Configure permissões de arquivo apropriadas para arquivos de knowledge e diretórios de armazenamento
    * Use variáveis de ambiente para chaves de API e configuração sensível
  </Accordion>
</AccordionGroup>


# LLMs
Source: https://docs.crewai.com/pt-BR/concepts/llms

Um guia abrangente para configurar e usar Modelos de Linguagem de Grande Escala (LLMs) em seus projetos CrewAI

## Visão Geral

O CrewAI integra-se com múltiplos provedores de LLM através do LiteLLM, oferecendo flexibilidade para você escolher o modelo certo para o seu caso de uso específico. Este guia irá ajudá-lo a entender como configurar e usar diferentes provedores de LLM em seus projetos CrewAI.

## O que são LLMs?

Modelos de Linguagem de Grande Escala (LLMs) são a inteligência central por trás dos agentes CrewAI. Eles permitem que os agentes compreendam o contexto, tomem decisões e gerem respostas semelhantes às humanas. Veja o que você precisa saber:

<CardGroup cols={2}>
  <Card title="Noções Básicas de LLM" icon="brain">
    Modelos de Linguagem de Grande Escala são sistemas de IA treinados em grandes volumes de dados textuais. Eles potencializam a inteligência dos agentes CrewAI, permitindo compreender e gerar textos de voz humana.
  </Card>

  <Card title="Janela de Contexto" icon="window">
    A janela de contexto determina quanto texto um LLM pode processar de uma só vez. Janelas maiores (por exemplo, 128K tokens) permitem mais contexto, porém podem ser mais caras e lentas.
  </Card>

  <Card title="Temperatura" icon="temperature-three-quarters">
    A temperatura (0.0 a 1.0) controla a aleatoriedade das respostas. Valores mais baixos (ex.: 0.2) produzem respostas mais focadas e determinísticas, enquanto valores mais altos (ex.: 0.8) aumentam criatividade e variabilidade.
  </Card>

  <Card title="Seleção de Provedor" icon="server">
    Cada provedor de LLM (ex.: OpenAI, Anthropic, Google) oferece modelos diferentes, com capacidades, preços e recursos variados. Escolha conforme suas necessidades de precisão, velocidade e custo.
  </Card>
</CardGroup>

## Configurando seu LLM

Existem diferentes locais no código do CrewAI onde você pode especificar o modelo a ser utilizado. Após definir o modelo usado, será necessário fornecer a configuração (como uma chave de API) para cada provedor de modelo. Veja a seção de [exemplos de configuração de provedores](#provider-configuration-examples) para seu provedor.

<Tabs>
  <Tab title="1. Variáveis de Ambiente">
    A maneira mais simples de começar. Defina o modelo diretamente em seu ambiente, usando um arquivo `.env` ou no código do seu aplicativo. Se você utilizou `crewai create` para iniciar seu projeto, já estará configurado.

    ```bash .env
    MODEL=model-id  # e.g. gpt-4o, gemini-2.0-flash, claude-3-sonnet-...

    # Lembre-se de definir suas chaves de API aqui também. Veja a seção
    # do Provedor abaixo.
    ```

    <Warning>
      Nunca envie chaves de API para controle de versão. Use arquivos de ambiente (.env) ou o gerenciamento de segredos do seu sistema.
    </Warning>
  </Tab>

  <Tab title="2. Configuração YAML">
    Crie um arquivo YAML para definir as configurações dos seus agentes. Este método é ótimo para controle de versão e colaboração em equipe:

    ```yaml agents.yaml {6}
    researcher:
        role: Research Specialist
        goal: Conduct comprehensive research and analysis
        backstory: A dedicated research professional with years of experience
        verbose: true
        llm: provider/model-id  # e.g. openai/gpt-4o, google/gemini-2.0-flash, anthropic/claude...
        # (veja exemplos de configuração de provedores abaixo para mais)
    ```

    <Info>
      A configuração YAML permite:

      * Controlar versões das configurações dos agentes
      * Trocar facilmente entre diferentes modelos
      * Compartilhar configurações entre membros da equipe
      * Documentar escolhas de modelos e seus propósitos
    </Info>
  </Tab>

  <Tab title="3. Código Direto">
    Para máxima flexibilidade, configure os LLMs diretamente no seu código Python:

    ```python {4,8}
    from crewai import LLM

    # Configuração básica
    llm = LLM(model="model-id-here")  # gpt-4o, gemini-2.0-flash, anthropic/claude...

    # Configuração avançada com parâmetros detalhados
    llm = LLM(
        model="openai/gpt-4",
        temperature=0.8,
        max_tokens=150,
        top_p=0.9,
        frequency_penalty=0.1,
        presence_penalty=0.1,
        response_format={"type":"json"},
        stop=["FIM"],
        seed=42
    )
    ```

    <Info>
      Explicações dos parâmetros:

      * `temperature`: Controla a aleatoriedade (0.0-1.0)
      * `timeout`: Tempo máximo de espera pela resposta
      * `max_tokens`: Limita o comprimento da resposta
      * `top_p`: Alternativa à temperatura para amostragem
      * `frequency_penalty`: Reduz repetição de palavras
      * `presence_penalty`: Incentiva novos tópicos
      * `response_format`: Especifica formato de saída
      * `seed`: Garante resultados consistentes
    </Info>
  </Tab>
</Tabs>

## Exemplos de Configuração de Provedores

O CrewAI suporta uma grande variedade de provedores de LLM, cada um com recursos, métodos de autenticação e capacidades de modelo únicos.
Nesta seção, você encontrará exemplos detalhados que ajudam a selecionar, configurar e otimizar o LLM que melhor atende às necessidades do seu projeto.

<AccordionGroup>
  <Accordion title="OpenAI">
    Defina as seguintes variáveis de ambiente no seu arquivo `.env`:

    ```toml Code
    # Obrigatório
    OPENAI_API_KEY=sk-...

    # Opcional
    OPENAI_API_BASE=<custom-base-url>
    OPENAI_ORGANIZATION=<your-org-id>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    from crewai import LLM

    llm = LLM(
        model="openai/gpt-4",
        temperature=0.8,
        max_tokens=150,
        top_p=0.9,
        frequency_penalty=0.1,
        presence_penalty=0.1,
        stop=["FIM"],
        seed=42
    )
    ```

    OpenAI é um dos líderes em modelos LLM com uma ampla gama de modelos e recursos.

    | Modelo               | Janela de Contexto | Melhor Para                                             |
    | -------------------- | ------------------ | ------------------------------------------------------- |
    | GPT-4                | 8.192 tokens       | Tarefas de alta precisão, raciocínio complexo           |
    | GPT-4 Turbo          | 128.000 tokens     | Conteúdo longo, análise de documentos                   |
    | GPT-4o & GPT-4o-mini | 128.000 tokens     | Processamento de contexto amplo com bom custo-benefício |
    | o3-mini              | 200.000 tokens     | Raciocínio rápido, tarefas complexas                    |
    | o1-mini              | 128.000 tokens     | Raciocínio rápido, tarefas complexas                    |
    | o1-preview           | 128.000 tokens     | Raciocínio rápido, tarefas complexas                    |
    | o1                   | 200.000 tokens     | Raciocínio rápido, tarefas complexas                    |
  </Accordion>

  <Accordion title="Meta-Llama">
    A API Llama da Meta fornece acesso à família de modelos de linguagem de grande escala da Meta.
    A API está disponível através da [Meta Llama API](https://llama.developer.meta.com?utm_source=partner-crewai\&utm_medium=website).
    Defina as seguintes variáveis de ambiente no seu arquivo `.env`:

    ```toml Code
    # Configuração chave da API Meta Llama
    LLAMA_API_KEY=LLM|your_api_key_here
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    from crewai import LLM

    # Inicializar Meta Llama LLM
    llm = LLM(
        model="meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8",
        temperature=0.8,
        stop=["FIM"],
        seed=42
    )
    ```

    Todos os modelos listados em [https://llama.developer.meta.com/docs/models/](https://llama.developer.meta.com/docs/models/) são suportados.

    | ID do Modelo                                        | Comprimento contexto entrada | Comprimento contexto saída | Modalidades de entrada | Modalidades de saída |
    | --------------------------------------------------- | ---------------------------- | -------------------------- | ---------------------- | -------------------- |
    | `meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8`     | 128k                         | 4028                       | Texto, Imagem          | Texto                |
    | `meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8` | 128k                         | 4028                       | Texto, Imagem          | Texto                |
    | `meta_llama/Llama-3.3-70B-Instruct`                 | 128k                         | 4028                       | Texto                  | Texto                |
    | `meta_llama/Llama-3.3-8B-Instruct`                  | 128k                         | 4028                       | Texto                  | Texto                |
  </Accordion>

  <Accordion title="Anthropic">
    ```toml Code
    # Obrigatório
    ANTHROPIC_API_KEY=sk-ant-...

    # Opcional
    ANTHROPIC_API_BASE=<custom-base-url>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="anthropic/claude-3-sonnet-20240229-v1:0",
        temperature=0.7
    )
    ```
  </Accordion>

  <Accordion title="Google (Gemini API)">
    Defina sua chave de API no seu arquivo `.env`. Se precisar de uma chave, ou encontrar uma existente, verifique o [AI Studio](https://aistudio.google.com/apikey).

    ```toml .env
    # https://ai.google.dev/gemini-api/docs/api-key
    GEMINI_API_KEY=<your-api-key>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    from crewai import LLM

    llm = LLM(
        model="gemini/gemini-2.0-flash",
        temperature=0.7,
    )
    ```

    ### Modelos Gemini

    O Google oferece uma variedade de modelos poderosos otimizados para diferentes casos de uso.

    | Modelo                         | Janela de Contexto | Melhor Para                                                                                                               |
    | ------------------------------ | ------------------ | ------------------------------------------------------------------------------------------------------------------------- |
    | gemini-2.5-flash-preview-04-17 | 1M tokens          | Pensamento adaptativo, eficiência de custo                                                                                |
    | gemini-2.5-pro-preview-05-06   | 1M tokens          | Pensamento e raciocínio avançados, compreensão multimodal, codificação avançada, etc.                                     |
    | gemini-2.0-flash               | 1M tokens          | Próxima geração de recursos, velocidade, raciocínio e streaming em tempo real                                             |
    | gemini-2.0-flash-lite          | 1M tokens          | Eficiência de custo e baixa latência                                                                                      |
    | gemini-1.5-flash               | 1M tokens          | Modelo multimodal equilibrado, bom para maioria das tarefas                                                               |
    | gemini-1.5-flash-8B            | 1M tokens          | Mais rápido, mais eficiente em custo, adequado para tarefas de alta frequência                                            |
    | gemini-1.5-pro                 | 2M tokens          | Melhor desempenho para uma ampla variedade de tarefas de raciocínio, incluindo lógica, codificação e colaboração criativa |

    A lista completa de modelos está disponível na [documentação dos modelos Gemini](https://ai.google.dev/gemini-api/docs/models).

    ### Gemma

    A API Gemini também permite uso de sua chave de API para acessar [modelos Gemma](https://ai.google.dev/gemma/docs) hospedados na infraestrutura Google.

    | Modelo         | Janela de Contexto |
    | -------------- | ------------------ |
    | gemma-3-1b-it  | 32k tokens         |
    | gemma-3-4b-it  | 32k tokens         |
    | gemma-3-12b-it | 32k tokens         |
    | gemma-3-27b-it | 128k tokens        |
  </Accordion>

  <Accordion title="Google (Vertex AI)">
    Obtenha as credenciais pelo Google Cloud Console, salve em um arquivo JSON e carregue com o código a seguir:

    ```python Code
    import json

    file_path = 'path/to/vertex_ai_service_account.json'

    # Carregar o arquivo JSON
    with open(file_path, 'r') as file:
        vertex_credentials = json.load(file)

    # Converter credenciais em string JSON
    vertex_credentials_json = json.dumps(vertex_credentials)
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    from crewai import LLM

    llm = LLM(
        model="gemini/gemini-1.5-pro-latest",
        temperature=0.7,
        vertex_credentials=vertex_credentials_json
    )
    ```

    O Google oferece uma variedade de modelos poderosos otimizados para diferentes casos de uso:

    | Modelo                         | Janela de Contexto | Melhor Para                                                                                                               |
    | ------------------------------ | ------------------ | ------------------------------------------------------------------------------------------------------------------------- |
    | gemini-2.5-flash-preview-04-17 | 1M tokens          | Pensamento adaptativo, eficiência de custo                                                                                |
    | gemini-2.5-pro-preview-05-06   | 1M tokens          | Pensamento e raciocínio avançados, compreensão multimodal, codificação avançada, etc.                                     |
    | gemini-2.0-flash               | 1M tokens          | Próxima geração de recursos, velocidade, raciocínio e streaming em tempo real                                             |
    | gemini-2.0-flash-lite          | 1M tokens          | Eficiência de custo e baixa latência                                                                                      |
    | gemini-1.5-flash               | 1M tokens          | Modelo multimodal equilibrado, bom para maioria das tarefas                                                               |
    | gemini-1.5-flash-8B            | 1M tokens          | Mais rápido, mais eficiente em custo, adequado para tarefas de alta frequência                                            |
    | gemini-1.5-pro                 | 2M tokens          | Melhor desempenho para uma ampla variedade de tarefas de raciocínio, incluindo lógica, codificação e colaboração criativa |
  </Accordion>

  <Accordion title="Azure">
    ```toml Code
    # Obrigatório
    AZURE_API_KEY=<your-api-key>
    AZURE_API_BASE=<your-resource-url>
    AZURE_API_VERSION=<api-version>

    # Opcional
    AZURE_AD_TOKEN=<your-azure-ad-token>
    AZURE_API_TYPE=<your-azure-api-type>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="azure/gpt-4",
        api_version="2023-05-15"
    )
    ```
  </Accordion>

  <Accordion title="AWS Bedrock">
    ```toml Code
    AWS_ACCESS_KEY_ID=<your-access-key>
    AWS_SECRET_ACCESS_KEY=<your-secret-key>
    AWS_DEFAULT_REGION=<your-region>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="bedrock/anthropic.claude-3-sonnet-20240229-v1:0"
    )
    ```

    Antes de usar o Amazon Bedrock, certifique-se de ter o boto3 instalado em seu ambiente

    [Amazon Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/models-regions.html) é um serviço gerenciado que fornece acesso a múltiplos modelos fundamentais dos principais provedores de IA através de uma API unificada, permitindo o desenvolvimento seguro e responsável de aplicações de IA.

    | Modelo                  | Janela de Contexto | Melhor Para                                                                                                                       |
    | ----------------------- | ------------------ | --------------------------------------------------------------------------------------------------------------------------------- |
    | Amazon Nova Pro         | Até 300k tokens    | Alto desempenho, equilíbrio entre precisão, velocidade e custo em tarefas diversas.                                               |
    | Amazon Nova Micro       | Até 128k tokens    | Modelo texto-only de alta performance, custo-benefício, otimizado para baixa latência.                                            |
    | Amazon Nova Lite        | Até 300k tokens    | Alto desempenho, processamento multimodal acessível para texto, imagem, vídeo em tempo real.                                      |
    | Claude 3.7 Sonnet       | Até 128k tokens    | Alto desempenho para raciocínio complexo, programação & agentes de IA                                                             |
    | Claude 3.5 Sonnet v2    | Até 200k tokens    | Modelo avançado especializado em engenharia de software, capacidades agenticas e interação computacional com custo otimizado.     |
    | Claude 3.5 Sonnet       | Até 200k tokens    | Alto desempenho com inteligência e raciocínio excepcionais, equilíbrio entre velocidade-custo.                                    |
    | Claude 3.5 Haiku        | Até 200k tokens    | Modelo multimodal rápido e compacto, otimizado para respostas rápidas e interações humanas naturais                               |
    | Claude 3 Sonnet         | Até 200k tokens    | Modelo multimodal equilibrando inteligência e velocidade para grandes volumes de uso.                                             |
    | Claude 3 Haiku          | Até 200k tokens    | Compacto, multimodal, otimizado para respostas rápidas e diálogo natural                                                          |
    | Claude 3 Opus           | Até 200k tokens    | Modelo multimodal mais avançado para tarefas complexas com raciocínio humano e entendimento contextual superior.                  |
    | Claude 2.1              | Até 200k tokens    | Versão aprimorada com janela de contexto aumentada, maior confiabilidade, menos alucinações para aplicações longas e RAG          |
    | Claude                  | Até 100k tokens    | Modelo versátil para diálogos sofisticados, conteúdo criativo e instruções precisas.                                              |
    | Claude Instant          | Até 100k tokens    | Modelo rápido e de baixo custo para tarefas diárias, como diálogos, análise, sumarização e Q\&A em documentos                     |
    | Llama 3.1 405B Instruct | Até 128k tokens    | LLM avançado para geração de dados sintéticos, distilação e inferência para chatbots, programação, tarefas de domínio específico. |
    | Llama 3.1 70B Instruct  | Até 128k tokens    | Potencializa conversas complexas com entendimento contextual superior, raciocínio e geração de texto.                             |
    | Llama 3.1 8B Instruct   | Até 128k tokens    | Modelo de última geração, entendimento de linguagem, raciocínio e geração de texto.                                               |
    | Llama 3 70B Instruct    | Até 8k tokens      | Potencializa conversas complexas com entendimento contextual superior, raciocínio e geração de texto.                             |
    | Llama 3 8B Instruct     | Até 8k tokens      | LLM de última geração com excelente desempenho em linguagem e geração de texto.                                                   |
    | Titan Text G1 - Lite    | Até 4k tokens      | Modelo leve e econômico para tarefas em inglês e ajuste fino, focado em sumarização e geração de conteúdo.                        |
    | Titan Text G1 - Express | Até 8k tokens      | Modelo versátil para tarefas gerais de linguagem, chat e aplicações RAG com suporte a inglês e 100+ línguas.                      |
    | Cohere Command          | Até 4k tokens      | Modelo especializado em seguir comandos do usuário e entregar soluções empresariais práticas.                                     |
    | Jurassic-2 Mid          | Até 8.191 tokens   | Modelo econômico equilibrando qualidade e custo para tarefas como Q\&A, sumarização e geração de conteúdo.                        |
    | Jurassic-2 Ultra        | Até 8.191 tokens   | Geração avançada de texto e compreensão, excelente em análise e criação de conteúdo complexo.                                     |
    | Jamba-Instruct          | Até 256k tokens    | Modelo com janela de contexto extendida para geração de texto, sumarização e Q\&A de baixo custo.                                 |
    | Mistral 7B Instruct     | Até 32k tokens     | LLM atende instruções, solicitações e gera texto criativo.                                                                        |
    | Mistral 8x7B Instruct   | Até 32k tokens     | MOE LLM que atende instruções, solicitações e gera texto criativo.                                                                |
  </Accordion>

  <Accordion title="Amazon SageMaker">
    ```toml Code
    AWS_ACCESS_KEY_ID=<your-access-key>
    AWS_SECRET_ACCESS_KEY=<your-secret-key>
    AWS_DEFAULT_REGION=<your-region>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="sagemaker/<my-endpoint>"
    )
    ```
  </Accordion>

  <Accordion title="Mistral">
    Defina as seguintes variáveis de ambiente no seu arquivo `.env`:

    ```toml Code
    MISTRAL_API_KEY=<your-api-key>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="mistral/mistral-large-latest",
        temperature=0.7
    )
    ```
  </Accordion>

  <Accordion title="Nvidia NIM">
    Defina as seguintes variáveis de ambiente no seu arquivo `.env`:

    ```toml Code
    NVIDIA_API_KEY=<your-api-key>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="nvidia_nim/meta/llama3-70b-instruct",
        temperature=0.7
    )
    ```

    O Nvidia NIM oferece uma suíte abrangente de modelos para diversos usos, desde tarefas gerais até aplicações especializadas.

    | Modelo                                      | Janela de Contexto | Melhor Para                                                                                                                 |
    | ------------------------------------------- | ------------------ | --------------------------------------------------------------------------------------------------------------------------- |
    | nvidia/mistral-nemo-minitron-8b-8k-instruct | 8.192 tokens       | Modelo pequeno de linguagem topo de linha para chatbots, assistentes virtuais e geração de conteúdo.                        |
    | nvidia/nemotron-4-mini-hindi-4b-instruct    | 4.096 tokens       | SLM bilíngue Hindi-Inglês para inferência no dispositivo, específico para língua hindi.                                     |
    | nvidia/llama-3.1-nemotron-70b-instruct      | 128k tokens        | Personalizado para respostas mais úteis                                                                                     |
    | nvidia/llama3-chatqa-1.5-8b                 | 128k tokens        | LLM avançado para respostas contextuais de alta qualidade em chatbots e mecanismos de busca.                                |
    | nvidia/llama3-chatqa-1.5-70b                | 128k tokens        | LLM avançado para respostas contextuais de alta qualidade para chatbots e mecanismos de busca.                              |
    | nvidia/vila                                 | 128k tokens        | Modelo multmodal visão-linguagem para compreensão de texto/img/vídeo com respostas informativas                             |
    | nvidia/neva-22                              | 4.096 tokens       | Modelo de visão-linguagem multimodal para compreensão textos/imagens e respostas informativas                               |
    | nvidia/nemotron-mini-4b-instruct            | 8.192 tokens       | Tarefas gerais                                                                                                              |
    | nvidia/usdcode-llama3-70b-instruct          | 128k tokens        | LLM de ponta para queries OpenUSD e geração de código USD-Python.                                                           |
    | nvidia/nemotron-4-340b-instruct             | 4.096 tokens       | Gera dados sintéticos diversos simulando características reais.                                                             |
    | meta/codellama-70b                          | 100k tokens        | LLM capaz de gerar código a partir de linguagem natural e vice-versa.                                                       |
    | meta/llama2-70b                             | 4.096 tokens       | Modelo de IA avançado para geração de textos e códigos.                                                                     |
    | meta/llama3-8b-instruct                     | 8.192 tokens       | LLM de última geração, entendimento de linguagem, raciocínio e geração de texto.                                            |
    | meta/llama3-70b-instruct                    | 8.192 tokens       | Potencializa conversas complexas com entendimento contextual superior, raciocínio e geração de texto.                       |
    | meta/llama-3.1-8b-instruct                  | 128k tokens        | Modelo compacto de última geração, com compreensão, raciocínio e geração de texto superior.                                 |
    | meta/llama-3.1-70b-instruct                 | 128k tokens        | Potencializa conversas complexas com entendimento contextual superior, raciocínio e geração de texto.                       |
    | meta/llama-3.1-405b-instruct                | 128k tokens        | LLM avançado para geração sintética de dados, destilação e inferência para chatbots, código, tarefas de domínio específico. |
    | meta/llama-3.2-1b-instruct                  | 128k tokens        | Pequeno modelo de linguagem de última geração, entendimento, raciocínio e geração textual.                                  |
    | meta/llama-3.2-3b-instruct                  | 128k tokens        | Pequeno modelo de linguagem de última geração, entendimento, raciocínio e geração textual.                                  |
    | meta/llama-3.2-11b-vision-instruct          | 128k tokens        | Pequeno modelo de linguagem de última geração, entendimento, raciocínio e geração textual multimodal.                       |
    | meta/llama-3.2-90b-vision-instruct          | 128k tokens        | Pequeno modelo de linguagem de última geração, entendimento, raciocínio e geração textual multimodal.                       |
    | google/gemma-7b                             | 8.192 tokens       | Modelo avançado de geração de texto, compreensão, transformação e programação.                                              |
    | google/gemma-2b                             | 8.192 tokens       | Modelo avançado de geração de texto, compreensão, transformação e programação.                                              |
    | google/codegemma-7b                         | 8.192 tokens       | Modelo avançado baseado no Gemma-7B do Google, especializado em geração de códigos e autocomplete.                          |
    | google/codegemma-1.1-7b                     | 8.192 tokens       | Modelo avançado para geração, complemento, raciocínio e instrução em código.                                                |
    | google/recurrentgemma-2b                    | 8.192 tokens       | Modelo baseado em arquitetura recorrente para inferência mais rápida em sequências longas.                                  |
    | google/gemma-2-9b-it                        | 8.192 tokens       | Modelo avançado de geração de texto, compreensão, transformação e programação.                                              |
    | google/gemma-2-27b-it                       | 8.192 tokens       | Modelo avançado de geração de texto, compreensão, transformação e programação.                                              |
    | google/gemma-2-2b-it                        | 8.192 tokens       | Modelo avançado de geração de texto, compreensão, transformação e programação.                                              |
    | google/deplot                               | 512 tokens         | Modelo visual por linguagem para entender gráficos e converter em tabelas.                                                  |
    | google/paligemma                            | 8.192 tokens       | Modelo visão-linguagem experto em compreender texto e visual, gerando respostas informativas.                               |
    | mistralai/mistral-7b-instruct-v0.2          | 32k tokens         | LLM que segue instruções, completa pedidos e gera texto criativo.                                                           |
    | mistralai/mixtral-8x7b-instruct-v0.1        | 8.192 tokens       | MOE LLM para seguir instruções e gerar versões criativas de texto.                                                          |
    | mistralai/mistral-large                     | 4.096 tokens       | Geração de dados sintéticos.                                                                                                |
    | mistralai/mixtral-8x22b-instruct-v0.1       | 8.192 tokens       | Geração de dados sintéticos.                                                                                                |
    | mistralai/mistral-7b-instruct-v0.3          | 32k tokens         | LLM que segue instruções, completa pedidos e gera texto criativo.                                                           |
    | nv-mistralai/mistral-nemo-12b-instruct      | 128k tokens        | Modelo de linguagem avançado para raciocínio, código, tarefas multilíngues; roda em uma única GPU.                          |
    | mistralai/mamba-codestral-7b-v0.1           | 256k tokens        | Modelo para escrita e interação com código em múltiplas linguagens e tarefas.                                               |
    | microsoft/phi-3-mini-128k-instruct          | 128K tokens        | LLM leve, de última geração, com habilidades de lógica e matemática.                                                        |
    | microsoft/phi-3-mini-4k-instruct            | 4.096 tokens       | LLM leve, de última geração, com habilidades de lógica e matemática.                                                        |
    | microsoft/phi-3-small-8k-instruct           | 8.192 tokens       | LLM leve, de última geração, com habilidades de lógica e matemática.                                                        |
    | microsoft/phi-3-small-128k-instruct         | 128K tokens        | LLM leve, de última geração, com habilidades de lógica e matemática.                                                        |
    | microsoft/phi-3-medium-4k-instruct          | 4.096 tokens       | LLM leve, de última geração, com habilidades de lógica e matemática.                                                        |
    | microsoft/phi-3-medium-128k-instruct        | 128K tokens        | LLM leve, de última geração, com habilidades de lógica e matemática.                                                        |
    | microsoft/phi-3.5-mini-instruct             | 128K tokens        | LLM multilíngue leve para aplicações de IA restritas em memória e tempo.                                                    |
    | microsoft/phi-3.5-moe-instruct              | 128K tokens        | LLM avançada baseada em Mixture of Experts para geração eficiente de conteúdo.                                              |
    | microsoft/kosmos-2                          | 1.024 tokens       | Modelo multimodal revolucionário para compreender e raciocinar elementos visuais em imagens.                                |
    | microsoft/phi-3-vision-128k-instruct        | 128k tokens        | Modelo multimodal aberto de ponta para raciocínio de alta qualidade a partir de imagens.                                    |
    | microsoft/phi-3.5-vision-instruct           | 128k tokens        | Modelo multimodal aberto de ponta para raciocínio de alta qualidade a partir de imagens.                                    |
    | databricks/dbrx-instruct                    | 12k tokens         | LLM de uso geral com desempenho no estado da arte para linguagem, programação e RAG.                                        |
    | snowflake/arctic                            | 1.024 tokens       | Inferência eficiente para aplicações empresariais focadas em SQL e programação.                                             |
    | aisingapore/sea-lion-7b-instruct            | 4.096 tokens       | LLM para representação e diversidade linguística e cultural do sudeste asiático.                                            |
    | ibm/granite-8b-code-instruct                | 4.096 tokens       | LLM para programação: geração, explicação e diálogo multi-turn de código.                                                   |
    | ibm/granite-34b-code-instruct               | 8.192 tokens       | LLM para programação: geração, explicação e diálogo multi-turn de código.                                                   |
    | ibm/granite-3.0-8b-instruct                 | 4.096 tokens       | Pequeno modelo avançado, com suporte a RAG, sumário, classificação, código e IA agentica.                                   |
    | ibm/granite-3.0-3b-a800m-instruct           | 4.096 tokens       | Modelo Mixture of Experts eficiente para RAG, sumário, extração de entidades, classificação.                                |
    | mediatek/breeze-7b-instruct                 | 4.096 tokens       | Gera dados sintéticos diversos.                                                                                             |
    | upstage/solar-10.7b-instruct                | 4.096 tokens       | Excelente em tarefas de PLN, especialmente seguir instruções, raciocínio e matemática.                                      |
    | writer/palmyra-med-70b-32k                  | 32k tokens         | LLM líder para respostas médicas precisas e contextuais.                                                                    |
    | writer/palmyra-med-70b                      | 32k tokens         | LLM líder para respostas médicas precisas e contextuais.                                                                    |
    | writer/palmyra-fin-70b-32k                  | 32k tokens         | LLM especializada em análise financeira, relatórios e processamento de dados.                                               |
    | 01-ai/yi-large                              | 32k tokens         | Poderoso para inglês e chinês, incluindo chatbot e escrita criativa.                                                        |
    | deepseek-ai/deepseek-coder-6.7b-instruct    | 2k tokens          | Modelo avançado para geração de código, autocomplete, infilling.                                                            |
    | rakuten/rakutenai-7b-instruct               | 1.024 tokens       | LLM topo de linha, compreensão, raciocínio e geração textual.                                                               |
    | rakuten/rakutenai-7b-chat                   | 1.024 tokens       | LLM topo de linha, compreensão, raciocínio e geração textual.                                                               |
    | baichuan-inc/baichuan2-13b-chat             | 4.096 tokens       | Suporte a chat em chinês/inglês, programação, matemática, seguir instruções, resolver quizzes.                              |
  </Accordion>

  <Accordion title="Local NVIDIA NIM Deployed using WSL2">
    O NVIDIA NIM permite rodar LLMs potentes localmente em máquinas Windows usando WSL2 (Windows Subsystem for Linux).
    Este método aproveita o GPU NVIDIA para inferência privativa, segura e econômica, sem depender de serviços em nuvem.
    Perfeito para desenvolvimento, testes ou produção onde privacidade ou funcionalidades offline são necessárias.

    Aqui está um guia passo a passo para configurar um modelo local NVIDIA NIM:

    1. Siga as instruções de instalação no [site da NVIDIA](https://docs.nvidia.com/nim/wsl2/latest/getting-started.html)

    2. Instale o modelo local. Para Llama 3.1-8b siga as [instruções](https://build.nvidia.com/meta/llama-3_1-8b-instruct/deploy)

    3. Configure seus modelos locais crewai:

    ```python Code
    from crewai.llm import LLM

    local_nvidia_nim_llm = LLM(
        model="openai/meta/llama-3.1-8b-instruct", # é compatível com openai-api
        base_url="http://localhost:8000/v1",
        api_key="<your_api_key|any text if you have not configured it>", # api_key obrigatório, pode usar qualquer texto
    )

    # Então pode usá-lo no seu crew:

    @CrewBase
    class MyCrew():
        # ...

        @agent
        def researcher(self) -> Agent:
            return Agent(
                config=self.agents_config['researcher'], # type: ignore[index]
                llm=local_nvidia_nim_llm
            )

        # ...
    ```
  </Accordion>

  <Accordion title="Groq">
    Defina as seguintes variáveis de ambiente no seu arquivo `.env`:

    ```toml Code
    GROQ_API_KEY=<your-api-key>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="groq/llama-3.2-90b-text-preview",
        temperature=0.7
    )
    ```

    | Modelo           | Janela de Contexto | Melhor Para                                   |
    | ---------------- | ------------------ | --------------------------------------------- |
    | Llama 3.1 70B/8B | 131.072 tokens     | Alta performance e tarefas de contexto grande |
    | Llama 3.2 Série  | 8.192 tokens       | Tarefas gerais                                |
    | Mixtral 8x7B     | 32.768 tokens      | Equilíbrio entre performance e contexto       |
  </Accordion>

  <Accordion title="IBM watsonx.ai">
    Defina as seguintes variáveis de ambiente no seu arquivo `.env`:

    ```toml Code
    # Obrigatório
    WATSONX_URL=<your-url>
    WATSONX_APIKEY=<your-apikey>
    WATSONX_PROJECT_ID=<your-project-id>

    # Opcional
    WATSONX_TOKEN=<your-token>
    WATSONX_DEPLOYMENT_SPACE_ID=<your-space-id>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="watsonx/meta-llama/llama-3-1-70b-instruct",
        base_url="https://api.watsonx.ai/v1"
    )
    ```
  </Accordion>

  <Accordion title="Ollama (LLMs Locais)">
    1. Instale o Ollama: [ollama.ai](https://ollama.ai/)
    2. Rode um modelo: `ollama run llama3`
    3. Configure:

    ```python Code
    llm = LLM(
        model="ollama/llama3:70b",
        base_url="http://localhost:11434"
    )
    ```
  </Accordion>

  <Accordion title="Fireworks AI">
    Defina as seguintes variáveis de ambiente no seu arquivo `.env`:

    ```toml Code
    FIREWORKS_API_KEY=<your-api-key>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="fireworks_ai/accounts/fireworks/models/llama-v3-70b-instruct",
        temperature=0.7
    )
    ```
  </Accordion>

  <Accordion title="Perplexity AI">
    Defina as seguintes variáveis de ambiente no seu arquivo `.env`:

    ```toml Code
    PERPLEXITY_API_KEY=<your-api-key>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="llama-3.1-sonar-large-128k-online",
        base_url="https://api.perplexity.ai/"
    )
    ```
  </Accordion>

  <Accordion title="Hugging Face">
    Defina as seguintes variáveis de ambiente no seu arquivo `.env`:

    ```toml Code
    HF_TOKEN=<your-api-key>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="huggingface/meta-llama/Meta-Llama-3.1-8B-Instruct"
    )
    ```
  </Accordion>

  <Accordion title="SambaNova">
    Defina as seguintes variáveis de ambiente no seu arquivo `.env`:

    ```toml Code
    SAMBANOVA_API_KEY=<your-api-key>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="sambanova/Meta-Llama-3.1-8B-Instruct",
        temperature=0.7
    )
    ```

    | Modelo           | Janela de Contexto | Melhor Para                                  |
    | ---------------- | ------------------ | -------------------------------------------- |
    | Llama 3.1 70B/8B | Até 131.072 tokens | Alto desempenho, tarefas com grande contexto |
    | Llama 3.1 405B   | 8.192 tokens       | Desempenho e qualidade de saída elevada      |
    | Llama 3.2 Série  | 8.192 tokens       | Tarefas gerais e multimodais                 |
    | Llama 3.3 70B    | Até 131.072 tokens | Desempenho e qualidade de saída elevada      |
    | Família Qwen2    | 8.192 tokens       | Desempenho e qualidade de saída elevada      |
  </Accordion>

  <Accordion title="Cerebras">
    Defina as seguintes variáveis de ambiente no seu arquivo `.env`:

    ```toml Code
    # Obrigatório
    CEREBRAS_API_KEY=<your-api-key>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="cerebras/llama3.1-70b",
        temperature=0.7,
        max_tokens=8192
    )
    ```

    <Info>
      Recursos do Cerebras:

      * Altas velocidades de inferência
      * Preços competitivos
      * Equilíbrio entre velocidade e qualidade
      * Suporte a longas janelas de contexto
    </Info>
  </Accordion>

  <Accordion title="Open Router">
    Defina as seguintes variáveis de ambiente no seu arquivo `.env`:

    ```toml Code
    OPENROUTER_API_KEY=<your-api-key>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="openrouter/deepseek/deepseek-r1",
        base_url="https://openrouter.ai/api/v1",
        api_key=OPENROUTER_API_KEY
    )
    ```

    <Info>
      Modelos do Open Router:

      * openrouter/deepseek/deepseek-r1
      * openrouter/deepseek/deepseek-chat
    </Info>
  </Accordion>
</AccordionGroup>

## Respostas em streaming

O CrewAI suporta respostas em streaming de LLMs, permitindo que sua aplicação receba e processe saídas em tempo real assim que são geradas.

<Tabs>
  <Tab title="Configuração Básica">
    Ative o streaming definindo o parâmetro `stream` como `True` ao inicializar seu LLM:

    ```python
    from crewai import LLM

    # Crie um LLM com streaming ativado
    llm = LLM(
        model="openai/gpt-4o",
        stream=True  # Ativar streaming
    )
    ```

    Quando o streaming está ativado, as respostas são entregues em partes à medida que vão sendo geradas, criando uma experiência mais responsiva para o usuário.
  </Tab>

  <Tab title="Manipulação de Eventos">
    O CrewAI emite eventos para cada chunk recebido durante o streaming:

    ```python
    from crewai.utilities.events import (
      LLMStreamChunkEvent
    )
    from crewai.utilities.events.base_event_listener import BaseEventListener

    class MyCustomListener(BaseEventListener):
        def setup_listeners(self, crewai_event_bus):
            @crewai_event_bus.on(LLMStreamChunkEvent)
            def on_llm_stream_chunk(self, event: LLMStreamChunkEvent):
              # Clique para cada chunk assim que chegar
              print(f"Received chunk: {event.chunk}")

    my_listener = MyCustomListener()
    ```

    <Tip>
      [Clique aqui](https://docs.crewai.com/concepts/event-listener#event-listeners) para mais detalhes
    </Tip>
  </Tab>
</Tabs>

## Chamada Estruturada de LLM

O CrewAI suporta respostas estruturadas de LLMs permitindo que você defina um `response_format` usando um modelo Pydantic. Isso permite que o framework automaticamente faça o parsing e valide a saída, facilitando a integração da resposta em sua aplicação sem pós-processamento manual.

Por exemplo, é possível definir um modelo Pydantic para representar a resposta esperada e passá-lo como `response_format` ao instanciar o LLM. O modelo será utilizado para converter a resposta do LLM em um objeto Python estruturado.

```python Code
from crewai import LLM

class Dog(BaseModel):
    name: str
    age: int
    breed: str


llm = LLM(model="gpt-4o", response_format=Dog)

response = llm.call(
    "Analyze the following messages and return the name, age, and breed. "
    "Meet Kona! She is 3 years old and is a black german shepherd."
)
print(response)

# Output:
# Dog(name='Kona', age=3, breed='black german shepherd')
```

## Recursos Avançados e Otimização

Saiba como obter o máximo da configuração do seu LLM:

<AccordionGroup>
  <Accordion title="Gestão da Janela de Contexto">
    O CrewAI inclui recursos inteligentes para gerenciamento de contexto:

    ```python
    from crewai import LLM

    # O CrewAI automaticamente gerencia:
    # 1. Contagem e acompanhamento de tokens
    # 2. Resumo de conteúdo quando necessário
    # 3. Divisão de tarefas para grandes contextos

    llm = LLM(
        model="gpt-4",
        max_tokens=4000,  # Limitar tamanho da resposta
    )
    ```

    <Info>
      Boas práticas para o gerenciamento de contexto:

      1. Prefira modelos com janelas apropriadas
      2. Pré-processe entradas muito longas
      3. Utilize divisão para documentos grandes
      4. Monitore tokens para otimizar custos
    </Info>
  </Accordion>

  <Accordion title="Otimização de Performance">
    <Steps>
      <Step title="Otimização do Uso de Tokens">
        Escolha a janela de contexto certa para sua tarefa:

        * Tarefas pequenas (até 4K tokens): Modelos padrão
        * Tarefas médias (entre 4K-32K): Modelos aprimorados
        * Tarefas grandes (acima de 32K): Modelos com contexto expandido

        ```python
        # Configure o modelo com as opções certas
        llm = LLM(
            model="openai/gpt-4-turbo-preview",
            temperature=0.7,    # Ajuste conforme a tarefa
            max_tokens=4096,    # Defina conforme a necessidade da saída
            timeout=300        # Timeout maior para tarefas complexas
        )
        ```

        <Tip>
          * Temperaturas baixas (0.1 a 0.3) para respostas factuais
          * Temperaturas altas (0.7 a 0.9) para tarefas criativas
        </Tip>
      </Step>

      <Step title="Boas Práticas">
        1. Monitore o uso de tokens
        2. Implemente limites de taxa (rate limiting)
        3. Use cache quando possível
        4. Defina limites apropriados para max\_tokens
      </Step>
    </Steps>

    <Info>
      Lembre-se de monitorar regularmente o uso de tokens e ajustar suas configurações para otimizar custos e desempenho.
    </Info>
  </Accordion>

  <Accordion title="Descartar Parâmetros Adicionais">
    O CrewAI usa Litellm internamente para chamadas LLM, permitindo descartar parâmetros adicionais desnecessários para seu caso de uso. Isso pode simplificar seu código e reduzir a complexidade da configuração do LLM.
    Por exemplo, se não precisar enviar o parâmetro <code>stop</code>, basta omiti-lo na chamada do LLM:

    ```python
    from crewai import LLM
    import os

    os.environ["OPENAI_API_KEY"] = "<api-key>"

    o3_llm = LLM(
        model="o3",
        drop_params=True,
        additional_drop_params=["stop"]
    )
    ```
  </Accordion>
</AccordionGroup>

## Problemas Comuns e Soluções

<Tabs>
  <Tab title="Autenticação">
    <Warning>
      A maioria dos problemas de autenticação pode ser resolvida verificando o formato da chave da API e os nomes das variáveis de ambiente.
    </Warning>

    ```bash
    # OpenAI
    OPENAI_API_KEY=sk-...

    # Anthropic
    ANTHROPIC_API_KEY=sk-ant-...
    ```
  </Tab>

  <Tab title="Nomes dos Modelos">
    <Check>
      Sempre inclua o prefixo do provedor nos nomes dos modelos
    </Check>

    ```python
    # Correto
    llm = LLM(model="openai/gpt-4")

    # Incorreto
    llm = LLM(model="gpt-4")
    ```
  </Tab>

  <Tab title="Comprimento do Contexto">
    <Tip>
      Use modelos de contexto expandido para tarefas extensas
    </Tip>

    ```python
    # Modelo com contexto expandido
    llm = LLM(model="openai/gpt-4o")  # 128K tokens
    ```
  </Tab>
</Tabs>


# Memória
Source: https://docs.crewai.com/pt-BR/concepts/memory

Aproveitando sistemas de memória no framework CrewAI para aprimorar as capacidades dos agentes.

## Visão Geral

O framework CrewAI oferece um sistema de memória sofisticado projetado para aprimorar significativamente as capacidades dos agentes de IA. O CrewAI disponibiliza **três abordagens distintas de memória** que atendem a diferentes casos de uso:

1. **Sistema Básico de Memória** - Memória de curto prazo, longo prazo e de entidades integradas
2. **Memória de Usuário** - Memória específica do usuário com integração ao Mem0 (abordagem legada)
3. **Memória Externa** - Provedores de memória externos autônomos (nova abordagem)

## Componentes do Sistema de Memória

| Componente                 | Descrição                                                                                                                                                                                                                                     |
| :------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Memória de Curto Prazo** | Armazena temporariamente interações e resultados recentes usando `RAG`, permitindo que os agentes recordem e utilizem informações relevantes ao contexto atual durante as execuções.                                                          |
| **Memória de Longo Prazo** | Preserva informações valiosas e aprendizados de execuções passadas, permitindo que os agentes construam e refinem seu conhecimento ao longo do tempo.                                                                                         |
| **Memória de Entidades**   | Captura e organiza informações sobre entidades (pessoas, lugares, conceitos) encontradas durante tarefas, facilitando um entendimento mais profundo e o mapeamento de relacionamentos. Utiliza `RAG` para armazenar informações de entidades. |
| **Memória Contextual**     | Mantém o contexto das interações combinando `ShortTermMemory`, `LongTermMemory` e `EntityMemory`, auxiliando na coerência e relevância das respostas dos agentes ao longo de uma sequência de tarefas ou conversas.                           |

## 1. Sistema Básico de Memória (Recomendado)

A abordagem mais simples e comum de uso. Ative a memória para sua crew com um único parâmetro:

### Início Rápido

```python
from crewai import Crew, Agent, Task, Process

# Habilitar o sistema básico de memória
crew = Crew(
    agents=[...],
    tasks=[...],
    process=Process.sequential,
    memory=True,  # Ativa memória de curto prazo, longo prazo e de entidades
    verbose=True
)
```

### Como Funciona

* **Memória de Curto Prazo**: Usa ChromaDB com RAG para o contexto atual
* **Memória de Longo Prazo**: Usa SQLite3 para armazenar resultados de tarefas entre sessões
* **Memória de Entidades**: Usa RAG para rastrear entidades (pessoas, lugares, conceitos)
* **Local de Armazenamento**: Localidade específica da plataforma via pacote `appdirs`
* **Diretório de Armazenamento Personalizado**: Defina a variável de ambiente `CREWAI_STORAGE_DIR`

## Transparência no Local de Armazenamento

<Info>
  **Compreendendo os Locais de Armazenamento**: CrewAI utiliza diretórios específicos da plataforma para guardar arquivos de memória e conhecimento seguindo as convenções do sistema operacional. Conhecer esses locais ajuda na implantação em produção, backups e depuração.
</Info>

### Onde o CrewAI Armazena os Arquivos

Por padrão, o CrewAI usa a biblioteca `appdirs` para determinar os locais de armazenamento conforme a convenção da plataforma. Veja exatamente onde seus arquivos são armazenados:

#### Locais de Armazenamento Padrão por Plataforma

**macOS:**

```
~/Library/Application Support/CrewAI/{project_name}/
├── knowledge/           # Arquivos base de conhecimento ChromaDB
├── short_term_memory/   # Arquivos de memória de curto prazo ChromaDB
├── long_term_memory/    # Arquivos de memória de longo prazo ChromaDB
├── entities/            # Arquivos de memória de entidades ChromaDB
└── long_term_memory_storage.db  # Banco de dados SQLite
```

**Linux:**

```
~/.local/share/CrewAI/{project_name}/
├── knowledge/
├── short_term_memory/
├── long_term_memory/
├── entities/
└── long_term_memory_storage.db
```

**Windows:**

```
C:\Users\{username}\AppData\Local\CrewAI\{project_name}\
├── knowledge\
├── short_term_memory\
├── long_term_memory\
├── entities\
└── long_term_memory_storage.db
```

### Encontrando Seu Local de Armazenamento

Para ver exatamente onde o CrewAI está armazenando arquivos em seu sistema:

```python
from crewai.utilities.paths import db_storage_path
import os

# Obter o caminho base de armazenamento
storage_path = db_storage_path()
print(f"CrewAI storage location: {storage_path}")

# Listar todos os diretórios e arquivos do CrewAI
if os.path.exists(storage_path):
    print("\nStored files and directories:")
    for item in os.listdir(storage_path):
        item_path = os.path.join(storage_path, item)
        if os.path.isdir(item_path):
            print(f"📁 {item}/")
            # Exibir coleções ChromaDB
            if os.path.exists(item_path):
                for subitem in os.listdir(item_path):
                    print(f"   └── {subitem}")
        else:
            print(f"📄 {item}")
else:
    print("No CrewAI storage directory found yet.")
```

### Controlando Locais de Armazenamento

#### Opção 1: Variável de Ambiente (Recomendado)

```python
import os
from crewai import Crew

# Definir local de armazenamento personalizado
os.environ["CREWAI_STORAGE_DIR"] = "./my_project_storage"

# Toda a memória e conhecimento serão salvos em ./my_project_storage/
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True
)
```

#### Opção 2: Caminho de Armazenamento Personalizado

```python
import os
from crewai import Crew
from crewai.memory import LongTermMemory
from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage

# Configurar local de armazenamento personalizado
custom_storage_path = "./storage"
os.makedirs(custom_storage_path, exist_ok=True)

crew = Crew(
    memory=True,
    long_term_memory=LongTermMemory(
        storage=LTMSQLiteStorage(
            db_path=f"{custom_storage_path}/memory.db"
        )
    )
)
```

#### Opção 3: Armazenamento Específico de Projeto

```python
import os
from pathlib import Path

# Armazenar no diretório do projeto
project_root = Path(__file__).parent
storage_dir = project_root / "crewai_storage"

os.environ["CREWAI_STORAGE_DIR"] = str(storage_dir)

# Todo o armazenamento ficará agora na pasta do projeto
```

### Padrão do Provedor de Embedding

<Info>
  **Provedor de Embedding Padrão**: O CrewAI utiliza embeddings do OpenAI por padrão para garantir consistência e confiabilidade. Você pode facilmente customizar para combinar com seu provedor LLM ou utilizar embeddings locais.
</Info>

#### Compreendendo o Comportamento Padrão

```python
# Ao utilizar Claude como seu LLM...
from crewai import Agent, LLM

agent = Agent(
    role="Analyst",
    goal="Analyze data",
    backstory="Expert analyst",
    llm=LLM(provider="anthropic", model="claude-3-sonnet")  # Usando Claude
)

# O CrewAI usará embeddings OpenAI por padrão para garantir consistência
# Você pode customizar facilmente para combinar com seu provedor preferido
```

#### Personalizando Provedores de Embedding

```python
from crewai import Crew

# Opção 1: Combinar com seu provedor de LLM
crew = Crew(
    agents=[agent],
    tasks=[task],
    memory=True,
    embedder={
        "provider": "anthropic",  # Combine com seu provedor de LLM
        "config": {
            "api_key": "your-anthropic-key",
            "model": "text-embedding-3-small"
        }
    }
)

# Opção 2: Use embeddings locais (sem chamadas para API externa)
crew = Crew(
    agents=[agent],
    tasks=[task],
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    }
)
```

### Depuração de Problemas de Armazenamento

#### Verifique Permissões do Armazenamento

```python
import os
from crewai.utilities.paths import db_storage_path

storage_path = db_storage_path()
print(f"Storage path: {storage_path}")
print(f"Path exists: {os.path.exists(storage_path)}")
print(f"Is writable: {os.access(storage_path, os.W_OK) if os.path.exists(storage_path) else 'Path does not exist'}")

# Crie com permissões apropriadas
if not os.path.exists(storage_path):
    os.makedirs(storage_path, mode=0o755, exist_ok=True)
    print(f"Created storage directory: {storage_path}")
```

#### Inspecione Coleções do ChromaDB

```python
import chromadb
from crewai.utilities.paths import db_storage_path

# Conecte-se ao ChromaDB do CrewAI
storage_path = db_storage_path()
chroma_path = os.path.join(storage_path, "knowledge")

if os.path.exists(chroma_path):
    client = chromadb.PersistentClient(path=chroma_path)
    collections = client.list_collections()

    print("ChromaDB Collections:")
    for collection in collections:
        print(f"  - {collection.name}: {collection.count()} documentos")
else:
    print("No ChromaDB storage found")
```

#### Resetar Armazenamento (Depuração)

```python
from crewai import Crew

# Limpar todo o armazenamento de memória
crew = Crew(agents=[...], tasks=[...], memory=True)

# Limpar tipos específicos de memória
crew.reset_memories(command_type='short')     # Memória de curto prazo
crew.reset_memories(command_type='long')      # Memória de longo prazo
crew.reset_memories(command_type='entity')    # Memória de entidades
crew.reset_memories(command_type='knowledge') # Armazenamento de conhecimento
```

### Melhores Práticas para Produção

1. **Defina o `CREWAI_STORAGE_DIR`** para um local conhecido em produção para maior controle
2. **Escolha explicitamente provedores de embeddings** para coincidir com seu setup de LLM
3. **Monitore o tamanho do diretório de armazenamento** em casos de grande escala
4. **Inclua diretórios de armazenamento** em sua política de backup
5. **Defina permissões apropriadas de arquivo** (0o755 para diretórios, 0o644 para arquivos)
6. **Use caminhos relativos ao projeto** para implantações containerizadas

### Problemas Comuns de Armazenamento

**Erros "ChromaDB permission denied":**

```bash
# Corrija permissões
chmod -R 755 ~/.local/share/CrewAI/
```

**Erros "Database is locked":**

```python
# Certifique-se que apenas uma instância CrewAI acesse o armazenamento
import fcntl
import os

storage_path = db_storage_path()
lock_file = os.path.join(storage_path, ".crewai.lock")

with open(lock_file, 'w') as f:
    fcntl.flock(f.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
    # Seu código CrewAI aqui
```

**Armazenamento não persiste entre execuções:**

```python
# Verifique se o local do armazenamento é consistente
import os
print("CREWAI_STORAGE_DIR:", os.getenv("CREWAI_STORAGE_DIR"))
print("Current working directory:", os.getcwd())
print("Computed storage path:", db_storage_path())
```

## Configuração Personalizada de Embedders

O CrewAI suporta múltiplos provedores de embeddings para oferecer flexibilidade na escolha da melhor opção para seu caso de uso. Aqui está um guia completo para configuração de diferentes provedores de embeddings para seu sistema de memória.

### Por que Escolher Diferentes Provedores de Embeddings?

* **Otimização de Custos**: Embeddings locais (Ollama) são gratuitos após configuração inicial
* **Privacidade**: Mantenha seus dados locais com Ollama ou use seu provedor preferido na nuvem
* **Desempenho**: Alguns modelos têm melhor desempenho para domínios ou idiomas específicos
* **Consistência**: Combine seu provedor de embedding com o de LLM
* **Conformidade**: Atenda a requisitos regulatórios ou organizacionais

### OpenAI Embeddings (Padrão)

A OpenAI oferece embeddings confiáveis e de alta qualidade para a maioria dos cenários.

```python
from crewai import Crew

# Configuração básica OpenAI (usa a variável de ambiente OPENAI_API_KEY)
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "model": "text-embedding-3-small"  # ou "text-embedding-3-large"
        }
    }
)

# Configuração avançada OpenAI
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "api_key": "your-openai-api-key",  # Opcional: sobrescreve variável de ambiente
            "model": "text-embedding-3-large",
            "dimensions": 1536,  # Opcional: reduz as dimensões para armazenamento menor
            "organization_id": "your-org-id"  # Opcional: para contas organizacionais
        }
    }
)
```

### Azure OpenAI Embeddings

Para empresas que utilizam deploys Azure OpenAI.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",  # Use openai como provider para Azure
        "config": {
            "api_key": "your-azure-api-key",
            "api_base": "https://your-resource.openai.azure.com/",
            "api_type": "azure",
            "api_version": "2023-05-15",
            "model": "text-embedding-3-small",
            "deployment_id": "your-deployment-name"  # Nome do deploy Azure
        }
    }
)
```

### Google AI Embeddings

Use modelos de embeddings de texto do Google para integração com serviços do Google Cloud.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "google",
        "config": {
            "api_key": "your-google-api-key",
            "model": "text-embedding-004"  # ou "text-embedding-preview-0409"
        }
    }
)
```

### Vertex AI Embeddings

Para usuários do Google Cloud com acesso ao Vertex AI.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "vertexai",
        "config": {
            "project_id": "your-gcp-project-id",
            "region": "us-central1",  # ou sua região preferencial
            "api_key": "your-service-account-key",
            "model_name": "textembedding-gecko"
        }
    }
)
```

### Ollama Embeddings (Local)

Execute embeddings localmente para privacidade e economia.

```python
# Primeiro, instale e rode Ollama localmente, depois baixe um modelo de embedding:
# ollama pull mxbai-embed-large

crew = Crew(
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {
            "model": "mxbai-embed-large",  # ou "nomic-embed-text"
            "url": "http://localhost:11434/api/embeddings"  # URL padrão do Ollama
        }
    }
)

# Para instalações personalizadas do Ollama
crew = Crew(
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {
            "model": "mxbai-embed-large",
            "url": "http://your-ollama-server:11434/api/embeddings"
        }
    }
)
```

### Cohere Embeddings

Utilize os modelos de embedding da Cohere para suporte multilíngue.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "cohere",
        "config": {
            "api_key": "your-cohere-api-key",
            "model": "embed-english-v3.0"  # ou "embed-multilingual-v3.0"
        }
    }
)
```

### VoyageAI Embeddings

Embeddings de alto desempenho otimizados para tarefas de recuperação.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "voyageai",
        "config": {
            "api_key": "your-voyage-api-key",
            "model": "voyage-large-2",  # ou "voyage-code-2" para código
            "input_type": "document"  # ou "query"
        }
    }
)
```

### AWS Bedrock Embeddings

Para usuários AWS com acesso ao Bedrock.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "bedrock",
        "config": {
            "aws_access_key_id": "your-access-key",
            "aws_secret_access_key": "your-secret-key",
            "region_name": "us-east-1",
            "model": "amazon.titan-embed-text-v1"
        }
    }
)
```

### Hugging Face Embeddings

Utilize modelos open-source do Hugging Face.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "huggingface",
        "config": {
            "api_key": "your-hf-token",  # Opcional para modelos públicos
            "model": "sentence-transformers/all-MiniLM-L6-v2",
            "api_url": "https://api-inference.huggingface.co"  # ou seu endpoint customizado
        }
    }
)
```

### IBM Watson Embeddings

Para usuários do IBM Cloud.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "watson",
        "config": {
            "api_key": "your-watson-api-key",
            "url": "your-watson-instance-url",
            "model": "ibm/slate-125m-english-rtrvr"
        }
    }
)
```

### Como Escolher o Provedor de Embedding Certo

| Provedor         | Melhor Para                    | Prós                        | Contras                    |
| :--------------- | :----------------------------- | :-------------------------- | :------------------------- |
| **OpenAI**       | Uso geral, confiabilidade      | Alta qualidade, bem testado | Custo, requer chave de API |
| **Ollama**       | Privacidade, economia          | Gratuito, local, privado    | Requer configuração local  |
| **Google AI**    | Ecossistema Google             | Bom desempenho              | Requer conta Google        |
| **Azure OpenAI** | Empresas, conformidade         | Recursos corporativos       | Configuração mais complexa |
| **Cohere**       | Conteúdo multilíngue           | Excelente suporte a idiomas | Uso especializado          |
| **VoyageAI**     | Tarefas de busca e recuperação | Otimizado para pesquisa     | Provedor mais novo         |

### Configuração via Variável de Ambiente

Para segurança, armazene chaves de API em variáveis de ambiente:

```python
import os

# Configurar variáveis de ambiente
os.environ["OPENAI_API_KEY"] = "your-openai-key"
os.environ["GOOGLE_API_KEY"] = "your-google-key"
os.environ["COHERE_API_KEY"] = "your-cohere-key"

# Use sem expor as chaves no código
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "model": "text-embedding-3-small"
            # A chave de API será carregada automaticamente da variável de ambiente
        }
    }
)
```

### Testando Diferentes Provedores de Embedding

Compare provedores de embedding para o seu caso de uso específico:

```python
from crewai import Crew
from crewai.utilities.paths import db_storage_path

# Testar diferentes provedores com os mesmos dados
providers_to_test = [
    {
        "name": "OpenAI",
        "config": {
            "provider": "openai",
            "config": {"model": "text-embedding-3-small"}
        }
    },
    {
        "name": "Ollama",
        "config": {
            "provider": "ollama",
            "config": {"model": "mxbai-embed-large"}
        }
    }
]

for provider in providers_to_test:
    print(f"\nTesting {provider['name']} embeddings...")

    # Criar crew com embedder específico
    crew = Crew(
        agents=[...],
        tasks=[...],
        memory=True,
        embedder=provider['config']
    )

    # Execute o teste e meça o desempenho
    result = crew.kickoff()
    print(f"{provider['name']} completed successfully")
```

### Solução de Problemas de Embeddings

**Erros de modelo não encontrado:**

```python
# Verifique disponibilidade do modelo
from crewai.utilities.embedding_configurator import EmbeddingConfigurator

configurator = EmbeddingConfigurator()
try:
    embedder = configurator.configure_embedder({
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    })
    print("Embedder configured successfully")
except Exception as e:
    print(f"Configuration error: {e}")
```

**Problemas com chave de API:**

```python
import os

# Verifique se as chaves de API estão configuradas
required_keys = ["OPENAI_API_KEY", "GOOGLE_API_KEY", "COHERE_API_KEY"]
for key in required_keys:
    if os.getenv(key):
        print(f"✅ {key} is set")
    else:
        print(f"❌ {key} is not set")
```

**Comparação de desempenho:**

```python
import time

def test_embedding_performance(embedder_config, test_text="This is a test document"):
    start_time = time.time()

    crew = Crew(
        agents=[...],
        tasks=[...],
        memory=True,
        embedder=embedder_config
    )

    # Simula operação de memória
    crew.kickoff()

    end_time = time.time()
    return end_time - start_time

# Comparar desempenho
openai_time = test_embedding_performance({
    "provider": "openai",
    "config": {"model": "text-embedding-3-small"}
})

ollama_time = test_embedding_performance({
    "provider": "ollama",
    "config": {"model": "mxbai-embed-large"}
})

print(f"OpenAI: {openai_time:.2f}s")
print(f"Ollama: {ollama_time:.2f}s")
```

## 2. Memória de Usuário com Mem0 (Legado)

<Warning>
  **Abordagem Legada**: Embora totalmente funcional, esta abordagem é considerada legada. Para novos projetos que exijam memória específica do usuário, considere usar Memória Externa.
</Warning>

A Memória de Usuário se integra com o [Mem0](https://mem0.ai/) para fornecer memória específica do usuário que persiste entre sessões e se integra ao sistema de memória contextual da crew.

### Pré-requisitos

```bash
pip install mem0ai
```

### Configuração Mem0 na Nuvem

```python
import os
from crewai import Crew, Process

# Defina sua chave de API do Mem0
os.environ["MEM0_API_KEY"] = "m0-your-api-key"

crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,  # Necessário para integração com a memória contextual
    memory_config={
        "provider": "mem0",
        "config": {"user_id": "john"},
        "user_memory": {}  # Obrigatório - inicializa a memória de usuário
    },
    process=Process.sequential,
    verbose=True
)
```

### Configuração Avançada Mem0

```python
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,
    memory_config={
        "provider": "mem0",
        "config": {
            "user_id": "john",
            "org_id": "my_org_id",        # Opcional
            "project_id": "my_project_id", # Opcional
            "api_key": "custom-api-key"    # Opcional - sobrescreve variável de ambiente
        },
        "user_memory": {}
    }
)
```

### Configuração Mem0 Local

```python
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,
    memory_config={
        "provider": "mem0",
        "config": {
            "user_id": "john",
            "local_mem0_config": {
                "vector_store": {
                    "provider": "qdrant",
                    "config": {"host": "localhost", "port": 6333}
                },
                "llm": {
                    "provider": "openai",
                    "config": {"api_key": "your-api-key", "model": "gpt-4"}
                },
                "embedder": {
                    "provider": "openai",
                    "config": {"api_key": "your-api-key", "model": "text-embedding-3-small"}
                }
            }
        },
        "user_memory": {}
    }
)
```

## 3. Memória Externa (Nova Abordagem)

A Memória Externa fornece um sistema de memória autônomo que opera independentemente da memória interna da crew. Isso é ideal para provedores de memória especializados ou compartilhamento de memória entre aplicações.

### Memória Externa Básica com Mem0

```python
import os
from crewai import Agent, Crew, Process, Task
from crewai.memory.external.external_memory import ExternalMemory

os.environ["MEM0_API_KEY"] = "your-api-key"

# Criar instância de memória externa
external_memory = ExternalMemory(
    embedder_config={
        "provider": "mem0",
        "config": {"user_id": "U-123"}
    }
)

crew = Crew(
    agents=[...],
    tasks=[...],
    external_memory=external_memory,  # Independente da memória básica
    process=Process.sequential,
    verbose=True
)
```

### Implementação Personalizada de Armazenamento

```python
from crewai.memory.external.external_memory import ExternalMemory
from crewai.memory.storage.interface import Storage

class CustomStorage(Storage):
    def __init__(self):
        self.memories = []

    def save(self, value, metadata=None, agent=None):
        self.memories.append({
            "value": value,
            "metadata": metadata,
            "agent": agent
        })

    def search(self, query, limit=10, score_threshold=0.5):
        # Implemente sua lógica de busca aqui
        return [m for m in self.memories if query.lower() in str(m["value"]).lower()]

    def reset(self):
        self.memories = []

# Usando armazenamento customizado
external_memory = ExternalMemory(storage=CustomStorage())

crew = Crew(
    agents=[...],
    tasks=[...],
    external_memory=external_memory
)
```

## Comparação dos Sistemas de Memória

| Recurso                       | Memória Básica       | Memória de Usuário (Legado)        | Memória Externa             |
| ----------------------------- | -------------------- | ---------------------------------- | --------------------------- |
| **Complexidade de Setup**     | Simples              | Média                              | Média                       |
| **Integração**                | Contextual integrada | Contextual + específica do usuário | Autônoma                    |
| **Armazenamento**             | Arquivos locais      | Mem0 Cloud/Local                   | Customizada/Mem0            |
| **Multi-sessão**              | ✅                    | ✅                                  | ✅                           |
| **Especificidade do Usuário** | ❌                    | ✅                                  | ✅                           |
| **Provedores Customizados**   | Limitado             | Apenas Mem0                        | Qualquer provedor           |
| **Recomendado para**          | Maioria dos casos    | Projetos legados                   | Necessidades especializadas |

## Provedores de Embedding Suportados

### OpenAI (Padrão)

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {"model": "text-embedding-3-small"}
    }
)
```

### Ollama

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    }
)
```

### Google AI

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "google",
        "config": {
            "api_key": "your-api-key",
            "model": "text-embedding-004"
        }
    }
)
```

### Azure OpenAI

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "api_key": "your-api-key",
            "api_base": "https://your-resource.openai.azure.com/",
            "api_version": "2023-05-15",
            "model_name": "text-embedding-3-small"
        }
    }
)
```

### Vertex AI

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "vertexai",
        "config": {
            "project_id": "your-project-id",
            "region": "your-region",
            "api_key": "your-api-key",
            "model_name": "textembedding-gecko"
        }
    }
)
```

## Melhores Práticas de Segurança

### Variáveis de Ambiente

```python
import os
from crewai import Crew

# Armazene dados sensíveis em variáveis de ambiente
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "api_key": os.getenv("OPENAI_API_KEY"),
            "model": "text-embedding-3-small"
        }
    }
)
```

### Segurança no Armazenamento

```python
import os
from crewai import Crew
from crewai.memory import LongTermMemory
from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage

# Use caminhos seguros para armazenamento
storage_path = os.getenv("CREWAI_STORAGE_DIR", "./storage")
os.makedirs(storage_path, mode=0o700, exist_ok=True)  # Permissões restritas

crew = Crew(
    memory=True,
    long_term_memory=LongTermMemory(
        storage=LTMSQLiteStorage(
            db_path=f"{storage_path}/memory.db"
        )
    )
)
```

## Solução de Problemas

### Problemas Comuns

**A memória não está persistindo entre sessões?**

* Verifique a variável de ambiente `CREWAI_STORAGE_DIR`
* Garanta permissões de escrita no diretório de armazenamento
* Certifique-se que a memória está ativada com `memory=True`

**Erros de autenticação no Mem0?**

* Verifique se a variável de ambiente `MEM0_API_KEY` está definida
* Confira permissões da chave de API no painel do Mem0
* Certifique-se de que o pacote `mem0ai` está instalado

**Alto uso de memória com grandes volumes de dados?**

* Considere usar Memória Externa com armazenamento personalizado
* Implemente paginação nos métodos de busca do armazenamento customizado
* Utilize modelos de embedding menores para menor consumo de memória

### Dicas de Desempenho

* Use `memory=True` para a maioria dos casos (mais simples e rápido)
* Só utilize Memória de Usuário se precisar de persistência específica por usuário
* Considere Memória Externa para necessidades de grande escala ou especializadas
* Prefira modelos de embedding menores para maior rapidez
* Defina limites apropriados de busca para controlar o tamanho da recuperação

## Benefícios do Sistema de Memória do CrewAI

* 🦾 **Aprendizado Adaptativo:** As crews tornam-se mais eficientes ao longo do tempo, adaptando-se a novas informações e refinando sua abordagem para tarefas.
* 🫡 **Personalização Avançada:** A memória permite que agentes lembrem preferências do usuário e interações passadas, proporcionando experiências personalizadas.
* 🧠 **Melhoria na Resolução de Problemas:** O acesso a um rico acervo de memória auxilia os agentes a tomar decisões mais informadas, recorrendo a aprendizados prévios e contextuais.

## Conclusão

Integrar o sistema de memória do CrewAI em seus projetos é simples. Ao aproveitar os componentes e configurações oferecidos,
você rapidamente capacita seus agentes a lembrar, raciocinar e aprender com suas interações, desbloqueando novos níveis de inteligência e capacidade.


# Planejamento
Source: https://docs.crewai.com/pt-BR/concepts/planning

Aprenda como adicionar planejamento à sua CrewAI Crew e melhorar sua performance.

## Visão geral

O recurso de planejamento no CrewAI permite que você adicione capacidade de planejamento à sua crew. Quando ativado, antes de cada iteração da Crew, todas as informações da Crew são enviadas para um AgentPlanner que irá planejar as tarefas passo a passo, e este plano será adicionado à descrição de cada tarefa.

### Usando o recurso de Planejamento

Começar a usar o recurso de planejamento é muito simples, o único passo necessário é adicionar `planning=True` à sua Crew:

<CodeGroup>
  ```python Code
  from crewai import Crew, Agent, Task, Process

  # Monte sua crew com capacidades de planejamento
  minha_crew = Crew(
      agents=self.agents,
      tasks=self.tasks,
      process=Process.sequential,
      planning=True,
  )
  ```
</CodeGroup>

A partir deste ponto, sua crew terá o planejamento ativado, e as tarefas serão planejadas antes de cada iteração.

<Warning>
  Quando o planejamento está ativado, o crewAI irá usar `gpt-4o-mini` como o LLM padrão para planejamento, o que requer uma chave de API válida da OpenAI. Como seus agentes podem estar usando LLMs diferentes, isso pode causar confusão se você não tiver uma chave de API da OpenAI configurada ou se estiver experimentando um comportamento inesperado relacionado a chamadas de API de LLM.
</Warning>

#### LLM de Planejamento

Agora você pode definir qual LLM será usado para planejar as tarefas.

Ao executar o exemplo básico, você verá algo semelhante ao resultado abaixo, que representa a saída do `AgentPlanner` responsável por criar a lógica passo a passo a ser adicionada às tarefas dos Agents.

<CodeGroup>
  ```python Code
  from crewai import Crew, Agent, Task, Process

  # Monte sua crew com capacidades de planejamento e LLM personalizado
  my_crew = Crew(
      agents=self.agents,
      tasks=self.tasks,
      process=Process.sequential,
      planning=True,
      planning_llm="gpt-4o"
  )

  # Execute a crew
  my_crew.kickoff()
  ```

  ````markdown Result
  [2024-07-15 16:49:11][INFO]: Planejando a execução da crew
  **Plano Passo a Passo para Execução das Tarefas**

  **Tarefa Número 1: Realizar uma pesquisa aprofundada sobre LLMs de IA**

  **Agente:** Pesquisador Sênior de Dados de LLMs de IA

  **Objetivo do Agente:** Descobrir avanços de ponta em LLMs de IA

  **Resultado Esperado da Tarefa:** Uma lista com 10 tópicos dos dados mais relevantes sobre LLMs de IA

  **Ferramentas da Tarefa:** Nenhuma especificada

  **Ferramentas do Agente:** Nenhuma especificada

  **Plano Passo a Passo:**

  1. **Definir o Escopo da Pesquisa:**

     - Determine as áreas específicas de LLMs de IA a focar, como avanços em arquitetura, casos de uso, considerações éticas e métricas de performance.

  2. **Identificar Fontes Confiáveis:**

     - Liste fontes confiáveis para pesquisa em IA, incluindo periódicos acadêmicos, relatórios da indústria, conferências (ex: NeurIPS, ACL), laboratórios de pesquisa em IA (ex: OpenAI, Google AI) e bancos de dados online (ex: IEEE Xplore, arXiv).

  3. **Coletar Dados:**

     - Procure pelos artigos, publicações e relatórios mais recentes publicados em 2024 e início de 2025.
     - Use palavras-chave como "Large Language Models 2025", "Avanços em LLM de IA", "Ética em IA 2025", etc.

  4. **Analisar Resultados:**

     - Leia e resuma os principais pontos de cada fonte.
     - Destaque novas técnicas, modelos e aplicações introduzidos no último ano.

  5. **Organizar as Informações:**

     - Categorize as informações em tópicos relevantes (ex: novas arquiteturas, implicações éticas, aplicações no mundo real).
     - Garanta que cada tópico seja conciso, mas informativo.

  6. **Criar a Lista:**

     - Compile os 10 dados mais relevantes em itens de uma lista.
     - Revise a lista para garantir clareza e relevância.

  **Saída Esperada:**

  Uma lista com 10 tópicos dos dados mais relevantes sobre LLMs de IA.

  ---

  **Tarefa Número 2: Revise o contexto obtido e expanda cada tópico em uma seção completa para um relatório**

  **Agente:** Analista de Relatórios de LLMs de IA

  **Objetivo do Agente:** Criar relatórios detalhados baseados na análise de dados e pesquisa sobre LLMs de IA

  **Resultado Esperado da Tarefa:** Um relatório completo com os principais tópicos, cada um com uma seção completa de informações. Formatado em markdown sem '```'

  **Ferramentas da Tarefa:** Nenhuma especificada

  **Ferramentas do Agente:** Nenhuma especificada

  **Plano Passo a Passo:**

  1. **Revisar os Tópicos:**
     - Leia atentamente a lista dos 10 tópicos fornecida pelo Pesquisador Sênior de Dados de LLMs de IA.

  2. **Esboçar o Relatório:**
     - Crie um esboço com cada tópico como título principal da seção.
     - Planeje subseções sob cada título para abordar diferentes aspectos do tema.

  3. **Pesquisar Detalhes Adicionais:**
     - Para cada tópico, conduza pesquisa adicional, se necessário, para reunir informações mais detalhadas.
     - Busque estudos de caso, exemplos e dados estatísticos para embasar cada seção.

  4. **Redigir Seções Detalhadas:**
     - Expanda cada tópico em uma seção abrangente.
     - Certifique-se de que cada seção inclua introdução, explicação detalhada, exemplos e conclusão.
     - Utilize formatação markdown para títulos, subtítulos, listas e ênfase.

  5. **Revisar e Editar:**
     - Revise o relatório para garantir clareza, coerência e correção.
     - Garanta uma sequência lógica de uma seção para a outra.
     - Formate o relatório conforme os padrões markdown.

  6. **Finalizar o Relatório:**
     - Certifique-se de que o relatório está completo, com todas as seções expandidas e detalhadas.
     - Faça uma última verificação de formatação e ajustes necessários.

  **Saída Esperada:**
  Um relatório completo com os principais tópicos, cada um com uma seção cheia de informações. Formatado em markdown sem '```'.
  ````
</CodeGroup>


# Processos
Source: https://docs.crewai.com/pt-BR/concepts/processes

Guia detalhado sobre o gerenciamento de fluxos de trabalho através de processos no CrewAI, com detalhes de implementação atualizados.

## Visão Geral

<Tip>
  Processos orquestram a execução de tarefas por agentes, de maneira semelhante à gestão de projetos em equipes humanas.
  Esses processos garantem que as tarefas sejam distribuídas e executadas de forma eficiente, alinhadas a uma estratégia predefinida.
</Tip>

## Implementações de Processos

* **Sequencial**: Executa tarefas de forma sequencial, garantindo que as tarefas sejam concluídas em uma progressão ordenada.
* **Hierárquico**: Organiza tarefas em uma hierarquia gerencial, onde as tarefas são delegadas e executadas com base numa cadeia de comando estruturada. Um modelo de linguagem de gerente (`manager_llm`) ou um agente gerente personalizado (`manager_agent`) deve ser especificado na crew para habilitar o processo hierárquico, facilitando a criação e o gerenciamento de tarefas pelo gerente.
* **Processo Consensual (Planejado)**: Visando a tomada de decisão colaborativa entre agentes para execução de tarefas, esse tipo de processo introduz uma abordagem democrática ao gerenciamento de tarefas dentro do CrewAI. Está planejado para desenvolvimento futuro e ainda não está implementado no código-fonte.

## O Papel dos Processos no Trabalho em Equipe

Os processos permitem que agentes individuais atuem como uma unidade coesa, otimizando seus esforços para atingir objetivos comuns com eficiência e coerência.

## Atribuindo Processos a uma Crew

Para atribuir um processo a uma crew, especifique o tipo de processo ao criar a crew para definir a estratégia de execução. Para um processo hierárquico, garanta a definição de `manager_llm` ou `manager_agent` para o agente gerente.

```python
from crewai import Crew, Process

# Exemplo: Criando uma crew com processo sequencial
crew = Crew(
    agents=meus_agentes,
    tasks=minhas_tarefas,
    process=Process.sequential
)

# Exemplo: Criando uma crew com processo hierárquico
# Certifique-se de fornecer um manager_llm ou manager_agent
crew = Crew(
    agents=meus_agentes,
    tasks=minhas_tarefas,
    process=Process.hierarchical,
    manager_llm="gpt-4o"
    # ou
    # manager_agent=meu_agente_gerente
)
```

**Nota:** Certifique-se de que `meus_agentes` e `minhas_tarefas` estejam definidos antes de criar o objeto `Crew`, e para o processo hierárquico, é necessário também fornecer o `manager_llm` ou `manager_agent`.

## Processo Sequencial

Este método reflete fluxos de trabalho dinâmicos de equipes, progredindo nas tarefas de maneira cuidadosa e sistemática. A execução das tarefas segue a ordem preestabelecida na lista de tarefas, com a saída de uma tarefa servindo de contexto para a próxima.

Para personalizar o contexto das tarefas, utilize o parâmetro `context` na classe `Task` para especificar as saídas que devem ser usadas como contexto para as tarefas subsequentes.

## Processo Hierárquico

Emulando uma hierarquia corporativa, o CrewAI permite especificar um agente gerente personalizado ou criar um automaticamente, exigindo a especificação de um modelo de linguagem de gerente (`manager_llm`). Esse agente supervisiona a execução das tarefas, incluindo planejamento, delegação e validação. As tarefas não são pré-atribuídas; o gerente aloca tarefas aos agentes com base em suas capacidades, revisa as saídas e avalia a conclusão das tarefas.

## Classe Process: Visão Detalhada

A classe `Process` é implementada como uma enumeração (`Enum`), garantindo segurança de tipo e restringindo os valores de processos aos tipos definidos (`sequential`, `hierarchical`). O processo consensual está planejado para inclusão futura, reforçando nosso compromisso com o desenvolvimento contínuo e a inovação.

## Conclusão

A colaboração estruturada possibilitada pelos processos dentro do CrewAI é fundamental para permitir o trabalho em equipe sistemático entre agentes.
Esta documentação foi atualizada para refletir os mais recentes recursos, melhorias e a planejada integração do Processo Consensual, garantindo que os usuários tenham acesso às informações mais atuais e abrangentes.


# Reasoning
Source: https://docs.crewai.com/pt-BR/concepts/reasoning

Aprenda como habilitar e usar o reasoning do agente para aprimorar a execução de tarefas.

## Visão Geral

O reasoning do agente é um recurso que permite que agentes reflitam sobre uma tarefa e criem um plano antes da execução. Isso ajuda os agentes a abordarem tarefas de forma mais metódica e garante que estejam preparados para realizar o trabalho atribuído.

## Uso

Para habilitar o reasoning para um agente, basta definir `reasoning=True` ao criar o agente:

```python
from crewai import Agent

analista = Agent(
    role="Analista de Dados",
    goal="Analisar dados e fornecer insights",
    backstory="Você é um analista de dados especialista.",
    reasoning=True,
    max_reasoning_attempts=3  # Opcional: Defina um limite de tentativas de reasoning
)
```

## Como Funciona

Quando o reasoning está habilitado, antes de executar uma tarefa, o agente irá:

1. Refletir sobre a tarefa e criar um plano detalhado
2. Avaliar se está pronto para executar a tarefa
3. Refinar o plano conforme necessário até estar pronto ou até o limite de max\_reasoning\_attempts ser atingido
4. Inserir o plano de reasoning na descrição da tarefa antes da execução

Esse processo ajuda o agente a dividir tarefas complexas em etapas gerenciáveis e identificar potenciais desafios antes de começar.

## Opções de Configuração

<ParamField body="reasoning" type="bool" default="False">
  Ativa ou desativa o reasoning
</ParamField>

<ParamField body="max_reasoning_attempts" type="int" default="None">
  Número máximo de tentativas para refinar o plano antes de prosseguir com a execução. Se None (padrão), o agente continuará refinando até que esteja pronto.
</ParamField>

## Exemplo

Aqui está um exemplo completo:

```python
from crewai import Agent, Task, Crew

# Create an agent with reasoning enabled
analista = Agent(
    role="Analista de Dados",
    goal="Analisar dados e fornecer insights",
    backstory="Você é um analista de dados especialista.",
    reasoning=True,
    max_reasoning_attempts=3  # Opcional: Defina um limite de tentativas de reasoning
)

# Create a task
analysis_task = Task(
    description="Analise os dados de vendas fornecidos e identifique as principais tendências.",
    expected_output="Um relatório destacando as 3 principais tendências de vendas.",
    agent=analista
)

# Create a crew and run the task
crew = Crew(agents=[analista], tasks=[analysis_task])
result = crew.kickoff()

print(result)
```

## Tratamento de Erros

O processo de reasoning foi projetado para ser robusto, com tratamento de erros integrado. Se ocorrer um erro durante o reasoning, o agente prosseguirá com a execução da tarefa sem o plano de reasoning. Isso garante que as tarefas ainda possam ser executadas mesmo que o processo de reasoning falhe.

Veja como lidar com possíveis erros no seu código:

```python
from crewai import Agent, Task
import logging

# Set up logging to capture any reasoning errors
logging.basicConfig(level=logging.INFO)

# Create an agent with reasoning enabled
agent = Agent(
    role="Analista de Dados",
    goal="Analisar dados e fornecer insights",
    reasoning=True,
    max_reasoning_attempts=3
)

# Create a task
task = Task(
    description="Analise os dados de vendas fornecidos e identifique as principais tendências.",
    expected_output="Um relatório destacando as 3 principais tendências de vendas.",
    agent=agent
)

# Execute the task
# If an error occurs during reasoning, it will be logged and execution will continue
result = agent.execute_task(task)
```

## Exemplo de Saída de reasoning

Veja um exemplo de como pode ser um plano de reasoning para uma tarefa de análise de dados:

```
Task: Analise os dados de vendas fornecidos e identifique as principais tendências.

Reasoning Plan:
I'll analyze the sales data to identify the top 3 trends.

1. Understanding of the task:
   I need to analyze sales data to identify key trends that would be valuable for business decision-making.

2. Key steps I'll take:
   - First, I'll examine the data structure to understand what fields are available
   - Then I'll perform exploratory data analysis to identify patterns
   - Next, I'll analyze sales by time periods to identify temporal trends
   - I'll also analyze sales by product categories and customer segments
   - Finally, I'll identify the top 3 most significant trends

3. Approach to challenges:
   - If the data has missing values, I'll decide whether to fill or filter them
   - If the data has outliers, I'll investigate whether they're valid data points or errors
   - If trends aren't immediately obvious, I'll apply statistical methods to uncover patterns

4. Use of available tools:
   - I'll use data analysis tools to explore and visualize the data
   - I'll use statistical tools to identify significant patterns
   - I'll use knowledge retrieval to access relevant information about sales analysis

5. Expected outcome:
   A concise report highlighting the top 3 sales trends with supporting evidence from the data.

READY: I am ready to execute the task.
```

Esse plano de reasoning ajuda o agente a organizar sua abordagem para a tarefa, considerar possíveis desafios e garantir que entregará o resultado esperado.


# Tarefas
Source: https://docs.crewai.com/pt-BR/concepts/tasks

Guia detalhado sobre como gerenciar e criar tarefas dentro do framework CrewAI.

## Visão Geral

No framework CrewAI, uma `Task` (Tarefa) é uma atribuição específica executada por um `Agent` (Agente).

As tarefas fornecem todos os detalhes necessários para sua execução, como descrição, agente responsável, ferramentas exigidas e mais, facilitando uma ampla gama de complexidades de ação.

As tarefas dentro do CrewAI podem ser colaborativas, exigindo que múltiplos agentes trabalhem juntos. Isso é gerenciado por meio das propriedades da tarefa e orquestrado pelo processo do Crew, potencializando o trabalho em equipe e a eficiência.

<Note type="info" title="Aprimoramento Empresarial: Construtor Visual de Tarefas">
  O CrewAI Enterprise inclui um Construtor Visual de Tarefas no Crew Studio, que simplifica a criação e o encadeamento de tarefas complexas. Projete seus fluxos de tarefas visualmente e teste-os em tempo real sem necessidade de escrever código.

  ![Task Builder Screenshot](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-studio-interface.png)

  O Construtor Visual de Tarefas permite:

  * Criação de tarefas via arrastar-e-soltar
  * Visualização de dependências e fluxo de tarefas
  * Testes e validações em tempo real
  * Fácil compartilhamento e colaboração
</Note>

### Fluxo de Execução de Tarefas

As tarefas podem ser executadas de duas maneiras:

* **Sequencial**: As tarefas são executadas na ordem em que são definidas
* **Hierárquica**: As tarefas são atribuídas aos agentes com base em seus papéis e especialidades

O fluxo de execução é definido ao criar o crew:

```python Code
crew = Crew(
    agents=[agent1, agent2],
    tasks=[task1, task2],
    process=Process.sequential  # ou Process.hierarchical
)
```

## Atributos da Tarefa

| Atributo                          | Parâmetros        | Tipo                        | Descrição                                                                                               |
| :-------------------------------- | :---------------- | :-------------------------- | :------------------------------------------------------------------------------------------------------ |
| **Descrição**                     | `description`     | `str`                       | Uma declaração clara e concisa do que a tarefa envolve.                                                 |
| **Saída Esperada**                | `expected_output` | `str`                       | Uma descrição detalhada de como deve ser o resultado da tarefa concluída.                               |
| **Nome** *(opcional)*             | `name`            | `Optional[str]`             | Um identificador de nome para a tarefa.                                                                 |
| **Agente** *(opcional)*           | `agent`           | `Optional[BaseAgent]`       | O agente responsável por executar a tarefa.                                                             |
| **Ferramentas** *(opcional)*      | `tools`           | `List[BaseTool]`            | As ferramentas/recursos que o agente pode usar para esta tarefa.                                        |
| **Contexto** *(opcional)*         | `context`         | `Optional[List["Task"]]`    | Outras tarefas cujas saídas serão usadas como contexto para esta tarefa.                                |
| **Execução Assíncrona** *(opc.)*  | `async_execution` | `Optional[bool]`            | Se a tarefa deve ser executada de forma assíncrona. O padrão é False.                                   |
| **Input Humano** *(opcional)*     | `human_input`     | `Optional[bool]`            | Se a tarefa deve ter uma revisão humana da resposta final do agente. O padrão é False.                  |
| **Markdown** *(opcional)*         | `markdown`        | `Optional[bool]`            | Se a tarefa deve instruir o agente a retornar a resposta final formatada em Markdown. O padrão é False. |
| **Config** *(opcional)*           | `config`          | `Optional[Dict[str, Any]]`  | Parâmetros de configuração específicos da tarefa.                                                       |
| **Arquivo de Saída** *(opcional)* | `output_file`     | `Optional[str]`             | Caminho do arquivo para armazenar a saída da tarefa.                                                    |
| **Saída JSON** *(opcional)*       | `output_json`     | `Optional[Type[BaseModel]]` | Um modelo Pydantic para estruturar a saída em JSON.                                                     |
| **Output Pydantic** *(opcional)*  | `output_pydantic` | `Optional[Type[BaseModel]]` | Um modelo Pydantic para a saída da tarefa.                                                              |
| **Callback** *(opcional)*         | `callback`        | `Optional[Any]`             | Função/objeto a ser executado após a conclusão da tarefa.                                               |

## Criando Tarefas

Existem duas maneiras de criar tarefas no CrewAI: utilizando **configuração YAML (recomendado)** ou definindo-as **diretamente no código**.

### Configuração YAML (Recomendado)

Utilizar configuração YAML oferece uma forma mais limpa e de fácil manutenção para definir tarefas. Recomendamos fortemente esse método em seus projetos CrewAI.

Após criar seu projeto CrewAI conforme indicado na seção [Instalação](/pt-BR/installation), navegue até o arquivo `src/latest_ai_development/config/tasks.yaml` e modifique o template para refletir os requisitos específicos das tarefas.

<Note>
  Variáveis em seus arquivos YAML (como `{topic}`) serão substituídas por valores vindos dos seus inputs ao executar o crew:

  ```python Code
  crew.kickoff(inputs={'topic': 'AI Agents'})
  ```
</Note>

Veja um exemplo de configuração de tarefas usando YAML:

````yaml tasks.yaml
research_task:
  description: >
    Realize uma pesquisa detalhada sobre {topic}
    Certifique-se de encontrar informações interessantes e relevantes considerando
    que o ano atual é 2025.
  expected_output: >
    Uma lista com 10 tópicos em bullet points das informações mais relevantes sobre {topic}
  agent: researcher

reporting_task:
  description: >
    Revise o contexto recebido e expanda cada tópico em uma seção completa de um relatório.
    Certifique-se de que o relatório seja detalhado e contenha todas as informações relevantes.
  expected_output: >
    Um relatório completo com os principais tópicos, cada um com uma seção cheia de informações.
    Formatado em markdown sem '```'
  agent: reporting_analyst
  markdown: true
  output_file: report.md
````

Para usar essa configuração YAML em seu código, crie uma classe crew que herda de `CrewBase`:

```python crew.py
# src/latest_ai_development/crew.py

from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task
from crewai_tools import SerperDevTool

@CrewBase
class LatestAiDevelopmentCrew():
  """LatestAiDevelopment crew"""

  @agent
  def researcher(self) -> Agent:
    return Agent(
      config=self.agents_config['researcher'], # type: ignore[index]
      verbose=True,
      tools=[SerperDevTool()]
    )

  @agent
  def reporting_analyst(self) -> Agent:
    return Agent(
      config=self.agents_config['reporting_analyst'], # type: ignore[index]
      verbose=True
    )

  @task
  def research_task(self) -> Task:
    return Task(
      config=self.tasks_config['research_task'] # type: ignore[index]
    )

  @task
  def reporting_task(self) -> Task:
    return Task(
      config=self.tasks_config['reporting_task'] # type: ignore[index]
    )

  @crew
  def crew(self) -> Crew:
    return Crew(
      agents=[
        self.researcher(),
        self.reporting_analyst()
      ],
      tasks=[
        self.research_task(),
        self.reporting_task()
      ],
      process=Process.sequential
    )
```

<Note>
  Os nomes usados em seus arquivos YAML (`agents.yaml` e `tasks.yaml`) devem corresponder aos nomes dos métodos no seu código Python.
</Note>

### Definição Direta no Código (Alternativa)

Alternativamente, você pode definir tarefas diretamente no seu código sem usar configuração YAML:

```python task.py
from crewai import Task

research_task = Task(
    description="""
        Realize uma pesquisa detalhada sobre AI Agents.
        Certifique-se de encontrar informações interessantes e relevantes considerando
        que o ano atual é 2025.
    """,
    expected_output="""
        Uma lista com 10 tópicos em bullet points das informações mais relevantes sobre AI Agents
    """,
    agent=researcher
)

reporting_task = Task(
    description="""
        Revise o contexto recebido e expanda cada tópico em uma seção completa de um relatório.
        Certifique-se de que o relatório seja detalhado e contenha todas as informações relevantes.
    """,
    expected_output="""
        Um relatório completo com os principais tópicos, cada um com uma seção cheia de informações.
    """,
    agent=reporting_analyst,
    markdown=True,  # Ativa formatação markdown para a saída final
    output_file="report.md"
)
```

<Tip>
  Especifique diretamente um `agent` para a tarefa ou permita que o processo `hierarchical` do CrewAI decida com base em papéis, disponibilidade, etc.
</Tip>

## Saída da Tarefa

Compreender as saídas das tarefas é crucial para construir fluxos de trabalho de IA eficazes. O CrewAI oferece uma maneira estruturada de lidar com resultados usando a classe `TaskOutput`, que suporta múltiplos formatos de saída e pode ser facilmente passada entre tarefas.

A saída de uma tarefa no framework CrewAI é encapsulada na classe `TaskOutput`. Essa classe fornece uma maneira estruturada de acessar os resultados da tarefa, incluindo vários formatos como saída bruta, JSON e modelos Pydantic.

Por padrão, o `TaskOutput` incluirá apenas a saída `raw`. Um `TaskOutput` só terá as saídas `pydantic` ou `json_dict` se o objeto original da `Task` estiver configurado com `output_pydantic` ou `output_json`, respectivamente.

### Atributos do Task Output

| Atributo          | Parâmetros      | Tipo                       | Descrição                                                                                 |
| :---------------- | :-------------- | :------------------------- | :---------------------------------------------------------------------------------------- |
| **Description**   | `description`   | `str`                      | Descrição da tarefa.                                                                      |
| **Summary**       | `summary`       | `Optional[str]`            | Resumo da tarefa, gerado automaticamente a partir das primeiras 10 palavras da descrição. |
| **Raw**           | `raw`           | `str`                      | Saída bruta da tarefa. Este é o formato padrão da saída.                                  |
| **Pydantic**      | `pydantic`      | `Optional[BaseModel]`      | Objeto modelo Pydantic representando a saída da tarefa de forma estruturada.              |
| **JSON Dict**     | `json_dict`     | `Optional[Dict[str, Any]]` | Dicionário representando a saída da tarefa em JSON.                                       |
| **Agent**         | `agent`         | `str`                      | O agente que executou a tarefa.                                                           |
| **Output Format** | `output_format` | `OutputFormat`             | O formato da saída da tarefa, podendo ser RAW, JSON e Pydantic. O padrão é RAW.           |

### Métodos e Propriedades da Tarefa

| Método/Propriedade | Descrição                                                                                            |
| :----------------- | :--------------------------------------------------------------------------------------------------- |
| **json**           | Retorna a representação da saída da tarefa em JSON como string, se o formato de saída for JSON.      |
| **to\_dict**       | Converte as saídas JSON e Pydantic para um dicionário.                                               |
| **str**            | Retorna a representação em string da saída da tarefa, priorizando Pydantic, depois JSON, depois raw. |

### Acessando Saídas das Tarefas

Uma vez que a tarefa é executada, sua saída pode ser acessada pelo atributo `output` do objeto `Task`. A classe `TaskOutput` oferece várias formas de interagir e apresentar esse resultado.

#### Exemplo

```python Code
# Exemplo de tarefa
task = Task(
    description='Encontre e resuma as últimas notícias de IA',
    expected_output='Uma lista em bullet points com o resumo das 5 notícias mais importantes de IA',
    agent=research_agent,
    tools=[search_tool]
)

# Executando o crew
crew = Crew(
    agents=[research_agent],
    tasks=[task],
    verbose=True
)

result = crew.kickoff()

# Acessando a saída da tarefa
task_output = task.output

print(f"Descrição da Tarefa: {task_output.description}")
print(f"Resumo da Tarefa: {task_output.summary}")
print(f"Saída Bruta: {task_output.raw}")
if task_output.json_dict:
    print(f"Saída em JSON: {json.dumps(task_output.json_dict, indent=2)}")
if task_output.pydantic:
    print(f"Saída Pydantic: {task_output.pydantic}")
```

## Formatação Markdown na Saída

O parâmetro `markdown` ativa a formatação automática em markdown na saída das tarefas. Quando configurado como `True`, a tarefa irá instruir o agente a formatar a resposta final utilizando a sintaxe Markdown correta.

### Usando Formatação Markdown

```python Code
# Exemplo de tarefa com formatação markdown ativada
formatted_task = Task(
    description="Crie um relatório abrangente sobre tendências em IA",
    expected_output="Um relatório bem estruturado com títulos, seções e bullet points",
    agent=reporter_agent,
    markdown=True  # Habilita a formatação automática em markdown
)
```

Quando `markdown=True`, o agente recebe instruções extras para formatar a saída usando:

* `#` para títulos
* `**texto**` para negrito
* `*texto*` para itálico
* `-` ou `*` para bullet points
* `` `código` `` para código inline
* ` `linguagem \`\`\` para blocos de código

### Configuração YAML com Markdown

```yaml tasks.yaml
analysis_task:
  description: >
    Analise os dados de mercado e crie um relatório detalhado
  expected_output: >
    Uma análise completa com gráficos e descobertas-chave
  agent: analyst
  markdown: true  # Habilita formatação em markdown
  output_file: analysis.md
```

### Benefícios da Saída Markdown

* **Formatação Consistente**: Garante que todas as saídas sigam as convenções de markdown
* **Maior Legibilidade**: Conteúdo estruturado com títulos, listas e ênfase
* **Pronto para Documentação**: A saída pode ser usada diretamente em sistemas de documentação
* **Compatibilidade Multi-plataforma**: Markdown é universalmente suportado

<Note>
  As instruções de formatação em markdown são adicionadas automaticamente ao prompt da tarefa quando `markdown=True`, então não é necessário detalhar os requisitos de formatação na descrição da tarefa.
</Note>

## Dependências de Tarefas e Contexto

As tarefas podem depender da saída de outras tarefas utilizando o atributo `context`. Por exemplo:

```python Code
research_task = Task(
    description="Pesquise os últimos avanços em IA",
    expected_output="Uma lista de avanços recentes em IA",
    agent=researcher
)

analysis_task = Task(
    description="Analise os achados da pesquisa e identifique as tendências principais",
    expected_output="Relatório de análise das tendências em IA",
    agent=analyst,
    context=[research_task]  # Esta tarefa aguardará a conclusão da research_task
)
```

## Guardrails em Tarefas

Guardrails (trilhas de proteção) de tarefas fornecem uma maneira de validar e transformar as saídas das tarefas antes que elas sejam passadas para a próxima tarefa. Esse recurso assegura a qualidade dos dados e oferece feedback aos agentes quando sua saída não atende a critérios específicos.

### Usando Guardrails em Tarefas

Para adicionar um guardrail a uma tarefa, forneça uma função de validação por meio do parâmetro `guardrail`:

```python Code
from typing import Tuple, Union, Dict, Any
from crewai import TaskOutput

def validate_blog_content(result: TaskOutput) -> Tuple[bool, Any]:
    """Valida se o conteúdo do blog atende aos requisitos."""
    try:
        # Verifica a contagem de palavras
        word_count = len(result.split())
        if word_count > 200:
            return (False, "O conteúdo do blog excede 200 palavras")

        # Lógica adicional de validação aqui
        return (True, result.strip())
    except Exception as e:
        return (False, "Erro inesperado durante a validação")

blog_task = Task(
    description="Escreva um post de blog sobre IA",
    expected_output="Um post de blog com menos de 200 palavras",
    agent=blog_agent,
    guardrail=validate_blog_content  # Adiciona a função guardrail
)
```

### Requisitos da Função Guardrail

1. **Assinatura da Função**:
   * Deve aceitar exatamente um parâmetro (a saída da tarefa)
   * Deve retornar uma tupla `(bool, Any)`
   * Type hints são recomendados, mas opcionais

2. **Valores de Retorno**:
   * Em caso de sucesso: retorna uma tupla `(True, resultado_validado)`
   * Em caso de falha: retorna uma tupla `(False, "mensagem de erro explicando a falha")`

### LLMGuardrail

A classe `LLMGuardrail` oferece um mecanismo robusto para validação das saídas das tarefas.

### Melhores Práticas de Tratamento de Erros

1. **Respostas de Erro Estruturadas**:

```python Code
from crewai import TaskOutput, LLMGuardrail

def validate_with_context(result: TaskOutput) -> Tuple[bool, Any]:
    try:
        # Lógica principal de validação
        validated_data = perform_validation(result)
        return (True, validated_data)
    except ValidationError as e:
        return (False, f"ERRO_DE_VALIDACAO: {str(e)}")
    except Exception as e:
        return (False, str(e))
```

2. **Categorias de Erro**:
   * Use códigos de erro específicos
   * Inclua contexto relevante
   * Forneça feedback acionável

3. **Cadeia de Validação**:

```python Code
from typing import Any, Dict, List, Tuple, Union
from crewai import TaskOutput

def complex_validation(result: TaskOutput) -> Tuple[bool, Any]:
    """Encadeia múltiplas etapas de validação."""
    # Passo 1: Validação básica
    if not result:
        return (False, "Resultado vazio")

    # Passo 2: Validação de conteúdo
    try:
        validated = validate_content(result)
        if not validated:
            return (False, "Conteúdo inválido")

        # Passo 3: Validação de formato
        formatted = format_output(validated)
        return (True, formatted)
    except Exception as e:
        return (False, str(e))
```

### Tratamento dos Resultados do Guardrail

Quando um guardrail retorna `(False, erro)`:

1. O erro é enviado de volta para o agente
2. O agente tenta corrigir o problema
3. O processo se repete até:
   * O guardrail retornar `(True, resultado)`
   * O número máximo de tentativas ser atingido

Exemplo com manipulação de tentativas:

```python Code
from typing import Optional, Tuple, Union
from crewai import TaskOutput, Task

def validate_json_output(result: TaskOutput) -> Tuple[bool, Any]:
    """Valida e faz o parsing da saída como JSON."""
    try:
        # Tenta realizar o parsing como JSON
        data = json.loads(result)
        return (True, data)
    except json.JSONDecodeError as e:
        return (False, "Formato JSON inválido")

task = Task(
    description="Gere um relatório em JSON",
    expected_output="Um objeto JSON válido",
    agent=analyst,
    guardrail=validate_json_output,
    max_retries=3  # Limite de tentativas
)
```

## Obtendo Saídas Estruturadas e Consistentes das Tarefas

<Note>
  É importante também observar que a saída da última tarefa de um crew se torna a saída final do próprio crew.
</Note>

### Usando `output_pydantic`

A propriedade `output_pydantic` permite que você defina um modelo Pydantic que a saída da tarefa deve seguir. Isso garante que a saída seja não apenas estruturada, mas também validada de acordo com o modelo.

Veja um exemplo de uso do output\_pydantic:

```python Code
import json

from crewai import Agent, Crew, Process, Task
from pydantic import BaseModel


class Blog(BaseModel):
    title: str
    content: str


blog_agent = Agent(
    role="Blog Content Generator Agent",
    goal="Gerar um título e conteúdo para blog",
    backstory="""Você é um especialista em criação de conteúdo, habilidoso em escrever posts de blogs engajadores e informativos.""",
    verbose=False,
    allow_delegation=False,
    llm="gpt-4o",
)

task1 = Task(
    description="""Crie um título e conteúdo para blog sobre um tópico. Certifique-se de que o conteúdo tenha menos de 200 palavras.""",
    expected_output="Um título atraente e um conteúdo bem escrito para blog.",
    agent=blog_agent,
    output_pydantic=Blog,
)

# Instanciando o crew com processo sequencial
crew = Crew(
    agents=[blog_agent],
    tasks=[task1],
    verbose=True,
    process=Process.sequential,
)

result = crew.kickoff()

# Opção 1: Acessando propriedades via indexação de dicionário
print("Acessando propriedades - Opção 1")
title = result["title"]
content = result["content"]
print("Título:", title)
print("Conteúdo:", content)

# Opção 2: Acessando diretamente do modelo Pydantic
print("Acessando propriedades - Opção 2")
title = result.pydantic.title
content = result.pydantic.content
print("Título:", title)
print("Conteúdo:", content)

# Opção 3: Usando o método to_dict()
print("Acessando propriedades - Opção 3")
output_dict = result.to_dict()
title = output_dict["title"]
content = output_dict["content"]
print("Título:", title)
print("Conteúdo:", content)

# Opção 4: Imprimindo o objeto Blog inteiro
print("Acessando propriedades - Opção 5")
print("Blog:", result)

```

Neste exemplo:

* Um modelo Pydantic Blog é definido com os campos title e content.
* A tarefa task1 utiliza a propriedade output\_pydantic para especificar que sua saída deve seguir o modelo Blog.
* Após executar o crew, você pode acessar a saída estruturada de várias formas, como mostrado.

#### Explicação sobre o acesso à saída

1. Indexação estilo dicionário: Acesse os campos diretamente usando result\["nome\_do\_campo"]. Isso funciona porque a classe CrewOutput implementa o método **getitem**.
2. Diretamente do modelo Pydantic: Acesse os atributos diretamente do objeto result.pydantic.
3. Usando o método to\_dict(): Converta a saída para um dicionário e acesse os campos.
4. Imprimindo o objeto inteiro: Simplesmente imprima o objeto result para ver a saída estruturada.

### Usando `output_json`

A propriedade `output_json` permite definir o formato de saída esperado em JSON. Isso garante que a saída da tarefa seja uma estrutura JSON válida que pode ser facilmente analisada e utilizada na aplicação.

Veja um exemplo de uso do `output_json`:

```python Code
import json

from crewai import Agent, Crew, Process, Task
from pydantic import BaseModel


# Define o modelo Pydantic para o blog
class Blog(BaseModel):
    title: str
    content: str


# Define o agente
blog_agent = Agent(
    role="Blog Content Generator Agent",
    goal="Gerar um título e conteúdo para blog",
    backstory="""Você é um especialista em criação de conteúdo, habilidoso em escrever posts de blogs engajadores e informativos.""",
    verbose=False,
    allow_delegation=False,
    llm="gpt-4o",
)

# Define a tarefa com output_json configurado para o modelo Blog
task1 = Task(
    description="""Crie um título e conteúdo para blog sobre um tópico. Certifique-se de que o conteúdo tenha menos de 200 palavras.""",
    expected_output="Um objeto JSON com os campos 'title' e 'content'.",
    agent=blog_agent,
    output_json=Blog,
)

# Instancia o crew com processo sequencial
crew = Crew(
    agents=[blog_agent],
    tasks=[task1],
    verbose=True,
    process=Process.sequential,
)

# Executa o crew para realizar a tarefa
result = crew.kickoff()

# Opção 1: Acessando propriedades via indexação de dicionário
print("Acessando propriedades - Opção 1")
title = result["title"]
content = result["content"]
print("Título:", title)
print("Conteúdo:", content)

# Opção 2: Imprimindo o objeto Blog inteiro
print("Acessando propriedades - Opção 2")
print("Blog:", result)
```

Neste exemplo:

* Um modelo Pydantic Blog é definido com os campos title e content, usado para especificar a estrutura do JSON de saída.
* A tarefa task1 utiliza a propriedade output\_json para indicar que espera uma saída JSON que segue o modelo Blog.
* Após executar o crew, você pode acessar a saída estruturada em JSON conforme demonstrado.

#### Explicação sobre o acesso à saída

1. Acessando propriedades via indexação de dicionário: Você pode acessar os campos diretamente usando result\["nome\_do\_campo"]. Isso é possível pois a classe CrewOutput implementa o método **getitem**, permitindo tratar a saída como um dicionário. Nesse caso, estamos acessando title e content do resultado.
2. Imprimindo o objeto Blog inteiro: Ao imprimir result, você obterá a representação em string do objeto CrewOutput. Como o método **str** é implementado para retornar a saída em JSON, isso exibirá toda a saída como uma string formatada representando o objeto Blog.

***

Utilizando `output_pydantic` ou `output_json`, você garante que suas tarefas produzam saídas em um formato estruturado e consistente, facilitando o processamento e uso dos dados na sua aplicação ou entre múltiplas tarefas.

## Integrando Ferramentas com Tarefas

Utilize ferramentas do [CrewAI Toolkit](https://github.com/joaomdmoura/crewai-tools) e [LangChain Tools](https://python.langchain.com/docs/integrations/tools) para ampliar o desempenho das tarefas e aprimorar a interação dos agentes.

## Criando uma Tarefa com Ferramentas

```python Code
import os
os.environ["OPENAI_API_KEY"] = "Sua Chave"
os.environ["SERPER_API_KEY"] = "Sua Chave" # Chave serper.dev

from crewai import Agent, Task, Crew
from crewai_tools import SerperDevTool

research_agent = Agent(
  role='Researcher',
  goal='Encontrar e resumir as últimas notícias de IA',
  backstory="""Você é um pesquisador em uma grande empresa.
  Sua responsabilidade é analisar dados e fornecer insights
  para o negócio.""",
  verbose=True
)

# Para realizar buscas semânticas de um termo a partir de textos da internet
search_tool = SerperDevTool()

task = Task(
  description='Encontre e resuma as últimas notícias de IA',
  expected_output='Uma lista em bullet points com o resumo das 5 notícias mais importantes de IA',
  agent=research_agent,
  tools=[search_tool]
)

crew = Crew(
    agents=[research_agent],
    tasks=[task],
    verbose=True
)

result = crew.kickoff()
print(result)
```

Isso demonstra como tarefas com ferramentas específicas podem sobrescrever o conjunto padrão de um agente para uma execução mais personalizada da tarefa.

## Referenciando Outras Tarefas

No CrewAI, a saída de uma tarefa é automaticamente repassada para a próxima, mas você pode definir explicitamente de quais tarefas a saída deve ser utilizada como contexto por outra, inclusive múltiplas saídas.

É útil especialmente quando você precisa que uma tarefa dependa do resultado de outra que não é executada imediatamente antes dela. Isso é feito pelo atributo `context`:

```python Code
# ...

research_ai_task = Task(
    description="Pesquise os avanços mais recentes em IA",
    expected_output="Uma lista de avanços recentes em IA",
    async_execution=True,
    agent=research_agent,
    tools=[search_tool]
)

research_ops_task = Task(
    description="Pesquise os avanços mais recentes em AI Ops",
    expected_output="Uma lista de avanços recentes em AI Ops",
    async_execution=True,
    agent=research_agent,
    tools=[search_tool]
)

write_blog_task = Task(
    description="Escreva um post de blog completo sobre a importância da IA e suas últimas notícias",
    expected_output="Post de blog completo com 4 parágrafos",
    agent=writer_agent,
    context=[research_ai_task, research_ops_task]
)

#...
```

## Execução Assíncrona

Você pode definir que uma tarefa seja executada de forma assíncrona. Isso significa que o crew não aguardará sua conclusão para seguir para a próxima tarefa. É útil para tarefas demoradas, ou que não são cruciais para as seguintes.

Depois, utilize o atributo `context` para indicar, em uma tarefa futura, que ela deve aguardar os resultados da tarefa assíncrona.

```python Code
#...

list_ideas = Task(
    description="Liste 5 ideias interessantes para explorar em um artigo sobre IA.",
    expected_output="Lista em bullet points com 5 ideias para um artigo.",
    agent=researcher,
    async_execution=True # Será executada de forma assíncrona
)

list_important_history = Task(
    description="Pesquise a história da IA e forneça os 5 eventos mais importantes.",
    expected_output="Lista em bullet points com 5 eventos importantes.",
    agent=researcher,
    async_execution=True # Será executada de forma assíncrona
)

write_article = Task(
    description="Escreva um artigo sobre IA, sua história e ideias interessantes.",
    expected_output="Artigo de 4 parágrafos sobre IA.",
    agent=writer,
    context=[list_ideas, list_important_history] # Vai esperar o resultado das duas tarefas
)

#...
```

## Mecanismo de Callback

A função callback é executada após a conclusão da tarefa, permitindo acionar ações ou notificações baseadas no resultado da tarefa.

```python Code
# ...

def callback_function(output: TaskOutput):
    # Realiza algo após a conclusão da tarefa
    # Exemplo: Envia um e-mail ao gerente
    print(f"""
        Tarefa concluída!
        Tarefa: {output.description}
        Saída: {output.raw}
    """)

research_task = Task(
    description='Encontre e resuma as últimas notícias de IA',
    expected_output='Uma lista em bullet points com o resumo das 5 notícias mais importantes de IA',
    agent=research_agent,
    tools=[search_tool],
    callback=callback_function
)

#...
```

## Acessando a Saída de uma Tarefa Específica

Assim que um crew finaliza sua execução, você pode acessar a saída de uma tarefa específica por meio do atributo `output` do objeto da tarefa:

```python Code
# ...
task1 = Task(
    description='Encontre e resuma as últimas notícias de IA',
    expected_output='Uma lista em bullet points com o resumo das 5 notícias mais importantes de IA',
    agent=research_agent,
    tools=[search_tool]
)

#...

crew = Crew(
    agents=[research_agent],
    tasks=[task1, task2, task3],
    verbose=True
)

result = crew.kickoff()

# Retorna um objeto TaskOutput com a descrição e resultado da tarefa
print(f"""
    Tarefa concluída!
    Tarefa: {task1.output.description}
    Saída: {task1.output.raw}
""")
```

## Mecanismo de Sobrescrição de Ferramentas

Especificar ferramentas em uma tarefa permite a adaptação dinâmica das capacidades do agente, destacando a flexibilidade do CrewAI.

## Mecanismos de Validação e Tratamento de Erros

Ao criar e executar tarefas, determinados mecanismos de validação garantem a robustez e confiabilidade dos atributos das tarefas. Isso inclui, mas não se limita a:

* Garantir que apenas um tipo de saída seja definido por tarefa para manter expectativas de saída claras.
* Impedir a atribuição manual do atributo `id`, preservando a integridade do sistema de identificadores únicos.

Estas validações colaboram para a consistência e confiabilidade das execuções de tarefas no framework CrewAI.

## Guardrails em Tarefas

Guardrails de tarefas oferecem uma maneira poderosa de validar, transformar ou filtrar as saídas das tarefas antes de serem encaminhadas à próxima. São funções opcionais que executam antes do início da próxima tarefa, garantindo que as saídas estejam em conformidade com requisitos ou formatos esperados.

### Uso Básico

#### Defina sua própria lógica de validação

```python Code
from typing import Tuple, Union
from crewai import Task

def validate_json_output(result: str) -> Tuple[bool, Union[dict, str]]:
    """Valida se a saída é um JSON válido."""
    try:
        json_data = json.loads(result)
        return (True, json_data)
    except json.JSONDecodeError:
        return (False, "A saída deve ser um JSON válido")

task = Task(
    description="Gerar dados em JSON",
    expected_output="Objeto JSON válido",
    guardrail=validate_json_output
)
```

#### Use uma abordagem no-code para validação

```python Code
from crewai import Task

task = Task(
    description="Gerar dados em JSON",
    expected_output="Objeto JSON válido",
    guardrail="Garanta que a resposta é um objeto JSON válido"
)
```

#### Usando YAML

```yaml
research_task:
  ...
  guardrail: garanta que cada bullet tenha no mínimo 100 palavras
  ...
```

```python Code
@CrewBase
class InternalCrew:
    agents_config = "config/agents.yaml"
    tasks_config = "config/tasks.yaml"

    ...
    @task
    def research_task(self):
        return Task(config=self.tasks_config["research_task"])  # type: ignore[index]
    ...
```

#### Use modelos customizados para geração de código

```python Code
from crewai import Task
from crewai.llm import LLM

task = Task(
    description="Gerar dados em JSON",
    expected_output="Objeto JSON válido",
    guardrail=LLMGuardrail(
        description="Garanta que a resposta é um objeto JSON válido",
        llm=LLM(model="gpt-4o-mini"),
    )
)
```

### Como Guardrails Funcionam

1. **Atributo Opcional**: Guardrails são opcionais por tarefa, permitindo adicionar validação só onde for necessário.
2. **Momento de Execução**: A função guardrail é executada antes do início da próxima tarefa, garantindo fluxo de dados válido entre tarefas.
3. **Formato de Retorno**: Guardrails devem retornar uma tupla `(sucesso, dados)`:
   * Se `sucesso` é `True`, `dados` é o resultado validado/transformado
   * Se `sucesso` é `False`, `dados` é a mensagem de erro
4. **Roteamento do Resultado**:
   * Sucesso (`True`): o resultado é automaticamente passado para a próxima tarefa
   * Falha (`False`): o erro é enviado de volta ao agente para gerar uma nova resposta

### Casos Comuns de Uso

#### Validação de Formato de Dados

```python Code
def validate_email_format(result: str) -> Tuple[bool, Union[str, str]]:
    """Garante que a saída contenha um e-mail válido."""
    import re
    email_pattern = r'^[\w\.-]+@[\w\.-]+\.\w+$'
    if re.match(email_pattern, result.strip()):
        return (True, result.strip())
    return (False, "A saída deve ser um e-mail válido")
```

#### Filtragem de Conteúdo

```python Code
def filter_sensitive_info(result: str) -> Tuple[bool, Union[str, str]]:
    """Remove ou valida informações sensíveis."""
    sensitive_patterns = ['SSN:', 'password:', 'secret:']
    for pattern in sensitive_patterns:
        if pattern.lower() in result.lower():
            return (False, f"A saída contém informação sensível ({pattern})")
    return (True, result)
```

#### Transformação de Dados

```python Code
def normalize_phone_number(result: str) -> Tuple[bool, Union[str, str]]:
    """Garante que números de telefone estejam em formato consistente."""
    import re
    digits = re.sub(r'\D', '', result)
    if len(digits) == 10:
        formatted = f"({digits[:3]}) {digits[3:6]}-{digits[6:]}"
        return (True, formatted)
    return (False, "A saída deve ser um telefone com 10 dígitos")
```

### Recursos Avançados

#### Encadeando Múltiplas Validações

```python Code
def chain_validations(*validators):
    """Encadeia múltiplos validadores."""
    def combined_validator(result):
        for validator in validators:
            success, data = validator(result)
            if not success:
                return (False, data)
            result = data
        return (True, result)
    return combined_validator

# Uso
task = Task(
    description="Obtenha informações de contato do usuário",
    expected_output="E-mail e telefone",
    guardrail=chain_validations(
        validate_email_format,
        filter_sensitive_info
    )
)
```

#### Lógica Customizada de Retentativas

```python Code
task = Task(
    description="Gerar dados",
    expected_output="Dados válidos",
    guardrail=validate_data,
    max_retries=5  # Sobrescreve o limite padrão de tentativas
)
```

## Criando Diretórios ao Salvar Arquivos

Agora é possível especificar se uma tarefa deve criar diretórios ao salvar sua saída em arquivo. Isso é útil para organizar outputs e garantir que os caminhos estejam corretos.

```python Code
# ...

save_output_task = Task(
    description='Salve o resumo das notícias de IA em um arquivo',
    expected_output='Arquivo salvo com sucesso',
    agent=research_agent,
    tools=[file_save_tool],
    output_file='outputs/ai_news_summary.txt',
    create_directory=True
)

#...
```

Veja o vídeo abaixo para aprender como utilizar saídas estruturadas no CrewAI:

<iframe width="560" height="315" src="https://www.youtube.com/embed/dNpKQk5uxHw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen />

## Conclusão

Tarefas são a força motriz por trás das ações dos agentes no CrewAI.
Ao definir corretamente as tarefas e seus resultados, você prepara seus agentes de IA para trabalhar de forma eficaz, seja de forma independente ou colaborativa.
Equipar tarefas com as ferramentas adequadas, compreender o processo de execução e seguir práticas sólidas de validação são fundamentais para maximizar o potencial do CrewAI,
assegurando que os agentes estejam devidamente preparados para suas atribuições e que as tarefas sejam executadas conforme o esperado.


# Testes
Source: https://docs.crewai.com/pt-BR/concepts/testing

Saiba como testar sua CrewAI Crew e avaliar seu desempenho.

## Visão Geral

Testar é uma parte crucial do processo de desenvolvimento, sendo essencial para garantir que sua crew está performando conforme o esperado. Com o crewAI, você pode facilmente testar sua crew e avaliar seu desempenho utilizando as funcionalidades de teste integradas.

### Utilizando o Recurso de Teste

Adicionamos o comando de CLI `crewai test` para facilitar o teste da sua crew. Esse comando executará sua crew por um número especificado de iterações e fornecerá métricas de desempenho detalhadas. Os parâmetros são `n_iterations` e `model`, ambos opcionais e com valores padrão de 2 e `gpt-4o-mini`, respectivamente. Por enquanto, o único provedor disponível é a OpenAI.

```bash
crewai test
```

Se quiser rodar mais iterações ou utilizar um modelo diferente, você pode especificar os parâmetros assim:

```bash
crewai test --n_iterations 5 --model gpt-4o
```

ou usando as formas abreviadas:

```bash
crewai test -n 5 -m gpt-4o
```

Ao executar o comando `crewai test`, a crew será executada pelo número especificado de iterações, e as métricas de desempenho serão exibidas ao final da execução.

Uma tabela de pontuações ao final mostrará o desempenho da crew em relação às seguintes métricas:

<center>**Pontuações das Tarefas (1-10, quanto maior melhor)**</center>

| Tarefas/Crew/Agentes  | Exec. 1 | Exec. 2 | Méd. Total |            Agentes           | Informações Adicionais         |
| :-------------------- | :-----: | :-----: | :--------: | :--------------------------: | :----------------------------- |
| Tarefa 1              |   9,0   |   9,5   |   **9,2**  |     Professional Insights    |                                |
|                       |         |         |            |          Researcher          |                                |
| Tarefa 2              |   9,0   |   10,0  |   **9,5**  | Company Profile Investigator |                                |
| Tarefa 3              |   9,0   |   9,0   |   **9,0**  |      Automation Insights     |                                |
|                       |         |         |            |          Specialist          |                                |
| Tarefa 4              |   9,0   |   9,0   |   **9,0**  |     Final Report Compiler    | Automation Insights Specialist |
| Crew                  |   9,00  |   9,38  |   **9,2**  |                              |                                |
| Tempo de Execução (s) |   126   |   145   |   **135**  |                              |                                |

O exemplo acima mostra os resultados dos testes para duas execuções da crew com duas tarefas, apresentando a pontuação média total de cada tarefa e da crew como um todo.


# Ferramentas
Source: https://docs.crewai.com/pt-BR/concepts/tools

Compreendendo e aproveitando ferramentas dentro do framework CrewAI para colaboração e execução de tarefas por agentes.

## Visão geral

As ferramentas do CrewAI capacitam agentes com habilidades que vão desde busca na web e análise de dados até colaboração e delegação de tarefas entre colegas de trabalho.
Esta documentação descreve como criar, integrar e aproveitar essas ferramentas dentro do framework CrewAI, incluindo um novo foco em ferramentas de colaboração.

## O que é uma Ferramenta?

Uma ferramenta no CrewAI é uma habilidade ou função que os agentes podem utilizar para executar diversas ações.
Isso inclui ferramentas do [CrewAI Toolkit](https://github.com/joaomdmoura/crewai-tools) e [LangChain Tools](https://python.langchain.com/docs/integrations/tools),
permitindo desde buscas simples até interações complexas e trabalho em equipe eficiente entre agentes.

<Note type="info" title="Aprimoramento para Empresas: Repositório de Ferramentas">
  O CrewAI Enterprise oferece um Repositório de Ferramentas abrangente, com integrações pré-construídas para sistemas empresariais e APIs comuns. Implemente agentes com ferramentas corporativas em minutos em vez de dias.

  O Repositório de Ferramentas Empresariais inclui:

  * Conectores pré-construídos para sistemas empresariais populares
  * Interface para criação de ferramentas personalizadas
  * Controle de versão e funcionalidades de compartilhamento
  * Recursos de segurança e conformidade
</Note>

## Características Principais das Ferramentas

* **Utilidade**: Desenvolvidas para tarefas como busca web, análise de dados, geração de conteúdo e colaboração entre agentes.
* **Integração**: Potencializa as habilidades dos agentes ao integrar ferramentas de forma transparente ao seu fluxo de trabalho.
* **Personalização**: Oferece flexibilidade para desenvolver ferramentas personalizadas ou utilizar existentes, atendendo necessidades específicas dos agentes.
* **Tratamento de Erros**: Incorpora mecanismos robustos de tratamento de erros para garantir operação sem interrupções.
* **Mecanismo de Cache**: Possui cache inteligente para otimizar desempenho e reduzir operações redundantes.
* **Suporte Assíncrono**: Suporta ferramentas síncronas e assíncronas, permitindo operações não bloqueantes.

## Utilizando Ferramentas CrewAI

Para aprimorar as capacidades de seus agentes com as ferramentas do CrewAI, comece instalando nosso pacote extra de ferramentas:

```bash
pip install 'crewai[tools]'
```

Aqui está um exemplo demonstrando seu uso:

```python Code
import os
from crewai import Agent, Task, Crew
# Importando ferramentas do crewAI
from crewai_tools import (
    DirectoryReadTool,
    FileReadTool,
    SerperDevTool,
    WebsiteSearchTool
)

# Configure as chaves de API
os.environ["SERPER_API_KEY"] = "Your Key" # chave da API serper.dev
os.environ["OPENAI_API_KEY"] = "Your Key"

# Instanciar as ferramentas
docs_tool = DirectoryReadTool(directory='./blog-posts')
file_tool = FileReadTool()
search_tool = SerperDevTool()
web_rag_tool = WebsiteSearchTool()

# Criar agentes
researcher = Agent(
    role='Analista de Mercado',
    goal='Fornecer análise de mercado atualizada da indústria de IA',
    backstory='Analista especialista com olhar atento para tendências de mercado.',
    tools=[search_tool, web_rag_tool],
    verbose=True
)

writer = Agent(
    role='Redator de Conteúdo',
    goal='Criar posts de blog envolventes sobre a indústria de IA',
    backstory='Redator habilidoso com paixão por tecnologia.',
    tools=[docs_tool, file_tool],
    verbose=True
)

# Definir tarefas
research = Task(
    description='Research the latest trends in the AI industry and provide a summary.',
    expected_output='A summary of the top 3 trending developments in the AI industry with a unique perspective on their significance.',
    agent=researcher
)

write = Task(
    description='Write an engaging blog post about the AI industry, based on the research analyst's summary. Draw inspiration from the latest blog posts in the directory.',
    expected_output='A 4-paragraph blog post formatted in markdown with engaging, informative, and accessible content, avoiding complex jargon.',
    agent=writer,
    output_file='blog-posts/new_post.md'  # O post final do blog será salvo aqui
)

# Montar um crew com o planejamento habilitado
crew = Crew(
    agents=[researcher, writer],
    tasks=[research, write],
    verbose=True,
    planning=True,  # Habilitar o recurso de planejamento
)

# Executar tarefas
crew.kickoff()
```

## Ferramentas CrewAI Disponíveis

* **Tratamento de Erros**: Todas as ferramentas são construídas com capacidades de tratamento de erros, permitindo que os agentes administrem exceções de forma adequada e prossigam com suas tarefas.
* **Mecanismo de Cache**: Todas as ferramentas suportam cache, possibilitando que agentes reutilizem de forma eficiente resultados obtidos anteriormente, reduzindo a carga em recursos externos e acelerando o tempo de execução. Também é possível definir controles mais precisos sobre o mecanismo de cache usando o atributo `cache_function` na ferramenta.

Aqui está uma lista das ferramentas disponíveis e suas descrições:

| Ferramenta                       | Descrição                                                                                            |
| :------------------------------- | :--------------------------------------------------------------------------------------------------- |
| **ApifyActorsTool**              | Ferramenta que integra Apify Actors aos seus fluxos de trabalho para web scraping e automação.       |
| **BrowserbaseLoadTool**          | Ferramenta para interação e extração de dados de navegadores web.                                    |
| **CodeDocsSearchTool**           | Uma ferramenta RAG otimizada para busca em documentações de código e documentos técnicos.            |
| **CodeInterpreterTool**          | Ferramenta para interpretar código Python.                                                           |
| **ComposioTool**                 | Permite o uso de ferramentas Composio.                                                               |
| **CSVSearchTool**                | Ferramenta RAG projetada para busca em arquivos CSV, ideal para dados estruturados.                  |
| **DALL-E Tool**                  | Ferramenta para gerar imagens utilizando a API do DALL-E.                                            |
| **DirectorySearchTool**          | Ferramenta RAG para busca em diretórios, útil para navegação em sistemas de arquivos.                |
| **DOCXSearchTool**               | Ferramenta RAG voltada para busca em documentos DOCX, ideal para processar arquivos Word.            |
| **DirectoryReadTool**            | Facilita a leitura e processamento de estruturas de diretórios e seus conteúdos.                     |
| **EXASearchTool**                | Ferramenta projetada para buscas exaustivas em diversas fontes de dados.                             |
| **FileReadTool**                 | Permite a leitura e extração de dados de arquivos, suportando diversos formatos.                     |
| **FirecrawlSearchTool**          | Ferramenta para buscar páginas web usando Firecrawl e retornar os resultados.                        |
| **FirecrawlCrawlWebsiteTool**    | Ferramenta para rastrear páginas web utilizando o Firecrawl.                                         |
| **FirecrawlScrapeWebsiteTool**   | Ferramenta para extrair o conteúdo de URLs usando Firecrawl.                                         |
| **GithubSearchTool**             | Ferramenta RAG para buscar em repositórios GitHub, útil para pesquisa de código e documentação.      |
| **SerperDevTool**                | Ferramenta especializada para finalidades de desenvolvimento, com funcionalidades em evolução.       |
| **TXTSearchTool**                | Ferramenta RAG voltada para busca em arquivos de texto (.txt), adaptada para dados não estruturados. |
| **JSONSearchTool**               | Ferramenta RAG para busca em arquivos JSON, voltada ao manuseio de dados estruturados.               |
| **LlamaIndexTool**               | Permite o uso das ferramentas LlamaIndex.                                                            |
| **MDXSearchTool**                | Ferramenta RAG para busca em arquivos Markdown (MDX), útil para documentação.                        |
| **PDFSearchTool**                | Ferramenta RAG para busca em documentos PDF, ideal para processar documentos digitalizados.          |
| **PGSearchTool**                 | Ferramenta RAG otimizada para busca em bancos de dados PostgreSQL, adequada para consultas.          |
| **Vision Tool**                  | Ferramenta para gerar imagens utilizando a API do DALL-E.                                            |
| **RagTool**                      | Ferramenta RAG de uso geral, capaz de lidar com diferentes fontes e tipos de dados.                  |
| **ScrapeElementFromWebsiteTool** | Permite extrair elementos específicos de sites, útil para extração de dados direcionada.             |
| **ScrapeWebsiteTool**            | Facilita o scraping de sites inteiros, ideal para coleta abrangente de dados.                        |
| **WebsiteSearchTool**            | Ferramenta RAG para busca em conteúdos de sites, otimizada para extração de dados web.               |
| **XMLSearchTool**                | Ferramenta RAG para busca em arquivos XML, adequada para formatos de dados estruturados.             |
| **YoutubeChannelSearchTool**     | Ferramenta RAG para busca em canais do YouTube, útil para análise de conteúdo em vídeo.              |
| **YoutubeVideoSearchTool**       | Ferramenta RAG para busca em vídeos do YouTube, ideal para extração de dados de vídeo.               |

## Criando suas próprias Ferramentas

<Tip>
  Desenvolvedores podem criar `ferramentas personalizadas` adaptadas para as necessidades de seus agentes ou utilizar opções pré-construídas.
</Tip>

Existem duas formas principais de criar uma ferramenta CrewAI:

### Herança de `BaseTool`

```python Code
from crewai.tools import BaseTool
from pydantic import BaseModel, Field

class MyToolInput(BaseModel):
    """Input schema for MyCustomTool."""
    argument: str = Field(..., description="Description of the argument.")

class MyCustomTool(BaseTool):
    name: str = "Name of my tool"
    description: str = "What this tool does. It's vital for effective utilization."
    args_schema: Type[BaseModel] = MyToolInput

    def _run(self, argument: str) -> str:
        # Seu código da ferramenta aqui
        return "Tool's result"
```

## Suporte a Ferramentas Assíncronas

O CrewAI suporta ferramentas assíncronas, permitindo que você implemente ferramentas que realizam operações não bloqueantes, como requisições de rede, I/O de arquivos ou outras operações async sem bloquear o fluxo principal de execução.

### Criando Ferramentas Assíncronas

Você pode criar ferramentas assíncronas de duas formas:

#### 1. Utilizando o Decorador `tool` com Funções Assíncronas

```python Code
from crewai.tools import tool

@tool("fetch_data_async")
async def fetch_data_async(query: str) -> str:
    """Asynchronously fetch data based on the query."""
    # Simulate async operation
    await asyncio.sleep(1)
    return f"Data retrieved for {query}"
```

#### 2. Implementando Métodos Assíncronos em Classes de Ferramentas Personalizadas

```python Code
from crewai.tools import BaseTool

class AsyncCustomTool(BaseTool):
    name: str = "async_custom_tool"
    description: str = "An asynchronous custom tool"

    async def _run(self, query: str = "") -> str:
        """Asynchronously run the tool"""
        # Sua implementação assíncrona aqui
        await asyncio.sleep(1)
        return f"Processed {query} asynchronously"
```

### Utilizando Ferramentas Assíncronas

Ferramentas assíncronas funcionam perfeitamente tanto em fluxos tradicionais do Crew quanto em fluxos baseados em Flow:

```python Code
# No Crew tradicional
agent = Agent(role="researcher", tools=[async_custom_tool])

# Em Flow
class MyFlow(Flow):
    @start()
    async def begin(self):
        crew = Crew(agents=[agent])
        result = await crew.kickoff_async()
        return result
```

O framework CrewAI lida automaticamente com a execução de ferramentas síncronas e assíncronas, então você não precisa se preocupar com diferenças na chamada.

### Utilizando o Decorador `tool`

```python Code
from crewai.tools import tool
@tool("Name of my tool")
def my_tool(question: str) -> str:
    """Clear description for what this tool is useful for, your agent will need this information to use it."""
    # Lógica da função aqui
    return "Result from your custom tool"
```

### Mecanismo de Cache Personalizado

<Tip>
  As ferramentas podem implementar opcionalmente uma `cache_function` para ajuste fino do comportamento de cache.
  Esta função determina quando armazenar resultados em cache com base em condições específicas, oferecendo controle granular sobre a lógica de cache.
</Tip>

```python Code
from crewai.tools import tool

@tool
def multiplication_tool(first_number: int, second_number: int) -> str:
    """Useful for when you need to multiply two numbers together."""
    return first_number * second_number

def cache_func(args, result):
    # Neste exemplo, só cacheamos o resultado se for múltiplo de 2
    cache = result % 2 == 0
    return cache

multiplication_tool.cache_function = cache_func

writer1 = Agent(
        role="Writer",
        goal="You write lessons of math for kids.",
        backstory="You're an expert in writing and you love to teach kids but you know nothing of math.",
        tools=[multiplication_tool],
        allow_delegation=False,
    )
    #...
```

## Conclusão

Ferramentas são fundamentais para expandir as capacidades dos agentes CrewAI, permitindo que assumam uma ampla gama de tarefas e colaborem de forma eficiente.
Ao construir soluções com CrewAI, aproveite tanto ferramentas existentes quanto personalizadas para potencializar seus agentes e ampliar o ecossistema de IA. Considere utilizar tratamento de erros,
mecanismos de cache e a flexibilidade de argumentos das ferramentas para otimizar o desempenho e as capacidades dos seus agentes.


# Treinamento
Source: https://docs.crewai.com/pt-BR/concepts/training

Aprenda como treinar seus agentes CrewAI fornecendo feedback desde o início e obtenha resultados consistentes.

## Visão Geral

O recurso de treinamento no CrewAI permite que você treine seus agentes de IA usando a interface de linha de comando (CLI).
Ao executar o comando `crewai train -n <n_iterations>`, você pode especificar o número de iterações para o processo de treinamento.

Durante o treinamento, o CrewAI utiliza técnicas para otimizar o desempenho dos seus agentes juntamente com o feedback humano.
Isso ajuda os agentes a aprimorar sua compreensão, tomada de decisão e habilidades de resolução de problemas.

### Treinando sua Crew Usando a CLI

Para utilizar o recurso de treinamento, siga estes passos:

1. Abra seu terminal ou prompt de comando.
2. Navegue até o diretório onde seu projeto CrewAI está localizado.
3. Execute o seguinte comando:

```shell
crewai train -n <n_iterations> <filename> (optional)
```

<Tip>
  Substitua `<n_iterations>` pelo número desejado de iterações de treinamento e `<filename>` pelo nome de arquivo apropriado terminando com `.pkl`.
</Tip>

### Treinando sua Crew Programaticamente

Para treinar sua crew de forma programática, siga estes passos:

1. Defina o número de iterações para o treinamento.
2. Especifique os parâmetros de entrada para o processo de treinamento.
3. Execute o comando de treinamento dentro de um bloco try-except para tratar possíveis erros.

```python Code
n_iteracoes = 2
entradas = {"topic": "Treinamento CrewAI"}
nome_arquivo = "seu_modelo.pkl"

try:
    SuaCrew().crew().train(
      n_iterations=n_iteracoes,
      inputs=entradas,
      filename=nome_arquivo
    )
except Exception as e:
    raise Exception(f"Ocorreu um erro ao treinar a crew: {e}")
```

### Pontos Importantes

* **Requisito de Número Inteiro Positivo:** Certifique-se de que o número de iterações (`n_iterations`) seja um inteiro positivo. O código lançará um `ValueError` se essa condição não for atendida.
* **Requisito de Nome de Arquivo:** Certifique-se de que o nome do arquivo termine com `.pkl`. O código lançará um `ValueError` se essa condição não for atendida.
* **Tratamento de Erros:** O código trata erros de subprocessos e exceções inesperadas, fornecendo mensagens de erro ao usuário.

É importante observar que o processo de treinamento pode levar algum tempo, dependendo da complexidade dos seus agentes e também exigirá seu feedback em cada iteração.

Uma vez concluído o treinamento, seus agentes estarão equipados com capacidades e conhecimentos aprimorados, prontos para enfrentar tarefas complexas e fornecer insights mais consistentes e valiosos.

Lembre-se de atualizar e treinar seus agentes regularmente para garantir que permaneçam atualizados com as últimas informações e avanços na área.

Bom treinamento com o CrewAI! 🚀


# Proteção contra Alucinações
Source: https://docs.crewai.com/pt-BR/enterprise/features/hallucination-guardrail

Previna e detecte alucinações de IA nas suas tarefas do CrewAI

## Visão Geral

A Proteção contra Alucinações é um recurso empresarial que valida o conteúdo gerado por IA para garantir que esteja fundamentado em fatos e não contenha alucinações. Ela analisa as saídas das tarefas em relação ao contexto de referência e fornece feedback detalhado quando é detectado conteúdo potencialmente alucinado.

## O que são Alucinações?

Alucinações em IA ocorrem quando modelos de linguagem geram conteúdos que parecem plausíveis, mas estão factualmente incorretos ou não são suportados pelo contexto fornecido. A Proteção contra Alucinações ajuda a prevenir esses problemas por meio de:

* Comparação das saídas com o contexto de referência
* Avaliação da fidelidade ao material de origem
* Fornecimento de feedback detalhado sobre conteúdo problemático
* Suporte a limiares personalizados para rigor da validação

## Uso Básico

### Configurando a Proteção

```python
from crewai.tasks.hallucination_guardrail import HallucinationGuardrail
from crewai import LLM

# Uso básico - utiliza o expected_output da tarefa como contexto
protecao = HallucinationGuardrail(
    llm=LLM(model="gpt-4o-mini")
)

# Com contexto de referência explícito
protecao_com_contexto = HallucinationGuardrail(
    context="IA ajuda em várias tarefas, incluindo análise e geração.",
    llm=LLM(model="gpt-4o-mini")
)
```

### Adicionando às Tarefas

```python
from crewai import Task

# Crie sua tarefa com a proteção
minha_tarefa = Task(
    description="Escreva um resumo sobre as capacidades da IA",
    expected_output="Um resumo factual baseado no contexto fornecido",
    agent=meu_agente,
    guardrail=protecao  # Adiciona a proteção para validar a saída
)
```

## Configuração Avançada

### Validação com Limiar Personalizado

Para validação mais rigorosa, é possível definir um limiar de fidelidade personalizado (escala de 0-10):

```python
# Proteção rigorosa exigindo alta pontuação de fidelidade
protecao_rigorosa = HallucinationGuardrail(
    context="Computação quântica utiliza qubits que existem em estados de superposição.",
    llm=LLM(model="gpt-4o-mini"),
    threshold=8.0  # Requer pontuação >= 8 para validar
)
```

### Incluindo Contexto da Resposta de Ferramentas

Se sua tarefa utiliza ferramentas, você pode incluir as respostas das ferramentas para validação mais precisa:

```python
# Proteção com contexto de resposta da ferramenta
protecao_clima = HallucinationGuardrail(
    context="Informações meteorológicas atuais para o local solicitado",
    llm=LLM(model="gpt-4o-mini"),
    tool_response="API do Clima retornou: Temperatura 22°C, Umidade 65%, Céu limpo"
)
```

## Como Funciona

### Processo de Validação

1. **Análise de Contexto**: A proteção compara a saída da tarefa com o contexto de referência fornecido
2. **Pontuação de Fidelidade**: Usa um avaliador interno para atribuir uma pontuação de fidelidade (0-10)
3. **Determinação do Veredito**: Determina se o conteúdo é fiel ou contém alucinações
4. **Verificação de Limiar**: Se um limiar personalizado for definido, valida contra essa pontuação
5. **Geração de Feedback**: Fornece motivos detalhados caso a validação falhe

### Lógica de Validação

* **Modo Padrão**: Utiliza validação baseada em veredito (FIÉL vs ALUCINADO)
* **Modo com Limiar**: Requer que a pontuação de fidelidade atinja ou supere o limiar especificado
* **Tratamento de Erros**: Lida com erros de avaliação de forma elegante e fornece feedback informativo

## Resultados da Proteção

A proteção retorna resultados estruturados indicando o status da validação:

```python
# Exemplo de estrutura de resultado da proteção
{
    "valid": False,
    "feedback": "Content appears to be hallucinated (score: 4.2/10, verdict: HALLUCINATED). The output contains information not supported by the provided context."
}
```

### Propriedades do Resultado

* **valid**: Booleano indicando se a saída passou na validação
* **feedback**: Explicação detalhada quando a validação falha, incluindo:
  * Pontuação de fidelidade
  * Classificação do veredito
  * Motivos específicos para a falha

## Integração com o Sistema de Tarefas

### Validação Automática

Quando uma proteção é adicionada à tarefa, ela valida automaticamente a saída antes da tarefa ser marcada como concluída:

```python
# Fluxo de validação de saída da tarefa
task_output = meu_agente.execute_task(minha_tarefa)
resultado_validacao = protecao(task_output)

if resultado_validacao.valid:
    # Tarefa concluída com sucesso
    return task_output
else:
    # Tarefa falha com feedback de validação
    raise ValidationError(resultado_validacao.feedback)
```

### Rastreamento de Eventos

A proteção se integra ao sistema de eventos do CrewAI para fornecer observabilidade:

* **Validação Iniciada**: Quando a avaliação da proteção começa
* **Validação Concluída**: Quando a avaliação termina com resultados
* **Falha na Validação**: Quando ocorrem erros técnicos durante a avaliação

## Melhores Práticas

### Diretrizes para o Contexto

<Steps>
  <Step title="Forneça Contexto Abrangente">
    Inclua todas as informações factuais relevantes nas quais a IA deve basear sua saída:

    ```python
    contexto = """
    Empresa XYZ foi fundada em 2020 e é especializada em soluções de energia renovável.
    Possui 150 funcionários e faturou R$ 50 milhões em 2023.
    Seus principais produtos incluem painéis solares e turbinas eólicas.
    """
    ```
  </Step>

  <Step title="Mantenha o Contexto Relevante">
    Inclua apenas informações diretamente relacionadas à tarefa para evitar confusão:

    ```python
    # Bom: Contexto focado
    contexto = "O clima atual em Nova York é 18°C com chuva leve."

    # Evite: Informações irrelevantes
    contexto = "The weather is 18°C. The city has 8 million people. Traffic is heavy."
    ```
  </Step>

  <Step title="Atualize o Contexto Regularmente">
    Certifique-se de que seu contexto de referência reflita informações atuais e precisas.
  </Step>
</Steps>

### Seleção de Limiar

<Steps>
  <Step title="Comece com a Validação Padrão">
    Inicie sem limiares personalizados para entender a performance inicial.
  </Step>

  <Step title="Ajuste Conforme as Necessidades">
    * **Conteúdo crítico**: Use limiar 8-10 para máxima precisão
    * **Conteúdo geral**: Use limiar 6-7 para validação equilibrada
    * **Conteúdo criativo**: Use limiar 4-5 ou validação padrão baseada em veredito
  </Step>

  <Step title="Monitore e Itere">
    Acompanhe os resultados da validação e ajuste os limiares conforme falsos positivos/negativos.
  </Step>
</Steps>

## Considerações de Performance

### Impacto no Tempo de Execução

* **Sobrecarga de Validação**: Cada proteção adiciona \~1-3 segundos por tarefa
* **Eficiência do LLM**: Escolha modelos eficientes para avaliação (ex: gpt-4o-mini)

### Otimização de Custos

* **Seleção de Modelo**: Utilize modelos menores e eficientes para avaliação da proteção
* **Tamanho do Contexto**: Mantenha o contexto de referência conciso, mas abrangente
* **Cache**: Considere armazenar resultados de validação para conteúdos repetidos

## Solução de Problemas

<Accordion title="Validação Sempre Falha">
  **Possíveis Causas:**

  * Contexto muito restrito ou não relacionado à saída da tarefa
  * Limiar configurado alto demais para o tipo de conteúdo
  * Contexto de referência desatualizado

  **Soluções:**

  * Revise e atualize o contexto para corresponder aos requisitos da tarefa
  * Reduza o limiar ou utilize validação padrão baseada em veredito
  * Certifique-se de que o contexto esteja atual e correto
</Accordion>

<Accordion title="Falsos Positivos (Conteúdo Válido Marcado como Inválido)">
  **Possíveis Causas:**

  * Limiar alto demais para tarefas criativas ou interpretativas
  * Contexto não cobre todos os aspectos válidos da saída
  * Modelo de avaliação excessivamente conservador

  **Soluções:**

  * Reduza o limiar ou utilize validação padrão
  * Expanda o contexto para incluir um espectro maior do conteúdo aceitável
  * Teste com diferentes modelos de avaliação
</Accordion>

<Accordion title="Erros de Avaliação">
  **Possíveis Causas:**

  * Problemas de conexão de rede
  * Modelo LLM indisponível ou com limite de uso
  * Saída ou contexto da tarefa em formato inadequado

  **Soluções:**

  * Verifique a conectividade de rede e o status do serviço LLM
  * Implemente lógica de retentativas para falhas transitórias
  * Valide o formato da saída da tarefa antes da avaliação da proteção
</Accordion>

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nosso suporte para assistência na configuração ou solução de problemas da proteção contra alucinações.
</Card>


# Integrações
Source: https://docs.crewai.com/pt-BR/enterprise/features/integrations

Aplicativos conectados para que seus agentes possam tomar ações.

## Visão Geral

Permita que seus agentes autentiquem com qualquer provedor habilitado para OAuth e tomem ações. Do Salesforce e HubSpot ao Google e GitHub, você conta com mais de 16 serviços integrados.

<Frame>
  ![Integrações](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew_connectors.png)
</Frame>

## Integrações Suportadas

### **Comunicação & Colaboração**

* **Gmail** - Gerencie e-mails e rascunhos
* **Slack** - Notificações e alertas do workspace
* **Microsoft** - Integração com Office 365 e Teams

### **Gerenciamento de Projetos**

* **Jira** - Rastreamento de issues e gerenciamento de projetos
* **ClickUp** - Gerenciamento de tarefas e produtividade
* **Asana** - Coordenação de tarefas e projetos de equipe
* **Notion** - Gerenciamento de páginas e bases de dados
* **Linear** - Gerenciamento de projetos de software e bugs
* **GitHub** - Gerenciamento de repositórios e issues

### **Gestão de Relacionamento com o Cliente**

* **Salesforce** - Gerenciamento de contas e oportunidades de CRM
* **HubSpot** - Gestão de pipeline de vendas e contatos
* **Zendesk** - Administração de chamados de suporte ao cliente

### **Negócios & Finanças**

* **Stripe** - Processamento de pagamentos e gerenciamento de clientes
* **Shopify** - Gestão de loja de e-commerce e produtos

### **Produtividade & Armazenamento**

* **Google Sheets** - Sincronização de dados de planilhas
* **Google Calendar** - Gerenciamento de eventos e agendas
* **Box** - Armazenamento de arquivos e gerenciamento de documentos

e mais estão por vir!

## Pré-requisitos

Antes de usar as Integrações de Autenticação, certifique-se de que você possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com). Você pode começar com uma avaliação gratuita.

## Configurando Integrações

### 1. Conecte sua Conta

1. Acesse o [CrewAI Enterprise](https://app.crewai.com)
2. Vá até a aba **Integrações** - [https://app.crewai.com/crewai\_plus/connectors](https://app.crewai.com/crewai_plus/connectors)
3. Clique em **Conectar** no serviço desejado na seção Integrações de Autenticação
4. Complete o fluxo de autenticação OAuth
5. Conceda as permissões necessárias para seu caso de uso
6. Obtenha seu Token Enterprise na sua página de conta do [CrewAI Enterprise](https://app.crewai.com) - [https://app.crewai.com/crewai\_plus/settings/account](https://app.crewai.com/crewai_plus/settings/account)

<Frame>
  ![Integrações](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/enterprise_action_auth_token.png)
</Frame>

### 2. Instale as Ferramentas de Integração

Tudo o que você precisa é da versão mais recente do pacote `crewai-tools`.

```bash
uv add crewai-tools
```

## Exemplos de Uso

### Uso Básico

<Tip>
  Todos os serviços nos quais você estiver autenticado estarão disponíveis como ferramentas. Portanto, tudo que você precisa fazer é adicionar o `CrewaiEnterpriseTools` ao seu agente e pronto.
</Tip>

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Obtenha ferramentas enterprise (a ferramenta Gmail será incluída)
ferramentas_enterprise = CrewaiEnterpriseTools(
    enterprise_token="seu_token_enterprise"
)
# imprima as ferramentas
printf(ferramentas_enterprise)

# Crie um agente com capacidades do Gmail
agente_email = Agent(
    role="Gerente de E-mails",
    goal="Gerenciar e organizar comunicações por e-mail",
    backstory="Um assistente de IA especializado em gestão de e-mails e comunicação.",
    tools=ferramentas_enterprise
)

# Tarefa para enviar um e-mail
tarefa_email = Task(
    description="Redigir e enviar um e-mail de acompanhamento para john@example.com sobre a atualização do projeto",
    agent=agente_email,
    expected_output="Confirmação de que o e-mail foi enviado com sucesso"
)

# Execute a tarefa
crew = Crew(
    agents=[agente_email],
    tasks=[tarefa_email]
)

# Execute o crew
crew.kickoff()
```

### Filtrando Ferramentas

```python
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    actions_list=["gmail_find_email"] # apenas a ferramenta gmail_find_email estará disponível
)
gmail_tool = enterprise_tools["gmail_find_email"]

agente_gmail = Agent(
    role="Gerente do Gmail",
    goal="Gerenciar comunicações e notificações do gmail",
    backstory="Um assistente de IA que ajuda a coordenar comunicações no gmail.",
    tools=[gmail_tool]
)

tarefa_notificacao = Task(
    description="Encontrar o e-mail de john@example.com",
    agent=agente_gmail,
    expected_output="E-mail encontrado de john@example.com"
)

# Execute a tarefa
crew = Crew(
    agents=[agente_gmail],
    tasks=[tarefa_notificacao]
)
```

## Melhores Práticas

### Segurança

* **Princípio do Menor Privilégio**: Conceda apenas as permissões mínimas exigidas para as tarefas dos seus agentes
* **Auditorias Regulares**: Revise periodicamente as integrações conectadas e suas permissões
* **Credenciais Seguras**: Nunca insira credenciais diretamente no código; utilize o fluxo seguro de autenticação do CrewAI

### Filtrando Ferramentas

Em um crew implantado, você pode especificar quais ações estão disponíveis para cada integração a partir da página de configurações do serviço ao qual você se conectou.

<Frame>
  ![Integrações](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/filtering_enterprise_action_tools.png)
</Frame>

### Implantações com Escopo para organizações multiusuário

Você pode implantar seu crew e associar cada integração a um usuário específico. Por exemplo, um crew que se conecta ao Google pode usar a conta do Gmail de um usuário específico.

<Tip>
  Isso é útil para organizações multiusuário, onde você deseja direcionar a integração para um usuário específico.
</Tip>

Use o `user_bearer_token` para direcionar a integração a um usuário específico; assim, quando o crew for iniciado, ele usará o bearer token desse usuário para autenticar com a integração. Se o usuário não estiver logado, o crew não utilizará nenhuma integração conectada. Use o bearer token padrão para autenticar com as integrações que estão sendo implantadas com o crew.

<Frame>
  ![Integrações](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/user_bearer_token.png)
</Frame>

### Precisa de Ajuda?

<Card title="Precisa de ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nosso time de suporte para assistência com a configuração de integrações ou solução de problemas.
</Card>


# Repositório de Ferramentas
Source: https://docs.crewai.com/pt-BR/enterprise/features/tool-repository

Usando o Repositório de Ferramentas para gerenciar suas ferramentas

## Visão geral

O Repositório de Ferramentas é um gerenciador de pacotes para ferramentas da CrewAI. Ele permite que usuários publiquem, instalem e gerenciem ferramentas que se integram com crews e flows da CrewAI.

As ferramentas podem ser:

* **Privadas**: acessíveis apenas dentro da sua organização (padrão)
* **Públicas**: acessíveis a todos os usuários CrewAI se publicadas com a flag `--public`

O repositório não é um sistema de controle de versões. Use o Git para rastrear mudanças no código e permitir colaboração.

## Pré-requisitos

Antes de usar o Repositório de Ferramentas, certifique-se de que você possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com)
* [CrewAI CLI](https://docs.crewai.com/concepts/cli#cli) instalada
* uv>=0.5.0 instalado. Veja [como atualizar](https://docs.astral.sh/uv/getting-started/installation/#upgrading-uv)
* [Git](https://git-scm.com) instalado e configurado
* Permissões de acesso para publicar ou instalar ferramentas em sua organização CrewAI Enterprise

## Instalando ferramentas

Para instalar uma ferramenta:

```bash
crewai tool install <nome-da-ferramenta>
```

Isso instala a ferramenta e a adiciona ao `pyproject.toml`.

## Criando e publicando ferramentas

Para criar um novo projeto de ferramenta:

```bash
crewai tool create <nome-da-ferramenta>
```

Isso gera um projeto de ferramenta estruturado localmente.

Após fazer alterações, inicialize um repositório Git e faça o commit do código:

```bash
git init
git add .
git commit -m "Initial version"
```

Para publicar a ferramenta:

```bash
crewai tool publish
```

Por padrão, as ferramentas são publicadas como privadas. Para tornar uma ferramenta pública:

```bash
crewai tool publish --public
```

Para mais detalhes sobre como construir ferramentas, acesse [Criando suas próprias ferramentas](https://docs.crewai.com/concepts/tools#creating-your-own-tools).

## Atualizando ferramentas

Para atualizar uma ferramenta publicada:

1. Modifique a ferramenta localmente
2. Atualize a versão no `pyproject.toml` (por exemplo, de `0.1.0` para `0.1.1`)
3. Faça o commit das alterações e publique

```bash
git commit -m "Atualizar versão para 0.1.1"
crewai tool publish
```

## Excluindo ferramentas

Para excluir uma ferramenta:

1. Acesse o [CrewAI Enterprise](https://app.crewai.com)
2. Navegue até **Ferramentas**
3. Selecione a ferramenta
4. Clique em **Excluir**

<Warning>
  A exclusão é permanente. Ferramentas excluídas não podem ser restauradas ou reinstaladas.
</Warning>

## Verificações de segurança

Cada versão publicada passa por verificações automáticas de segurança e só fica disponível para instalação após aprovação.

Você pode verificar o status das verificações de segurança de uma ferramenta em:

`CrewAI Enterprise > Tools > Your Tool > Versions`

<Card title="Precisa de ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para assistência com integração de API ou resolução de problemas.
</Card>


# Traces
Source: https://docs.crewai.com/pt-BR/enterprise/features/traces

Usando Traces para monitorar seus Crews

## Visão Geral

Traces fornecem visibilidade abrangente sobre as execuções dos seus crews, ajudando você a monitorar o desempenho, depurar problemas e otimizar os fluxos de trabalho dos seus agentes de IA.

## O que são Traces?

Traces no CrewAI Enterprise são registros detalhados de execução que capturam todos os aspectos da operação do seu crew, desde as entradas iniciais até as saídas finais. Eles registram:

* Pensamentos e raciocínio do agente
* Detalhes da execução das tarefas
* Uso de ferramentas e resultados
* Métricas de consumo de tokens
* Tempos de execução
* Estimativas de custo

<Frame>
  ![Traces Overview](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/traces-overview.png)
</Frame>

## Acessando os Traces

<Steps>
  <Step title="Navegue até a aba Traces">
    No seu painel do CrewAI Enterprise, clique em **Traces** para ver todos os registros de execução.
  </Step>

  <Step title="Selecione uma Execução">
    Você verá uma lista de todas as execuções do crew, ordenadas por data. Clique em qualquer execução para visualizar seu trace detalhado.
  </Step>
</Steps>

## Entendendo a Interface do Trace

A interface do trace é dividida em várias seções, cada uma fornecendo diferentes insights sobre a execução do seu crew:

### 1. Resumo da Execução

A seção superior exibe métricas de alto nível sobre a execução:

* **Total de Tokens**: Número de tokens consumidos em todas as tarefas
* **Prompt Tokens**: Tokens usados em prompts para o LLM
* **Completion Tokens**: Tokens gerados nas respostas do LLM
* **Requisições**: Número de chamadas de API feitas
* **Tempo de Execução**: Duração total da execução do crew
* **Custo Estimado**: Custo aproximado com base no uso de tokens

<Frame>
  ![Execution Summary](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/trace-summary.png)
</Frame>

### 2. Tarefas & Agentes

Esta seção mostra todas as tarefas e agentes que fizeram parte da execução do crew:

* Nome da tarefa e atribuição do agente
* Agentes e LLMs usados em cada tarefa
* Status (concluído/falhou)
* Tempo de execução individual da tarefa

<Frame>
  ![Task List](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/trace-tasks.png)
</Frame>

### 3. Saída Final

Exibe o resultado final produzido pelo crew após a conclusão de todas as tarefas.

<Frame>
  ![Final Output](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/final-output.png)
</Frame>

### 4. Linha do Tempo da Execução

Uma representação visual de quando cada tarefa começou e terminou, ajudando a identificar gargalos ou padrões de execução paralela.

<Frame>
  ![Execution Timeline](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/trace-timeline.png)
</Frame>

### 5. Visão Detalhada da Tarefa

Ao clicar em uma tarefa específica na linha do tempo ou na lista de tarefas, você verá:

<Frame>
  ![Detailed Task View](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/trace-detailed-task.png)
</Frame>

* **Task Key**: Identificador único da tarefa
* **Task ID**: Identificador técnico no sistema
* **Status**: Estado atual (concluída/em execução/falhou)
* **Agente**: Qual agente executou a tarefa
* **LLM**: Modelo de linguagem usado nesta tarefa
* **Início/Fim**: Quando a tarefa foi iniciada e concluída
* **Tempo de Execução**: Duração desta tarefa específica
* **Descrição da Tarefa**: O que o agente foi instruído a fazer
* **Expected Output**: Qual formato de saída foi solicitado
* **Input**: Qualquer entrada fornecida a essa tarefa vinda de tarefas anteriores
* **Output**: O resultado real produzido pelo agente

## Usando Traces para Depuração

Traces são indispensáveis para solucionar problemas nos seus crews:

<Steps>
  <Step title="Identifique Pontos de Falha">
    Quando uma execução de crew não produzir os resultados esperados, examine o trace para encontrar onde ocorreu o problema. Procure por:

    * Tarefas que falharam
    * Decisões inesperadas dos agentes
    * Erros no uso de ferramentas
    * Instruções mal interpretadas

    <Frame>
      ![Failure Points](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/failure.png)
    </Frame>
  </Step>

  <Step title="Otimizar Desempenho">
    Use métricas de execução para identificar gargalos de desempenho:

    * Tarefas que demoraram mais do que o esperado
    * Uso excessivo de tokens
    * Operações redundantes de ferramentas
    * Chamadas de API desnecessárias
  </Step>

  <Step title="Melhore a Eficiência de Custos">
    Analise o uso de tokens e as estimativas de custo para otimizar a eficiência do seu crew:

    * Considere usar modelos menores para tarefas mais simples
    * Refine prompts para serem mais concisos
    * Faça cache de informações acessadas frequentemente
    * Estruture tarefas para minimizar operações redundantes
  </Step>
</Steps>

<Card title="Precisa de ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para assistência com análise de traces ou outros recursos do CrewAI Enterprise.
</Card>


# Webhook Streaming
Source: https://docs.crewai.com/pt-BR/enterprise/features/webhook-streaming

Usando Webhook Streaming para transmitir eventos para o seu webhook

## Visão Geral

O Enterprise Event Streaming permite que você receba atualizações em tempo real via webhook sobre suas crews e flows implantados no CrewAI Enterprise, como chamadas de modelo, uso de ferramentas e etapas do flow.

## Uso

Ao utilizar a API Kickoff, inclua um objeto `webhooks` em sua requisição, por exemplo:

# Exemplo de uso da API Kickoff com webhooks

```json
{
  "inputs": {"foo": "bar"},
  "webhooks": {
    "events": ["crew_kickoff_started", "llm_call_started"],
    "url": "https://seu.endpoint/webhook",
    "realtime": false,
    "authentication": {
      "strategy": "bearer",
      "token": "meu-token-secreto"
    }
  }
}
```

Se `realtime` estiver definido como `true`, cada evento será entregue individualmente e imediatamente, com impacto no desempenho da crew/flow.

## Formato do Webhook

Cada webhook envia uma lista de eventos:

# Exemplo de evento enviado pelo webhook

```json
{
  "events": [
    {
      "id": "id-do-evento",
      "execution_id": "id-da-execucao-do-crew",
      "timestamp": "2025-02-16T10:58:44.965Z",
      "type": "llm_call_started",
      "data": {
        "model": "gpt-4",
        "messages": [
          {"role": "system", "content": "Você é um assistente."},
          {"role": "user", "content": "Resuma este artigo."}
        ]
      }
    }
  ]
}
```

A estrutura do objeto `data` varia conforme o tipo de evento. Consulte a [lista de eventos](https://github.com/crewAIInc/crewAI/tree/main/src/crewai/utilities/events) no GitHub.

Como as requisições são enviadas via HTTP, a ordem dos eventos não pode ser garantida. Caso precise de ordenação, utilize o campo `timestamp`.

## Eventos Suportados

O CrewAI oferece suporte a eventos do sistema e eventos personalizados no Enterprise Event Streaming. Esses eventos são enviados para o endpoint do seu webhook configurado durante a execução das crews e flows.

* `crew_kickoff_started`
* `crew_step_started`
* `crew_step_completed`
* `crew_execution_completed`
* `llm_call_started`
* `llm_call_completed`
* `tool_usage_started`
* `tool_usage_completed`
* `crew_test_failed`
* *...e outros*

Os nomes dos eventos correspondem ao event bus interno. Veja o [código fonte no GitHub](https://github.com/crewAIInc/crewAI/tree/main/src/crewai/utilities/events) para a lista completa.

Você pode emitir seus próprios eventos personalizados, e eles serão entregues através do webhook stream juntamente com os eventos do sistema.

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para assistência com integração de webhook ou solução de problemas.
</Card>


# Configuração do Azure OpenAI
Source: https://docs.crewai.com/pt-BR/enterprise/guides/azure-openai-setup

Configure o Azure OpenAI com o Crew Studio para conexões empresariais de LLM

Este guia orienta você na conexão do Azure OpenAI com o Crew Studio para operações de IA empresarial sem interrupções.

## Processo de Configuração

<Steps>
  <Step title="Acesse o Azure OpenAI Studio">
    1. No Azure, vá para `Serviços de IA do Azure > selecione sua implantação > abra o Azure OpenAI Studio`.
    2. No menu à esquerda, clique em `Implantações`. Se não houver nenhuma, crie uma implantação com o modelo desejado.
    3. Uma vez criada, selecione sua implantação e localize o `Target URI` e a `Key` no lado direito da página. Mantenha esta página aberta, pois você precisará dessas informações.
       <Frame>
         <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/azure-openai-studio.png" alt="Azure OpenAI Studio" />
       </Frame>
  </Step>

  <Step title="Configure a Conexão Enterprise do CrewAI">
    4. Em outra aba, abra `CrewAI Enterprise > LLM Connections`. Dê um nome à sua LLM Connection, selecione Azure como provedor e escolha o mesmo modelo que você selecionou no Azure.
    5. Na mesma página, adicione as variáveis de ambiente do passo 3:
       * Uma chamada `AZURE_DEPLOYMENT_TARGET_URL` (usando o Target URI). A URL deve ser parecida com: [https://your-deployment.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-08-01-preview](https://your-deployment.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-08-01-preview)
       * Outra chamada `AZURE_API_KEY` (usando a Key).
    6. Clique em `Add Connection` para salvar sua LLM Connection.
  </Step>

  <Step title="Defina Configurações Padrão">
    7. Em `CrewAI Enterprise > Settings > Defaults > Crew Studio LLM Settings`, defina a nova LLM Connection e o modelo como padrão.
  </Step>

  <Step title="Configure o Acesso à Rede">
    8. Certifique-se das configurações de acesso à rede:
       * No Azure, vá para `Azure OpenAI > selecione sua implantação`.
       * Navegue até `Resource Management > Networking`.
       * Certifique-se de que a opção `Allow access from all networks` está habilitada. Se essa configuração estiver restrita, o CrewAI pode ser impedido de acessar seu endpoint do Azure OpenAI.
  </Step>
</Steps>

## Verificação

Tudo pronto! O Crew Studio agora utilizará sua conexão Azure OpenAI. Teste a conexão criando um crew ou task simples para garantir que tudo está funcionando corretamente.

## Solução de Problemas

Se você encontrar problemas:

* Verifique se o formato do Target URI corresponde ao padrão esperado
* Confira se a API key está correta e com as permissões adequadas
* Certifique-se de que o acesso à rede está configurado para permitir conexões do CrewAI
* Confirme se o modelo da implantação corresponde ao que você configurou no CrewAI


# Build Crew
Source: https://docs.crewai.com/pt-BR/enterprise/guides/build-crew

Uma Crew é um grupo de agentes que trabalham juntos para completar uma tarefa.

## Visão Geral

[CrewAI Enterprise](https://app.crewai.com) simplifica o processo de **criação**, **implantação** e **gerenciamento** dos seus agentes de IA em ambientes de produção.

## Primeiros Passos

<iframe width="100%" height="400" src="https://www.youtube.com/embed/-kSOTtYzgEw" title="Building Crews with CrewAI CLI" frameborder="0" style={{ borderRadius: '10px' }} allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

### Instalação e Configuração

<Card title="Siga a Instalação Padrão" icon="wrench" href="/pt-BR/installation">
  Siga nosso guia de instalação padrão para configurar o CrewAI CLI e criar seu primeiro projeto.
</Card>

### Construindo Sua Crew

<Card title="Tutorial Rápido" icon="rocket" href="/pt-BR/quickstart">
  Siga nosso tutorial rápido para criar sua primeira crew de agentes usando a configuração YAML.
</Card>

## Suporte e Recursos

Para suporte ou dúvidas específicas da versão Enterprise, entre em contato com nossa equipe dedicada através do [support@crewai.com](mailto:support@crewai.com).

<Card title="Agende uma Demonstração" icon="calendar" href="mailto:support@crewai.com">
  Reserve um horário com nossa equipe para saber mais sobre os recursos Enterprise e como eles podem beneficiar sua organização.
</Card>


# Deploy Crew
Source: https://docs.crewai.com/pt-BR/enterprise/guides/deploy-crew

Implantando um Crew na CrewAI Enterprise

<Note>
  Depois de criar um crew localmente ou pelo Crew Studio, o próximo passo é implantá-lo na plataforma CrewAI Enterprise. Este guia cobre múltiplos métodos de implantação para ajudá-lo a escolher a melhor abordagem para o seu fluxo de trabalho.
</Note>

## Pré-requisitos

<CardGroup cols={2}>
  <Card title="Crew Pronto para Implantação" icon="users">
    Você deve ter um crew funcional, criado localmente ou pelo Crew Studio
  </Card>

  <Card title="Repositório GitHub" icon="github">
    O código do seu crew deve estar em um repositório do GitHub (para o método de integração com GitHub)
  </Card>
</CardGroup>

## Opção 1: Implantar Usando o CrewAI CLI

A CLI fornece a maneira mais rápida de implantar crews desenvolvidos localmente na plataforma Enterprise.

<Steps>
  <Step title="Instale o CrewAI CLI">
    Se ainda não tiver, instale o CrewAI CLI:

    ```bash
    pip install crewai[tools]
    ```

    <Tip>
      A CLI vem com o pacote principal CrewAI, mas o extra `[tools]` garante todas as dependências de implantação.
    </Tip>
  </Step>

  <Step title="Autentique-se na Plataforma Enterprise">
    Primeiro, você precisa autenticar sua CLI com a plataforma CrewAI Enterprise:

    ```bash
    # Se já possui uma conta CrewAI Enterprise, ou deseja criar uma:
    crewai login
    ```

    Ao executar qualquer um dos comandos, a CLI irá:

    1. Exibir uma URL e um código de dispositivo único
    2. Abrir seu navegador para a página de autenticação
    3. Solicitar a confirmação do dispositivo
    4. Completar o processo de autenticação

    Após a autenticação bem-sucedida, você verá uma mensagem de confirmação no terminal!
  </Step>

  <Step title="Criar uma Implantação">
    No diretório do seu projeto, execute:

    ```bash
    crewai deploy create
    ```

    Este comando irá:

    1. Detectar informações do seu repositório GitHub
    2. Identificar variáveis de ambiente no seu arquivo `.env` local
    3. Transferir essas variáveis com segurança para a plataforma Enterprise
    4. Criar uma nova implantação com um identificador único

    Com a criação bem-sucedida, você verá uma mensagem como:

    ```shell
    Deployment created successfully!
    Name: your_project_name
    Deployment ID: 01234567-89ab-cdef-0123-456789abcdef
    Current Status: Deploy Enqueued
    ```
  </Step>

  <Step title="Acompanhe o Progresso da Implantação">
    Acompanhe o status da implantação com:

    ```bash
    crewai deploy status
    ```

    Para ver logs detalhados do processo de build:

    ```bash
    crewai deploy logs
    ```

    <Tip>
      A primeira implantação normalmente leva de 10 a 15 minutos, pois as imagens dos containers são construídas. As próximas implantações são bem mais rápidas.
    </Tip>
  </Step>
</Steps>

## Comandos Adicionais da CLI

O CrewAI CLI oferece vários comandos para gerenciar suas implantações:

```bash
# Liste todas as suas implantações
crewai deploy list

# Consulte o status de uma implantação
crewai deploy status

# Veja os logs da implantação
crewai deploy logs

# Envie atualizações após alterações no código
crewai deploy push

# Remova uma implantação
crewai deploy remove <deployment_id>
```

## Opção 2: Implantar Diretamente pela Interface Web

Você também pode implantar seus crews diretamente pela interface web da CrewAI Enterprise conectando sua conta do GitHub. Esta abordagem não requer utilizar a CLI na sua máquina local.

<Steps>
  <Step title="Enviar no GitHub">
    Você precisa subir seu crew para um repositório do GitHub. Caso ainda não tenha criado um crew, você pode [seguir este tutorial](/pt-BR/quickstart).
  </Step>

  <Step title="Conectando o GitHub ao CrewAI Enterprise">
    1. Faça login em [CrewAI Enterprise](https://app.crewai.com)
    2. Clique no botão "Connect GitHub"

    <Frame>
      ![Botão Connect GitHub](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/connect-github.png)
    </Frame>
  </Step>

  <Step title="Selecionar o Repositório">
    Após conectar sua conta GitHub, você poderá selecionar qual repositório deseja implantar:

    <Frame>
      ![Selecionar Repositório](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/select-repo.png)
    </Frame>
  </Step>

  <Step title="Definir as Variáveis de Ambiente">
    Antes de implantar, você precisará configurar as variáveis de ambiente para conectar ao seu provedor de LLM ou outros serviços:

    1. Você pode adicionar variáveis individualmente ou em lote
    2. Digite suas variáveis no formato `KEY=VALUE` (uma por linha)

    <Frame>
      ![Definir Variáveis de Ambiente](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/set-env-variables.png)
    </Frame>
  </Step>

  <Step title="Implante Seu Crew">
    1. Clique no botão "Deploy" para iniciar o processo de implantação
    2. Você pode monitorar o progresso pela barra de progresso
    3. A primeira implantação geralmente demora de 10 a 15 minutos; as próximas serão mais rápidas

    <Frame>
      ![Progresso da Implantação](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/deploy-progress.png)
    </Frame>

    Após a conclusão, você verá:

    * A URL exclusiva do seu crew
    * Um Bearer token para proteger sua API crew
    * Um botão "Delete" caso precise remover a implantação
  </Step>
</Steps>

## ⚠️ Requisitos de Segurança para Variáveis de Ambiente

<Warning>
  **Importante**: A CrewAI Enterprise possui restrições de segurança sobre os nomes de variáveis de ambiente que podem causar falha na implantação caso não sejam seguidas.
</Warning>

### Padrões de Variáveis de Ambiente Bloqueados

Por motivos de segurança, os seguintes padrões de nome de variável de ambiente são **automaticamente filtrados** e causarão problemas de implantação:

**Padrões Bloqueados:**

* Variáveis terminando em `_TOKEN` (ex: `MY_API_TOKEN`)
* Variáveis terminando em `_PASSWORD` (ex: `DB_PASSWORD`)
* Variáveis terminando em `_SECRET` (ex: `API_SECRET`)
* Variáveis terminando em `_KEY` em certos contextos

**Variáveis Bloqueadas Específicas:**

* `GITHUB_USER`, `GITHUB_TOKEN`
* `AWS_REGION`, `AWS_DEFAULT_REGION`
* Diversas variáveis internas do sistema CrewAI

### Exceções Permitidas

Algumas variáveis são explicitamente permitidas mesmo coincidindo com os padrões bloqueados:

* `AZURE_AD_TOKEN`
* `AZURE_OPENAI_AD_TOKEN`
* `ENTERPRISE_ACTION_TOKEN`
* `CREWAI_ENTEPRISE_TOOLS_TOKEN`

### Como Corrigir Problemas de Nomeação

Se sua implantação falhar devido a restrições de variáveis de ambiente:

```bash
# ❌ Estas irão causar falhas na implantação
OPENAI_TOKEN=sk-...
DATABASE_PASSWORD=mysenha
API_SECRET=segredo123

# ✅ Utilize estes padrões de nomeação
OPENAI_API_KEY=sk-...
DATABASE_CREDENTIALS=mysenha
API_CONFIG=segredo123
```

### Melhores Práticas

1. **Use convenções padrão de nomenclatura**: `PROVIDER_API_KEY` em vez de `PROVIDER_TOKEN`
2. **Teste localmente primeiro**: Certifique-se de que seu crew funciona com as variáveis renomeadas
3. **Atualize seu código**: Altere todas as referências aos nomes antigos das variáveis
4. **Documente as mudanças**: Mantenha registro das variáveis renomeadas para seu time

<Tip>
  Se você se deparar com falhas de implantação com erros enigmáticos de variáveis de ambiente, confira primeiro os nomes das variáveis em relação a esses padrões.
</Tip>

### Interaja com Seu Crew Implantado

Após a implantação, você pode acessar seu crew por meio de:

1. **REST API**: A plataforma gera um endpoint HTTPS exclusivo com estas rotas principais:
   * `/inputs`: Lista os parâmetros de entrada requeridos
   * `/kickoff`: Inicia uma execução com os inputs fornecidos
   * `/status/{kickoff_id}`: Consulta o status da execução

2. **Interface Web**: Acesse [app.crewai.com](https://app.crewai.com) para visualizar:
   * **Aba Status**: Informações da implantação, detalhes do endpoint da API e token de autenticação
   * **Aba Run**: Visualização da estrutura do seu crew
   * **Aba Executions**: Histórico de todas as execuções
   * **Aba Metrics**: Análises de desempenho
   * **Aba Traces**: Insights detalhados das execuções

### Dispare uma Execução

No dashboard Enterprise, você pode:

1. Clicar no nome do seu crew para abrir seus detalhes
2. Selecionar "Trigger Crew" na interface de gerenciamento
3. Inserir os inputs necessários no modal exibido
4. Monitorar o progresso à medida que a execução avança pelo pipeline

### Monitoramento e Análises

A plataforma Enterprise oferece recursos abrangentes de observabilidade:

* **Gestão das Execuções**: Acompanhe execuções ativas e concluídas
* **Traces**: Quebra detalhada de cada execução
* **Métricas**: Uso de tokens, tempos de execução e custos
* **Visualização em Linha do Tempo**: Representação visual das sequências de tarefas

### Funcionalidades Avançadas

A plataforma Enterprise também oferece:

* **Gerenciamento de Variáveis de Ambiente**: Armazene e gerencie com segurança as chaves de API
* **Conexões com LLM**: Configure integrações com diversos provedores de LLM
* **Repositório Custom Tools**: Crie, compartilhe e instale ferramentas
* **Crew Studio**: Monte crews via interface de chat sem escrever código

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para ajuda com questões de implantação ou dúvidas sobre a plataforma Enterprise.
</Card>


# Ativar Crew Studio
Source: https://docs.crewai.com/pt-BR/enterprise/guides/enable-crew-studio

Ativando o Crew Studio no CrewAI Enterprise

<Tip>
  Crew Studio é uma poderosa ferramenta **no-code/low-code** que permite criar ou estruturar Crews rapidamente por meio de uma interface conversacional.
</Tip>

## O que é o Crew Studio?

O Crew Studio é uma forma inovadora de criar equipes de agentes de IA sem escrever código.

<Frame>
  ![Crew Studio Interface](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-studio-interface.png)
</Frame>

Com o Crew Studio, você pode:

* Conversar com o Crew Assistant para descrever seu problema
* Gerar automaticamente agentes e tarefas
* Selecionar as ferramentas apropriadas
* Configurar os inputs necessários
* Gerar código para download e personalização
* Fazer deploy diretamente na plataforma CrewAI Enterprise

## Etapas de Configuração

Antes de começar a usar o Crew Studio, você precisa configurar suas conexões LLM:

<Steps>
  <Step title="Configurar a Conexão LLM">
    Acesse a aba **LLM Connections** no painel do CrewAI Enterprise e crie uma nova conexão LLM.

    <Note>
      Sinta-se à vontade para utilizar qualquer provedor LLM suportado pelo CrewAI.
    </Note>

    Configure sua conexão LLM:

    * Insira um `Connection Name` (por exemplo, `OpenAI`)
    * Selecione o provedor do modelo: `openai` ou `azure`
    * Selecione os modelos que deseja usar em suas Crews geradas pelo Studio
      * Recomendamos pelo menos `gpt-4o`, `o1-mini` e `gpt-4o-mini`
    * Adicione sua chave de API como uma variável de ambiente:
      * Para OpenAI: adicione `OPENAI_API_KEY` com sua chave de API
      * Para Azure OpenAI: consulte [este artigo](https://blog.crewai.com/configuring-azure-openai-with-crewai-a-comprehensive-guide/) para detalhes de configuração
    * Clique em `Add Connection` para salvar sua configuração

    <Frame>
      ![LLM Connection Configuration](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/llm-connection-config.png)
    </Frame>
  </Step>

  <Step title="Verificar Conexão Adicionada">
    Assim que concluir a configuração, você verá sua nova conexão adicionada à lista de conexões disponíveis.

    <Frame>
      ![Connection Added](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/connection-added.png)
    </Frame>
  </Step>

  <Step title="Configurar Padrões do LLM">
    No menu principal, vá em **Settings → Defaults** e configure as opções padrão do LLM:

    * Selecione os modelos padrão para agentes e outros componentes
    * Defina as configurações padrão para o Crew Studio

    Clique em `Save Settings` para aplicar as alterações.

    <Frame>
      ![LLM Defaults Configuration](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/llm-defaults.png)
    </Frame>
  </Step>
</Steps>

## Usando o Crew Studio

Agora que você configurou sua conexão LLM e os padrões, está pronto para começar a usar o Crew Studio!

<Steps>
  <Step title="Acessar o Studio">
    Navegue até a seção **Studio** no painel do CrewAI Enterprise.
  </Step>

  <Step title="Iniciar uma Conversa">
    Inicie uma conversa com o Crew Assistant descrevendo o problema que deseja resolver:

    ```md
    I need a crew that can research the latest AI developments and create a summary report.
    ```

    O Crew Assistant fará perguntas de esclarecimento para entender melhor suas necessidades.
  </Step>

  <Step title="Revisar o Crew Gerado">
    Revise a configuração do crew gerado, incluindo:

    * Agentes e seus papéis
    * Tarefas a serem realizadas
    * Inputs necessários
    * Ferramentas a serem utilizadas

    Esta é sua oportunidade para refinar a configuração antes de prosseguir.
  </Step>

  <Step title="Fazer Deploy ou Baixar">
    Quando estiver satisfeito com a configuração, você pode:

    * Baixar o código gerado para personalização local
    * Fazer deploy do crew diretamente na plataforma CrewAI Enterprise
    * Modificar a configuração e gerar o crew novamente
  </Step>

  <Step title="Testar seu Crew">
    Após o deploy, teste seu crew com inputs de exemplo para garantir que ele funcione conforme esperado.
  </Step>
</Steps>

<Tip>
  Para melhores resultados, forneça descrições claras e detalhadas do que deseja que seu crew realize. Inclua inputs específicos e outputs esperados em sua descrição.
</Tip>

## Exemplo de Fluxo de Trabalho

Veja um fluxo de trabalho típico para criação de um crew com o Crew Studio:

<Steps>
  <Step title="Descreva seu Problema">
    Comece descrevendo seu problema:

    ```md
    I need a crew that can analyze financial news and provide investment recommendations
    ```
  </Step>

  <Step title="Responder Perguntas">
    Responda às perguntas de esclarecimento do Crew Assistant para refinar seus requisitos.
  </Step>

  <Step title="Revisar o Plano">
    Revise o plano do crew gerado, que pode incluir:

    * Um Research Agent para coletar notícias financeiras
    * Um Analysis Agent para interpretar os dados
    * Um Recommendations Agent para fornecer conselhos de investimento
  </Step>

  <Step title="Aprovar ou Modificar">
    Aprove o plano ou solicite alterações, se necessário.
  </Step>

  <Step title="Baixar ou Fazer Deploy">
    Baixe o código para personalização ou faça o deploy diretamente na plataforma.
  </Step>

  <Step title="Testar e Refinar">
    Teste seu crew com inputs de exemplo e faça ajustes conforme necessário.
  </Step>
</Steps>

<Card title="Precisa de ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para obter assistência com o Crew Studio ou qualquer outro recurso do CrewAI Enterprise.
</Card>


# Gatilho HubSpot
Source: https://docs.crewai.com/pt-BR/enterprise/guides/hubspot-trigger

Acione crews do CrewAI diretamente a partir de Workflows do HubSpot

Este guia fornece um processo passo a passo para configurar gatilhos do HubSpot para o CrewAI Enterprise, permitindo iniciar crews diretamente a partir de Workflows do HubSpot.

## Pré-requisitos

* Uma conta CrewAI Enterprise
* Uma conta HubSpot com o recurso de [Workflows do HubSpot](https://knowledge.hubspot.com/workflows/create-workflows)

## Etapas de Configuração

<Steps>
  <Step title="Conecte sua conta HubSpot com o CrewAI Enterprise">
    * Faça login na sua `Conta CrewAI Enterprise > Triggers`
    * Selecione `HubSpot` na lista de gatilhos disponíveis
    * Escolha a conta HubSpot que deseja conectar ao CrewAI Enterprise
    * Siga as instruções na tela para autorizar o acesso do CrewAI Enterprise à sua conta HubSpot
    * Uma mensagem de confirmação aparecerá assim que o HubSpot estiver conectado com sucesso ao CrewAI Enterprise
  </Step>

  <Step title="Crie um Workflow no HubSpot">
    * Faça login na sua `Conta HubSpot > Automations > Workflows > New workflow`
    * Selecione o tipo de workflow que atende às suas necessidades (por exemplo, Começar do zero)
    * No construtor de workflow, clique no ícone de mais (+) para adicionar uma nova ação.
    * Escolha `Integrated apps > CrewAI > Kickoff a Crew`.
    * Selecione a Crew que deseja iniciar.
    * Clique em `Save` para adicionar a ação ao seu workflow

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/hubspot-workflow-1.png" alt="HubSpot Workflow 1" />
    </Frame>
  </Step>

  <Step title="Use os resultados da Crew com outras ações">
    * Após a etapa Kickoff a Crew, clique no ícone de mais (+) para adicionar uma nova ação.
    * Por exemplo, para enviar uma notificação de e-mail interna, escolha `Communications > Send internal email notification`
    * No campo Body, clique em `Insert data`, selecione `View properties or action outputs from > Action outputs > Crew Result` para incluir dados da Crew no e-mail
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/hubspot-workflow-2.png" alt="HubSpot Workflow 2" />
      </Frame>
    * Configure quaisquer ações adicionais necessárias
    * Revise as etapas do seu workflow para garantir que tudo está configurado corretamente
    * Ative o workflow
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/hubspot-workflow-3.png" alt="HubSpot Workflow 3" />
      </Frame>
  </Step>
</Steps>

## Recursos Adicionais

Para informações mais detalhadas sobre as ações disponíveis e opções de personalização, consulte a [Documentação de Workflows do HubSpot](https://knowledge.hubspot.com/workflows/create-workflows).


# Workflows HITL
Source: https://docs.crewai.com/pt-BR/enterprise/guides/human-in-the-loop

Aprenda como implementar workflows Human-In-The-Loop no CrewAI para decisões aprimoradas

Human-In-The-Loop (HITL) é uma abordagem poderosa que combina inteligência artificial com expertise humana para aprimorar a tomada de decisão e melhorar os resultados das tarefas. Este guia mostra como implementar HITL dentro do CrewAI.

## Configurando Workflows HITL

<Steps>
  <Step title="Configure Sua Tarefa">
    Configure sua tarefa com a entrada humana habilitada:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-human-input.png" alt="Crew Human Input" />
    </Frame>
  </Step>

  <Step title="Forneça o URL do Webhook">
    Ao iniciar seu crew, inclua um URL de webhook para entrada humana:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-webhook-url.png" alt="Crew Webhook URL" />
    </Frame>
  </Step>

  <Step title="Receba a Notificação do Webhook">
    Assim que o crew concluir a tarefa que requer entrada humana, você receberá uma notificação do webhook contendo:

    * **ID de Execução**
    * **ID da Tarefa**
    * **Saída da Tarefa**
  </Step>

  <Step title="Revise a Saída da Tarefa">
    O sistema irá pausar no estado `Pending Human Input`. Revise cuidadosamente a saída da tarefa.
  </Step>

  <Step title="Envie o Feedback Humano">
    Chame o endpoint de retomada do seu crew com as seguintes informações:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-resume-endpoint.png" alt="Crew Resume Endpoint" />
    </Frame>

    <Warning>
      **Impacto do Feedback na Execução da Tarefa**:
      É crucial ter cuidado ao fornecer o feedback, pois todo o conteúdo do feedback será incorporado como contexto adicional para as próximas execuções da tarefa.
    </Warning>

    Isso significa:

    * Todas as informações do seu feedback passam a fazer parte do contexto da tarefa.
    * Detalhes irrelevantes podem prejudicar a execução.
    * Feedbacks concisos e relevantes ajudam a manter o foco e a eficiência da tarefa.
    * Sempre revise atentamente seu feedback antes de enviá-lo para garantir que ele contém apenas informações pertinentes que irão guiar positivamente a execução da tarefa.
  </Step>

  <Step title="Lide com Feedback Negativo">
    Se você fornecer um feedback negativo:

    * O crew irá tentar executar novamente a tarefa com o contexto adicional do seu feedback.
    * Você receberá uma nova notificação de webhook para nova revisão.
    * Repita os passos 4-6 até estar satisfeito.
  </Step>

  <Step title="Continuação da Execução">
    Quando você enviar um feedback positivo, a execução prosseguirá para as próximas etapas.
  </Step>
</Steps>

## Melhores Práticas

* **Seja Específico**: Forneça feedback claro e acionável que trate diretamente da tarefa em questão
* **Mantenha a Relevância**: Inclua apenas informações que possam ajudar a melhorar a execução da tarefa
* **Seja Ágil**: Responda rapidamente aos prompts HITL para evitar atrasos no workflow
* **Revise Cuidadosamente**: Verifique duas vezes o seu feedback antes de enviá-lo para garantir precisão

## Casos de Uso Comuns

Workflows HITL são particularmente valiosos para:

* Garantia de qualidade e validação
* Cenários de tomada de decisão complexa
* Operações sensíveis ou de alto risco
* Tarefas criativas que exigem julgamento humano
* Revisões de conformidade e regulatórias


# Kickoff Crew
Source: https://docs.crewai.com/pt-BR/enterprise/guides/kickoff-crew

Inicie um Crew no CrewAI Enterprise

## Visão Geral

Uma vez que você tenha implantado seu crew na plataforma CrewAI Enterprise, é possível iniciar execuções pela interface web ou pela API. Este guia aborda ambos os métodos.

## Método 1: Usando a Interface Web

### Passo 1: Navegue até seu Crew Implantado

1. Faça login no [CrewAI Enterprise](https://app.crewai.com)
2. Clique no nome do crew na sua lista de projetos
3. Você será direcionado para a página de detalhes do crew

<Frame>
  ![Crew Dashboard](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-dashboard.png)
</Frame>

### Passo 2: Iniciar Execução

Na página de detalhes do seu crew, você tem duas opções para iniciar uma execução:

#### Opção A: Kickoff Rápido

1. Clique no link `Kickoff` na seção Test Endpoints
2. Insira os parâmetros de entrada necessários para seu crew no editor JSON
3. Clique no botão `Send Request`

<Frame>
  ![Kickoff Endpoint](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-endpoint.png)
</Frame>

#### Opção B: Usando a Interface Visual

1. Clique na aba `Run` na página de detalhes do crew
2. Insira os inputs necessários nos campos do formulário
3. Clique no botão `Run Crew`

<Frame>
  ![Run Crew](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/run-crew.png)
</Frame>

### Passo 3: Monitorar o Progresso da Execução

Após iniciar a execução:

1. Você receberá uma resposta contendo um `kickoff_id` - **copie este ID**
2. Esse ID é fundamental para o acompanhamento da sua execução

<Frame>
  ![Copy Task ID](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/copy-task-id.png)
</Frame>

### Passo 4: Verificar o Status da Execução

Para monitorar o andamento da sua execução:

1. Clique no endpoint "Status" na seção Test Endpoints
2. Cole o `kickoff_id` no campo indicado
3. Clique no botão "Get Status"

<Frame>
  ![Get Status](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/get-status.png)
</Frame>

A resposta de status mostrará:

* Estado atual da execução (`running`, `completed`, etc.)
* Detalhes sobre quais tarefas estão em andamento
* Quaisquer outputs gerados até o momento

### Passo 5: Visualizar Resultados Finais

Quando a execução for concluída:

1. O status mudará para `completed`
2. Você poderá visualizar todos os resultados e outputs da execução
3. Para uma visão mais detalhada, acesse a aba `Executions` na página de detalhes do crew

## Método 2: Usando a API

Você também pode iniciar crews programaticamente usando a REST API do CrewAI Enterprise.

### Autenticação

Todas as requisições à API exigem um bearer token para autenticação:

```bash
curl -H "Authorization: Bearer YOUR_CREW_TOKEN" https://your-crew-url.crewai.com
```

Seu bearer token está disponível na aba Status na página de detalhes do seu crew.

### Verificando o Status do Crew

Antes de executar operações, você pode verificar se seu crew está funcionando corretamente:

```bash
curl -H "Authorization: Bearer YOUR_CREW_TOKEN" https://your-crew-url.crewai.com
```

Uma resposta de sucesso trará uma mensagem indicando que o crew está operacional:

```
Healthy%
```

### Passo 1: Recuperar Entradas Necessárias

Primeiro, descubra quais entradas seu crew exige:

```bash
curl -X GET \
  -H "Authorization: Bearer YOUR_CREW_TOKEN" \
  https://your-crew-url.crewai.com/inputs
```

A resposta será um objeto JSON contendo um array de parâmetros de entrada obrigatórios, por exemplo:

```json
{"inputs":["topic","current_year"]}
```

Este exemplo mostra que este crew em particular requer dois inputs: `topic` e `current_year`.

### Passo 2: Iniciar Execução

Inicie a execução fornecendo os inputs obrigatórios:

```bash
curl -X POST \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_CREW_TOKEN" \
  -d '{"inputs": {"topic": "AI Agent Frameworks", "current_year": "2025"}}' \
  https://your-crew-url.crewai.com/kickoff
```

A resposta incluirá um `kickoff_id` que você precisará para o acompanhamento:

```json
{"kickoff_id":"abcd1234-5678-90ef-ghij-klmnopqrstuv"}
```

### Passo 3: Verificar Status da Execução

Acompanhe o progresso da execução usando o kickoff\_id:

```bash
curl -X GET \
  -H "Authorization: Bearer YOUR_CREW_TOKEN" \
  https://your-crew-url.crewai.com/status/abcd1234-5678-90ef-ghij-klmnopqrstuv
```

## Gerenciando Execuções

### Execuções de Longa Duração

Para execuções que possam demandar mais tempo:

1. Considere implementar um mecanismo de polling para verificar status periodicamente
2. Utilize webhooks (se disponíveis) para notificação quando a execução for concluída
3. Implemente tratamento de erros para possíveis timeouts

### Contexto da Execução

O contexto da execução inclui:

* Inputs fornecidos no momento do kickoff
* Variáveis de ambiente configuradas durante o deploy
* Qualquer estado mantido entre as tarefas

### Depuração de Execuções com Falha

Se uma execução falhar:

1. Verifique a aba "Executions" para logs detalhados
2. Avalie a aba "Traces" para detalhes passo a passo da execução
3. Procure por respostas LLM e uso de ferramentas nos detalhes do trace

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para obter ajuda com problemas de execução ou dúvidas sobre a plataforma Enterprise.
</Card>


# Exportação de Componentes React
Source: https://docs.crewai.com/pt-BR/enterprise/guides/react-component-export

Aprenda como exportar e integrar componentes React do CrewAI Enterprise em suas aplicações

Este guia explica como exportar crews do CrewAI Enterprise como componentes React e integrá-los às suas próprias aplicações.

## Exportando um Componente React

<Steps>
  <Step title="Exporte o Componente">
    Clique no menu de opções (três pontos à direita do seu crew implantado), selecione a opção de exportação e salve o arquivo localmente. Usaremos o arquivo `CrewLead.jsx` como exemplo.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/export-react-component.png" alt="Exportar Componente React" />
    </Frame>
  </Step>
</Steps>

## Configurando seu Ambiente React

Para executar este componente React localmente, você precisará configurar um ambiente de desenvolvimento React e integrar este componente em um projeto React.

<Steps>
  <Step title="Instale o Node.js">
    * Baixe e instale o Node.js no site oficial: [https://nodejs.org/](https://nodejs.org/)
    * Escolha a versão LTS (Long Term Support) para maior estabilidade.
  </Step>

  <Step title="Crie um novo projeto React">
    * Abra o Prompt de Comando ou PowerShell
    * Navegue até o diretório onde deseja criar seu projeto
    * Execute o seguinte comando para criar um novo projeto React:

      ```bash
      npx create-react-app my-crew-app
      ```
    * Entre no diretório do projeto:

      ```bash
      cd my-crew-app
      ```
  </Step>

  <Step title="Instale as dependências necessárias">
    ```bash
    npm install react-dom
    ```
  </Step>

  <Step title="Crie o componente CrewLead">
    * Mova o arquivo baixado `CrewLead.jsx` para a pasta `src` do seu projeto.
  </Step>

  <Step title="Modifique seu App.js para usar o componente CrewLead">
    * Abra o arquivo `src/App.js`
    * Substitua o conteúdo por algo semelhante a isso:

    ```jsx
    import React from 'react';
    import CrewLead from './CrewLead';

    function App() {
        return (
            <div className="App">
                <CrewLead baseUrl="YOUR_API_BASE_URL" bearerToken="YOUR_BEARER_TOKEN" />
            </div>
        );
    }

    export default App;
    ```

    * Substitua `YOUR_API_BASE_URL` e `YOUR_BEARER_TOKEN` pelos valores reais da sua API.
  </Step>

  <Step title="Inicie o servidor de desenvolvimento">
    * No diretório do seu projeto, execute:

      ```bash
      npm start
      ```
    * Isso iniciará o servidor de desenvolvimento, e seu navegador padrão será aberto automaticamente em [http://localhost:3000](http://localhost:3000), onde você verá sua aplicação React rodando.
  </Step>
</Steps>

## Personalização

Você pode então personalizar o `CrewLead.jsx` para adicionar cor, título etc.

<Frame>
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/customise-react-component.png" alt="Personalizar Componente React" />
</Frame>

<Frame>
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/customise-react-component-2.png" alt="Personalizar Componente React" />
</Frame>

## Próximos Passos

* Personalize o estilo do componente para combinar com o design da sua aplicação
* Adicione props adicionais para configuração
* Integre com o gerenciamento de estado da sua aplicação
* Adicione tratamento de erros e estados de carregamento


# Trigger Salesforce
Source: https://docs.crewai.com/pt-BR/enterprise/guides/salesforce-trigger

Dispare equipes CrewAI a partir de fluxos de trabalho do Salesforce para automação de CRM

A CrewAI Enterprise pode ser acionada a partir do Salesforce para automatizar fluxos de trabalho de gestão de relacionamento com o cliente e aprimorar suas operações de vendas.

## Visão Geral

O Salesforce é uma das principais plataformas de gestão de relacionamento com o cliente (CRM), que ajuda empresas a otimizar operações de vendas, atendimento e marketing. Ao configurar triggers da CrewAI a partir do Salesforce, você pode:

* Automatizar a classificação e qualificação de leads
* Gerar materiais de vendas personalizados
* Aprimorar o atendimento ao cliente com respostas baseadas em IA
* Otimizar análise e relatórios de dados

## Demonstração

<Frame>
  <iframe width="100%" height="400" src="https://www.youtube.com/embed/oJunVqjjfu4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />
</Frame>

## Primeiros Passos

Para configurar triggers no Salesforce:

1. **Contato com o Suporte**: Entre em contato com o suporte da CrewAI Enterprise para obter assistência na configuração dos triggers no Salesforce
2. **Revisar Requisitos**: Certifique-se de possuir as permissões necessárias no Salesforce e acesso à API
3. **Configurar Conexão**: Trabalhe com a equipe de suporte para estabelecer a conexão entre a CrewAI e sua instância do Salesforce
4. **Testar Triggers**: Verifique se os triggers funcionam corretamente para os seus casos de uso específicos

## Casos de Uso

Cenários comuns de uso de triggers Salesforce + CrewAI incluem:

* **Processamento de Leads**: Analisar e classificar leads recebidos automaticamente
* **Geração de Propostas**: Criar propostas personalizadas com base nos dados das oportunidades
* **Insights de Clientes**: Gerar relatórios de análise a partir do histórico de interações com clientes
* **Automação de Follow-up**: Criar mensagens de follow-up e recomendações personalizadas

## Próximos Passos

Para instruções detalhadas de configuração e opções avançadas, entre em contato com o suporte da CrewAI Enterprise, que pode fornecer orientações personalizadas para o seu ambiente Salesforce e necessidades de negócio.


# Slack Trigger
Source: https://docs.crewai.com/pt-BR/enterprise/guides/slack-trigger

Acione crews do CrewAI diretamente do Slack usando comandos de barra

Este guia explica como iniciar um crew diretamente do Slack usando triggers do CrewAI.

## Pré-requisitos

* Trigger do CrewAI para Slack instalado e conectado ao seu workspace do Slack
* Pelo menos um crew configurado no CrewAI

## Etapas de Configuração

<Steps>
  <Step title="Garanta que o trigger do CrewAI para Slack está configurado">
    No dashboard do CrewAI, navegue até a seção **Triggers**.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/slack-integration.png" alt="Integração CrewAI Slack" />
    </Frame>

    Verifique se o Slack está listado e conectado.
  </Step>

  <Step title="Abra o canal do Slack">
    * Navegue até o canal onde você deseja iniciar o crew.
    * Digite o comando de barra "**/kickoff**" para iniciar o processo de kickoff do crew.
    * Você deverá ver "**Kickoff crew**" aparecendo enquanto digita:
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-slack-crew.png" alt="Kickoff crew" />
      </Frame>
    * Pressione Enter ou selecione a opção "**Kickoff crew**". Uma caixa de diálogo intitulada "**Kickoff an AI Crew**" aparecerá.
  </Step>

  <Step title="Selecione o crew que deseja iniciar">
    * No menu suspenso rotulado "**Select of the crews online:**", escolha o crew que deseja iniciar.
    * No exemplo abaixo, "**prep-for-meeting**" está selecionado:
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-slack-crew-dropdown.png" alt="Kickoff crew dropdown" />
      </Frame>
    * Se o seu crew exigir algum input, clique no botão "**Add Inputs**" para fornecê-los.
      <Note>
        O botão "**Add Inputs**" é mostrado no exemplo acima, mas ainda não foi clicado.
      </Note>
  </Step>

  <Step title="Clique em Kickoff e aguarde o término do crew">
    * Assim que você tiver selecionado o crew e adicionado os inputs necessários, clique em "**Kickoff**" para iniciar o crew.
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-slack-crew-kickoff.png" alt="Kickoff crew" />
      </Frame>
    * O crew começará a ser executado e você verá os resultados no canal do Slack.
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-slack-crew-results.png" alt="Kickoff crew results" />
      </Frame>
  </Step>
</Steps>

## Dicas

* Certifique-se de que você possui as permissões necessárias para usar o comando `/kickoff` em seu workspace do Slack.
* Se você não visualizar o crew desejado no menu suspenso, verifique se ele está devidamente configurado e online no CrewAI.


# Gestão de Equipes
Source: https://docs.crewai.com/pt-BR/enterprise/guides/team-management

Aprenda como convidar e gerenciar membros da equipe em sua organização CrewAI Enterprise

Como administrador de uma conta CrewAI Enterprise, você pode facilmente convidar novos membros para sua organização. Este guia irá orientá-lo passo a passo pelo processo.

## Convidando Membros da Equipe

<Steps>
  <Step title="Acesse a Página de Configurações">
    * Faça login na sua conta CrewAI Enterprise
    * Procure o ícone de engrenagem (⚙️) no canto superior direito do painel
    * Clique no ícone de engrenagem para acessar a página de **Configurações**:
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/settings-page.png" alt="Página de Configurações" />
      </Frame>
  </Step>

  <Step title="Navegue até a Seção de Membros">
    * Na página de Configurações, você verá a aba `Members`
    * Clique na aba `Members` para acessar a página de **Membros**:
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/members-tab.png" alt="Aba Membros" />
      </Frame>
  </Step>

  <Step title="Convidar Novos Membros">
    * Na seção de Membros, você verá uma lista dos membros atuais (incluindo você)
    * Localize o campo de entrada `Email`
    * Digite o endereço de e-mail da pessoa que você deseja convidar
    * Clique no botão `Invite` para enviar o convite
  </Step>

  <Step title="Repita Conforme Necessário">
    * Você pode repetir esse processo para convidar vários membros da equipe
    * Cada membro convidado receberá um convite por e-mail para ingressar na sua organização
  </Step>
</Steps>

## Adicionando Funções

Você pode adicionar funções aos membros da equipe para controlar o acesso a diferentes partes da plataforma.

<Steps>
  <Step title="Acesse a Página de Configurações">
    * Faça login na sua conta CrewAI Enterprise
    * Procure o ícone de engrenagem (⚙️) no canto superior direito do painel
    * Clique no ícone de engrenagem para acessar a página de **Configurações**:
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/settings-page.png" alt="Página de Configurações" />
      </Frame>
  </Step>

  <Step title="Navegue até a Seção de Funções">
    * Na página de Configurações, você verá a aba `Roles`
    * Clique na aba `Roles` para acessar a página de **Funções**.
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/roles-tab.png" alt="Aba Funções" />
      </Frame>
    * Clique no botão `Add Role` para adicionar uma nova função.
    * Insira os detalhes e as permissões da função e clique no botão `Create Role` para criar a função.
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/add-role-modal.png" alt="Modal Adicionar Função" />
      </Frame>
  </Step>

  <Step title="Adicionar Funções aos Membros">
    * Na seção de Membros, você verá uma lista dos membros atuais (incluindo você)
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/member-accepted-invitation.png" alt="Membro Aceitou Convite" />
      </Frame>
    * Após o membro aceitar o convite, você poderá adicionar uma função a ele.
    * Volte para a aba `Roles`
    * Vá até o membro ao qual deseja adicionar uma função e, na coluna `Role`, clique no menu suspenso
    * Selecione a função que deseja atribuir ao membro
    * Clique no botão `Update` para salvar a função
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/assign-role.png" alt="Adicionar Função ao Membro" />
      </Frame>
  </Step>
</Steps>

## Notas Importantes

* **Privilégios de Administrador**: Apenas usuários com privilégios administrativos podem convidar novos membros
* **Precisão do E-mail**: Certifique-se de que você tem os endereços de e-mail corretos dos membros da equipe
* **Aceite do Convite**: Os membros convidados precisarão aceitar o convite para ingressar na sua organização
* **Notificações por E-mail**: Oriente seus membros a verificarem o e-mail (incluindo a pasta de spam) para localizar o convite

Seguindo estes passos, você conseguirá expandir sua equipe e colaborar de forma mais eficaz dentro da sua organização CrewAI Enterprise.


# Atualizar Crew
Source: https://docs.crewai.com/pt-BR/enterprise/guides/update-crew

Atualizando uma Crew no CrewAI Enterprise

<Note>
  Após implantar sua crew no CrewAI Enterprise, pode ser necessário fazer atualizações no código, configurações de segurança ou configuração.
  Este guia explica como realizar essas operações de atualização comuns.
</Note>

## Por que atualizar sua Crew?

Por padrão, o CrewAI não irá buscar atualizações do GitHub automaticamente, então você precisará acionar manualmente as atualizações, a menos que tenha marcado a opção `Auto-update` ao implantar sua crew.

Há várias razões para querer atualizar sua implantação de crew:

* Você deseja atualizar o código com o commit mais recente que enviou para o GitHub
* Você deseja redefinir o bearer token por motivos de segurança
* Você deseja atualizar variáveis de ambiente

## 1. Atualizando o código da sua Crew para o último commit

Quando você fizer push de novos commits no seu repositório do GitHub e quiser atualizar sua implantação:

1. Navegue até sua crew na plataforma CrewAI Enterprise
2. Clique no botão `Re-deploy` na página de detalhes da sua crew

<Frame>
  ![Botão Re-deploy](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/redeploy-button.png)
</Frame>

Isso irá acionar uma atualização que pode ser acompanhada pela barra de progresso. O sistema irá buscar o código mais recente do seu repositório e reconstruir sua implantação.

## 2. Redefinindo o Bearer Token

Se precisar gerar um novo bearer token (por exemplo, se suspeitar que o token atual possa ter sido comprometido):

1. Navegue até sua crew na plataforma CrewAI Enterprise
2. Encontre a seção `Bearer Token`
3. Clique no botão `Reset` ao lado do token atual

<Frame>
  ![Reset Token](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/reset-token.png)
</Frame>

<Warning>
  A redefinição do bearer token invalidará imediatamente o token anterior. Certifique-se de atualizar quaisquer aplicações ou scripts que estejam utilizando o token antigo.
</Warning>

## 3. Atualizando Variáveis de Ambiente

Para atualizar as variáveis de ambiente da sua crew:

1. Primeiro, acesse a página de implantação clicando no nome da sua crew

<Frame>
  ![Botão Variáveis de Ambiente](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/env-vars-button.png)
</Frame>

2. Localize a seção `Environment Variables` (você deverá clicar no ícone de `Settings` para acessá-la)
3. Edite as variáveis existentes ou adicione novas nos campos fornecidos
4. Clique no botão `Update` ao lado de cada variável que você modificar

<Frame>
  ![Atualizar Variáveis de Ambiente](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/update-env-vars.png)
</Frame>

5. Por fim, clique no botão `Update Deployment` na parte inferior da página para aplicar as alterações

<Note>
  A atualização das variáveis de ambiente irá acionar uma nova implantação, mas isso atualizará apenas a configuração de ambiente e não o código em si.
</Note>

## Após atualizar

Após realizar qualquer atualização:

1. O sistema irá reconstruir e reimplantar sua crew
2. Você poderá monitorar o progresso da implantação em tempo real
3. Quando finalizado, teste sua crew para garantir que as alterações estão funcionando como esperado

<Tip>
  Se encontrar algum problema após a atualização, é possível visualizar os logs de implantação na plataforma ou entrar em contato com o suporte para obter assistência.
</Tip>

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para obter assistência com a atualização da sua crew ou solução de problemas de implantação.
</Card>


# Automação com Webhook
Source: https://docs.crewai.com/pt-BR/enterprise/guides/webhook-automation

Automatize fluxos de trabalho do CrewAI Enterprise usando webhooks com plataformas como ActivePieces, Zapier e Make.com

O CrewAI Enterprise permite que você automatize seu fluxo de trabalho usando webhooks. Este artigo irá guiá-lo no processo de configuração e uso de webhooks para iniciar a execução do crew, com foco na integração com o ActivePieces, uma plataforma de automação de fluxos de trabalho semelhante ao Zapier e Make.com.

## Configurando Webhooks

<Steps>
  <Step title="Acessando a Interface de Kickoff">
    * Navegue até o painel do CrewAI Enterprise
    * Procure pela seção `/kickoff`, que é usada para iniciar a execução do crew
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-interface.png" alt="Interface Kickoff" />
      </Frame>
  </Step>

  <Step title="Configurando o Conteúdo JSON">
    Na seção de Conteúdo JSON, você deverá fornecer as seguintes informações:

    * **inputs**: Um objeto JSON contendo:
      * `company`: O nome da empresa (ex.: "tesla")
      * `product_name`: O nome do produto (ex.: "crewai")
      * `form_response`: O tipo de resposta (ex.: "financial")
      * `icp_description`: Uma breve descrição do Perfil de Cliente Ideal
      * `product_description`: Uma breve descrição do produto
      * `taskWebhookUrl`, `stepWebhookUrl`, `crewWebhookUrl`: URLs para diversos endpoints de webhook (ActivePieces, Zapier, Make.com ou outra plataforma compatível)
  </Step>

  <Step title="Integração com ActivePieces">
    Neste exemplo usaremos o ActivePieces. Você pode utilizar outras plataformas, como Zapier e Make.com.

    Para integrar com o ActivePieces:

    1. Crie um novo flow no ActivePieces

    2. Adicione um gatilho (ex.: agendamento `Every Day`)
       <Frame>
         <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-trigger.png" alt="Gatilho ActivePieces" />
       </Frame>

    3. Adicione uma etapa de ação HTTP
       * Configure a ação como `Send HTTP request`

       * Use o método `POST`

       * Defina a URL para o endpoint de kickoff do CrewAI Enterprise

       * Adicione os headers necessários (ex.: `Bearer Token`)
         <Frame>
           <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-headers.png" alt="Headers ActivePieces" />
         </Frame>

       * No corpo, inclua o conteúdo JSON conforme configurado na etapa 2
         <Frame>
           <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-body.png" alt="Body ActivePieces" />
         </Frame>

       * O crew será iniciado no horário pré-definido.
  </Step>

  <Step title="Configurando o Webhook">
    1. Crie um novo flow no ActivePieces e nomeie-o
       <Frame>
         <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-flow.png" alt="Flow ActivePieces" />
       </Frame>

    2. Adicione uma etapa de webhook como gatilho:
       * Selecione `Catch Webhook` como tipo de gatilho

       * Isso irá gerar uma URL única que receberá requisições HTTP e disparará seu flow
         <Frame>
           <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-webhook.png" alt="Webhook ActivePieces" />
         </Frame>

       * Configure o e-mail para usar o corpo de texto do webhook do crew
         <Frame>
           <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-email.png" alt="Email ActivePieces" />
         </Frame>
  </Step>
</Steps>

## Exemplos de Output do Webhook

<Tabs>
  <Tab title="Step Webhook">
    `stepWebhookUrl` - Callback executado a cada pensamento interno do agente

    ```json
    {
        "action": "**Preliminary Research Report on the Financial Industry for crewai Enterprise Solution**\n1. Industry Overview and Trends\nThe financial industry in ....\nConclusion:\nThe financial industry presents a fertile ground for implementing AI solutions like crewai, particularly in areas such as digital customer engagement, risk management, and regulatory compliance. Further engagement with the lead is recommended to better tailor the crewai solution to their specific needs and scale.",
        "task_id": "97eba64f-958c-40a0-b61c-625fe635a3c0"
    }
    ```
  </Tab>

  <Tab title="Task Webhook">
    `taskWebhookUrl` - Callback executado ao final de cada task

    ```json
    {
        "description": "Using the information gathered from the lead's data, conduct preliminary research on the lead's industry, company background, and potential use cases for crewai. Focus on finding relevant data that can aid in scoring the lead and planning a strategy to pitch them crewai.The financial industry presents a fertile ground for implementing AI solutions like crewai, particularly in areas such as digital customer engagement, risk management, and regulatory compliance. Further engagement with the lead is recommended to better tailor the crewai solution to their specific needs and scale.",
        "task_id": "97eba64f-958c-40a0-b61c-625fe635a3c0"
    }
    ```
  </Tab>

  <Tab title="Crew Webhook">
    `crewWebhookUrl` - Callback executado ao final da execução do crew

    ```json
    {
        "task_id": "97eba64f-958c-40a0-b61c-625fe635a3c0",
        "result": {
            "lead_score": "Customer service enhancement, and compliance are particularly relevant.",
            "talking_points": [
                "Highlight how crewai's AI solutions can transform customer service with automated, personalized experiences and 24/7 support, improving both customer satisfaction and operational efficiency.",
                "Discuss crewai's potential to help the institution achieve its sustainability goals through better data analysis and decision-making, contributing to responsible investing and green initiatives.",
                "Emphasize crewai's ability to enhance compliance with evolving regulations through efficient data processing and reporting, reducing the risk of non-compliance penalties.",
                "Stress the adaptability of crewai to support both extensive multinational operations and smaller, targeted projects, ensuring the solution grows with the institution's needs."
            ]
        }
    }
    ```
  </Tab>
</Tabs>


# Trigger Zapier
Source: https://docs.crewai.com/pt-BR/enterprise/guides/zapier-trigger

Dispare crews do CrewAI a partir de fluxos de trabalho no Zapier para automatizar fluxos multiaplicativos

Este guia irá conduzi-lo pelo processo de configuração de triggers no Zapier para o CrewAI Enterprise, permitindo automatizar fluxos de trabalho entre CrewAI Enterprise e outros aplicativos.

## Pré-requisitos

* Uma conta CrewAI Enterprise
* Uma conta Zapier
* Uma conta Slack (para este exemplo específico)

## Configuração Passo a Passo

<Steps>
  <Step title="Configure o Trigger do Slack">
    * No Zapier, crie um novo Zap.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-1.png" alt="Zapier 1" />
    </Frame>
  </Step>

  <Step title="Escolha o Slack como seu app de trigger">
    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-2.png" alt="Zapier 2" />
    </Frame>

    * Selecione `New Pushed Message` como o Evento de Trigger.
    * Conecte sua conta Slack, caso ainda não tenha feito isso.
  </Step>

  <Step title="Configure a ação do CrewAI Enterprise">
    * Adicione uma nova etapa de ação ao seu Zap.
    * Escolha CrewAI+ como o app de ação e Kickoff como Evento de Ação.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-3.png" alt="Zapier 5" />
    </Frame>
  </Step>

  <Step title="Conecte sua conta CrewAI Enterprise">
    * Conecte sua conta CrewAI Enterprise.
    * Selecione o Crew apropriado para seu fluxo de trabalho.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-4.png" alt="Zapier 6" />
    </Frame>

    * Configure as entradas para o Crew usando os dados da mensagem do Slack.
  </Step>

  <Step title="Formate a saída do CrewAI Enterprise">
    * Adicione outra etapa de ação para formatar a saída de texto do CrewAI Enterprise.
    * Utilize as ferramentas de formatação do Zapier para converter a saída em Markdown para HTML.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-5.png" alt="Zapier 8" />
    </Frame>

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-6.png" alt="Zapier 9" />
    </Frame>
  </Step>

  <Step title="Envie a saída por e-mail">
    * Adicione uma etapa final de ação para enviar a saída formatada por e-mail.
    * Escolha seu serviço de e-mail preferido (ex.: Gmail, Outlook).
    * Configure os detalhes do e-mail, incluindo destinatário, assunto e corpo.
    * Insira a saída formatada do CrewAI Enterprise no corpo do e-mail.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-7.png" alt="Zapier 7" />
    </Frame>
  </Step>

  <Step title="Dispare o crew a partir do Slack">
    * Digite o texto no seu canal do Slack

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-7b.png" alt="Zapier 10" />
    </Frame>

    * Selecione o botão de três pontos e então escolha Push to Zapier

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-8.png" alt="Zapier 11" />
    </Frame>
  </Step>

  <Step title="Selecione o crew e então pressione Push to Kick Off">
    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-9.png" alt="Zapier 12" />
    </Frame>
  </Step>
</Steps>

## Dicas para o Sucesso

* Certifique-se de que as entradas do CrewAI Enterprise estejam corretamente mapeadas a partir da mensagem do Slack.
* Teste seu Zap cuidadosamente antes de ativá-lo para identificar possíveis problemas.
* Considere adicionar etapas de tratamento de erros para gerenciar possíveis falhas no fluxo.

Seguindo estes passos, você terá configurado com sucesso triggers no Zapier para o CrewAI Enterprise, permitindo fluxos de trabalho automatizados disparados por mensagens no Slack e resultando em notificações por e-mail com a saída do CrewAI Enterprise.


# Integração com Asana
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/asana

Coordenação de tarefas e projetos em equipe com a integração Asana para CrewAI.

## Visão Geral

Permita que seus agentes gerenciem tarefas, projetos e a coordenação da equipe através do Asana. Crie tarefas, atualize o status de projetos, gerencie atribuições e otimize o fluxo de trabalho da sua equipe com automação baseada em IA.

## Pré-requisitos

Antes de usar a integração com o Asana, assegure-se de ter:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Uma conta Asana com as permissões apropriadas
* Sua conta Asana conectada através da [página de Integrações](https://app.crewai.com/crewai_plus/connectors)

## Configurando a Integração Asana

### 1. Conecte sua Conta Asana

1. Acesse [CrewAI Enterprise Integrações](https://app.crewai.com/crewai_plus/connectors)
2. Encontre **Asana** na seção Integrações de Autenticação
3. Clique em **Conectar** e complete o fluxo OAuth
4. Conceda as permissões necessárias para gerenciamento de tarefas e projetos
5. Copie seu Token Enterprise em [Configurações da Conta](https://app.crewai.com/crewai_plus/settings/account)

### 2. Instale o Pacote Necessário

```bash
uv add crewai-tools
```

## Ações Disponíveis

<AccordionGroup>
  <Accordion title="ASANA_CREATE_COMMENT">
    **Descrição:** Cria um comentário no Asana.

    **Parâmetros:**

    * `task` (string, obrigatório): ID da Tarefa - O ID da tarefa à qual o comentário será adicionado. O comentário será escrito pelo usuário atualmente autenticado.
    * `text` (string, obrigatório): Texto (exemplo: "Este é um comentário.").
  </Accordion>

  <Accordion title="ASANA_CREATE_PROJECT">
    **Descrição:** Cria um projeto no Asana.

    **Parâmetros:**

    * `name` (string, obrigatório): Nome (exemplo: "Itens para comprar").
    * `workspace` (string, obrigatório): Área de trabalho - Use as Configurações de Fluxo do Portal Connect para permitir que usuários escolham em qual área de trabalho criar projetos. Por padrão, será usada a primeira área de trabalho do usuário se deixado em branco.
    * `team` (string, opcional): Equipe - Use as Configurações de Fluxo do Portal Connect para permitir que usuários escolham com qual equipe compartilhar o projeto. Por padrão, será usada a primeira equipe do usuário se deixado em branco.
    * `notes` (string, opcional): Notas (exemplo: "Esses são itens que precisamos comprar.").
  </Accordion>

  <Accordion title="ASANA_GET_PROJECTS">
    **Descrição:** Obtém uma lista de projetos do Asana.

    **Parâmetros:**

    * `archived` (string, opcional): Arquivado - Escolha "true" para mostrar projetos arquivados, "false" para exibir apenas projetos ativos ou "default" para mostrar ambos.
      * Opções: `default`, `true`, `false`
  </Accordion>

  <Accordion title="ASANA_GET_PROJECT_BY_ID">
    **Descrição:** Obtém um projeto pelo ID no Asana.

    **Parâmetros:**

    * `projectFilterId` (string, obrigatório): ID do Projeto.
  </Accordion>

  <Accordion title="ASANA_CREATE_TASK">
    **Descrição:** Cria uma tarefa no Asana.

    **Parâmetros:**

    * `name` (string, obrigatório): Nome (exemplo: "Nome da tarefa").
    * `workspace` (string, opcional): Área de trabalho - Use as Configurações de Fluxo do Portal Connect para permitir que usuários escolham em qual área de trabalho criar tarefas. Por padrão, será usada a primeira área de trabalho do usuário se deixado em branco.
    * `project` (string, opcional): Projeto - Use as Configurações de Fluxo do Portal Connect para permitir que usuários escolham em qual projeto criar a tarefa.
    * `notes` (string, opcional): Notas.
    * `dueOnDate` (string, opcional): Data de Vencimento - A data em que esta tarefa deve ser concluída. Não pode ser usada em conjunto com Due At. (exemplo: "YYYY-MM-DD").
    * `dueAtDate` (string, opcional): Vence Em - A data e hora (timestamp ISO) em que esta tarefa deve ser concluída. Não pode ser usada em conjunto com Due On. (exemplo: "2019-09-15T02:06:58.147Z").
    * `assignee` (string, opcional): Responsável - O ID do usuário Asana a quem esta tarefa será atribuída. Use as Configurações de Fluxo do Portal Connect para permitir que usuários selecionem um responsável.
    * `gid` (string, opcional): ID Externo - Um ID da sua aplicação para associar esta tarefa. Você pode usar este ID para sincronizar atualizações com esta tarefa posteriormente.
  </Accordion>

  <Accordion title="ASANA_UPDATE_TASK">
    **Descrição:** Atualiza uma tarefa no Asana.

    **Parâmetros:**

    * `taskId` (string, obrigatório): ID da Tarefa - O ID da tarefa a ser atualizada.
    * `completeStatus` (string, opcional): Status de Conclusão.
      * Opções: `true`, `false`
    * `name` (string, opcional): Nome (exemplo: "Nome da Tarefa").
    * `notes` (string, opcional): Notas.
    * `dueOnDate` (string, opcional): Data de Vencimento - A data em que esta tarefa deve ser concluída. Não pode ser usada junto com Due At. (exemplo: "YYYY-MM-DD").
    * `dueAtDate` (string, opcional): Vence Em - A data e hora (timestamp ISO) em que esta tarefa deve ser concluída. Não pode ser usada junto com Due On. (exemplo: "2019-09-15T02:06:58.147Z").
    * `assignee` (string, opcional): Responsável - O ID do usuário Asana a quem esta tarefa será atribuída. Use as Configurações de Fluxo do Portal Connect para permitir que usuários selecionem o responsável.
    * `gid` (string, opcional): ID Externo - Um ID da sua aplicação para associar a tarefa. Você pode usar este ID para sincronizar atualizações posteriormente.
  </Accordion>

  <Accordion title="ASANA_GET_TASKS">
    **Descrição:** Obtém uma lista de tarefas no Asana.

    **Parâmetros:**

    * `workspace` (string, opcional): Área de trabalho - O ID da área de trabalho para filtrar tarefas. Use as Configurações de Fluxo do Portal Connect para permitir que usuários selecionem uma área de trabalho.
    * `project` (string, opcional): Projeto - O ID do projeto para filtrar as tarefas. Use as Configurações de Fluxo do Portal Connect para permitir que usuários selecionem um projeto.
    * `assignee` (string, opcional): Responsável - O ID do responsável para filtrar tarefas. Use as Configurações de Fluxo do Portal Connect para permitir que usuários selecionem um responsável.
    * `completedSince` (string, opcional): Concluída desde - Retorna apenas tarefas que estejam incompletas ou que tenham sido concluídas desde este horário (timestamp ISO ou Unix). (exemplo: "2014-04-25T16:15:47-04:00").
  </Accordion>

  <Accordion title="ASANA_GET_TASKS_BY_ID">
    **Descrição:** Obtém uma lista de tarefas pelo ID no Asana.

    **Parâmetros:**

    * `taskId` (string, obrigatório): ID da Tarefa.
  </Accordion>

  <Accordion title="ASANA_GET_TASK_BY_EXTERNAL_ID">
    **Descrição:** Obtém uma tarefa pelo ID externo no Asana.

    **Parâmetros:**

    * `gid` (string, obrigatório): ID Externo - O ID que esta tarefa está associada ou sincronizada, de sua aplicação.
  </Accordion>

  <Accordion title="ASANA_ADD_TASK_TO_SECTION">
    **Descrição:** Adiciona uma tarefa a uma seção no Asana.

    **Parâmetros:**

    * `sectionId` (string, obrigatório): ID da Seção - O ID da seção à qual a tarefa será adicionada.
    * `taskId` (string, obrigatório): ID da Tarefa - O ID da tarefa. (exemplo: "1204619611402340").
    * `beforeTaskId` (string, opcional): Antes da Tarefa - O ID de uma tarefa nesta seção antes da qual esta tarefa será inserida. Não pode ser usada junto com After Task ID. (exemplo: "1204619611402340").
    * `afterTaskId` (string, opcional): Após a Tarefa - O ID de uma tarefa nesta seção após a qual esta tarefa será inserida. Não pode ser usada junto com Before Task ID. (exemplo: "1204619611402340").
  </Accordion>

  <Accordion title="ASANA_GET_TEAMS">
    **Descrição:** Obtém uma lista de equipes no Asana.

    **Parâmetros:**

    * `workspace` (string, obrigatório): Área de trabalho - Retorna as equipes nesta área de trabalho visíveis para o usuário autorizado.
  </Accordion>

  <Accordion title="ASANA_GET_WORKSPACES">
    **Descrição:** Obtém uma lista de áreas de trabalho do Asana.

    **Parâmetros:** Nenhum obrigatório.
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configuração Básica do Agente Asana

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Asana tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Asana capabilities
asana_agent = Agent(
    role="Project Manager",
    goal="Manage tasks and projects in Asana efficiently",
    backstory="An AI assistant specialized in project management and task coordination.",
    tools=[enterprise_tools]
)

# Task to create a new project
create_project_task = Task(
    description="Create a new project called 'Q1 Marketing Campaign' in the Marketing workspace",
    agent=asana_agent,
    expected_output="Confirmation that the project was created successfully with project ID"
)

# Run the task
crew = Crew(
    agents=[asana_agent],
    tasks=[create_project_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Específicas do Asana

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Asana tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["asana_create_task", "asana_update_task", "asana_get_tasks"]
)

task_manager_agent = Agent(
    role="Task Manager",
    goal="Create and manage tasks efficiently",
    backstory="An AI assistant that focuses on task creation and management.",
    tools=enterprise_tools
)

# Task to create and assign a task
task_management = Task(
    description="Create a task called 'Review quarterly reports' and assign it to the appropriate team member",
    agent=task_manager_agent,
    expected_output="Task created and assigned successfully"
)

crew = Crew(
    agents=[task_manager_agent],
    tasks=[task_management]
)

crew.kickoff()
```

### Gerenciamento Avançado de Projetos

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

project_coordinator = Agent(
    role="Project Coordinator",
    goal="Coordinate project activities and track progress",
    backstory="An experienced project coordinator who ensures projects run smoothly.",
    tools=[enterprise_tools]
)

# Complex task involving multiple Asana operations
coordination_task = Task(
    description="""
    1. Get all active projects in the workspace
    2. For each project, get the list of incomplete tasks
    3. Create a summary report task in the 'Management Reports' project
    4. Add comments to overdue tasks to request status updates
    """,
    agent=project_coordinator,
    expected_output="Summary report created and status update requests sent for overdue tasks"
)

crew = Crew(
    agents=[project_coordinator],
    tasks=[coordination_task]
)

crew.kickoff()
```


# Integração com Box
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/box

Armazenamento de arquivos e gerenciamento de documentos com a integração do Box para CrewAI.

## Visão Geral

Permita que seus agentes gerenciem arquivos, pastas e documentos através do Box. Faça upload de arquivos, organize estruturas de pastas, pesquise conteúdos e otimize o gerenciamento de documentos da sua equipe com automação alimentada por IA.

## Pré-requisitos

Antes de utilizar a integração com o Box, assegure-se de que você possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Uma conta Box com as permissões apropriadas
* Sua conta Box conectada através da [página de Integrações](https://app.crewai.com/crewai_plus/connectors)

## Configurando a Integração com o Box

### 1. Conecte sua conta Box

1. Acesse [Integrações do CrewAI Enterprise](https://app.crewai.com/crewai_plus/connectors)
2. Encontre **Box** na seção de Integrações de Autenticação
3. Clique em **Conectar** e conclua o fluxo de OAuth
4. Conceda as permissões necessárias para gerenciamento de arquivos e pastas
5. Copie seu Token Enterprise em [Configurações da Conta](https://app.crewai.com/crewai_plus/settings/account)

### 2. Instale o pacote necessário

```bash
uv add crewai-tools
```

## Ações Disponíveis

<AccordionGroup>
  <Accordion title="BOX_SAVE_FILE">
    **Descrição:** Salva um arquivo a partir de uma URL no Box.

    **Parâmetros:**

    * `fileAttributes` (object, obrigatório): Atributos - Metadados do arquivo incluindo nome, pasta pai e datas.
      ```json
      {
        "content_created_at": "2012-12-12T10:53:43-08:00",
        "content_modified_at": "2012-12-12T10:53:43-08:00",
        "name": "qwerty.png",
        "parent": { "id": "1234567" }
      }
      ```
    * `file` (string, obrigatório): URL do arquivo - Os arquivos devem ter menos de 50MB. (exemplo: "[https://picsum.photos/200/300](https://picsum.photos/200/300)").
  </Accordion>

  <Accordion title="BOX_SAVE_FILE_FROM_OBJECT">
    **Descrição:** Salva um arquivo no Box.

    **Parâmetros:**

    * `file` (string, obrigatório): Arquivo - Aceita um Objeto de Arquivo contendo os dados. O arquivo deve ter menos de 50MB.
    * `fileName` (string, obrigatório): Nome do Arquivo (exemplo: "qwerty.png").
    * `folder` (string, opcional): Pasta - Use as configurações de workflow do Connect Portal para permitir que usuários escolham o destino da pasta. Caso em branco, o padrão é a pasta raiz do usuário.
  </Accordion>

  <Accordion title="BOX_GET_FILE_BY_ID">
    **Descrição:** Obtém um arquivo pelo ID no Box.

    **Parâmetros:**

    * `fileId` (string, obrigatório): ID do arquivo - Identificador único que representa um arquivo. (exemplo: "12345").
  </Accordion>

  <Accordion title="BOX_LIST_FILES">
    **Descrição:** Lista arquivos no Box.

    **Parâmetros:**

    * `folderId` (string, obrigatório): ID da pasta - Identificador único que representa uma pasta. (exemplo: "0").
    * `filterFormula` (object, opcional): Um filtro em forma normal disjuntiva - OU de grupos E de condições únicas.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "direction",
                "operator": "$stringExactlyMatches",
                "value": "ASC"
              }
            ]
          }
        ]
      }
      ```
  </Accordion>

  <Accordion title="BOX_CREATE_FOLDER">
    **Descrição:** Cria uma pasta no Box.

    **Parâmetros:**

    * `folderName` (string, obrigatório): Nome - Nome para a nova pasta. (exemplo: "Nova Pasta").
    * `folderParent` (object, obrigatório): Pasta Pai - A pasta onde a nova pasta será criada.
      ```json
      {
        "id": "123456"
      }
      ```
  </Accordion>

  <Accordion title="BOX_MOVE_FOLDER">
    **Descrição:** Move uma pasta no Box.

    **Parâmetros:**

    * `folderId` (string, obrigatório): ID da pasta - Identificador único que representa uma pasta. (exemplo: "0").
    * `folderName` (string, obrigatório): Nome - Nome da pasta. (exemplo: "Nova Pasta").
    * `folderParent` (object, obrigatório): Nova pasta pai de destino.
      ```json
      {
        "id": "123456"
      }
      ```
  </Accordion>

  <Accordion title="BOX_GET_FOLDER_BY_ID">
    **Descrição:** Obtém uma pasta pelo ID no Box.

    **Parâmetros:**

    * `folderId` (string, obrigatório): ID da pasta - Identificador único que representa uma pasta. (exemplo: "0").
  </Accordion>

  <Accordion title="BOX_SEARCH_FOLDERS">
    **Descrição:** Pesquisa pastas no Box.

    **Parâmetros:**

    * `folderId` (string, obrigatório): ID da pasta - A pasta na qual pesquisar.
    * `filterFormula` (object, opcional): Um filtro em forma normal disjuntiva - OU de grupos E de condições únicas.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "sort",
                "operator": "$stringExactlyMatches",
                "value": "name"
              }
            ]
          }
        ]
      }
      ```
  </Accordion>

  <Accordion title="BOX_DELETE_FOLDER">
    **Descrição:** Exclui uma pasta no Box.

    **Parâmetros:**

    * `folderId` (string, obrigatório): ID da pasta - Identificador único que representa uma pasta. (exemplo: "0").
    * `recursive` (boolean, opcional): Recursivo - Exclui uma pasta que não está vazia, deletando de forma recursiva a pasta e todo o seu conteúdo.
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configuração Básica de Agente Box

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Box tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Box capabilities
box_agent = Agent(
    role="Document Manager",
    goal="Manage files and folders in Box efficiently",
    backstory="An AI assistant specialized in document management and file organization.",
    tools=[enterprise_tools]
)

# Task to create a folder structure
create_structure_task = Task(
    description="Create a folder called 'Project Files' in the root directory and upload a document from URL",
    agent=box_agent,
    expected_output="Folder created and file uploaded successfully"
)

# Run the task
crew = Crew(
    agents=[box_agent],
    tasks=[create_structure_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Específicas do Box

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Box tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["box_create_folder", "box_save_file", "box_list_files"]
)

file_organizer_agent = Agent(
    role="File Organizer",
    goal="Organize and manage file storage efficiently",
    backstory="An AI assistant that focuses on file organization and storage management.",
    tools=enterprise_tools
)

# Task to organize files
organization_task = Task(
    description="Create a folder structure for the marketing team and organize existing files",
    agent=file_organizer_agent,
    expected_output="Folder structure created and files organized"
)

crew = Crew(
    agents=[file_organizer_agent],
    tasks=[organization_task]
)

crew.kickoff()
```

### Gerenciamento Avançado de Arquivos

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

file_manager = Agent(
    role="File Manager",
    goal="Maintain organized file structure and manage document lifecycle",
    backstory="An experienced file manager who ensures documents are properly organized and accessible.",
    tools=[enterprise_tools]
)

# Complex task involving multiple Box operations
management_task = Task(
    description="""
    1. List all files in the root folder
    2. Create monthly archive folders for the current year
    3. Move old files to appropriate archive folders
    4. Generate a summary report of the file organization
    """,
    agent=file_manager,
    expected_output="Files organized into archive structure with summary report"
)

crew = Crew(
    agents=[file_manager],
    tasks=[management_task]
)

crew.kickoff()
```


# Integração com ClickUp
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/clickup

Gerenciamento de tarefas e produtividade com integração ClickUp para CrewAI.

## Visão Geral

Permita que seus agentes gerenciem tarefas, projetos e fluxos de produtividade por meio do ClickUp. Crie e atualize tarefas, organize projetos, gerencie a designação de equipes e otimize o gerenciamento da sua produtividade com automação impulsionada por IA.

## Pré-requisitos

Antes de utilizar a integração com o ClickUp, certifique-se de que você possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Uma conta ClickUp com as permissões apropriadas
* Sua conta ClickUp conectada pela [Página de Integrações](https://app.crewai.com/crewai_plus/connectors)

## Configurando a Integração com o ClickUp

### 1. Conecte sua Conta ClickUp

1. Acesse [CrewAI Enterprise Integrações](https://app.crewai.com/crewai_plus/connectors)
2. Encontre **ClickUp** na seção Integrações de Autenticação
3. Clique em **Conectar** e complete o fluxo OAuth
4. Conceda as permissões necessárias para gerenciamento de tarefas e projetos
5. Copie seu Token Enterprise das [Configurações da Conta](https://app.crewai.com/crewai_plus/settings/account)

### 2. Instale o Pacote Necessário

```bash
uv add crewai-tools
```

## Ações Disponíveis

<AccordionGroup>
  <Accordion title="CLICKUP_SEARCH_TASKS">
    **Descrição:** Busque tarefas no ClickUp utilizando filtros avançados.

    **Parâmetros:**

    * `taskFilterFormula` (objeto, opcional): Um filtro em forma normal disjuntiva - OU de grupos E de condições individuais.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "statuses%5B%5D",
                "operator": "$stringExactlyMatches",
                "value": "open"
              }
            ]
          }
        ]
      }
      ```
      Campos disponíveis: `space_ids%5B%5D`, `project_ids%5B%5D`, `list_ids%5B%5D`, `statuses%5B%5D`, `include_closed`, `assignees%5B%5D`, `tags%5B%5D`, `due_date_gt`, `due_date_lt`, `date_created_gt`, `date_created_lt`, `date_updated_gt`, `date_updated_lt`
  </Accordion>

  <Accordion title="CLICKUP_GET_TASK_IN_LIST">
    **Descrição:** Obtenha tarefas em uma lista específica do ClickUp.

    **Parâmetros:**

    * `listId` (string, obrigatório): Lista - Selecione uma Lista da qual obter as tarefas. Use as Configurações do Usuário no Portal de Conexão para permitir que os usuários selecionem uma Lista ClickUp.
    * `taskFilterFormula` (string, opcional): Busque tarefas que correspondam aos filtros especificados. Por exemplo: name=task1.
  </Accordion>

  <Accordion title="CLICKUP_CREATE_TASK">
    **Descrição:** Crie uma tarefa no ClickUp.

    **Parâmetros:**

    * `listId` (string, obrigatório): Lista - Selecione uma Lista para criar esta tarefa. Use as Configurações do Usuário no Portal de Conexão para permitir que os usuários selecionem uma Lista ClickUp.
    * `name` (string, obrigatório): Nome - O nome da tarefa.
    * `description` (string, opcional): Descrição - Descrição da tarefa.
    * `status` (string, opcional): Status - Selecione um Status para esta tarefa. Use as Configurações do Usuário no Portal de Conexão para permitir que os usuários selecionem um Status ClickUp.
    * `assignees` (string, opcional): Responsáveis - Selecione um Membro (ou um array de IDs de membros) para ser responsável por esta tarefa. Use as Configurações do Usuário no Portal de Conexão para permitir que os usuários selecionem um Membro ClickUp.
    * `dueDate` (string, opcional): Data de Vencimento - Especifique uma data para a conclusão desta tarefa.
    * `additionalFields` (string, opcional): Campos Adicionais - Especifique campos adicionais para incluir nesta tarefa em formato JSON.
  </Accordion>

  <Accordion title="CLICKUP_UPDATE_TASK">
    **Descrição:** Atualize uma tarefa no ClickUp.

    **Parâmetros:**

    * `taskId` (string, obrigatório): ID da tarefa - O ID da tarefa a ser atualizada.
    * `listId` (string, obrigatório): Lista - Selecione uma Lista para criar esta tarefa. Use as Configurações do Usuário no Portal de Conexão para permitir que os usuários selecionem uma Lista ClickUp.
    * `name` (string, opcional): Nome - O nome da tarefa.
    * `description` (string, opcional): Descrição - Descrição da tarefa.
    * `status` (string, opcional): Status - Selecione um Status para esta tarefa. Use as Configurações do Usuário no Portal de Conexão para permitir que os usuários selecionem um Status ClickUp.
    * `assignees` (string, opcional): Responsáveis - Selecione um Membro (ou um array de IDs de membros) para ser responsável por esta tarefa. Use as Configurações do Usuário no Portal de Conexão para permitir que os usuários selecionem um Membro ClickUp.
    * `dueDate` (string, opcional): Data de Vencimento - Especifique uma data para a conclusão desta tarefa.
    * `additionalFields` (string, opcional): Campos Adicionais - Especifique campos adicionais para incluir nesta tarefa em formato JSON.
  </Accordion>

  <Accordion title="CLICKUP_DELETE_TASK">
    **Descrição:** Exclua uma tarefa no ClickUp.

    **Parâmetros:**

    * `taskId` (string, obrigatório): ID da tarefa - O ID da tarefa a ser excluída.
  </Accordion>

  <Accordion title="CLICKUP_GET_LIST">
    **Descrição:** Obtenha informações da Lista no ClickUp.

    **Parâmetros:**

    * `spaceId` (string, obrigatório): ID do Espaço - O ID do espaço que contém as listas.
  </Accordion>

  <Accordion title="CLICKUP_GET_CUSTOM_FIELDS_IN_LIST">
    **Descrição:** Obtenha Campos Personalizados em uma Lista no ClickUp.

    **Parâmetros:**

    * `listId` (string, obrigatório): ID da Lista - O ID da lista da qual obter os campos personalizados.
  </Accordion>

  <Accordion title="CLICKUP_GET_ALL_FIELDS_IN_LIST">
    **Descrição:** Obtenha Todos os Campos em uma Lista no ClickUp.

    **Parâmetros:**

    * `listId` (string, obrigatório): ID da Lista - O ID da lista da qual obter todos os campos.
  </Accordion>

  <Accordion title="CLICKUP_GET_SPACE">
    **Descrição:** Obtenha informações do Espaço no ClickUp.

    **Parâmetros:**

    * `spaceId` (string, opcional): ID do Espaço - O ID do espaço a ser recuperado.
  </Accordion>

  <Accordion title="CLICKUP_GET_FOLDERS">
    **Descrição:** Obtenha Pastas no ClickUp.

    **Parâmetros:**

    * `spaceId` (string, obrigatório): ID do Espaço - O ID do espaço que contém as pastas.
  </Accordion>

  <Accordion title="CLICKUP_GET_MEMBER">
    **Descrição:** Obtenha informações de Membro no ClickUp.

    **Parâmetros:** Nenhum obrigatório.
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configuração Básica do Agente ClickUp

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (ClickUp tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with ClickUp capabilities
clickup_agent = Agent(
    role="Task Manager",
    goal="Manage tasks and projects in ClickUp efficiently",
    backstory="An AI assistant specialized in task management and productivity coordination.",
    tools=[enterprise_tools]
)

# Task to create a new task
create_task = Task(
    description="Create a task called 'Review Q1 Reports' in the Marketing list with high priority",
    agent=clickup_agent,
    expected_output="Task created successfully with task ID"
)

# Run the task
crew = Crew(
    agents=[clickup_agent],
    tasks=[create_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Específicas do ClickUp

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific ClickUp tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["clickup_create_task", "clickup_update_task", "clickup_search_tasks"]
)

task_coordinator = Agent(
    role="Task Coordinator",
    goal="Create and manage tasks efficiently",
    backstory="An AI assistant that focuses on task creation and status management.",
    tools=enterprise_tools
)

# Task to manage task workflow
task_workflow = Task(
    description="Create a task for project planning and assign it to the development team",
    agent=task_coordinator,
    expected_output="Task created and assigned successfully"
)

crew = Crew(
    agents=[task_coordinator],
    tasks=[task_workflow]
)

crew.kickoff()
```

### Gerenciamento Avançado de Projetos

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

project_manager = Agent(
    role="Project Manager",
    goal="Coordinate project activities and track team productivity",
    backstory="An experienced project manager who ensures projects are delivered on time.",
    tools=[enterprise_tools]
)

# Complex task involving multiple ClickUp operations
project_coordination = Task(
    description="""
    1. Get all open tasks in the current space
    2. Identify overdue tasks and update their status
    3. Create a weekly report task summarizing project progress
    4. Assign the report task to the team lead
    """,
    agent=project_manager,
    expected_output="Project status updated and weekly report task created and assigned"
)

crew = Crew(
    agents=[project_manager],
    tasks=[project_coordination]
)

crew.kickoff()
```

### Busca e Gerenciamento de Tarefas

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

task_analyst = Agent(
    role="Task Analyst",
    goal="Analyze task patterns and optimize team productivity",
    backstory="An AI assistant that analyzes task data to improve team efficiency.",
    tools=[enterprise_tools]
)

# Task to analyze and optimize task distribution
task_analysis = Task(
    description="""
    Search for all tasks assigned to team members in the last 30 days,
    analyze completion patterns, and create optimization recommendations
    """,
    agent=task_analyst,
    expected_output="Task analysis report with optimization recommendations"
)

crew = Crew(
    agents=[task_analyst],
    tasks=[task_analysis]
)

crew.kickoff()
```

### Precisa de Ajuda?

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para auxílio na configuração ou solução de problemas da integração com ClickUp.
</Card>


# Integração com GitHub
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/github

Gerenciamento de repositórios e issues com a integração do GitHub para CrewAI.

## Visão Geral

Permita que seus agentes gerenciem repositórios, issues e releases através do GitHub. Crie e atualize issues, gerencie releases, acompanhe o desenvolvimento do projeto e otimize seu fluxo de trabalho de desenvolvimento de software com automação alimentada por IA.

## Pré-requisitos

Antes de usar a integração do GitHub, assegure-se de ter:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Uma conta GitHub com permissões adequadas no repositório
* Conta do GitHub conectada através da [página de Integrações](https://app.crewai.com/crewai_plus/connectors)

## Configurando a Integração com GitHub

### 1. Conecte sua conta GitHub

1. Acesse [Integrações CrewAI Enterprise](https://app.crewai.com/crewai_plus/connectors)
2. Encontre **GitHub** na seção de Integrações de Autenticação
3. Clique em **Conectar** e complete o fluxo OAuth
4. Conceda as permissões necessárias para gerenciamento de repositório e issues
5. Copie seu Token Enterprise nas [Configurações de Conta](https://app.crewai.com/crewai_plus/settings/account)

### 2. Instale o pacote necessário

```bash
uv add crewai-tools
```

## Ações Disponíveis

<AccordionGroup>
  <Accordion title="GITHUB_CREATE_ISSUE">
    **Descrição:** Cria uma issue no GitHub.

    **Parâmetros:**

    * `owner` (string, obrigatório): Proprietário - Especifique o nome do proprietário da conta do repositório associado a esta Issue. (exemplo: "abc").
    * `repo` (string, obrigatório): Repositório - Especifique o nome do repositório associado a esta Issue.
    * `title` (string, obrigatório): Título da Issue - Especifique o título da issue a ser criada.
    * `body` (string, opcional): Corpo da Issue - Especifique o conteúdo do corpo da issue a ser criada.
    * `assignees` (string, opcional): Responsáveis - Especifique o login dos responsáveis no GitHub como um array de strings para esta issue. (exemplo: `["octocat"]`).
  </Accordion>

  <Accordion title="GITHUB_UPDATE_ISSUE">
    **Descrição:** Atualiza uma issue no GitHub.

    **Parâmetros:**

    * `owner` (string, obrigatório): Proprietário - Especifique o nome do proprietário da conta do repositório associado a esta Issue. (exemplo: "abc").
    * `repo` (string, obrigatório): Repositório - Especifique o nome do repositório associado a esta Issue.
    * `issue_number` (string, obrigatório): Número da Issue - Especifique o número da issue a ser atualizada.
    * `title` (string, obrigatório): Título da Issue - Especifique o título da issue a ser atualizada.
    * `body` (string, opcional): Corpo da Issue - Especifique o conteúdo do corpo da issue a ser atualizada.
    * `assignees` (string, opcional): Responsáveis - Especifique o login dos responsáveis no GitHub como um array de strings para esta issue. (exemplo: `["octocat"]`).
    * `state` (string, opcional): Estado - Especifique o estado atualizado da issue.
      * Opções: `open`, `closed`
  </Accordion>

  <Accordion title="GITHUB_GET_ISSUE_BY_NUMBER">
    **Descrição:** Obtém uma issue pelo número no GitHub.

    **Parâmetros:**

    * `owner` (string, obrigatório): Proprietário - Especifique o nome do proprietário da conta do repositório associado a esta Issue. (exemplo: "abc").
    * `repo` (string, obrigatório): Repositório - Especifique o nome do repositório associado a esta Issue.
    * `issue_number` (string, obrigatório): Número da Issue - Especifique o número da issue a ser buscada.
  </Accordion>

  <Accordion title="GITHUB_LOCK_ISSUE">
    **Descrição:** Bloqueia uma issue no GitHub.

    **Parâmetros:**

    * `owner` (string, obrigatório): Proprietário - Especifique o nome do proprietário da conta do repositório associado a esta Issue. (exemplo: "abc").
    * `repo` (string, obrigatório): Repositório - Especifique o nome do repositório associado a esta Issue.
    * `issue_number` (string, obrigatório): Número da Issue - Especifique o número da issue a ser bloqueada.
    * `lock_reason` (string, obrigatório): Motivo do Bloqueio - Especifique um motivo para bloquear a discussão da issue ou pull request.
      * Opções: `off-topic`, `too heated`, `resolved`, `spam`
  </Accordion>

  <Accordion title="GITHUB_SEARCH_ISSUE">
    **Descrição:** Busca por issues no GitHub.

    **Parâmetros:**

    * `owner` (string, obrigatório): Proprietário - Especifique o nome do proprietário da conta do repositório associado a esta Issue. (exemplo: "abc").
    * `repo` (string, obrigatório): Repositório - Especifique o nome do repositório associado a esta Issue.
    * `filter` (object, obrigatório): Um filtro em forma normal disjuntiva - OU de grupos E de condições simples.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "assignee",
                "operator": "$stringExactlyMatches",
                "value": "octocat"
              }
            ]
          }
        ]
      }
      ```
      Campos disponíveis: `assignee`, `creator`, `mentioned`, `labels`
  </Accordion>

  <Accordion title="GITHUB_CREATE_RELEASE">
    **Descrição:** Cria um release no GitHub.

    **Parâmetros:**

    * `owner` (string, obrigatório): Proprietário - Especifique o nome do proprietário da conta do repositório associado a este Release. (exemplo: "abc").
    * `repo` (string, obrigatório): Repositório - Especifique o nome do repositório associado a este Release.
    * `tag_name` (string, obrigatório): Nome - Especifique o nome da tag do release a ser criada. (exemplo: "v1.0.0").
    * `target_commitish` (string, opcional): Destino - Especifique o destino do release. Pode ser o nome de um branch ou o SHA de um commit. Padrão é o branch principal. (exemplo: "master").
    * `body` (string, opcional): Descrição - Especifique uma descrição para este release.
    * `draft` (string, opcional): Rascunho - Especifique se o release criado deve ser um rascunho (não publicado).
      * Opções: `true`, `false`
    * `prerelease` (string, opcional): Pré-lançamento - Especifique se o release criado deve ser um pré-lançamento.
      * Opções: `true`, `false`
    * `discussion_category_name` (string, opcional): Nome da Categoria de Discussão - Se especificado, uma discussão da categoria indicada é criada e vinculada ao release. O valor deve ser uma categoria já existente no repositório.
    * `generate_release_notes` (string, opcional): Notas de Release - Especifique se o release criado deve criar automaticamente notas de release usando o nome e a descrição fornecidos.
      * Opções: `true`, `false`
  </Accordion>

  <Accordion title="GITHUB_UPDATE_RELEASE">
    **Descrição:** Atualiza um release no GitHub.

    **Parâmetros:**

    * `owner` (string, obrigatório): Proprietário - Especifique o nome do proprietário da conta do repositório associado a este Release. (exemplo: "abc").
    * `repo` (string, obrigatório): Repositório - Especifique o nome do repositório associado a este Release.
    * `id` (string, obrigatório): ID do Release - Especifique o ID do release a ser atualizado.
    * `tag_name` (string, opcional): Nome - Especifique o nome da tag do release a ser atualizado. (exemplo: "v1.0.0").
    * `target_commitish` (string, opcional): Destino - Especifique o destino do release. Pode ser o nome de um branch ou o SHA de um commit. Padrão é o branch principal. (exemplo: "master").
    * `body` (string, opcional): Descrição - Especifique uma descrição para este release.
    * `draft` (string, opcional): Rascunho - Especifique se o release criado deve ser um rascunho (não publicado).
      * Opções: `true`, `false`
    * `prerelease` (string, opcional): Pré-lançamento - Especifique se o release criado deve ser um pré-lançamento.
      * Opções: `true`, `false`
    * `discussion_category_name` (string, opcional): Nome da Categoria de Discussão - Se especificado, uma discussão da categoria indicada é criada e vinculada ao release. O valor deve ser uma categoria já existente no repositório.
    * `generate_release_notes` (string, opcional): Notas de Release - Especifique se o release criado deve criar automaticamente notas de release usando o nome e a descrição fornecidos.
      * Opções: `true`, `false`
  </Accordion>

  <Accordion title="GITHUB_GET_RELEASE_BY_ID">
    **Descrição:** Obtém um release por ID no GitHub.

    **Parâmetros:**

    * `owner` (string, obrigatório): Proprietário - Especifique o nome do proprietário da conta do repositório associado a este Release. (exemplo: "abc").
    * `repo` (string, obrigatório): Repositório - Especifique o nome do repositório associado a este Release.
    * `id` (string, obrigatório): ID do Release - Especifique o ID do release a ser recuperado.
  </Accordion>

  <Accordion title="GITHUB_GET_RELEASE_BY_TAG_NAME">
    **Descrição:** Obtém um release pelo nome da tag no GitHub.

    **Parâmetros:**

    * `owner` (string, obrigatório): Proprietário - Especifique o nome do proprietário da conta do repositório associado a este Release. (exemplo: "abc").
    * `repo` (string, obrigatório): Repositório - Especifique o nome do repositório associado a este Release.
    * `tag_name` (string, obrigatório): Nome - Especifique o nome da tag do release a ser recuperado. (exemplo: "v1.0.0").
  </Accordion>

  <Accordion title="GITHUB_DELETE_RELEASE">
    **Descrição:** Exclui um release no GitHub.

    **Parâmetros:**

    * `owner` (string, obrigatório): Proprietário - Especifique o nome do proprietário da conta do repositório associado a este Release. (exemplo: "abc").
    * `repo` (string, obrigatório): Repositório - Especifique o nome do repositório associado a este Release.
    * `id` (string, obrigatório): ID do Release - Especifique o ID do release a ser excluído.
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configuração Básica de Agente GitHub

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (GitHub tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with GitHub capabilities
github_agent = Agent(
    role="Repository Manager",
    goal="Manage GitHub repositories, issues, and releases efficiently",
    backstory="An AI assistant specialized in repository management and issue tracking.",
    tools=[enterprise_tools]
)

# Task to create a new issue
create_issue_task = Task(
    description="Create a bug report issue for the login functionality in the main repository",
    agent=github_agent,
    expected_output="Issue created successfully with issue number"
)

# Run the task
crew = Crew(
    agents=[github_agent],
    tasks=[create_issue_task]
)

crew.kickoff()
```

### Filtrando Ferramentas GitHub Específicas

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific GitHub tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["github_create_issue", "github_update_issue", "github_search_issue"]
)

issue_manager = Agent(
    role="Issue Manager",
    goal="Create and manage GitHub issues efficiently",
    backstory="An AI assistant that focuses on issue tracking and management.",
    tools=enterprise_tools
)

# Task to manage issue workflow
issue_workflow = Task(
    description="Create a feature request issue and assign it to the development team",
    agent=issue_manager,
    expected_output="Feature request issue created and assigned successfully"
)

crew = Crew(
    agents=[issue_manager],
    tasks=[issue_workflow]
)

crew.kickoff()
```

### Gerenciamento de Releases

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

release_manager = Agent(
    role="Release Manager",
    goal="Manage software releases and versioning",
    backstory="An experienced release manager who handles version control and release processes.",
    tools=[enterprise_tools]
)

# Task to create a new release
release_task = Task(
    description="""
    Create a new release v2.1.0 for the project with:
    - Auto-generated release notes
    - Target the main branch
    - Include a description of new features and bug fixes
    """,
    agent=release_manager,
    expected_output="Release v2.1.0 created successfully with release notes"
)

crew = Crew(
    agents=[release_manager],
    tasks=[release_task]
)

crew.kickoff()
```

### Acompanhamento e Gerenciamento de Issues

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

project_coordinator = Agent(
    role="Project Coordinator",
    goal="Track and coordinate project issues and development progress",
    backstory="An AI assistant that helps coordinate development work and track project progress.",
    tools=[enterprise_tools]
)

# Complex task involving multiple GitHub operations
coordination_task = Task(
    description="""
    1. Search for all open issues assigned to the current milestone
    2. Identify overdue issues and update their priority labels
    3. Create a weekly progress report issue
    4. Lock resolved issues that have been inactive for 30 days
    """,
    agent=project_coordinator,
    expected_output="Project coordination completed with progress report and issue management"
)

crew = Crew(
    agents=[project_coordinator],
    tasks=[coordination_task]
)

crew.kickoff()
```

### Obtendo Ajuda

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para auxílio na configuração ou solução de problemas com a integração do GitHub.
</Card>


# Integração com Gmail
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/gmail

Gerenciamento de e-mails e contatos com a integração do Gmail para o CrewAI.

## Visão Geral

Permita que seus agentes gerenciem e-mails, contatos e rascunhos através do Gmail. Envie e-mails, pesquise mensagens, gerencie contatos, crie rascunhos e otimize suas comunicações por e-mail com automação impulsionada por IA.

## Pré-requisitos

Antes de usar a integração com o Gmail, certifique-se de que você possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Uma conta do Gmail com as permissões adequadas
* Conectou sua conta do Gmail através da [página de Integrações](https://app.crewai.com/crewai_plus/connectors)

## Configurando a Integração com o Gmail

### 1. Conecte sua Conta do Gmail

1. Navegue até [Integrações CrewAI Enterprise](https://app.crewai.com/crewai_plus/connectors)
2. Encontre **Gmail** na seção de Integrações de Autenticação
3. Clique em **Conectar** e conclua o fluxo OAuth
4. Conceda as permissões necessárias para o gerenciamento de e-mail e contato
5. Copie seu Token Empresarial em [Configurações de Conta](https://app.crewai.com/crewai_plus/settings/account)

### 2. Instale o Pacote Necessário

```bash
uv add crewai-tools
```

## Ações Disponíveis

<AccordionGroup>
  <Accordion title="GMAIL_SEND_EMAIL">
    **Descrição:** Envia um e-mail pelo Gmail.

    **Parâmetros:**

    * `toRecipients` (array, obrigatório): Para - Especifique os destinatários como uma única string ou um array JSON.
      ```json
      [
        "recipient1@domain.com",
        "recipient2@domain.com"
      ]
      ```
    * `from` (string, obrigatório): De - Especifique o e-mail do remetente.
    * `subject` (string, obrigatório): Assunto - Especifique o assunto da mensagem.
    * `messageContent` (string, obrigatório): Conteúdo da Mensagem - Especifique o conteúdo do e-mail em texto simples ou HTML.
    * `attachments` (string, opcional): Anexos - Aceita um único objeto de arquivo ou um array JSON de objetos de arquivo.
    * `additionalHeaders` (object, opcional): Cabeçalhos Adicionais - Especifique quaisquer campos de cabeçalho adicionais aqui.
      ```json
      {
        "reply-to": "Nome do Remetente <sender@domain.com>"
      }
      ```
  </Accordion>

  <Accordion title="GMAIL_GET_EMAIL_BY_ID">
    **Descrição:** Obtém um e-mail pelo ID no Gmail.

    **Parâmetros:**

    * `userId` (string, obrigatório): ID do Usuário - Especifique o endereço de e-mail do usuário. (exemplo: "[user@domain.com](mailto:user@domain.com)").
    * `messageId` (string, obrigatório): ID da Mensagem - Especifique o ID da mensagem a ser recuperada.
  </Accordion>

  <Accordion title="GMAIL_SEARCH_FOR_EMAIL">
    **Descrição:** Pesquisa e-mails no Gmail usando filtros avançados.

    **Parâmetros:**

    * `emailFilterFormula` (object, opcional): Um filtro na forma normal disjuntiva - OU de grupos E de condições únicas.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "from",
                "operator": "$stringContains",
                "value": "example@domain.com"
              }
            ]
          }
        ]
      }
      ```
      Campos disponíveis: `from`, `to`, `date`, `label`, `subject`, `cc`, `bcc`, `category`, `deliveredto:`, `size`, `filename`, `older_than`, `newer_than`, `list`, `is:important`, `is:unread`, `is:snoozed`, `is:starred`, `is:read`, `has:drive`, `has:document`, `has:spreadsheet`, `has:presentation`, `has:attachment`, `has:youtube`, `has:userlabels`
    * `paginationParameters` (object, opcional): Parâmetros de Paginação.
      ```json
      {
        "pageCursor": "page_cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="GMAIL_DELETE_EMAIL">
    **Descrição:** Exclui um e-mail no Gmail.

    **Parâmetros:**

    * `userId` (string, obrigatório): ID do Usuário - Especifique o endereço de e-mail do usuário. (exemplo: "[user@domain.com](mailto:user@domain.com)").
    * `messageId` (string, obrigatório): ID da Mensagem - Especifique o ID da mensagem para enviar para a lixeira.
  </Accordion>

  <Accordion title="GMAIL_CREATE_A_CONTACT">
    **Descrição:** Cria um contato no Gmail.

    **Parâmetros:**

    * `givenName` (string, obrigatório): Primeiro Nome - Especifique o Primeiro Nome do contato a ser criado. (exemplo: "João").
    * `familyName` (string, obrigatório): Sobrenome - Especifique o Sobrenome do contato a ser criado. (exemplo: "Silva").
    * `email` (string, obrigatório): E-mail - Especifique o endereço de e-mail do contato a ser criado.
    * `additionalFields` (object, opcional): Campos Adicionais - Informações adicionais de contato.
      ```json
      {
        "addresses": [
          {
            "streetAddress": "1000 North St.",
            "city": "Los Angeles"
          }
        ]
      }
      ```
  </Accordion>

  <Accordion title="GMAIL_GET_CONTACT_BY_RESOURCE_NAME">
    **Descrição:** Obtém um contato pelo nome do recurso no Gmail.

    **Parâmetros:**

    * `resourceName` (string, obrigatório): Nome do Recurso - Especifique o nome do recurso do contato a ser buscado.
  </Accordion>

  <Accordion title="GMAIL_SEARCH_FOR_CONTACT">
    **Descrição:** Pesquisa um contato no Gmail.

    **Parâmetros:**

    * `searchTerm` (string, obrigatório): Termo - Especifique um termo para buscar correspondências aproximadas ou exatas nos campos nome, apelido, endereços de e-mail, números de telefone ou organizações do contato.
  </Accordion>

  <Accordion title="GMAIL_DELETE_CONTACT">
    **Descrição:** Exclui um contato no Gmail.

    **Parâmetros:**

    * `resourceName` (string, obrigatório): Nome do Recurso - Especifique o nome do recurso do contato a ser excluído.
  </Accordion>

  <Accordion title="GMAIL_CREATE_DRAFT">
    **Descrição:** Cria um rascunho no Gmail.

    **Parâmetros:**

    * `toRecipients` (array, opcional): Para - Especifique os destinatários como uma única string ou um array JSON.
      ```json
      [
        "recipient1@domain.com",
        "recipient2@domain.com"
      ]
      ```
    * `from` (string, opcional): De - Especifique o e-mail do remetente.
    * `subject` (string, opcional): Assunto - Especifique o assunto da mensagem.
    * `messageContent` (string, opcional): Conteúdo da Mensagem - Especifique o conteúdo do e-mail em texto simples ou HTML.
    * `attachments` (string, opcional): Anexos - Aceita um único objeto de arquivo ou um array JSON de objetos de arquivo.
    * `additionalHeaders` (object, opcional): Cabeçalhos Adicionais - Especifique quaisquer campos de cabeçalho adicionais aqui.
      ```json
      {
        "reply-to": "Nome do Remetente <sender@domain.com>"
      }
      ```
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configuração Básica de Agente Gmail

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Gmail tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Gmail capabilities
gmail_agent = Agent(
    role="Email Manager",
    goal="Manage email communications and contacts efficiently",
    backstory="An AI assistant specialized in email management and communication.",
    tools=[enterprise_tools]
)

# Task to send a follow-up email
send_email_task = Task(
    description="Send a follow-up email to john@example.com about the project update meeting",
    agent=gmail_agent,
    expected_output="Email sent successfully with confirmation"
)

# Run the task
crew = Crew(
    agents=[gmail_agent],
    tasks=[send_email_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Específicas do Gmail

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Gmail tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["gmail_send_email", "gmail_search_for_email", "gmail_create_draft"]
)

email_coordinator = Agent(
    role="Email Coordinator",
    goal="Coordinate email communications and manage drafts",
    backstory="An AI assistant that focuses on email coordination and draft management.",
    tools=enterprise_tools
)

# Task to prepare and send emails
email_coordination = Task(
    description="Search for emails from the marketing team, create a summary draft, and send it to stakeholders",
    agent=email_coordinator,
    expected_output="Summary email sent to stakeholders"
)

crew = Crew(
    agents=[email_coordinator],
    tasks=[email_coordination]
)

crew.kickoff()
```

### Gerenciamento de Contatos

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

contact_manager = Agent(
    role="Contact Manager",
    goal="Manage and organize email contacts efficiently",
    backstory="An experienced contact manager who maintains organized contact databases.",
    tools=[enterprise_tools]
)

# Task to manage contacts
contact_task = Task(
    description="""
    1. Search for contacts from the 'example.com' domain
    2. Create new contacts for recent email senders not in the contact list
    3. Update contact information with recent interaction data
    """,
    agent=contact_manager,
    expected_output="Contact database updated with new contacts and recent interactions"
)

crew = Crew(
    agents=[contact_manager],
    tasks=[contact_task]
)

crew.kickoff()
```

### Pesquisa e Análise de E-mails

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

email_analyst = Agent(
    role="Email Analyst",
    goal="Analyze email patterns and provide insights",
    backstory="An AI assistant that analyzes email data to provide actionable insights.",
    tools=[enterprise_tools]
)

# Task to analyze email patterns
analysis_task = Task(
    description="""
    Search for all unread emails from the last 7 days,
    categorize them by sender domain,
    and create a summary report of communication patterns
    """,
    agent=email_analyst,
    expected_output="Email analysis report with communication patterns and recommendations"
)

crew = Crew(
    agents=[email_analyst],
    tasks=[analysis_task]
)

crew.kickoff()
```

### Fluxos de Trabalho Automatizados de E-mail

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

workflow_manager = Agent(
    role="Email Workflow Manager",
    goal="Automate email workflows and responses",
    backstory="An AI assistant that manages automated email workflows and responses.",
    tools=[enterprise_tools]
)

# Complex task involving multiple Gmail operations
workflow_task = Task(
    description="""
    1. Search for emails with 'urgent' in the subject from the last 24 hours
    2. Create draft responses for each urgent email
    3. Send automated acknowledgment emails to senders
    4. Create a summary report of urgent items requiring attention
    """,
    agent=workflow_manager,
    expected_output="Urgent emails processed with automated responses and summary report"
)

crew = Crew(
    agents=[workflow_manager],
    tasks=[workflow_task]
)

crew.kickoff()
```

### Precisa de Ajuda?

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nosso time de suporte para obter assistência na configuração ou solução de problemas da integração Gmail.
</Card>


# Integração com Google Calendar
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/google_calendar

Gerenciamento de eventos e agendas com integração ao Google Calendar para o CrewAI.

## Visão Geral

Permita que seus agentes gerenciem eventos de calendário, agendas e disponibilidade através do Google Calendar. Crie e atualize eventos, gerencie participantes, verifique disponibilidade e otimize seu fluxo de agendamento com automação potencializada por IA.

## Pré-requisitos

Antes de usar a integração com o Google Calendar, certifique-se de ter:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Uma conta Google com acesso ao Google Calendar
* Sua conta Google conectada pela [página de Integrações](https://app.crewai.com/crewai_plus/connectors)

## Configurando a Integração com Google Calendar

### 1. Conecte sua Conta Google

1. Acesse [Integrações do CrewAI Enterprise](https://app.crewai.com/crewai_plus/connectors)
2. Encontre **Google Calendar** na seção de Integrações de Autenticação
3. Clique em **Conectar** e complete o fluxo OAuth
4. Conceda as permissões necessárias para acesso ao calendário e contatos
5. Copie seu Token Enterprise nas [Configurações da Conta](https://app.crewai.com/crewai_plus/settings/account)

### 2. Instale o Pacote Necessário

```bash
uv add crewai-tools
```

## Ações Disponíveis

<AccordionGroup>
  <Accordion title="GOOGLE_CALENDAR_CREATE_EVENT">
    **Descrição:** Cria um evento no Google Calendar.

    **Parâmetros:**

    * `eventName` (string, obrigatório): Nome do evento.
    * `startTime` (string, obrigatório): Horário de início – Aceita timestamp Unix ou formatos de data ISO8601.
    * `endTime` (string, opcional): Horário de término – Padrão para uma hora após o início, se deixado em branco.
    * `calendar` (string, opcional): Calendário – Use as Configurações de Workflow do Connect Portal para permitir que o usuário selecione em qual calendário o evento será adicionado. Padrão para o calendário principal do usuário se deixado em branco.
    * `attendees` (string, opcional): Participantes – Aceita um array de e-mails ou e-mails separados por vírgula.
    * `eventLocation` (string, opcional): Local do evento.
    * `eventDescription` (string, opcional): Descrição do evento.
    * `eventId` (string, opcional): ID do evento – Um ID da sua aplicação para associar a este evento. Você pode usar esse ID para sincronizar atualizações posteriores neste evento.
    * `includeMeetLink` (boolean, opcional): Incluir link do Google Meet? – Cria automaticamente um link para conferência Google Meet para este evento.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_UPDATE_EVENT">
    **Descrição:** Atualiza um evento existente no Google Calendar.

    **Parâmetros:**

    * `eventId` (string, obrigatório): ID do evento – O ID do evento a ser atualizado.
    * `eventName` (string, opcional): Nome do evento.
    * `startTime` (string, opcional): Horário de início – Aceita timestamp Unix ou formatos de data ISO8601.
    * `endTime` (string, opcional): Horário de término – Padrão para uma hora após o início, se deixado em branco.
    * `calendar` (string, opcional): Calendário – Use as Configurações de Workflow do Connect Portal para permitir que o usuário selecione em qual calendário o evento será adicionado. Padrão para o calendário principal do usuário se deixado em branco.
    * `attendees` (string, opcional): Participantes – Aceita um array de e-mails ou e-mails separados por vírgula.
    * `eventLocation` (string, opcional): Local do evento.
    * `eventDescription` (string, opcional): Descrição do evento.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_LIST_EVENTS">
    **Descrição:** Lista eventos do Google Calendar.

    **Parâmetros:**

    * `calendar` (string, opcional): Calendário – Use as Configurações de Workflow do Connect Portal para permitir que o usuário selecione em qual calendário o evento será adicionado. Padrão para o calendário principal do usuário se deixado em branco.
    * `after` (string, opcional): Após – Filtra eventos que começam após a data fornecida (Unix em milissegundos ou timestamp ISO). (exemplo: "2025-04-12T10:00:00Z ou 1712908800000").
    * `before` (string, opcional): Antes – Filtra eventos que terminam antes da data fornecida (Unix em milissegundos ou timestamp ISO). (exemplo: "2025-04-12T10:00:00Z ou 1712908800000").
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_GET_EVENT_BY_ID">
    **Descrição:** Obtém um evento específico pelo ID no Google Calendar.

    **Parâmetros:**

    * `eventId` (string, obrigatório): ID do evento.
    * `calendar` (string, opcional): Calendário – Use as Configurações de Workflow do Connect Portal para permitir que o usuário selecione em qual calendário o evento será adicionado. Padrão para o calendário principal do usuário se deixado em branco.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_DELETE_EVENT">
    **Descrição:** Exclui um evento do Google Calendar.

    **Parâmetros:**

    * `eventId` (string, obrigatório): ID do evento – O ID do evento do calendário a ser excluído.
    * `calendar` (string, opcional): Calendário – Use as Configurações de Workflow do Connect Portal para permitir que o usuário selecione em qual calendário o evento será adicionado. Padrão para o calendário principal do usuário se deixado em branco.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_GET_CONTACTS">
    **Descrição:** Obtém contatos do Google Calendar.

    **Parâmetros:**

    * `paginationParameters` (objeto, opcional): Parâmetros de Paginação.
      ```json
      {
        "pageCursor": "page_cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_SEARCH_CONTACTS">
    **Descrição:** Pesquisa contatos no Google Calendar.

    **Parâmetros:**

    * `query` (string, opcional): Termo de pesquisa para buscar contatos.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_LIST_DIRECTORY_PEOPLE">
    **Descrição:** Lista pessoas do diretório.

    **Parâmetros:**

    * `paginationParameters` (objeto, opcional): Parâmetros de Paginação.
      ```json
      {
        "pageCursor": "page_cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_SEARCH_DIRECTORY_PEOPLE">
    **Descrição:** Pesquisa pessoas no diretório.

    **Parâmetros:**

    * `query` (string, obrigatório): Termo de pesquisa para buscar contatos.
    * `paginationParameters` (objeto, opcional): Parâmetros de Paginação.
      ```json
      {
        "pageCursor": "page_cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_LIST_OTHER_CONTACTS">
    **Descrição:** Lista outros contatos.

    **Parâmetros:**

    * `paginationParameters` (objeto, opcional): Parâmetros de Paginação.
      ```json
      {
        "pageCursor": "page_cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_SEARCH_OTHER_CONTACTS">
    **Descrição:** Pesquisa outros contatos.

    **Parâmetros:**

    * `query` (string, opcional): Termo de pesquisa para buscar contatos.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_GET_AVAILABILITY">
    **Descrição:** Obtém informações de disponibilidade para calendários.

    **Parâmetros:**

    * `timeMin` (string, obrigatório): Início do intervalo. Em formato ISO.
    * `timeMax` (string, obrigatório): Fim do intervalo. Em formato ISO.
    * `timeZone` (string, opcional): Fuso horário usado na resposta. Opcional. O padrão é UTC.
    * `items` (array, opcional): Lista de calendários e/ou grupos para consulta. Padrão para o calendário padrão do usuário.
      ```json
      [
        {
          "id": "calendar_id_1"
        },
        {
          "id": "calendar_id_2"
        }
      ]
      ```
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configuração Básica de Agente de Calendário

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Obter ferramentas empresariais (as ferramentas do Google Calendar serão incluídas)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Criar um agente com capacidades do Google Calendar
calendar_agent = Agent(
    role="Schedule Manager",
    goal="Gerenciar eventos de calendário e agendamento de maneira eficiente",
    backstory="Um assistente de IA especializado em gerenciamento de agendas e coordenação de horários.",
    tools=[enterprise_tools]
)

# Tarefa de criação de reunião
create_meeting_task = Task(
    description="Crie uma reunião diária de equipe amanhã às 9h com o time de desenvolvimento",
    agent=calendar_agent,
    expected_output="Reunião criada com sucesso com link do Google Meet"
)

# Executar a tarefa
crew = Crew(
    agents=[calendar_agent],
    tasks=[create_meeting_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Específicas do Calendário

```python
from crewai_tools import CrewaiEnterpriseTools

# Obter apenas ferramentas específicas do Google Calendar
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["google_calendar_create_event", "google_calendar_list_events", "google_calendar_get_availability"]
)

meeting_coordinator = Agent(
    role="Meeting Coordinator",
    goal="Coordenar reuniões e verificar disponibilidade",
    backstory="Um assistente de IA que foca em agendamento de reuniões e gerenciamento de disponibilidade.",
    tools=enterprise_tools
)

# Tarefa para agendar reunião com verificação de disponibilidade
schedule_meeting = Task(
    description="Verifique a disponibilidade para a próxima semana e agende uma reunião de revisão do projeto com os stakeholders",
    agent=meeting_coordinator,
    expected_output="Reunião agendada após verificação da disponibilidade de todos os participantes"
)

crew = Crew(
    agents=[meeting_coordinator],
    tasks=[schedule_meeting]
)

crew.kickoff()
```

### Gerenciamento e Atualização de Eventos

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

event_manager = Agent(
    role="Event Manager",
    goal="Gerenciar e atualizar eventos de calendário de forma eficiente",
    backstory="Um experiente gestor de eventos responsável pela logística e atualizações dos eventos.",
    tools=[enterprise_tools]
)

# Tarefa para gerenciar atualizações de eventos
event_management = Task(
    description="""
    1. Liste todos os eventos desta semana
    2. Atualize os eventos que precisarem de alteração de local para incluir links de videoconferência
    3. Envie convites de calendário para novos membros do time para reuniões recorrentes
    """,
    agent=event_manager,
    expected_output="Eventos semanais atualizados com os locais corretos e novos participantes incluídos"
)

crew = Crew(
    agents=[event_manager],
    tasks=[event_management]
)

crew.kickoff()
```

### Gerenciamento de Contatos e Disponibilidade

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

availability_coordinator = Agent(
    role="Availability Coordinator",
    goal="Coordenar disponibilidade e gerenciar contatos para agendamento",
    backstory="Um assistente de IA que se especializa em gerenciamento de disponibilidade e coordenação de contatos.",
    tools=[enterprise_tools]
)

# Tarefa de coordenação de disponibilidade
availability_task = Task(
    description="""
    1. Pesquise contatos no departamento de engenharia
    2. Verifique a disponibilidade de todos os engenheiros para a próxima sexta-feira à tarde
    3. Crie uma reunião de equipe no primeiro intervalo de 2 horas disponível
    4. Inclua o link do Google Meet e envie convites
    """,
    agent=availability_coordinator,
    expected_output="Reunião agendada com base na disponibilidade com todos os engenheiros convidados"
)

crew = Crew(
    agents=[availability_coordinator],
    tasks=[availability_task]
)

crew.kickoff()
```

### Workflows de Agendamento Automatizado

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

scheduling_automator = Agent(
    role="Scheduling Automator",
    goal="Automatizar workflows de agendamento e gerenciamento de calendários",
    backstory="Um assistente de IA que automatiza cenários complexos de agendamento e workflows de agenda.",
    tools=[enterprise_tools]
)

# Tarefa de automação de agendamento complexo
automation_task = Task(
    description="""
    1. Liste todos os eventos futuros das próximas duas semanas
    2. Identifique conflitos de agendamento ou reuniões consecutivas
    3. Sugira horários ótimos de reunião verificando as disponibilidades
    4. Crie intervalos entre reuniões quando necessário
    5. Atualize a descrição dos eventos com pautas e links de reunião
    """,
    agent=scheduling_automator,
    expected_output="Calendário otimizado com conflitos resolvidos, intervalos e detalhes das reuniões atualizados"
)

crew = Crew(
    agents=[scheduling_automator],
    tasks=[automation_task]
)

crew.kickoff()
```

## Solução de Problemas

### Problemas Comuns

**Erros de Autenticação**

* Certifique-se de que sua conta Google possui as permissões necessárias para acessar o calendário
* Verifique se a conexão OAuth inclui todos os escopos necessários para a API do Google Calendar
* Confirme se as configurações de compartilhamento do calendário permitem o nível de acesso necessário

**Problemas na Criação de Eventos**

* Verifique se os formatos de horário estão corretos (ISO8601 ou timestamps Unix)
* Assegure-se de que os endereços de e-mail dos participantes estão corretamente formatados
* Verifique se o calendário de destino existe e está acessível
* Confirme se os fusos horários estão especificados corretamente

**Disponibilidade e Conflitos de Horário**

* Use formato ISO adequado para os intervalos de horário ao verificar disponibilidade
* Certifique-se de que os fusos horários estão consistentes em todas as operações
* Verifique se os IDs dos calendários estão corretos ao consultar múltiplos calendários

**Pesquisa de Contatos e Pessoas**

* Assegure-se de que os termos de pesquisa estão devidamente formatados
* Verifique se as permissões para acesso ao diretório foram concedidas
* Certifique-se de que as informações de contato estão atualizadas e acessíveis

**Atualização e Exclusão de Eventos**

* Verifique se os IDs dos eventos estão corretos e se os eventos existem
* Assegure-se de que você possui permissões de edição para os eventos
* Verifique se a propriedade do calendário permite modificações

### Obtendo Ajuda

<Card title="Precisa de ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nosso time de suporte para assistência na configuração da integração com o Google Calendar ou solução de problemas.
</Card>


# Integração com Google Sheets
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/google_sheets

Sincronização de dados de planilhas com a integração do Google Sheets para CrewAI.

## Visão Geral

Permita que seus agentes gerenciem dados de planilhas por meio do Google Sheets. Leia linhas, crie novos registros, atualize dados existentes e otimize os fluxos de trabalho de gerenciamento de dados com automação alimentada por IA. Perfeito para acompanhamento de dados, relatórios e gestão colaborativa de informações.

## Pré-requisitos

Antes de utilizar a integração com o Google Sheets, certifique-se de que você possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Uma conta Google com acesso ao Google Sheets
* Sua conta Google conectada pela [página de integrações](https://app.crewai.com/crewai_plus/connectors)
* Planilhas com cabeçalhos de coluna adequados para operações com dados

## Configurando a Integração com Google Sheets

### 1. Conecte sua Conta Google

1. Acesse [Integrações do CrewAI Enterprise](https://app.crewai.com/crewai_plus/connectors)
2. Localize **Google Sheets** na seção Integrações de Autenticação
3. Clique em **Conectar** e conclua o fluxo OAuth
4. Conceda as permissões necessárias para acesso à planilha
5. Copie seu Token Enterprise em [Configurações da Conta](https://app.crewai.com/crewai_plus/settings/account)

### 2. Instale o Pacote Necessário

```bash
uv add crewai-tools
```

## Ações Disponíveis

<AccordionGroup>
  <Accordion title="GOOGLE_SHEETS_GET_ROW">
    **Descrição:** Obtém linhas de uma planilha Google Sheets.

    **Parâmetros:**

    * `spreadsheetId` (string, obrigatório): Planilha - Use as Configurações de Workflow do Portal de Conexão para permitir ao usuário selecionar uma planilha. Por padrão, usa a primeira worksheet da planilha selecionada.
    * `limit` (string, opcional): Limite de linhas - Limita o número máximo de linhas retornadas.
  </Accordion>

  <Accordion title="GOOGLE_SHEETS_CREATE_ROW">
    **Descrição:** Cria uma nova linha em uma planilha Google Sheets.

    **Parâmetros:**

    * `spreadsheetId` (string, obrigatório): Planilha - Use as Configurações de Workflow do Portal de Conexão para permitir ao usuário selecionar uma planilha. Por padrão, usa a primeira worksheet da planilha selecionada.
    * `worksheet` (string, obrigatório): Worksheet - Sua worksheet deve conter cabeçalhos de coluna.
    * `additionalFields` (object, obrigatório): Campos - Inclua os campos para criar essa linha como um objeto, usando os nomes das colunas como chaves. Use as Configurações de Workflow do Portal de Conexão para permitir ao usuário selecionar um Mapeamento de Colunas.
      ```json
      {
        "columnName1": "columnValue1",
        "columnName2": "columnValue2",
        "columnName3": "columnValue3",
        "columnName4": "columnValue4"
      }
      ```
  </Accordion>

  <Accordion title="GOOGLE_SHEETS_UPDATE_ROW">
    **Descrição:** Atualiza linhas existentes em uma planilha Google Sheets.

    **Parâmetros:**

    * `spreadsheetId` (string, obrigatório): Planilha - Use as Configurações de Workflow do Portal de Conexão para permitir ao usuário selecionar uma planilha. Por padrão, usa a primeira worksheet da planilha selecionada.
    * `worksheet` (string, obrigatório): Worksheet - Sua worksheet deve conter cabeçalhos de coluna.
    * `filterFormula` (object, opcional): Filtro em forma normal disjuntiva - OU de grupos E (AND) de condições individuais para identificar quais linhas atualizar.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "status",
                "operator": "$stringExactlyMatches",
                "value": "pending"
              }
            ]
          }
        ]
      }
      ```
      Operadores disponíveis: `$stringContains`, `$stringDoesNotContain`, `$stringExactlyMatches`, `$stringDoesNotExactlyMatch`, `$stringStartsWith`, `$stringDoesNotStartWith`, `$stringEndsWith`, `$stringDoesNotEndWith`, `$numberGreaterThan`, `$numberLessThan`, `$numberEquals`, `$numberDoesNotEqual`, `$dateTimeAfter`, `$dateTimeBefore`, `$dateTimeEquals`, `$booleanTrue`, `$booleanFalse`, `$exists`, `$doesNotExist`
    * `additionalFields` (object, obrigatório): Campos - Inclua os campos a serem atualizados como objeto, usando os nomes das colunas como chaves. Use as Configurações de Workflow do Portal de Conexão para permitir ao usuário selecionar um Mapeamento de Colunas.
      ```json
      {
        "columnName1": "newValue1",
        "columnName2": "newValue2",
        "columnName3": "newValue3",
        "columnName4": "newValue4"
      }
      ```
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configuração Básica de um Agente Google Sheets

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Obtenha as ferramentas enterprise (ferramentas Google Sheets incluídas)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Crie um agente com capacidades para Google Sheets
sheets_agent = Agent(
    role="Data Manager",
    goal="Gerenciar dados de planilha e rastrear informações de maneira eficiente",
    backstory="Um assistente de IA especializado em gestão de dados e operações em planilhas.",
    tools=[enterprise_tools]
)

# Tarefa para adicionar novos dados a uma planilha
data_entry_task = Task(
    description="Adicionar novo registro de cliente na planilha de banco de dados de clientes com nome, e-mail e data de cadastro",
    agent=sheets_agent,
    expected_output="Novo registro de cliente adicionado com sucesso à planilha"
)

# Execute a tarefa
crew = Crew(
    agents=[sheets_agent],
    tasks=[data_entry_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Específicas do Google Sheets

```python
from crewai_tools import CrewaiEnterpriseTools

# Obtenha apenas ferramentas específicas do Google Sheets
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["google_sheets_get_row", "google_sheets_create_row"]
)

data_collector = Agent(
    role="Data Collector",
    goal="Coletar e organizar dados em planilhas",
    backstory="Um assistente de IA dedicado à coleta e organização de dados.",
    tools=enterprise_tools
)

# Tarefa para coletar e organizar dados
data_collection = Task(
    description="Recuperar dados atuais de inventário e adicionar novos produtos à planilha de inventário",
    agent=data_collector,
    expected_output="Dados de inventário recuperados e novos produtos adicionados com sucesso"
)

crew = Crew(
    agents=[data_collector],
    tasks=[data_collection]
)

crew.kickoff()
```

### Análise de Dados e Geração de Relatórios

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

data_analyst = Agent(
    role="Data Analyst",
    goal="Analisar dados de planilhas e gerar insights",
    backstory="Um analista de dados experiente que extrai insights dos dados de planilhas.",
    tools=[enterprise_tools]
)

# Tarefa para analisar dados e criar relatórios
analysis_task = Task(
    description="""
    1. Recuperar todos os dados de vendas da planilha do mês atual
    2. Analisar os dados em busca de tendências e padrões
    3. Criar um relatório resumo em uma nova linha com os principais indicadores
    """,
    agent=data_analyst,
    expected_output="Dados de vendas analisados e relatório resumo criado com os principais insights"
)

crew = Crew(
    agents=[data_analyst],
    tasks=[analysis_task]
)

crew.kickoff()
```

### Atualizações Automatizadas de Dados

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

data_updater = Agent(
    role="Data Updater",
    goal="Atualizar e manter dados de planilhas automaticamente",
    backstory="Um assistente de IA que mantém a precisão dos dados e atualiza registros automaticamente.",
    tools=[enterprise_tools]
)

# Tarefa para atualizar dados com base em condições
update_task = Task(
    description="""
    1. Encontrar todos os pedidos pendentes na planilha de pedidos
    2. Atualizar o status para 'processing'
    3. Adicionar um registro de data/hora da atualização do status
    4. Registrar as alterações em uma planilha de acompanhamento separada
    """,
    agent=data_updater,
    expected_output="Todos os pedidos pendentes atualizados para o status processing com registros de data/hora"
)

crew = Crew(
    agents=[data_updater],
    tasks=[update_task]
)

crew.kickoff()
```

### Fluxo de Trabalho Complexo com Dados

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

workflow_manager = Agent(
    role="Data Workflow Manager",
    goal="Gerenciar fluxos de dados complexos entre várias planilhas",
    backstory="Um assistente de IA que orquestra operações complexas de dados entre várias planilhas.",
    tools=[enterprise_tools]
)

# Tarefa de workflow complexa
workflow_task = Task(
    description="""
    1. Obter todos os dados de clientes da planilha principal de clientes
    2. Criar registros de resumo mensal para clientes ativos
    3. Atualizar o status de clientes com base na atividade nos últimos 30 dias
    4. Gerar um relatório mensal com métricas dos clientes
    5. Arquivar registros de clientes inativos em uma planilha separada
    """,
    agent=workflow_manager,
    expected_output="Workflow mensal de clientes concluído com atualizações de status e relatórios gerados"
)

crew = Crew(
    agents=[workflow_manager],
    tasks=[workflow_task]
)

crew.kickoff()
```

## Solução de Problemas

### Problemas Comuns

**Erros de Permissão**

* Certifique-se de que sua conta Google tem acesso de edição às planilhas alvo
* Verifique se a conexão OAuth inclui os escopos necessários para a API do Google Sheets
* Confira se as planilhas estão compartilhadas com a conta autenticada

**Problemas de Estrutura da Planilha**

* Certifique-se de que as worksheets têm cabeçalhos de coluna antes de criar ou atualizar linhas
* Verifique se os nomes das colunas em `additionalFields` correspondem exatamente aos cabeçalhos
* Confirme que a worksheet especificada existe na planilha

**Problemas de Tipo e Formato de Dados**

* Garanta que os valores dos dados estejam no formato esperado para cada coluna
* Utilize formatos de data adequados nas colunas de data (recomenda-se ISO)
* Verifique se valores numéricos estão devidamente formatados para colunas numéricas

**Problemas com Fórmulas de Filtro**

* Certifique-se de que as fórmulas de filtro seguem a estrutura JSON correta para forma normal disjuntiva
* Use nomes de campos válidos, correspondendo exatamente aos cabeçalhos das colunas
* Teste filtros simples antes de criar consultas com múltiplas condições
* Verifique se os tipos de operadores correspondem aos tipos de dados das colunas

**Limites de Linhas e Performance**

* Fique atento aos limites de linhas ao usar `GOOGLE_SHEETS_GET_ROW`
* Considere paginação para grandes volumes de dados
* Use filtros específicos para reduzir a quantidade de dados processados

**Operações de Atualização**

* Certifique-se de que as condições de filtro identifiquem corretamente as linhas a serem atualizadas
* Teste condições de filtro com pequenos conjuntos de dados antes de grandes atualizações
* Verifique se todos os campos obrigatórios estão incluídos nas operações de atualização

### Obtendo Ajuda

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nosso time de suporte para auxílio na configuração ou solução de problemas da integração com o Google Sheets.
</Card>


# Integração com HubSpot
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/hubspot

Gerencie empresas e contatos no HubSpot com o CrewAI.

## Visão Geral

Permita que seus agentes gerenciem empresas e contatos dentro do HubSpot. Crie novos registros e otimize seus processos de CRM com automação baseada em IA.

## Pré-requisitos

Antes de utilizar a integração com o HubSpot, certifique-se de que você possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa.
* Uma conta HubSpot com permissões adequadas.
* Sua conta HubSpot conectada pela [página de Integrações](https://app.crewai.com/crewai_plus/connectors).

## Configurando a Integração com o HubSpot

### 1. Conecte Sua Conta HubSpot

1. Navegue até [CrewAI Enterprise Integrações](https://app.crewai.com/crewai_plus/connectors).
2. Encontre **HubSpot** na seção de Integrações de Autenticação.
3. Clique em **Conectar** e complete o fluxo OAuth.
4. Conceda as permissões necessárias para gerenciamento de empresas e contatos.
5. Copie o seu Token Enterprise nas [Configurações da Conta](https://app.crewai.com/crewai_plus/settings/account).

### 2. Instale o Pacote Necessário

```bash
uv add crewai-tools
```

## Ações Disponíveis

<AccordionGroup>
  <Accordion title="HUBSPOT_CREATE_RECORD_COMPANIES">
    **Descrição:** Crie um novo registro de empresa no HubSpot.

    **Parâmetros:**

    * `name` (string, obrigatório): Nome da empresa.
    * `domain` (string, opcional): Nome do domínio da empresa.
    * `industry` (string, opcional): Setor. Deve ser um dos valores predefinidos do HubSpot.
    * `phone` (string, opcional): Telefone.
    * `hubspot_owner_id` (string, opcional): ID do responsável pela empresa.
    * `type` (string, opcional): Tipo da empresa. Valores disponíveis: `PROSPECT`, `PARTNER`, `RESELLER`, `VENDOR`, `OTHER`.
    * `city` (string, opcional): Cidade.
    * `state` (string, opcional): Estado/Região.
    * `zip` (string, opcional): CEP.
    * `numberofemployees` (number, opcional): Número de funcionários.
    * `annualrevenue` (number, opcional): Receita anual.
    * `timezone` (string, opcional): Fuso horário.
    * `description` (string, opcional): Descrição.
    * `linkedin_company_page` (string, opcional): URL da página da empresa no LinkedIn.
    * `company_email` (string, opcional): E-mail da empresa.
    * `first_name` (string, opcional): Nome do contato na empresa.
    * `last_name` (string, opcional): Sobrenome do contato na empresa.
    * `about_us` (string, opcional): Sobre nós.
    * `hs_csm_sentiment` (string, opcional): Sentimento CSM. Valores disponíveis: `at_risk`, `neutral`, `healthy`.
    * `closedate` (string, opcional): Data de fechamento.
    * `hs_keywords` (string, opcional): Palavras-chave da empresa. Deve ser um dos valores predefinidos.
    * `country` (string, opcional): País/Região.
    * `hs_country_code` (string, opcional): Código do País/Região.
    * `hs_employee_range` (string, opcional): Faixa de funcionários.
    * `facebook_company_page` (string, opcional): URL da página da empresa no Facebook.
    * `facebookfans` (number, opcional): Número de fãs no Facebook.
    * `hs_gps_coordinates` (string, opcional): Coordenadas GPS.
    * `hs_gps_error` (string, opcional): Erro de GPS.
    * `googleplus_page` (string, opcional): URL da página do Google Plus.
    * `owneremail` (string, opcional): E-mail do proprietário no HubSpot.
    * `ownername` (string, opcional): Nome do proprietário no HubSpot.
    * `hs_ideal_customer_profile` (string, opcional): Tier de Perfil de Cliente Ideal. Valores disponíveis: `tier_1`, `tier_2`, `tier_3`.
    * `hs_industry_group` (string, opcional): Grupo do setor.
    * `is_public` (boolean, opcional): É público.
    * `hs_last_metered_enrichment_timestamp` (string, opcional): Último registro de enriquecimento medido.
    * `hs_lead_status` (string, opcional): Status do lead. Valores disponíveis: `NEW`, `OPEN`, `IN_PROGRESS`, `OPEN_DEAL`, `UNQUALIFIED`, `ATTEMPTED_TO_CONTACT`, `CONNECTED`, `BAD_TIMING`.
    * `lifecyclestage` (string, opcional): Estágio no ciclo de vida. Valores disponíveis: `subscriber`, `lead`, `marketingqualifiedlead`, `salesqualifiedlead`, `opportunity`, `customer`, `evangelist`, `other`.
    * `linkedinbio` (string, opcional): Bio do LinkedIn.
    * `hs_linkedin_handle` (string, opcional): Handle do LinkedIn.
    * `hs_live_enrichment_deadline` (string, opcional): Prazo para enriquecimento ao vivo.
    * `hs_logo_url` (string, opcional): URL do logotipo.
    * `hs_analytics_source` (string, opcional): Fonte original do tráfego.
    * `hs_pinned_engagement_id` (number, opcional): ID do engajamento fixado.
    * `hs_quick_context` (string, opcional): Contexto rápido.
    * `hs_revenue_range` (string, opcional): Faixa de receita.
    * `hs_state_code` (string, opcional): Código do Estado/Região.
    * `address` (string, opcional): Endereço.
    * `address2` (string, opcional): Complemento de endereço.
    * `hs_is_target_account` (boolean, opcional): Conta alvo.
    * `hs_target_account` (string, opcional): Tier da Conta Alvo. Valores disponíveis: `tier_1`, `tier_2`, `tier_3`.
    * `hs_target_account_recommendation_snooze_time` (string, opcional): Tempo para adiar recomendação de conta alvo.
    * `hs_target_account_recommendation_state` (string, opcional): Estado da recomendação da conta alvo. Valores disponíveis: `DISMISSED`, `NONE`, `SNOOZED`.
    * `total_money_raised` (string, opcional): Total arrecadado.
    * `twitterbio` (string, opcional): Bio do Twitter.
    * `twitterfollowers` (number, opcional): Seguidores no Twitter.
    * `twitterhandle` (string, opcional): Usuário do Twitter.
    * `web_technologies` (string, opcional): Tecnologias web utilizadas. Deve ser um dos valores predefinidos.
    * `website` (string, opcional): URL do site.
    * `founded_year` (string, opcional): Ano de fundação.
  </Accordion>

  <Accordion title="HUBSPOT_CREATE_RECORD_CONTACTS">
    **Descrição:** Crie um novo registro de contato no HubSpot.

    **Parâmetros:**

    * `email` (string, obrigatório): E-mail do contato.
    * `firstname` (string, opcional): Nome.
    * `lastname` (string, opcional): Sobrenome.
    * `phone` (string, opcional): Telefone.
    * `hubspot_owner_id` (string, opcional): Responsável pelo contato.
    * `lifecyclestage` (string, opcional): Estágio no ciclo de vida. Valores disponíveis: `subscriber`, `lead`, `marketingqualifiedlead`, `salesqualifiedlead`, `opportunity`, `customer`, `evangelist`, `other`.
    * `hs_lead_status` (string, opcional): Status do lead. Valores disponíveis: `NEW`, `OPEN`, `IN_PROGRESS`, `OPEN_DEAL`, `UNQUALIFIED`, `ATTEMPTED_TO_CONTACT`, `CONNECTED`, `BAD_TIMING`.
    * `annualrevenue` (string, opcional): Receita anual.
    * `hs_buying_role` (string, opcional): Papel na compra.
    * `cc_emails` (string, opcional): E-mails em cópia.
    * `ch_customer_id` (string, opcional): ID do cliente no Chargify.
    * `ch_customer_reference` (string, opcional): Referência do cliente no Chargify.
    * `chargify_sites` (string, opcional): Sites Chargify.
    * `city` (string, opcional): Cidade.
    * `hs_facebook_ad_clicked` (boolean, opcional): Clicou em anúncio do Facebook.
    * `hs_linkedin_ad_clicked` (string, opcional): Clicou em anúncio do LinkedIn.
    * `hs_clicked_linkedin_ad` (string, opcional): Clicou em anúncio do LinkedIn.
    * `closedate` (string, opcional): Data de fechamento.
    * `company` (string, opcional): Nome da empresa.
    * `company_size` (string, opcional): Tamanho da empresa.
    * `country` (string, opcional): País/Região.
    * `hs_country_region_code` (string, opcional): Código do País/Região.
    * `date_of_birth` (string, opcional): Data de nascimento.
    * `degree` (string, opcional): Grau de instrução.
    * `hs_email_customer_quarantined_reason` (string, opcional): Motivo da quarentena de e-mail.
    * `hs_role` (string, opcional): Cargo. Deve ser um dos valores predefinidos.
    * `hs_seniority` (string, opcional): Senioridade. Deve ser um dos valores predefinidos.
    * `hs_sub_role` (string, opcional): Sub papel. Deve ser um dos valores predefinidos.
    * `hs_employment_change_detected_date` (string, opcional): Data da detecção de mudança de emprego.
    * `hs_enriched_email_bounce_detected` (boolean, opcional): Bounce de e-mail enriquecido detectado.
    * `hs_facebookid` (string, opcional): Facebook ID.
    * `hs_facebook_click_id` (string, opcional): ID de clique no Facebook.
    * `fax` (string, opcional): Fax.
    * `field_of_study` (string, opcional): Área de estudo.
    * `followercount` (number, opcional): Número de seguidores.
    * `gender` (string, opcional): Gênero.
    * `hs_google_click_id` (string, opcional): ID de clique no Google.
    * `graduation_date` (string, opcional): Data de graduação.
    * `owneremail` (string, opcional): E-mail do proprietário no HubSpot (legado).
    * `ownername` (string, opcional): Nome do proprietário no HubSpot (legado).
    * `industry` (string, opcional): Setor.
    * `hs_inferred_language_codes` (string, opcional): Códigos de idioma inferido. Deve ser um dos valores predefinidos.
    * `jobtitle` (string, opcional): Cargo.
    * `hs_job_change_detected_date` (string, opcional): Data de detecção de mudança de emprego.
    * `job_function` (string, opcional): Função.
    * `hs_journey_stage` (string, opcional): Estágio da jornada. Deve ser um dos valores predefinidos.
    * `kloutscoregeneral` (number, opcional): Klout Score.
    * `hs_last_metered_enrichment_timestamp` (string, opcional): Último registro de enriquecimento medido.
    * `hs_latest_source` (string, opcional): Fonte de tráfego mais recente.
    * `hs_latest_source_timestamp` (string, opcional): Data da fonte mais recente.
    * `hs_legal_basis` (string, opcional): Base legal para o processamento dos dados do contato.
    * `linkedinbio` (string, opcional): Bio do LinkedIn.
    * `linkedinconnections` (number, opcional): Conexões no LinkedIn.
    * `hs_linkedin_url` (string, opcional): URL do LinkedIn.
    * `hs_linkedinid` (string, opcional): Linkedin ID.
    * `hs_live_enrichment_deadline` (string, opcional): Prazo para enriquecimento ao vivo.
    * `marital_status` (string, opcional): Estado civil.
    * `hs_content_membership_email` (string, opcional): E-mail de membro.
    * `hs_content_membership_notes` (string, opcional): Notas de associação.
    * `message` (string, opcional): Mensagem.
    * `military_status` (string, opcional): Status militar.
    * `mobilephone` (string, opcional): Celular.
    * `numemployees` (string, opcional): Número de funcionários.
    * `hs_analytics_source` (string, opcional): Fonte original do tráfego.
    * `photo` (string, opcional): Foto.
    * `hs_pinned_engagement_id` (number, opcional): ID de engajamento fixado.
    * `zip` (string, opcional): CEP.
    * `hs_language` (string, opcional): Idioma preferencial. Deve ser um dos valores predefinidos.
    * `associatedcompanyid` (number, opcional): ID da empresa associada primária.
    * `hs_email_optout_survey_reason` (string, opcional): Motivo da recusa de e-mail.
    * `relationship_status` (string, opcional): Status de relacionamento.
    * `hs_returning_to_office_detected_date` (string, opcional): Data de retorno ao escritório detectada.
    * `salutation` (string, opcional): Saudação.
    * `school` (string, opcional): Escola.
    * `seniority` (string, opcional): Senioridade.
    * `hs_feedback_show_nps_web_survey` (boolean, opcional): Mostrar pesquisa NPS na web.
    * `start_date` (string, opcional): Data de início.
    * `state` (string, opcional): Estado/Região.
    * `hs_state_code` (string, opcional): Código do Estado/Região.
    * `hs_content_membership_status` (string, opcional): Status.
    * `address` (string, opcional): Endereço.
    * `tax_exempt` (string, opcional): Isento de impostos.
    * `hs_timezone` (string, opcional): Fuso horário. Deve ser um dos valores predefinidos.
    * `twitterbio` (string, opcional): Bio do Twitter.
    * `hs_twitterid` (string, opcional): Twitter ID.
    * `twitterprofilephoto` (string, opcional): Foto de perfil do Twitter.
    * `twitterhandle` (string, opcional): Usuário do Twitter.
    * `vat_number` (string, opcional): Número VAT.
    * `ch_verified` (string, opcional): Verificado para pagamentos ACH/eCheck.
    * `website` (string, opcional): URL do site.
    * `hs_whatsapp_phone_number` (string, opcional): Número do WhatsApp.
    * `work_email` (string, opcional): E-mail corporativo.
    * `hs_googleplusid` (string, opcional): googleplus ID.
  </Accordion>

  <Accordion title="HUBSPOT_CREATE_RECORD_DEALS">
    **Descrição:** Crie um novo registro de negócio (deal) no HubSpot.

    **Parâmetros:**

    * `dealname` (string, obrigatório): Nome do negócio.
    * `amount` (number, opcional): Valor do negócio.
    * `dealstage` (string, opcional): Estágio no pipeline.
    * `pipeline` (string, opcional): Pipeline ao qual o negócio pertence.
    * `closedate` (string, opcional): Data prevista de fechamento do negócio.
    * `hubspot_owner_id` (string, opcional): Responsável pelo negócio.
    * `dealtype` (string, opcional): Tipo do negócio. Valores disponíveis: `newbusiness`, `existingbusiness`.
    * `description` (string, opcional): Descrição do negócio.
    * `hs_priority` (string, opcional): Prioridade do negócio. Valores disponíveis: `low`, `medium`, `high`.
  </Accordion>

  <Accordion title="HUBSPOT_CREATE_RECORD_ENGAGEMENTS">
    **Descrição:** Crie um novo engajamento (ex: nota, e-mail, ligação, reunião, tarefa) no HubSpot.

    **Parâmetros:**

    * `engagementType` (string, obrigatório): Tipo de engajamento. Valores disponíveis: `NOTE`, `EMAIL`, `CALL`, `MEETING`, `TASK`.
    * `hubspot_owner_id` (string, opcional): Usuário responsável pela atividade.
    * `hs_timestamp` (string, opcional): Data e hora da atividade.
    * `hs_note_body` (string, opcional): Corpo da nota. (Utilizado para `NOTE`)
    * `hs_task_subject` (string, opcional): Título da tarefa. (Utilizado para `TASK`)
    * `hs_task_body` (string, opcional): Notas da tarefa. (Utilizado para `TASK`)
    * `hs_task_status` (string, opcional): Status da tarefa. (Utilizado para `TASK`)
    * `hs_meeting_title` (string, opcional): Título da reunião. (Utilizado para `MEETING`)
    * `hs_meeting_body` (string, opcional): Descrição da reunião. (Utilizado para `MEETING`)
    * `hs_meeting_start_time` (string, opcional): Horário de início da reunião. (Utilizado para `MEETING`)
    * `hs_meeting_end_time` (string, opcional): Horário de término da reunião. (Utilizado para `MEETING`)
  </Accordion>

  <Accordion title="HUBSPOT_UPDATE_RECORD_COMPANIES">
    **Descrição:** Atualize um registro de empresa existente no HubSpot.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID da empresa a ser atualizada.
    * `name` (string, opcional): Nome da empresa.
    * `domain` (string, opcional): Nome do domínio da empresa.
    * `industry` (string, opcional): Setor.
    * `phone` (string, opcional): Telefone.
    * `city` (string, opcional): Cidade.
    * `state` (string, opcional): Estado/Região.
    * `zip` (string, opcional): CEP.
    * `numberofemployees` (number, opcional): Número de funcionários.
    * `annualrevenue` (number, opcional): Receita anual.
    * `description` (string, opcional): Descrição.
  </Accordion>

  <Accordion title="HUBSPOT_CREATE_RECORD_ANY">
    **Descrição:** Crie um registro para um tipo de objeto especificado no HubSpot.

    **Parâmetros:**

    * `recordType` (string, obrigatório): ID do tipo de objeto personalizado.
    * Parâmetros adicionais dependem do esquema do objeto personalizado.
  </Accordion>

  <Accordion title="HUBSPOT_UPDATE_RECORD_CONTACTS">
    **Descrição:** Atualize um registro de contato existente no HubSpot.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID do contato a ser atualizado.
    * `firstname` (string, opcional): Nome.
    * `lastname` (string, opcional): Sobrenome.
    * `email` (string, opcional): E-mail.
    * `phone` (string, opcional): Telefone.
    * `company` (string, opcional): Nome da empresa.
    * `jobtitle` (string, opcional): Cargo.
    * `lifecyclestage` (string, opcional): Estágio no ciclo de vida.
  </Accordion>

  <Accordion title="HUBSPOT_UPDATE_RECORD_DEALS">
    **Descrição:** Atualize um registro de negócio existente no HubSpot.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID do negócio a ser atualizado.
    * `dealname` (string, opcional): Nome do negócio.
    * `amount` (number, opcional): Valor do negócio.
    * `dealstage` (string, opcional): Estágio do pipeline.
    * `pipeline` (string, opcional): Pipeline ao qual o negócio pertence.
    * `closedate` (string, opcional): Data prevista de fechamento.
    * `dealtype` (string, opcional): Tipo de negócio.
  </Accordion>

  <Accordion title="HUBSPOT_UPDATE_RECORD_ENGAGEMENTS">
    **Descrição:** Atualize um engajamento existente no HubSpot.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID do engajamento a ser atualizado.
    * `hs_note_body` (string, opcional): Corpo da nota.
    * `hs_task_subject` (string, opcional): Título da tarefa.
    * `hs_task_body` (string, opcional): Notas da tarefa.
    * `hs_task_status` (string, opcional): Status da tarefa.
  </Accordion>

  <Accordion title="HUBSPOT_UPDATE_RECORD_ANY">
    **Descrição:** Atualize um registro para um tipo de objeto especificado no HubSpot.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID do registro a ser atualizado.
    * `recordType` (string, obrigatório): ID do tipo de objeto personalizado.
    * Parâmetros adicionais dependem do esquema do objeto personalizado.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORDS_COMPANIES">
    **Descrição:** Obtenha uma lista de registros de empresas do HubSpot.

    **Parâmetros:**

    * `paginationParameters` (object, opcional): Use `pageCursor` para buscar páginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORDS_CONTACTS">
    **Descrição:** Obtenha uma lista de registros de contatos do HubSpot.

    **Parâmetros:**

    * `paginationParameters` (object, opcional): Use `pageCursor` para buscar páginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORDS_DEALS">
    **Descrição:** Obtenha uma lista de registros de negócios do HubSpot.

    **Parâmetros:**

    * `paginationParameters` (object, opcional): Use `pageCursor` para buscar páginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORDS_ENGAGEMENTS">
    **Descrição:** Obtenha uma lista de registros de engajamentos do HubSpot.

    **Parâmetros:**

    * `objectName` (string, obrigatório): O tipo de engajamento a ser buscado (ex.: "notes").
    * `paginationParameters` (object, opcional): Use `pageCursor` para buscar páginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORDS_ANY">
    **Descrição:** Obtenha uma lista de registros de qualquer tipo de objeto no HubSpot.

    **Parâmetros:**

    * `recordType` (string, obrigatório): O ID do tipo de objeto personalizado.
    * `paginationParameters` (object, opcional): Use `pageCursor` para buscar páginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORD_BY_ID_COMPANIES">
    **Descrição:** Obtenha um registro de empresa pelo seu ID.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID da empresa a ser consultada.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORD_BY_ID_CONTACTS">
    **Descrição:** Obtenha um registro de contato pelo seu ID.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID do contato a ser consultado.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORD_BY_ID_DEALS">
    **Descrição:** Obtenha um registro de negócio pelo seu ID.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID do negócio a ser consultado.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORD_BY_ID_ENGAGEMENTS">
    **Descrição:** Obtenha um registro de engajamento pelo seu ID.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID do engajamento a ser consultado.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORD_BY_ID_ANY">
    **Descrição:** Obtenha um registro de qualquer tipo de objeto especificado pelo seu ID.

    **Parâmetros:**

    * `recordType` (string, obrigatório): ID do tipo de objeto personalizado.
    * `recordId` (string, obrigatório): ID do registro a ser consultado.
  </Accordion>

  <Accordion title="HUBSPOT_SEARCH_RECORDS_COMPANIES">
    **Descrição:** Pesquise registros de empresas no HubSpot utilizando uma fórmula de filtro.

    **Parâmetros:**

    * `filterFormula` (object, opcional): Filtro em forma normal disjuntiva (OU de E).
    * `paginationParameters` (object, opcional): Use `pageCursor` para buscar páginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_SEARCH_RECORDS_CONTACTS">
    **Descrição:** Pesquise registros de contatos no HubSpot utilizando uma fórmula de filtro.

    **Parâmetros:**

    * `filterFormula` (object, opcional): Filtro em forma normal disjuntiva (OU de E).
    * `paginationParameters` (object, opcional): Use `pageCursor` para buscar páginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_SEARCH_RECORDS_DEALS">
    **Descrição:** Pesquise registros de negócios no HubSpot utilizando uma fórmula de filtro.

    **Parâmetros:**

    * `filterFormula` (object, opcional): Filtro em forma normal disjuntiva (OU de E).
    * `paginationParameters` (object, opcional): Use `pageCursor` para buscar páginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_SEARCH_RECORDS_ENGAGEMENTS">
    **Descrição:** Pesquise registros de engajamento no HubSpot utilizando uma fórmula de filtro.

    **Parâmetros:**

    * `engagementFilterFormula` (object, opcional): Filtro para engajamentos.
    * `paginationParameters` (object, opcional): Use `pageCursor` para buscar páginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_SEARCH_RECORDS_ANY">
    **Descrição:** Pesquise registros de qualquer tipo de objeto no HubSpot.

    **Parâmetros:**

    * `recordType` (string, obrigatório): O ID do tipo de objeto para pesquisa.
    * `filterFormula` (string, opcional): Fórmula de filtro a aplicar.
    * `paginationParameters` (object, opcional): Use `pageCursor` para buscar páginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_DELETE_RECORD_COMPANIES">
    **Descrição:** Exclua um registro de empresa pelo seu ID.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID da empresa a ser excluída.
  </Accordion>

  <Accordion title="HUBSPOT_DELETE_RECORD_CONTACTS">
    **Descrição:** Exclua um registro de contato pelo seu ID.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID do contato a ser excluído.
  </Accordion>

  <Accordion title="HUBSPOT_DELETE_RECORD_DEALS">
    **Descrição:** Exclua um registro de negócio pelo seu ID.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID do negócio a ser excluído.
  </Accordion>

  <Accordion title="HUBSPOT_DELETE_RECORD_ENGAGEMENTS">
    **Descrição:** Exclua um registro de engajamento pelo seu ID.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID do engajamento a ser excluído.
  </Accordion>

  <Accordion title="HUBSPOT_DELETE_RECORD_ANY">
    **Descrição:** Exclua um registro de qualquer tipo de objeto especificado pelo seu ID.

    **Parâmetros:**

    * `recordType` (string, obrigatório): ID do tipo de objeto personalizado.
    * `recordId` (string, obrigatório): ID do registro a ser excluído.
  </Accordion>

  <Accordion title="HUBSPOT_GET_CONTACTS_BY_LIST_ID">
    **Descrição:** Obtenha contatos de uma lista específica pelo seu ID.

    **Parâmetros:**

    * `listId` (string, obrigatório): ID da lista da qual obter os contatos.
    * `paginationParameters` (object, opcional): Use `pageCursor` para páginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_DESCRIBE_ACTION_SCHEMA">
    **Descrição:** Obtenha o esquema esperado para um dado tipo de objeto e operação.

    **Parâmetros:**

    * `recordType` (string, obrigatório): ID do tipo de objeto (ex.: 'companies').
    * `operation` (string, obrigatório): Tipo de operação (ex.: 'CREATE\_RECORD').
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configuração Básica de Agente HubSpot

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Obtenha as ferramentas enterprise (ferramentas HubSpot incluídas)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Crie um agente com capacidades HubSpot
hubspot_agent = Agent(
    role="CRM Manager",
    goal="Manage company and contact records in HubSpot",
    backstory="An AI assistant specialized in CRM management.",
    tools=[enterprise_tools]
)

# Task para criar nova empresa
create_company_task = Task(
    description="Create a new company in HubSpot with name 'Innovate Corp' and domain 'innovatecorp.com'.",
    agent=hubspot_agent,
    expected_output="Company created successfully with confirmation"
)

# Execute a tarefa
crew = Crew(
    agents=[hubspot_agent],
    tasks=[create_company_task]
)

crew.kickoff()
```

### Filtrando Ferramentas HubSpot Específicas

```python
from crewai_tools import CrewaiEnterpriseTools

# Obtenha somente a ferramenta para criar contatos
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["hubspot_create_record_contacts"]
)

contact_creator = Agent(
    role="Contact Creator",
    goal="Create new contacts in HubSpot",
    backstory="An AI assistant that focuses on creating new contact entries in the CRM.",
    tools=[enterprise_tools]
)

# Task para criar contato
create_contact = Task(
    description="Create a new contact for 'John Doe' with email 'john.doe@example.com'.",
    agent=contact_creator,
    expected_output="Contact created successfully in HubSpot."
)

crew = Crew(
    agents=[contact_creator],
    tasks=[create_contact]
)

crew.kickoff()
```

### Gerenciamento de Contatos

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

crm_manager = Agent(
    role="CRM Manager",
    goal="Manage and organize HubSpot contacts efficiently.",
    backstory="An experienced CRM manager who maintains an organized contact database.",
    tools=[enterprise_tools]
)

# Task para gerenciar contatos
contact_task = Task(
    description="Create a new contact for 'Jane Smith' at 'Global Tech Inc.' with email 'jane.smith@globaltech.com'.",
    agent=crm_manager,
    expected_output="Contact database updated with the new contact."
)

crew = Crew(
    agents=[crm_manager],
    tasks=[contact_task]
)

crew.kickoff()
```

### Precisa de Ajuda?

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para assistência na configuração ou solução de problemas com a integração HubSpot.
</Card>


# Integração com Jira
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/jira

Rastreamento de problemas e gestão de projetos com a integração Jira para CrewAI.

## Visão Geral

Permita que seus agentes gerenciem problemas, projetos e fluxos de trabalho pelo Jira. Crie e atualize issues, acompanhe o progresso de projetos, gerencie atribuições e otimize sua gestão de projetos com automação potencializada por IA.

## Pré-requisitos

Antes de usar a integração com o Jira, certifique-se de ter:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Uma conta Jira com permissões adequadas para o projeto
* Sua conta Jira conectada pela [Página de Integrações](https://app.crewai.com/crewai_plus/connectors)

## Configurando a Integração com o Jira

### 1. Conectar Sua Conta Jira

1. Acesse [Integrações CrewAI Enterprise](https://app.crewai.com/crewai_plus/connectors)
2. Encontre **Jira** na seção de Integrações de Autenticação
3. Clique em **Conectar** e complete o fluxo do OAuth
4. Conceda as permissões necessárias para gestão de issues e projetos
5. Copie seu Token Enterprise em [Configurações da Conta](https://app.crewai.com/crewai_plus/settings/account)

### 2. Instalar o Pacote Necessário

```bash
uv add crewai-tools
```

## Ações Disponíveis

<AccordionGroup>
  <Accordion title="JIRA_CREATE_ISSUE">
    **Descrição:** Cria uma issue no Jira.

    **Parâmetros:**

    * `summary` (string, obrigatório): Resumo - Um breve resumo da issue. (exemplo: "A impressora parou de funcionar").
    * `project` (string, opcional): Projeto - Projeto ao qual a issue pertence. Padrão para o primeiro projeto do usuário se não informado. Use as Configurações de Workflow do Portal de Conexão para permitir a seleção de Projeto.
    * `issueType` (string, opcional): Tipo de issue - Padrão para Task se não informado.
    * `jiraIssueStatus` (string, opcional): Status - Padrão para o primeiro status do projeto se não informado.
    * `assignee` (string, opcional): Responsável - Padrão para o usuário autenticado se não informado.
    * `descriptionType` (string, opcional): Tipo de Descrição - Selecione o Tipo de Descrição.
      * Opções: `description`, `descriptionJSON`
    * `description` (string, opcional): Descrição - Uma descrição detalhada da issue. Este campo aparece apenas se 'descriptionType' = 'description'.
    * `additionalFields` (string, opcional): Campos Adicionais - Especifique outros campos em formato JSON. Use as Configurações de Workflow do Portal de Conexão para permitir ao usuário selecionar quais campos atualizar.
      ```json
      {
        "customfield_10001": "value"
      }
      ```
  </Accordion>

  <Accordion title="JIRA_UPDATE_ISSUE">
    **Descrição:** Atualiza uma issue no Jira.

    **Parâmetros:**

    * `issueKey` (string, obrigatório): Chave da Issue (exemplo: "TEST-1234").
    * `summary` (string, opcional): Resumo - Breve resumo da issue. (exemplo: "A impressora parou de funcionar").
    * `issueType` (string, opcional): Tipo de issue - Use as Configurações de Workflow do Portal de Conexão para permitir a seleção.
    * `jiraIssueStatus` (string, opcional): Status - Use as Configurações de Workflow do Portal de Conexão para permitir a seleção.
    * `assignee` (string, opcional): Responsável - Use as Configurações de Workflow do Portal de Conexão para permitir a seleção.
    * `descriptionType` (string, opcional): Tipo de Descrição - Selecione o Tipo de Descrição.
      * Opções: `description`, `descriptionJSON`
    * `description` (string, opcional): Descrição - Descrição detalhada da issue. Este campo aparece apenas se 'descriptionType' = 'description'.
    * `additionalFields` (string, opcional): Campos Adicionais - Especifique outros campos em formato JSON.
  </Accordion>

  <Accordion title="JIRA_GET_ISSUE_BY_KEY">
    **Descrição:** Obtém uma issue pelo identificador no Jira.

    **Parâmetros:**

    * `issueKey` (string, obrigatório): Chave da Issue (exemplo: "TEST-1234").
  </Accordion>

  <Accordion title="JIRA_FILTER_ISSUES">
    **Descrição:** Busca issues no Jira usando filtros.

    **Parâmetros:**

    * `jqlQuery` (object, opcional): Filtro em forma normal disjuntiva - OU de grupos E de condições simples.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "status",
                "operator": "$stringExactlyMatches",
                "value": "Open"
              }
            ]
          }
        ]
      }
      ```
      Operadores disponíveis: `$stringExactlyMatches`, `$stringDoesNotExactlyMatch`, `$stringIsIn`, `$stringIsNotIn`, `$stringContains`, `$stringDoesNotContain`, `$stringGreaterThan`, `$stringLessThan`
    * `limit` (string, opcional): Limitar resultados - Limite máximo de issues retornados. Padrão para 10 se estiver em branco.
  </Accordion>

  <Accordion title="JIRA_SEARCH_BY_JQL">
    **Descrição:** Busca issues no Jira utilizando JQL.

    **Parâmetros:**

    * `jqlQuery` (string, obrigatório): Query JQL (exemplo: "project = PROJECT").
    * `paginationParameters` (object, opcional): Parâmetros de paginação para resultados paginados.
      ```json
      {
        "pageCursor": "cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="JIRA_UPDATE_ISSUE_ANY">
    **Descrição:** Atualiza qualquer issue no Jira. Use DESCRIBE\_ACTION\_SCHEMA para obter o schema de propriedades dessa função.

    **Parâmetros:** Nenhum parâmetro específico - use JIRA\_DESCRIBE\_ACTION\_SCHEMA primeiro para obter o schema esperado.
  </Accordion>

  <Accordion title="JIRA_DESCRIBE_ACTION_SCHEMA">
    **Descrição:** Obtém o schema esperado para um tipo de issue. Use esta função caso nenhuma outra função atenda ao tipo de issue que deseja operar.

    **Parâmetros:**

    * `issueTypeId` (string, obrigatório): ID do Tipo de Issue.
    * `projectKey` (string, obrigatório): Chave do projeto.
    * `operation` (string, obrigatório): Tipo de Operação, por exemplo CREATE\_ISSUE ou UPDATE\_ISSUE.
  </Accordion>

  <Accordion title="JIRA_GET_PROJECTS">
    **Descrição:** Obtém os projetos no Jira.

    **Parâmetros:**

    * `paginationParameters` (object, opcional): Parâmetros de Paginação.
      ```json
      {
        "pageCursor": "cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="JIRA_GET_ISSUE_TYPES_BY_PROJECT">
    **Descrição:** Obtém os tipos de issues por projeto no Jira.

    **Parâmetros:**

    * `project` (string, obrigatório): Chave do projeto.
  </Accordion>

  <Accordion title="JIRA_GET_ISSUE_TYPES">
    **Descrição:** Obtém todos os tipos de issues no Jira.

    **Parâmetros:** Nenhum obrigatório.
  </Accordion>

  <Accordion title="JIRA_GET_ISSUE_STATUS_BY_PROJECT">
    **Descrição:** Obtém os status das issues de um projeto específico.

    **Parâmetros:**

    * `project` (string, obrigatório): Chave do projeto.
  </Accordion>

  <Accordion title="JIRA_GET_ALL_ASSIGNEES_BY_PROJECT">
    **Descrição:** Obtém os responsáveis por um projeto específico.

    **Parâmetros:**

    * `project` (string, obrigatório): Chave do projeto.
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configuração Básica de um Agente Jira

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Obtenha as ferramentas enterprise (incluirá ferramentas do Jira)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Criação de um agente com capacidades Jira
jira_agent = Agent(
    role="Issue Manager",
    goal="Gerenciar issues do Jira e acompanhar o progresso do projeto de forma eficiente",
    backstory="Um assistente de IA especializado em rastreamento de issues e gestão de projetos.",
    tools=[enterprise_tools]
)

# Tarefa para criar um relatório de bug
create_bug_task = Task(
    description="Criar um relatório de bug para a funcionalidade de login com alta prioridade e designar para o time de desenvolvimento",
    agent=jira_agent,
    expected_output="Bug report creado com sucesso e chave da issue"
)

# Executar a tarefa
crew = Crew(
    agents=[jira_agent],
    tasks=[create_bug_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Jira Específicas

```python
from crewai_tools import CrewaiEnterpriseTools

# Obtenha apenas ferramentas Jira específicas
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["jira_create_issue", "jira_update_issue", "jira_search_by_jql"]
)

issue_coordinator = Agent(
    role="Issue Coordinator",
    goal="Criar e gerenciar issues Jira de forma eficiente",
    backstory="Um assistente de IA focado na criação e gestão de issues.",
    tools=enterprise_tools
)

# Tarefa para gerenciar workflow de issues
issue_workflow = Task(
    description="Criar uma issue de solicitação de feature e atualizar o status de issues relacionadas",
    agent=issue_coordinator,
    expected_output="Feature request criada e issues relacionadas atualizadas"
)

crew = Crew(
    agents=[issue_coordinator],
    tasks=[issue_workflow]
)

crew.kickoff()
```

### Análise e Relatórios de Projeto

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

project_analyst = Agent(
    role="Project Analyst",
    goal="Analisar dados de projetos e gerar insights a partir do Jira",
    backstory="Um analista de projetos experiente que extrai insights de dados de gestão de projetos.",
    tools=[enterprise_tools]
)

# Tarefa para analisar status do projeto
analysis_task = Task(
    description="""
    1. Obtenha todos os projetos e seus tipos de issues
    2. Busque todas as issues abertas entre projetos
    3. Analise distribuição de issues por status e responsável
    4. Crie uma issue de relatório de resumo com os achados
    """,
    agent=project_analyst,
    expected_output="Análise do projeto completa com relatório de resumo criado"
)

crew = Crew(
    agents=[project_analyst],
    tasks=[analysis_task]
)

crew.kickoff()
```

### Gestão Automatizada de Issues

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

automation_manager = Agent(
    role="Automation Manager",
    goal="Automatizar gestão de issues e processos de workflow",
    backstory="Um assistente de IA que automatiza tarefas repetitivas de gestão de issues.",
    tools=[enterprise_tools]
)

# Tarefa para automatizar gestão de issues
automation_task = Task(
    description="""
    1. Buscar todas as issues não atribuídas usando JQL
    2. Obter responsáveis disponíveis de cada projeto
    3. Atribuir issues automaticamente com base na carga de trabalho e especialidade
    4. Atualizar prioridades das issues baseando-se na idade e tipo
    5. Criar issues semanais de planejamento de sprint
    """,
    agent=automation_manager,
    expected_output="Issues atribuídas automaticamente e issues de planejamento de sprint criadas"
)

crew = Crew(
    agents=[automation_manager],
    tasks=[automation_task]
)

crew.kickoff()
```

### Operações Avançadas Baseadas em Schema

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

schema_specialist = Agent(
    role="Schema Specialist",
    goal="Executar operações complexas no Jira usando schemas dinâmicos",
    backstory="Um assistente de IA que manipula schemas dinâmicos e tipos de issues customizadas do Jira.",
    tools=[enterprise_tools]
)

# Tarefa usando operações baseadas em schema
schema_task = Task(
    description="""
    1. Obtenha todos os projetos e seus tipos personalizados de issues
    2. Para cada tipo personalizado, descreva o schema de ação
    3. Crie issues usando schema dinâmico para campos complexos customizados
    4. Atualize issues com valores de campos personalizados a partir de regras de negócio
    """,
    agent=schema_specialist,
    expected_output="Issues customizadas criadas e atualizadas utilizando schemas dinâmicos"
)

crew = Crew(
    agents=[schema_specialist],
    tasks=[schema_task]
)

crew.kickoff()
```

## Solução de Problemas

### Problemas Comuns

**Erros de Permissão**

* Certifique-se de que sua conta Jira tem as permissões necessárias nos projetos alvo
* Verifique se a conexão OAuth inclui os escopos necessários da API Jira
* Confira se você possui permissões de criar/editar issues nos projetos especificados

**Chaves de Projeto ou Issue Inválidas**

* Confira o formato das chaves dos projetos e issues (ex: "PROJ-123")
* Verifique se os projetos existem e são acessíveis pela sua conta
* Certifique-se de que chaves de issues referenciam issues existentes

**Problemas de Tipo ou Status de Issue**

* Use JIRA\_GET\_ISSUE\_TYPES\_BY\_PROJECT para obter tipos válidos de issue para um projeto
* Use JIRA\_GET\_ISSUE\_STATUS\_BY\_PROJECT para obter status válidos
* Certifique-se de que tipos e status de issue estão disponíveis no projeto alvo

**Problemas com Queries JQL**

* Teste as queries JQL na busca de issues do Jira antes de utilizar em chamadas de API
* Certifique-se de que os nomes dos campos em JQL estejam corretos e existam em sua instância do Jira
* Use a sintaxe correta de JQL para queries complexas

**Problemas com Campos Customizados e Schemas**

* Use JIRA\_DESCRIBE\_ACTION\_SCHEMA para obter o schema correto para tipos de issues complexas
* Certifique-se de que os IDs dos campos customizados estão corretos (ex: "customfield\_10001")
* Verifique se esses campos estão disponíveis no projeto e tipo de issue alvo

**Problemas de Fórmulas de Filtro**

* Garanta que as fórmulas de filtro sigam a estrutura JSON correta para forma normal disjuntiva
* Use apenas campos válidos conforme configuração do seu Jira
* Teste filtros simples antes de construir queries complexas com múltiplas condições

### Obtenha Ajuda

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nosso time de suporte para obter assistência na configuração ou solução de problemas da integração Jira.
</Card>


# Integração com o Linear
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/linear

Acompanhamento de projetos de software e rastreamento de bugs com a integração Linear para CrewAI.

## Visão Geral

Permita que seus agentes gerenciem issues, projetos e fluxos de trabalho de desenvolvimento através do Linear. Crie e atualize issues, gerencie cronogramas de projetos, organize equipes e otimize seu processo de desenvolvimento de software com automação impulsionada por IA.

## Pré-requisitos

Antes de utilizar a integração com o Linear, certifique-se de que você possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com uma assinatura ativa
* Uma conta Linear com permissões apropriadas no workspace
* Conectou sua conta Linear através da [página de Integrações](https://app.crewai.com/crewai_plus/connectors)

## Configurando a Integração com o Linear

### 1. Conecte sua Conta Linear

1. Navegue até [Integrações CrewAI Enterprise](https://app.crewai.com/crewai_plus/connectors)
2. Encontre **Linear** na seção Integrações de Autenticação
3. Clique em **Conectar** e complete o fluxo OAuth
4. Conceda as permissões necessárias para gerenciamento de issues e projetos
5. Copie seu Token Empresarial em [Configurações da Conta](https://app.crewai.com/crewai_plus/settings/account)

### 2. Instale o Pacote Necessário

```bash
uv add crewai-tools
```

## Ações Disponíveis

<AccordionGroup>
  <Accordion title="LINEAR_CREATE_ISSUE">
    **Descrição:** Crie uma nova issue no Linear.

    **Parâmetros:**

    * `teamId` (string, obrigatório): ID da Equipe - Especifique o ID da equipe responsável para esta nova issue. Use as Configurações de Fluxo do Connect Portal para permitir que usuários escolham um ID de Equipe. (exemplo: "a70bdf0f-530a-4887-857d-46151b52b47c").
    * `title` (string, obrigatório): Título - Especifique um título para esta issue.
    * `description` (string, opcional): Descrição - Especifique uma descrição para esta issue.
    * `statusId` (string, opcional): Status - Especifique o status desta issue.
    * `priority` (string, opcional): Prioridade - Especifique a prioridade desta issue como um inteiro.
    * `dueDate` (string, opcional): Data de Vencimento - Especifique a data de vencimento desta issue no formato ISO 8601.
    * `cycleId` (string, opcional): ID do Ciclo - Especifique o ciclo associado a esta issue.
    * `additionalFields` (object, opcional): Campos Adicionais.
      ```json
      {
        "assigneeId": "a70bdf0f-530a-4887-857d-46151b52b47c",
        "labelIds": ["a70bdf0f-530a-4887-857d-46151b52b47c"]
      }
      ```
  </Accordion>

  <Accordion title="LINEAR_UPDATE_ISSUE">
    **Descrição:** Atualize uma issue no Linear.

    **Parâmetros:**

    * `issueId` (string, obrigatório): ID da Issue - Especifique o ID da issue a ser atualizada. (exemplo: "90fbc706-18cd-42c9-ae66-6bd344cc8977").
    * `title` (string, opcional): Título - Especifique um título para esta issue.
    * `description` (string, opcional): Descrição - Especifique uma descrição para esta issue.
    * `statusId` (string, opcional): Status - Especifique o status desta issue.
    * `priority` (string, opcional): Prioridade - Especifique a prioridade desta issue como um inteiro.
    * `dueDate` (string, opcional): Data de Vencimento - Especifique a data de vencimento desta issue no formato ISO 8601.
    * `cycleId` (string, opcional): ID do Ciclo - Especifique o ciclo associado a esta issue.
    * `additionalFields` (object, opcional): Campos Adicionais.
      ```json
      {
        "assigneeId": "a70bdf0f-530a-4887-857d-46151b52b47c",
        "labelIds": ["a70bdf0f-530a-4887-857d-46151b52b47c"]
      }
      ```
  </Accordion>

  <Accordion title="LINEAR_GET_ISSUE_BY_ID">
    **Descrição:** Obtenha uma issue pelo ID no Linear.

    **Parâmetros:**

    * `issueId` (string, obrigatório): ID da Issue - Especifique o ID do registro da issue a ser buscada. (exemplo: "90fbc706-18cd-42c9-ae66-6bd344cc8977").
  </Accordion>

  <Accordion title="LINEAR_GET_ISSUE_BY_ISSUE_IDENTIFIER">
    **Descrição:** Obtenha uma issue através do identificador da issue no Linear.

    **Parâmetros:**

    * `externalId` (string, obrigatório): ID Externo - Especifique o identificador legível da issue a ser buscada. (exemplo: "ABC-1").
  </Accordion>

  <Accordion title="LINEAR_SEARCH_ISSUE">
    **Descrição:** Pesquise issues no Linear.

    **Parâmetros:**

    * `queryTerm` (string, obrigatório): Termo de Pesquisa - O termo a ser localizado na busca.
    * `issueFilterFormula` (object, opcional): Um filtro na forma normal disjuntiva – OU de grupos E de condições únicas.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "title",
                "operator": "$stringContains",
                "value": "bug"
              }
            ]
          }
        ]
      }
      ```
      Campos disponíveis: `title`, `number`, `project`, `createdAt`
      Operadores disponíveis: `$stringExactlyMatches`, `$stringDoesNotExactlyMatch`, `$stringIsIn`, `$stringIsNotIn`, `$stringStartsWith`, `$stringDoesNotStartWith`, `$stringEndsWith`, `$stringDoesNotEndWith`, `$stringContains`, `$stringDoesNotContain`, `$stringGreaterThan`, `$stringLessThan`, `$numberGreaterThanOrEqualTo`, `$numberLessThanOrEqualTo`, `$numberGreaterThan`, `$numberLessThan`, `$dateTimeAfter`, `$dateTimeBefore`
  </Accordion>

  <Accordion title="LINEAR_DELETE_ISSUE">
    **Descrição:** Exclua uma issue no Linear.

    **Parâmetros:**

    * `issueId` (string, obrigatório): ID da Issue - Especifique o ID do registro da issue a ser excluída. (exemplo: "90fbc706-18cd-42c9-ae66-6bd344cc8977").
  </Accordion>

  <Accordion title="LINEAR_ARCHIVE_ISSUE">
    **Descrição:** Arquive uma issue no Linear.

    **Parâmetros:**

    * `issueId` (string, obrigatório): ID da Issue - Especifique o ID do registro da issue a ser arquivada. (exemplo: "90fbc706-18cd-42c9-ae66-6bd344cc8977").
  </Accordion>

  <Accordion title="LINEAR_CREATE_SUB_ISSUE">
    **Descrição:** Crie uma sub-issue no Linear.

    **Parâmetros:**

    * `parentId` (string, obrigatório): ID do Pai - Especifique o ID da issue pai desta nova issue.
    * `teamId` (string, obrigatório): ID da Equipe - Especifique o ID da equipe responsável pela nova sub-issue. Use as Configurações de Fluxo do Connect Portal para permitir que usuários escolham um ID de Equipe. (exemplo: "a70bdf0f-530a-4887-857d-46151b52b47c").
    * `title` (string, obrigatório): Título - Especifique um título para esta issue.
    * `description` (string, opcional): Descrição - Especifique uma descrição para esta issue.
    * `additionalFields` (object, opcional): Campos Adicionais.
      ```json
      {
        "lead": "linear_user_id"
      }
      ```
  </Accordion>

  <Accordion title="LINEAR_CREATE_PROJECT">
    **Descrição:** Crie um novo projeto no Linear.

    **Parâmetros:**

    * `teamIds` (object, obrigatório): ID da Equipe - Especifique o(s) ID(s) da equipe associada a este projeto como string ou array JSON. Use as Configurações de Usuário do Connect Portal para que seu usuário selecione um ID de Equipe.
      ```json
      [
        "a70bdf0f-530a-4887-857d-46151b52b47c",
        "4ac7..."
      ]
      ```
    * `projectName` (string, obrigatório): Nome do Projeto - Especifique o nome do projeto. (exemplo: "Meu Projeto Linear").
    * `description` (string, opcional): Descrição do Projeto - Especifique uma descrição para este projeto.
    * `additionalFields` (object, opcional): Campos Adicionais.
      ```json
      {
        "state": "planned",
        "description": ""
      }
      ```
  </Accordion>

  <Accordion title="LINEAR_UPDATE_PROJECT">
    **Descrição:** Atualize um projeto no Linear.

    **Parâmetros:**

    * `projectId` (string, obrigatório): ID do Projeto - Especifique o ID do projeto a ser atualizado. (exemplo: "a6634484-6061-4ac7-9739-7dc5e52c796b").
    * `projectName` (string, opcional): Nome do Projeto - Especifique o nome do projeto a ser atualizado. (exemplo: "Meu Projeto Linear").
    * `description` (string, opcional): Descrição do Projeto - Especifique uma descrição para este projeto.
    * `additionalFields` (object, opcional): Campos Adicionais.
      ```json
      {
        "state": "planned",
        "description": ""
      }
      ```
  </Accordion>

  <Accordion title="LINEAR_GET_PROJECT_BY_ID">
    **Descrição:** Obtenha um projeto pelo ID no Linear.

    **Parâmetros:**

    * `projectId` (string, obrigatório): ID do Projeto - Especifique o ID do projeto a ser buscado. (exemplo: "a6634484-6061-4ac7-9739-7dc5e52c796b").
  </Accordion>

  <Accordion title="LINEAR_DELETE_PROJECT">
    **Descrição:** Exclua um projeto no Linear.

    **Parâmetros:**

    * `projectId` (string, obrigatório): ID do Projeto - Especifique o ID do projeto a ser excluído. (exemplo: "a6634484-6061-4ac7-9739-7dc5e52c796b").
  </Accordion>

  <Accordion title="LINEAR_SEARCH_TEAMS">
    **Descrição:** Pesquise equipes no Linear.

    **Parâmetros:**

    * `teamFilterFormula` (object, opcional): Um filtro na forma normal disjuntiva – OU de grupos E de condições únicas.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "name",
                "operator": "$stringContains",
                "value": "Engineering"
              }
            ]
          }
        ]
      }
      ```
      Campos disponíveis: `id`, `name`
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configuração Básica do Agente Linear

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Obtenha ferramentas empresariais (ferramentas do Linear serão incluídas)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Crie um agente com funcionalidades do Linear
linear_agent = Agent(
    role="Development Manager",
    goal="Gerenciar issues do Linear e acompanhar o progresso do desenvolvimento de forma eficiente",
    backstory="Um assistente de IA especializado em gerenciamento de projetos de desenvolvimento de software.",
    tools=[enterprise_tools]
)

# Tarefa para criar um relatório de bug
create_bug_task = Task(
    description="Crie um relatório de bug de alta prioridade para o sistema de autenticação e atribua à equipe de backend",
    agent=linear_agent,
    expected_output="Bug report criado com sucesso com ID da issue"
)

# Execute a tarefa
crew = Crew(
    agents=[linear_agent],
    tasks=[create_bug_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Lineares Específicas

```python
from crewai_tools import CrewaiEnterpriseTools

# Obtenha apenas ferramentas lineares específicas
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["linear_create_issue", "linear_update_issue", "linear_search_issue"]
)

issue_manager = Agent(
    role="Issue Manager",
    goal="Criar e gerenciar issues no Linear de forma eficiente",
    backstory="Um assistente de IA focado na criação e no gerenciamento do ciclo de vida de issues.",
    tools=enterprise_tools
)

# Tarefa para gerenciar fluxo de issues
issue_workflow = Task(
    description="Crie uma issue de solicitação de recurso e atualize os status das issues relacionadas para refletir o progresso atual",
    agent=issue_manager,
    expected_output="Solicitação de recurso criada e issues relacionadas atualizadas"
)

crew = Crew(
    agents=[issue_manager],
    tasks=[issue_workflow]
)

crew.kickoff()
```

### Gerenciamento de Projetos e Equipes

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

project_coordinator = Agent(
    role="Project Coordinator",
    goal="Coordenar projetos e equipes no Linear de forma eficiente",
    backstory="Um coordenador de projetos experiente que gerencia ciclos de desenvolvimento e fluxos de trabalho de equipe.",
    tools=[enterprise_tools]
)

# Tarefa para coordenar a configuração de projeto
project_coordination = Task(
    description="""
    1. Pesquise por equipes de engenharia no Linear
    2. Crie um novo projeto para o desenvolvimento de recursos do Q2
    3. Associe o projeto às equipes relevantes
    4. Crie marcos iniciais do projeto como issues
    """,
    agent=project_coordinator,
    expected_output="Projeto Q2 criado com equipes atribuídas e marcos iniciais estabelecidos"
)

crew = Crew(
    agents=[project_coordinator],
    tasks=[project_coordination]
)

crew.kickoff()
```

### Hierarquia de Issues e Gerenciamento de Sub-tarefas

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

task_organizer = Agent(
    role="Task Organizer",
    goal="Organizar issues complexas em sub-tarefas gerenciáveis",
    backstory="Um assistente de IA que divide trabalhos de desenvolvimento complexos em sub-tarefas organizadas.",
    tools=[enterprise_tools]
)

# Tarefa para criar hierarquia de issues
hierarchy_task = Task(
    description="""
    1. Pesquise por issues de recursos grandes que precisam ser divididos
    2. Para cada issue complexa, crie sub-issues para diferentes componentes
    3. Atualize as issues principais com descrições adequadas e links para sub-issues
    4. Atribua sub-issues aos membros apropriados da equipe com base na especialidade
    """,
    agent=task_organizer,
    expected_output="Issues complexas divididas em sub-tarefas gerenciáveis com atribuições corretas"
)

crew = Crew(
    agents=[task_organizer],
    tasks=[hierarchy_task]
)

crew.kickoff()
```

### Fluxo de Trabalho de Desenvolvimento Automatizado

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

workflow_automator = Agent(
    role="Workflow Automator",
    goal="Automatizar processos de fluxo de trabalho de desenvolvimento no Linear",
    backstory="Um assistente de IA que automatiza tarefas repetitivas de fluxo de trabalho de desenvolvimento.",
    tools=[enterprise_tools]
)

# Tarefa de automação de workflow complexa
automation_task = Task(
    description="""
    1. Pesquise por issues que estejam em progresso há mais de 7 dias
    2. Atualize suas prioridades com base nas datas de vencimento e importância do projeto
    3. Crie issues semanais de planejamento de sprint para cada equipe
    4. Arquive issues concluídas do ciclo anterior
    5. Gere relatórios de status do projeto como novas issues
    """,
    agent=workflow_automator,
    expected_output="Fluxo de desenvolvimento automatizado com prioridades atualizadas, planejamento de sprint e relatórios de status"
)

crew = Crew(
    agents=[workflow_automator],
    tasks=[automation_task]
)

crew.kickoff()
```

## Solução de Problemas

### Problemas Comuns

**Erros de Permissão**

* Certifique-se de que sua conta Linear possui as permissões necessárias no workspace de destino
* Verifique se a conexão OAuth inclui os escopos requeridos pela API do Linear
* Confirme se você tem permissões para criar/editar issues e projetos no workspace

**IDs e Referências Inválidas**

* Verifique os IDs de equipes, IDs de issues e IDs de projetos para garantir o formato UUID correto
* Assegure que as entidades referenciadas (equipes, projetos, ciclos) existem e estão acessíveis
* Verifique se os identificadores de issues seguem o formato correto (ex: "ABC-1")

**Problemas de Associação entre Equipe e Projeto**

* Use LINEAR\_SEARCH\_TEAMS para obter IDs de equipe válidos antes de criar issues ou projetos
* Certifique-se de que as equipes existem e estão ativas no seu workspace
* Verifique se os IDs das equipes estão devidamente formatados como UUIDs

**Problemas com Status e Prioridade das Issues**

* Verifique se os IDs de status referenciam estados de workflow válidos para a equipe
* Certifique-se de que os valores de prioridade estão dentro do intervalo válido para sua configuração do Linear
* Confirme que campos personalizados e labels existem antes de referenciá-los

**Problemas com Formato de Data e Hora**

* Use o formato ISO 8601 para datas de vencimento e timestamps
* Certifique-se de que os fusos horários estão corretos para cálculos de datas de vencimento
* Verifique se os valores de data são válidos e posteriores à data atual para datas de vencimento

**Problemas de Pesquisa e Filtros**

* Garanta que as consultas de busca estejam formatadas corretamente e não estejam vazias
* Utilize nomes de campos válidos nas fórmulas de filtro: `title`, `number`, `project`, `createdAt`
* Teste filtros simples antes de montar consultas complexas com múltiplas condições
* Verifique se os tipos de operadores correspondem aos tipos de dados dos campos filtrados

**Problemas na Criação de Sub-issues**

* Certifique-se de que os IDs das issues pai são válidos e acessíveis
* Verifique se o ID da equipe para as sub-issues corresponde ou é compatível com o da issue pai
* Assegure-se de que as issues pai não estejam arquivadas ou excluídas

### Obtendo Ajuda

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para assistência na configuração ou solução de problemas da integração com o Linear.
</Card>


# Integração com o Notion
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/notion

Gerenciamento de páginas e bancos de dados com integração do Notion para o CrewAI.

## Visão Geral

Permita que seus agentes gerenciem páginas, bancos de dados e conteúdos através do Notion. Crie e atualize páginas, gerencie blocos de conteúdo, organize bases de conhecimento e otimize seus fluxos de documentação com automação alimentada por IA.

## Pré-requisitos

Antes de usar a integração com o Notion, certifique-se de que você tem:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Uma conta Notion com permissões adequadas no workspace
* Sua conta Notion conectada através da [página de Integrações](https://app.crewai.com/crewai_plus/connectors)

## Configurando a Integração com o Notion

### 1. Conecte sua Conta Notion

1. Acesse [Integrações do CrewAI Enterprise](https://app.crewai.com/crewai_plus/connectors)
2. Procure por **Notion** na seção de Integrações de Autenticação
3. Clique em **Conectar** e complete o fluxo de OAuth
4. Conceda as permissões necessárias para gerenciamento de páginas e bancos de dados
5. Copie seu Token Enterprise em [Configurações da Conta](https://app.crewai.com/crewai_plus/settings/account)

### 2. Instale o Pacote Necessário

```bash
uv add crewai-tools
```

## Ações Disponíveis

<AccordionGroup>
  <Accordion title="NOTION_CREATE_PAGE">
    **Descrição:** Cria uma página no Notion.

    **Parâmetros:**

    * `parent` (object, obrigatório): Parent - A página ou banco de dados pai onde a nova página será inserida, representado como um objeto JSON com uma chave page\_id ou database\_id.
      ```json
      {
        "database_id": "DATABASE_ID"
      }
      ```
    * `properties` (object, obrigatório): Properties - Os valores das propriedades da página. Se o pai for um banco de dados, o schema deve corresponder às propriedades do banco de dados.
      ```json
      {
        "title": [
          {
            "text": {
              "content": "My Page"
            }
          }
        ]
      }
      ```
    * `icon` (object, obrigatório): Icon - O ícone da página.
      ```json
      {
        "emoji": "🥬"
      }
      ```
    * `children` (object, opcional): Children - Blocos de conteúdo a serem adicionados à página.
      ```json
      [
        {
          "object": "block",
          "type": "heading_2",
          "heading_2": {
            "rich_text": [
              {
                "type": "text",
                "text": {
                  "content": "Lacinato kale"
                }
              }
            ]
          }
        }
      ]
      ```
    * `cover` (object, opcional): Cover - A imagem de capa da página.
      ```json
      {
        "external": {
          "url": "https://upload.wikimedia.org/wikipedia/commons/6/62/Tuscankale.jpg"
        }
      }
      ```
  </Accordion>

  <Accordion title="NOTION_UPDATE_PAGE">
    **Descrição:** Atualiza uma página no Notion.

    **Parâmetros:**

    * `pageId` (string, obrigatório): Page ID - Especifique o ID da Página a ser atualizada. (exemplo: "59833787-2cf9-4fdf-8782-e53db20768a5").
    * `icon` (object, obrigatório): Icon - O ícone da página.
      ```json
      {
        "emoji": "🥬"
      }
      ```
    * `archived` (boolean, opcional): Archived - Indica se a página está arquivada (excluída). Defina como true para arquivar a página. Defina como false para restaurar.
    * `properties` (object, opcional): Properties - Os valores das propriedades a serem atualizados na página.
      ```json
      {
        "title": [
          {
            "text": {
              "content": "My Updated Page"
            }
          }
        ]
      }
      ```
    * `cover` (object, opcional): Cover - A imagem de capa da página.
      ```json
      {
        "external": {
          "url": "https://upload.wikimedia.org/wikipedia/commons/6/62/Tuscankale.jpg"
        }
      }
      ```
  </Accordion>

  <Accordion title="NOTION_GET_PAGE_BY_ID">
    **Descrição:** Busca uma página pelo ID no Notion.

    **Parâmetros:**

    * `pageId` (string, obrigatório): Page ID - Especifique o ID da Página a ser buscada. (exemplo: "59833787-2cf9-4fdf-8782-e53db20768a5").
  </Accordion>

  <Accordion title="NOTION_ARCHIVE_PAGE">
    **Descrição:** Arquiva uma página no Notion.

    **Parâmetros:**

    * `pageId` (string, obrigatório): Page ID - Especifique o ID da Página a ser arquivada. (exemplo: "59833787-2cf9-4fdf-8782-e53db20768a5").
  </Accordion>

  <Accordion title="NOTION_SEARCH_PAGES">
    **Descrição:** Pesquisa páginas no Notion utilizando filtros.

    **Parâmetros:**

    * `searchByTitleFilterSearch` (object, opcional): Um filtro na forma normal disjuntiva - OU de grupos E de condições simples.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "query",
                "operator": "$stringExactlyMatches",
                "value": "meeting notes"
              }
            ]
          }
        ]
      }
      ```
      Campos disponíveis: `query`, `filter.value`, `direction`, `page_size`
  </Accordion>

  <Accordion title="NOTION_GET_PAGE_CONTENT">
    **Descrição:** Obtém o conteúdo (blocos) de uma página no Notion.

    **Parâmetros:**

    * `blockId` (string, obrigatório): Page ID - Especifique o ID de um Bloco ou Página para receber todos os seus blocos filhos na ordem correta. (exemplo: "59833787-2cf9-4fdf-8782-e53db20768a5").
  </Accordion>

  <Accordion title="NOTION_UPDATE_BLOCK">
    **Descrição:** Atualiza um bloco no Notion.

    **Parâmetros:**

    * `blockId` (string, obrigatório): Block ID - Especifique o ID do Bloco a ser atualizado. (exemplo: "9bc30ad4-9373-46a5-84ab-0a7845ee52e6").
    * `archived` (boolean, opcional): Archived - Defina como true para arquivar (excluir) um bloco. Defina como false para restaurar um bloco.
    * `paragraph` (object, opcional): Conteúdo do parágrafo.
      ```json
      {
        "rich_text": [
          {
            "type": "text",
            "text": {
              "content": "Lacinato kale",
              "link": null
            }
          }
        ],
        "color": "default"
      }
      ```
    * `image` (object, opcional): Bloco de imagem.
      ```json
      {
        "type": "external",
        "external": {
          "url": "https://website.domain/images/image.png"
        }
      }
      ```
    * `bookmark` (object, opcional): Bloco de bookmark.
      ```json
      {
        "caption": [],
        "url": "https://companywebsite.com"
      }
      ```
    * `code` (object, opcional): Bloco de código.
      ```json
      {
        "rich_text": [
          {
            "type": "text",
            "text": {
              "content": "const a = 3"
            }
          }
        ],
        "language": "javascript"
      }
      ```
    * `pdf` (object, opcional): Bloco de PDF.
      ```json
      {
        "type": "external",
        "external": {
          "url": "https://website.domain/files/doc.pdf"
        }
      }
      ```
    * `table` (object, opcional): Bloco de Tabela.
      ```json
      {
        "table_width": 2,
        "has_column_header": false,
        "has_row_header": false
      }
      ```
    * `tableOfContent` (object, opcional): Bloco de Sumário.
      ```json
      {
        "color": "default"
      }
      ```
    * `additionalFields` (object, opcional): Blocos adicionais.
      ```json
      {
        "child_page": {
          "title": "Lacinato kale"
        },
        "child_database": {
          "title": "My database"
        }
      }
      ```
  </Accordion>

  <Accordion title="NOTION_GET_BLOCK_BY_ID">
    **Descrição:** Busca um bloco pelo ID no Notion.

    **Parâmetros:**

    * `blockId` (string, obrigatório): Block ID - Especifique o ID do Bloco a ser buscado. (exemplo: "9bc30ad4-9373-46a5-84ab-0a7845ee52e6").
  </Accordion>

  <Accordion title="NOTION_DELETE_BLOCK">
    **Descrição:** Exclui um bloco no Notion.

    **Parâmetros:**

    * `blockId` (string, obrigatório): Block ID - Especifique o ID do Bloco a ser excluído. (exemplo: "9bc30ad4-9373-46a5-84ab-0a7845ee52e6").
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configuração Básica do Agente Notion

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Notion tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Notion capabilities
notion_agent = Agent(
    role="Documentation Manager",
    goal="Manage documentation and knowledge base in Notion efficiently",
    backstory="An AI assistant specialized in content management and documentation.",
    tools=[enterprise_tools]
)

# Task to create a meeting notes page
create_notes_task = Task(
    description="Create a new meeting notes page in the team database with today's date and agenda items",
    agent=notion_agent,
    expected_output="Meeting notes page created successfully with structured content"
)

# Run the task
crew = Crew(
    agents=[notion_agent],
    tasks=[create_notes_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Específicas do Notion

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Notion tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["notion_create_page", "notion_update_block", "notion_search_pages"]
)

content_manager = Agent(
    role="Content Manager",
    goal="Create and manage content pages efficiently",
    backstory="An AI assistant that focuses on content creation and management.",
    tools=enterprise_tools
)

# Task to manage content workflow
content_workflow = Task(
    description="Create a new project documentation page and add structured content blocks for requirements and specifications",
    agent=content_manager,
    expected_output="Project documentation created with organized content sections"
)

crew = Crew(
    agents=[content_manager],
    tasks=[content_workflow]
)

crew.kickoff()
```

### Gerenciamento de Base de Conhecimento

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

knowledge_curator = Agent(
    role="Knowledge Curator",
    goal="Curate and organize knowledge base content in Notion",
    backstory="An experienced knowledge manager who organizes and maintains comprehensive documentation.",
    tools=[enterprise_tools]
)

# Task to curate knowledge base
curation_task = Task(
    description="""
    1. Search for existing documentation pages related to our new product feature
    2. Create a comprehensive feature documentation page with proper structure
    3. Add code examples, images, and links to related resources
    4. Update existing pages with cross-references to the new documentation
    """,
    agent=knowledge_curator,
    expected_output="Feature documentation created and integrated with existing knowledge base"
)

crew = Crew(
    agents=[knowledge_curator],
    tasks=[curation_task]
)

crew.kickoff()
```

### Estrutura e Organização de Conteúdo

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

content_organizer = Agent(
    role="Content Organizer",
    goal="Organize and structure content blocks for optimal readability",
    backstory="An AI assistant that specializes in content structure and user experience.",
    tools=[enterprise_tools]
)

# Task to organize content structure
organization_task = Task(
    description="""
    1. Get content from existing project pages
    2. Analyze the structure and identify improvement opportunities
    3. Update content blocks to use proper headings, tables, and formatting
    4. Add table of contents and improve navigation between related pages
    5. Create templates for future documentation consistency
    """,
    agent=content_organizer,
    expected_output="Content reorganized with improved structure and navigation"
)

crew = Crew(
    agents=[content_organizer],
    tasks=[organization_task]
)

crew.kickoff()
```

### Fluxos de Trabalho de Documentação Automatizados

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

doc_automator = Agent(
    role="Documentation Automator",
    goal="Automate documentation workflows and maintenance",
    backstory="An AI assistant that automates repetitive documentation tasks.",
    tools=[enterprise_tools]
)

# Complex documentation automation task
automation_task = Task(
    description="""
    1. Search for pages that haven't been updated in the last 30 days
    2. Review and update outdated content blocks
    3. Create weekly team update pages with consistent formatting
    4. Add status indicators and progress tracking to project pages
    5. Generate monthly documentation health reports
    6. Archive completed project pages and organize them in archive sections
    """,
    agent=doc_automator,
    expected_output="Documentation automated with updated content, weekly reports, and organized archives"
)

crew = Crew(
    agents=[doc_automator],
    tasks=[automation_task]
)

crew.kickoff()
```

## Solução de Problemas

### Problemas Comuns

**Erros de Permissão**

* Certifique-se de que sua conta Notion possui acesso de edição ao workspace desejado
* Verifique se a conexão OAuth inclui os escopos necessários para a API do Notion
* Confira se as páginas e bancos de dados estão compartilhados com a integração autenticada

**IDs de Página e Bloco Inválidos**

* Revise os IDs de página e bloco para garantir que estejam no formato UUID correto
* Garanta que as páginas e blocos referenciados existem e são acessíveis
* Verifique se os IDs da página ou banco de dados pai são válidos ao criar novas páginas

**Problemas com Schema de Propriedades**

* Assegure que as propriedades da página correspondem ao schema do banco de dados ao criar páginas em bancos de dados
* Verifique se os nomes e tipos das propriedades estão corretos para o banco de dados alvo
* Confirme que as propriedades obrigatórias estão incluídas ao criar ou atualizar páginas

**Estrutura dos Blocos de Conteúdo**

* Assegure que o conteúdo dos blocos segue as especificações de rich text do Notion
* Verifique se estruturas aninhadas de blocos estão devidamente formatadas
* Confira se URLs de mídias são acessíveis e estão corretamente formatadas

**Problemas de Pesquisa e Filtros**

* Certifique-se de que as queries de pesquisa estão devidamente formatadas e não estão vazias
* Use nomes de campos válidos em fórmulas de filtro: `query`, `filter.value`, `direction`, `page_size`
* Teste pesquisas simples antes de construir condições de filtro mais complexas

**Relacionamentos Pai-Filho**

* Verifique se a página ou banco de dados pai existe antes de criar páginas filhas
* Assegure que existam permissões apropriadas para o container pai
* Confirme que os schemas do banco permitem definir as propriedades desejadas

**Rich Text e Conteúdo de Mídia**

* Assegure que URLs para imagens externas, PDFs e bookmarks sejam acessíveis
* Verifique se a formatação rich text segue as especificações da API do Notion
* Confira se os tipos de linguagem nos blocos de código são suportados pelo Notion

**Operações de Arquivamento e Exclusão**

* Entenda a diferença entre arquivar (reversível) e excluir (permanente)
* Certifique-se de ter permissões para arquivar ou excluir o conteúdo desejado
* Tenha cuidado com operações em massa que possam afetar múltiplas páginas ou blocos

### Obtendo Ajuda

<Card title="Precisa de ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nosso time de suporte para auxílio na configuração ou solução de problemas com a integração Notion.
</Card>


# Integração com Salesforce
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/salesforce

Automação de vendas e CRM com integração Salesforce para CrewAI.

## Visão Geral

Permita que seus agentes gerenciem relacionamentos com clientes, processos de vendas e dados através do Salesforce. Crie e atualize registros, gerencie leads e oportunidades, execute consultas SOQL e otimize seus fluxos de trabalho de CRM com automação potencializada por IA.

## Pré-requisitos

Antes de usar a integração Salesforce, certifique-se de que você possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Uma conta Salesforce com permissões apropriadas
* Sua conta Salesforce conectada via a [página de Integrações](https://app.crewai.com/integrations)

## Ferramentas Disponíveis

### **Gerenciamento de Registros**

<AccordionGroup>
  <Accordion title="SALESFORCE_CREATE_RECORD_CONTACT">
    **Descrição:** Crie um novo registro de Contato no Salesforce.

    **Parâmetros:**

    * `FirstName` (string, opcional): Primeiro nome
    * `LastName` (string, obrigatório): Sobrenome - Este campo é obrigatório
    * `accountId` (string, opcional): ID da Conta - Conta à qual o contato pertence
    * `Email` (string, opcional): Endereço de e-mail
    * `Title` (string, opcional): Cargo do contato, como CEO ou Vice-presidente
    * `Description` (string, opcional): Descrição do contato
    * `additionalFields` (object, opcional): Campos adicionais no formato JSON para campos personalizados de Contato
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_RECORD_LEAD">
    **Descrição:** Crie um novo registro de Lead no Salesforce.

    **Parâmetros:**

    * `FirstName` (string, opcional): Primeiro nome
    * `LastName` (string, obrigatório): Sobrenome - Este campo é obrigatório
    * `Company` (string, obrigatório): Empresa - Este campo é obrigatório
    * `Email` (string, opcional): Endereço de e-mail
    * `Phone` (string, opcional): Número de telefone
    * `Website` (string, opcional): URL do site
    * `Title` (string, opcional): Cargo do contato, como CEO ou Vice-presidente
    * `Status` (string, opcional): Status do Lead - Use as Configurações de Workflow do Connect Portal para selecionar o status do Lead
    * `Description` (string, opcional): Descrição do lead
    * `additionalFields` (object, opcional): Campos adicionais no formato JSON para campos personalizados de Lead
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_RECORD_OPPORTUNITY">
    **Descrição:** Crie um novo registro de Oportunidade no Salesforce.

    **Parâmetros:**

    * `Name` (string, obrigatório): Nome da Oportunidade - Este campo é obrigatório
    * `StageName` (string, opcional): Estágio da Oportunidade - Use as Configurações de Workflow do Connect Portal para selecionar o estágio
    * `CloseDate` (string, opcional): Data de fechamento no formato YYYY-MM-DD - Padrão para 30 dias a partir da data atual
    * `AccountId` (string, opcional): Conta à qual a Oportunidade pertence
    * `Amount` (string, opcional): Valor total estimado da venda
    * `Description` (string, opcional): Descrição da oportunidade
    * `OwnerId` (string, opcional): Usuário Salesforce designado para esta Oportunidade
    * `NextStep` (string, opcional): Descrição da próxima tarefa no fechamento da Oportunidade
    * `additionalFields` (object, opcional): Campos adicionais no formato JSON para campos personalizados de Oportunidade
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_RECORD_TASK">
    **Descrição:** Crie um novo registro de Tarefa no Salesforce.

    **Parâmetros:**

    * `whatId` (string, opcional): Relacionado ao ID - ID da Conta ou Oportunidade relacionada à Tarefa
    * `whoId` (string, opcional): ID do Nome - ID do Contato ou Lead relacionado à Tarefa
    * `subject` (string, obrigatório): Assunto da tarefa
    * `activityDate` (string, opcional): Data da Atividade no formato YYYY-MM-DD
    * `description` (string, opcional): Descrição da tarefa
    * `taskSubtype` (string, obrigatório): Subtipo da Tarefa - Opções: task, email, listEmail, call
    * `Status` (string, opcional): Status - Opções: Not Started, In Progress, Completed
    * `ownerId` (string, opcional): ID do responsável - Usuário Salesforce designado para a Tarefa
    * `callDurationInSeconds` (string, opcional): Duração da chamada em segundos
    * `isReminderSet` (boolean, opcional): Se o lembrete está definido
    * `reminderDateTime` (string, opcional): Data/Hora do lembrete no formato ISO
    * `additionalFields` (object, opcional): Campos adicionais no formato JSON para campos personalizados de Tarefa
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_RECORD_ACCOUNT">
    **Descrição:** Crie um novo registro de Conta no Salesforce.

    **Parâmetros:**

    * `Name` (string, obrigatório): Nome da Conta - Este campo é obrigatório
    * `OwnerId` (string, opcional): Usuário Salesforce responsável por esta Conta
    * `Website` (string, opcional): URL do site
    * `Phone` (string, opcional): Número de telefone
    * `Description` (string, opcional): Descrição da conta
    * `additionalFields` (object, opcional): Campos adicionais no formato JSON para campos personalizados de Conta
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_RECORD_ANY">
    **Descrição:** Crie um registro de qualquer tipo de objeto no Salesforce.

    **Nota:** Esta é uma ferramenta flexível para criar registros de tipos de objetos personalizados ou desconhecidos.
  </Accordion>
</AccordionGroup>

### **Atualização de Registros**

<AccordionGroup>
  <Accordion title="SALESFORCE_UPDATE_RECORD_CONTACT">
    **Descrição:** Atualize um registro de Contato existente no Salesforce.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID do registro a ser atualizado
    * `FirstName` (string, opcional): Primeiro nome
    * `LastName` (string, opcional): Sobrenome
    * `accountId` (string, opcional): ID da Conta à qual o contato pertence
    * `Email` (string, opcional): Endereço de e-mail
    * `Title` (string, opcional): Cargo do contato
    * `Description` (string, opcional): Descrição do contato
    * `additionalFields` (object, opcional): Campos adicionais no formato JSON para campos personalizados de Contato
  </Accordion>

  <Accordion title="SALESFORCE_UPDATE_RECORD_LEAD">
    **Descrição:** Atualize um registro de Lead existente no Salesforce.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID do registro a ser atualizado
    * `FirstName` (string, opcional): Primeiro nome
    * `LastName` (string, opcional): Sobrenome
    * `Company` (string, opcional): Nome da empresa
    * `Email` (string, opcional): Endereço de e-mail
    * `Phone` (string, opcional): Número de telefone
    * `Website` (string, opcional): URL do site
    * `Title` (string, opcional): Cargo do contato
    * `Status` (string, opcional): Status do Lead
    * `Description` (string, opcional): Descrição do lead
    * `additionalFields` (object, opcional): Campos adicionais no formato JSON para campos personalizados de Lead
  </Accordion>

  <Accordion title="SALESFORCE_UPDATE_RECORD_OPPORTUNITY">
    **Descrição:** Atualize um registro de Oportunidade existente no Salesforce.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID do registro a ser atualizado
    * `Name` (string, opcional): Nome da Oportunidade
    * `StageName` (string, opcional): Estágio da oportunidade
    * `CloseDate` (string, opcional): Data de fechamento no formato YYYY-MM-DD
    * `AccountId` (string, opcional): Conta à qual a Oportunidade pertence
    * `Amount` (string, opcional): Valor total estimado da venda
    * `Description` (string, opcional): Descrição da oportunidade
    * `OwnerId` (string, opcional): Usuário Salesforce responsável por esta Oportunidade
    * `NextStep` (string, opcional): Descrição da próxima tarefa no fechamento da Oportunidade
    * `additionalFields` (object, opcional): Campos adicionais no formato JSON para campos personalizados de Oportunidade
  </Accordion>

  <Accordion title="SALESFORCE_UPDATE_RECORD_TASK">
    **Descrição:** Atualize um registro de Tarefa existente no Salesforce.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID do registro a ser atualizado
    * `whatId` (string, opcional): Relacionado ao ID - ID da Conta ou Oportunidade relacionada
    * `whoId` (string, opcional): ID do Nome - ID do Contato ou Lead relacionado à Tarefa
    * `subject` (string, opcional): Assunto da tarefa
    * `activityDate` (string, opcional): Data da Atividade no formato YYYY-MM-DD
    * `description` (string, opcional): Descrição da tarefa
    * `Status` (string, opcional): Status - Opções: Not Started, In Progress, Completed
    * `ownerId` (string, opcional): ID do responsável - Usuário Salesforce designado para a Tarefa
    * `callDurationInSeconds` (string, opcional): Duração da chamada em segundos
    * `isReminderSet` (boolean, opcional): Se o lembrete está definido
    * `reminderDateTime` (string, opcional): Data/Hora do lembrete em formato ISO
    * `additionalFields` (object, opcional): Campos adicionais no formato JSON para campos personalizados de Tarefa
  </Accordion>

  <Accordion title="SALESFORCE_UPDATE_RECORD_ACCOUNT">
    **Descrição:** Atualize um registro de Conta existente no Salesforce.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID do registro a ser atualizado
    * `Name` (string, opcional): Nome da Conta
    * `OwnerId` (string, opcional): Usuário Salesforce responsável por esta Conta
    * `Website` (string, opcional): URL do site
    * `Phone` (string, opcional): Número de telefone
    * `Description` (string, opcional): Descrição da conta
    * `additionalFields` (object, opcional): Campos adicionais no formato JSON para campos personalizados de Conta
  </Accordion>

  <Accordion title="SALESFORCE_UPDATE_RECORD_ANY">
    **Descrição:** Atualize um registro de qualquer tipo de objeto no Salesforce.

    **Nota:** Esta é uma ferramenta flexível para atualizar registros de tipos de objetos personalizados ou desconhecidos.
  </Accordion>
</AccordionGroup>

### **Recuperação de Registros**

<AccordionGroup>
  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_CONTACT">
    **Descrição:** Obtenha um registro de Contato pelo seu ID.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID do registro do Contato
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_LEAD">
    **Descrição:** Obtenha um registro de Lead pelo seu ID.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID do registro do Lead
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_OPPORTUNITY">
    **Descrição:** Obtenha um registro de Oportunidade pelo seu ID.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID do registro da Oportunidade
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_TASK">
    **Descrição:** Obtenha um registro de Tarefa pelo seu ID.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID do registro da Tarefa
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_ACCOUNT">
    **Descrição:** Obtenha um registro de Conta pelo seu ID.

    **Parâmetros:**

    * `recordId` (string, obrigatório): ID do registro da Conta
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_ANY">
    **Descrição:** Obtenha um registro de qualquer tipo de objeto pelo seu ID.

    **Parâmetros:**

    * `recordType` (string, obrigatório): Tipo do registro (ex.: "CustomObject\_\_c")
    * `recordId` (string, obrigatório): ID do registro
  </Accordion>
</AccordionGroup>

### **Busca de Registros**

<AccordionGroup>
  <Accordion title="SALESFORCE_SEARCH_RECORDS_CONTACT">
    **Descrição:** Pesquise registros de Contato com filtragem avançada.

    **Parâmetros:**

    * `filterFormula` (object, opcional): Filtro avançado em forma normal disjuntiva com operadores específicos de campo
    * `sortBy` (string, opcional): Campo para ordenação (ex.: "CreatedDate")
    * `sortDirection` (string, opcional): Direção da ordenação - Opções: ASC, DESC
    * `includeAllFields` (boolean, opcional): Incluir todos os campos nos resultados
    * `paginationParameters` (object, opcional): Configurações de paginação com pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_SEARCH_RECORDS_LEAD">
    **Descrição:** Pesquise registros de Lead com filtragem avançada.

    **Parâmetros:**

    * `filterFormula` (object, opcional): Filtro avançado em forma normal disjuntiva com operadores específicos de campo
    * `sortBy` (string, opcional): Campo para ordenação (ex.: "CreatedDate")
    * `sortDirection` (string, opcional): Direção da ordenação - Opções: ASC, DESC
    * `includeAllFields` (boolean, opcional): Incluir todos os campos nos resultados
    * `paginationParameters` (object, opcional): Configurações de paginação com pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_SEARCH_RECORDS_OPPORTUNITY">
    **Descrição:** Pesquise registros de Oportunidade com filtragem avançada.

    **Parâmetros:**

    * `filterFormula` (object, opcional): Filtro avançado em forma normal disjuntiva com operadores específicos de campo
    * `sortBy` (string, opcional): Campo para ordenação (ex.: "CreatedDate")
    * `sortDirection` (string, opcional): Direção da ordenação - Opções: ASC, DESC
    * `includeAllFields` (boolean, opcional): Incluir todos os campos nos resultados
    * `paginationParameters` (object, opcional): Configurações de paginação com pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_SEARCH_RECORDS_TASK">
    **Descrição:** Pesquise registros de Tarefa com filtragem avançada.

    **Parâmetros:**

    * `filterFormula` (object, opcional): Filtro avançado em forma normal disjuntiva com operadores específicos de campo
    * `sortBy` (string, opcional): Campo para ordenação (ex.: "CreatedDate")
    * `sortDirection` (string, opcional): Direção da ordenação - Opções: ASC, DESC
    * `includeAllFields` (boolean, opcional): Incluir todos os campos nos resultados
    * `paginationParameters` (object, opcional): Configurações de paginação com pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_SEARCH_RECORDS_ACCOUNT">
    **Descrição:** Pesquise registros de Conta com filtragem avançada.

    **Parâmetros:**

    * `filterFormula` (object, opcional): Filtro avançado em forma normal disjuntiva com operadores específicos de campo
    * `sortBy` (string, opcional): Campo para ordenação (ex.: "CreatedDate")
    * `sortDirection` (string, opcional): Direção da ordenação - Opções: ASC, DESC
    * `includeAllFields` (boolean, opcional): Incluir todos os campos nos resultados
    * `paginationParameters` (object, opcional): Configurações de paginação com pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_SEARCH_RECORDS_ANY">
    **Descrição:** Pesquise registros de qualquer tipo de objeto.

    **Parâmetros:**

    * `recordType` (string, obrigatório): Tipo de registro para buscar
    * `filterFormula` (string, opcional): Critérios de busca por filtro
    * `includeAllFields` (boolean, opcional): Incluir todos os campos nos resultados
    * `paginationParameters` (object, opcional): Configurações de paginação com pageCursor
  </Accordion>
</AccordionGroup>

### **Recuperação por List View**

<AccordionGroup>
  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_CONTACT">
    **Descrição:** Obtenha registros de Contato de um List View específico.

    **Parâmetros:**

    * `listViewId` (string, obrigatório): ID do List View
    * `paginationParameters` (object, opcional): Configurações de paginação com pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_LEAD">
    **Descrição:** Obtenha registros de Lead de um List View específico.

    **Parâmetros:**

    * `listViewId` (string, obrigatório): ID do List View
    * `paginationParameters` (object, opcional): Configurações de paginação com pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_OPPORTUNITY">
    **Descrição:** Obtenha registros de Oportunidade de um List View específico.

    **Parâmetros:**

    * `listViewId` (string, obrigatório): ID do List View
    * `paginationParameters` (object, opcional): Configurações de paginação com pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_TASK">
    **Descrição:** Obtenha registros de Tarefa de um List View específico.

    **Parâmetros:**

    * `listViewId` (string, obrigatório): ID do List View
    * `paginationParameters` (object, opcional): Configurações de paginação com pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_ACCOUNT">
    **Descrição:** Obtenha registros de Conta de um List View específico.

    **Parâmetros:**

    * `listViewId` (string, obrigatório): ID do List View
    * `paginationParameters` (object, opcional): Configurações de paginação com pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_ANY">
    **Descrição:** Obtenha registros de qualquer tipo de objeto a partir de um List View específico.

    **Parâmetros:**

    * `recordType` (string, obrigatório): Tipo do registro
    * `listViewId` (string, obrigatório): ID do List View
    * `paginationParameters` (object, opcional): Configurações de paginação com pageCursor
  </Accordion>
</AccordionGroup>

### **Campos Personalizados**

<AccordionGroup>
  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_CONTACT">
    **Descrição:** Crie campos personalizados para objetos de Contato.

    **Parâmetros:**

    * `label` (string, obrigatório): Rótulo do campo para exibições e referência interna
    * `type` (string, obrigatório): Tipo do campo - Opções: Checkbox, Currency, Date, Email, Number, Percent, Phone, Picklist, MultiselectPicklist, Text, TextArea, LongTextArea, Html, Time, Url
    * `defaultCheckboxValue` (boolean, opcional): Valor padrão para campos checkbox
    * `length` (string, obrigatório): Comprimento para campos numéricos/texto
    * `decimalPlace` (string, obrigatório): Casas decimais para campos numéricos
    * `pickListValues` (string, obrigatório): Valores para campos picklist (separados por novas linhas)
    * `visibleLines` (string, obrigatório): Linhas visíveis para campos multiseleção/área de texto
    * `description` (string, opcional): Descrição do campo
    * `helperText` (string, opcional): Texto de ajuda exibido ao passar o mouse
    * `defaultFieldValue` (string, opcional): Valor padrão do campo
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_LEAD">
    **Descrição:** Crie campos personalizados para objetos de Lead.

    **Parâmetros:**

    * `label` (string, obrigatório): Rótulo do campo para exibições e referência interna
    * `type` (string, obrigatório): Tipo do campo - Opções: Checkbox, Currency, Date, Email, Number, Percent, Phone, Picklist, MultiselectPicklist, Text, TextArea, LongTextArea, Html, Time, Url
    * `defaultCheckboxValue` (boolean, opcional): Valor padrão para campos checkbox
    * `length` (string, obrigatório): Comprimento para campos numéricos/texto
    * `decimalPlace` (string, obrigatório): Casas decimais para campos numéricos
    * `pickListValues` (string, obrigatório): Valores para campos picklist (separados por novas linhas)
    * `visibleLines` (string, obrigatório): Linhas visíveis para campos multiseleção/área de texto
    * `description` (string, opcional): Descrição do campo
    * `helperText` (string, opcional): Texto de ajuda exibido ao passar o mouse
    * `defaultFieldValue` (string, opcional): Valor padrão do campo
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_OPPORTUNITY">
    **Descrição:** Crie campos personalizados para objetos de Oportunidade.

    **Parâmetros:**

    * `label` (string, obrigatório): Rótulo do campo para exibições e referência interna
    * `type` (string, obrigatório): Tipo do campo - Opções: Checkbox, Currency, Date, Email, Number, Percent, Phone, Picklist, MultiselectPicklist, Text, TextArea, LongTextArea, Html, Time, Url
    * `defaultCheckboxValue` (boolean, opcional): Valor padrão para campos checkbox
    * `length` (string, obrigatório): Comprimento para campos numéricos/texto
    * `decimalPlace` (string, obrigatório): Casas decimais para campos numéricos
    * `pickListValues` (string, obrigatório): Valores para campos picklist (separados por novas linhas)
    * `visibleLines` (string, obrigatório): Linhas visíveis para campos multiseleção/área de texto
    * `description` (string, opcional): Descrição do campo
    * `helperText` (string, opcional): Texto de ajuda exibido ao passar o mouse
    * `defaultFieldValue` (string, opcional): Valor padrão do campo
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_TASK">
    **Descrição:** Crie campos personalizados para objetos de Tarefa.

    **Parâmetros:**

    * `label` (string, obrigatório): Rótulo do campo para exibições e referência interna
    * `type` (string, obrigatório): Tipo do campo - Opções: Checkbox, Currency, Date, Email, Number, Percent, Phone, Picklist, MultiselectPicklist, Text, TextArea, Time, Url
    * `defaultCheckboxValue` (boolean, opcional): Valor padrão para campos checkbox
    * `length` (string, obrigatório): Comprimento para campos numéricos/texto
    * `decimalPlace` (string, obrigatório): Casas decimais para campos numéricos
    * `pickListValues` (string, obrigatório): Valores para campos picklist (separados por novas linhas)
    * `visibleLines` (string, obrigatório): Linhas visíveis para campos multiseleção
    * `description` (string, opcional): Descrição do campo
    * `helperText` (string, opcional): Texto de ajuda exibido ao passar o mouse
    * `defaultFieldValue` (string, opcional): Valor padrão do campo
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_ACCOUNT">
    **Descrição:** Crie campos personalizados para objetos de Conta.

    **Parâmetros:**

    * `label` (string, obrigatório): Rótulo do campo para exibições e referência interna
    * `type` (string, obrigatório): Tipo do campo - Opções: Checkbox, Currency, Date, Email, Number, Percent, Phone, Picklist, MultiselectPicklist, Text, TextArea, LongTextArea, Html, Time, Url
    * `defaultCheckboxValue` (boolean, opcional): Valor padrão para campos checkbox
    * `length` (string, obrigatório): Comprimento para campos numéricos/texto
    * `decimalPlace` (string, obrigatório): Casas decimais para campos numéricos
    * `pickListValues` (string, obrigatório): Valores para campos picklist (separados por novas linhas)
    * `visibleLines` (string, obrigatório): Linhas visíveis para campos multiseleção/área de texto
    * `description` (string, opcional): Descrição do campo
    * `helperText` (string, opcional): Texto de ajuda exibido ao passar o mouse
    * `defaultFieldValue` (string, opcional): Valor padrão do campo
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_ANY">
    **Descrição:** Crie campos personalizados para qualquer tipo de objeto.

    **Nota:** Esta é uma ferramenta flexível para criar campos personalizados para tipos de objetos personalizados ou desconhecidos.
  </Accordion>
</AccordionGroup>

### **Operações Avançadas**

<AccordionGroup>
  <Accordion title="SALESFORCE_WRITE_SOQL_QUERY">
    **Descrição:** Execute consultas SOQL personalizadas em seus dados do Salesforce.

    **Parâmetros:**

    * `query` (string, obrigatório): Consulta SOQL (ex.: "SELECT Id, Name FROM Account WHERE Name = 'Exemplo'")
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_OBJECT">
    **Descrição:** Crie um novo objeto personalizado no Salesforce.

    **Parâmetros:**

    * `label` (string, obrigatório): Rótulo do objeto para abas, layouts de página e relatórios
    * `pluralLabel` (string, obrigatório): Rótulo plural (ex.: "Contas")
    * `description` (string, opcional): Uma descrição do Objeto Personalizado
    * `recordName` (string, obrigatório): Nome do registro exibido em layouts e buscas (ex.: "Nome da Conta")
  </Accordion>

  <Accordion title="SALESFORCE_DESCRIBE_ACTION_SCHEMA">
    **Descrição:** Obtenha o schema esperado para operações em tipos de objetos específicos.

    **Parâmetros:**

    * `recordType` (string, obrigatório): Tipo de registro a ser detalhado
    * `operation` (string, obrigatório): Tipo de Operação (ex.: "CREATE\_RECORD" ou "UPDATE\_RECORD")

    **Nota:** Use esta função primeiro ao trabalhar com objetos personalizados para entender seu schema antes de realizar operações.
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configuração Básica de um Agente Salesforce

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Obtenha ferramentas enterprise (ferramentas Salesforce serão incluídas)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Crie um agente com capacidades Salesforce
salesforce_agent = Agent(
    role="CRM Manager",
    goal="Manage customer relationships and sales processes efficiently",
    backstory="An AI assistant specialized in CRM operations and sales automation.",
    tools=[enterprise_tools]
)

# Task to create a new lead
create_lead_task = Task(
    description="Create a new lead for John Doe from Example Corp with email john.doe@example.com",
    agent=salesforce_agent,
    expected_output="Lead created successfully with lead ID"
)

# Run the task
crew = Crew(
    agents=[salesforce_agent],
    tasks=[create_lead_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Salesforce Específicas

```python
from crewai_tools import CrewaiEnterpriseTools

# Obtenha apenas ferramentas Salesforce específicas
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["salesforce_create_record_lead", "salesforce_update_record_opportunity", "salesforce_search_records_contact"]
)

sales_manager = Agent(
    role="Sales Manager",
    goal="Manage leads and opportunities in the sales pipeline",
    backstory="An experienced sales manager who handles lead qualification and opportunity management.",
    tools=enterprise_tools
)

# Task to manage sales pipeline
pipeline_task = Task(
    description="Create a qualified lead and convert it to an opportunity with $50,000 value",
    agent=sales_manager,
    expected_output="Lead created and opportunity established successfully"
)

crew = Crew(
    agents=[sales_manager],
    tasks=[pipeline_task]
)

crew.kickoff()
```

### Gerenciamento de Contatos e Contas

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

account_manager = Agent(
    role="Account Manager",
    goal="Manage customer accounts and maintain strong relationships",
    backstory="An AI assistant that specializes in account management and customer relationship building.",
    tools=[enterprise_tools]
)

# Task to manage customer accounts
account_task = Task(
    description="""
    1. Create a new account for TechCorp Inc.
    2. Add John Doe as the primary contact for this account
    3. Create a follow-up task for next week to check on their project status
    """,
    agent=account_manager,
    expected_output="Account, contact, and follow-up task created successfully"
)

crew = Crew(
    agents=[account_manager],
    tasks=[account_task]
)

crew.kickoff()
```

### Consultas SOQL Avançadas e Relatórios

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

data_analyst = Agent(
    role="Sales Data Analyst",
    goal="Generate insights from Salesforce data using SOQL queries",
    backstory="An analytical AI that excels at extracting meaningful insights from CRM data.",
    tools=[enterprise_tools]
)

# Complex task involving SOQL queries and data analysis
analysis_task = Task(
    description="""
    1. Execute a SOQL query to find all opportunities closing this quarter
    2. Search for contacts at companies with opportunities over $100K
    3. Create a summary report of the sales pipeline status
    4. Update high-value opportunities with next steps
    """,
    agent=data_analyst,
    expected_output="Comprehensive sales pipeline analysis with actionable insights"
)

crew = Crew(
    agents=[data_analyst],
    tasks=[analysis_task]
)

crew.kickoff()
```

Esta documentação abrangente cobre todas as ferramentas Salesforce organizadas por funcionalidade, facilitando que os usuários encontrem as operações específicas de que necessitam para automação de seu CRM.

### Precisa de ajuda?

<Card title="Precisa de ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para assistência na configuração da integração com Salesforce ou para resolução de problemas.
</Card>


# Integração com Shopify
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/shopify

Gestão de e-commerce e loja online com integração do Shopify para CrewAI.

## Visão Geral

Permita que seus agentes gerenciem operações de e-commerce através do Shopify. Gerencie clientes, pedidos, produtos, inventário e análises da loja para otimizar sua empresa online com automação alimentada por IA.

## Pré-requisitos

Antes de utilizar a integração com o Shopify, certifique-se de que você possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com uma assinatura ativa
* Uma loja Shopify com permissões administrativas adequadas
* Sua loja Shopify conectada através da [página de Integrações](https://app.crewai.com/integrations)

## Ferramentas Disponíveis

### **Gerenciamento de Clientes**

<AccordionGroup>
  <Accordion title="SHOPIFY_GET_CUSTOMERS">
    **Descrição:** Recupera uma lista de clientes da sua loja Shopify.

    **Parâmetros:**

    * `customerIds` (string, opcional): Lista de IDs de clientes separada por vírgula para filtrar (exemplo: "207119551, 207119552")
    * `createdAtMin` (string, opcional): Retorna somente clientes criados após esta data (ISO ou timestamp Unix)
    * `createdAtMax` (string, opcional): Retorna somente clientes criados antes desta data (ISO ou timestamp Unix)
    * `updatedAtMin` (string, opcional): Retorna somente clientes atualizados após esta data (ISO ou timestamp Unix)
    * `updatedAtMax` (string, opcional): Retorna somente clientes atualizados antes desta data (ISO ou timestamp Unix)
    * `limit` (string, opcional): Número máximo de clientes a retornar (padrão 250)
  </Accordion>

  <Accordion title="SHOPIFY_SEARCH_CUSTOMERS">
    **Descrição:** Pesquise por clientes usando critérios de filtragem avançados.

    **Parâmetros:**

    * `filterFormula` (object, opcional): Filtro avançado em forma normal disjuntiva com operadores específicos de campo
    * `limit` (string, opcional): Número máximo de clientes a retornar (padrão 250)
  </Accordion>

  <Accordion title="SHOPIFY_CREATE_CUSTOMER">
    **Descrição:** Crie um novo cliente em sua loja Shopify.

    **Parâmetros:**

    * `firstName` (string, obrigatório): Primeiro nome do cliente
    * `lastName` (string, obrigatório): Sobrenome do cliente
    * `email` (string, obrigatório): Endereço de e-mail do cliente
    * `company` (string, opcional): Nome da empresa
    * `streetAddressLine1` (string, opcional): Endereço
    * `streetAddressLine2` (string, opcional): Complemento do endereço
    * `city` (string, opcional): Cidade
    * `state` (string, opcional): Estado ou código da província
    * `country` (string, opcional): País
    * `zipCode` (string, opcional): CEP
    * `phone` (string, opcional): Telefone
    * `tags` (string, opcional): Tags como array ou lista separada por vírgula
    * `note` (string, opcional): Observação sobre o cliente
    * `sendEmailInvite` (boolean, opcional): Se deve enviar convite por e-mail
    * `metafields` (object, opcional): Metacampos adicionais em formato JSON
  </Accordion>

  <Accordion title="SHOPIFY_UPDATE_CUSTOMER">
    **Descrição:** Atualize um cliente existente em sua loja Shopify.

    **Parâmetros:**

    * `customerId` (string, obrigatório): O ID do cliente a ser atualizado
    * `firstName` (string, opcional): Primeiro nome do cliente
    * `lastName` (string, opcional): Sobrenome do cliente
    * `email` (string, opcional): Endereço de e-mail do cliente
    * `company` (string, opcional): Nome da empresa
    * `streetAddressLine1` (string, opcional): Endereço
    * `streetAddressLine2` (string, opcional): Complemento do endereço
    * `city` (string, opcional): Cidade
    * `state` (string, opcional): Estado ou código da província
    * `country` (string, opcional): País
    * `zipCode` (string, opcional): CEP
    * `phone` (string, opcional): Telefone
    * `tags` (string, opcional): Tags como array ou lista separada por vírgula
    * `note` (string, opcional): Observação sobre o cliente
    * `sendEmailInvite` (boolean, opcional): Se deve enviar convite por e-mail
    * `metafields` (object, opcional): Metacampos adicionais em formato JSON
  </Accordion>
</AccordionGroup>

### **Gestão de Pedidos**

<AccordionGroup>
  <Accordion title="SHOPIFY_GET_ORDERS">
    **Descrição:** Recupera uma lista de pedidos da sua loja Shopify.

    **Parâmetros:**

    * `orderIds` (string, opcional): Lista de IDs de pedidos separada por vírgula para filtrar (exemplo: "450789469, 450789470")
    * `createdAtMin` (string, opcional): Retorna somente pedidos criados após esta data (ISO ou timestamp Unix)
    * `createdAtMax` (string, opcional): Retorna somente pedidos criados antes desta data (ISO ou timestamp Unix)
    * `updatedAtMin` (string, opcional): Retorna somente pedidos atualizados após esta data (ISO ou timestamp Unix)
    * `updatedAtMax` (string, opcional): Retorna somente pedidos atualizados antes desta data (ISO ou timestamp Unix)
    * `limit` (string, opcional): Número máximo de pedidos a retornar (padrão 250)
  </Accordion>

  <Accordion title="SHOPIFY_CREATE_ORDER">
    **Descrição:** Crie um novo pedido em sua loja Shopify.

    **Parâmetros:**

    * `email` (string, obrigatório): Endereço de e-mail do cliente
    * `lineItems` (object, obrigatório): Itens do pedido em formato JSON com título, preço, quantidade e variant\_id
    * `sendReceipt` (boolean, opcional): Se deve enviar recibo do pedido
    * `fulfillmentStatus` (string, opcional): Status de atendimento - Opções: fulfilled, null, partial, restocked
    * `financialStatus` (string, opcional): Status financeiro - Opções: pending, authorized, partially\_paid, paid, partially\_refunded, refunded, voided
    * `inventoryBehaviour` (string, opcional): Comportamento de inventário - Opções: bypass, decrement\_ignoring\_policy, decrement\_obeying\_policy
    * `note` (string, opcional): Observação do pedido
  </Accordion>

  <Accordion title="SHOPIFY_UPDATE_ORDER">
    **Descrição:** Atualize um pedido existente em sua loja Shopify.

    **Parâmetros:**

    * `orderId` (string, obrigatório): O ID do pedido a ser atualizado
    * `email` (string, opcional): Endereço de e-mail do cliente
    * `lineItems` (object, opcional): Itens do pedido atualizados em formato JSON
    * `sendReceipt` (boolean, opcional): Se deve enviar recibo do pedido
    * `fulfillmentStatus` (string, opcional): Status de atendimento - Opções: fulfilled, null, partial, restocked
    * `financialStatus` (string, opcional): Status financeiro - Opções: pending, authorized, partially\_paid, paid, partially\_refunded, refunded, voided
    * `inventoryBehaviour` (string, opcional): Comportamento de inventário - Opções: bypass, decrement\_ignoring\_policy, decrement\_obeying\_policy
    * `note` (string, opcional): Observação do pedido
  </Accordion>

  <Accordion title="SHOPIFY_GET_ABANDONED_CARTS">
    **Descrição:** Recupera carrinhos abandonados da sua loja Shopify.

    **Parâmetros:**

    * `createdWithInLast` (string, opcional): Restringe os resultados para checkouts criados dentro do período especificado
    * `createdAfterId` (string, opcional): Restringe os resultados após o ID especificado
    * `status` (string, opcional): Mostra checkouts com o status especificado - Opções: open, closed (padrão open)
    * `createdAtMin` (string, opcional): Retorna somente carrinhos criados após esta data (ISO ou timestamp Unix)
    * `createdAtMax` (string, opcional): Retorna somente carrinhos criados antes desta data (ISO ou timestamp Unix)
    * `limit` (string, opcional): Número máximo de carrinhos a retornar (padrão 250)
  </Accordion>
</AccordionGroup>

### **Gestão de Produtos (REST API)**

<AccordionGroup>
  <Accordion title="SHOPIFY_GET_PRODUCTS">
    **Descrição:** Recupera uma lista de produtos da sua loja Shopify utilizando a REST API.

    **Parâmetros:**

    * `productIds` (string, opcional): Lista de IDs de produtos separada por vírgula para filtrar (exemplo: "632910392, 632910393")
    * `title` (string, opcional): Filtrar pelo título do produto
    * `productType` (string, opcional): Filtrar pelo tipo de produto
    * `vendor` (string, opcional): Filtrar por fornecedor
    * `status` (string, opcional): Filtrar por status - Opções: active, archived, draft
    * `createdAtMin` (string, opcional): Retorna somente produtos criados após esta data (ISO ou timestamp Unix)
    * `createdAtMax` (string, opcional): Retorna somente produtos criados antes desta data (ISO ou timestamp Unix)
    * `updatedAtMin` (string, opcional): Retorna somente produtos atualizados após esta data (ISO ou timestamp Unix)
    * `updatedAtMax` (string, opcional): Retorna somente produtos atualizados antes desta data (ISO ou timestamp Unix)
    * `limit` (string, opcional): Número máximo de produtos a retornar (padrão 250)
  </Accordion>

  <Accordion title="SHOPIFY_CREATE_PRODUCT">
    **Descrição:** Crie um novo produto em sua loja Shopify utilizando a REST API.

    **Parâmetros:**

    * `title` (string, obrigatório): Título do produto
    * `productType` (string, obrigatório): Tipo/categoria do produto
    * `vendor` (string, obrigatório): Fornecedor do produto
    * `productDescription` (string, opcional): Descrição do produto (aceita texto simples ou HTML)
    * `tags` (string, opcional): Tags do produto como array ou lista separada por vírgula
    * `price` (string, opcional): Preço do produto
    * `inventoryPolicy` (string, opcional): Política de estoque - Opções: deny, continue
    * `imageUrl` (string, opcional): URL da imagem do produto
    * `isPublished` (boolean, opcional): Se o produto está publicado
    * `publishToPointToSale` (boolean, opcional): Se deve publicar no ponto de venda
  </Accordion>

  <Accordion title="SHOPIFY_UPDATE_PRODUCT">
    **Descrição:** Atualize um produto existente em sua loja Shopify utilizando a REST API.

    **Parâmetros:**

    * `productId` (string, obrigatório): O ID do produto a ser atualizado
    * `title` (string, opcional): Título do produto
    * `productType` (string, opcional): Tipo/categoria do produto
    * `vendor` (string, opcional): Fornecedor do produto
    * `productDescription` (string, opcional): Descrição do produto (aceita texto simples ou HTML)
    * `tags` (string, opcional): Tags do produto como array ou lista separada por vírgula
    * `price` (string, opcional): Preço do produto
    * `inventoryPolicy` (string, opcional): Política de estoque - Opções: deny, continue
    * `imageUrl` (string, opcional): URL da imagem do produto
    * `isPublished` (boolean, opcional): Se o produto está publicado
    * `publishToPointToSale` (boolean, opcional): Se deve publicar no ponto de venda
  </Accordion>
</AccordionGroup>

### **Gestão de Produtos (GraphQL)**

<AccordionGroup>
  <Accordion title="SHOPIFY_GET_PRODUCTS_GRAPHQL">
    **Descrição:** Recupere produtos utilizando filtros avançados do GraphQL.

    **Parâmetros:**

    * `productFilterFormula` (object, opcional): Filtro avançado em forma normal disjuntiva com suporte a campos como id, title, vendor, status, handle, tag, created\_at, updated\_at, published\_at
  </Accordion>

  <Accordion title="SHOPIFY_CREATE_PRODUCT_GRAPHQL">
    **Descrição:** Crie um novo produto utilizando a API GraphQL com suporte aprimorado a mídias.

    **Parâmetros:**

    * `title` (string, obrigatório): Título do produto
    * `productType` (string, obrigatório): Tipo/categoria do produto
    * `vendor` (string, obrigatório): Fornecedor do produto
    * `productDescription` (string, opcional): Descrição do produto (aceita texto simples ou HTML)
    * `tags` (string, opcional): Tags do produto como array ou lista separada por vírgula
    * `media` (object, opcional): Objetos de mídia com texto alternativo, tipo de conteúdo e URL de origem
    * `additionalFields` (object, opcional): Campos adicionais do produto como status, requiresSellingPlan, giftCard
  </Accordion>

  <Accordion title="SHOPIFY_UPDATE_PRODUCT_GRAPHQL">
    **Descrição:** Atualize um produto existente utilizando a API GraphQL com suporte aprimorado a mídias.

    **Parâmetros:**

    * `productId` (string, obrigatório): O ID GraphQL do produto a ser atualizado (ex.: "gid://shopify/Product/913144112")
    * `title` (string, opcional): Título do produto
    * `productType` (string, opcional): Tipo/categoria do produto
    * `vendor` (string, opcional): Fornecedor do produto
    * `productDescription` (string, opcional): Descrição do produto (aceita texto simples ou HTML)
    * `tags` (string, opcional): Tags do produto como array ou lista separada por vírgula
    * `media` (object, opcional): Objetos de mídia atualizados com texto alternativo, tipo de conteúdo e URL de origem
    * `additionalFields` (object, opcional): Campos adicionais do produto como status, requiresSellingPlan, giftCard
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configuração Básica do Agente Shopify

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Shopify tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Shopify capabilities
shopify_agent = Agent(
    role="E-commerce Manager",
    goal="Manage online store operations and customer relationships efficiently",
    backstory="An AI assistant specialized in e-commerce operations and online store management.",
    tools=[enterprise_tools]
)

# Task to create a new customer
create_customer_task = Task(
    description="Create a new VIP customer Jane Smith with email jane.smith@example.com and phone +1-555-0123",
    agent=shopify_agent,
    expected_output="Customer created successfully with customer ID"
)

# Run the task
crew = Crew(
    agents=[shopify_agent],
    tasks=[create_customer_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Específicas do Shopify

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Shopify tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["shopify_create_customer", "shopify_create_order", "shopify_get_products"]
)

store_manager = Agent(
    role="Store Manager",
    goal="Manage customer orders and product catalog",
    backstory="An experienced store manager who handles customer relationships and inventory management.",
    tools=enterprise_tools
)

# Task to manage store operations
store_task = Task(
    description="Create a new customer and process their order for 2 Premium Coffee Mugs",
    agent=store_manager,
    expected_output="Customer created and order processed successfully"
)

crew = Crew(
    agents=[store_manager],
    tasks=[store_task]
)

crew.kickoff()
```

### Gestão de Produtos com GraphQL

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

product_manager = Agent(
    role="Product Manager",
    goal="Manage product catalog and inventory with advanced GraphQL capabilities",
    backstory="An AI assistant that specializes in product management and catalog optimization.",
    tools=[enterprise_tools]
)

# Task to manage product catalog
catalog_task = Task(
    description="""
    1. Create a new product "Premium Coffee Mug" from Coffee Co vendor
    2. Add high-quality product images and descriptions
    3. Search for similar products from the same vendor
    4. Update product tags and pricing strategy
    """,
    agent=product_manager,
    expected_output="Product created and catalog optimized successfully"
)

crew = Crew(
    agents=[product_manager],
    tasks=[catalog_task]
)

crew.kickoff()
```

### Análise de Pedidos e Clientes

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

analytics_agent = Agent(
    role="E-commerce Analyst",
    goal="Analyze customer behavior and order patterns to optimize store performance",
    backstory="An analytical AI that excels at extracting insights from e-commerce data.",
    tools=[enterprise_tools]
)

# Complex task involving multiple operations
analytics_task = Task(
    description="""
    1. Retrieve recent customer data and order history
    2. Identify abandoned carts from the last 7 days
    3. Analyze product performance and inventory levels
    4. Generate recommendations for customer retention
    """,
    agent=analytics_agent,
    expected_output="Comprehensive e-commerce analytics report with actionable insights"
)

crew = Crew(
    agents=[analytics_agent],
    tasks=[analytics_task]
)

crew.kickoff()
```

### Precisa de Ajuda?

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para assistência na configuração ou resolução de problemas de integração com o Shopify.
</Card>


# Integração com Slack
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/slack

Comunicação e colaboração em equipe com a integração Slack para CrewAI.

## Visão Geral

Permita que seus agentes gerenciem a comunicação da equipe pelo Slack. Envie mensagens, pesquise conversas, gerencie canais e coordene as atividades do time para otimizar os fluxos de colaboração com automação impulsionada por IA.

## Pré-requisitos

Antes de usar a integração com o Slack, certifique-se de que você tenha:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Um workspace do Slack com permissões apropriadas
* Seu workspace do Slack conectado por meio da [página de Integrações](https://app.crewai.com/integrations)

## Ferramentas Disponíveis

### **Gerenciamento de Usuários**

<AccordionGroup>
  <Accordion title="SLACK_LIST_MEMBERS">
    **Descrição:** Lista todos os membros de um canal do Slack.

    **Parâmetros:**

    * Nenhum parâmetro necessário – recupera todos os membros do canal
  </Accordion>

  <Accordion title="SLACK_GET_USER_BY_EMAIL">
    **Descrição:** Encontre um usuário no seu workspace do Slack pelo endereço de e-mail.

    **Parâmetros:**

    * `email` (string, obrigatório): O endereço de e-mail de um usuário do workspace
  </Accordion>

  <Accordion title="SLACK_GET_USERS_BY_NAME">
    **Descrição:** Pesquise usuários pelo nome ou nome de exibição.

    **Parâmetros:**

    * `name` (string, obrigatório): Nome real do usuário para a pesquisa
    * `displayName` (string, obrigatório): Nome de exibição do usuário para a pesquisa
    * `paginationParameters` (object, opcional): Configurações de paginação
      * `pageCursor` (string, opcional): Cursor de página para paginação
  </Accordion>
</AccordionGroup>

### **Gerenciamento de Canais**

<AccordionGroup>
  <Accordion title="SLACK_LIST_CHANNELS">
    **Descrição:** Lista todos os canais do seu workspace no Slack.

    **Parâmetros:**

    * Nenhum parâmetro necessário – recupera todos os canais acessíveis
  </Accordion>
</AccordionGroup>

### **Mensagens**

<AccordionGroup>
  <Accordion title="SLACK_SEND_MESSAGE">
    **Descrição:** Envie uma mensagem para um canal do Slack.

    **Parâmetros:**

    * `channel` (string, obrigatório): Nome ou ID do canal – Use as Configurações de Workflow do Connect Portal para que usuários selecionem o canal, ou insira o nome do canal para criar um novo
    * `message` (string, obrigatório): Texto da mensagem a ser enviada
    * `botName` (string, obrigatório): Nome do bot que enviará a mensagem
    * `botIcon` (string, obrigatório): Ícone do bot – Pode ser uma URL de imagem ou um emoji (ex.: ":dog:")
    * `blocks` (object, opcional): JSON do Slack Block Kit para mensagens ricas com anexos e elementos interativos
    * `authenticatedUser` (boolean, opcional): Se verdadeiro, a mensagem aparecerá como enviada pelo seu usuário autenticado do Slack ao invés do aplicativo (por padrão é falso)
  </Accordion>

  <Accordion title="SLACK_SEND_DIRECT_MESSAGE">
    **Descrição:** Envie uma mensagem direta para um usuário específico no Slack.

    **Parâmetros:**

    * `memberId` (string, obrigatório): ID do usuário destinatário – Use as Configurações de Workflow do Connect Portal para que usuários selecionem um membro
    * `message` (string, obrigatório): Texto da mensagem a ser enviada
    * `botName` (string, obrigatório): Nome do bot que enviará a mensagem
    * `botIcon` (string, obrigatório): Ícone do bot – Pode ser uma URL de imagem ou um emoji (ex.: ":dog:")
    * `blocks` (object, opcional): JSON do Slack Block Kit para formatação rica com anexos e elementos interativos
    * `authenticatedUser` (boolean, opcional): Se verdadeiro, a mensagem aparecerá como enviada pelo seu usuário autenticado do Slack (padrão é falso)
  </Accordion>
</AccordionGroup>

### **Pesquisa & Descoberta**

<AccordionGroup>
  <Accordion title="SLACK_SEARCH_MESSAGES">
    **Descrição:** Procure por mensagens em todo o seu workspace do Slack.

    **Parâmetros:**

    * `query` (string, obrigatório): Consulta de pesquisa usando a sintaxe do Slack para encontrar mensagens que correspondam aos critérios especificados

    **Exemplos de Consultas de Pesquisa:**

    * `"project update"` – Busca mensagens contendo "project update"
    * `from:@john in:#general` – Busca mensagens do John no canal #general
    * `has:link after:2023-01-01` – Busca mensagens com links após 1º de janeiro de 2023
    * `in:@channel before:yesterday` – Busca mensagens em um canal específico antes de ontem
  </Accordion>
</AccordionGroup>

## Integração com Block Kit

O Block Kit do Slack permite criar mensagens ricas e interativas. Veja alguns exemplos de como usar o parâmetro `blocks`:

### Texto Simples com Anexo

```json
[
  {
    "text": "I am a test message",
    "attachments": [
      {
        "text": "And here's an attachment!"
      }
    ]
  }
]
```

### Formatação Rica com Seções

```json
[
  {
    "type": "section",
    "text": {
      "type": "mrkdwn",
      "text": "*Project Update*\nStatus: ✅ Complete"
    }
  },
  {
    "type": "divider"
  },
  {
    "type": "section",
    "text": {
      "type": "plain_text",
      "text": "All tasks have been completed successfully."
    }
  }
]
```

## Exemplos de Uso

### Configuração Básica de Agente Slack

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Slack tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Slack capabilities
slack_agent = Agent(
    role="Team Communication Manager",
    goal="Facilitate team communication and coordinate collaboration efficiently",
    backstory="An AI assistant specialized in team communication and workspace coordination.",
    tools=[enterprise_tools]
)

# Task to send project updates
update_task = Task(
    description="Send a project status update to the #general channel with current progress",
    agent=slack_agent,
    expected_output="Project update message sent successfully to team channel"
)

# Run the task
crew = Crew(
    agents=[slack_agent],
    tasks=[update_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Específicas do Slack

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Slack tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["slack_send_message", "slack_send_direct_message", "slack_search_messages"]
)

communication_manager = Agent(
    role="Communication Coordinator",
    goal="Manage team communications and ensure important messages reach the right people",
    backstory="An experienced communication coordinator who handles team messaging and notifications.",
    tools=enterprise_tools
)

# Task to coordinate team communication
coordination_task = Task(
    description="Send task completion notifications to team members and update project channels",
    agent=communication_manager,
    expected_output="Team notifications sent and project channels updated successfully"
)

crew = Crew(
    agents=[communication_manager],
    tasks=[coordination_task]
)

crew.kickoff()
```

### Mensagens Avançadas com Block Kit

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

notification_agent = Agent(
    role="Notification Manager",
    goal="Create rich, interactive notifications and manage workspace communication",
    backstory="An AI assistant that specializes in creating engaging team notifications and updates.",
    tools=[enterprise_tools]
)

# Task to send rich notifications
notification_task = Task(
    description="""
    1. Send a formatted project completion message to #general with progress charts
    2. Send direct messages to team leads with task summaries
    3. Create interactive notification with action buttons for team feedback
    """,
    agent=notification_agent,
    expected_output="Rich notifications sent with interactive elements and formatted content"
)

crew = Crew(
    agents=[notification_agent],
    tasks=[notification_task]
)

crew.kickoff()
```

### Pesquisa de Mensagens e Análises

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

analytics_agent = Agent(
    role="Communication Analyst",
    goal="Analyze team communication patterns and extract insights from conversations",
    backstory="An analytical AI that excels at understanding team dynamics through communication data.",
    tools=[enterprise_tools]
)

# Complex task involving search and analysis
analysis_task = Task(
    description="""
    1. Search for recent project-related messages across all channels
    2. Find users by email to identify team members
    3. Analyze communication patterns and response times
    4. Generate weekly team communication summary
    """,
    agent=analytics_agent,
    expected_output="Comprehensive communication analysis with team insights and recommendations"
)

crew = Crew(
    agents=[analytics_agent],
    tasks=[analysis_task]
)

crew.kickoff()
```

## Fale com o Suporte

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para obter ajuda na configuração ou solução de problemas da integração com o Slack.
</Card>


# Integração Stripe
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/stripe

Processamento de pagamentos e gerenciamento de assinaturas com integração Stripe para CrewAI.

## Visão Geral

Permita que seus agentes gerenciem pagamentos, assinaturas e faturamento de clientes através do Stripe. Gerencie dados de clientes, processe assinaturas, gerencie produtos e acompanhe transações financeiras para otimizar seus fluxos de pagamento com automação impulsionada por IA.

## Pré-requisitos

Antes de usar a integração com o Stripe, certifique-se de que você tem:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com uma assinatura ativa
* Uma conta Stripe com permissões apropriadas de API
* Sua conta Stripe conectada através da [página de Integrações](https://app.crewai.com/integrations)

## Ferramentas Disponíveis

### **Gerenciamento de Clientes**

<AccordionGroup>
  <Accordion title="STRIPE_CREATE_CUSTOMER">
    **Descrição:** Crie um novo cliente em sua conta Stripe.

    **Parâmetros:**

    * `emailCreateCustomer` (string, obrigatório): Endereço de e-mail do cliente
    * `name` (string, opcional): Nome completo do cliente
    * `description` (string, opcional): Descrição do cliente para referência interna
    * `metadataCreateCustomer` (objeto, opcional): Metadados adicionais como pares chave-valor (exemplo: `{"field1": 1, "field2": 2}`)
  </Accordion>

  <Accordion title="STRIPE_GET_CUSTOMER_BY_ID">
    **Descrição:** Recupera um cliente específico pelo ID do cliente Stripe.

    **Parâmetros:**

    * `idGetCustomer` (string, obrigatório): O ID do cliente Stripe a ser recuperado
  </Accordion>

  <Accordion title="STRIPE_GET_CUSTOMERS">
    **Descrição:** Recupera uma lista de clientes com filtragem opcional.

    **Parâmetros:**

    * `emailGetCustomers` (string, opcional): Filtra clientes pelo endereço de e-mail
    * `createdAfter` (string, opcional): Filtra clientes criados após esta data (timestamp Unix)
    * `createdBefore` (string, opcional): Filtra clientes criados antes desta data (timestamp Unix)
    * `limitGetCustomers` (string, opcional): Número máximo de clientes a retornar (padrão: 10)
  </Accordion>

  <Accordion title="STRIPE_UPDATE_CUSTOMER">
    **Descrição:** Atualiza as informações de um cliente existente.

    **Parâmetros:**

    * `customerId` (string, obrigatório): O ID do cliente a ser atualizado
    * `emailUpdateCustomer` (string, opcional): Novo endereço de e-mail
    * `name` (string, opcional): Novo nome do cliente
    * `description` (string, opcional): Nova descrição do cliente
    * `metadataUpdateCustomer` (objeto, opcional): Novos metadados como pares chave-valor
  </Accordion>
</AccordionGroup>

### **Gerenciamento de Assinaturas**

<AccordionGroup>
  <Accordion title="STRIPE_CREATE_SUBSCRIPTION">
    **Descrição:** Cria uma nova assinatura para um cliente.

    **Parâmetros:**

    * `customerIdCreateSubscription` (string, obrigatório): O ID do cliente para o qual a assinatura será criada
    * `plan` (string, obrigatório): O ID do plano para assinatura - Use as Configurações do Workflow do Portal Connect para permitir que usuários selecionem um plano
    * `metadataCreateSubscription` (objeto, opcional): Metadados adicionais para a assinatura
  </Accordion>

  <Accordion title="STRIPE_GET_SUBSCRIPTIONS">
    **Descrição:** Recupera assinaturas com filtragem opcional.

    **Parâmetros:**

    * `customerIdGetSubscriptions` (string, opcional): Filtra assinaturas por ID do cliente
    * `subscriptionStatus` (string, opcional): Filtra por status da assinatura - Opções: incomplete, incomplete\_expired, trialing, active, past\_due, canceled, unpaid
    * `limitGetSubscriptions` (string, opcional): Número máximo de assinaturas a retornar (padrão: 10)
  </Accordion>
</AccordionGroup>

### **Gerenciamento de Produtos**

<AccordionGroup>
  <Accordion title="STRIPE_CREATE_PRODUCT">
    **Descrição:** Cria um novo produto no seu catálogo Stripe.

    **Parâmetros:**

    * `productName` (string, obrigatório): Nome do produto
    * `description` (string, opcional): Descrição do produto
    * `metadataProduct` (objeto, opcional): Metadados adicionais do produto como pares chave-valor
  </Accordion>

  <Accordion title="STRIPE_GET_PRODUCT_BY_ID">
    **Descrição:** Recupera um produto específico pelo ID do produto Stripe.

    **Parâmetros:**

    * `productId` (string, obrigatório): O ID do produto Stripe a ser recuperado
  </Accordion>

  <Accordion title="STRIPE_GET_PRODUCTS">
    **Descrição:** Recupera uma lista de produtos com filtragem opcional.

    **Parâmetros:**

    * `createdAfter` (string, opcional): Filtra produtos criados após esta data (timestamp Unix)
    * `createdBefore` (string, opcional): Filtra produtos criados antes desta data (timestamp Unix)
    * `limitGetProducts` (string, opcional): Número máximo de produtos a retornar (padrão: 10)
  </Accordion>
</AccordionGroup>

### **Operações Financeiras**

<AccordionGroup>
  <Accordion title="STRIPE_GET_BALANCE_TRANSACTIONS">
    **Descrição:** Recupera transações de saldo da sua conta Stripe.

    **Parâmetros:**

    * `balanceTransactionType` (string, opcional): Filtra por tipo de transação - Opções: charge, refund, payment, payment\_refund
    * `paginationParameters` (objeto, opcional): Configurações de paginação
      * `pageCursor` (string, opcional): Cursor da página para paginação
  </Accordion>

  <Accordion title="STRIPE_GET_PLANS">
    **Descrição:** Recupera planos de assinatura da sua conta Stripe.

    **Parâmetros:**

    * `isPlanActive` (boolean, opcional): Filtra por status do plano - true para planos ativos, false para inativos
    * `paginationParameters` (objeto, opcional): Configurações de paginação
      * `pageCursor` (string, opcional): Cursor da página para paginação
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configuração Básica do Agente Stripe

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Stripe tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Stripe capabilities
stripe_agent = Agent(
    role="Payment Manager",
    goal="Manage customer payments, subscriptions, and billing operations efficiently",
    backstory="An AI assistant specialized in payment processing and subscription management.",
    tools=[enterprise_tools]
)

# Task to create a new customer
create_customer_task = Task(
    description="Create a new premium customer John Doe with email john.doe@example.com",
    agent=stripe_agent,
    expected_output="Customer created successfully with customer ID"
)

# Run the task
crew = Crew(
    agents=[stripe_agent],
    tasks=[create_customer_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Stripe Específicas

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Stripe tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["stripe_create_customer", "stripe_create_subscription", "stripe_get_balance_transactions"]
)

billing_manager = Agent(
    role="Billing Manager",
    goal="Handle customer billing, subscriptions, and payment processing",
    backstory="An experienced billing manager who handles subscription lifecycle and payment operations.",
    tools=enterprise_tools
)

# Task to manage billing operations
billing_task = Task(
    description="Create a new customer and set up their premium subscription plan",
    agent=billing_manager,
    expected_output="Customer created and subscription activated successfully"
)

crew = Crew(
    agents=[billing_manager],
    tasks=[billing_task]
)

crew.kickoff()
```

### Gerenciamento de Assinaturas

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

subscription_manager = Agent(
    role="Subscription Manager",
    goal="Manage customer subscriptions and optimize recurring revenue",
    backstory="An AI assistant that specializes in subscription lifecycle management and customer retention.",
    tools=[enterprise_tools]
)

# Task to manage subscription operations
subscription_task = Task(
    description="""
    1. Create a new product "Premium Service Plan" with advanced features
    2. Set up subscription plans with different tiers
    3. Create customers and assign them to appropriate plans
    4. Monitor subscription status and handle billing issues
    """,
    agent=subscription_manager,
    expected_output="Subscription management system configured with customers and active plans"
)

crew = Crew(
    agents=[subscription_manager],
    tasks=[subscription_task]
)

crew.kickoff()
```

### Análises e Relatórios Financeiros

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

financial_analyst = Agent(
    role="Financial Analyst",
    goal="Analyze payment data and generate financial insights",
    backstory="An analytical AI that excels at extracting insights from payment and subscription data.",
    tools=[enterprise_tools]
)

# Complex task involving financial analysis
analytics_task = Task(
    description="""
    1. Retrieve balance transactions for the current month
    2. Analyze customer payment patterns and subscription trends
    3. Identify high-value customers and subscription performance
    4. Generate monthly financial performance report
    """,
    agent=financial_analyst,
    expected_output="Comprehensive financial analysis with payment insights and recommendations"
)

crew = Crew(
    agents=[financial_analyst],
    tasks=[analytics_task]
)

crew.kickoff()
```

## Referência de Status de Assinatura

Compreendendo os status de assinaturas:

* **incomplete** - A assinatura requer método de pagamento ou confirmação de pagamento
* **incomplete\_expired** - A assinatura expirou antes da confirmação do pagamento
* **trialing** - A assinatura está em período de avaliação
* **active** - A assinatura está ativa e em dia
* **past\_due** - O pagamento falhou mas a assinatura ainda está ativa
* **canceled** - A assinatura foi cancelada
* **unpaid** - O pagamento falhou e a assinatura não está mais ativa

## Uso de Metadados

Os metadados permitem que você armazene informações adicionais sobre clientes, assinaturas e produtos:

```json
{
  "customer_segment": "enterprise",
  "acquisition_source": "google_ads",
  "lifetime_value": "high",
  "custom_field_1": "value1"
}
```

Esta integração permite uma automação abrangente do gerenciamento de pagamentos e assinaturas, possibilitando que seus agentes de IA administrem operações de faturamento perfeitamente dentro do seu ecossistema Stripe.


# Integração com Zendesk
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/zendesk

Gestão de suporte ao cliente e helpdesk com integração Zendesk para CrewAI.

## Visão Geral

Permita que seus agentes gerenciem operações de suporte ao cliente através do Zendesk. Crie e atualize tickets, gerencie usuários, monitore métricas de suporte e otimize seus fluxos de atendimento ao cliente com automação impulsionada por IA.

## Pré-requisitos

Antes de usar a integração com o Zendesk, certifique-se de que você possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com uma assinatura ativa
* Uma conta Zendesk com permissões apropriadas de API
* Sua conta Zendesk conectada através da [página de Integrações](https://app.crewai.com/integrations)

## Ferramentas Disponíveis

### **Gerenciamento de Tickets**

<AccordionGroup>
  <Accordion title="ZENDESK_CREATE_TICKET">
    **Descrição:** Crie um novo ticket de suporte no Zendesk.

    **Parâmetros:**

    * `ticketSubject` (string, obrigatório): Assunto do ticket (ex.: "Socorro, minha impressora está pegando fogo!")
    * `ticketDescription` (string, obrigatório): Primeiro comentário que aparece no ticket (ex.: "A fumaça é muito colorida.")
    * `requesterName` (string, obrigatório): Nome do usuário solicitando suporte (ex.: "Jane Cliente")
    * `requesterEmail` (string, obrigatório): E-mail do solicitante do suporte (ex.: "[jane@example.com](mailto:jane@example.com)")
    * `assigneeId` (string, opcional): ID do agente Zendesk atribuído ao ticket - Use as Configurações de Fluxo de Trabalho do Portal Connect para permitir a seleção do responsável
    * `ticketType` (string, opcional): Tipo de ticket - Opções: problem, incident, question, task
    * `ticketPriority` (string, opcional): Nível de prioridade - Opções: urgent, high, normal, low
    * `ticketStatus` (string, opcional): Status do ticket - Opções: new, open, pending, hold, solved, closed
    * `ticketDueAt` (string, opcional): Data de vencimento para tickets do tipo tarefa (timestamp ISO 8601)
    * `ticketTags` (string, opcional): Array de tags a aplicar (ex.: `["enterprise", "outra_tag"]`)
    * `ticketExternalId` (string, opcional): ID externo para vincular tickets a registros locais
    * `ticketCustomFields` (object, opcional): Valores de campos personalizados em formato JSON
  </Accordion>

  <Accordion title="ZENDESK_UPDATE_TICKET">
    **Descrição:** Atualize um ticket de suporte existente no Zendesk.

    **Parâmetros:**

    * `ticketId` (string, obrigatório): ID do ticket a ser atualizado (ex.: "35436")
    * `ticketSubject` (string, opcional): Assunto atualizado do ticket
    * `requesterName` (string, obrigatório): Nome do solicitante deste ticket
    * `requesterEmail` (string, obrigatório): E-mail do solicitante deste ticket
    * `assigneeId` (string, opcional): ID atualizado do responsável - Use as Configurações de Fluxo de Trabalho do Portal Connect
    * `ticketType` (string, opcional): Tipo atualizado - Opções: problem, incident, question, task
    * `ticketPriority` (string, opcional): Prioridade atualizada - Opções: urgent, high, normal, low
    * `ticketStatus` (string, opcional): Status atualizado - Opções: new, open, pending, hold, solved, closed
    * `ticketDueAt` (string, opcional): Nova data de vencimento (timestamp ISO 8601)
    * `ticketTags` (string, opcional): Array de tags atualizadas
    * `ticketExternalId` (string, opcional): Novo ID externo
    * `ticketCustomFields` (object, opcional): Valores atualizados dos campos personalizados
  </Accordion>

  <Accordion title="ZENDESK_GET_TICKET_BY_ID">
    **Descrição:** Recupere um ticket específico pelo ID.

    **Parâmetros:**

    * `ticketId` (string, obrigatório): ID do ticket a ser recuperado (ex.: "35436")
  </Accordion>

  <Accordion title="ZENDESK_ADD_COMMENT_TO_TICKET">
    **Descrição:** Adicione um comentário ou nota interna a um ticket existente.

    **Parâmetros:**

    * `ticketId` (string, obrigatório): ID do ticket para adicionar o comentário (ex.: "35436")
    * `commentBody` (string, obrigatório): Mensagem do comentário (aceita texto simples ou HTML, ex.: "Obrigado pela sua ajuda!")
    * `isInternalNote` (boolean, opcional): Defina como verdadeiro para notas internas ao invés de respostas públicas (padrão é falso)
    * `isPublic` (boolean, opcional): Verdadeiro para comentários públicos, falso para notas internas
  </Accordion>

  <Accordion title="ZENDESK_SEARCH_TICKETS">
    **Descrição:** Busque tickets usando diversos filtros e critérios.

    **Parâmetros:**

    * `ticketSubject` (string, opcional): Filtrar pelo texto no assunto do ticket
    * `ticketDescription` (string, opcional): Filtrar por texto na descrição e comentários do ticket
    * `ticketStatus` (string, opcional): Filtrar por status - Opções: new, open, pending, hold, solved, closed
    * `ticketType` (string, opcional): Filtrar por tipo - Opções: problem, incident, question, task, no\_type
    * `ticketPriority` (string, opcional): Filtrar por prioridade - Opções: urgent, high, normal, low, no\_priority
    * `requesterId` (string, opcional): Filtrar por ID do solicitante
    * `assigneeId` (string, opcional): Filtrar pelo ID do agente responsável
    * `recipientEmail` (string, opcional): Filtrar pelo e-mail do destinatário original
    * `ticketTags` (string, opcional): Filtrar por tags do ticket
    * `ticketExternalId` (string, opcional): Filtrar por ID externo
    * `createdDate` (object, opcional): Filtrar por data de criação com operador (EQUALS, LESS\_THAN\_EQUALS, GREATER\_THAN\_EQUALS) e valor
    * `updatedDate` (object, opcional): Filtrar por data de atualização com operador e valor
    * `dueDate` (object, opcional): Filtrar por data de vencimento com operador e valor
    * `sort_by` (string, opcional): Campo de ordenação - Opções: created\_at, updated\_at, priority, status, ticket\_type
    * `sort_order` (string, opcional): Direção da ordenação - Opções: asc, desc
  </Accordion>
</AccordionGroup>

### **Gerenciamento de Usuários**

<AccordionGroup>
  <Accordion title="ZENDESK_CREATE_USER">
    **Descrição:** Crie um novo usuário no Zendesk.

    **Parâmetros:**

    * `name` (string, obrigatório): Nome completo do usuário
    * `email` (string, opcional): E-mail do usuário (ex.: "[jane@example.com](mailto:jane@example.com)")
    * `phone` (string, opcional): Telefone do usuário
    * `role` (string, opcional): Papel do usuário - Opções: admin, agent, end-user
    * `externalId` (string, opcional): Identificador único de outro sistema
    * `details` (string, opcional): Detalhes adicionais do usuário
    * `notes` (string, opcional): Notas internas sobre o usuário
  </Accordion>

  <Accordion title="ZENDESK_UPDATE_USER">
    **Descrição:** Atualize informações de um usuário existente.

    **Parâmetros:**

    * `userId` (string, obrigatório): ID do usuário a ser atualizado
    * `name` (string, opcional): Nome atualizado do usuário
    * `email` (string, opcional): Novo e-mail (adicionado como e-mail secundário na atualização)
    * `phone` (string, opcional): Novo telefone
    * `role` (string, opcional): Novo papel - Opções: admin, agent, end-user
    * `externalId` (string, opcional): Novo ID externo
    * `details` (string, opcional): Novos detalhes do usuário
    * `notes` (string, opcional): Novas notas internas
  </Accordion>

  <Accordion title="ZENDESK_GET_USER_BY_ID">
    **Descrição:** Recupere um usuário específico pelo ID.

    **Parâmetros:**

    * `userId` (string, obrigatório): ID do usuário a ser recuperado
  </Accordion>

  <Accordion title="ZENDESK_SEARCH_USERS">
    **Descrição:** Busque usuários utilizando vários critérios.

    **Parâmetros:**

    * `name` (string, opcional): Filtrar por nome do usuário
    * `email` (string, opcional): Filtrar por e-mail do usuário (ex.: "[jane@example.com](mailto:jane@example.com)")
    * `role` (string, opcional): Filtrar por papel - Opções: admin, agent, end-user
    * `externalId` (string, opcional): Filtrar por ID externo
    * `sort_by` (string, opcional): Campo de ordenação - Opções: created\_at, updated\_at
    * `sort_order` (string, opcional): Direção de ordenação - Opções: asc, desc
  </Accordion>
</AccordionGroup>

### **Ferramentas Administrativas**

<AccordionGroup>
  <Accordion title="ZENDESK_GET_TICKET_FIELDS">
    **Descrição:** Recupere todos os campos padrão e personalizados disponíveis para tickets.

    **Parâmetros:**

    * `paginationParameters` (object, opcional): Configurações de paginação
      * `pageCursor` (string, opcional): Cursor de página para paginação
  </Accordion>

  <Accordion title="ZENDESK_GET_TICKET_AUDITS">
    **Descrição:** Obtenha registros de auditoria (histórico somente leitura) dos tickets.

    **Parâmetros:**

    * `ticketId` (string, opcional): Obtenha auditorias para um ticket específico (se vazio, recupera auditorias de todos os tickets não arquivados, ex.: "1234")
    * `paginationParameters` (object, opcional): Configurações de paginação
      * `pageCursor` (string, opcional): Cursor de página para paginação
  </Accordion>
</AccordionGroup>

## Campos Personalizados

Campos personalizados permitem armazenar informações adicionais específicas para sua organização:

```json
[
  { "id": 27642, "value": "745" },
  { "id": 27648, "value": "yes" }
]
```

## Níveis de Prioridade dos Tickets

Compreendendo os níveis de prioridade:

* **urgent** - Questões críticas que exigem atenção imediata
* **high** - Questões importantes que devem ser tratadas rapidamente
* **normal** - Prioridade padrão para a maioria dos tickets
* **low** - Questões menores que podem ser tratadas quando conveniente

## Fluxo de Status dos Tickets

Progresso padrão de status dos tickets:

* **new** - Recém-criado, ainda não atribuído
* **open** - Em andamento
* **pending** - Aguardando resposta do cliente ou ação externa
* **hold** - Pausa temporária
* **solved** - Problema resolvido, aguardando confirmação do cliente
* **closed** - Ticket finalizado e fechado

## Exemplos de Uso

### Configuração Básica de Agente Zendesk

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Obtenha as ferramentas enterprise (as ferramentas Zendesk serão incluídas)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Crie um agente com capacidades Zendesk
zendesk_agent = Agent(
    role="Gerente de Suporte",
    goal="Gerenciar tickets de suporte ao cliente e oferecer excelente atendimento",
    backstory="Um assistente de IA especializado em operações de suporte ao cliente e gerenciamento de tickets.",
    tools=[enterprise_tools]
)

# Tarefa para criar um novo ticket de suporte
create_ticket_task = Task(
    description="Crie um ticket de suporte de alta prioridade para John Smith que não consegue acessar sua conta após redefinir a senha",
    agent=zendesk_agent,
    expected_output="Ticket de suporte criado com sucesso com o ID do ticket"
)

# Execute a tarefa
crew = Crew(
    agents=[zendesk_agent],
    tasks=[create_ticket_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Zendesk Específicas

```python
from crewai_tools import CrewaiEnterpriseTools

# Obtenha apenas ferramentas Zendesk específicas
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["zendesk_create_ticket", "zendesk_update_ticket", "zendesk_add_comment_to_ticket"]
)

support_agent = Agent(
    role="Agente de Suporte ao Cliente",
    goal="Atender consultas de clientes e resolver issues de suporte de forma eficiente",
    backstory="Um agente de suporte experiente que se especializa em resolução de tickets e comunicação com clientes.",
    tools=enterprise_tools
)

# Tarefa para gerenciar o fluxo de suporte
support_task = Task(
    description="Crie um ticket para problemas de login, adicione comentários de troubleshooting e atualize o status para resolvido",
    agent=support_agent,
    expected_output="Ticket de suporte gerenciado através de todo o fluxo de resolução"
)

crew = Crew(
    agents=[support_agent],
    tasks=[support_task]
)

crew.kickoff()
```

### Gerenciamento Avançado de Tickets

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

ticket_manager = Agent(
    role="Gerente de Tickets",
    goal="Gerenciar fluxos de tickets de suporte e garantir resolução tempestiva",
    backstory="Um assistente de IA que se especializa em triagem de tickets de suporte e otimização de fluxos de trabalho.",
    tools=[enterprise_tools]
)

# Tarefa para gerenciar o ciclo de vida do ticket
ticket_workflow = Task(
    description="""
    1. Crie um novo ticket de suporte para problemas de acesso à conta
    2. Adicione notas internas com as etapas de troubleshooting
    3. Atualize a prioridade do ticket de acordo com o nível do cliente
    4. Adicione comentários de resolução e feche o ticket
    """,
    agent=ticket_manager,
    expected_output="Ciclo de vida completo do ticket gerenciado da criação à resolução"
)

crew = Crew(
    agents=[ticket_manager],
    tasks=[ticket_workflow]
)

crew.kickoff()
```

### Análise e Relatórios de Suporte

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

support_analyst = Agent(
    role="Analista de Suporte",
    goal="Analisar métricas de suporte e gerar insights para desempenho da equipe",
    backstory="Um IA analítico que se destaca na extração de insights a partir de dados de suporte e padrões de tickets.",
    tools=[enterprise_tools]
)

# Tarefa complexa envolvendo análise e geração de relatórios
analytics_task = Task(
    description="""
    1. Busque todos os tickets abertos nos últimos 30 dias
    2. Analise tempos de resolução dos tickets e satisfação do cliente
    3. Identifique problemas comuns e padrões de suporte
    4. Gere relatório semanal de desempenho do suporte
    """,
    agent=support_analyst,
    expected_output="Relatório analítico abrangente de suporte com insights de desempenho e recomendações"
)

crew = Crew(
    agents=[support_analyst],
    tasks=[analytics_task]
)

crew.kickoff()
```


# CrewAI Enterprise
Source: https://docs.crewai.com/pt-BR/enterprise/introduction

Implemente, monitore e escale seus fluxos de trabalho de agentes de IA

## Introdução

CrewAI Enterprise fornece uma plataforma para implementar, monitorar e escalar seus crews e agentes em um ambiente de produção.

<Frame>
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crewai-enterprise-dashboard.png" alt="CrewAI Enterprise Dashboard" />
</Frame>

CrewAI Enterprise expande o poder do framework open-source com funcionalidades projetadas para implantações em produção, colaboração e escalabilidade. Implemente seus crews em uma infraestrutura gerenciada e monitore sua execução em tempo real.

## Principais Funcionalidades

<CardGroup cols={2}>
  <Card title="Implantação de Crews" icon="rocket">
    Implemente seus crews em uma infraestrutura gerenciada com apenas alguns cliques
  </Card>

  <Card title="Acesso via API" icon="code">
    Acesse seus crews implantados via REST API para integração com sistemas existentes
  </Card>

  <Card title="Observabilidade" icon="chart-line">
    Monitore seus crews com rastreamentos de execução e logs detalhados
  </Card>

  <Card title="Repositório de Ferramentas" icon="toolbox">
    Publique e instale ferramentas para aprimorar as capacidades de seus crews
  </Card>

  <Card title="Transmissão via Webhook" icon="webhook">
    Transmita eventos e atualizações em tempo real para seus sistemas
  </Card>

  <Card title="Crew Studio" icon="paintbrush">
    Crie e personalize crews utilizando uma interface no-code/low-code
  </Card>
</CardGroup>

## Opções de Implantação

<CardGroup cols={3}>
  <Card title="Integração com GitHub" icon="github">
    Conecte-se diretamente aos seus repositórios do GitHub para implementar código
  </Card>

  <Card title="Crew Studio" icon="palette">
    Implemente crews criados pela interface no-code do Crew Studio
  </Card>

  <Card title="Implantação via CLI" icon="terminal">
    Use o CrewAI CLI para fluxos de trabalho de implantação mais avançados
  </Card>
</CardGroup>

## Primeiros Passos

<Steps>
  <Step title="Cadastre-se para uma conta">
    Crie sua conta em [app.crewai.com](https://app.crewai.com)

    <Card title="Cadastre-se" icon="user" href="https://app.crewai.com/signup">
      Cadastre-se
    </Card>
  </Step>

  <Step title="Construa seu primeiro crew">
    Utilize código ou o Crew Studio para construir seu crew

    <Card title="Construir Crew" icon="paintbrush" href="/pt-BR/enterprise/guides/build-crew">
      Construir Crew
    </Card>
  </Step>

  <Step title="Implemente seu crew">
    Implemente seu crew na plataforma Enterprise

    <Card title="Implantar Crew" icon="rocket" href="/pt-BR/enterprise/guides/deploy-crew">
      Implantar Crew
    </Card>
  </Step>

  <Step title="Acesse seu crew">
    Integre-se ao seu crew através dos endpoints de API gerados

    <Card title="Acesso via API" icon="code" href="/pt-BR/enterprise/guides/deploy-crew">
      Usar a API do Crew
    </Card>
  </Step>
</Steps>

Para instruções detalhadas, consulte nosso [guia de implantação](/pt-BR/enterprise/guides/deploy-crew) ou clique no botão abaixo para começar.


# FAQs
Source: https://docs.crewai.com/pt-BR/enterprise/resources/frequently-asked-questions

Perguntas frequentes sobre CrewAI Enterprise

<AccordionGroup>
  <Accordion title="Como a execução de tarefas é tratada no processo hierárquico?">
    No processo hierárquico, um agente gerente é criado automaticamente e coordena o fluxo de trabalho, delegando tarefas e validando resultados para uma execução eficiente e simplificada. O agente gerente utiliza ferramentas para facilitar a delegação e execução de tarefas por agentes sob sua orientação. O LLM do gerente é fundamental para o processo hierárquico e deve ser configurado corretamente para funcionar adequadamente.
  </Accordion>

  <Accordion title="Onde posso encontrar a documentação mais recente da CrewAI?">
    A documentação mais atualizada da CrewAI está disponível em nosso site oficial de documentação: [https://docs.crewai.com/](https://docs.crewai.com/)
    <Card href="https://docs.crewai.com/" icon="books">CrewAI Docs</Card>
  </Accordion>

  <Accordion title="Quais as principais diferenças entre os Processos Hierárquico e Sequencial na CrewAI?">
    #### Processo Hierárquico:

    * As tarefas são delegadas e executadas com base em uma cadeia de comando estruturada
    * Um modelo de linguagem do gerente (`manager_llm`) deve ser especificado para o agente gerente
    * O agente gerente supervisiona a execução de tarefas, planejamento, delegação e validação
    * As tarefas não são pré-atribuídas; o gerente aloca tarefas para os agentes com base em suas capacidades

    #### Processo Sequencial:

    * As tarefas são executadas uma após a outra, garantindo uma progressão ordenada
    * O resultado de uma tarefa serve como contexto para a próxima
    * A execução das tarefas segue a ordem predefinida na lista de tarefas

    #### Qual Processo é Melhor para Projetos Complexos?

    O processo hierárquico é mais adequado para projetos complexos porque permite:

    * **Alocação e delegação dinâmica de tarefas**: O agente gerente pode atribuir tarefas de acordo com as capacidades dos agentes
    * **Validação e supervisão estruturadas**: O agente gerente revisa os resultados das tarefas e garante a conclusão
    * **Gestão de tarefas complexas**: Controle preciso da disponibilidade de ferramentas por agente
  </Accordion>

  <Accordion title="Quais são os benefícios do uso de memória no framework CrewAI?">
    * **Aprendizado adaptativo**: As crews tornam-se mais eficientes ao longo do tempo, adaptando-se a novas informações e aprimorando sua abordagem às tarefas
    * **Personalização aprimorada**: A memória permite que os agentes recordem preferências do usuário e interações anteriores, possibilitando experiências personalizadas
    * **Resolução aprimorada de problemas**: O acesso a um repositório rico em memória auxilia os agentes a tomarem decisões mais informadas, baseando-se em aprendizados anteriores e insights contextuais
  </Accordion>

  <Accordion title="Qual é o propósito de definir um limite máximo de RPM para um agente?">
    Definir um limite máximo de RPM para um agente evita que ele faça solicitações excessivas a serviços externos, o que pode ajudar a evitar limites de taxa e melhorar o desempenho.
  </Accordion>

  <Accordion title="Qual o papel da entrada humana na execução de tarefas dentro de uma crew da CrewAI?">
    A entrada humana permite que os agentes solicitem informações adicionais ou esclarecimentos quando necessário. Este recurso é fundamental em processos de tomada de decisão complexos ou quando os agentes precisam de mais detalhes para concluir uma tarefa com eficácia.

    Para integrar a entrada humana na execução do agente, defina a flag `human_input` na definição da tarefa. Quando habilitada, o agente solicitará a entrada do usuário antes de entregar sua resposta final. Essa entrada pode fornecer contexto extra, esclarecer ambiguidades ou validar a saída do agente.

    Para orientações detalhadas de implementação, veja nosso [guia Human-in-the-Loop](/pt-BR/how-to/human-in-the-loop).
  </Accordion>

  <Accordion title="Quais opções avançadas de customização estão disponíveis para aprimorar e personalizar o comportamento e as capacidades dos agentes na CrewAI?">
    A CrewAI oferece diversas opções avançadas de customização:

    * **Customização de Modelo de Linguagem**: Os agentes podem ser personalizados com modelos de linguagem específicos (`llm`) e modelos de linguagem para chamadas de função (`function_calling_llm`)
    * **Configurações de Desempenho e Debug**: Ajuste o desempenho do agente e monitore suas operações
    * **Modo Verbose**: Habilita registros detalhados das ações do agente, útil para depuração e otimização
    * **Limite de RPM**: Define o número máximo de solicitações por minuto (`max_rpm`)
    * **Máximo de Iterações**: O atributo `max_iter` permite definir o número máximo de iterações que um agente pode executar para uma única tarefa
    * **Delegação e Autonomia**: Controle a capacidade do agente de delegar ou fazer perguntas com o atributo `allow_delegation` (padrão: True)
    * **Integração de Entrada Humana**: Os agentes podem solicitar informações adicionais ou esclarecimentos quando necessário
  </Accordion>

  <Accordion title="Em quais cenários a entrada humana é particularmente útil na execução de agentes?">
    A entrada humana é especialmente útil quando:

    * **Os agentes precisam de informações adicionais ou esclarecimentos**: Quando se deparam com ambiguidade ou dados incompletos
    * **Os agentes precisam tomar decisões complexas ou sensíveis**: A entrada humana pode auxiliar em decisões éticas ou de nuances
    * **Supervisão e validação da saída do agente**: A entrada humana pode ajudar a validar resultados e prevenir erros
    * **Personalização do comportamento do agente**: Entradas humanas podem fornecer feedback para aprimorar respostas dos agentes ao longo do tempo
    * **Identificação e resolução de erros ou limitações**: A entrada humana auxilia a suprir lacunas de capacidade dos agentes
  </Accordion>

  <Accordion title="Quais são os diferentes tipos de memória disponíveis na crewAI?">
    Os diferentes tipos de memória disponíveis na CrewAI são:

    * **Memória de curto prazo**: Armazenamento temporário para contexto imediato
    * **Memória de longo prazo**: Armazenamento persistente para padrões aprendidos e informações
    * **Memória de entidade**: Armazenamento focado em entidades específicas e seus atributos
    * **Memória contextual**: Memória que mantém o contexto ao longo das interações

    Saiba mais sobre os diferentes tipos de memória:
    <Card href="https://docs.crewai.com/concepts/memory" icon="brain">CrewAI Memory</Card>
  </Accordion>

  <Accordion title="Como faço para usar Output Pydantic em uma Tarefa?">
    Para usar Output Pydantic em uma tarefa, você precisa definir a saída esperada da tarefa como um modelo Pydantic. Veja um exemplo rápido:

    <Steps>
      <Step title="Defina um modelo Pydantic">
        ```python
        from pydantic import BaseModel

        class User(BaseModel):
            name: str
            age: int
        ```
      </Step>

      <Step title="Crie uma tarefa com Output Pydantic">
        ```python
        from crewai import Task, Crew, Agent
        from my_models import User

        task = Task(
            description="Create a user with the provided name and age",
            expected_output=User,  # This is the Pydantic model
            agent=agent,
            tools=[tool1, tool2]
        )
        ```
      </Step>

      <Step title="Defina o atributo output_pydantic no seu agente">
        ```python
        from crewai import Agent
        from my_models import User

        agent = Agent(
            role='User Creator',
            goal='Create users',
            backstory='I am skilled in creating user accounts',
            tools=[tool1, tool2],
            output_pydantic=User
        )
        ```
      </Step>
    </Steps>

    Aqui está um tutorial de como obter saídas estruturadas de forma consistente dos seus agentes:

    <Frame>
      <iframe height="400" width="100%" src="https://www.youtube.com/embed/dNpKQk5uxHw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />
    </Frame>
  </Accordion>

  <Accordion title="Como posso criar ferramentas personalizadas para meus agentes CrewAI?">
    Você pode criar ferramentas personalizadas herdando da classe `BaseTool` fornecida pela CrewAI ou usando o decorador de ferramenta. Herdar envolve definir uma nova classe que herda de `BaseTool`, especificando o nome, a descrição e o método `_run` para a lógica operacional. O decorador de ferramenta permite criar um objeto `Tool` diretamente com os atributos necessários e uma lógica funcional.

    <Card href="https://docs.crewai.com/how-to/create-custom-tools" icon="code">CrewAI Tools Guide</Card>
  </Accordion>

  <Accordion title="Como controlar o número máximo de solicitações por minuto que toda a crew pode realizar?">
    O atributo `max_rpm` define o número máximo de solicitações por minuto que a crew pode realizar para evitar limites de taxa, e irá sobrescrever as definições de `max_rpm` dos agentes individuais se você defini-lo.
  </Accordion>
</AccordionGroup>


# Exemplos CrewAI
Source: https://docs.crewai.com/pt-BR/examples/example

Uma coleção de exemplos que mostram como usar o framework CrewAI para automatizar fluxos de trabalho.

<CardGroup cols={3}>
  <Card title="Estratégia de Marketing" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/marketing_strategy" icon="bullhorn" iconType="solid">
    Automatize a criação de estratégias de marketing com CrewAI.
  </Card>

  <Card title="Viagem Surpresa" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/surprise_trip" icon="plane" iconType="duotone">
    Crie um roteiro de viagem surpresa com CrewAI.
  </Card>

  <Card title="Relacionar Perfil a Posições" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/match_profile_to_positions" icon="linkedin" iconType="duotone">
    Relacione um perfil a vagas de emprego com CrewAI.
  </Card>

  <Card title="Criar Vaga" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/job-posting" icon="newspaper" iconType="duotone">
    Crie uma vaga de emprego com CrewAI.
  </Card>

  <Card title="Gerador de Jogos" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/game-builder-crew" icon="gamepad" iconType="duotone">
    Crie um jogo com CrewAI.
  </Card>

  <Card title="Encontrar Candidatos" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/recruitment" icon="user-group" iconType="duotone">
    Encontre candidatos a vagas com CrewAI.
  </Card>
</CardGroup>


# Personalizando Prompts
Source: https://docs.crewai.com/pt-BR/guides/advanced/customizing-prompts

Aprofunde-se na personalização de prompts de baixo nível no CrewAI, habilitando casos de uso super customizados e complexos para diferentes modelos e idiomas.

## Por Que Personalizar Prompts?

Embora os prompts padrão do CrewAI funcionem bem para muitos cenários, a personalização de baixo nível permite comportamentos de agentes significativamente mais flexíveis e poderosos. Veja por que você pode querer aproveitar esse controle mais profundo:

1. **Otimizar para LLMs específicas** – Diferentes modelos (como GPT-4, Claude ou Llama) funcionam melhor com formatos de prompt adaptados às suas arquiteturas exclusivas.
2. **Alterar o idioma** – Construa agentes que operam exclusivamente em idiomas além do inglês, lidando com nuances com precisão.
3. **Especializar para domínios complexos** – Adapte prompts para setores altamente especializados como saúde, finanças ou jurídico.
4. **Ajustar tom e estilo** – Torne os agentes mais formais, casuais, criativos ou analíticos.
5. **Suportar casos de uso super customizados** – Utilize estruturas e formatações avançadas de prompt para atender requisitos detalhados e específicos do projeto.

Este guia explora como acessar os prompts do CrewAI em um nível mais baixo, oferecendo controle granular sobre como os agentes pensam e interagem.

## Entendendo o Sistema de Prompt do CrewAI

Nos bastidores, o CrewAI adota um sistema de prompt modular que pode ser amplamente customizado:

* **Templates de agente** – Determinam o modo como cada agente aborda o papel que lhe foi atribuído.
* **Prompt slices** – Controlam comportamentos especializados como tarefas, o uso de ferramentas e a estrutura de saída.
* **Tratamento de erros** – Definem como os agentes respondem a falhas, exceções ou timeouts.
* **Prompts específicos de ferramentas** – Definem instruções detalhadas para como as ferramentas são invocadas ou utilizadas.

Confira os [templates de prompt originais no repositório do CrewAI](https://github.com/crewAIInc/crewAI/blob/main/src/crewai/translations/en.json) para ver como esses elementos são organizados. A partir daí, você pode sobrescrever ou adaptar conforme necessário para desbloquear comportamentos avançados.

## Entendendo as Instruções de Sistema Padrão

<Warning>
  **Questão de Transparência em Produção**: O CrewAI injeta automaticamente instruções padrão nos seus prompts que talvez você não conheça. Esta seção explica o que acontece nos bastidores e como obter controle total.
</Warning>

Ao definir um agente com `role`, `goal` e `backstory`, o CrewAI automaticamente adiciona instruções de sistema adicionais que controlam a formatação e o comportamento. Entender essas injeções padrão é essencial para sistemas em produção onde você precisa de total transparência nos prompts.

### O Que CrewAI Injeta Automaticamente

Baseado na configuração do seu agente, o CrewAI adiciona diferentes instruções padrão:

#### Para Agentes Sem Ferramentas

```text
"I MUST use these formats, my job depends on it!"
```

#### Para Agentes Com Ferramentas

```text
"IMPORTANT: Use the following format in your response:

Thought: you should always think about what to do
Action: the action to take, only one name of [tool_names]
Action Input: the input to the action, just a simple JSON object...
```

#### Para Saídas Estruturadas (JSON/Pydantic)

````text
"Ensure your final answer contains only the content in the following format: {output_format}
Ensure the final output does not include any code block markers like ```json or ```python."
````

### Visualizando o Prompt de Sistema Completo

Para ver exatamente qual prompt está sendo enviado para seu LLM, você pode inspecionar o prompt gerado:

```python
from crewai import Agent, Crew, Task
from crewai.utilities.prompts import Prompts

# Crie seu agente
agent = Agent(
    role="Data Analyst",
    goal="Analyze data and provide insights",
    backstory="You are an expert data analyst with 10 years of experience.",
    verbose=True
)

# Crie uma tarefa de exemplo
task = Task(
    description="Analyze the sales data and identify trends",
    expected_output="A detailed analysis with key insights and trends",
    agent=agent
)

# Crie o gerador de prompt
prompt_generator = Prompts(
    agent=agent,
    has_tools=len(agent.tools) > 0,
    use_system_prompt=agent.use_system_prompt
)

# Gere e inspecione o prompt atual
generated_prompt = prompt_generator.task_execution()

# Imprima o prompt completo de sistema que será enviado ao LLM
if "system" in generated_prompt:
    print("=== SYSTEM PROMPT ===")
    print(generated_prompt["system"])
    print("\n=== USER PROMPT ===")
    print(generated_prompt["user"])
else:
    print("=== COMPLETE PROMPT ===")
    print(generated_prompt["prompt"])

# Você também pode ver como a descrição da tarefa é formatada
print("\n=== TASK CONTEXT ===")
print(f"Task Description: {task.description}")
print(f"Expected Output: {task.expected_output}")
```

### Sobrescrevendo Instruções Padrão

Você tem várias opções para obter controle total sobre os prompts:

#### Opção 1: Templates Personalizados (Recomendado)

```python
from crewai import Agent

# Defina seu próprio template de sistema sem instruções padrão
custom_system_template = """You are {role}. {backstory}
Your goal is: {goal}

Respond naturally and conversationally. Focus on providing helpful, accurate information."""

custom_prompt_template = """Task: {input}

Please complete this task thoughtfully."""

agent = Agent(
    role="Research Assistant",
    goal="Help users find accurate information",
    backstory="You are a helpful research assistant.",
    system_template=custom_system_template,
    prompt_template=custom_prompt_template,
    use_system_prompt=True  # Use mensagens separadas system/user
)
```

#### Opção 2: Arquivo de Prompt Personalizado

Crie um arquivo `custom_prompts.json` para sobrescrever slices específicas de prompt:

```json
{
  "slices": {
    "no_tools": "\nProvide your best answer in a natural, conversational way.",
    "tools": "\nYou have access to these tools: {tools}\n\nUse them when helpful, but respond naturally.",
    "formatted_task_instructions": "Format your response as: {output_format}"
  }
}
```

Em seguida, utilize no seu crew:

```python
crew = Crew(
    agents=[agent],
    tasks=[task],
    prompt_file="custom_prompts.json",
    verbose=True
)
```

#### Opção 3: Desativar Prompts de Sistema para Modelos o1

```python
agent = Agent(
    role="Analyst",
    goal="Analyze data",
    backstory="Expert analyst",
    use_system_prompt=False  # Desativa separação de mensagens system prompt
)
```

### Depuração com Ferramentas de Observabilidade

Para garantir transparência em produção, integre com plataformas de observabilidade para monitorar todos os prompts e interações com LLM. Isso permite que você veja exatamente quais prompts (incluindo instruções padrão) estão sendo enviados para os seus LLMs.

Veja nossa [documentação sobre Observabilidade](/pt-BR/observability/overview) para guias detalhados de integração com diversas plataformas como Langfuse, MLflow, Weights & Biases e soluções de logging customizadas.

### Boas Práticas para Produção

1. **Sempre inspecione prompts gerados** antes de implantar em produção
2. **Use templates customizados** quando precisar de controle total sobre o conteúdo do prompt
3. **Integre ferramentas de observabilidade** para monitoramento contínuo de prompts (veja [docs de Observabilidade](/pt-BR/observability/overview))
4. **Teste com diferentes LLMs** já que instruções padrão podem se comportar de maneira diferente em cada modelo
5. **Documente suas customizações de prompt** para transparência da equipe

<Tip>
  As instruções padrão existem para garantir comportamento consistente nos agentes, mas podem interferir com requisitos de domínio específicos. Use as opções de customização acima para manter controle total sobre o comportamento do seu agente em sistemas de produção.
</Tip>

## Melhores Práticas para Gerenciar Arquivos de Prompt

Ao realizar personalização de prompts em baixo nível, siga estas diretrizes para manter tudo organizado e fácil de manter:

1. **Mantenha arquivos separados** – Armazene seus prompts personalizados em arquivos JSON dedicados fora do código principal.
2. **Controle de versão** – Acompanhe as alterações no seu repositório, garantindo documentação clara das mudanças nos prompts ao longo do tempo.
3. **Organize por modelo ou idioma** – Utilize nomes como `prompts_llama.json` ou `prompts_es.json` para identificar rapidamente configurações especializadas.
4. **Documente as alterações** – Adicione comentários ou mantenha um README detalhando o propósito e o escopo das customizações.
5. **Minimize alterações** – Sobrescreva apenas os slices específicos que realmente precisam de ajuste, mantendo a funcionalidade padrão para o restante.

## O Jeito Mais Simples de Personalizar Prompts

Uma abordagem direta é criar um arquivo JSON para os prompts que deseja sobrescrever e então indicar este arquivo no seu Crew:

1. Crie um arquivo JSON com os slices de prompt atualizados.
2. Referencie este arquivo no parâmetro `prompt_file` do seu Crew.

O CrewAI então mescla suas customizações com os padrões, assim você não precisa redefinir todos os prompts. Veja como:

### Exemplo: Customização Básica de Prompt

Crie um arquivo `custom_prompts.json` com os prompts que deseja modificar. Certifique-se de listar todos os prompts de nível superior que ele deve conter, não apenas suas alterações:

```json
{
  "slices": {
    "format": "When responding, follow this structure:\n\nTHOUGHTS: Your step-by-step thinking\nACTION: Any tool you're using\nRESULT: Your final answer or conclusion"
  }
}
```

Integre assim:

```python
from crewai import Agent, Crew, Task, Process

# Crie agentes e tarefas normalmente
researcher = Agent(
    role="Research Specialist",
    goal="Find information on quantum computing",
    backstory="You are a quantum physics expert",
    verbose=True
)

research_task = Task(
    description="Research quantum computing applications",
    expected_output="A summary of practical applications",
    agent=researcher
)

# Crie um crew com seu arquivo de prompt personalizado
crew = Crew(
    agents=[researcher],
    tasks=[research_task],
    prompt_file="path/to/custom_prompts.json",
    verbose=True
)

# Execute o crew
result = crew.kickoff()
```

Com essas poucas edições, você conquista controle de baixo nível sobre como seus agentes se comunicam e solucionam tarefas.

## Otimizando para Modelos Específicos

Modelos diferentes respondem melhor a estruturas de prompt diferentes. Ajustes mais profundos podem aumentar significativamente o desempenho ao alinhar seus prompts às nuances de cada modelo.

### Exemplo: Template de Prompt para Llama 3.3

Por exemplo, ao lidar com o Llama 3.3 da Meta, a personalização de baixo nível pode refletir a estrutura recomendada descrita em:
[https://www.llama.com/docs/model-cards-and-prompt-formats/llama3\_1/#prompt-template](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1/#prompt-template)

Veja um exemplo destacando como você pode ajustar um Agent para usar o Llama 3.3 em código:

```python
from crewai import Agent, Crew, Task, Process
from crewai_tools import DirectoryReadTool, FileReadTool

# Defina templates para mensagens de system, user (prompt) e assistant (resposta)
system_template = """<|begin_of_text|><|start_header_id|>system<|end_header_id|>{{ .System }}<|eot_id|>"""
prompt_template = """<|start_header_id|>user<|end_header_id|>{{ .Prompt }}<|eot_id|>"""
response_template = """<|start_header_id|>assistant<|end_header_id|>{{ .Response }}<|eot_id|>"""

# Crie um Agent usando layouts específicos do Llama
principal_engineer = Agent(
    role="Principal Engineer",
    goal="Oversee AI architecture and make high-level decisions",
    backstory="You are the lead engineer responsible for critical AI systems",
    verbose=True,
    llm="groq/llama-3.3-70b-versatile",  # Usando o modelo Llama 3
    system_template=system_template,
    prompt_template=prompt_template,
    response_template=response_template,
    tools=[DirectoryReadTool(), FileReadTool()]
)

# Defina uma tarefa de exemplo
engineering_task = Task(
    description="Review AI implementation files for potential improvements",
    expected_output="A summary of key findings and recommendations",
    agent=principal_engineer
)

# Crie um Crew para a tarefa
llama_crew = Crew(
    agents=[principal_engineer],
    tasks=[engineering_task],
    process=Process.sequential,
    verbose=True
)

# Execute o crew
result = llama_crew.kickoff()
print(result.raw)
```

Com essa configuração, você exerce controle abrangente e de baixo nível sobre seus fluxos de trabalho baseados em Llama sem precisar de um arquivo JSON separado.

## Conclusão

A personalização de prompts em baixo nível no CrewAI abre portas para casos de uso super customizados e complexos. Mantendo arquivos de prompt organizados (ou templates inline diretos), é possível acomodar diferentes modelos, idiomas e domínios especializados. Esse nível de flexibilidade garante que você possa criar exatamente o comportamento de IA que precisa, sabendo que o CrewAI ainda fornece padrões confiáveis quando você não sobrescreve.

<Check>
  Agora você tem a base para customizações avançadas de prompt no CrewAI. Seja adaptando para estruturas específicas de modelo ou restrições de domínio, esta abordagem de baixo nível permite moldar as interações dos agentes de forma altamente especializada.
</Check>


# Impressão digital
Source: https://docs.crewai.com/pt-BR/guides/advanced/fingerprinting

Saiba como usar o sistema de impressão digital da CrewAI para identificar e rastrear componentes de forma única durante todo o seu ciclo de vida.

## Visão geral

As impressões digitais na CrewAI fornecem uma maneira de identificar e rastrear componentes de forma única durante todo o seu ciclo de vida. Cada `Agent`, `Crew` e `Task` recebe automaticamente uma impressão digital única quando criado, que não pode ser sobrescrita manualmente.

Essas impressões digitais podem ser usadas para:

* Auditoria e rastreamento do uso de componentes
* Garantir a integridade da identidade dos componentes
* Anexar metadados aos componentes
* Criar uma cadeia rastreável de operações

## Como funciona a impressão digital

Uma impressão digital é uma instância da classe `Fingerprint` do módulo `crewai.security`. Cada impressão digital contém:

* Uma string UUID: Um identificador único para o componente, gerado automaticamente e que não pode ser definido manualmente
* Um timestamp de criação: Quando a impressão digital foi gerada, definido automaticamente e que não pode ser modificado manualmente
* Metadados: Um dicionário de informações adicionais que pode ser customizado

As impressões digitais são geradas e atribuídas automaticamente quando um componente é criado. Cada componente expõe sua impressão digital por meio de uma propriedade de somente leitura.

## Uso básico

### Acessando impressões digitais

```python
from crewai import Agent, Crew, Task

# Criar componentes - impressões digitais são geradas automaticamente
agent = Agent(
    role="Data Scientist",
    goal="Analyze data",
    backstory="Expert in data analysis"
)

crew = Crew(
    agents=[agent],
    tasks=[]
)

task = Task(
    description="Analyze customer data",
    expected_output="Insights from data analysis",
    agent=agent
)

# Acessar as impressões digitais
agent_fingerprint = agent.fingerprint
crew_fingerprint = crew.fingerprint
task_fingerprint = task.fingerprint

# Imprimir as strings UUID
print(f"Agent fingerprint: {agent_fingerprint.uuid_str}")
print(f"Crew fingerprint: {crew_fingerprint.uuid_str}")
print(f"Task fingerprint: {task_fingerprint.uuid_str}")
```

### Trabalhando com metadados das impressões digitais

Você pode adicionar metadados às impressões digitais para fornecer contexto adicional:

```python
# Adicionar metadados à impressão digital do agente
agent.security_config.fingerprint.metadata = {
    "version": "1.0",
    "department": "Data Science",
    "project": "Customer Analysis"
}

# Acessar os metadados
print(f"Agent metadata: {agent.fingerprint.metadata}")
```

## Persistência das impressões digitais

As impressões digitais foram projetadas para persistir e permanecer inalteradas durante todo o ciclo de vida de um componente. Se você modificar um componente, a impressão digital permanece a mesma:

```python
original_fingerprint = agent.fingerprint.uuid_str

# Modificar o agente
agent.goal = "New goal for analysis"

# A impressão digital permanece inalterada
assert agent.fingerprint.uuid_str == original_fingerprint
```

## Impressões digitais determinísticas

Apesar de não ser possível definir diretamente o UUID e o timestamp de criação, é possível criar impressões digitais determinísticas usando o método `generate` com uma seed:

```python
from crewai.security import Fingerprint

# Criar uma impressão digital determinística usando uma string seed
deterministic_fingerprint = Fingerprint.generate(seed="my-agent-id")

# A mesma seed sempre gera a mesma impressão digital
same_fingerprint = Fingerprint.generate(seed="my-agent-id")
assert deterministic_fingerprint.uuid_str == same_fingerprint.uuid_str

# Também é possível definir metadados
custom_fingerprint = Fingerprint.generate(
    seed="my-agent-id",
    metadata={"version": "1.0"}
)
```

## Uso avançado

### Estrutura da impressão digital

Cada impressão digital possui a seguinte estrutura:

```python
from crewai.security import Fingerprint

fingerprint = agent.fingerprint

# String UUID - identificador único (gerado automaticamente)
uuid_str = fingerprint.uuid_str  # e.g., "123e4567-e89b-12d3-a456-426614174000"

# Timestamp de criação (gerado automaticamente)
created_at = fingerprint.created_at  # Um objeto datetime

# Metadados - informações adicionais (podem ser customizadas)
metadata = fingerprint.metadata  # Um dicionário, padrão {}
```


# Criando Agentes Eficazes
Source: https://docs.crewai.com/pt-BR/guides/agents/crafting-effective-agents

Aprenda as melhores práticas para projetar agentes de IA poderosos e especializados que colaboram de forma eficaz para resolver problemas complexos.

## A Arte e a Ciência do Design de Agentes

No núcleo do CrewAI está o agente – uma entidade de IA especializada projetada para desempenhar funções específicas dentro de um framework colaborativo. Embora criar agentes básicos seja simples, criar agentes verdadeiramente eficazes que geram resultados excepcionais requer a compreensão de princípios fundamentais de design e boas práticas.

Este guia vai ajudá-lo a dominar a arte de projetar agentes, permitindo criar personas de IA especializadas que colaboram de forma eficaz, pensam criticamente e produzem resultados de alta qualidade adaptados às suas necessidades específicas.

### Por Que o Design de Agentes é Importante

A forma como você define seus agentes impacta significativamente:

1. **Qualidade do resultado**: Agentes bem projetados produzem resultados mais relevantes e de alta qualidade
2. **Eficiência da colaboração**: Agentes com habilidades complementares trabalham juntos de maneira mais eficiente
3. **Desempenho nas tarefas**: Agentes com papéis e objetivos claros executam tarefas de forma mais eficaz
4. **Escalabilidade do sistema**: Agentes bem projetados podem ser reutilizados em múltiplos crews e contextos

Vamos explorar as melhores práticas para criar agentes que se destacam nessas dimensões.

## A Regra 80/20: Foque Mais nas Tarefas do que nos Agentes

Ao construir sistemas de IA eficazes, lembre-se deste princípio crucial: **80% do seu esforço deve ser dedicado ao design das tarefas, e apenas 20% à definição dos agentes**.

Por quê? Porque mesmo o agente mais perfeitamente definido irá falhar com tarefas mal elaboradas, mas tarefas bem projetadas podem elevar até mesmo agentes simples. Isso significa:

* Dedique a maior parte do seu tempo escrevendo instruções claras para as tarefas
* Defina entradas detalhadas e saídas esperadas
* Adicione exemplos e contexto para orientar a execução
* Reserve o tempo restante para o papel, objetivo e histórico do agente

Isso não quer dizer que o design do agente não seja importante – ele é, sim. Mas o design das tarefas é onde ocorrem a maioria das falhas de execução, então priorize de acordo.

## Princípios Fundamentais do Design de Agentes Eficazes

### 1. O Framework Papel–Objetivo–Histórico

Os agentes mais poderosos no CrewAI têm uma base sólida em três elementos-chave:

#### Papel: A Função Especializada do Agente

O papel define o que o agente faz e sua área de especialização. Ao criar papéis:

* **Seja específico e especializado**: Em vez de “Escritor”, use “Especialista em Documentação Técnica” ou “Contador de Histórias Criativo”
* **Alinhe com profissões do mundo real**: Baseie os papéis em arquétipos profissionais reconhecíveis
* **Inclua expertise no domínio**: Especifique o campo de conhecimento do agente (ex: “Analista Financeiro especializado em tendências de mercado”)

**Exemplos de papéis eficazes:**

```yaml
role: "Pesquisador Sênior de UX especializado em análise de entrevistas com usuários"
role: "Arquiteto de Software Full-Stack com expertise em sistemas distribuídos"
role: "Diretor de Comunicação Corporativa especializado em gestão de crises"
```

#### Objetivo: A Finalidade e Motivação do Agente

O objetivo direciona os esforços do agente e orienta seu processo de tomada de decisão. Objetivos eficazes devem:

* **Ser claros e focados em resultado**: Defina o que o agente precisa alcançar
* **Enfatizar padrões de qualidade**: Inclua expectativas sobre a qualidade do trabalho
* **Incorporar critérios de sucesso**: Ajude o agente a entender o que é considerado “bom”

**Exemplos de objetivos eficazes:**

```yaml
goal: "Descobrir insights acionáveis analisando dados de entrevistas, identificando padrões recorrentes, necessidades não atendidas e oportunidades de melhoria"
goal: "Projetar arquiteturas de sistemas robustas e escaláveis que equilibrem performance, manutenção e custo-benefício"
goal: "Criar comunicações de crise claras e empáticas, abordando as preocupações das partes interessadas e protegendo a reputação organizacional"
```

#### Histórico: Experiência e Perspectiva do Agente

O histórico aprofunda o agente, influenciando como ele aborda problemas e interage com os demais. Bons históricos:

* **Estabelecem expertise e experiência**: Explique como o agente adquiriu suas habilidades
* **Definem estilo de trabalho e valores**: Descreva como o agente encara seu trabalho
* **Criam uma persona coesa**: Garanta que todos os elementos do histórico estejam alinhados ao papel e ao objetivo

**Exemplos de históricos eficazes:**

```yaml
backstory: "Você passou 15 anos conduzindo e analisando pesquisas com usuários em grandes empresas de tecnologia. Tem talento para ler nas entrelinhas e identificar padrões que outros não enxergam. Acredita que uma boa experiência do usuário é invisível e que os melhores insights vêm tanto do que os usuários não dizem quanto do que dizem."

backstory: "Com mais de 20 anos de experiência construindo sistemas distribuídos em larga escala, você desenvolveu uma abordagem pragmática para arquitetura de software. Viu sistemas bem sucedidos e fracassados e aprendeu lições valiosas com ambos. Equilibra as melhores práticas teóricas com restrições práticas e sempre considera os aspectos de manutenção e operação em seus projetos."

backstory: "Como um profissional de comunicação experiente que já orientou múltiplas organizações em crises de grande repercussão, você entende a importância da transparência, agilidade e empatia em respostas a crises. Tem uma abordagem metódica para criar mensagens que abordam preocupações mantendo a credibilidade da organização."
```

### 2. Especialistas em vez de Generalistas

Agentes desempenham muito melhor quando recebem papéis especializados em vez de papéis genéricos. Um agente altamente focado gera resultados mais precisos e relevantes:

**Genérico (Menos Eficaz):**

```yaml
role: "Writer"
```

**Especializado (Mais Eficaz):**

```yaml
role: "Redator Técnico de Blog especializado em explicar conceitos complexos de IA para públicos não técnicos"
```

**Vantagens dos Especialistas:**

* Compreensão mais clara do resultado esperado
* Performance mais consistente
* Melhor alinhamento com tarefas específicas
* Maior capacidade de fazer julgamentos específicos do domínio

### 3. Equilibrando Especialização e Versatilidade

Agentes eficazes equilibram bem a especialização (fazer uma coisa muito bem) e a versatilidade (adaptar-se a diversas situações):

* **Especialize no papel, seja versátil na aplicação**: Crie agentes com habilidades especializadas aplicáveis em múltiplos contextos
* **Evite definições excessivamente restritas**: Garanta que agentes possam lidar com variações dentro de sua área de expertise
* **Considere o contexto colaborativo**: Projete agentes cujas especialidades complementem os demais do crew

### 4. Definição Nível Apropriado de Expertise

O nível de expertise atribuído ao agente determina como ele realiza as tarefas:

* **Agentes iniciantes**: Bons para tarefas simples, brainstorm, rascunhos iniciais
* **Agentes intermediários**: Adequados para a maioria das tarefas padrão com execução confiável
* **Agentes especialistas**: Ideais para tarefas complexas e especializadas que exigem profundidade e nuances
* **Agentes de classe mundial**: Reservados para tarefas críticas onde a qualidade excepcional é essencial

Escolha o nível de expertise baseado na complexidade da tarefa e no padrão de qualidade exigido. Em crews colaborativos, tendem a funcionar melhor equipes com níveis variados de expertise, reservando maior especialização para as funções mais chave.

## Exemplos Práticos: Antes e Depois

Veja exemplos de definições de agentes antes e depois de aplicar essas boas práticas:

### Exemplo 1: Agente de Criação de Conteúdo

**Antes:**

```yaml
role: "Writer"
goal: "Write good content"
backstory: "You are a writer who creates content for websites."
```

**Depois:**

```yaml
role: "Estrategista de Conteúdo B2B para Tecnologia"
goal: "Criar conteúdos envolventes e tecnicamente precisos, explicando tópicos complexos em linguagem acessível, promovendo engajamento e apoiando os objetivos do negócio"
backstory: "Você passou uma década criando conteúdos para empresas líderes em tecnologia, especializando-se na tradução de conceitos técnicos para públicos empresariais. É ótimo em pesquisa, entrevistas com especialistas e estruturação da informação para máxima clareza e impacto. Acredita que o melhor conteúdo B2B educa antes de vender, construindo confiança através da expertise genuína e não do hype de marketing."
```

### Exemplo 2: Agente de Pesquisa

**Antes:**

```yaml
role: "Researcher"
goal: "Find information"
backstory: "You are good at finding information online."
```

**Depois:**

```yaml
role: "Especialista em Pesquisa Acadêmica de Tecnologias Emergentes"
goal: "Descobrir e sintetizar pesquisas de ponta, identificando tendências, metodologias e resultados principais, avaliando a qualidade e confiabilidade das fontes"
backstory: "Com formação em ciência da computação e biblioteconomia, você dominou a arte da pesquisa digital. Já trabalhou com equipes de pesquisa em universidades de prestígio e sabe como navegar bancos de dados acadêmicos, avaliar a qualidade das pesquisas e sintetizar descobertas em diferentes áreas. Seu método é rigoroso: sempre cruza informações e rastreia a origem dos dados antes de chegar a conclusões."
```

## Criando Tarefas Eficazes para seus Agentes

Embora o design dos agentes seja importante, o design das tarefas é crítico para uma boa execução. Aqui estão as melhores práticas para definir tarefas que irão impulsionar o sucesso dos seus agentes:

### A Anatomia de uma Tarefa Eficaz

Uma tarefa bem projetada tem dois componentes-chave com propósitos distintos:

#### Descrição da Tarefa: O Processo

A descrição deve focar no que fazer e como fazer, incluindo:

* Instruções detalhadas de execução
* Contexto e informações de fundo
* Escopo e restrições
* Passos do processo a serem seguidos

#### Saída Esperada: O Entregável

A saída esperada deve definir como o resultado final deve ser apresentado:

* Especificações de formato (markdown, JSON, etc.)
* Estrutura exigida
* Critérios de qualidade
* Exemplos de bons entregáveis (sempre que possível)

### Melhores Práticas para Design de Tarefas

#### 1. Propósito Único, Saída Única

Tarefas funcionam melhor quando são focadas em um objetivo claro:

**Exemplo Ruim (Muito Abrangente):**

```yaml
task_description: "Research market trends, analyze the data, and create a visualization."
```

**Exemplo Bom (Focado):**

```yaml
# Task 1
research_task:
  description: "Research the top 5 market trends in the AI industry for 2024."
  expected_output: "A markdown list of the 5 trends with supporting evidence."

# Task 2
analysis_task:
  description: "Analyze the identified trends to determine potential business impacts."
  expected_output: "A structured analysis with impact ratings (High/Medium/Low)."

# Task 3
visualization_task:
  description: "Create a visual representation of the analyzed trends."
  expected_output: "A description of a chart showing trends and their impact ratings."
```

#### 2. Seja Explícito Sobre Entradas e Saídas

Sempre especifique claramente quais são as entradas da tarefa e como deve ser o resultado:

**Exemplo:**

```yaml
analysis_task:
  description: >
    Analyze the customer feedback data from the CSV file.
    Focus on identifying recurring themes related to product usability.
    Consider sentiment and frequency when determining importance.
  expected_output: >
    A markdown report with the following sections:
    1. Executive summary (3-5 bullet points)
    2. Top 3 usability issues with supporting data
    3. Recommendations for improvement
```

#### 3. Inclua Propósito e Contexto

Explique por que a tarefa importa e como ela se encaixa no fluxo de trabalho maior:

**Exemplo:**

```yaml
competitor_analysis_task:
  description: >
    Analyze our three main competitors' pricing strategies.
    This analysis will inform our upcoming pricing model revision.
    Focus on identifying patterns in how they price premium features
    and how they structure their tiered offerings.
```

#### 4. Use Ferramentas de Saída Estruturada

Para saídas legíveis por máquina, especifique claramente o formato:

**Exemplo:**

```yaml
data_extraction_task:
  description: "Extract key metrics from the quarterly report."
  expected_output: "JSON object with the following keys: revenue, growth_rate, customer_acquisition_cost, and retention_rate."
```

## Erros Comuns a Evitar

Baseando-se em experiências de casos reais, estes são os erros mais comuns no design de agentes e tarefas:

### 1. Instruções de Tarefa Pouco Claras

**Problema:** Tarefas sem detalhes suficientes, dificultando a execução pelo agente.

**Exemplo de Design Ruim:**

```yaml
research_task:
  description: "Research AI trends."
  expected_output: "A report on AI trends."
```

**Versão Melhorada:**

```yaml
research_task:
  description: >
    Research the top emerging AI trends for 2024 with a focus on:
    1. Enterprise adoption patterns
    2. Technical breakthroughs in the past 6 months
    3. Regulatory developments affecting implementation

    For each trend, identify key companies, technologies, and potential business impacts.
  expected_output: >
    A comprehensive markdown report with:
    - Executive summary (5 bullet points)
    - 5-7 major trends with supporting evidence
    - For each trend: definition, examples, and business implications
    - References to authoritative sources
```

### 2. "Tarefas-Deus" Que Tentam Fazer Demais

**Problema:** Tarefas que combinam múltiplas operações complexas em um único conjunto de instruções.

**Exemplo de Design Ruim:**

```yaml
comprehensive_task:
  description: "Research market trends, analyze competitor strategies, create a marketing plan, and design a launch timeline."
```

**Versão Melhorada:**
Divida em tarefas sequenciais e focadas:

```yaml
# Task 1: Research
market_research_task:
  description: "Research current market trends in the SaaS project management space."
  expected_output: "A markdown summary of key market trends."

# Task 2: Competitive Analysis
competitor_analysis_task:
  description: "Analyze strategies of the top 3 competitors based on the market research."
  expected_output: "A comparison table of competitor strategies."
  context: [market_research_task]

# Continue with additional focused tasks...
```

### 3. Descrição e Saída Esperada Desalinhadas

**Problema:** O que a descrição pede não corresponde ao que a saída esperada especifica.

**Exemplo de Design Ruim:**

```yaml
analysis_task:
  description: "Analyze customer feedback to find areas of improvement."
  expected_output: "A marketing plan for the next quarter."
```

**Versão Melhorada:**

```yaml
analysis_task:
  description: "Analyze customer feedback to identify the top 3 areas for product improvement."
  expected_output: "A report listing the 3 priority improvement areas with supporting customer quotes and data points."
```

### 4. Não Entender o Processo Você Mesmo

**Problema:** Pedir para o agente executar tarefas que você mesmo não entende completamente.

**Solução:**

1. Tente realizar a tarefa manualmente primeiro
2. Documente o processo, pontos de decisão e fontes de informação
3. Use esta documentação como base para a descrição da tarefa

### 5. Uso Prematuro de Estruturas Hierárquicas

**Problema:** Criar hierarquias de agentes desnecessariamente complexas quando processos sequenciais seriam suficientes.

**Solução:** Comece com processos sequenciais e só adote modelos hierárquicos quando a complexidade do fluxo de trabalho realmente justificar.

### 6. Definições Genéricas ou Pouco Claras de Agentes

**Problema:** Definições genéricas de agentes levam a resultados genéricos.

**Exemplo de Design Ruim:**

```yaml
agent:
  role: "Business Analyst"
  goal: "Analyze business data"
  backstory: "You are good at business analysis."
```

**Versão Melhorada:**

```yaml
agent:
  role: "Especialista em Métricas SaaS focado em startups em fase de crescimento"
  goal: "Identificar insights acionáveis em dados de negócios que possam impactar diretamente a retenção de clientes e o crescimento de receita"
  backstory: "Com mais de 10 anos analisando modelos de negócios SaaS, você desenvolveu um olhar apurado para as métricas que realmente impulsionam crescimento sustentável. Já ajudou diversas empresas a identificar pontos de alavancagem que mudaram o rumo dos negócios. Acredita em conectar dados a recomendações específicas e acionáveis, e não apenas a observações genéricas."
```

## Estratégias Avançadas de Design de Agentes

### Projetando para Colaboração

Ao criar agentes que trabalharão em conjunto em um crew, pense em:

* **Habilidades complementares**: Projete agentes com competências distintas, porém complementares
* **Pontos de transferência**: Defina interfaces claras para a passagem de trabalho entre agentes
* **Tensão construtiva**: Às vezes, agentes com perspectivas um pouco diferentes promovem melhores resultados por meio de diálogos construtivos

Por exemplo, um crew de criação de conteúdo pode incluir:

```yaml
# Research Agent
role: "Research Specialist for technical topics"
goal: "Gather comprehensive, accurate information from authoritative sources"
backstory: "You are a meticulous researcher with a background in library science..."

# Writer Agent
role: "Technical Content Writer"
goal: "Transform research into engaging, clear content that educates and informs"
backstory: "You are an experienced writer who excels at explaining complex concepts..."

# Editor Agent
role: "Content Quality Editor"
goal: "Ensure content is accurate, well-structured, and polished while maintaining consistency"
backstory: "With years of experience in publishing, you have a keen eye for detail..."
```

### Criando Usuários Especializados de Ferramentas

Alguns agentes podem ser projetados para explorar certas ferramentas de maneira eficiente:

```yaml
role: "Data Analysis Specialist"
goal: "Derive meaningful insights from complex datasets through statistical analysis"
backstory: "With a background in data science, you excel at working with structured and unstructured data..."
tools: [PythonREPLTool, DataVisualizationTool, CSVAnalysisTool]
```

### Personalizando Agentes para Capacidades do LLM

Diferentes LLMs têm pontos fortes distintos. Projete seus agentes levando essas capacidades em conta:

```yaml
# For complex reasoning tasks
analyst:
  role: "Data Insights Analyst"
  goal: "..."
  backstory: "..."
  llm: openai/gpt-4o

# For creative content
writer:
  role: "Creative Content Writer"
  goal: "..."
  backstory: "..."
  llm: anthropic/claude-3-opus
```

## Testando e Iterando no Design de Agentes

A construção de agentes geralmente é um processo iterativo. Veja como colocar em prática:

1. **Comece com um protótipo**: Crie uma definição inicial do agente
2. **Teste com tarefas de exemplo**: Avalie o desempenho em tarefas representativas
3. **Analise os resultados**: Identifique pontos fortes e fracos
4. **Refine a definição**: Ajuste papel, objetivo e histórico conforme suas observações
5. **Teste em colaboração**: Avalie como o agente se sai em conjunto no crew

## Conclusão

Criar agentes eficazes é tanto arte quanto ciência. Ao definir cuidadosamente papéis, objetivos e históricos alinhados às suas necessidades, e combinar isso com tarefas bem projetadas, você constrói colaboradores de IA especializados capazes de gerar resultados excepcionais.

Lembre-se de que o design de agentes e tarefas é um processo iterativo. Comece com essas boas práticas, observe os agentes em ação e refine sua abordagem conforme necessário. E sempre tenha em mente a regra 80/20 – concentre a maior parte do esforço em criar tarefas claras e focadas para tirar o melhor de seus agentes.

<Check>
  Parabéns! Agora você entende os princípios e práticas do design eficaz de agentes. Aplique estas técnicas para criar agentes poderosos e especializados que trabalham juntos perfeitamente e realizam tarefas complexas.
</Check>

## Próximos Passos

* Experimente diferentes configurações de agentes para o seu caso de uso
* Aprenda sobre [como construir seu primeiro crew](/pt-BR/guides/crews/first-crew) para ver como agentes trabalham juntos
* Explore os [CrewAI Flows](/pt-BR/guides/flows/first-flow) para uma orquestração mais avançada


# Avaliando Casos de Uso para CrewAI
Source: https://docs.crewai.com/pt-BR/guides/concepts/evaluating-use-cases

Aprenda a avaliar as necessidades da sua aplicação de IA e escolher a abordagem certa entre Crews e Flows com base nos requisitos de complexidade e precisão.

## Entendendo o Framework de Decisão

Ao construir aplicações de IA com CrewAI, uma das decisões mais importantes que você tomará é escolher a abordagem correta para o seu caso de uso específico. Você deve usar uma Crew? Um Flow? Uma combinação dos dois? Este guia vai ajudar você a avaliar seus requisitos e tomar decisões arquitetônicas embasadas.

No centro dessa decisão está o entendimento da relação entre **complexidade** e **precisão** em sua aplicação:

<Frame caption="Matriz de Complexidade vs. Precisão para Aplicações CrewAI">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/complexity_precision.png" alt="Matriz de Complexidade vs. Precisão" />
</Frame>

Essa matriz ajuda a visualizar como diferentes abordagens se alinham com os requisitos variados de complexidade e precisão. Vamos explorar o significado de cada quadrante e como isso orienta suas escolhas arquiteturais.

## Explicando a Matriz Complexidade-Precisão

### O que é Complexidade?

No contexto das aplicações CrewAI, **complexidade** refere-se a:

* O número de etapas ou operações distintas necessárias
* A diversidade de tarefas que precisam ser realizadas
* As interdependências entre diferentes componentes
* A necessidade de lógica condicional e ramificações
* A sofisticação do fluxo de trabalho como um todo

### O que é Precisão?

**Precisão** nesse contexto refere-se a:

* O grau de exatidão exigido no resultado final
* A necessidade de resultados estruturados e previsíveis
* A importância da reprodutibilidade
* O nível de controle necessário sobre cada etapa
* A tolerância à variação nos resultados

### Os Quatro Quadrantes

#### 1. Baixa Complexidade, Baixa Precisão

**Características:**

* Tarefas simples e diretas
* Tolerância a alguma variação nos resultados
* Número limitado de etapas
* Aplicações criativas ou exploratórias

**Abordagem Recomendada:** Crews simples com poucos agentes

**Exemplos de Casos de Uso:**

* Geração básica de conteúdo
* Brainstorming de ideias
* Tarefas simples de sumarização
* Assistência à escrita criativa

#### 2. Baixa Complexidade, Alta Precisão

**Características:**

* Fluxos de trabalho simples que exigem resultados exatos e estruturados
* Necessidade de resultados reproduzíveis
* Poucas etapas, mas alto requisito de precisão
* Frequentemente envolve processamento ou transformação de dados

**Abordagem Recomendada:** Flows com chamadas diretas a LLM ou Crews simples com saídas estruturadas

**Exemplos de Casos de Uso:**

* Extração e transformação de dados
* Preenchimento e validação de formulários
* Geração estruturada de conteúdo (JSON, XML)
* Tarefas simples de classificação

#### 3. Alta Complexidade, Baixa Precisão

**Características:**

* Processos multiestágio com muitas etapas
* Saídas criativas ou exploratórias
* Interações complexas entre componentes
* Tolerância à variação nos resultados finais

**Abordagem Recomendada:** Crews complexas com múltiplos agentes especializados

**Exemplos de Casos de Uso:**

* Pesquisa e análise
* Pipelines de criação de conteúdo
* Análise exploratória de dados
* Solução criativa de problemas

#### 4. Alta Complexidade, Alta Precisão

**Características:**

* Fluxos de trabalho complexos que requerem saídas estruturadas
* Múltiplas etapas interdependentes com rígida exigência de precisão
* Necessidade tanto de processamento sofisticado quanto de resultados precisos
* Frequentemente aplicações críticas

**Abordagem Recomendada:** Flows orquestrando múltiplas Crews com etapas de validação

**Exemplos de Casos de Uso:**

* Sistemas corporativos de suporte à decisão
* Pipelines complexos de processamento de dados
* Processamento de documentos em múltiplos estágios
* Aplicações em indústrias reguladas

## Escolhendo Entre Crews e Flows

### Quando Escolher Crews

Crews são ideais quando:

1. **Você precisa de inteligência colaborativa** - Múltiplos agentes com especializações diferentes precisam trabalhar juntos
2. **O problema requer pensamento emergente** - A solução se beneficia de diferentes perspectivas e abordagens
3. **A tarefa é principalmente criativa ou analítica** - O trabalho envolve pesquisa, criação de conteúdo ou análise
4. **Você valoriza adaptabilidade mais do que estrutura rígida** - O fluxo de trabalho pode se beneficiar da autonomia dos agentes
5. **O formato da saída pode ser um pouco flexível** - Alguma variação na estrutura do resultado é aceitável

```python
# Example: Research Crew for market analysis
from crewai import Agent, Crew, Process, Task

# Create specialized agents
researcher = Agent(
    role="Market Research Specialist",
    goal="Find comprehensive market data on emerging technologies",
    backstory="You are an expert at discovering market trends and gathering data."
)

analyst = Agent(
    role="Market Analyst",
    goal="Analyze market data and identify key opportunities",
    backstory="You excel at interpreting market data and spotting valuable insights."
)

# Define their tasks
research_task = Task(
    description="Research the current market landscape for AI-powered healthcare solutions",
    expected_output="Comprehensive market data including key players, market size, and growth trends",
    agent=researcher
)

analysis_task = Task(
    description="Analyze the market data and identify the top 3 investment opportunities",
    expected_output="Analysis report with 3 recommended investment opportunities and rationale",
    agent=analyst,
    context=[research_task]
)

# Create the crew
market_analysis_crew = Crew(
    agents=[researcher, analyst],
    tasks=[research_task, analysis_task],
    process=Process.sequential,
    verbose=True
)

# Run the crew
result = market_analysis_crew.kickoff()
```

### Quando Escolher Flows

Flows são ideais quando:

1. **Você precisa de controle preciso da execução** - O fluxo de trabalho exige sequenciamento exato e gerenciamento de estado
2. **A aplicação tem requisitos complexos de estado** - Você precisa manter e transformar estado ao longo de múltiplas etapas
3. **Você precisa de saídas estruturadas e previsíveis** - A aplicação exige resultados consistentes e formatados
4. **O fluxo de trabalho envolve lógica condicional** - Caminhos diferentes precisam ser seguidos com base em resultados intermediários
5. **Você precisa combinar IA com código procedural** - A solução demanda tanto capacidades de IA quanto programação tradicional

```python
# Example: Customer Support Flow with structured processing
from crewai.flow.flow import Flow, listen, router, start
from pydantic import BaseModel
from typing import List, Dict

# Define structured state
class SupportTicketState(BaseModel):
    ticket_id: str = ""
    customer_name: str = ""
    issue_description: str = ""
    category: str = ""
    priority: str = "medium"
    resolution: str = ""
    satisfaction_score: int = 0

class CustomerSupportFlow(Flow[SupportTicketState]):
    @start()
    def receive_ticket(self):
        # In a real app, this might come from an API
        self.state.ticket_id = "TKT-12345"
        self.state.customer_name = "Alex Johnson"
        self.state.issue_description = "Unable to access premium features after payment"
        return "Ticket received"

    @listen(receive_ticket)
    def categorize_ticket(self, _):
        # Use a direct LLM call for categorization
        from crewai import LLM
        llm = LLM(model="openai/gpt-4o-mini")

        prompt = f"""
        Categorize the following customer support issue into one of these categories:
        - Billing
        - Account Access
        - Technical Issue
        - Feature Request
        - Other

        Issue: {self.state.issue_description}

        Return only the category name.
        """

        self.state.category = llm.call(prompt).strip()
        return self.state.category

    @router(categorize_ticket)
    def route_by_category(self, category):
        # Route to different handlers based on category
        return category.lower().replace(" ", "_")

    @listen("billing")
    def handle_billing_issue(self):
        # Handle billing-specific logic
        self.state.priority = "high"
        # More billing-specific processing...
        return "Billing issue handled"

    @listen("account_access")
    def handle_access_issue(self):
        # Handle access-specific logic
        self.state.priority = "high"
        # More access-specific processing...
        return "Access issue handled"

    # Additional category handlers...

    @listen("billing", "account_access", "technical_issue", "feature_request", "other")
    def resolve_ticket(self, resolution_info):
        # Final resolution step
        self.state.resolution = f"Issue resolved: {resolution_info}"
        return self.state.resolution

# Run the flow
support_flow = CustomerSupportFlow()
result = support_flow.kickoff()
```

### Quando Combinar Crews e Flows

As aplicações mais sofisticadas frequentemente se beneficiam da combinação de Crews e Flows:

1. **Processos complexos em múltiplos estágios** - Use Flows para orquestrar o processo geral e Crews para sub-tarefas complexas
2. **Aplicações que exigem criatividade e estrutura** - Use Crews para tarefas criativas e Flows para processamento estruturado
3. **Aplicações corporativas de IA** - Use Flows para gerenciar estado e fluxo de processo enquanto aproveita Crews para tarefas especializadas

```python
# Example: Content Production Pipeline combining Crews and Flows
from crewai.flow.flow import Flow, listen, start
from crewai import Agent, Crew, Process, Task
from pydantic import BaseModel
from typing import List, Dict

class ContentState(BaseModel):
    topic: str = ""
    target_audience: str = ""
    content_type: str = ""
    outline: Dict = {}
    draft_content: str = ""
    final_content: str = ""
    seo_score: int = 0

class ContentProductionFlow(Flow[ContentState]):
    @start()
    def initialize_project(self):
        # Set initial parameters
        self.state.topic = "Sustainable Investing"
        self.state.target_audience = "Millennial Investors"
        self.state.content_type = "Blog Post"
        return "Project initialized"

    @listen(initialize_project)
    def create_outline(self, _):
        # Use a research crew to create an outline
        researcher = Agent(
            role="Content Researcher",
            goal=f"Research {self.state.topic} for {self.state.target_audience}",
            backstory="You are an expert researcher with deep knowledge of content creation."
        )

        outliner = Agent(
            role="Content Strategist",
            goal=f"Create an engaging outline for a {self.state.content_type}",
            backstory="You excel at structuring content for maximum engagement."
        )

        research_task = Task(
            description=f"Research {self.state.topic} focusing on what would interest {self.state.target_audience}",
            expected_output="Comprehensive research notes with key points and statistics",
            agent=researcher
        )

        outline_task = Task(
            description=f"Create an outline for a {self.state.content_type} about {self.state.topic}",
            expected_output="Detailed content outline with sections and key points",
            agent=outliner,
            context=[research_task]
        )

        outline_crew = Crew(
            agents=[researcher, outliner],
            tasks=[research_task, outline_task],
            process=Process.sequential,
            verbose=True
        )

        # Run the crew and store the result
        result = outline_crew.kickoff()

        # Parse the outline (in a real app, you might use a more robust parsing approach)
        import json
        try:
            self.state.outline = json.loads(result.raw)
        except:
            # Fallback if not valid JSON
            self.state.outline = {"sections": result.raw}

        return "Outline created"

    @listen(create_outline)
    def write_content(self, _):
        # Use a writing crew to create the content
        writer = Agent(
            role="Content Writer",
            goal=f"Write engaging content for {self.state.target_audience}",
            backstory="You are a skilled writer who creates compelling content."
        )

        editor = Agent(
            role="Content Editor",
            goal="Ensure content is polished, accurate, and engaging",
            backstory="You have a keen eye for detail and a talent for improving content."
        )

        writing_task = Task(
            description=f"Write a {self.state.content_type} about {self.state.topic} following this outline: {self.state.outline}",
            expected_output="Complete draft content in markdown format",
            agent=writer
        )

        editing_task = Task(
            description="Edit and improve the draft content for clarity, engagement, and accuracy",
            expected_output="Polished final content in markdown format",
            agent=editor,
            context=[writing_task]
        )

        writing_crew = Crew(
            agents=[writer, editor],
            tasks=[writing_task, editing_task],
            process=Process.sequential,
            verbose=True
        )

        # Run the crew and store the result
        result = writing_crew.kickoff()
        self.state.final_content = result.raw

        return "Content created"

    @listen(write_content)
    def optimize_for_seo(self, _):
        # Use a direct LLM call for SEO optimization
        from crewai import LLM
        llm = LLM(model="openai/gpt-4o-mini")

        prompt = f"""
        Analyze this content for SEO effectiveness for the keyword "{self.state.topic}".
        Rate it on a scale of 1-100 and provide 3 specific recommendations for improvement.

        Content: {self.state.final_content[:1000]}... (truncated for brevity)

        Format your response as JSON with the following structure:
        {{
            "score": 85,
            "recommendations": [
                "Recommendation 1",
                "Recommendation 2",
                "Recommendation 3"
            ]
        }}
        """

        seo_analysis = llm.call(prompt)

        # Parse the SEO analysis
        import json
        try:
            analysis = json.loads(seo_analysis)
            self.state.seo_score = analysis.get("score", 0)
            return analysis
        except:
            self.state.seo_score = 50
            return {"score": 50, "recommendations": ["Unable to parse SEO analysis"]}

# Run the flow
content_flow = ContentProductionFlow()
result = content_flow.kickoff()
```

## Framework Prático de Avaliação

Para determinar a abordagem certa para seu caso de uso específico, siga este framework passo a passo:

### Passo 1: Avalie a Complexidade

Classifique a complexidade do seu aplicativo numa escala de 1-10 considerando:

1. **Número de etapas**: Quantas operações distintas são necessárias?
   * 1-3 etapas: Baixa complexidade (1-3)
   * 4-7 etapas: Média complexidade (4-7)
   * 8+ etapas: Alta complexidade (8-10)

2. **Interdependências**: Quão interligadas estão as partes diferentes?
   * Poucas dependências: Baixa complexidade (1-3)
   * Algumas dependências: Média complexidade (4-7)
   * Muitas dependências complexas: Alta complexidade (8-10)

3. **Lógica condicional**: Quanto de ramificação e tomada de decisão é necessário?
   * Processo linear: Baixa complexidade (1-3)
   * Alguma ramificação: Média complexidade (4-7)
   * Árvores de decisão complexas: Alta complexidade (8-10)

4. **Conhecimento de domínio**: Quão especializado deve ser o conhecimento requerido?
   * Conhecimento geral: Baixa complexidade (1-3)
   * Algum conhecimento especializado: Média complexidade (4-7)
   * Grande especialização em múltiplos domínios: Alta complexidade (8-10)

Calcule a média das pontuações para determinar sua complexidade geral.

### Passo 2: Avalie os Requisitos de Precisão

Classifique seus requisitos de precisão numa escala de 1-10 considerando:

1. **Estrutura da saída**: Quão estruturado o resultado deve ser?
   * Texto livre: Baixa precisão (1-3)
   * Semi-estruturado: Média precisão (4-7)
   * Estritamente formatado (JSON, XML): Alta precisão (8-10)

2. **Necessidade de exatidão**: Qual a importância da precisão factual?
   * Conteúdo criativo: Baixa precisão (1-3)
   * Conteúdo informacional: Média precisão (4-7)
   * Informação crítica: Alta precisão (8-10)

3. **Reprodutibilidade**: Quão consistentes devem ser os resultados entre execuções?
   * Variação aceitável: Baixa precisão (1-3)
   * Alguma consistência necessária: Média precisão (4-7)
   * Exata reprodutibilidade: Alta precisão (8-10)

4. **Tolerância a erros**: Qual o impacto de erros?
   * Baixo impacto: Baixa precisão (1-3)
   * Impacto moderado: Média precisão (4-7)
   * Alto impacto: Alta precisão (8-10)

Calcule a média das pontuações para determinar seu requisito geral de precisão.

### Passo 3: Mapeie na Matriz

Plote as pontuações de complexidade e precisão na matriz:

* **Baixa Complexidade (1-4), Baixa Precisão (1-4)**: Crews simples
* **Baixa Complexidade (1-4), Alta Precisão (5-10)**: Flows com chamadas diretas a LLM
* **Alta Complexidade (5-10), Baixa Precisão (1-4)**: Crews complexas
* **Alta Complexidade (5-10), Alta Precisão (5-10)**: Flows orquestrando Crews

### Passo 4: Considere Fatores Adicionais

Além de complexidade e precisão, considere:

1. **Tempo de desenvolvimento**: Crews costumam ser mais rápidas para prototipar
2. **Necessidades de manutenção**: Flows proporcionam melhor manutenção a longo prazo
3. **Expertise do time**: Considere a familiaridade de sua equipe com as abordagens
4. **Requisitos de escalabilidade**: Flows normalmente escalam melhor para aplicações complexas
5. **Necessidades de integração**: Considere como a solução se integrará aos sistemas existentes

## Conclusão

Escolher entre Crews e Flows — ou combiná-los — é uma decisão arquitetônica crítica que impacta a efetividade, manutenibilidade e escalabilidade da sua aplicação CrewAI. Ao avaliar seu caso de uso nas dimensões de complexidade e precisão, você toma decisões inteligentes que alinham-se aos seus requisitos.

Lembre-se de que a melhor abordagem geralmente evolui na medida em que sua aplicação amadurece. Comece com a solução mais simples que atenda às suas necessidades e esteja preparado para refinar sua arquitetura conforme for ganhando experiência e seus requisitos se tornarem mais claros.

<Check>
  Agora você tem um framework para avaliar casos de uso CrewAI e escolher a abordagem certa de acordo com requisitos de complexidade e precisão. Isso vai ajudar você a construir aplicações de IA mais eficientes, de fácil manutenção e escaláveis.
</Check>

## Próximos Passos

* Saiba mais sobre [como criar agentes eficazes](/pt-BR/guides/agents/crafting-effective-agents)
* Explore [como construir sua primeira crew](/pt-BR/guides/crews/first-crew)
* Aprofunde-se em [gerenciamento de estado em flows](/pt-BR/guides/flows/mastering-flow-state)
* Confira os [conceitos centrais](/pt-BR/concepts/agents) para um entendimento mais aprofundado


# Monte sua Primeira Crew
Source: https://docs.crewai.com/pt-BR/guides/crews/first-crew

Tutorial passo a passo para criar uma equipe colaborativa de IA que trabalha junta para resolver problemas complexos.

## Liberando o Poder da IA Colaborativa

Imagine ter uma equipe de agentes de IA especializados trabalhando juntos de forma harmoniosa para resolver problemas complexos, cada um contribuindo com suas habilidades únicas para alcançar um objetivo comum. Esse é o poder da CrewAI – um framework que permite criar sistemas colaborativos de IA que podem realizar tarefas muito além do que uma única IA conseguiria sozinha.

Neste guia, vamos criar uma crew de pesquisa que irá nos ajudar a pesquisar e analisar um tema, e então criar um relatório abrangente. Este exemplo prático demonstra como agentes de IA podem colaborar para realizar tarefas complexas, mas é apenas o começo do que é possível com a CrewAI.

### O que Você Vai Construir e Aprender

Ao final deste guia, você terá:

1. **Criado uma equipe de pesquisa em IA especializada** com papéis e responsabilidades distintas
2. **Orquestrado a colaboração** entre múltiplos agentes de IA
3. **Automatizado um fluxo de trabalho complexo** que envolve coleta de informações, análise e geração de relatórios
4. **Desenvolvido habilidades fundamentais** que podem ser aplicadas em projetos mais ambiciosos

Embora estejamos criando uma crew de pesquisa simples neste guia, os mesmos padrões e técnicas podem ser aplicados para criar equipes muito mais sofisticadas para tarefas como:

* Criação de conteúdo em múltiplas etapas com redatores, editores e checadores de fatos especializados
* Sistemas de atendimento ao cliente complexos com agentes de suporte em diferentes níveis
* Analistas de negócios autônomos que coletam dados, criam visualizações e geram insights
* Equipes de desenvolvimento de produto que idealizam, projetam e planejam a implementação

Vamos começar a construir sua primeira crew!

### Pré-requisitos

Antes de começar, certifique-se de que você:

1. Instalou a CrewAI seguindo o [guia de instalação](/pt-BR/installation)
2. Configurou sua chave de API de LLM no ambiente, conforme o [guia de configuração do LLM](/pt-BR/concepts/llms#setting-up-your-llm)
3. Tem conhecimento básico de Python

## Passo 1: Crie um Novo Projeto CrewAI

Primeiro, vamos criar um novo projeto CrewAI usando a CLI. Este comando irá configurar toda a estrutura do projeto com os arquivos necessários, permitindo que você foque em definir seus agentes e suas tarefas, em vez de se preocupar com código boilerplate.

```bash
crewai create crew research_crew
cd research_crew
```

Isso irá gerar um projeto com a estrutura básica necessária para sua crew. A CLI cria automaticamente:

* Um diretório de projeto com os arquivos necessários
* Arquivos de configuração para agentes e tarefas
* Uma implementação básica da crew
* Um script principal para rodar a crew

<Frame caption="CrewAI Framework Overview">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crews.png" alt="CrewAI Framework Overview" />
</Frame>

## Passo 2: Explore a Estrutura do Projeto

Vamos dedicar um momento para entender a estrutura do projeto criada pela CLI. A CrewAI segue boas práticas para projetos Python, tornando fácil manter e estender seu código à medida que suas crews se tornam mais complexas.

```
research_crew/
├── .gitignore
├── pyproject.toml
├── README.md
├── .env
└── src/
    └── research_crew/
        ├── __init__.py
        ├── main.py
        ├── crew.py
        ├── tools/
        │   ├── custom_tool.py
        │   └── __init__.py
        └── config/
            ├── agents.yaml
            └── tasks.yaml
```

Esta estrutura segue as melhores práticas para projetos Python e facilita a organização do seu código. A separação dos arquivos de configuração (em YAML) do código de implementação (em Python) permite modificar o comportamento da sua crew sem alterar o código subjacente.

## Passo 3: Configure seus Agentes

Agora vem a parte divertida – definir seus agentes de IA! Na CrewAI, agentes são entidades especializadas com papéis, objetivos e históricos específicos que moldam seu comportamento. Pense neles como personagens em uma peça, cada um com sua personalidade e propósito próprios.

Para nossa crew de pesquisa, vamos criar dois agentes:

1. Um **pesquisador** que é especialista em encontrar e organizar informações
2. Um **analista** que pode interpretar os resultados da pesquisa e criar relatórios perspicazes

Vamos modificar o arquivo `agents.yaml` para definir esses agentes especializados. Certifique-se de
definir `llm` para o provedor que você está utilizando.

```yaml
# src/research_crew/config/agents.yaml
researcher:
  role: >
    Especialista Sênior em Pesquisa para {topic}
  goal: >
    Encontrar informações abrangentes e precisas sobre {topic}
    com foco em desenvolvimentos recentes e insights chave
  backstory: >
    Você é um especialista em pesquisa experiente com talento para
    encontrar informações relevantes de diversas fontes. Você se destaca em
    organizar informações de forma clara e estruturada, tornando temas complexos acessíveis para outros.
  llm: provider/model-id  # ex: openai/gpt-4o, google/gemini-2.0-flash, anthropic/claude...

analyst:
  role: >
    Analista de Dados e Redator de Relatórios para {topic}
  goal: >
    Analisar os resultados da pesquisa e criar um relatório abrangente e bem estruturado
    que apresente os insights de forma clara e envolvente
  backstory: >
    Você é um analista habilidoso com experiência em interpretação de dados
    e redação técnica. Tem talento para identificar padrões
    e extrair insights relevantes dos dados de pesquisa, comunicando esses insights de forma eficaz por meio de relatórios bem elaborados.
  llm: provider/model-id  # ex: openai/gpt-4o, google/gemini-2.0-flash, anthropic/claude...
```

Perceba como cada agente tem um papel, objetivo e histórico distintos. Esses elementos não são apenas descritivos – eles efetivamente moldam como o agente aborda suas tarefas. Ao criar cuidadosamente esses detalhes, você pode ter agentes com habilidades e perspectivas que se complementam.

## Passo 4: Defina suas Tarefas

Com nossos agentes definidos, agora precisamos atribuir tarefas específicas para eles realizarem. Tarefas na CrewAI representam o trabalho concreto que os agentes irão executar, com instruções detalhadas e saídas esperadas.

Para nossa crew de pesquisa, vamos definir duas tarefas principais:

1. Uma **tarefa de pesquisa** para coletar informações abrangentes
2. Uma **tarefa de análise** para criar um relatório com insights

Vamos modificar o arquivo `tasks.yaml`:

```yaml
# src/research_crew/config/tasks.yaml
research_task:
  description: >
    Realize uma pesquisa aprofundada sobre {topic}. Foque em:
    1. Conceitos e definições chave
    2. Desenvolvimento histórico e tendências recentes
    3. Principais desafios e oportunidades
    4. Aplicações relevantes ou estudos de caso
    5. Perspectivas futuras e novos desenvolvimentos

    Certifique-se de organizar seus achados em um formato estruturado, com seções claras.
  expected_output: >
    Um documento de pesquisa abrangente com seções bem organizadas cobrindo
    todos os aspectos solicitados de {topic}. Inclua fatos, números
    e exemplos específicos sempre que possível.
  agent: researcher

analysis_task:
  description: >
    Analise os resultados da pesquisa e crie um relatório abrangente sobre {topic}.
    Seu relatório deve:
    1. Iniciar com um resumo executivo
    2. Incluir todas as informações relevantes da pesquisa
    3. Oferecer uma análise perspicaz de tendências e padrões
    4. Apresentar recomendações ou considerações futuras
    5. Estar formatado de forma profissional, clara e com títulos bem definidos
  expected_output: >
    Um relatório profissional, polido e estruturado sobre {topic} com apresentação dos resultados da pesquisa,
    acrescentando análise e insights. O relatório deve ser bem estruturado,
    incluindo resumo executivo, sessões principais e conclusão.
  agent: analyst
  context:
    - research_task
  output_file: output/report.md
```

Note o campo `context` na tarefa de análise – esse é um recurso poderoso que permite ao analista acessar a saída da tarefa de pesquisa. Isso cria um fluxo de trabalho em que a informação circula naturalmente entre os agentes, como aconteceria em uma equipe humana.

## Passo 5: Configure sua Crew

Agora é hora de juntar tudo configurando nossa crew. A crew é o container que orquestra como os agentes trabalham juntos para completar as tarefas.

Vamos modificar o arquivo `crew.py`:

```python
# src/research_crew/crew.py
from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task
from crewai_tools import SerperDevTool
from crewai.agents.agent_builder.base_agent import BaseAgent
from typing import List

@CrewBase
class ResearchCrew():
    """Research crew for comprehensive topic analysis and reporting"""

    agents: List[BaseAgent]
    tasks: List[Task]

    @agent
    def researcher(self) -> Agent:
        return Agent(
            config=self.agents_config['researcher'], # type: ignore[index]
            verbose=True,
            tools=[SerperDevTool()]
        )

    @agent
    def analyst(self) -> Agent:
        return Agent(
            config=self.agents_config['analyst'], # type: ignore[index]
            verbose=True
        )

    @task
    def research_task(self) -> Task:
        return Task(
            config=self.tasks_config['research_task'] # type: ignore[index]
        )

    @task
    def analysis_task(self) -> Task:
        return Task(
            config=self.tasks_config['analysis_task'], # type: ignore[index]
            output_file='output/report.md'
        )

    @crew
    def crew(self) -> Crew:
        """Creates the research crew"""
        return Crew(
            agents=self.agents,
            tasks=self.tasks,
            process=Process.sequential,
            verbose=True,
        )
```

Neste código, estamos:

1. Criando o agente pesquisador e equipando-o com o SerperDevTool para buscas web
2. Criando o agente analista
3. Definindo as tarefas de pesquisa e análise
4. Configurando a crew para executar as tarefas sequencialmente (o analista espera o pesquisador terminar)

É aqui que a mágica acontece – com poucas linhas de código, definimos um sistema colaborativo de IA onde agentes especializados trabalham juntos em um processo coordenado.

## Passo 6: Prepare seu Script Principal

Agora, vamos preparar o script principal que irá rodar nossa crew. É aqui que informamos o tema específico que queremos pesquisar.

```python
#!/usr/bin/env python
# src/research_crew/main.py
import os
from research_crew.crew import ResearchCrew

# Crie o diretório de saída se não existir
os.makedirs('output', exist_ok=True)

def run():
    """
    Rodar a crew de pesquisa.
    """
    inputs = {
        'topic': 'Inteligência Artificial na Saúde'
    }

    # Criar e rodar a crew
    result = ResearchCrew().crew().kickoff(inputs=inputs)

    # Imprimir o resultado
    print("\n\n=== RELATÓRIO FINAL ===\n\n")
    print(result.raw)

    print("\n\nRelatório salvo em output/report.md")

if __name__ == "__main__":
    run()
```

Este script prepara o ambiente, define o tema de pesquisa e inicia o trabalho da crew. O poder da CrewAI fica evidente em como esse código é simples – toda a complexidade do gerenciamento de múltiplos agentes de IA é tratada pelo framework.

## Passo 7: Defina suas Variáveis de Ambiente

Crie um arquivo `.env` na raiz do seu projeto com suas chaves de API:

```sh
SERPER_API_KEY=sua_serper_api_key
# Adicione a chave de API do seu provedor também.
```

Confira o [guia de configuração do LLM](/pt-BR/concepts/llms#setting-up-your-llm) para detalhes sobre como configurar o provedor de sua escolha. Você pode obter a chave da Serper em [Serper.dev](https://serper.dev/).

## Passo 8: Instale as Dependências

Instale as dependências necessárias usando a CLI da CrewAI:

```bash
crewai install
```

Este comando irá:

1. Ler as dependências da configuração do seu projeto
2. Criar um ambiente virtual se necessário
3. Instalar todos os pacotes necessários

## Passo 9: Execute sua Crew

Agora chega o momento empolgante – é hora de rodar sua crew e assistir à colaboração de IA em ação!

```bash
crewai run
```

Ao rodar esse comando, você verá sua crew ganhando vida. O pesquisador irá coletar informações sobre o tema especificado, e o analista irá criar um relatório abrangente baseado nessa pesquisa. Você poderá acompanhar em tempo real o raciocínio, as ações e os resultados dos agentes à medida que colaboram para concluir as tarefas.

## Passo 10: Revise o Resultado

Após a conclusão do trabalho da crew, você encontrará o relatório final em `output/report.md`. O relatório incluirá:

1. Um resumo executivo
2. Informações detalhadas sobre o tema
3. Análises e insights
4. Recomendações ou considerações futuras

Tire um momento para valorizar o que você realizou – você criou um sistema no qual múltiplos agentes de IA colaboraram em uma tarefa complexa, cada um contribuindo com suas habilidades especializadas para gerar um resultado maior do que qualquer agente conseguiria sozinho.

## Explorando Outros Comandos da CLI

A CrewAI oferece vários outros comandos úteis de CLI para trabalhar com crews:

```bash
# Ver todos os comandos disponíveis
crewai --help

# Rodar a crew
crewai run

# Testar a crew
crewai test

# Resetar as memórias da crew
crewai reset-memories

# Repetir a partir de uma tarefa específica
crewai replay -t <task_id>
```

## O que Mais é Possível: Além da sua Primeira Crew

O que você construiu neste guia é só o começo. As habilidades e padrões aprendidos aqui podem ser aplicados para criar sistemas de IA cada vez mais sofisticados. Veja algumas maneiras de expandir sua crew de pesquisa básica:

### Expandindo sua Crew

Você pode adicionar mais agentes especializados à sua crew:

* Um **checador de fatos** para verificar as informações encontradas
* Um **visualizador de dados** para criar gráficos e tabelas
* Um **especialista de domínio** com conhecimento aprofundado em uma área específica
* Um **crítico** para identificar pontos fracos na análise

### Adicionando Ferramentas e Capacidades

Você pode potencializar seus agentes com ferramentas adicionais:

* Ferramentas de navegação web para pesquisa em tempo real
* Ferramentas para CSV ou bancos de dados para análise de dados
* Ferramentas de execução de código para processamento de dados
* Conexões de API com serviços externos

### Criando Fluxos de Trabalho Mais Complexos

Você pode implementar processos mais sofisticados:

* Processos hierárquicos em que agentes gestores delegam para agentes
* Processos iterativos com loops de feedback para refinamento
* Processos paralelos onde múltiplos agentes trabalham simultaneamente
* Processos dinâmicos que se adaptam a resultados intermediários

### Aplicando em Diferentes Domínios

Os mesmos padrões podem ser aplicados para criar crews para:

* **Criação de conteúdo:** Redatores, editores, checadores de fatos e designers trabalhando juntos
* **Atendimento ao cliente:** Agentes de triagem, especialistas e controle de qualidade atuando colaborativamente
* **Desenvolvimento de produto:** Pesquisadores, designers e planejadores trabalhando em conjunto
* **Análise de dados:** Coletores de dados, analistas e especialistas em visualização

## Próximos Passos

Agora que você montou sua primeira crew, você pode:

1. Experimentar diferentes configurações e personalidades de agentes
2. Testar estruturas de tarefas e fluxos de trabalho mais complexos
3. Implementar ferramentas customizadas para dar novas capacidades aos agentes
4. Aplicar sua crew em outros temas ou domínios de problemas
5. Explorar [CrewAI Flows](/pt-BR/guides/flows/first-flow) para fluxos de trabalho avançados usando programação procedural

<Check>
  Parabéns! Você construiu com sucesso sua primeira crew com o CrewAI, capaz de pesquisar e analisar qualquer tema que desejar. Essa experiência fundamental lhe deu as habilidades para criar sistemas de IA cada vez mais sofisticados, aptos a encarar problemas complexos e de múltiplas etapas por meio da inteligência colaborativa.
</Check>


# Construa Seu Primeiro Flow
Source: https://docs.crewai.com/pt-BR/guides/flows/first-flow

Aprenda como criar fluxos de trabalho estruturados e orientados a eventos com controle preciso sobre a execução.

## Assumindo o Controle de Workflows de IA com Flows

Os Flows do CrewAI representam o próximo nível em orquestração de IA – combinando o poder colaborativo de equipes de agentes de IA com a precisão e flexibilidade da programação procedural. Enquanto os crews se destacam em colaboração de agentes, os flows dão a você controle detalhado sobre exatamente como e quando diferentes componentes do seu sistema de IA interagem.

Neste guia, vamos percorrer a criação de um poderoso CrewAI Flow que gera um guia de aprendizado abrangente sobre qualquer tema. Este tutorial demonstrará como os Flows oferecem controle estruturado e orientado a eventos sobre seus workflows de IA ao combinar código regular, chamadas diretas a LLM e processamento baseado em crews.

### O Que Torna os Flows Poderosos

Com flows, você pode:

1. **Combinar diferentes padrões de interação com IA** – Use crews para tarefas colaborativas complexas, chamadas diretas às LLMs para operações mais simples, e código regular para lógica procedural.
2. **Construir sistemas orientados a eventos** – Defina como os componentes respondem a eventos e mudanças de dados específicos.
3. **Manter estado entre componentes** – Compartilhe e transforme dados entre diferentes partes da sua aplicação.
4. **Integrar com sistemas externos** – Conecte seu fluxo de trabalho de IA com bancos de dados, APIs e interfaces de usuário de forma transparente.
5. **Criar caminhos de execução complexos** – Projete ramificações condicionais, processamento paralelo e workflows dinâmicos.

### O Que Você Vai Construir e Aprender

Ao final deste guia, você terá:

1. **Criado um sistema sofisticado de geração de conteúdo** que combina entrada do usuário, planejamento por IA e criação de conteúdo multiagente.
2. **Orquestrado o fluxo de informações** entre diferentes componentes do seu sistema.
3. **Implementado uma arquitetura orientada a eventos** onde cada etapa responde à conclusão das etapas anteriores.
4. **Construído uma base para aplicações de IA mais complexas** que você pode expandir e personalizar.

Este flow de criação de guia demonstra padrões fundamentais que podem ser aplicados para criar aplicações muito mais avançadas, como:

* Assistentes de IA interativos que combinam múltiplos subsistemas especializados.
* Pipelines de processamento de dados complexos com transformações aprimoradas por IA.
* Agentes autônomos integrados a serviços e APIs externas.
* Sistemas de tomada de decisão em múltiplas etapas com processos envolvendo humanos no loop.

Vamos começar e construir seu primeiro flow!

## Pré-requisitos

Antes de começar, certifique-se de ter:

1. Instalado o CrewAI seguindo o [guia de instalação](/pt-BR/installation)
2. Configurado sua chave de API LLM no ambiente, conforme o [guia de configuração do LLM](/pt-BR/concepts/llms#setting-up-your-llm)
3. Conhecimentos básicos de Python

## Passo 1: Crie um Novo Projeto de CrewAI Flow

Primeiro, vamos criar um novo projeto de Flow do CrewAI usando a CLI. Este comando configura um projeto com todos os diretórios necessários e arquivos de template para seu flow.

```bash
crewai create flow guide_creator_flow
cd guide_creator_flow
```

Isso gerará um projeto com a estrutura básica necessária para seu flow.

<Frame caption="Visão Geral do Framework CrewAI">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/flows.png" alt="CrewAI Framework Overview" />
</Frame>

## Passo 2: Entendendo a Estrutura do Projeto

O projeto gerado possui a seguinte estrutura. Reserve um momento para conhecê-la, pois isso ajudará você a criar flows mais complexos no futuro.

```
guide_creator_flow/
├── .gitignore
├── pyproject.toml
├── README.md
├── .env
├── main.py
├── crews/
│   └── poem_crew/
│       ├── config/
│       │   ├── agents.yaml
│       │   └── tasks.yaml
│       └── poem_crew.py
└── tools/
    └── custom_tool.py
```

Esta estrutura oferece uma separação clara entre os diferentes componentes do seu flow:

* A lógica principal do flow no arquivo `main.py`
* Crews especializados no diretório `crews`
* Ferramentas customizadas no diretório `tools`

Vamos modificar esta estrutura para criar nosso flow de criação de guias, que irá orquestrar o processo de geração de guias de aprendizagem abrangentes.

## Passo 3: Adicione um Crew de Redator de Conteúdo

Nosso flow precisará de um crew especializado para lidar com o processo de criação de conteúdo. Vamos usar a CLI do CrewAI para adicionar um crew de redatores de conteúdo:

```bash
crewai flow add-crew content-crew
```

Este comando cria automaticamente os diretórios e arquivos de template necessários para seu crew. O crew de redatores será responsável por escrever e revisar seções do nosso guia, trabalhando dentro do flow orquestrado pela aplicação principal.

## Passo 4: Configure o Crew de Redator de Conteúdo

Agora, vamos modificar os arquivos gerados para o crew de redatores. Vamos configurar dois agentes especializados – um escritor e um revisor – que irão colaborar para criar um conteúdo de alta qualidade para o nosso guia.

1. Primeiro, atualize o arquivo de configuração de agents para definir a equipe de criação de conteúdo:

   Lembre-se de configurar o `llm` com o provedor que está utilizando.

```yaml
# src/guide_creator_flow/crews/content_crew/config/agents.yaml
content_writer:
  role: >
    Redator de Conteúdo Educacional
  goal: >
    Criar conteúdo envolvente e informativo que explique completamente o tema proposto
    e forneça insights valiosos ao leitor
  backstory: >
    Você é um talentoso escritor educacional com experiência em criar conteúdo claro
    e atraente. Você tem facilidade para explicar conceitos complexos em linguagem acessível
    e organizar as informações de forma a ajudar o leitor a construir seu entendimento.
  llm: provider/model-id  # e.g. openai/gpt-4o, google/gemini-2.0-flash, anthropic/claude...

content_reviewer:
  role: >
    Revisor(a) e Editor(a) de Conteúdo Educacional
  goal: >
    Garantir que o conteúdo seja preciso, abrangente, bem estruturado e mantenha
    consistência com as seções previamente escritas
  backstory: >
    Você é um editor(a) meticuloso(a) com anos de experiência revisando conteúdo educacional.
    Tem atenção aos detalhes, clareza e coesão. Você se destaca em aprimorar conteúdo
    mantendo o estilo do autor original e garantindo qualidade consistente em várias seções.
  llm: provider/model-id  # e.g. openai/gpt-4o, google/gemini-2.0-flash, anthropic/claude...
```

Essas definições de agents estabelecem papéis e perspectivas especializadas que irão moldar como nossos agentes de IA abordam a criação de conteúdo. Note como cada agent possui um propósito e expertise distintos.

2. Em seguida, atualize o arquivo de configuração de tarefas para definir as tarefas específicas de escrita e revisão:

```yaml
# src/guide_creator_flow/crews/content_crew/config/tasks.yaml
write_section_task:
  description: >
    Escreva uma seção abrangente sobre o tema: "{section_title}"

    Descrição da seção: {section_description}
    Público-alvo: {audience_level} aprendizes

    Seu conteúdo deve:
    1. Começar com uma breve introdução ao tema da seção
    2. Explicar claramente todos os conceitos principais com exemplos
    3. Incluir aplicações práticas ou exercícios onde apropriado
    4. Terminar com um resumo dos pontos principais
    5. Ter aproximadamente 500-800 palavras

    Formate seu conteúdo em Markdown com títulos, listas e ênfase apropriados.

    Seções previamente escritas:
    {previous_sections}

    Certifique-se de que seu conteúdo mantenha consistência com as seções já escritas
    e amplie os conceitos que já foram explicados.
  expected_output: >
    Uma seção bem estruturada e abrangente em formato Markdown que explique
    totalmente o tema e é apropriada para o público-alvo.
  agent: content_writer

review_section_task:
  description: >
    Revise e melhore a seguinte seção sobre "{section_title}":

    {draft_content}

    Público-alvo: {audience_level} aprendizes

    Seções previamente escritas:
    {previous_sections}

    Sua revisão deve:
    1. Corrigir qualquer erro gramatical ou de ortografia
    2. Melhorar clareza e legibilidade
    3. Garantir que o conteúdo seja abrangente e preciso
    4. Verificar a consistência com as seções já escritas
    5. Aprimorar a estrutura e o fluxo
    6. Adicionar qualquer informação-chave ausente

    Forneça a versão aprimorada da seção em formato Markdown.
  expected_output: >
    Uma versão melhorada e refinada da seção, mantendo a estrutura original,
    mas aprimorando clareza, precisão e consistência.
  agent: content_reviewer
  context:
    - write_section_task
```

Essas definições de tarefas fornecem instruções detalhadas para nossos agents, garantindo que eles produzam conteúdo que atenda aos padrões de qualidade. Observe como o parâmetro `context` na tarefa de revisão cria um fluxo onde o revisor tem acesso à produção do redator.

3. Agora, atualize o arquivo de implementação do crew para definir como nossos agents e tasks trabalham juntos:

```python
# src/guide_creator_flow/crews/content_crew/content_crew.py
from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task
from crewai.agents.agent_builder.base_agent import BaseAgent
from typing import List

@CrewBase
class ContentCrew():
    """Crew de redação de conteúdo"""

    agents: List[BaseAgent]
    tasks: List[Task]

    @agent
    def content_writer(self) -> Agent:
        return Agent(
            config=self.agents_config['content_writer'], # type: ignore[index]
            verbose=True
        )

    @agent
    def content_reviewer(self) -> Agent:
        return Agent(
            config=self.agents_config['content_reviewer'], # type: ignore[index]
            verbose=True
        )

    @task
    def write_section_task(self) -> Task:
        return Task(
            config=self.tasks_config['write_section_task'] # type: ignore[index]
        )

    @task
    def review_section_task(self) -> Task:
        return Task(
            config=self.tasks_config['review_section_task'], # type: ignore[index]
            context=[self.write_section_task()]
        )

    @crew
    def crew(self) -> Crew:
        """Cria o crew de redação de conteúdo"""
        return Crew(
            agents=self.agents,
            tasks=self.tasks,
            process=Process.sequential,
            verbose=True,
        )
```

Essa definição de crew estabelece o relacionamento entre nossos agents e tasks, definindo um processo sequencial onde o redator cria o rascunho e o revisor o aprimora. Embora este crew possa funcionar de forma independente, em nosso flow ele será orquestrado como parte de um sistema maior.

## Passo 5: Crie o Flow

Agora vem a parte emocionante – criar o flow que irá orquestrar todo o processo de criação do guia. Aqui iremos combinar código Python regular, chamadas diretas a LLM e nosso crew de criação de conteúdo em um sistema coeso.

Nosso flow irá:

1. Obter a entrada do usuário sobre o tema e nível do público
2. Fazer uma chamada direta à LLM para criar um roteiro estruturado do guia
3. Processar cada seção sequencialmente usando o crew de redatores
4. Combinar tudo em um documento final abrangente

Vamos criar nosso flow no arquivo `main.py`:

```python
# [CÓDIGO NÃO TRADUZIDO, MANTER COMO ESTÁ]
```

Vamos analisar o que está acontecendo neste flow:

1. Definimos modelos Pydantic para dados estruturados, garantindo segurança de tipos e representação clara dos dados.
2. Criamos uma classe de estado para manter dados entre os diferentes passos do flow.
3. Implementamos três etapas principais para o flow:
   * Obtenção da entrada do usuário com o decorator `@start()`
   * Criação do roteiro do guia com uma chamada direta à LLM
   * Processamento das seções com nosso crew de conteúdo
4. Usamos o decorator `@listen()` para estabelecer relações orientadas a eventos entre as etapas

Este é o poder dos flows – combinar diferentes tipos de processamento (interação com usuário, chamadas diretas a IA, tarefas colaborativas com crews) em um sistema orientado a eventos e coeso.

## Passo 6: Configure suas Variáveis de Ambiente

Crie um arquivo `.env` na raiz do projeto com suas chaves de API. Veja o [guia de configuração do LLM](/pt-BR/concepts/llms#setting-up-your-llm) para detalhes sobre como configurar o provedor.

```sh .env
OPENAI_API_KEY=sua_chave_openai
# ou
GEMINI_API_KEY=sua_chave_gemini
# ou
ANTHROPIC_API_KEY=sua_chave_anthropic
```

## Passo 7: Instale as Dependências

Instale as dependências necessárias:

```bash
crewai install
```

## Passo 8: Execute Seu Flow

Agora é hora de ver seu flow em ação! Execute-o usando a CLI do CrewAI:

```bash
crewai flow kickoff
```

Quando você rodar esse comando, verá seu flow ganhando vida:

1. Ele solicitará um tema e o nível do público para você
2. Criará um roteiro estruturado para o seu guia
3. Processará cada seção, com o redator e o revisor colaborando em cada uma
4. Por fim, irá compilar tudo em um guia abrangente

Isso demonstra o poder dos flows para orquestrar processos complexos envolvendo múltiplos componentes, tanto de IA quanto não-IA.

## Passo 9: Visualize Seu Flow

Uma das funcionalidades mais poderosas dos flows é a possibilidade de visualizar sua estrutura:

```bash
crewai flow plot
```

Isso irá criar um arquivo HTML que mostra a estrutura do seu flow, incluindo os relacionamentos entre etapas e o fluxo de dados. Essa visualização pode ser inestimável para entender e depurar flows complexos.

## Passo 10: Revise o Resultado

Depois que o flow finalizar, você encontrará dois arquivos no diretório `output`:

1. `guide_outline.json`: Contém o roteiro estruturado do guia
2. `complete_guide.md`: O guia abrangente com todas as seções

Reserve um momento para revisar esses arquivos e apreciar o que você construiu – um sistema que combina entrada do usuário, interações diretas com IA e trabalho colaborativo de agents para produzir um output complexo e de alta qualidade.

## A Arte do Possível: Além do Seu Primeiro Flow

O que você aprendeu neste guia é uma base para criar sistemas de IA muito mais sofisticados. Veja algumas formas de expandir este flow básico:

### Aprimorando a Interação com o Usuário

Você pode criar flows mais interativos com:

* Interfaces web para entrada e saída de dados
* Atualizações em tempo real de progresso
* Loops de feedback e refinamento interativos
* Interações multi-stage com o usuário

### Adicionando Mais Etapas de Processamento

Você pode expandir seu flow com etapas adicionais para:

* Pesquisa antes da criação do roteiro
* Geração de imagens para ilustrações
* Geração de snippets de código para guias técnicos
* Garantia de qualidade e checagem final de fatos

### Criando Flows Mais Complexos

Você pode implementar padrões de flow mais sofisticados:

* Ramificações condicionais com base na preferência do usuário ou tipo de conteúdo
* Processamento paralelo de seções independentes
* Loops de refinamento iterativo com feedback
* Integração a APIs e serviços externos

### Aplicando a Diferentes Domínios

Os mesmos padrões podem ser usados para criar flows de:

* **Narrativas interativas**: criação de histórias personalizadas com base na entrada do usuário
* **Inteligência de negócios**: processamento de dados, geração de insights e criação de relatórios
* **Desenvolvimento de produtos**: facilitação de ideação, design e planejamento
* **Sistemas educacionais**: criação de experiências de aprendizagem personalizadas

## Principais Funcionalidades Demonstradas

Este flow de criação de guia demonstra diversos recursos poderosos do CrewAI:

1. **Interação com o usuário**: O flow coleta input diretamente do usuário
2. **Chamadas diretas à LLM**: Usa a classe LLM para interações eficientes e direcionadas com IA
3. **Dados estruturados com Pydantic**: Usa Pydantic para garantir segurança de tipos
4. **Processamento sequencial com contexto**: Escreve seções em ordem, fornecendo as anteriores como contexto
5. **Crews multiagentes**: Utiliza agents especializados (redator e revisor) para criação de conteúdo
6. **Gerenciamento de estado**: Mantém estado entre diferentes etapas do processo
7. **Arquitetura orientada a eventos**: Usa o decorator `@listen` para responder a eventos

## Entendendo a Estrutura do Flow

Vamos decompor os principais componentes dos flows para ajudá-lo a entender como construir o seu:

### 1. Chamadas Diretas à LLM

Flows permitem que você faça chamadas diretas a modelos de linguagem quando precisa de respostas simples e estruturadas:

```python
llm = LLM(
    model="model-id-here",  # gpt-4o, gemini-2.0-flash, anthropic/claude...
    response_format=GuideOutline
)
response = llm.call(messages=messages)
```

Isso é mais eficiente do que usar um crew quando você precisa de um output específico e estruturado.

### 2. Arquitetura Orientada a Eventos

Flows usam decorators para estabelecer relações entre componentes:

```python
@start()
def get_user_input(self):
    # Primeira etapa no flow
    # ...

@listen(get_user_input)
def create_guide_outline(self, state):
    # Esta roda quando get_user_input é concluída
    # ...
```

Isso cria uma estrutura clara e declarativa para sua aplicação.

### 3. Gerenciamento de Estado

Flows mantêm o estado entre as etapas, facilitando o compartilhamento de dados:

```python
class GuideCreatorState(BaseModel):
    topic: str = ""
    audience_level: str = ""
    guide_outline: GuideOutline = None
    sections_content: Dict[str, str] = {}
```

Isso fornece uma maneira segura e tipada de rastrear e transformar dados ao longo do flow.

### 4. Integração com Crews

Flows podem integrar crews para tarefas colaborativas complexas:

```python
result = ContentCrew().crew().kickoff(inputs={
    "section_title": section.title,
    # ...
})
```

Assim, você usa a ferramenta certa para cada parte da aplicação – chamadas diretas para tarefas simples e crews para colaboração avançada.

## Próximos Passos

Agora que você construiu seu primeiro flow, pode:

1. Experimentar estruturas e padrões mais complexos de flow
2. Testar o uso do `@router()` para criar ramificações condicionais em seus flows
3. Explorar as funções `and_` e `or_` para execuções paralelas e mais complexas
4. Conectar seu flow a APIs externas, bancos de dados ou interfaces de usuário
5. Combinar múltiplos crews especializados em um único flow

<Check>
  Parabéns! Você construiu seu primeiro CrewAI Flow que combina código regular, chamadas diretas a LLM e processamento baseado em crews para criar um guia abrangente. Essas habilidades fundamentais permitem criar aplicações de IA cada vez mais sofisticadas, capazes de resolver problemas complexos de múltiplas etapas por meio de controle procedural e inteligência colaborativa.
</Check>


# Dominando o Gerenciamento de Estado em Flows
Source: https://docs.crewai.com/pt-BR/guides/flows/mastering-flow-state

Um guia abrangente sobre como gerenciar, persistir e utilizar o estado em CrewAI Flows para construir aplicações de IA robustas.

## Entendendo o Poder do Estado em Flows

O gerenciamento de estado é a espinha dorsal de qualquer workflow de IA sofisticado. Nos Flows da CrewAI, o sistema de estado permite manter o contexto, compartilhar dados entre etapas e construir lógicas de aplicação complexas. Dominar o gerenciamento de estado é essencial para criar aplicações de IA confiáveis, sustentáveis e poderosas.

Este guia vai te levar por tudo o que você precisa saber sobre como gerenciar o estado em CrewAI Flows, desde conceitos básicos até técnicas avançadas, com exemplos práticos de código ao longo do conteúdo.

### Por Que o Gerenciamento de Estado Importa

Um gerenciamento de estado efetivo possibilita que você:

1. **Mantenha o contexto entre as etapas de execução** – Transfira informações de forma transparente entre diferentes estágios do seu workflow
2. **Construa lógicas condicionais complexas** – Tome decisões baseadas nos dados acumulados
3. **Crie aplicações persistentes** – Salve e recupere o progresso do workflow
4. **Trate erros de forma elegante** – Implemente padrões de recuperação para aplicações mais robustas
5. **Escalone suas aplicações** – Ofereça suporte a workflows complexos com organização apropriada dos dados
6. **Habilite aplicações conversacionais** – Armazene e acesse o histórico da conversa para interações de IA com contexto

Vamos explorar como aproveitar essas capacidades de forma eficiente.

## Fundamentos do Gerenciamento de Estado

### O Ciclo de Vida do Estado em um Flow

Nos Flows da CrewAI, o estado segue um ciclo de vida previsível:

1. **Inicialização** – Quando um flow é criado, seu estado é inicializado (como um dicionário vazio ou uma instância de modelo Pydantic)
2. **Modificação** – Os métodos do flow acessam e modificam o estado durante a execução
3. **Transmissão** – O estado é automaticamente passado entre os métodos do flow
4. **Persistência** (opcional) – O estado pode ser salvo em um armazenamento e recuperado posteriormente
5. **Conclusão** – O estado final reflete as mudanças acumuladas de todos os métodos executados

Compreender esse ciclo de vida é crucial para projetar flows eficientes.

### Duas Abordagens Para Gerenciar Estado

A CrewAI oferece duas maneiras para você gerenciar o estado nos seus flows:

1. **Estado Não Estruturado** – Usando objetos do tipo dicionário para mais flexibilidade
2. **Estado Estruturado** – Usando modelos Pydantic para segurança de tipo e validação

Vamos analisar cada abordagem em detalhe.

## Gerenciamento de Estado Não Estruturado

O estado não estruturado utiliza uma abordagem semelhante a dicionários, oferecendo flexibilidade e simplicidade para aplicações diretas.

### Como Funciona

Com estado não estruturado:

* Você acessa o estado via `self.state`, que se comporta como um dicionário
* Pode adicionar, modificar ou remover chaves livremente a qualquer momento
* Todo o estado está disponível automaticamente para todos os métodos do flow

### Exemplo Básico

Veja um exemplo simples de gerenciamento de estado não estruturado:

```python
# código não traduzido
```

### Quando Usar Estado Não Estruturado

O estado não estruturado é ideal para:

* Prototipagem rápida e flows simples
* Necessidade de estado que evolui dinamicamente
* Casos onde a estrutura pode não ser conhecida antecipadamente
* Flows com requisitos de estado simples

Embora seja flexível, o estado não estruturado não possui checagem de tipos nem validação de esquema, o que pode gerar erros em aplicações mais complexas.

## Gerenciamento de Estado Estruturado

O estado estruturado utiliza modelos Pydantic para definir um esquema para o estado do seu flow, provendo segurança de tipo, validação e melhor experiência de desenvolvimento.

### Como Funciona

Ao utilizar estado estruturado:

* Você define um modelo Pydantic que representa a estrutura do seu estado
* Passa este tipo de modelo para sua classe Flow como parâmetro de tipo
* Acessa o estado via `self.state`, que se comporta como uma instância do modelo Pydantic
* Todos os campos são validados de acordo com os tipos definidos
* O IDE oferece autocompletar e suporte à checagem de tipos

### Exemplo Básico

Veja como implementar o gerenciamento de estado estruturado:

```python
# código não traduzido
```

### Benefícios do Estado Estruturado

Utilizar estado estruturado traz várias vantagens:

1. **Segurança de Tipo** – Detecte erros de tipo durante o desenvolvimento
2. **Autodocumentação** – O modelo de estado documenta claramente quais dados estão disponíveis
3. **Validação** – Validação automática de tipos de dados e restrições
4. **Suporte do IDE** – Obtenha autocompletar e documentação inline
5. **Valores Padrão** – Defina facilmente valores padrões para falta de dados

### Quando Usar Estado Estruturado

O estado estruturado é recomendado para:

* Flows complexos com esquemas de dados bem definidos
* Projetos em equipe com múltiplos desenvolvedores no mesmo código
* Aplicações onde a validação de dados é importante
* Flows que precisam impor tipos de dados e restrições específicas

## O ID de Estado Automático

Tanto estados não estruturados quanto estruturados recebem automaticamente um identificador único (UUID) para ajudar a rastrear e gerenciar instâncias de estado.

### Como Funciona

* Para estado não estruturado, o ID é acessível via `self.state["id"]`
* Para estado estruturado, o ID é acessível via `self.state.id`
* Este ID é gerado automaticamente ao criar o flow
* O ID permanece igual durante todo o ciclo de vida do flow
* O ID pode ser usado para rastreamento, logs e recuperação de estados persistidos

Este UUID é útil especialmente ao implementar persistência ou monitorar múltiplas execuções de flows.

## Atualizações Dinâmicas de Estado

Independente de você usar estado estruturado ou não estruturado, é possível atualizar o estado dinamicamente ao longo da execução do flow.

### Passando Dados Entre Etapas

Métodos do flow podem retornar valores que serão passados como argumento para métodos listeners:

```python
# código não traduzido
```

Esse padrão permite combinar passagem de dados direta com atualizações de estado para obter máxima flexibilidade.

## Persistindo o Estado do Flow

Uma das funcionalidades mais poderosas da CrewAI é a habilidade de persistir o estado do flow entre execuções. Isso habilita workflows que podem ser pausados, retomados e até recuperados após falhas.

### O Decorador @persist()

O decorador `@persist()` automatiza a persistência de estado, salvando o estado do flow em pontos chave da execução.

#### Persistência em Nível de Classe

Ao aplicar em nível de classe, `@persist()` salva o estado após cada execução de método:

```python
# código não traduzido
```

#### Persistência em Nível de Método

Para mais controle, você pode aplicar `@persist()` em métodos específicos:

```python
# código não traduzido
```

## Padrões Avançados de Estado

### Lógica Condicional Baseada no Estado

Você pode usar o estado para implementar lógicas condicionais complexas em seus flows:

```python
# código não traduzido
```

### Manipulações Complexas de Estado

Para transformar estados complexos, você pode criar métodos dedicados:

```python
# código não traduzido
```

Esse padrão de criar métodos auxiliares mantém seus métodos de flow limpos, enquanto permite manipulações complexas de estado.

## Gerenciamento de Estado com Crews

Um dos padrões mais poderosos na CrewAI é combinar o gerenciamento de estado do flow com a execução de crews.

### Passando Estado para Crews

Você pode usar o estado do flow para parametrizar crews:

```python
# código não traduzido
```

### Manipulando Saídas de Crews no Estado

Quando um crew finaliza, é possível processar sua saída e armazená-la no estado do flow:

```python
# código não traduzido
```

## Boas Práticas para Gerenciamento de Estado

### 1. Mantenha o Estado Focado

Projete seu estado para conter somente o necessário:

```python
# Exemplo não traduzido
```

### 2. Use Estado Estruturado em Flows Complexos

À medida que seus flows evoluem em complexidade, o estado estruturado se torna cada vez mais valioso:

```python
# Exemplo não traduzido
```

### 3. Documente Transições de Estado

Para flows complexos, documente como o estado muda ao longo da execução:

```python
# Exemplo não traduzido
```

### 4. Trate Erros de Estado de Forma Elegante

Implemente tratamento de erros ao acessar o estado:

```python
# Exemplo não traduzido
```

### 5. Use o Estado Para Acompanhar o Progresso

Aproveite o estado para monitorar o progresso em flows de longa duração:

```python
# Exemplo não traduzido
```

### 6. Prefira Operações Imutáveis Quando Possível

Especialmente com estado estruturado, prefira operações imutáveis para maior clareza:

```python
# Exemplo não traduzido
```

## Depurando o Estado do Flow

### Logando Alterações no Estado

Ao desenvolver, adicione logs para acompanhar mudanças no estado:

```python
# Exemplo não traduzido
```

### Visualizando o Estado

Você pode adicionar métodos para visualizar seu estado durante o debug:

```python
# Exemplo não traduzido
```

## Conclusão

Dominar o gerenciamento de estado em CrewAI Flows te dá poder para construir aplicações de IA sofisticadas e robustas, que mantêm contexto, tomam decisões complexas e entregam resultados consistentes.

Seja escolhendo estado não estruturado ou estruturado, implementar boas práticas de gerenciamento de estado irá ajudar a criar flows manteníveis, extensíveis e eficazes na resolução de problemas do mundo real.

À medida que desenvolver flows mais complexos, lembre-se de que um bom gerenciamento de estado está relacionado ao equilíbrio entre flexibilidade e estrutura, tornando seu código tanto poderoso quanto fácil de entender.

<Check>
  Agora você domina os conceitos e práticas de gerenciamento de estado em CrewAI Flows! Com este conhecimento, você pode criar workflows de IA robustos que mantêm contexto, compartilham dados entre as etapas e constroem lógicas avançadas de aplicação.
</Check>

## Próximos Passos

* Experimente usar estado estruturado e não estruturado em seus flows
* Teste a implementação de persistência de estado para workflows de longa duração
* Explore [como construir seu primeiro crew](/pt-BR/guides/crews/first-crew) para ver como crews e flows podem funcionar juntos
* Confira a [documentação de referência de Flow](/pt-BR/concepts/flows) para funcionalidades mais avançadas


# Instalação
Source: https://docs.crewai.com/pt-BR/installation

Comece a usar o CrewAI - Instale, configure e crie seu primeiro crew de IA

## Tutorial em Vídeo

Assista a este tutorial em vídeo para uma demonstração passo a passo do processo de instalação:

<iframe width="100%" height="400" src="https://www.youtube.com/embed/-kSOTtYzgEw" title="CrewAI Installation Guide" frameborder="0" style={{ borderRadius: '10px' }} allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

## Tutorial em Texto

<Note>
  **Requisitos de Versão do Python**

  CrewAI requer `Python >=3.10 e <3.14`. Veja como verificar sua versão:

  ```bash
  python3 --version
  ```

  Se você precisar atualizar o Python, acesse [python.org/downloads](https://python.org/downloads)
</Note>

CrewAI utiliza o `uv` como ferramenta de gerenciamento de dependências e pacotes. Ele simplifica a configuração e execução do projeto, oferecendo uma experiência fluida.

Se você ainda não instalou o `uv`, siga o **passo 1** para instalá-lo rapidamente em seu sistema, caso contrário, avance para o **passo 2**.

<Steps>
  <Step title="Instale o uv">
    * **No macOS/Linux:**

      Use `curl` para baixar o script e executá-lo com `sh`:

      ```shell
      curl -LsSf https://astral.sh/uv/install.sh | sh
      ```

      Se seu sistema não possuir `curl`, você pode usar `wget`:

      ```shell
      wget -qO- https://astral.sh/uv/install.sh | sh
      ```

    * **No Windows:**

      Use `irm` para baixar o script e `iex` para executá-lo:

      ```shell
      powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
      ```

      Caso enfrente algum problema, consulte o [guia de instalação do UV](https://docs.astral.sh/uv/getting-started/installation/) para mais informações.
  </Step>

  <Step title="Instale o CrewAI 🚀">
    * Execute o seguinte comando para instalar o CLI do `crewai`:

      ```shell
      uv tool install crewai
      ```

      <Warning>
        Se aparecer um aviso relacionado ao `PATH`, execute este comando para atualizar seu shell:

        ```shell
        uv tool update-shell
        ```
      </Warning>

      <Warning>
        Se você encontrar o erro de build ao instalar `chroma-hnswlib==0.7.6` (`fatal error C1083: Cannot open include file: 'float.h'`) no Windows, instale o (Visual Studio Build Tools)\[[https://visualstudio.microsoft.com/downloads/](https://visualstudio.microsoft.com/downloads/)] com o *Desenvolvimento de Desktop com C++*.
      </Warning>

    * Para verificar se o `crewai` está instalado, execute:
      ```shell
      uv tool list
      ```

    * Você deverá ver algo assim:
      ```shell
      crewai v0.102.0
      - crewai
      ```

    * Caso precise atualizar o `crewai`, execute:
      ```shell
      uv tool install crewai --upgrade
      ```

    <Check>Instalação realizada com sucesso! Você está pronto para criar seu primeiro crew! 🎉</Check>
  </Step>
</Steps>

# Criando um Projeto CrewAI

Recomendamos utilizar o template de scaffolding `YAML` para uma abordagem estruturada na definição dos agentes e tarefas. Veja como começar:

<Steps>
  <Step title="Gerar Scaffolding do Projeto">
    * Execute o comando CLI do `crewai`:
      ```shell
      crewai create crew <your_project_name>
      ```

    * Isso criará um novo projeto com a seguinte estrutura:
      <Frame>
        ```
        my_project/
        ├── .gitignore
        ├── knowledge/
        ├── pyproject.toml
        ├── README.md
        ├── .env
        └── src/
            └── my_project/
                ├── __init__.py
                ├── main.py
                ├── crew.py
                ├── tools/
                │   ├── custom_tool.py
                │   └── __init__.py
                └── config/
                    ├── agents.yaml
                    └── tasks.yaml
        ```
      </Frame>
  </Step>

  <Step title="Personalize Seu Projeto">
    * Seu projeto conterá estes arquivos essenciais:
      | Arquivo       | Finalidade                                            |
      | ------------- | ----------------------------------------------------- |
      | `agents.yaml` | Defina seus agentes de IA e seus papéis               |
      | `tasks.yaml`  | Configure as tarefas e fluxos de trabalho dos agentes |
      | `.env`        | Armazene chaves de API e variáveis de ambiente        |
      | `main.py`     | Ponto de entrada e fluxo de execução do projeto       |
      | `crew.py`     | Orquestração e coordenação do crew                    |
      | `tools/`      | Diretório para ferramentas customizadas dos agentes   |
      | `knowledge/`  | Diretório para base de conhecimento                   |

    * Comece editando `agents.yaml` e `tasks.yaml` para definir o comportamento do seu crew.

    * Mantenha informações sensíveis como chaves de API no arquivo `.env`.
  </Step>

  <Step title="Execute seu Crew">
    * Antes de rodar seu crew, execute:
      ```bash
      crewai install
      ```
    * Se precisar instalar pacotes adicionais, utilize:
      ```shell
      uv add <package-name>
      ```
    * Para rodar seu crew, execute o seguinte comando na raiz do seu projeto:
      ```bash
      crewai run
      ```
  </Step>
</Steps>

## Opções de Instalação Enterprise

<Note type="info">
  Para equipes e organizações, o CrewAI oferece opções de implantação corporativa que eliminam a complexidade da configuração:

  ### CrewAI Enterprise (SaaS)

  * Zero instalação necessária - basta se cadastrar gratuitamente em [app.crewai.com](https://app.crewai.com)
  * Atualizações e manutenção automáticas
  * Infraestrutura e escalabilidade gerenciadas
  * Construa crews sem código

  ### CrewAI Factory (Auto-Hospedado)

  * Implantação containerizada para sua infraestrutura
  * Compatível com qualquer hyperscaler, incluindo ambientes on-premises
  * Integração com seus sistemas de segurança existentes

  <Card title="Explore as Opções Enterprise" icon="building" href="https://crewai.com/enterprise">
    Saiba mais sobre as soluções enterprise do CrewAI e agende uma demonstração
  </Card>
</Note>

## Próximos Passos

<CardGroup cols={2}>
  <Card title="Construa Seu Primeiro Agente" icon="code" href="/pt-BR/quickstart">
    Siga nosso guia de início rápido para criar seu primeiro agente CrewAI e obter experiência prática.
  </Card>

  <Card title="Junte-se à Comunidade" icon="comments" href="https://community.crewai.com">
    Conecte-se com outros desenvolvedores, obtenha ajuda e compartilhe suas experiências com o CrewAI.
  </Card>
</CardGroup>


# Introdução
Source: https://docs.crewai.com/pt-BR/introduction

Construa equipes de agentes de IA que trabalham juntas para resolver tarefas complexas

# O que é CrewAI?

**CrewAI é um framework Python enxuto e ultrarrápido, construído totalmente do zero—completamente independente do LangChain ou de outros frameworks de agentes.**

O CrewAI capacita desenvolvedores tanto com simplicidade de alto nível quanto com controle detalhado de baixo nível, ideal para criar agentes de IA autônomos sob medida para qualquer cenário:

* **[Crews do CrewAI](/pt-BR/guides/crews/first-crew)**: Otimizados para autonomia e inteligência colaborativa, permitindo criar equipes de IA onde cada agente possui funções, ferramentas e objetivos específicos.
* **[Flows do CrewAI](/pt-BR/guides/flows/first-flow)**: Proporcionam controle granular, orientado por eventos, com chamadas LLM individuais para uma orquestração precisa das tarefas, além de suportar Crews nativamente.

Com mais de 100.000 desenvolvedores certificados em nossos cursos comunitários, o CrewAI está se tornando rapidamente o padrão para automação de IA pronta para empresas.

## Como funcionam os Crews

<Note>
  Assim como uma empresa possui departamentos (Vendas, Engenharia, Marketing) trabalhando juntos sob uma liderança para atingir objetivos de negócio, o CrewAI ajuda você a criar uma “organização” de agentes de IA com funções especializadas colaborando para realizar tarefas complexas.
</Note>

<Frame caption="Visão Geral do Framework CrewAI">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crews.png" alt="Visão Geral do Framework CrewAI" />
</Frame>

| Componente        |                Descrição               | Principais Funcionalidades                                                                                                                                |
| :---------------- | :------------------------------------: | :-------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Crew**          |     Organização de mais alto nível     | • Gerencia equipes de agentes de IA<br />• Supervisiona fluxos de trabalho<br />• Garante colaboração<br />• Entrega resultados                           |
| **Agentes de IA** |    Membros especializados da equipe    | • Possuem funções específicas (pesquisador, escritor)<br />• Utilizam ferramentas designadas<br />• Podem delegar tarefas<br />• Tomam decisões autônomas |
| **Process**       | Sistema de gestão do fluxo de trabalho | • Define padrões de colaboração<br />• Controla designação de tarefas<br />• Gerencia interações<br />• Garante execução eficiente                        |
| **Tasks**         |         Atribuições individuais        | • Objetivos claros<br />• Utilizam ferramentas específicas<br />• Alimentam processos maiores<br />• Geram resultados acionáveis                          |

### Como tudo trabalha junto

1. O **Crew** organiza toda a operação
2. **Agentes de IA** realizam tarefas especializadas
3. O **Process** garante colaboração fluida
4. **Tasks** são concluídas para alcançar o objetivo

## Principais Funcionalidades

<CardGroup cols={2}>
  <Card title="Agentes Baseados em Funções" icon="users">
    Crie agentes especializados com funções, conhecimentos e objetivos definidos – de pesquisadores e analistas a escritores
  </Card>

  <Card title="Ferramentas Flexíveis" icon="screwdriver-wrench">
    Equipe os agentes com ferramentas e APIs personalizadas para interagir com serviços e fontes de dados externas
  </Card>

  <Card title="Colaboração Inteligente" icon="people-arrows">
    Agentes trabalham juntos, compartilhando insights e coordenando tarefas para conquistar objetivos complexos
  </Card>

  <Card title="Gerenciamento de Tarefas" icon="list-check">
    Defina fluxos de trabalho sequenciais ou paralelos, com agentes lidando automaticamente com dependências entre tarefas
  </Card>
</CardGroup>

## Como funcionam os Flows

<Note>
  Enquanto Crews se destacam na colaboração autônoma, Flows proporcionam automações estruturadas, oferecendo controle granular sobre a execução dos fluxos de trabalho. Flows garantem execução confiável, segura e eficiente, lidando com lógica condicional, loops e gerenciamento dinâmico de estados com precisão. Flows se integram perfeitamente com Crews, permitindo equilibrar alta autonomia com controle rigoroso.
</Note>

<Frame caption="Visão Geral do Framework CrewAI">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/flows.png" alt="Visão Geral do Framework CrewAI" />
</Frame>

| Componente       |                   Descrição                   | Principais Funcionalidades                                                                                                                                        |
| :--------------- | :-------------------------------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Flow**         | Orquestração de fluxo de trabalho estruturada | • Gerencia caminhos de execução<br />• Lida com transições de estado<br />• Controla a sequência de tarefas<br />• Garante execução confiável                     |
| **Events**       |         Gatilhos para ações nos fluxos        | • Iniciam processos específicos<br />• Permitem respostas dinâmicas<br />• Suportam ramificações condicionais<br />• Adaptam-se em tempo real                     |
| **States**       |        Contextos de execução dos fluxos       | • Mantêm dados de execução<br />• Permitem persistência<br />• Suportam retomada<br />• Garantem integridade na execução                                          |
| **Crew Support** |          Aprimora automação de fluxos         | • Injeta autonomia quando necessário<br />• Complementa fluxos estruturados<br />• Equilibra automação e inteligência<br />• Permite tomada de decisão adaptativa |

### Capacidades-Chave

<CardGroup cols={2}>
  <Card title="Orquestração Orientada por Eventos" icon="bolt">
    Defina caminhos de execução precisos respondendo dinamicamente a eventos
  </Card>

  <Card title="Controle Detalhado" icon="sliders">
    Gerencie estados de fluxo de trabalho e execução condicional de forma segura e eficiente
  </Card>

  <Card title="Integração Nativa com Crew" icon="puzzle-piece">
    Combine de forma simples com Crews para maior autonomia e inteligência
  </Card>

  <Card title="Execução Determinística" icon="route">
    Garanta resultados previsíveis com controle explícito de fluxo e tratamento de erros
  </Card>
</CardGroup>

## Quando usar Crews versus Flows

<Note>
  Entender quando utilizar [Crews](/pt-BR/guides/crews/first-crew) ou [Flows](/pt-BR/guides/flows/first-flow) é fundamental para maximizar o potencial do CrewAI em suas aplicações.
</Note>

| Caso de uso              | Abordagem recomendada                   | Por quê?                                                                                                                                                  |
| :----------------------- | :-------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Pesquisa aberta**      | [Crews](/pt-BR/guides/crews/first-crew) | Quando as tarefas exigem criatividade, exploração e adaptação                                                                                             |
| **Geração de conteúdo**  | [Crews](/pt-BR/guides/crews/first-crew) | Para criação colaborativa de artigos, relatórios ou materiais de marketing                                                                                |
| **Fluxos de decisão**    | [Flows](/pt-BR/guides/flows/first-flow) | Quando é necessário caminhos de decisão previsíveis, auditáveis e com controle preciso                                                                    |
| **Orquestração de APIs** | [Flows](/pt-BR/guides/flows/first-flow) | Para integração confiável com múltiplos serviços externos em sequência específica                                                                         |
| **Aplicações híbridas**  | Abordagem combinada                     | Use [Flows](/pt-BR/guides/flows/first-flow) para orquestrar o processo geral com [Crews](/pt-BR/guides/crews/first-crew) lidando com subtarefas complexas |

### Framework de Decisão

* **Escolha [Crews](/pt-BR/guides/crews/first-crew) quando:** Precisa de resolução autônoma de problemas, colaboração criativa ou tarefas exploratórias
* **Escolha [Flows](/pt-BR/guides/flows/first-flow) quando:** Requer resultados determinísticos, auditabilidade ou controle preciso sobre a execução
* **Combine ambos quando:** Sua aplicação precisa de processos estruturados e também de bolsões de inteligência autônoma

## Por que escolher o CrewAI?

* 🧠 **Operação Autônoma**: Agentes tomam decisões inteligentes com base em suas funções e nas ferramentas disponíveis
* 📝 **Interação Natural**: Agentes se comunicam e colaboram como membros humanos de uma equipe
* 🛠️ **Design Extensível**: Fácil de adicionar novas ferramentas, funções e capacidades
* 🚀 **Pronto para Produção**: Construído para confiabilidade e escalabilidade em aplicações reais
* 🔒 **Foco em Segurança**: Desenvolvido para atender requisitos de segurança empresarial
* 💰 **Custo-Efetivo**: Otimizado para minimizar o uso de tokens e chamadas de API

## Pronto para começar a construir?

<CardGroup cols={2}>
  <Card title="Crie Seu Primeiro Crew" icon="users-gear" href="/pt-BR/guides/crews/first-crew">
    Tutorial passo a passo para criar uma equipe de IA colaborativa que trabalha junto para resolver problemas complexos.
  </Card>

  <Card title="Crie Seu Primeiro Flow" icon="diagram-project" href="/pt-BR/guides/flows/first-flow">
    Aprenda a criar fluxos de trabalho estruturados e orientados por eventos com controle preciso de execução.
  </Card>
</CardGroup>

<CardGroup cols={3}>
  <Card title="Instale o CrewAI" icon="wrench" href="/pt-BR/installation">
    Comece a usar o CrewAI em seu ambiente de desenvolvimento.
  </Card>

  <Card title="Primeiros Passos" icon="bolt" href="/pt-BR/quickstart">
    Siga nosso guia rápido para criar seu primeiro agente CrewAI e colocar a mão na massa.
  </Card>

  <Card title="Junte-se à Comunidade" icon="comments" href="https://community.crewai.com">
    Conecte-se com outros desenvolvedores, obtenha ajuda e compartilhe suas experiências com o CrewAI.
  </Card>
</CardGroup>


# Hooks Antes e Depois do Kickoff
Source: https://docs.crewai.com/pt-BR/learn/before-and-after-kickoff-hooks

Aprenda a usar hooks antes e depois do kickoff em CrewAI

O CrewAI fornece hooks que permitem executar código antes e depois do kickoff de uma crew. Esses hooks são úteis para pré-processar entradas ou pós-processar resultados.

## Hook Antes do Kickoff

O hook antes do kickoff é executado antes da crew iniciar suas tarefas. Ele recebe o dicionário de entradas e pode modificá-lo antes de passá-lo para a crew. Você pode usar esse hook para configurar seu ambiente, carregar dados necessários ou pré-processar suas entradas. Isso é útil em cenários onde os dados de entrada podem precisar de enriquecimento ou validação antes de serem processados pela crew.

Aqui está um exemplo de como definir uma função antes do kickoff em seu `crew.py`:

```python
from crewai import CrewBase
from crewai.project import before_kickoff

@CrewBase
class MinhaEquipe:
    @before_kickoff
    def preparar_dados(self, entradas):
        # Pré-processa ou modifica as entradas
        entradas['processado'] = True
        return entradas

#...
```

Neste exemplo, a função preparar\_dados modifica as entradas adicionando um novo par chave-valor indicando que as entradas foram processadas.

## Hook Depois do Kickoff

O hook depois do kickoff é executado após a crew completar suas tarefas. Ele recebe o objeto de resultado, que contém as saídas da execução da crew. Este hook é ideal para pós-processar resultados, como log, transformação de dados ou análise adicional.

Veja como você pode definir uma função depois do kickoff em seu `crew.py`:

```python
from crewai import CrewBase
from crewai.project import after_kickoff

@CrewBase
class MinhaEquipe:
    @after_kickoff
    def registrar_resultados(self, resultado):
        # Registra ou modifica os resultados
        print("Execução da equipe concluída com resultado:", resultado)
        return resultado

# ...
```

Na função `registrar_resultados`, os resultados da execução da crew são simplesmente impressos. Você pode estender isso para realizar operações mais complexas, como enviar notificações ou integrar com outros serviços.

## Utilizando Ambos os Hooks

Ambos os hooks podem ser usados juntos para oferecer um processo completo de preparação e finalização na execução da sua crew. Eles são particularmente úteis para manter uma arquitetura de código limpa, separando responsabilidades e melhorando a modularidade das suas implementações com CrewAI.

## Conclusão

Os hooks antes e depois do kickoff em CrewAI oferecem formas poderosas de interagir com o ciclo de vida da execução de uma crew. Ao entender e utilizar esses hooks, você pode aumentar significativamente a robustez e flexibilidade dos seus agentes de IA.


# Traga seu próprio agente
Source: https://docs.crewai.com/pt-BR/learn/bring-your-own-agent

Aprenda como trazer seus próprios agentes que funcionam dentro de uma Crew.

Interoperabilidade é um conceito fundamental no CrewAI. Este guia mostrará como trazer seus próprios agentes para funcionar dentro de uma Crew.

## Guia de Adaptação para trazer seus próprios agentes (Agentes Langgraph, Agentes OpenAI, etc...)

Requeremos 3 adaptadores para tornar qualquer agente de diferentes frameworks compatível com uma crew.

1. BaseAgentAdapter
2. BaseToolAdapter
3. BaseConverter

## BaseAgentAdapter

Esta classe abstrata define a interface comum e a funcionalidade que todos
os adaptadores de agente devem implementar. Ela estende BaseAgent para manter compatibilidade
com o framework CrewAI, ao mesmo tempo em que adiciona requisitos específicos do adaptador.

Métodos obrigatórios:

1. `def configure_tools`
2. `def configure_structured_output`

## Criando seu próprio Adaptador

Para integrar um agente de um framework diferente (por exemplo, LangGraph, Autogen, OpenAI Assistants) ao CrewAI, você precisa criar um adaptador customizado herdando de `BaseAgentAdapter`. Esse adaptador atua como uma camada de compatibilidade, traduzindo entre as interfaces do CrewAI e os requisitos específicos do seu agente externo.

Veja como implementar seu adaptador customizado:

1. **Herdar de `BaseAgentAdapter`**:
   ```python
   from crewai.agents.agent_adapters.base_agent_adapter import BaseAgentAdapter
   from crewai.tools import BaseTool
   from typing import List, Optional, Any, Dict

   class MyCustomAgentAdapter(BaseAgentAdapter):
       # ... detalhes da implementação ...
   ```

2. **Implementar `__init__`**:
   O construtor deve chamar o construtor da classe pai `super().__init__(**kwargs)` e executar qualquer inicialização específica do seu agente externo. Você pode usar o dicionário opcional `agent_config` passado durante a inicialização do `Agent` do CrewAI para configurar seu adaptador e o agente subjacente.

   ```python
   def __init__(self, agent_config: Optional[Dict[str, Any]] = None, **kwargs: Any):
       super().__init__(agent_config=agent_config, **kwargs)
       # Inicialize seu agente externo aqui, possivelmente usando agent_config
       # Exemplo: self.external_agent = initialize_my_agent(agent_config)
       print(f"Inicializando MyCustomAgentAdapter com config: {agent_config}")
   ```

3. **Implementar `configure_tools`**:
   Este método abstrato é crucial. Ele recebe uma lista de instâncias de `BaseTool` do CrewAI. Sua implementação deve converter ou adaptar essas ferramentas para o formato esperado pelo seu framework de agente externo. Isso pode envolver encapsulamento, extração de atributos específicos ou registro delas na instância do agente externo.

   ```python
   def configure_tools(self, tools: Optional[List[BaseTool]] = None) -> None:
       if tools:
           adapted_tools = []
           for tool in tools:
               # Adapte o CrewAI BaseTool para o formato que seu agente espera
               # Exemplo: adapted_tool = adapt_to_my_framework(tool)
               # adapted_tools.append(adapted_tool)
               pass # Substitua pela sua lógica real de adaptação

           # Configure o agente externo com as ferramentas adaptadas
           # Exemplo: self.external_agent.set_tools(adapted_tools)
           print(f"Configurando ferramentas para MyCustomAgentAdapter: {adapted_tools}") # Placeholder
       else:
           # Caso nenhum ferramenta seja fornecida
           # Exemplo: self.external_agent.set_tools([])
           print("Nenhuma ferramenta fornecida para MyCustomAgentAdapter.")
   ```

4. **Implementar `configure_structured_output`**:
   Esse método é chamado quando o `Agent` do CrewAI é configurado com requisitos de saída estruturada (por exemplo, `output_json` ou `output_pydantic`). Seu adaptador precisa garantir que o agente externo esteja configurado para cumprir esses requisitos. Isso pode envolver definir parâmetros específicos no agente externo ou garantir que seu modelo subjacente suporte o formato solicitado. Se o agente externo não suportar saída estruturada de forma compatível com as expectativas do CrewAI, talvez seja necessário lidar com a conversão ou lançar um erro apropriado.

   ```python
   def configure_structured_output(self, structured_output: Any) -> None:
       # Configure seu agente externo para produzir saída no formato especificado
       # Exemplo: self.external_agent.set_output_format(structured_output)
       self.adapted_structured_output = True # Sinaliza que a saída estruturada foi tratada
       print(f"Configurando saída estruturada para MyCustomAgentAdapter: {structured_output}")
   ```

Implementando esses métodos, seu `MyCustomAgentAdapter` permitirá que sua implementação personalizada de agente funcione corretamente dentro de uma crew do CrewAI, interagindo com tarefas e ferramentas de forma transparente. Lembre-se de substituir os comentários e prints de exemplo pela sua lógica real de adaptação específica do framework externo que está integrando.

## Implementação de BaseToolAdapter

A classe `BaseToolAdapter` é responsável por converter os objetos nativos `BaseTool` do CrewAI em um formato que o seu framework de agente externo possa entender e utilizar. Diferentes frameworks de agentes (como LangGraph, OpenAI Assistants, etc.) possuem suas próprias formas de definir e tratar ferramentas, e o `BaseToolAdapter` age como tradutor.

Veja como implementar seu adaptador de ferramentas personalizado:

1. **Herdar de `BaseToolAdapter`**:
   ```python
   from crewai.agents.agent_adapters.base_tool_adapter import BaseToolAdapter
   from crewai.tools import BaseTool
   from typing import List, Any

   class MyCustomToolAdapter(BaseToolAdapter):
       # ... detalhes da implementação ...
   ```

2. **Implementar `configure_tools`**:
   Este é o método abstrato principal que você deve implementar. Ele recebe uma lista de instâncias de `BaseTool` fornecidas ao agente. Sua tarefa é iterar por essa lista, adaptar cada `BaseTool` para o formato esperado pelo seu framework externo e armazenar as ferramentas convertidas na lista `self.converted_tools` (inicializada no construtor da classe base).

   ```python
   def configure_tools(self, tools: List[BaseTool]) -> None:
       """Configura e converte ferramentas do CrewAI para a implementação específica."""
       self.converted_tools = [] # Reseta caso seja chamado múltiplas vezes
       for tool in tools:
           # Sanitizar o nome da ferramenta se necessário pelo framework alvo
           sanitized_name = self.sanitize_tool_name(tool.name)

           # --- Sua lógica de conversão aqui ---
           # Exemplo: Converter BaseTool para formato de dicionário para LangGraph
           # converted_tool = {
           #     "name": sanitized_name,
           #     "description": tool.description,
           #     "parameters": tool.args_schema.schema() if tool.args_schema else {},
           #     # Adicione outros campos específicos do framework
           # }

           # Exemplo: Converter BaseTool para definição de função OpenAI
           # converted_tool = {
           #     "type": "function",
           #     "function": {
           #         "name": sanitized_name,
           #         "description": tool.description,
           #         "parameters": tool.args_schema.schema() if tool.args_schema else {"type": "object", "properties": {}},
           #     }
           # }

           # --- Substitua os exemplos acima pela sua adaptação real ---
           converted_tool = self.adapt_tool_to_my_framework(tool, sanitized_name) # Placeholder

           self.converted_tools.append(converted_tool)
           print(f"Ferramenta '{tool.name}' adaptada para '{sanitized_name}' em MyCustomToolAdapter") # Placeholder

       print(f"MyCustomToolAdapter terminou de configurar ferramentas: {len(self.converted_tools)} adaptadas.") # Placeholder

   # --- Método auxiliar para adaptação (Exemplo) ---
   def adapt_tool_to_my_framework(self, tool: BaseTool, sanitized_name: str) -> Any:
       # Substitua pela lógica real para converter um CrewAI BaseTool
       # para o formato necessário do framework de agente externo específico.
       # Isso pode variar bastante de acordo com o framework.
       adapted_representation = {
           "framework_specific_name": sanitized_name,
           "framework_specific_description": tool.description,
           "inputs": tool.args_schema.schema() if tool.args_schema else None,
           "implementation_reference": tool.run # Ou conforme o framework precisa chamar
       }
       # Certifique-se também que a ferramenta funcione tanto síncrona quanto assincronamente
       async def async_tool_wrapper(*args, **kwargs):
           output = tool.run(*args, **kwargs)
           if inspect.isawaitable(output):
               return await output
           else:
               return output

       adapted_tool = MyFrameworkTool(
           name=sanitized_name,
           description=tool.description,
           inputs=tool.args_schema.schema() if tool.args_schema else None,
           implementation_reference=async_tool_wrapper
       )

       return adapted_representation

   ```

3. **Utilizando o Adaptador**:
   Normalmente, você instanciaria seu `MyCustomToolAdapter` dentro do método `configure_tools` do seu `MyCustomAgentAdapter` e o usaria para processar as ferramentas antes de configurar o agente externo.

   ```python
   # Dentro de MyCustomAgentAdapter.configure_tools
   def configure_tools(self, tools: Optional[List[BaseTool]] = None) -> None:
       if tools:
           tool_adapter = MyCustomToolAdapter() # Instancia seu adaptador de ferramenta
           tool_adapter.configure_tools(tools)  # Converte as ferramentas
           adapted_tools = tool_adapter.tools() # Obtém as ferramentas convertidas

           # Agora configure seu agente externo com as ferramentas adaptadas
           # Exemplo: self.external_agent.set_tools(adapted_tools)
           print(f"Configurando agente externo com ferramentas adaptadas: {adapted_tools}") # Placeholder
       else:
           # Caso sem ferramentas
           print("Nenhuma ferramenta fornecida para MyCustomAgentAdapter.")
   ```

Ao criar um `BaseToolAdapter`, você desacopla a lógica de conversão de ferramenta da adaptação de agente, tornando a integração mais limpa e modular. Lembre-se de substituir os exemplos de placeholder pela lógica de conversão real exigida pelo seu framework externo específico.

## BaseConverter

O `BaseConverterAdapter` desempenha um papel crucial quando uma `Task` do CrewAI exige que um agente retorne sua saída final em um formato estruturado específico, como JSON ou um modelo Pydantic. Ele faz a ponte entre os requisitos de saída estruturada do CrewAI e as capacidades do seu agente externo.

Suas responsabilidades principais são:

1. **Configurar o Agente para Saída Estruturada:** Com base nos requisitos da `Task` (`output_json` ou `output_pydantic`), ele instrui o `BaseAgentAdapter` associado (e indiretamente, o agente externo) sobre qual formato é esperado.
2. **Apriorar o Prompt do Sistema:** Ele modifica o prompt do sistema do agente para incluir instruções claras sobre *como* gerar a saída na estrutura exigida.
3. **Pós-processamento do Resultado:** Pega a saída bruta do agente e tenta fazer parsing, validar e formatar conforme a estrutura requerida, retornando por fim uma representação em string (por exemplo, uma string JSON).

Veja como implementar seu adaptador de conversão customizado:

1. **Herdar de `BaseConverterAdapter`**:
   ```python
   from crewai.agents.agent_adapters.base_converter_adapter import BaseConverterAdapter
   # Supondo que o seu MyCustomAgentAdapter foi definido
   # from .my_custom_agent_adapter import MyCustomAgentAdapter
   from crewai.task import Task
   from typing import Any

   class MyCustomConverterAdapter(BaseConverterAdapter):
       # Armazena o tipo de saída esperado (ex: 'json', 'pydantic', 'text')
       _output_type: str = 'text'
       _output_schema: Any = None # Armazena o schema JSON ou modelo Pydantic

       # ... detalhes da implementação ...
   ```

2. **Implementar `__init__`**:
   O construtor deve aceitar a instância correspondente de `agent_adapter` com a qual irá trabalhar.

   ```python
   def __init__(self, agent_adapter: Any): # Use um type hint específico para seu AgentAdapter
       self.agent_adapter = agent_adapter
       print(f"Inicializando MyCustomConverterAdapter para o adaptador de agente: {type(agent_adapter).__name__}")
   ```

3. **Implementar `configure_structured_output`**:
   Esse método recebe o objeto `Task` do CrewAI. Você precisa checar os atributos `output_json` e `output_pydantic` da task para determinar a estrutura de saída exigida. Armazene essa informação (por exemplo, em `_output_type` e `_output_schema`) e, potencialmente, chame métodos de configuração no seu `self.agent_adapter` se o agente externo necessitar de um ajuste específico para saída estruturada (algo que pode já ter sido parcialmente feito no `configure_structured_output` do adaptador de agente).

   ```python
   def configure_structured_output(self, task: Task) -> None:
       """Configura a saída estruturada esperada baseada na task."""
       if task.output_pydantic:
           self._output_type = 'pydantic'
           self._output_schema = task.output_pydantic
           print(f"Converter: Configurado para saída Pydantic: {self._output_schema.__name__}")
       elif task.output_json:
           self._output_type = 'json'
           self._output_schema = task.output_json
           print(f"Converter: Configurado para saída JSON com schema: {self._output_schema}")
       else:
           self._output_type = 'text'
           self._output_schema = None
           print("Converter: Configurado para saída de texto padrão.")

       # Opcionalmente, informe o agent_adapter se necessário
       # self.agent_adapter.set_output_mode(self._output_type, self._output_schema)
   ```

4. **Implementar `enhance_system_prompt`**:
   Este método recebe o prompt base do sistema do agente e deve anexar instruções adaptadas para o `_output_type` e `_output_schema` atualmente configurados. O objetivo é guiar o LLM que alimenta o agente a produzir saída no formato correto.

   ````python
   def enhance_system_prompt(self, base_prompt: str) -> str:
       """Aprimore o prompt do sistema com instruções de saída estruturada."""
       if self._output_type == 'text':
           return base_prompt # Nenhum aprimoramento necessário para texto puro

       instructions = "\n\nSua resposta final DEVE estar formatada como "
       if self._output_type == 'json':
           schema_str = json.dumps(self._output_schema, indent=2)
           instructions += f"um objeto JSON conforme o seguinte schema:\n```json\n{schema_str}\n```"
       elif self._output_type == 'pydantic':
           schema_str = json.dumps(self._output_schema.model_json_schema(), indent=2)
           instructions += f"um objeto JSON conforme o modelo Pydantic '{self._output_schema.__name__}' com o seguinte schema:\n```json\n{schema_str}\n```"

       instructions += "\nGaranta que toda a sua resposta seja APENAS o objeto JSON válido, sem nenhum texto introdutório, explicações ou considerações finais."

       print(f"Converter: Aprimorando prompt para saída {self._output_type}.")
       return base_prompt + instructions
   ````

   *Nota: O prompt pode precisar de ajustes conforme o agente/LLM usado.*

5. **Implementar `post_process_result`**:
   Esse método recebe a saída em string bruta do agente. Se uma saída estruturada foi solicitada (`json` ou `pydantic`), você deve tentar convertê-la para o formato esperado. Trate erros de parsing caso ocorram (por exemplo, registre-os, tente corrigir, ou lance uma exceção). O método **deve sempre retornar uma string**, mesmo se o formato intermediário seja um dicionário ou objeto Pydantic (por exemplo, serializando novamente para JSON).

   ```python
   import json
   from pydantic import ValidationError

   def post_process_result(self, result: str) -> str:
       """Pós-processa o resultado do agente para garantir que corresponde ao formato esperado."""
       print(f"Converter: Pós-processando resultado para saída {self._output_type}.")
       if self._output_type == 'json':
           try:
               # Tenta fazer parsing e re-serializar para garantir validade e formato consistente
               parsed_json = json.loads(result)
               # Opcional: Validar contra o schema se for um dicionário JSON schema
               # from jsonschema import validate
               # validate(instance=parsed_json, schema=self._output_schema)
               return json.dumps(parsed_json)
           except json.JSONDecodeError as e:
               print(f"Erro: Falha ao fazer parsing da saída JSON: {e}\nSaída bruta:\n{result}")
               # Trate o erro: retorne bruto, lance exceção, ou tente corrigir
               return result # Exemplo: retorna a saída bruta caso falhe
           # except Exception as e: # Captura erros de validação se usar jsonschema
           #     print(f"Erro: saída JSON falhou na validação do schema: {e}\nSaída bruta:\n{result}")
           #     return result
       elif self._output_type == 'pydantic':
           try:
               # Tenta fazer parsing para o modelo Pydantic
               model_instance = self._output_schema.model_validate_json(result)
               # Retorna o modelo serializado de volta para JSON
               return model_instance.model_dump_json()
           except ValidationError as e:
               print(f"Erro: Falha ao validar saída Pydantic: {e}\nSaída bruta:\n{result}")
               # Trate o erro
               return result # Exemplo: retorna a saída bruta caso falhe
           except json.JSONDecodeError as e:
                print(f"Erro: Falha ao fazer parsing do JSON para o modelo Pydantic: {e}\nSaída bruta:\n{result}")
                return result
       else: # 'text'
           return result # Sem processamento para texto puro
   ```

Implementando esses métodos, seu `MyCustomConverterAdapter` assegurará que as solicitações de saída estruturada das tarefas do CrewAI sejam corretamente tratadas pelo seu agente externo integrado, aumentando a confiabilidade e a usabilidade do seu agente customizado dentro do framework CrewAI.

## Adapters prontos para uso

Fornecemos adapters prontos para uso para os seguintes frameworks:

1. LangGraph
2. Agentes OpenAI

## Iniciando uma crew com agentes adaptados:

```python
import json
import os
from typing import List

from crewai_tools import SerperDevTool
from src.crewai import Agent, Crew, Task
from langchain_openai import ChatOpenAI
from pydantic import BaseModel

from crewai.agents.agent_adapters.langgraph.langgraph_adapter import (
    LangGraphAgentAdapter,
)
from crewai.agents.agent_adapters.openai_agents.openai_adapter import OpenAIAgentAdapter

# Agente CrewAI
code_helper_agent = Agent(
    role="Code Helper",
    goal="Help users solve coding problems effectively and provide clear explanations.",
    backstory="You are an experienced programmer with deep knowledge across multiple programming languages and frameworks. You specialize in solving complex coding challenges and explaining solutions clearly.",
    allow_delegation=False,
    verbose=True,
)
# OpenAI Agent Adapter
link_finder_agent = OpenAIAgentAdapter(
    role="Link Finder",
    goal="Find the most relevant and high-quality resources for coding tasks.",
    backstory="You are a research specialist with a talent for finding the most helpful resources. You're skilled at using search tools to discover documentation, tutorials, and examples that directly address the user's coding needs.",
    tools=[SerperDevTool()],
    allow_delegation=False,
    verbose=True,
)

# LangGraph Agent Adapter
reporter_agent = LangGraphAgentAdapter(
    role="Reporter",
    goal="Report the results of the tasks.",
    backstory="You are a reporter who reports the results of the other tasks",
    llm=ChatOpenAI(model="gpt-4o"),
    allow_delegation=True,
    verbose=True,
)


class Code(BaseModel):
    code: str


task = Task(
    description="Give an answer to the coding question: {task}",
    expected_output="A thorough answer to the coding question: {task}",
    agent=code_helper_agent,
    output_json=Code,
)
task2 = Task(
    description="Find links to resources that can help with coding tasks. Use the serper tool to find resources that can help.",
    expected_output="A list of links to resources that can help with coding tasks",
    agent=link_finder_agent,
)


class Report(BaseModel):
    code: str
    links: List[str]


task3 = Task(
    description="Report the results of the tasks.",
    expected_output="A report of the results of the tasks. this is the code produced and then the links to the resources that can help with the coding task.",
    agent=reporter_agent,
    output_json=Report,
)
# Usando no CrewAI
crew = Crew(
    agents=[code_helper_agent, link_finder_agent, reporter_agent],
    tasks=[task, task2, task3],
    verbose=True,
)

result = crew.kickoff(
    inputs={"task": "How do you implement an abstract class in python?"}
)

# Imprima o resultado bruto primeiro
print("Raw result:", result)

# Lide com o resultado de acordo com seu tipo
if hasattr(result, "json_dict") and result.json_dict:
    json_result = result.json_dict
    print("\nStructured JSON result:")
    print(f"{json.dumps(json_result, indent=2)}")

    # Acesse os campos de forma segura
    if isinstance(json_result, dict):
        if "code" in json_result:
            print("\nCode:")
            print(
                json_result["code"][:200] + "..."
                if len(json_result["code"]) > 200
                else json_result["code"]
            )

        if "links" in json_result:
            print("\nLinks:")
            for link in json_result["links"][:5]:  # Print first 5 links
                print(f"- {link}")
            if len(json_result["links"]) > 5:
                print(f"...and {len(json_result['links']) - 5} more links")
elif hasattr(result, "pydantic") and result.pydantic:
    print("\nPydantic model result:")
    print(result.pydantic.model_dump_json(indent=2))
else:
    # Fallback para saída bruta
    print("\nNo structured result available, using raw output:")
    print(result.raw[:500] + "..." if len(result.raw) > 500 else result.raw)

```


# Agentes de Codificação
Source: https://docs.crewai.com/pt-BR/learn/coding-agents

Aprenda como habilitar seus Agentes CrewAI para escrever e executar código, e explore funcionalidades avançadas para maior potencial.

## Introdução

Os Agentes CrewAI agora têm a poderosa capacidade de escrever e executar código, aumentando significativamente suas habilidades de resolução de problemas. Esse recurso é particularmente útil para tarefas que exigem soluções computacionais ou programáticas.

## Habilitando a Execução de Código

Para habilitar a execução de código para um agente, defina o parâmetro `allow_code_execution` como `True` ao criar o agente.

Veja um exemplo:

```python Code
from crewai import Agent

coding_agent = Agent(
    role="Senior Python Developer",
    goal="Craft well-designed and thought-out code",
    backstory="You are a senior Python developer with extensive experience in software architecture and best practices.",
    allow_code_execution=True
)
```

<Note>
  Observe que o parâmetro `allow_code_execution` é `False` por padrão.
</Note>

## Considerações Importantes

1. **Seleção de Modelo**: É fortemente recomendado utilizar modelos mais avançados como Claude 3.5 Sonnet e GPT-4 ao habilitar a execução de código.
   Esses modelos têm melhor compreensão de conceitos de programação e tendem a gerar códigos mais corretos e eficientes.

2. **Tratamento de Erros**: O recurso de execução de código inclui tratamento de erros. Se o código executado gerar uma exceção, o agente receberá a mensagem de erro e poderá tentar corrigir o código ou
   fornecer soluções alternativas. O parâmetro `max_retry_limit`, que por padrão é 2, controla o número máximo de tentativas para uma tarefa.

3. **Dependências**: Para usar o recurso de execução de código, é necessário instalar o pacote `crewai_tools`. Caso não esteja instalado, o agente registrará uma mensagem informativa:
   "Ferramentas de codificação não disponíveis. Instale crewai\_tools."

## Processo de Execução de Código

Quando um agente com execução de código habilitada encontra uma tarefa que requer programação:

<Steps>
  <Step title="Análise da Tarefa">
    O agente analisa a tarefa e determina que a execução de código é necessária.
  </Step>

  <Step title="Formulação do Código">
    Ele formula o código Python necessário para resolver o problema.
  </Step>

  <Step title="Execução do Código">
    O código é enviado para a ferramenta interna de execução de código (`CodeInterpreterTool`).
  </Step>

  <Step title="Interpretação dos Resultados">
    O agente interpreta o resultado e o incorpora na sua resposta ou o utiliza para aprofundar a solução do problema.
  </Step>
</Steps>

## Exemplo de Uso

Veja um exemplo detalhado de como criar um agente com capacidade de execução de código e utilizá-lo em uma tarefa:

```python Code
from crewai import Agent, Task, Crew

# Create an agent with code execution enabled
coding_agent = Agent(
    role="Python Data Analyst",
    goal="Analyze data and provide insights using Python",
    backstory="You are an experienced data analyst with strong Python skills.",
    allow_code_execution=True
)

# Create a task that requires code execution
data_analysis_task = Task(
    description="Analyze the given dataset and calculate the average age of participants.",
    agent=coding_agent
)

# Create a crew and add the task
analysis_crew = Crew(
    agents=[coding_agent],
    tasks=[data_analysis_task]
)

# Execute the crew
result = analysis_crew.kickoff()

print(result)
```

Neste exemplo, o `coding_agent` pode escrever e executar código Python para realizar tarefas de análise de dados.


# Tarefas Condicionais
Source: https://docs.crewai.com/pt-BR/learn/conditional-tasks

Saiba como usar tarefas condicionais em um kickoff do crewAI

## Introdução

As Tarefas Condicionais no crewAI permitem a adaptação dinâmica do fluxo de trabalho com base nos resultados de tarefas anteriores.
Esse recurso poderoso possibilita que crews tomem decisões e executem tarefas seletivamente, aumentando a flexibilidade e a eficiência dos seus processos orientados por IA.

## Exemplo de Uso

```python Code
from typing import List
from pydantic import BaseModel
from crewai import Agent, Crew
from crewai.tasks.conditional_task import ConditionalTask
from crewai.tasks.task_output import TaskOutput
from crewai.task import Task
from crewai_tools import SerperDevTool

# Define a condition function for the conditional task
# If false, the task will be skipped, if true, then execute the task.
def is_data_missing(output: TaskOutput) -> bool:
    return len(output.pydantic.events) < 10  # this will skip this task

# Define the agents
data_fetcher_agent = Agent(
    role="Data Fetcher",
    goal="Fetch data online using Serper tool",
    backstory="Backstory 1",
    verbose=True,
    tools=[SerperDevTool()]
)

data_processor_agent = Agent(
    role="Data Processor",
    goal="Process fetched data",
    backstory="Backstory 2",
    verbose=True
)

summary_generator_agent = Agent(
    role="Summary Generator",
    goal="Generate summary from fetched data",
    backstory="Backstory 3",
    verbose=True
)

class EventOutput(BaseModel):
    events: List[str]

task1 = Task(
    description="Fetch data about events in San Francisco using Serper tool",
    expected_output="List of 10 things to do in SF this week",
    agent=data_fetcher_agent,
    output_pydantic=EventOutput,
)

conditional_task = ConditionalTask(
    description="""
        Check if data is missing. If we have less than 10 events,
        fetch more events using Serper tool so that
        we have a total of 10 events in SF this week..
        """,
    expected_output="List of 10 Things to do in SF this week",
    condition=is_data_missing,
    agent=data_processor_agent,
)

task3 = Task(
    description="Generate summary of events in San Francisco from fetched data",
    expected_output="A complete report on the customer and their customers and competitors, including their demographics, preferences, market positioning and audience engagement.",
    agent=summary_generator_agent,
)

# Create a crew with the tasks
crew = Crew(
    agents=[data_fetcher_agent, data_processor_agent, summary_generator_agent],
    tasks=[task1, conditional_task, task3],
    verbose=True,
    planning=True
)

# Run the crew
result = crew.kickoff()
print("results", result)
```


# Criar Ferramentas Personalizadas
Source: https://docs.crewai.com/pt-BR/learn/create-custom-tools

Guia abrangente sobre como criar, utilizar e gerenciar ferramentas personalizadas dentro do framework CrewAI, incluindo novas funcionalidades e tratamento de erros.

## Criando e Utilizando Ferramentas no CrewAI

Este guia traz instruções detalhadas sobre como criar ferramentas personalizadas para o framework CrewAI e como gerenciar e utilizar essas ferramentas de forma eficiente,
incorporando funcionalidades recentes, como delegação de ferramentas, tratamento de erros e chamada dinâmica de ferramentas. Destaca também a importância de ferramentas de colaboração,
permitindo que agentes executem uma ampla gama de ações.

### Subclassificando `BaseTool`

Para criar uma ferramenta personalizada, herde de `BaseTool` e defina os atributos necessários, incluindo o `args_schema` para validação de entrada e o método `_run`.

```python Code
from typing import Type
from crewai.tools import BaseTool
from pydantic import BaseModel, Field

class MyToolInput(BaseModel):
    """Input schema for MyCustomTool."""
    argument: str = Field(..., description="Description of the argument.")

class MyCustomTool(BaseTool):
    name: str = "Name of my tool"
    description: str = "What this tool does. It's vital for effective utilization."
    args_schema: Type[BaseModel] = MyToolInput

    def _run(self, argument: str) -> str:
        # Your tool's logic here
        return "Tool's result"
```

### Usando o Decorador `tool`

Como alternativa, você pode utilizar o decorador de ferramenta `@tool`. Esta abordagem permite definir os atributos e as funcionalidades da ferramenta diretamente em uma função,
oferecendo uma maneira concisa e eficiente de criar ferramentas especializadas de acordo com suas necessidades.

```python Code
from crewai.tools import tool

@tool("Tool Name")
def my_simple_tool(question: str) -> str:
    """Tool description for clarity."""
    # Tool logic here
    return "Tool output"
```

### Definindo uma Função de Cache para a Ferramenta

Para otimizar o desempenho da ferramenta com cache, defina estratégias de cache personalizadas utilizando o atributo `cache_function`.

```python Code
@tool("Tool with Caching")
def cached_tool(argument: str) -> str:
    """Tool functionality description."""
    return "Cacheable result"

def my_cache_strategy(arguments: dict, result: str) -> bool:
    # Define custom caching logic
    return True if some_condition else False

cached_tool.cache_function = my_cache_strategy
```

Seguindo essas orientações e incorporando novas funcionalidades e ferramentas de colaboração nos seus processos de criação e gerenciamento de ferramentas,
você pode aproveitar ao máximo as capacidades do framework CrewAI, aprimorando tanto a experiência de desenvolvimento quanto a eficiência dos seus agentes de IA.


# Implementação de LLM Personalizada
Source: https://docs.crewai.com/pt-BR/learn/custom-llm

Aprenda a criar implementações personalizadas de LLM no CrewAI.

## Visão Geral

O CrewAI oferece suporte a implementações personalizadas de LLM por meio da classe abstrata `BaseLLM`. Isso permite integrar qualquer provedor de LLM que não tenha suporte nativo no LiteLLM ou implementar mecanismos de autenticação personalizados.

## Início Rápido

Aqui está uma implementação mínima de LLM personalizada:

```python
# (não traduzir blocos de código)
```

## Usando Seu LLM Personalizado

```python
# (não traduzir blocos de código)
```

## Métodos Necessários

### Construtor: `__init__()`

**Crítico**: Você deve chamar `super().__init__(model, temperature)` com os parâmetros necessários:

```python
# (não traduzir blocos de código)
```

### Método Abstrato: `call()`

O método `call()` é o núcleo da sua implementação de LLM. Ele deve:

* Aceitar mensagens (string ou lista de dicionários com 'role' e 'content')
* Retornar uma resposta como string
* Lidar com ferramentas e chamada de funções, se suportado
* Lançar exceções apropriadas para erros

### Métodos Opcionais

```python
# (não traduzir blocos de código)
```

## Padrões Comuns

### Tratamento de Erros

```python
# (não traduzir blocos de código)
```

### Autenticação Personalizada

```python
# (não traduzir blocos de código)
```

### Suporte a Stop Words

O CrewAI adiciona automaticamente `"\nObservation:"` como stop word para controlar o comportamento do agente. Se o seu LLM suporta stop words:

```python
# (não traduzir blocos de código)
```

Se o seu LLM não suporta stop words nativamente:

```python
# (não traduzir blocos de código)
```

## Chamada de Funções

Se o seu LLM suporta chamada de funções, implemente o fluxo completo:

```python
# (não traduzir blocos de código)
```

## Solução de Problemas

### Problemas Comuns

**Erros no Construtor**

```python
# ❌ Errado - parâmetros obrigatórios ausentes
def __init__(self, api_key: str):
    super().__init__()

# ✅ Correto
def __init__(self, model: str, api_key: str, temperature: Optional[float] = None):
    super().__init__(model=model, temperature=temperature)
```

**Chamada de Funções Não Funciona**

* Certifique-se de que `supports_function_calling()` retorna `True`
* Verifique se você lida com `tool_calls` na resposta
* Assegure-se de que o parâmetro `available_functions` está sendo corretamente utilizado

**Falhas de Autenticação**

* Verifique o formato e as permissões da chave de API
* Confira o formato do header de autenticação
* Certifique-se de que as URLs dos endpoints estão corretas

**Erros de Parsing de Resposta**

* Valide a estrutura da resposta antes de acessar campos aninhados
* Trate casos em que o content pode ser None
* Adicione tratamento de erros para respostas malformadas

## Testando Seu LLM Personalizado

```python
# (não traduzir blocos de código)
```

Este guia cobre o essencial para implementar LLMs personalizados no CrewAI.


# Agente Gerente Personalizado
Source: https://docs.crewai.com/pt-BR/learn/custom-manager-agent

Saiba como definir um agente personalizado como gerente no CrewAI, proporcionando mais controle sobre o gerenciamento e a coordenação das tarefas.

# Definindo um Agente Específico como Gerente no CrewAI

O CrewAI permite que usuários definam um agente específico como gerente da crew, oferecendo mais controle sobre o gerenciamento e a coordenação das tarefas.
Esse recurso possibilita a personalização do papel gerencial para se adequar melhor às necessidades do seu projeto.

## Utilizando o Atributo `manager_agent`

### Agente Gerente Personalizado

O atributo `manager_agent` permite que você defina um agente personalizado para gerenciar a crew. Este agente supervisionará todo o processo, garantindo que as tarefas sejam concluídas de forma eficiente e com o mais alto padrão de qualidade.

### Exemplo

```python Code
import os
from crewai import Agent, Task, Crew, Process

# Define your agents
researcher = Agent(
    role="Researcher",
    goal="Conduct thorough research and analysis on AI and AI agents",
    backstory="You're an expert researcher, specialized in technology, software engineering, AI, and startups. You work as a freelancer and are currently researching for a new client.",
    allow_delegation=False,
)

writer = Agent(
    role="Senior Writer",
    goal="Create compelling content about AI and AI agents",
    backstory="You're a senior writer, specialized in technology, software engineering, AI, and startups. You work as a freelancer and are currently writing content for a new client.",
    allow_delegation=False,
)

# Define your task
task = Task(
    description="Generate a list of 5 interesting ideas for an article, then write one captivating paragraph for each idea that showcases the potential of a full article on this topic. Return the list of ideas with their paragraphs and your notes.",
    expected_output="5 bullet points, each with a paragraph and accompanying notes.",
)

# Define the manager agent
manager = Agent(
    role="Project Manager",
    goal="Efficiently manage the crew and ensure high-quality task completion",
    backstory="You're an experienced project manager, skilled in overseeing complex projects and guiding teams to success. Your role is to coordinate the efforts of the crew members, ensuring that each task is completed on time and to the highest standard.",
    allow_delegation=True,
)

# Instantiate your crew with a custom manager
crew = Crew(
    agents=[researcher, writer],
    tasks=[task],
    manager_agent=manager,
    process=Process.hierarchical,
)

# Start the crew's work
result = crew.kickoff()
```

## Benefícios de um Agente Gerente Personalizado

* **Controle aprimorado**: Adapte a abordagem de gerenciamento para atender às necessidades específicas do seu projeto.
* **Coordenação melhorada**: Assegure uma coordenação e gestão eficiente das tarefas por um agente experiente.
* **Gestão personalizável**: Defina funções e responsabilidades gerenciais que estejam alinhadas aos objetivos do seu projeto.

## Definindo um Manager LLM

Se você estiver utilizando o processo hierarchical e não quiser definir um agente gerente personalizado, é possível especificar o modelo de linguagem para o gerente:

```python Code
from crewai import LLM

manager_llm = LLM(model="gpt-4o")

crew = Crew(
    agents=[researcher, writer],
    tasks=[task],
    process=Process.hierarchical,
    manager_llm=manager_llm
)
```

<Note>
  É necessário definir `manager_agent` ou `manager_llm` ao utilizar o processo hierarchical.
</Note>


# Personalize Agentes
Source: https://docs.crewai.com/pt-BR/learn/customizing-agents

Um guia abrangente para adaptar agentes a funções específicas, tarefas e customizações avançadas dentro do framework CrewAI.

## Atributos Personalizáveis

A construção de uma equipe CrewAI eficiente depende da capacidade de adaptar dinamicamente seus agentes de IA para atender aos requisitos únicos de qualquer projeto. Esta seção aborda os atributos fundamentais que você pode personalizar.

### Principais Atributos para Personalização

| Atributo                            | Descrição                                                                                                                                    |
| :---------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------- |
| **Role**                            | Especifica a função do agente dentro da equipe, como 'Analista' ou 'Representante de Atendimento ao Cliente'.                                |
| **Goal**                            | Define os objetivos do agente, alinhados à sua função e à missão geral da equipe.                                                            |
| **Backstory**                       | Fornece profundidade à persona do agente, aprimorando motivações e engajamento dentro da equipe.                                             |
| **Tools** *(Opcional)*              | Representa as capacidades ou métodos que o agente utiliza para tarefas, desde funções simples até integrações complexas.                     |
| **Cache** *(Opcional)*              | Determina se o agente deve usar cache para o uso de ferramentas.                                                                             |
| **Max RPM**                         | Define o número máximo de requisições por minuto (`max_rpm`). Pode ser definido como `None` para requisições ilimitadas a serviços externos. |
| **Verbose** *(Opcional)*            | Ativa registros detalhados para depuração e otimização, fornecendo insights sobre os processos de execução.                                  |
| **Allow Delegation** *(Opcional)*   | Controla a delegação de tarefas para outros agentes, padrão é `False`.                                                                       |
| **Max Iter** *(Opcional)*           | Limita o número máximo de iterações (`max_iter`) para uma tarefa, prevenindo loops infinitos, com valor padrão de 25.                        |
| **Max Execution Time** *(Opcional)* | Define o tempo máximo permitido para que o agente complete uma tarefa.                                                                       |
| **System Template** *(Opcional)*    | Define o formato do sistema para o agente.                                                                                                   |
| **Prompt Template** *(Opcional)*    | Define o formato do prompt para o agente.                                                                                                    |
| **Response Template** *(Opcional)*  | Define o formato da resposta para o agente.                                                                                                  |
| **Use System Prompt** *(Opcional)*  | Controla se o agente irá usar um prompt de sistema durante a execução de tarefas.                                                            |
| **Respect Context Window**          | Ativa uma janela deslizante de contexto por padrão, mantendo o tamanho do contexto.                                                          |
| **Max Retry Limit**                 | Define o número máximo de tentativas (`max_retry_limit`) para um agente em caso de erros.                                                    |

## Opções Avançadas de Personalização

Além dos atributos básicos, o CrewAI permite customizações mais profundas para aprimorar significativamente o comportamento e as capacidades de um agente.

### Personalização de Modelo de Linguagem

Agentes podem ser personalizados com modelos de linguagem específicos (`llm`) e modelos de linguagem com chamada de função (`function_calling_llm`), oferecendo controle avançado sobre o processamento e a tomada de decisão.
É importante notar que definir o `function_calling_llm` permite sobrescrever o modelo padrão de chamada de função da equipe, proporcionando maior grau de personalização.

## Ajustes de Performance e Depuração

Ajustar a performance do agente e monitorar suas operações é fundamental para a execução eficiente de tarefas.

### Modo Verbose e Limite de RPM

* **Modo Verbose**: Ativa o registro detalhado das ações do agente, útil para depuração e otimização. Especificamente, fornece insights sobre os processos de execução do agente, auxiliando na otimização de performance.
* **Limite de RPM**: Define o número máximo de requisições por minuto (`max_rpm`). Este atributo é opcional e pode ser definido como `None` para não haver limite, permitindo consultas ilimitadas a serviços externos, se necessário.

### Máximo de Iterações por Execução de Tarefa

O atributo `max_iter` permite ao usuário definir o número máximo de iterações que um agente pode executar para uma única tarefa, prevenindo loops infinitos ou execuções excessivamente longas.
O valor padrão é 25, fornecendo um equilíbrio entre profundidade e eficiência. Quando o agente chega próximo a esse número, ele tentará entregar a melhor resposta possível.

## Personalizando Agentes e Ferramentas

Agentes são personalizados definindo seus atributos e ferramentas durante a inicialização. As ferramentas são críticas para a funcionalidade do agente, permitindo que realizem tarefas especializadas.
O atributo `tools` deve ser um array de ferramentas que o agente pode utilizar, e, por padrão, é inicializado como uma lista vazia. As ferramentas podem ser adicionadas ou modificadas após a criação do agente para se adaptar a novos requisitos.

```shell
pip install 'crewai[tools]'
```

### Exemplo: Atribuindo Ferramentas a um Agente

```python Code
import os
from crewai import Agent
from crewai_tools import SerperDevTool

# Defina as chaves de API para inicialização da ferramenta
os.environ["OPENAI_API_KEY"] = "Sua Chave"
os.environ["SERPER_API_KEY"] = "Sua Chave"

# Inicialize uma ferramenta de busca
search_tool = SerperDevTool()

# Inicialize o agente com opções avançadas
agent = Agent(
  role='Analista de Pesquisa',
  goal='Fornecer análises de mercado atualizadas',
  backstory='Um analista especialista com olhar atento para tendências de mercado.',
  tools=[search_tool],
  memory=True, # Ativa memória
  verbose=True,
  max_rpm=None, # Sem limite de requisições por minuto
  max_iter=25, # Valor padrão de máximo de iterações
)
```

## Delegação e Autonomia

Controlar a capacidade de um agente delegar tarefas ou fazer perguntas é fundamental para ajustar sua autonomia e a dinâmica de colaboração dentro do framework CrewAI. Por padrão,
o atributo `allow_delegation` agora é definido como `False`, desabilitando para que agentes busquem assistência ou deleguem tarefas conforme necessário. Esse comportamento padrão pode ser alterado para promover resolução colaborativa de problemas e
eficiência dentro do ecossistema CrewAI. Se necessário, a delegação pode ser ativada para atender requisitos operacionais específicos.

### Exemplo: Desabilitando Delegação para um Agente

```python Code
agent = Agent(
  role='Redator de Conteúdo',
  goal='Escrever conteúdo envolvente sobre tendências de mercado',
  backstory='Um redator experiente com expertise em análise de mercado.',
  allow_delegation=True # Habilitando delegação
)
```


# Geração de Imagens com DALL-E
Source: https://docs.crewai.com/pt-BR/learn/dalle-image-generation

Aprenda a usar o DALL-E para geração de imagens com IA em seus projetos CrewAI

O CrewAI oferece integração com o DALL-E da OpenAI, permitindo que seus agentes de IA gerem imagens como parte de suas tarefas. Este guia irá orientá-lo sobre como configurar e utilizar a ferramenta DALL-E em seus projetos CrewAI.

## Pré-requisitos

* crewAI instalado (última versão)
* Chave de API OpenAI com acesso ao DALL-E

## Configurando a Ferramenta DALL-E

<Steps>
  <Step title="Importe a ferramenta DALL-E">
    ```python
    from crewai_tools import DallETool
    ```
  </Step>

  <Step title="Adicione a ferramenta DALL-E na configuração do seu agente">
    ```python
    @agent
    def researcher(self) -> Agent:
        return Agent(
            config=self.agents_config['researcher'],
            tools=[SerperDevTool(), DallETool()],  # Add DallETool to the list of tools
            allow_delegation=False,
            verbose=True
        )
    ```
  </Step>
</Steps>

## Utilizando a Ferramenta DALL-E

Depois de adicionar a ferramenta DALL-E ao seu agente, ele poderá gerar imagens baseadas em prompts de texto. A ferramenta retornará uma URL para a imagem gerada, que pode ser utilizada na resposta do agente ou repassada para outros agentes para processamento adicional.

### Exemplo de Configuração de Agente

```yaml
role: >
    Pesquisador Sênior de Dados para Perfis do LinkedIn
goal: >
    Encontrar perfis detalhados do LinkedIn com base no nome fornecido {name} e domínio {domain}
    Gerar uma imagem com o Dall-e baseada no domínio {domain}
backstory: >
    Você é um pesquisador experiente com habilidade para encontrar os perfis do LinkedIn mais relevantes.
    Conhecido por sua eficiência em navegar no LinkedIn, você se destaca em reunir e apresentar
    informações profissionais de forma clara e concisa.
```

### Resultado Esperado

O agente com a ferramenta DALL-E conseguirá gerar a imagem e fornecer uma URL em sua resposta. Você poderá então baixar a imagem.

<Frame>
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/dall-e-image.png" alt="Imagem DALL-E" />
</Frame>

## Boas Práticas

1. **Seja específico nos prompts de geração de imagem** para obter melhores resultados.
2. **Considere o tempo de geração** - A geração de imagens pode levar algum tempo, então inclua isso no seu planejamento de tarefas.
3. **Siga as políticas de uso** - Sempre cumpra as políticas de uso da OpenAI ao gerar imagens.

## Solução de Problemas

1. **Verifique o acesso à API** - Certifique-se de que sua chave de API OpenAI possui acesso ao DALL-E.
2. **Compatibilidade de versões** - Verifique se você está utilizando a versão mais recente do crewAI e crewai-tools.
3. **Configuração da ferramenta** - Confirme que a ferramenta DALL-E foi corretamente adicionada à lista de ferramentas do agente.


# Forçar a Saída da Ferramenta como Resultado
Source: https://docs.crewai.com/pt-BR/learn/force-tool-output-as-result

Aprenda como forçar a saída de uma ferramenta como resultado em uma tarefa de Agent no CrewAI.

## Introdução

No CrewAI, você pode forçar a saída de uma ferramenta como o resultado de uma tarefa de um agent.\
Esse recurso é útil quando você deseja garantir que a saída da ferramenta seja capturada e retornada como resultado da tarefa, evitando quaisquer modificações pelo agent durante a execução da tarefa.

## Forçando a Saída da Ferramenta como Resultado

Para forçar a saída da ferramenta como resultado da tarefa de um agent, você precisa definir o parâmetro `result_as_answer` como `True` ao adicionar uma ferramenta ao agent.\
Esse parâmetro garante que a saída da ferramenta seja capturada e retornada como resultado da tarefa, sem qualquer modificação pelo agent.

Veja um exemplo de como forçar a saída da ferramenta como resultado da tarefa de um agent:

```python Code
from crewai.agent import Agent
from my_tool import MyCustomTool

# Create a coding agent with the custom tool
coding_agent = Agent(
        role="Data Scientist",
        goal="Produce amazing reports on AI",
        backstory="You work with data and AI",
        tools=[MyCustomTool(result_as_answer=True)],
    )

# Assuming the tool's execution and result population occurs within the system
task_result = coding_agent.execute_task(task)
```

## Fluxo de Trabalho em Ação

<Steps>
  <Step title="Execução da Tarefa">
    O agent executa a tarefa utilizando a ferramenta fornecida.
  </Step>

  <Step title="Saída da Ferramenta">
    A ferramenta gera a saída, que é capturada como resultado da tarefa.
  </Step>

  <Step title="Interação do Agent">
    O agent pode refletir e aprender com a ferramenta, mas a saída não é modificada.
  </Step>

  <Step title="Retorno do Resultado">
    A saída da ferramenta é retornada como resultado da tarefa sem quaisquer modificações.
  </Step>
</Steps>


# Processo Hierárquico
Source: https://docs.crewai.com/pt-BR/learn/hierarchical-process

Um guia abrangente para compreender e aplicar o processo hierárquico em seus projetos CrewAI, atualizado para refletir as práticas de codificação e funcionalidades mais recentes.

## Introdução

O processo hierárquico no CrewAI introduz uma abordagem estruturada para a gestão de tarefas, simulando hierarquias organizacionais tradicionais para uma delegação e execução eficiente de tarefas.
Esse fluxo de trabalho sistemático melhora os resultados do projeto ao garantir que as tarefas sejam tratadas com máxima eficiência e precisão.

<Tip>
  O processo hierárquico foi projetado para alavancar modelos avançados como o GPT-4, otimizando o uso de tokens enquanto lida com tarefas complexas de forma mais eficiente.
</Tip>

## Visão Geral do Processo Hierárquico

Por padrão, as tarefas no CrewAI são gerenciadas por meio de um processo sequencial. No entanto, adotar uma abordagem hierárquica permite uma hierarquia clara na gestão de tarefas,
onde um agente 'gerente' coordena o fluxo de trabalho, delega tarefas e valida os resultados para uma execução eficaz e simplificada. Esse agente gerente pode agora ser
criado automaticamente pelo CrewAI ou explicitamente definido pelo usuário.

### Principais Características

* **Delegação de Tarefas**: Um agente gerente distribui tarefas entre os membros da crew com base em seus papéis e capacidades.
* **Validação de Resultados**: O gerente avalia os resultados para garantir que atendam aos padrões exigidos.
* **Fluxo de Trabalho Eficiente**: Emula estruturas corporativas, oferecendo uma abordagem organizada para a gestão de tarefas.
* **Manipulação de System Prompt**: Opcionalmente, especifique se o sistema deve usar prompts predefinidos.
* **Controle de Stop Words**: Opcionalmente, especifique se stop words devem ser usadas, oferecendo suporte a diversos modelos, incluindo os modelos o1.
* **Respeito à Context Window**: Priorização de contexto relevante ativando o respeito à context window, que agora é o comportamento padrão.
* **Controle de Delegação**: A delegação agora está desativada por padrão para dar controle explícito ao usuário.
* **Máximo de Requisições por Minuto**: Opção configurável para definir o número máximo de requisições por minuto.
* **Máximo de Iterações**: Limitação do número máximo de iterações até a obtenção de uma resposta final.

## Implementando o Processo Hierárquico

Para utilizar o processo hierárquico, é essencial definir explicitamente o atributo de processo como `Process.hierarchical`, já que o comportamento padrão é `Process.sequential`.
Defina uma crew com um gerente designado e estabeleça uma cadeia de comando clara.

<Tip>
  Atribua ferramentas no nível do agente para facilitar a delegação e execução de tarefas pelos agentes designados sob a orientação do gerente.
  Ferramentas também podem ser especificadas no nível da tarefa, para um controle preciso sobre a disponibilidade de ferramentas durante a execução das tarefas.
</Tip>

<Tip>
  Configurar o parâmetro `manager_llm` é fundamental para o processo hierárquico.
  O sistema exige a configuração de um LLM do gerente para funcionar corretamente, garantindo tomadas de decisão personalizadas.
</Tip>

```python Code
from crewai import Crew, Process, Agent

# Agents are defined with attributes for backstory, cache, and verbose mode
researcher = Agent(
    role='Researcher',
    goal='Conduct in-depth analysis',
    backstory='Experienced data analyst with a knack for uncovering hidden trends.',
)
writer = Agent(
    role='Writer',
    goal='Create engaging content',
    backstory='Creative writer passionate about storytelling in technical domains.',
)

# Establishing the crew with a hierarchical process and additional configurations
project_crew = Crew(
    tasks=[...],  # Tasks to be delegated and executed under the manager's supervision
    agents=[researcher, writer],
    manager_llm="gpt-4o",  # Specify which LLM the manager should use
    process=Process.hierarchical,
    planning=True,
)
```

### Usando um Agente Gerente Personalizado

Alternativamente, você pode criar um agente gerente personalizado com atributos específicos adaptados às necessidades de gestão do seu projeto. Isso oferece maior controle sobre o comportamento e as capacidades do gerente.

```python
# Define a custom manager agent
manager = Agent(
    role="Project Manager",
    goal="Efficiently manage the crew and ensure high-quality task completion",
    backstory="You're an experienced project manager, skilled in overseeing complex projects and guiding teams to success.",
    allow_delegation=True,
)

# Use the custom manager in your crew
project_crew = Crew(
    tasks=[...],
    agents=[researcher, writer],
    manager_agent=manager,  # Use your custom manager agent
    process=Process.hierarchical,
    planning=True,
)
```

<Tip>
  Para mais detalhes sobre a criação e personalização de um agente gerente, confira a [documentação do Custom Manager Agent](https://docs.crewai.com/how-to/custom-manager-agent#custom-manager-agent).
</Tip>

### Fluxo de Trabalho na Prática

1. **Atribuição de Tarefas**: O gerente atribui as tarefas estrategicamente, considerando as capacidades de cada agente e as ferramentas disponíveis.
2. **Execução e Revisão**: Os agentes concluem suas tarefas com a opção de execução assíncrona e funções de callback para fluxos de trabalho otimizados.
3. **Progresso Sequencial das Tarefas**: Apesar de ser um processo hierárquico, as tarefas seguem uma ordem lógica para um progresso fluido, facilitado pela supervisão do gerente.

## Conclusão

Adotar o processo hierárquico no CrewAI, com as configurações corretas e o entendimento das capacidades do sistema, facilita uma abordagem organizada e eficiente para o gerenciamento de projetos.
Aproveite os recursos avançados e as personalizações para ajustar o fluxo de trabalho conforme suas necessidades, garantindo a execução ideal das tarefas e o sucesso do projeto.


# Workflows Human-in-the-Loop (HITL)
Source: https://docs.crewai.com/pt-BR/learn/human-in-the-loop

Aprenda como implementar workflows Human-in-the-Loop na CrewAI para aprimorar a tomada de decisões

Human-in-the-Loop (HITL) é uma abordagem poderosa que combina a inteligência artificial com a experiência humana para aprimorar a tomada de decisões e melhorar os resultados das tarefas. Este guia mostra como implementar HITL dentro da CrewAI.

## Configurando Workflows HITL

<Steps>
  <Step title="Configure sua Tarefa">
    Configure sua tarefa com a entrada humana habilitada:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-human-input.png" alt="Entrada Humana Crew" />
    </Frame>
  </Step>

  <Step title="Forneça a URL do Webhook">
    Ao iniciar seu crew, inclua uma URL de webhook para entrada humana:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-webhook-url.png" alt="URL do Webhook Crew" />
    </Frame>
  </Step>

  <Step title="Receba Notificação do Webhook">
    Assim que o crew concluir a tarefa que requer entrada humana, você receberá uma notificação de webhook contendo:

    * Execution ID
    * Task ID
    * Task output
  </Step>

  <Step title="Revise o Resultado da Tarefa">
    O sistema irá pausar no estado `Pending Human Input`. Revise cuidadosamente o resultado da tarefa.
  </Step>

  <Step title="Envie o Feedback Humano">
    Chame o endpoint de retomada do seu crew com as seguintes informações:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-resume-endpoint.png" alt="Endpoint de Retomada Crew" />
    </Frame>

    <Warning>
      **Impacto do Feedback na Execução da Tarefa**:
      É fundamental ter cuidado ao fornecer feedback, pois todo o conteúdo do feedback será incorporado como contexto adicional para execuções futuras da tarefa.
    </Warning>

    Isso significa:

    * Todas as informações do seu feedback passam a fazer parte do contexto da tarefa.
    * Detalhes irrelevantes podem influenciar negativamente.
    * Feedback conciso e relevante ajuda a manter o foco e a eficiência da tarefa.
    * Sempre revise seu feedback cuidadosamente antes de enviar para garantir que contenha apenas informações pertinentes que irão guiar positivamente a execução da tarefa.
  </Step>

  <Step title="Lidar com Feedback Negativo">
    Se você fornecer um feedback negativo:

    * O crew irá tentar novamente a tarefa com o contexto adicionado do seu feedback.
    * Você receberá outra notificação de webhook para nova revisão.
    * Repita os passos 4-6 até ficar satisfeito.
  </Step>

  <Step title="Continuação da Execução">
    Quando você enviar um feedback positivo, a execução prosseguirá para as próximas etapas.
  </Step>
</Steps>

## Melhores Práticas

* **Seja Específico**: Forneça feedback claro e acionável que trate diretamente da tarefa em questão
* **Mantenha-se Relevante**: Inclua apenas informações que ajudem a melhorar a execução da tarefa
* **Seja Ágil**: Responda rapidamente às solicitações HITL para evitar atrasos no fluxo
* **Reveja Cuidadosamente**: Verifique seu feedback antes de enviar para garantir a precisão

## Casos de Uso Comuns

Workflows HITL são particularmente valiosos para:

* Garantia de qualidade e validação
* Cenários de tomada de decisão complexa
* Operações sensíveis ou de alto risco
* Tarefas criativas que requerem julgamento humano
* Revisões de conformidade e regulamentação


# Input Humano na Execução
Source: https://docs.crewai.com/pt-BR/learn/human-input-on-execution

Integrando o CrewAI com input humano durante a execução em processos complexos de tomada de decisão e aproveitando ao máximo todos os atributos e ferramentas do agente.

## Input humano na execução dos agentes

O input humano é fundamental em vários cenários de execução de agentes, permitindo que os agentes solicitem informações adicionais ou esclarecimentos quando necessário.
Esse recurso é especialmente útil em processos complexos de tomada de decisão ou quando os agentes precisam de mais detalhes para concluir uma tarefa de forma eficaz.

## Usando input humano com CrewAI

Para integrar input humano durante a execução do agente, defina o parâmetro `human_input` na definição da tarefa. Quando ativado, o agente solicitará informações ao usuário antes de fornecer sua resposta final.
Esse input pode oferecer contexto extra, esclarecer ambiguidades ou validar a saída produzida pelo agente.

### Exemplo:

```shell
pip install crewai
```

```python Code
import os
from crewai import Agent, Task, Crew
from crewai_tools import SerperDevTool

os.environ["SERPER_API_KEY"] = "Your Key"  # serper.dev API key
os.environ["OPENAI_API_KEY"] = "Your Key"

# Loading Tools
search_tool = SerperDevTool()

# Define your agents with roles, goals, tools, and additional attributes
researcher = Agent(
    role='Senior Research Analyst',
    goal='Uncover cutting-edge developments in AI and data science',
    backstory=(
        "You are a Senior Research Analyst at a leading tech think tank. "
        "Your expertise lies in identifying emerging trends and technologies in AI and data science. "
        "You have a knack for dissecting complex data and presenting actionable insights."
    ),
    verbose=True,
    allow_delegation=False,
    tools=[search_tool]
)
writer = Agent(
    role='Tech Content Strategist',
    goal='Craft compelling content on tech advancements',
    backstory=(
        "You are a renowned Tech Content Strategist, known for your insightful and engaging articles on technology and innovation. "
        "With a deep understanding of the tech industry, you transform complex concepts into compelling narratives."
    ),
    verbose=True,
    allow_delegation=True,
    tools=[search_tool],
    cache=False,  # Disable cache for this agent
)

# Create tasks for your agents
task1 = Task(
    description=(
        "Conduct a comprehensive analysis of the latest advancements in AI in 2025. "
        "Identify key trends, breakthrough technologies, and potential industry impacts. "
        "Compile your findings in a detailed report. "
        "Make sure to check with a human if the draft is good before finalizing your answer."
    ),
    expected_output='A comprehensive full report on the latest AI advancements in 2025, leave nothing out',
    agent=researcher,
    human_input=True
)

task2 = Task(
    description=(
        "Using the insights from the researcher\'s report, develop an engaging blog post that highlights the most significant AI advancements. "
        "Your post should be informative yet accessible, catering to a tech-savvy audience. "
        "Aim for a narrative that captures the essence of these breakthroughs and their implications for the future."
    ),
    expected_output='A compelling 3 paragraphs blog post formatted as markdown about the latest AI advancements in 2025',
    agent=writer,
    human_input=True
)

# Instantiate your crew with a sequential process
crew = Crew(
    agents=[researcher, writer],
    tasks=[task1, task2],
    verbose=True,
    memory=True,
    planning=True  # Enable planning feature for the crew
)

# Get your crew to work!
result = crew.kickoff()

print("######################")
print(result)
```


# Inicie uma Crew de Forma Assíncrona
Source: https://docs.crewai.com/pt-BR/learn/kickoff-async

Inicie uma Crew de Forma Assíncrona

## Introdução

A CrewAI oferece a capacidade de iniciar uma crew de forma assíncrona, permitindo que você comece a execução da crew de maneira não bloqueante.
Esse recurso é especialmente útil quando você deseja executar múltiplas crews simultaneamente ou quando precisa realizar outras tarefas enquanto a crew está em execução.

## Execução Assíncrona de Crew

Para iniciar uma crew de forma assíncrona, utilize o método `kickoff_async()`. Este método inicia a execução da crew em uma thread separada, permitindo que a thread principal continue executando outras tarefas.

### Assinatura do Método

```python Code
def kickoff_async(self, inputs: dict) -> CrewOutput:
```

### Parâmetros

* `inputs` (dict): Um dicionário contendo os dados de entrada necessários para as tarefas.

### Retorno

* `CrewOutput`: Um objeto que representa o resultado da execução da crew.

## Possíveis Casos de Uso

* **Geração Paralela de Conteúdo**: Inicie múltiplas crews independentes de forma assíncrona, cada uma responsável por gerar conteúdo sobre temas diferentes. Por exemplo, uma crew pode pesquisar e redigir um artigo sobre tendências em IA, enquanto outra gera posts para redes sociais sobre o lançamento de um novo produto. Cada crew atua de forma independente, permitindo a escala eficiente da produção de conteúdo.

* **Tarefas Conjuntas de Pesquisa de Mercado**: Lance múltiplas crews de forma assíncrona para realizar pesquisas de mercado em paralelo. Uma crew pode analisar tendências do setor, outra examinar estratégias de concorrentes e ainda outra avaliar o sentimento do consumidor. Cada crew conclui sua tarefa de forma independente, proporcionando insights mais rápidos e abrangentes.

* **Módulos Independentes de Planejamento de Viagem**: Execute crews separadas para planejar diferentes aspectos de uma viagem de forma independente. Uma crew pode cuidar das opções de voo, outra das acomodações e uma terceira do planejamento das atividades. Cada crew trabalha de maneira assíncrona, permitindo que os vários componentes da viagem sejam planejados ao mesmo tempo e de maneira independente, para resultados mais rápidos.

## Exemplo: Execução Assíncrona de uma Única Crew

Veja um exemplo de como iniciar uma crew de forma assíncrona utilizando asyncio e aguardando o resultado:

```python Code
import asyncio
from crewai import Crew, Agent, Task

# Create an agent with code execution enabled
coding_agent = Agent(
    role="Analista de Dados Python",
    goal="Analisar dados e fornecer insights usando Python",
    backstory="Você é um analista de dados experiente com fortes habilidades em Python.",
    allow_code_execution=True
)

# Create a task that requires code execution
data_analysis_task = Task(
    description="Analise o conjunto de dados fornecido e calcule a idade média dos participantes. Idades: {ages}",
    agent=coding_agent,
    expected_output="A idade média dos participantes."
)

# Create a crew and add the task
analysis_crew = Crew(
    agents=[coding_agent],
    tasks=[data_analysis_task]
)

# Async function to kickoff the crew asynchronously
async def async_crew_execution():
    result = await analysis_crew.kickoff_async(inputs={"ages": [25, 30, 35, 40, 45]})
    print("Crew Result:", result)

# Run the async function
asyncio.run(async_crew_execution())
```

## Exemplo: Execução Assíncrona de Múltiplas Crews

Neste exemplo, mostraremos como iniciar múltiplas crews de forma assíncrona e aguardar todas serem concluídas usando `asyncio.gather()`:

```python Code
import asyncio
from crewai import Crew, Agent, Task

# Create an agent with code execution enabled
coding_agent = Agent(
    role="Analista de Dados Python",
    goal="Analisar dados e fornecer insights usando Python",
    backstory="Você é um analista de dados experiente com fortes habilidades em Python.",
    allow_code_execution=True
)

# Create tasks that require code execution
task_1 = Task(
    description="Analise o primeiro conjunto de dados e calcule a idade média dos participantes. Idades: {ages}",
    agent=coding_agent,
    expected_output="A idade média dos participantes."
)

task_2 = Task(
    description="Analise o segundo conjunto de dados e calcule a idade média dos participantes. Idades: {ages}",
    agent=coding_agent,
    expected_output="A idade média dos participantes."
)

# Create two crews and add tasks
crew_1 = Crew(agents=[coding_agent], tasks=[task_1])
crew_2 = Crew(agents=[coding_agent], tasks=[task_2])

# Async function to kickoff multiple crews asynchronously and wait for all to finish
async def async_multiple_crews():
    # Create coroutines for concurrent execution
    result_1 = crew_1.kickoff_async(inputs={"ages": [25, 30, 35, 40, 45]})
    result_2 = crew_2.kickoff_async(inputs={"ages": [20, 22, 24, 28, 30]})

    # Wait for both crews to finish
    results = await asyncio.gather(result_1, result_2)

    for i, result in enumerate(results, 1):
        print(f"Crew {i} Result:", result)

# Run the async function
asyncio.run(async_multiple_crews())
```


# Kickoff Crew para Cada
Source: https://docs.crewai.com/pt-BR/learn/kickoff-for-each

Kickoff Crew para Cada Item em uma Lista

## Introdução

A CrewAI oferece a capacidade de iniciar um crew para cada item em uma lista, permitindo que você execute o crew para cada item da lista.
Esse recurso é particularmente útil quando é necessário realizar o mesmo conjunto de tarefas para vários itens.

## Iniciando um Crew para Cada Item

Para iniciar um crew para cada item em uma lista, utilize o método `kickoff_for_each()`.
Esse método executa o crew para cada item da lista, permitindo o processamento eficiente de múltiplos itens.

Veja um exemplo de como iniciar um crew para cada item em uma lista:

```python Code
from crewai import Crew, Agent, Task

# Create an agent with code execution enabled
coding_agent = Agent(
    role="Python Data Analyst",
    goal="Analyze data and provide insights using Python",
    backstory="You are an experienced data analyst with strong Python skills.",
    allow_code_execution=True
)

# Create a task that requires code execution
data_analysis_task = Task(
    description="Analyze the given dataset and calculate the average age of participants. Ages: {ages}",
    agent=coding_agent,
    expected_output="The average age calculated from the dataset"
)

# Create a crew and add the task
analysis_crew = Crew(
    agents=[coding_agent],
    tasks=[data_analysis_task],
    verbose=True,
    memory=False
)

datasets = [
  { "ages": [25, 30, 35, 40, 45] },
  { "ages": [20, 25, 30, 35, 40] },
  { "ages": [30, 35, 40, 45, 50] }
]

# Execute the crew
result = analysis_crew.kickoff_for_each(inputs=datasets)
```


# Conecte-se a qualquer LLM
Source: https://docs.crewai.com/pt-BR/learn/llm-connections

Guia abrangente sobre como integrar o CrewAI a diversos Large Language Models (LLMs) usando o LiteLLM, incluindo provedores compatíveis e opções de configuração.

## Conecte o CrewAI a LLMs

O CrewAI utiliza o LiteLLM para conectar-se a uma grande variedade de Modelos de Linguagem (LLMs). Essa integração proporciona grande versatilidade, permitindo que você utilize modelos de inúmeros provedores por meio de uma interface simples e unificada.

<Note>
  Por padrão, o CrewAI usa o modelo `gpt-4o-mini`. Isso é determinado pela variável de ambiente `OPENAI_MODEL_NAME`, que tem como padrão "gpt-4o-mini" se não for definida.
  Você pode facilmente configurar seus agentes para usar um modelo ou provedor diferente, conforme descrito neste guia.
</Note>

## Provedores Compatíveis

O LiteLLM oferece suporte a uma ampla gama de provedores, incluindo, mas não se limitando a:

* OpenAI
* Anthropic
* Google (Vertex AI, Gemini)
* Azure OpenAI
* AWS (Bedrock, SageMaker)
* Cohere
* VoyageAI
* Hugging Face
* Ollama
* Mistral AI
* Replicate
* Together AI
* AI21
* Cloudflare Workers AI
* DeepInfra
* Groq
* SambaNova
* [NVIDIA NIMs](https://docs.api.nvidia.com/nim/reference/models-1)
* E muitos outros!

Para uma lista completa e sempre atualizada dos provedores suportados, consulte a [documentação de Provedores do LiteLLM](https://docs.litellm.ai/docs/providers).

## Alterando a LLM

Para utilizar uma LLM diferente com seus agentes CrewAI, você tem várias opções:

<Tabs>
  <Tab title="Usando um Identificador de String">
    Passe o nome do modelo como uma string ao inicializar o agente:

    <CodeGroup>
      ```python Code
      from crewai import Agent

      # Usando o GPT-4 da OpenAI
      openai_agent = Agent(
          role='OpenAI Expert',
          goal='Provide insights using GPT-4',
          backstory="An AI assistant powered by OpenAI's latest model.",
          llm='gpt-4'
      )

      # Usando o Claude da Anthropic
      claude_agent = Agent(
          role='Anthropic Expert',
          goal='Analyze data using Claude',
          backstory="An AI assistant leveraging Anthropic's language model.",
          llm='claude-2'
      )
      ```
    </CodeGroup>
  </Tab>

  <Tab title="Usando a Classe LLM">
    Para uma configuração mais detalhada, utilize a classe LLM:

    <CodeGroup>
      ```python Code
      from crewai import Agent, LLM

      llm = LLM(
          model="gpt-4",
          temperature=0.7,
          base_url="https://api.openai.com/v1",
          api_key="your-api-key-here"
      )

      agent = Agent(
          role='Customized LLM Expert',
          goal='Provide tailored responses',
          backstory="An AI assistant with custom LLM settings.",
          llm=llm
      )
      ```
    </CodeGroup>
  </Tab>
</Tabs>

## Opções de Configuração

Ao configurar uma LLM para o seu agente, você tem acesso a uma variedade de parâmetros:

| Parâmetro              |        Tipo        | Descrição                                                                  |
| :--------------------- | :----------------: | :------------------------------------------------------------------------- |
| **model**              |        `str`       | O nome do modelo a ser utilizado (ex.: "gpt-4", "claude-2")                |
| **temperature**        |       `float`      | Controla o grau de aleatoriedade nas respostas (0.0 a 1.0)                 |
| **max\_tokens**        |        `int`       | Número máximo de tokens a serem gerados                                    |
| **top\_p**             |       `float`      | Controla a diversidade das respostas (0.0 a 1.0)                           |
| **frequency\_penalty** |       `float`      | Penaliza novos tokens com base na frequência em que já apareceram no texto |
| **presence\_penalty**  |       `float`      | Penaliza novos tokens com base na presença deles no texto até o momento    |
| **stop**               | `str`, `List[str]` | Sequência(s) que interrompem a geração do texto                            |
| **base\_url**          |        `str`       | URL base do endpoint da API                                                |
| **api\_key**           |        `str`       | Sua chave de API para autenticação                                         |

Para uma lista completa de parâmetros e suas respectivas descrições, consulte a documentação da classe LLM.

## Conectando-se a LLMs Compatíveis com OpenAI

Você pode se conectar a LLMs compatíveis com a OpenAI usando variáveis de ambiente ou definindo atributos específicos na classe LLM:

<Tabs>
  <Tab title="Usando Variáveis de Ambiente">
    <CodeGroup>
      ```python Generic
      import os

      os.environ["OPENAI_API_KEY"] = "your-api-key"
      os.environ["OPENAI_API_BASE"] = "https://api.your-provider.com/v1"
      os.environ["OPENAI_MODEL_NAME"] = "your-model-name"
      ```

      ```python Google
      import os

      # Exemplo usando a API compatível com OpenAI do Gemini.
      os.environ["OPENAI_API_KEY"] = "your-gemini-key"  # Deve começar com AIza...
      os.environ["OPENAI_API_BASE"] = "https://generativelanguage.googleapis.com/v1beta/openai/"
      os.environ["OPENAI_MODEL_NAME"] = "openai/gemini-2.0-flash"  # Adicione aqui seu modelo do Gemini, sob openai/
      ```
    </CodeGroup>
  </Tab>

  <Tab title="Usando Atributos da Classe LLM">
    <CodeGroup>
      ```python Generic
      llm = LLM(
          model="custom-model-name",
          api_key="your-api-key",
          base_url="https://api.your-provider.com/v1"
      )
      agent = Agent(llm=llm, ...)
      ```

      ```python Google
      # Exemplo usando a API compatível com OpenAI do Gemini
      llm = LLM(
          model="openai/gemini-2.0-flash",
          base_url="https://generativelanguage.googleapis.com/v1beta/openai/",
          api_key="your-gemini-key",  # Deve começar com AIza...
      )
      agent = Agent(llm=llm, ...)
      ```
    </CodeGroup>
  </Tab>
</Tabs>

## Utilizando Modelos Locais com Ollama

Para modelos locais como os oferecidos pelo Ollama:

<Steps>
  <Step title="Baixe e instale o Ollama">
    [Clique aqui para baixar e instalar o Ollama](https://ollama.com/download)
  </Step>

  <Step title="Puxe o modelo desejado">
    Por exemplo, execute `ollama pull llama3.2` para baixar o modelo.
  </Step>

  <Step title="Configure seu agente">
    <CodeGroup>
      ```python Code
          agent = Agent(
              role='Local AI Expert',
              goal='Process information using a local model',
              backstory="An AI assistant running on local hardware.",
              llm=LLM(model="ollama/llama3.2", base_url="http://localhost:11434")
          )
      ```
    </CodeGroup>
  </Step>
</Steps>

## Alterando a URL Base da API

Você pode alterar a URL base da API para qualquer provedor de LLM definindo o parâmetro `base_url`:

```python Code
llm = LLM(
    model="custom-model-name",
    base_url="https://api.your-provider.com/v1",
    api_key="your-api-key"
)
agent = Agent(llm=llm, ...)
```

Isso é particularmente útil ao trabalhar com APIs compatíveis com a OpenAI ou quando você precisa especificar um endpoint diferente para o provedor escolhido.

## Conclusão

Ao utilizar o LiteLLM, o CrewAI oferece integração transparente com uma vasta gama de LLMs. Essa flexibilidade permite que você escolha o modelo mais adequado para sua necessidade específica, seja priorizando desempenho, custo-benefício ou implantação local. Lembre-se de consultar a [documentação do LiteLLM](https://docs.litellm.ai/docs/) para obter as informações mais atualizadas sobre modelos suportados e opções de configuração.


# Guia Estratégico de Seleção de LLMs
Source: https://docs.crewai.com/pt-BR/learn/llm-selection-guide

Framework estratégico para escolher o LLM certo para seus agentes CrewAI e escrever definições eficazes de tarefas e agentes

## A Abordagem CrewAI para Seleção de LLMs

Em vez de recomendações prescritivas de modelos, defendemos um **framework de pensamento** que ajude você a tomar decisões informadas com base no seu caso de uso, restrições e requisitos específicos. O cenário de LLMs evolui rapidamente, com novos modelos surgindo regularmente e os existentes sendo atualizados frequentemente. O que mais importa é desenvolver uma abordagem sistemática de avaliação que permaneça relevante independentemente dos modelos disponíveis no momento.

<Note>
  Este guia foca em pensamento estratégico em vez de recomendações de modelos específicos, já que o cenário dos LLMs evolui rapidamente.
</Note>

## Framework de Decisão Rápida

<Steps>
  <Step title="Analise Suas Tarefas">
    Comece entendendo profundamente o que suas tarefas realmente exigem. Considere a complexidade cognitiva envolvida, a profundidade de raciocínio necessária, o formato dos resultados esperados e a quantidade de contexto que o modelo precisará processar. Essa análise fundamental guiará todas as decisões seguintes.
  </Step>

  <Step title="Mapeie as Capacidades dos Modelos">
    Assim que você compreende seus requisitos, mapeie-os para as forças dos modelos. Diferentes famílias de modelos se destacam em diferentes tipos de trabalho; alguns são otimizados para raciocínio e análise, outros para criatividade e geração de conteúdo, e outros para velocidade e eficiência.
  </Step>

  <Step title="Considere Restrições">
    Leve em conta suas reais restrições operacionais, incluindo limitações orçamentárias, requisitos de latência, necessidades de privacidade de dados e capacidades de infraestrutura. O melhor modelo teoricamente pode não ser a melhor escolha prática para sua situação.
  </Step>

  <Step title="Teste e Itere">
    Comece com modelos confiáveis e bem conhecidos e otimize com base no desempenho real no seu caso de uso. Os resultados práticos frequentemente diferem dos benchmarks teóricos, então testes empíricos são cruciais.
  </Step>
</Steps>

## Framework Central de Seleção

### a. Pensamento Orientado à Tarefa

O passo mais crítico na seleção de LLMs é entender o que sua tarefa realmente exige. Frequentemente, equipes escolhem modelos com base em reputação geral ou pontuações de benchmark, sem analisar cuidadosamente suas necessidades específicas. Essa abordagem leva tanto ao superdimensionamento de tarefas simples usando modelos caros e complexos quanto à subutilização em tarefas sofisticadas com modelos sem as capacidades necessárias.

<Tabs>
  <Tab title="Complexidade de Raciocínio">
    * **Tarefas Simples** representam a maioria do trabalho diário de IA e incluem seguir instruções básicas, processar dados simples e formatação elementar. Estas tarefas geralmente têm entradas e saídas claras, com mínima ambiguidade. A carga cognitiva é baixa e o modelo precisa apenas seguir instruções explícitas, não realizar raciocínio complexo.

    * **Tarefas Complexas** exigem raciocínio de múltiplas etapas, pensamento estratégico e a capacidade de lidar com informações ambíguas ou incompletas. Podem envolver análise de múltiplas fontes de dados, desenvolvimento de estratégias abrangentes ou resolução de problemas que precisam ser decompostos em componentes menores. O modelo deve manter o contexto ao longo de várias etapas de raciocínio e frequentemente precisa inferir informações não explicitamente declaradas.

    * **Tarefas Criativas** exigem um tipo diferente de capacidade cognitiva, focada em gerar conteúdo novo, envolvente e adequado ao contexto. Isso inclui storytelling, criação de textos de marketing e solução criativa de problemas. O modelo deve compreender nuances, tom e público, produzindo conteúdo autêntico e envolvente, não apenas fórmulas.
  </Tab>

  <Tab title="Requisitos de Saída">
    * **Dados Estruturados** exigem precisão e consistência na adesão ao formato. Ao trabalhar com JSON, XML ou formatos de banco de dados, o modelo deve produzir saídas sintaticamente corretas, que possam ser processadas programaticamente. Essas tarefas possuem requisitos rígidos de validação e pouca tolerância a erros de formato, tornando a confiabilidade mais importante que a criatividade.

    * **Conteúdo Criativo** requer equilíbrio entre competência técnica e criatividade. O modelo precisa compreender o público, tom e voz da marca, ao mesmo tempo em que produz conteúdo que engaja leitores e atinge objetivos comunicativos específicos. A qualidade aqui é mais subjetiva e exige modelos capazes de adaptar o estilo de escrita a diferentes contextos e propósitos.

    * **Conteúdo Técnico** situa-se entre dados estruturados e conteúdo criativo, demandando precisão e clareza. Documentação, geração de código e análises técnicas precisam ser exatas e completas, mas ainda assim acessíveis ao público-alvo. O modelo deve entender conceitos técnicos complexos e comunicá-los de forma eficaz.
  </Tab>

  <Tab title="Necessidades de Contexto">
    * **Contexto Curto** envolve tarefas imediatas e focalizadas, onde o modelo processa informações limitadas rapidamente. São interações transacionais em que velocidade e eficiência importam mais do que compreensão profunda. O modelo não precisa manter histórico extenso ou processar grandes documentos.

    * **Contexto Longo** é necessário ao lidar com documentos substanciais, conversas extensas ou tarefas complexas de múltiplas partes. O modelo precisa manter coerência ao longo de milhares de tokens, referenciando informações anteriores com precisão. Essencial para análise de documentos, pesquisa abrangente e sistemas de diálogo sofisticados.

    * **Contexto Muito Longo** ultrapassa os limites do possível hoje, com processamento de documentos massivos, síntese de pesquisas extensas ou interações multi-sessão. São casos que exigem modelos projetados especificamente para lidar com contexto estendido e envolvem trade-offs entre extensão e velocidade.
  </Tab>
</Tabs>

### b. Mapeamento de Capacidades do Modelo

Entender as capacidades dos modelos exige ir além do marketing e dos benchmarks, analisando forças e limitações fundamentais das arquiteturas e métodos de treinamento.

<AccordionGroup>
  <Accordion title="Modelos de Raciocínio" icon="brain">
    Modelos de raciocínio formam uma categoria especializada, projetada para tarefas de pensamento complexo e de múltiplas etapas. Eles se destacam na resolução de problemas que requerem análise cuidadosa, planejamento estratégico ou decomposição sistemática. Normalmente aplicam técnicas como chain-of-thought ou tree-of-thought para conduzir o raciocínio passo a passo.

    O ponto forte é manter consistência lógica em cadeias longas de raciocínio e decompor problemas complexos em partes gerenciáveis. São especialmente valiosos para planejamento estratégico, análise complexa e situações onde a qualidade do raciocínio importa mais que a velocidade.

    Entretanto, há trade-offs em termos de custo e velocidade. Podem ser menos adequados para tarefas criativas ou operações simples, onde suas capacidades avançadas não são necessárias. Considere-os quando as tarefas realmente se beneficiarem dessa análise detalhada.
  </Accordion>

  <Accordion title="Modelos de Uso Geral" icon="microchip">
    Modelos de uso geral oferecem uma abordagem equilibrada, com desempenho sólido em uma ampla gama de tarefas, sem especialização extrema. São treinados em conjuntos de dados diversificados e otimizados para versatilidade.

    A principal vantagem é a confiabilidade previsível em diversos trabalhos: pesquisa, análise, criação de conteúdo, processamento de dados. São ótimas opções iniciais para equipes que buscam consistência ao lidar com fluxos variados.

    Embora não atinjam picos de desempenho como modelos especializados, oferecem simplicidade operacional e baixa complexidade na gestão. São o melhor ponto de partida para novos projetos, permitindo descobertas de necessidades antes de avançar para otimizações.
  </Accordion>

  <Accordion title="Modelos Rápidos & Eficientes" icon="bolt">
    Modelos rápidos e eficientes priorizam velocidade, custo e eficiência de recursos, em vez de raciocínio sofisticado. São otimizados para cenários de alto volume onde respostas rápidas e baixos custos são mais importantes que compreensão ou criatividade profunda.

    Brilham em operações rotineiras, processamento simples de dados, chamadas de funções e tarefas de alto volume. Aplicações que processam muitos pedidos rapidamente ou operam sob restrições orçamentárias se beneficiam desses modelos.

    O ponto crucial é garantir que suas capacidades atendam às exigências da tarefa. Podem não atender tarefas que exijam entendimento profundo, raciocínio complexo ou geração de conteúdo sofisticado. São ideais para tarefas rotineiras bem definidas.
  </Accordion>

  <Accordion title="Modelos Criativos" icon="pen">
    Modelos criativos são otimizados para geração de conteúdo, qualidade de escrita e pensamento inovador. Excelentes na compreensão de nuances, tom e estilo, produzindo conteúdo envolvente e natural.

    O ponto forte está em adaptar o estilo para diferentes públicos, manter voz e tom consistentes e engajar leitores. Performam melhor em storytelling, textos publicitários, comunicações de marca e outras tarefas com criatividade como foco.

    Ao selecionar esses modelos, considere não apenas a habilidade de gerar texto, mas a compreensão de público, contexto e objetivo. Os melhores modelos criativos adaptam a saída à voz da marca, diferentes segmentos e mantêm consistência em peças longas.
  </Accordion>

  <Accordion title="Modelos Open Source" icon="code">
    Modelos open source oferecem vantagens em controle de custos, potencial de customização, privacidade de dados e flexibilidade de deployment. Podem ser rodados localmente ou em infraestrutura própria, dando controle total sobre dados e comportamento.

    Os principais benefícios incluem eliminação de custos por token, possibilidade de fine-tuning, privacidade total e independência de fornecedores externos. Perfeitos para organizações com necessidade de privacidade, orçamento limitado ou desejo de customização.

    Contudo, requerem maior expertise técnica para implantar e manter. Considere custos de infraestrutura, complexidade de gestão e esforços contínuos de atualização e otimização ao avaliar modelos open source. O custo total pode ser maior que o de alternativas em nuvem devido a esse overhead.
  </Accordion>
</AccordionGroup>

## Padrões Estratégicos de Configuração

### a. Abordagem Multi-Modelo

<Tip>
  Use diferentes modelos para diferentes propósitos dentro da mesma crew para otimizar desempenho e custos.
</Tip>

As implementações CrewAI mais sofisticadas empregam múltiplos modelos estrategicamente, designando-os conforme as funções e necessidades dos agentes. Assim, é possível otimizar desempenho e custos usando o modelo mais adequado para cada tipo de tarefa.

Agentes de planejamento se beneficiam de modelos de raciocínio para pensamento estratégico e análise multi-etapas. Esses agentes funcionam como o "cérebro" da operação. Agentes de conteúdo têm melhor desempenho com modelos criativos focados em qualidade de escrita e engajamento. Agentes de processamento, responsáveis por operações rotineiras, podem usar modelos eficientes priorizando velocidade.

**Exemplo: Crew de Pesquisa e Análise**

```python
from crewai import Agent, Task, Crew, LLM

# Modelo de raciocínio para planejamento estratégico
manager_llm = LLM(model="gemini-2.5-flash-preview-05-20", temperature=0.1)

# Modelo criativo para gerar conteúdo
content_llm = LLM(model="claude-3-5-sonnet-20241022", temperature=0.7)

# Modelo eficiente para processamento de dados
processing_llm = LLM(model="gpt-4o-mini", temperature=0)

research_manager = Agent(
    role="Research Strategy Manager",
    goal="Develop comprehensive research strategies and coordinate team efforts",
    backstory="Expert research strategist with deep analytical capabilities",
    llm=manager_llm,  # Modelo de alto nível para raciocínio complexo
    verbose=True
)

content_writer = Agent(
    role="Research Content Writer",
    goal="Transform research findings into compelling, well-structured reports",
    backstory="Skilled writer who excels at making complex topics accessible",
    llm=content_llm,  # Modelo criativo para conteúdo envolvente
    verbose=True
)

data_processor = Agent(
    role="Data Analysis Specialist",
    goal="Extract and organize key data points from research sources",
    backstory="Detail-oriented analyst focused on accuracy and efficiency",
    llm=processing_llm,  # Modelo rápido para tarefas rotineiras
    verbose=True
)

crew = Crew(
    agents=[research_manager, content_writer, data_processor],
    tasks=[...],  # Suas tarefas específicas
    manager_llm=manager_llm,  # Manager usa o modelo de raciocínio
    verbose=True
)
```

O segredo do sucesso na implementação multi-modelo está em entender como os agentes interagem e garantir que as capacidades dos modelos estejam alinhadas às responsabilidades. Isso exige planejamento estratégico, mas traz ganhos significativos em qualidade dos resultados e eficiência operacional.

### b. Seleção Específica por Componente

<Tabs>
  <Tab title="Manager LLM">
    O manager LLM desempenha papel central em fluxos hierárquicos CrewAI, coordenando agentes e tarefas. Este modelo precisa se destacar em delegação, priorização de tarefas e manutenção de contexto em várias operações simultâneas.

    LLMs de manager eficazes exigem forte raciocínio para delegar bem, desempenho consistente para coordenar previsivelmente e excelente gestão de contexto para acompanhar o estado dos agentes. O modelo deve entender capacidades e limitações dos agentes enquanto otimiza a alocação de tarefas.

    O custo é especialmente relevante, já que este LLM participa de todas as operações. O modelo precisa entregar capacidades suficientes, sem o preço premium de opções sofisticadas demais, buscando sempre o equilíbrio entre performance e valor.
  </Tab>

  <Tab title="Function Calling LLM">
    LLMs de function calling gerenciam o uso de ferramentas por todos os agentes, sendo críticos em crews que dependem fortemente de APIs externas e ferramentas. Devem ser precisos na extração de parâmetros e no processamento das respostas.

    As características mais importantes são precisão e confiabilidade, não criatividade ou raciocínio avançado. O modelo deve extrair parâmetros corretos de comandos em linguagem natural consistentemente e processar respostas de ferramentas adequadamente. Velocidade também importa, pois o uso de ferramentas pode envolver múltiplas idas e vindas de informação.

    Muitas equipes descobrem que modelos especializados em function calling ou de uso geral com forte suporte a ferramentas funcionam melhor do que modelos criativos ou de raciocínio nesse papel. O fundamental é assegurar que o modelo consiga converter instruções em chamadas estruturadas sem falhas.
  </Tab>

  <Tab title="Sobrescritas Específicas de Agente">
    Agentes individuais podem sobrescrever o LLM do nível da crew quando suas necessidades diferem significativamente das do restante. Isso permite otimização pontual, mantendo a simplicidade operacional para os demais agentes.

    Considere sobrescritas quando a função do agente exige capacidades distintas. Por exemplo, um agente de redação criativa pode se beneficiar de um LLM otimizado para geração de conteúdo, enquanto um analista de dados pode preferir um modelo voltado ao raciocínio.

    O desafio é balancear otimização com complexidade operacional. Cada modelo adicional aumenta a complexidade de deployment, monitoramento e custos. Foque em sobrescritas apenas quando a melhoria justificar essa complexidade.
  </Tab>
</Tabs>

## Framework de Definição de Tarefas

### a. Foque em Clareza, Não em Complexidade

Definir bem as tarefas é frequentemente mais importante do que a seleção do modelo no resultado gerado pelos agentes CrewAI. Tarefas bem formuladas orientam claramente mesmo modelos simples a terem bom desempenho. Já tarefas mal definidas prejudicam até os modelos mais avançados.

<AccordionGroup>
  <Accordion title="Descrições de Tarefas Eficazes" icon="list-check">
    As melhores descrições de tarefas equilibram detalhamento e clareza. Devem definir o objetivo de forma clara e sem ambiguidade, além de explicar o método a ser usado com detalhes que permitam ao agente agir corretamente.

    Descrições eficazes incluem contexto relevante e restrições, ajudando o agente a entender o propósito maior e quaisquer limitações. Divida trabalhos complexos em etapas gerenciáveis em vez de objetivos genéricos e sobrecarregados.

    Erros comuns incluem objetivos vagos, falta de contexto, critérios de sucesso mal definidos ou mistura de tarefas totalmente distintas em um mesmo texto. O objetivo é passar informação suficiente para o sucesso, mas mantendo foco no resultado claro.
  </Accordion>

  <Accordion title="Diretrizes para a Saída Esperada" icon="bullseye">
    As diretrizes da saída esperada funcionam como contrato entre definição de tarefa e agente, especificando claramente o que deve ser entregue e como será avaliado. Elas abrangem formato, estrutura e elementos essenciais.

    As melhores diretrizes incluem exemplos concretos de indicadores de qualidade e critérios claros de conclusão, de modo que agente e revisores humanos possam avaliar o resultado facilmente. Isso reduz ambiguidades e garante resultados consistentes.

    Evite descrições genéricas que serviriam para qualquer tarefa, ausência de especificações de formato, padrões vagos ou falta de exemplos/modelos que ajudem o agente a entender as expectativas.
  </Accordion>
</AccordionGroup>

### b. Estratégia de Sequenciamento de Tarefas

<Tabs>
  <Tab title="Dependências Sequenciais">
    Dependências são essenciais quando as tarefas se baseiam em resultados prévios, informações fluem de uma tarefa para outra, ou a qualidade depende da conclusão de fases anteriores. Assim, cada tarefa recebe o contexto correto para o sucesso.

    Para implementar bem, use o parâmetro de contexto para encadear tarefas, desenvolvendo gradualmente a complexidade. Cada tarefa deve gerar saídas que alimentam as próximas. O objetivo é manter um fluxo lógico entre as tarefas dependentes, evitando gargalos desnecessários.

    Funciona melhor quando há progressão lógica evidente e quando a saída de uma tarefa realmente agrega valor nas etapas seguintes. Cuidado com os gargalos; foque nas dependências essenciais.
  </Tab>

  <Tab title="Execução Paralela">
    A execução paralela é valiosa quando as tarefas são independentes, o tempo é crítico ou há expertise distintas que não exigem coordenação. Pode reduzir drasticamente o tempo total, permitindo que agentes especializados atuem simultaneamente.

    Para isso, identifique tarefas realmente independentes, agrupe fluxos de trabalho distintos e planeje a integração dos resultados posteriormente. O ponto-chave é garantir que tarefas paralelas não gerem conflitos ou redundâncias.

    Considere o paralelo em múltiplos fluxos independentes, diferentes tipos de análise autônoma, ou criação de conteúdo que pode ser feita ao mesmo tempo. Mas atente-se à alocação de recursos, evitando sobrecarga de modelos ou estouro no orçamento.
  </Tab>
</Tabs>

## Otimizando a Configuração dos Agentes para Desempenho de LLMs

### a. Seleção de LLM Guiada pelo Papel

<Warning>
  Funções genéricas de agentes tornam impossível escolher o LLM certo. Funções específicas permitem otimização do modelo conforme a função.
</Warning>

A especificidade das funções dos agentes determina quais capacidades de LLM mais importam para alto desempenho, criando oportunidade estratégica de alinhar forças do modelo ao papel do agente.

**Impacto de Funções Genéricas vs. Específicas:**

Ao definir funções, pense no conhecimento do domínio, estilo de trabalho e frameworks decisórios mais valiosos para o tipo de tarefa do agente. Quanto mais específica e contextualizada a função, melhor o modelo incorporará esse papel.

```python
# ✅ Função específica - requisitos claros de LLM
specific_agent = Agent(
    role="SaaS Revenue Operations Analyst",  # Expertise de domínio clara
    goal="Analyze recurring revenue metrics and identify growth opportunities",
    backstory="Specialist in SaaS business models with deep understanding of ARR, churn, and expansion revenue",
    llm=LLM(model="gpt-4o")  # Raciocínio justificado para análise complexa
)
```

**Estratégia de Mapeamento de Função para Modelo:**

* **"Research Analyst"** → Modelo de raciocínio (GPT-4o, Claude Sonnet) para análise complexa
* **"Content Editor"** → Modelo criativo (Claude, GPT-4o) para qualidade de escrita
* **"Data Processor"** → Modelo eficiente (GPT-4o-mini, Gemini Flash) para tarefas estruturadas
* **"API Coordinator"** → Modelo otimizado para function calling (GPT-4o, Claude) para uso de ferramentas

### b. Backstory como Amplificador de Contexto do Modelo

<Info>
  Backstories estratégicos maximizam a eficácia do LLM ao contextualizar as respostas de forma que prompts genéricos não conseguem.
</Info>

Um bom backstory transforma a escolha do LLM de genérica a especializada. Isso é crucial para otimizar custos: um modelo eficiente com contexto certo pode superar um premium sem contexto.

**Exemplo de Performance Guiada por Contexto:**

```python
# Contexto amplifica a efetividade do modelo
domain_expert = Agent(
    role="B2B SaaS Marketing Strategist",
    goal="Develop comprehensive go-to-market strategies for enterprise software",
    backstory="""
    You have 10+ years of experience scaling B2B SaaS companies from Series A to IPO.
    You understand the nuances of enterprise sales cycles, the importance of product-market
    fit in different verticals, and how to balance growth metrics with unit economics.
    You've worked with companies like Salesforce, HubSpot, and emerging unicorns, giving
    you perspective on both established and disruptive go-to-market strategies.
    """,
    llm=LLM(model="claude-3-5-sonnet", temperature=0.3)  # Criatividade balanceada com conhecimento de domínio
)

# Esse contexto faz o Claude agir como especialista do setor
# Sem isso, mesmo ele entregaria respostas genéricas
```

**Elementos de Backstory que Potencializam a Performance de LLMs:**

* **Experiência de Domínio**: "10+ anos em vendas enterprise SaaS"
* **Expertise Específica**: "Especialista em due diligence técnica para Série B+"
* **Estilo de Trabalho**: "Decisões orientadas a dados, documentação clara"
* **Padrões de Qualidade**: "Sempre cita fontes e mostra análise detalhada"

### c. Otimização Holística de Agente + LLM

As configurações mais eficazes criam sinergia entre função específica, profundidade do backstory e escolha do LLM. Cada elemento reforça o outro para maximizar rendimento.

**Framework de Otimização:**

```python
# Exemplo: Agente de Documentação Técnica
tech_writer = Agent(
    role="API Documentation Specialist",
    goal="Create comprehensive, developer-friendly API documentation",
    backstory="""
    You're a technical writer with 8+ years documenting REST APIs, GraphQL endpoints,
    and SDK integration guides. You've worked with developer tools companies and
    understand what developers need: clear examples, comprehensive error handling,
    and practical use cases. You prioritize accuracy and usability over marketing fluff.
    """,
    llm=LLM(
        model="claude-3-5-sonnet",
        temperature=0.1
    ),
    tools=[code_analyzer_tool, api_scanner_tool],
    verbose=True
)
```

**Checklist de Alinhamento:**

* ✅ **Função Específica**: Domínio e responsabilidades claras
* ✅ **Correspondência do LLM**: Forças do modelo conectadas à função
* ✅ **Profundidade do Backstory**: Contexto de domínio disponível pro modelo
* ✅ **Integração de Ferramentas**: Ferramentas fortalecem a função do agente
* ✅ **Ajuste de Parâmetros**: Temperatura e configs otimizadas para a função

O segredo é criar agentes onde cada configuração reforça sua estratégia de escolha do LLM, maximizando rendimento e otimizando custos.

## Checklist Prático de Implementação

Em vez de repetir o framework estratégico, segue um checklist tático para implementar as decisões de seleção de LLM em CrewAI:

<Steps>
  <Step title="Audite Sua Configuração Atual" icon="clipboard-check">
    **O que analisar:**

    * Todos os agentes usam o mesmo LLM por padrão?
    * Quais agentes lidam com tarefas mais complexas?
    * Quais agentes só processam ou formatam dados?
    * Algum agente depende fortemente de ferramentas?

    **Ação**: Documente funções dos agentes e identifique oportunidades de otimização.
  </Step>

  <Step title="Implemente Estratégia no Nível da Crew" icon="users-gear">
    **Defina sua Base:**

    ```python
    # Comece com um padrão confiável para a crew
    default_crew_llm = LLM(model="gpt-4o-mini")  # Base econômica

    crew = Crew(
        agents=[...],
        tasks=[...],
        memory=True
    )
    ```

    **Ação**: Defina o LLM padrão da crew antes de otimizar agentes individuais.
  </Step>

  <Step title="Otimize Agentes de Maior Impacto" icon="star">
    **Identifique e Aprimore Agentes-Chave:**

    ```python
    # Agentes gerenciadores ou de coordenação
    manager_agent = Agent(
        role="Project Manager",
        llm=LLM(model="gemini-2.5-flash-preview-05-20"),
        # ... demais configs
    )

    # Agentes criativos ou customer-facing
    content_agent = Agent(
        role="Content Creator",
        llm=LLM(model="claude-3-5-sonnet"),
        # ... demais configs
    )
    ```

    **Ação**: Faça upgrade dos 20% dos agentes que tratam 80% da complexidade.
  </Step>

  <Step title="Valide com Testes Empresariais" icon="test-tube">
    **Após colocar os agentes em produção:**

    * Use [CrewAI Enterprise platform](https://app.crewai.com) para testar seleções de modelo A/B
    * Execute múltiplas iterações com inputs reais para medir consistência e performance
    * Compare custo vs performance na configuração otimizada
    * Compartilhe resultados com o time para tomada coletiva de decisão

    **Ação**: Substitua achismos por validação com dados reais usando a plataforma de testes.
  </Step>
</Steps>

### Quando Usar Tipos Diferentes de Modelos

<Tabs>
  <Tab title="Modelos de Raciocínio">
    Modelos de raciocínio tornam-se essenciais quando tarefas exigem pensamento lógico genuíno em múltiplas etapas, planejamento estratégico ou decisões complexas beneficiadas por análise sistemática. Brilham na decomposição de problemas e análise estruturada, não no simples seguimento de padrões.

    Considere-os para desenvolvimento de estratégias de negócios, análise de dados combinados de múltiplas fontes, resolução de problemas dependente de etapas sucessivas e planejamento estratégico envolvendo múltiplas variáveis.

    Entretanto, esses modelos são mais caros e lentos, devendo ser reservados para tarefas onde suas capacidades agregam valor real — evite usá-los apenas para operações simples.
  </Tab>

  <Tab title="Modelos Criativos">
    Modelos criativos são valiosos quando a principal entrega é geração de conteúdo e a qualidade, estilo e engajamento desse conteúdo impactam o sucesso. Se destacam quando redação e estilo importam, ideação criativa é necessária, ou voz de marca é fundamental.

    Use-os em redação de posts, criação de artigos, textos de marketing com viés persuasivo, storytelling e comunicações da marca. Costumam captar nuances e contexto melhor do que generalistas.

    Podem ser menos adequados para tarefas técnicas ou analíticas, onde precisão supera criatividade. Use-os quando aspectos comunicativos são fatores críticos de sucesso.
  </Tab>

  <Tab title="Modelos Eficientes">
    Modelos eficientes são ideais para operações frequentes e rotineiras, onde velocidade e custo são prioridade. Trabalham melhor em tarefas com parâmetros bem definidos, sem necessidade de raciocínio avançado ou criatividade.

    Considere-os para processamento e transformação de dados, formatação simples, chamadas de funções (function calling) e operações em alto volume onde custo importa mais.

    O ponto crítico é verificar adequação à tarefa. Funcionam para muitos fluxos rotineiros, mas podem falhar se a tarefa exigir compreensão técnica ou raciocínio.
  </Tab>

  <Tab title="Modelos Open Source">
    Modelos open source são atraentes quando há restrição orçamentária, necessidade de privacidade, personalização especial ou exigência de deployment local.

    Considere para ferramentas internas de empresas, aplicações sensíveis, projetos onde não é possível usar APIs externas, casos com orçamento apertado ou requisitos de customização.

    Mas lembre-se: exigem mais expertise, manutenção e investimentos em infraestrutura. Avalie o custo total da operação ao avaliar esses modelos.
  </Tab>
</Tabs>

## Armadilhas Comuns na Seleção de Modelos CrewAI

<AccordionGroup>
  <Accordion title="A Armadilha do 'Um Modelo Serve para Tudo'" icon="triangle-exclamation">
    **O problema**: Usar o mesmo LLM para todos os agentes, independentemente das funções. Prática padrão, mas raramente ótima.

    **Exemplo real**: Usar GPT-4o tanto para planejamento estratégico quanto para extração simples de dados. O manager precisa do raciocínio premium, mas o extrator poderia usar o GPT-4o-mini, muito mais barato.

    **Solução CrewAI**: Configure modelos específicos por agente:

    ```python
    # Agente estratégico recebe modelo premium
    manager = Agent(role="Strategy Manager", llm=LLM(model="gpt-4o"))

    # Agente de processamento recebe modelo eficiente
    processor = Agent(role="Data Processor", llm=LLM(model="gpt-4o-mini"))
    ```
  </Accordion>

  <Accordion title="Ignorar Hierarquia de LLM entre Crew e Agente" icon="shuffle">
    **O problema**: Não entender como funciona a hierarquia LLM da CrewAI — configurações conflitam entre crew, manager e agentes.

    **Exemplo real**: Configurar crew com Claude, mas agentes com GPT, gerando comportamento inconsistente e trocas desnecessárias.

    **Solução CrewAI**: Planeje a hierarquia estrategicamente:

    ```python
    crew = Crew(
        agents=[agent1, agent2],
        tasks=[task1, task2],
        manager_llm=LLM(model="gpt-4o"),
        process=Process.hierarchical
    )

    # Agentes herdam o LLM da crew, salvo sobrescrita
    agent1 = Agent(llm=LLM(model="claude-3-5-sonnet"))
    ```
  </Accordion>

  <Accordion title="Incompatibilidade para Function Calling" icon="screwdriver-wrench">
    **O problema**: Escolher modelos pela capacidade geral e ignorar o desempenho em function calling em workflows intensivos em ferramentas.

    **Exemplo real**: Selecionar modelo criativo para agente que só precisa chamar APIs e processar dados estruturados, resultando em má extração de parâmetros.

    **Solução CrewAI**: Priorize desempenho em function calling para agentes que usam ferramentas:

    ```python
    # Para agentes com muitas ferramentas
    tool_agent = Agent(
        role="API Integration Specialist",
        tools=[search_tool, api_tool, data_tool],
        llm=LLM(model="gpt-4o"),
        # OU
        llm=LLM(model="claude-3-5-sonnet")
    )
    ```
  </Accordion>

  <Accordion title="Otimização Prematura sem Teste" icon="gear">
    **O problema**: Decidir configurações complexas de modelo com base em hipóteses não validadas nos fluxos e tarefas reais CrewAI.

    **Exemplo real**: Implementar lógica elaborada de troca de modelo por tipo de tarefa sem testar se os ganhos compensam a complexidade.

    **Solução CrewAI**: Comece simples e otimize baseado em dados reais:

    ```python
    # Comece assim
    crew = Crew(agents=[...], tasks=[...], llm=LLM(model="gpt-4o-mini"))

    # Teste a performance e só depois otimize agentes específicos
    # Use testes Enterprise para validar melhorias
    ```
  </Accordion>

  <Accordion title="Ignorar Limites de Contexto e Memória" icon="brain">
    **O problema**: Não considerar como janela de contexto dos modelos interage com memória e compartilhamento de contexto entre agentes CrewAI.

    **Exemplo real**: Usar modelo de contexto curto para agentes que precisam manter histórico ao longo de múltiplas iterações ou equipes com comunicação extensiva agent-to-agent.

    **Solução CrewAI**: Alinhe capacidades de contexto ao padrão de comunicação da crew.
  </Accordion>
</AccordionGroup>

## Estratégia de Teste e Iteração

<Steps>
  <Step title="Comece Simples" icon="play">
    Comece com modelos de uso geral, confiáveis e amplamente suportados. Isso estabelece base estável para entender necessidades e expectativas de desempenho antes de otimizar para demandas especializadas.
  </Step>

  <Step title="Meça o que Importa" icon="chart-line">
    Desenvolva métricas alinhadas ao seu caso de uso e metas de negócio, não apenas benchmarks gerais. Foque na mensuração de resultados relevantes ao seu sucesso.
  </Step>

  <Step title="Itere Baseado em Resultados" icon="arrows-rotate">
    Faça mudanças baseadas no desempenho observado no seu contexto, não apenas considerações teóricas ou recomendações genéricas. O desempenho prático costuma ser bem diferente dos benchmarks.
  </Step>

  <Step title="Considere o Custo Total" icon="calculator">
    Avalie todo custo de operação, incluindo modelo, tempo de desenvolvimento, manutenção e complexidade. O modelo mais barato por token pode não ser o mais econômico ao considerar todos os fatores.
  </Step>
</Steps>

<Tip>
  Foque em entender seus requisitos primeiro, e então escolha modelos que melhor correspondam a essas necessidades. O melhor LLM é aquele que consistentemente entrega os resultados esperados dentro das suas restrições.
</Tip>

### Validação de Modelos em Nível Enterprise

Para equipes sérias sobre otimização, a **plataforma CrewAI Enterprise** oferece testes sofisticados que vão além do CLI. Ela permite avaliação completa para decisões orientadas por dados na estratégia de LLM.

<Frame>
  ![Enterprise Testing Interface](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/enterprise-testing.png)
</Frame>

**Funcionalidades Avançadas de Teste:**

* **Comparação Multi-Modelo**: Teste diversos LLMs simultaneamente nas mesmas tarefas e entradas. Compare desempenho entre GPT-4o, Claude, Llama, Groq, Cerebras, e outros líderes em paralelo para identificar a melhor opção para você.

* **Rigor Estatístico**: Configure múltiplas iterações com inputs consistentes para medir confiabilidade e variação no desempenho. Assim, identifica modelos que performam bem e de modo consistente.

* **Validação no Mundo Real**: Use os inputs e cenários reais da sua crew, e não apenas benchmarks sintéticos. A plataforma permite testar no contexto da sua indústria, empresa e casos de uso.

* **Analytics Completo**: Acesse métricas detalhadas de desempenho, tempos de execução e análise de custos para todos os modelos testados. Decisões baseadas em dados reais, não apenas reputação.

* **Colaboração em Equipe**: Compartilhe resultados e análises com seu time, favorecendo decisões coletivas e estratégias alinhadas.

Acesse [app.crewai.com](https://app.crewai.com) para começar!

<Info>
  A plataforma Enterprise transforma a seleção de modelos de um "palpite" para um processo orientado por dados, permitindo validar os princípios deste guia com seus próprios casos de uso.
</Info>

## Resumo dos Princípios-Chave

<CardGroup cols={2}>
  <Card title="Seleção Orientada à Tarefa" icon="bullseye">
    Escolha os modelos pelo que sua tarefa realmente requer, não por reputação ou capacidades teóricas.
  </Card>

  <Card title="Combinação de Capacidades" icon="puzzle-piece">
    Alinhe forças do modelo a papéis e responsabilidades dos agentes para melhor desempenho.
  </Card>

  <Card title="Consistência Estratégica" icon="link">
    Mantenha uma estratégia coerente de seleção de modelos em fluxos e componentes relacionados.
  </Card>

  <Card title="Testes Práticos" icon="flask">
    Valide escolhas em uso real, não apenas em benchmarks.
  </Card>

  <Card title="Iteração Contínua" icon="arrow-up">
    Comece simples e otimize com base na performance e necessidade práticas.
  </Card>

  <Card title="Equilíbrio Operacional" icon="scale-balanced">
    Equilibre performance requerida, custo e complexidade.
  </Card>
</CardGroup>

<Check>
  Lembre-se: o melhor LLM é o que entrega consistentemente os resultados de que você precisa dentro de suas restrições. Conheça seu requisito primeiro, depois selecione o modelo mais adequado.
</Check>

## Panorama Atual dos Modelos (Junho/2025)

<Warning>
  **Retrato do Momento**: Os rankings a seguir representam o estado da arte em Junho de 2025, compilados do [LMSys Arena](https://arena.lmsys.org/), [Artificial Analysis](https://artificialanalysis.ai/) e outros benchmarks líderes. Performance, disponibilidade e preço mudam rapidamente. Sempre valide com seus dados e casos reais.
</Warning>

### Principais Modelos por Categoria

As tabelas abaixo mostram uma amostra dos modelos de maior destaque em cada categoria, junto de orientação sobre aplicação em agentes CrewAI:

<Note>
  Estas tabelas exibem apenas alguns modelos líderes por categoria. Existem muitos outros excelentes. O objetivo é ilustrar exemplos de capacidades buscadas em vez de apresentar um catálogo completo.
</Note>

<Tabs>
  <Tab title="Raciocínio & Planejamento">
    **Melhores para LLMs Manager e Análises Complexas**

    | Modelo                     | Score de Inteligência | Custo (\$/M tokens) | Velocidade | Melhor Uso em CrewAI                                         |
    | :------------------------- | :-------------------- | :------------------ | :--------- | :----------------------------------------------------------- |
    | **o3**                     | 70                    | \$17.50             | Rápido     | Manager LLM para coordenação multi-agente                    |
    | **Gemini 2.5 Pro**         | 69                    | \$3.44              | Rápido     | Agentes de planejamento estratégico, coordenação de pesquisa |
    | **DeepSeek R1**            | 68                    | \$0.96              | Moderada   | Raciocínio com bom custo-benefício                           |
    | **Claude 4 Sonnet**        | 53                    | \$6.00              | Rápido     | Agentes de análise que precisam de nuance                    |
    | **Qwen3 235B (Reasoning)** | 62                    | \$2.63              | Moderada   | Alternativa open source para raciocínio                      |

    Esses modelos se destacam em raciocínio multi-etapas e são ideais para agentes que desenvolvem estratégias, coordenam outros agentes ou analisam informações complexas.
  </Tab>

  <Tab title="Codificação & Técnica">
    **Melhores para Desenvolvimento e Workflows com Ferramentas**

    | Modelo                | Performance em Coding | Tool Use Score | Custo (\$/M tokens) | Melhor Uso em CrewAI                                             |
    | :-------------------- | :-------------------- | :------------- | :------------------ | :--------------------------------------------------------------- |
    | **Claude 4 Sonnet**   | Excelente             | 72.7%          | \$6.00              | Agente principal de código/documentação técnica                  |
    | **Claude 4 Opus**     | Excelente             | 72.5%          | \$30.00             | Arquitetura complexa, code review                                |
    | **DeepSeek V3**       | Muito bom             | Alto           | \$0.48              | Coding econômico para desenvolvimentos rotineiros                |
    | **Qwen2.5 Coder 32B** | Muito bom             | Médio          | \$0.15              | Agente de código econômico                                       |
    | **Llama 3.1 405B**    | Bom                   | 81.1%          | \$3.50              | LLM para function calling em workflows intensivos em ferramentas |

    Otimizados para geração de código, debugging e solução técnica, ideais para equipes de desenvolvimento.
  </Tab>

  <Tab title="Velocidade & Eficiência">
    **Melhores para Operações em Massa e Aplicações em Tempo Real**

    | Modelo                  | Velocidade (tokens/s) | Latência (TTFT) | Custo (\$/M tokens) | Melhor Uso em CrewAI                     |
    | :---------------------- | :-------------------- | :-------------- | :------------------ | :--------------------------------------- |
    | **Llama 4 Scout**       | 2.600                 | 0.33s           | \$0.27              | Agentes de processamento de alto volume  |
    | **Gemini 2.5 Flash**    | 376                   | 0.30s           | \$0.26              | Agentes de resposta em tempo real        |
    | **DeepSeek R1 Distill** | 383                   | Variável        | \$0.04              | Processamento rápido de baixo custo      |
    | **Llama 3.3 70B**       | 2.500                 | 0.52s           | \$0.60              | Equilíbrio entre velocidade e capacidade |
    | **Nova Micro**          | Alto                  | 0.30s           | \$0.04              | Execução rápida de tarefas simples       |

    Priorizam velocidade e eficiência, perfeitos para agentes em operações de rotina ou resposta ágil. **Dica:** Usar provedores de inference rápidos como Groq potencializa open source como Llama.
  </Tab>

  <Tab title="Performance Equilibrada">
    **Melhores Modelos Coringa para Crews Diversos**

    | Modelo                | Score Global | Versatilidade | Custo (\$/M tokens) | Melhor Uso em CrewAI                  |
    | :-------------------- | :----------- | :------------ | :------------------ | :------------------------------------ |
    | **GPT-4.1**           | 53           | Excelente     | \$3.50              | LLM generalista para equipes variadas |
    | **Claude 3.7 Sonnet** | 48           | Muito boa     | \$6.00              | Raciocínio e criatividade balanceados |
    | **Gemini 2.0 Flash**  | 48           | Boa           | \$0.17              | Generalista de bom custo benefício    |
    | **Llama 4 Maverick**  | 51           | Boa           | \$0.37              | Open source para usos gerais          |
    | **Qwen3 32B**         | 44           | Boa           | \$1.23              | Versatilidade econômica               |

    Oferecem bom desempenho geral, adequados para crews com demandas amplas.
  </Tab>
</Tabs>

### Framework de Seleção para Modelos Atuais

<AccordionGroup>
  <Accordion title="Crews de Alta Performance" icon="rocket">
    **Priorizando performance**: Use modelos topo de linha como **o3**, **Gemini 2.5 Pro** ou **Claude 4 Sonnet** para managers e agentes críticos. Excelentes em raciocínio e coordenação, porém mais caros.

    **Estratégia**: Implemente abordagem multi-modelo, reservando premium para raciocínio estratégico e eficientes para operações rotineiras.
  </Accordion>

  <Accordion title="Crews de Baixo Custo" icon="dollar-sign">
    **Foco no orçamento**: Foque em modelos como **DeepSeek R1**, **Llama 4 Scout** ou **Gemini 2.0 Flash**, que trazem ótimo desempenho com investimento reduzido.

    **Estratégia**: Use modelos econômicos para maioria dos agentes, reservando premium apenas para funções críticas.
  </Accordion>

  <Accordion title="Workflows Especializados" icon="screwdriver-wrench">
    **Para expertise específica**: Escolha modelos otimizados para seu principal caso de uso: **Claude 4** em código, **Gemini 2.5 Pro** em pesquisa, **Llama 405B** em function calling.

    **Estratégia**: Selecione conforme a principal função da crew, garantindo alinhamento de capacidade e modelo.
  </Accordion>

  <Accordion title="Empresa & Privacidade" icon="shield">
    **Para operações sensíveis**: Avalie modelos open source como **Llama 4** series, **DeepSeek V3** ou **Qwen3** para deployment privado, mantendo performance competitiva.

    **Estratégia**: Use open source em infraestrutura própria e aceite possíveis trade-offs por controle dos dados.
  </Accordion>
</AccordionGroup>

### Considerações-Chave na Seleção de Modelos

* **Tendências de Performance**: O cenário atual mostra competição forte entre modelos de raciocínio (o3, Gemini 2.5 Pro) e equilibrados (Claude 4, GPT-4.1). Modelos como DeepSeek R1 entregam excelente custo/performance.
* **Trade-off Velocidade x Inteligência**: Modelos como Llama 4 Scout priorizam velocidade (2.600 tokens/s) e inteligência razoável, enquanto outros como o3 maximizam raciocínio em detrimento de velocidade/preço.
* **Viabilidade Open Source**: A distância entre open source e proprietários diminui a cada mês, com Llama 4 Maverick e DeepSeek V3 entregando performance competitiva a preços atrativos. Inferência rápida via Groq maximiza custo-benefício nesses casos.

<Info>
  **Testes são essenciais**: Rankings servem de orientação geral, mas seu caso de uso, prompt e critério podem gerar resultados distintos. Sempre teste modelos candidatos com suas tarefas e dados reais antes de decidir.
</Info>

### Estratégia Prática de Implementação

<Steps>
  <Step title="Comece por Modelos Validados">
    Inicie com opções consagradas como **GPT-4.1**, **Claude 3.7 Sonnet** ou **Gemini 2.0 Flash**, que oferecem bom desempenho e ampla validação.
  </Step>

  <Step title="Identifique Demandas Especializadas">
    Descubra se sua crew possui requisitos específicos (código, raciocínio, velocidade) que justifiquem modelos como **Claude 4 Sonnet** para desenvolvimento ou **o3** para análise. Para aplicações críticas em velocidade, considere Groq aliado à seleção do modelo.
  </Step>

  <Step title="Implemente Estratégia Multi-Modelo">
    Use modelos diferentes para agentes distintos conforme o papel. Modelos de alta capacidade para managers e tarefas complexas, eficientes para rotinas.
  </Step>

  <Step title="Monitore e Otimize">
    Acompanhe métricas relevantes ao seu caso e esteja pronto para ajustar modelos conforme lançamentos ou mudanças de preços.
  </Step>
</Steps>


# Usando Agentes Multimodais
Source: https://docs.crewai.com/pt-BR/learn/multimodal-agents

Aprenda como habilitar e usar capacidades multimodais em seus agentes para processar imagens e outros conteúdos não textuais dentro do framework CrewAI.

## Usando Agentes Multimodais

O CrewAI suporta agentes multimodais que podem processar tanto conteúdo textual quanto não textual, como imagens. Este guia mostrará como habilitar e utilizar capacidades multimodais em seus agentes.

### Habilitando Capacidades Multimodais

Para criar um agente multimodal, basta definir o parâmetro `multimodal` como `True` ao inicializar seu agente:

```python
from crewai import Agent

agent = Agent(
    role="Image Analyst",
    goal="Analyze and extract insights from images",
    backstory="An expert in visual content interpretation with years of experience in image analysis",
    multimodal=True  # This enables multimodal capabilities
)
```

Ao definir `multimodal=True`, o agente é automaticamente configurado com as ferramentas necessárias para lidar com conteúdo não textual, incluindo a `AddImageTool`.

### Trabalhando com Imagens

O agente multimodal vem pré-configurado com a `AddImageTool`, permitindo que ele processe imagens. Não é necessário adicionar esta ferramenta manualmente – ela é automaticamente incluída ao habilitar capacidades multimodais.

Aqui está um exemplo completo mostrando como usar um agente multimodal para analisar uma imagem:

```python
from crewai import Agent, Task, Crew

# Create a multimodal agent
image_analyst = Agent(
    role="Product Analyst",
    goal="Analyze product images and provide detailed descriptions",
    backstory="Expert in visual product analysis with deep knowledge of design and features",
    multimodal=True
)

# Create a task for image analysis
task = Task(
    description="Analyze the product image at https://example.com/product.jpg and provide a detailed description",
    expected_output="A detailed description of the product image",
    agent=image_analyst
)

# Create and run the crew
crew = Crew(
    agents=[image_analyst],
    tasks=[task]
)

result = crew.kickoff()
```

### Uso Avançado com Contexto

Você pode fornecer contexto adicional ou perguntas específicas sobre a imagem ao criar tarefas para agentes multimodais. A descrição da tarefa pode incluir aspectos específicos nos quais você deseja que o agente foque:

```python
from crewai import Agent, Task, Crew

# Create a multimodal agent for detailed analysis
expert_analyst = Agent(
    role="Visual Quality Inspector",
    goal="Perform detailed quality analysis of product images",
    backstory="Senior quality control expert with expertise in visual inspection",
    multimodal=True  # AddImageTool is automatically included
)

# Create a task with specific analysis requirements
inspection_task = Task(
    description="""
    Analyze the product image at https://example.com/product.jpg with focus on:
    1. Quality of materials
    2. Manufacturing defects
    3. Compliance with standards
    Provide a detailed report highlighting any issues found.
    """,
    expected_output="A detailed report highlighting any issues found",
    agent=expert_analyst
)

# Create and run the crew
crew = Crew(
    agents=[expert_analyst],
    tasks=[inspection_task]
)

result = crew.kickoff()
```

### Detalhes da Ferramenta

Ao trabalhar com agentes multimodais, a `AddImageTool` é automaticamente configurada com o seguinte esquema:

```python
class AddImageToolSchema:
    image_url: str  # Required: The URL or path of the image to process
    action: Optional[str] = None  # Optional: Additional context or specific questions about the image
```

O agente multimodal irá automaticamente realizar o processamento de imagens por meio de suas ferramentas internas, permitindo que ele:

* Acesse imagens via URLs ou caminhos de arquivos locais
* Processe o conteúdo da imagem com contexto opcional ou perguntas específicas
* Forneça análises e insights com base nas informações visuais e requisitos da tarefa

### Boas Práticas

Ao trabalhar com agentes multimodais, tenha em mente as seguintes boas práticas:

1. **Acesso à Imagem**
   * Certifique-se de que suas imagens estejam acessíveis via URLs alcançáveis pelo agente
   * Para imagens locais, considere hospedá-las temporariamente ou utilize caminhos absolutos
   * Verifique se as URLs das imagens são válidas e acessíveis antes de rodar as tarefas

2. **Descrição da Tarefa**
   * Seja específico sobre quais aspectos da imagem você deseja que o agente analise
   * Inclua perguntas ou requisitos claros na descrição da tarefa
   * Considere usar o parâmetro opcional `action` para uma análise focada

3. **Gerenciamento de Recursos**
   * O processamento de imagens pode exigir mais recursos computacionais do que tarefas apenas textuais
   * Alguns modelos de linguagem podem exigir codificação em base64 para dados de imagem
   * Considere o processamento em lote para múltiplas imagens visando otimizar o desempenho

4. **Configuração do Ambiente**
   * Verifique se seu ambiente possui as dependências necessárias para processamento de imagens
   * Certifique-se de que seu modelo de linguagem suporta capacidades multimodais
   * Teste primeiro com imagens pequenas para validar sua configuração

5. **Tratamento de Erros**
   * Implemente tratamento apropriado para falhas no carregamento de imagens
   * Tenha estratégias de contingência para casos onde o processamento de imagens falhar
   * Monitore e registre operações de processamento de imagens para depuração


# Visão Geral
Source: https://docs.crewai.com/pt-BR/learn/overview

Aprenda como construir, personalizar e otimizar suas aplicações CrewAI com guias e tutoriais completos

## Aprenda CrewAI

Esta seção fornece guias e tutoriais completos para ajudar você a dominar o CrewAI, desde conceitos básicos até técnicas avançadas. Seja você iniciante ou esteja buscando otimizar suas implementações existentes, estes recursos o guiarão por todos os aspectos da construção de workflows poderosos de agentes de IA.

## Guias de Introdução

### Conceitos Centrais

<CardGroup cols={2}>
  <Card title="Processo Sequencial" icon="list-ol" href="/pt-BR/learn/sequential-process">
    Aprenda a executar tarefas em ordem sequencial para workflows estruturados.
  </Card>

  <Card title="Processo Hierárquico" icon="sitemap" href="/pt-BR/learn/hierarchical-process">
    Implemente execução hierárquica de tarefas com agentes gerentes supervisionando workflows.
  </Card>

  <Card title="Tarefas Condicionais" icon="code-branch" href="/pt-BR/learn/conditional-tasks">
    Crie workflows dinâmicos com execução condicional de tarefas baseada em resultados.
  </Card>

  <Card title="Kickoff Assíncrono" icon="bolt" href="/pt-BR/learn/kickoff-async">
    Execute crews de forma assíncrona para melhorar desempenho e concorrência.
  </Card>
</CardGroup>

### Desenvolvimento de Agentes

<CardGroup cols={2}>
  <Card title="Personalizando Agentes" icon="user-gear" href="/pt-BR/learn/customizing-agents">
    Aprenda como personalizar o comportamento, funções e capacidades dos agentes.
  </Card>

  <Card title="Codificando Agentes" icon="code" href="/pt-BR/learn/coding-agents">
    Construa agentes que podem escrever, executar e depurar código automaticamente.
  </Card>

  <Card title="Agentes Multimodais" icon="images" href="/pt-BR/learn/multimodal-agents">
    Crie agentes capazes de processar texto, imagens e outros tipos de mídia.
  </Card>

  <Card title="Agente Gerente Personalizado" icon="user-tie" href="/pt-BR/learn/custom-manager-agent">
    Implemente agentes gerentes personalizados para workflows hierárquicos complexos.
  </Card>
</CardGroup>

## Funcionalidades Avançadas

### Controle de Workflow

<CardGroup cols={2}>
  <Card title="Humano no Loop" icon="user-check" href="/pt-BR/learn/human-in-the-loop">
    Integre supervisão e intervenção humana aos workflows dos agentes.
  </Card>

  <Card title="Entrada Humana na Execução" icon="hand-paper" href="/pt-BR/learn/human-input-on-execution">
    Permita entrada humana durante a execução de tarefas para tomada de decisões dinâmicas.
  </Card>

  <Card title="Repetir Tarefas" icon="rotate-left" href="/pt-BR/learn/replay-tasks-from-latest-crew-kickoff">
    Refaça e retome tarefas a partir de execuções anteriores de crews.
  </Card>

  <Card title="Kickoff para Cada" icon="repeat" href="/pt-BR/learn/kickoff-for-each">
    Execute crews múltiplas vezes com diferentes entradas de maneira eficiente.
  </Card>
</CardGroup>

### Personalização & Integração

<CardGroup cols={2}>
  <Card title="LLM Personalizado" icon="brain" href="/pt-BR/learn/custom-llm">
    Integre modelos de linguagem personalizados e provedores ao CrewAI.
  </Card>

  <Card title="Conexões LLM" icon="link" href="/pt-BR/learn/llm-connections">
    Configure e gerencie conexões com vários provedores de LLM.
  </Card>

  <Card title="Criar Ferramentas Personalizadas" icon="wrench" href="/pt-BR/learn/create-custom-tools">
    Construa ferramentas personalizadas para estender as capacidades dos agentes.
  </Card>

  <Card title="Usando Anotações" icon="at" href="/pt-BR/learn/using-annotations">
    Use anotações Python para um código mais limpo e fácil de manter.
  </Card>
</CardGroup>

## Aplicações Especializadas

### Conteúdo & Mídia

<CardGroup cols={2}>
  <Card title="Geração de Imagens DALL-E" icon="image" href="/pt-BR/learn/dalle-image-generation">
    Gere imagens utilizando a integração DALL-E com seus agentes.
  </Card>

  <Card title="Traga Seu Próprio Agente" icon="user-plus" href="/pt-BR/learn/bring-your-own-agent">
    Integre agentes e modelos já existentes aos workflows do CrewAI.
  </Card>
</CardGroup>

### Gerenciamento de Ferramentas

<CardGroup cols={2}>
  <Card title="Forçar Saída da Ferramenta como Resultado" icon="hammer" href="/pt-BR/learn/force-tool-output-as-result">
    Configure ferramentas para retornarem sua saída diretamente como resultado da tarefa.
  </Card>
</CardGroup>

## Recomendações de Rotas de Aprendizagem

### Para Iniciantes

1. Comece pelo **Processo Sequencial** para entender a execução básica de workflows
2. Aprenda **Personalizando Agentes** para criar configurações de agentes eficazes
3. Explore **Criar Ferramentas Personalizadas** para estender funcionalidades
4. Experimente **Humano no Loop** para workflows interativos

### Para Usuários Intermediários

1. Domine **Processo Hierárquico** para sistemas multiagente complexos
2. Implemente **Tarefas Condicionais** para workflows dinâmicos
3. Utilize **Kickoff Assíncrono** para otimizar desempenho
4. Integre **LLM Personalizado** para modelos especializados

### Para Usuários Avançados

1. Construa **Agentes Multimodais** para processamento complexo de mídias
2. Crie **Agentes Gerentes Personalizados** para orquestração sofisticada
3. Implemente **Traga Seu Próprio Agente** para sistemas híbridos
4. Use **Repetir Tarefas** para recuperação de erros robusta

## Melhores Práticas

### Desenvolvimento

* **Comece Simples**: Inicie com workflows sequenciais básicos antes de adicionar complexidade
* **Teste de Forma Incremental**: Teste cada componente antes de integrar em sistemas maiores
* **Use Anotações**: Aproveite as anotações Python para código mais limpo e sustentável
* **Ferramentas Personalizadas**: Crie ferramentas reutilizáveis que possam ser compartilhadas entre diferentes agentes

### Produção

* **Tratamento de Erros**: Implemente mecanismos robustos de tratamento e recuperação de erros
* **Desempenho**: Utilize execução assíncrona e otimize chamadas a LLM para melhor desempenho
* **Monitoramento**: Integre ferramentas de observabilidade para acompanhar o desempenho dos agentes
* **Supervisão Humana**: Inclua checkpoints humanos para decisões críticas

### Otimização

* **Gestão de Recursos**: Monitore e otimize o uso de tokens e custos de API
* **Design de Workflow**: Elabore workflows que minimizem chamadas desnecessárias ao LLM
* **Eficiência das Ferramentas**: Crie ferramentas eficientes que ofereçam máximo valor com o mínimo de overhead
* **Aprimoramento Iterativo**: Use feedback e métricas para melhorar continuamente o desempenho dos agentes

## Obtendo Ajuda

* **Documentação**: Cada guia inclui exemplos detalhados e explicações
* **Comunidade**: Participe do [Fórum CrewAI](https://community.crewai.com) para discussões e suporte
* **Exemplos**: Consulte a seção de Exemplos para implementações completas e funcionais
* **Suporte**: Entre em contato via [support@crewai.com](mailto:support@crewai.com) para assistência técnica

Comece pelos guias que atendem às suas necessidades atuais e, gradualmente, explore tópicos mais avançados conforme você se sentir confortável com os fundamentos.


# Reexecutar Tarefas a partir do Último Crew Kickoff
Source: https://docs.crewai.com/pt-BR/learn/replay-tasks-from-latest-crew-kickoff

Reexecute tarefas a partir do último crew.kickoff(...)

## Introdução

O CrewAI oferece a capacidade de reexecutar uma tarefa especificada a partir do último crew kickoff. Esse recurso é particularmente útil quando você concluiu um kickoff e deseja tentar novamente determinadas tarefas, ou não precisa buscar dados novamente porque seus agentes já possuem o contexto salvo da execução do kickoff, sendo necessário apenas reexecutar as tarefas desejadas.

<Note>
  Você deve executar `crew.kickoff()` antes de poder reexecutar uma tarefa.
  Atualmente, apenas o kickoff mais recente é suportado, então se você utilizar `kickoff_for_each`, será possível reexecutar apenas a partir da execução de crew mais recente.
</Note>

Aqui está um exemplo de como reexecutar a partir de uma tarefa:

### Reexecutando a partir de uma Tarefa Específica Usando o CLI

Para utilizar o recurso de reexecução, siga estes passos:

<Steps>
  <Step title="Abra seu terminal ou prompt de comando." />

  <Step title="Navegue até o diretório onde está localizado seu projeto CrewAI." />

  <Step title="Execute os seguintes comandos:">
    Para visualizar os task\_ids do último kickoff, utilize:

    ```shell
    crewai log-tasks-outputs
    ```

    Após identificar o `task_id` que deseja reexecutar, utilize:

    ```shell
    crewai replay -t <task_id>
    ```
  </Step>
</Steps>

<Note>
  Certifique-se de que o `crewai` está instalado e devidamente configurado no seu ambiente de desenvolvimento.
</Note>

### Reexecutando uma Tarefa Programaticamente

Para reexecutar uma tarefa programaticamente, siga os passos abaixo:

<Steps>
  <Step title="Especifique o `task_id` e os parâmetros de entrada para o processo de reexecução.">
    Especifique o `task_id` e os parâmetros de entrada para o processo de reexecução.
  </Step>

  <Step title="Execute o comando de reexecução dentro de um bloco try-except para lidar com possíveis erros.">
    Execute o comando de reexecução dentro de um bloco try-except para lidar com possíveis erros.

    <CodeGroup>
      ```python Code
        def replay():
        """
        Replay the crew execution from a specific task.
        """
        task_id = '<task_id>'
        inputs = {"topic": "CrewAI Training"}  # This is optional; you can pass in the inputs you want to replay; otherwise, it uses the previous kickoff's inputs.
        try:
            YourCrewName_Crew().crew().replay(task_id=task_id, inputs=inputs)

        except subprocess.CalledProcessError as e:
            raise Exception(f"An error occurred while replaying the crew: {e}")

        except Exception as e:
            raise Exception(f"An unexpected error occurred: {e}")
      ```
    </CodeGroup>
  </Step>
</Steps>

## Conclusão

Com as melhorias acima e funcionalidades detalhadas, a reexecução de tarefas específicas no CrewAI ficou mais eficiente e robusta.
Certifique-se de seguir exatamente os comandos e passos para aproveitar ao máximo esses recursos.


# Processos Sequenciais
Source: https://docs.crewai.com/pt-BR/learn/sequential-process

Um guia abrangente para utilizar os processos sequenciais na execução de tarefas em projetos CrewAI.

## Introdução

O CrewAI oferece uma estrutura flexível para execução de tarefas de maneira estruturada, suportando tanto processos sequenciais quanto hierárquicos.
Este guia descreve como implementar esses processos de forma eficaz para garantir execução eficiente das tarefas e a conclusão do projeto.

## Visão Geral do Processo Sequencial

O processo sequencial garante que as tarefas sejam executadas uma após a outra, seguindo um progresso linear.
Essa abordagem é ideal para projetos nos quais as tarefas precisam ser concluídas em uma ordem específica.

### Principais Características

* **Fluxo Linear de Tarefas**: Garante o progresso ordenado ao tratar tarefas em uma sequência pré-determinada.
* **Simplicidade**: Melhor opção para projetos com tarefas claras e passo a passo.
* **Fácil Monitoramento**: Facilita o acompanhamento da conclusão das tarefas e do progresso do projeto.

## Implementando o Processo Sequencial

Para utilizar o processo sequencial, monte sua crew e defina as tarefas na ordem em que devem ser executadas.

```python Code
from crewai import Crew, Process, Agent, Task, TaskOutput, CrewOutput

# Define your agents
researcher = Agent(
  role='Researcher',
  goal='Conduct foundational research',
  backstory='An experienced researcher with a passion for uncovering insights'
)
analyst = Agent(
  role='Data Analyst',
  goal='Analyze research findings',
  backstory='A meticulous analyst with a knack for uncovering patterns'
)
writer = Agent(
  role='Writer',
  goal='Draft the final report',
  backstory='A skilled writer with a talent for crafting compelling narratives'
)

# Define your tasks
research_task = Task(
  description='Gather relevant data...',
  agent=researcher,
  expected_output='Raw Data'
)
analysis_task = Task(
  description='Analyze the data...',
  agent=analyst,
  expected_output='Data Insights'
)
writing_task = Task(
  description='Compose the report...',
  agent=writer,
  expected_output='Final Report'
)

# Form the crew with a sequential process
report_crew = Crew(
  agents=[researcher, analyst, writer],
  tasks=[research_task, analysis_task, writing_task],
  process=Process.sequential
)

# Execute the crew
result = report_crew.kickoff()

# Accessing the type-safe output
task_output: TaskOutput = result.tasks[0].output
crew_output: CrewOutput = result.output
```

### Nota:

Cada tarefa em um processo sequencial **deve** ter um agente atribuído. Certifique-se de que todo `Task` inclua um parâmetro `agent`.

### Fluxo de Trabalho em Ação

1. **Tarefa Inicial**: Em um processo sequencial, o primeiro agente conclui sua tarefa e sinaliza a finalização.
2. **Tarefas Subsequentes**: Os agentes assumem suas tarefas conforme o tipo de processo, com os resultados das tarefas anteriores ou diretrizes orientando sua execução.
3. **Finalização**: O processo é concluído assim que a última tarefa é executada, levando à conclusão do projeto.

## Funcionalidades Avançadas

### Delegação de Tarefas

Em processos sequenciais, se um agente possui `allow_delegation` definido como `True`, ele pode delegar tarefas para outros agentes na crew.
Esse recurso é configurado automaticamente quando há múltiplos agentes na crew.

### Execução Assíncrona

As tarefas podem ser executadas de forma assíncrona, permitindo processamento paralelo quando apropriado.
Para criar uma tarefa assíncrona, defina `async_execution=True` ao criar a tarefa.

### Memória e Cache

O CrewAI suporta recursos de memória e cache:

* **Memória**: Habilite definindo `memory=True` ao criar a Crew. Isso permite aos agentes reter informações entre as tarefas.
* **Cache**: Por padrão, o cache está habilitado. Defina `cache=False` para desativá-lo.

### Callbacks

Você pode definir callbacks tanto no nível da tarefa quanto no nível de etapa:

* `task_callback`: Executado após a conclusão de cada tarefa.
* `step_callback`: Executado após cada etapa na execução de um agente.

### Métricas de Uso

O CrewAI rastreia o uso de tokens em todas as tarefas e agentes. Você pode acessar essas métricas após a execução.

## Melhores Práticas para Processos Sequenciais

1. **A Ordem Importa**: Organize as tarefas em uma sequência lógica, onde cada uma aproveite o resultado da anterior.
2. **Descrições Claras de Tarefas**: Forneça descrições detalhadas para cada tarefa, orientando os agentes de forma eficaz.
3. **Seleção Apropriada de Agentes**: Relacione as habilidades e funções dos agentes às necessidades de cada tarefa.
4. **Use o Contexto**: Aproveite o contexto das tarefas anteriores para informar as seguintes.

Esta documentação atualizada garante que os detalhes reflitam com precisão as últimas mudanças no código e descreve claramente como aproveitar novos recursos e configurações.
O conteúdo foi mantido simples e direto para garantir fácil compreensão.


# Usando Anotações no crew.py
Source: https://docs.crewai.com/pt-BR/learn/using-annotations

Aprenda como usar anotações para estruturar corretamente agentes, tarefas e componentes no CrewAI

Este guia explica como utilizar anotações para referenciar corretamente **agentes**, **tarefas** e outros componentes no arquivo `crew.py`.

## Introdução

As anotações no framework CrewAI são utilizadas para decorar classes e métodos, fornecendo metadados e funcionalidades para diversos componentes do seu crew. Essas anotações auxiliam na organização e estruturação do seu código, tornando-o mais legível e fácil de manter.

## Anotações Disponíveis

O framework CrewAI fornece as seguintes anotações:

* `@CrewBase`: Usada para decorar a classe principal do crew.
* `@agent`: Decora métodos que definem e retornam objetos Agent.
* `@task`: Decora métodos que definem e retornam objetos Task.
* `@crew`: Decora o método que cria e retorna o objeto Crew.
* `@llm`: Decora métodos que inicializam e retornam objetos Language Model.
* `@tool`: Decora métodos que inicializam e retornam objetos Tool.
* `@callback`: Utilizada para definir métodos de callback.
* `@output_json`: Utilizada para métodos que retornam dados em JSON.
* `@output_pydantic`: Utilizada para métodos que retornam modelos Pydantic.
* `@cache_handler`: Utilizada para definição de métodos de manipulação de cache.

## Exemplos de Uso

Vamos passar por exemplos de como utilizar essas anotações:

### 1. Classe Base do Crew

```python
@CrewBase
class LinkedinProfileCrew():
    """LinkedinProfile crew"""
    agents_config = 'config/agents.yaml'
    tasks_config = 'config/tasks.yaml'
```

A anotação `@CrewBase` é usada para decorar a classe principal do crew. Esta classe geralmente contém as configurações e métodos para criação de agentes, tarefas e do próprio crew.

### 2. Definição de Tool

```python
@tool
def myLinkedInProfileTool(self):
    return LinkedInProfileTool()
```

A anotação `@tool` é usada para decorar métodos que retornam objetos tool. Essas ferramentas podem ser usadas por agentes para executar tarefas específicas.

### 3. Definição de LLM

```python
@llm
def groq_llm(self):
    api_key = os.getenv('api_key')
    return ChatGroq(api_key=api_key, temperature=0, model_name="mixtral-8x7b-32768")
```

A anotação `@llm` é usada para decorar métodos que inicializam e retornam objetos Language Model. Esses LLMs são utilizados pelos agentes para tarefas de processamento de linguagem natural.

### 4. Definição de Agente

```python
@agent
def researcher(self) -> Agent:
    return Agent(
        config=self.agents_config['researcher']
    )
```

A anotação `@agent` é usada para decorar métodos que definem e retornam objetos Agent.

### 5. Definição de Tarefa

```python
@task
def research_task(self) -> Task:
    return Task(
        config=self.tasks_config['research_linkedin_task'],
        agent=self.researcher()
    )
```

A anotação `@task` é usada para decorar métodos que definem e retornam objetos Task. Esses métodos especificam a configuração da tarefa e o agente responsável por ela.

### 6. Criação do Crew

```python
@crew
def crew(self) -> Crew:
    """Creates the LinkedinProfile crew"""
    return Crew(
        agents=self.agents,
        tasks=self.tasks,
        process=Process.sequential,
        verbose=True
    )
```

A anotação `@crew` é usada para decorar o método que cria e retorna o objeto `Crew`. Este método reúne todos os componentes (agentes e tarefas) em um crew funcional.

## Configuração YAML

As configurações dos agentes geralmente são armazenadas em um arquivo YAML. Veja um exemplo de como o arquivo `agents.yaml` pode ser estruturado para o agente researcher:

```yaml
researcher:
    role: >
        LinkedIn Profile Senior Data Researcher
    goal: >
        Uncover detailed LinkedIn profiles based on provided name {name} and domain {domain}
        Generate a Dall-E image based on domain {domain}
    backstory: >
        You're a seasoned researcher with a knack for uncovering the most relevant LinkedIn profiles.
        Known for your ability to navigate LinkedIn efficiently, you excel at gathering and presenting
        professional information clearly and concisely.
    allow_delegation: False
    verbose: True
    llm: groq_llm
    tools:
        - myLinkedInProfileTool
        - mySerperDevTool
        - myDallETool
```

Esta configuração YAML corresponde ao agente researcher definido na classe `LinkedinProfileCrew`. A configuração especifica o papel do agente, objetivo, contexto e outras propriedades, como o LLM e as tools que ele utiliza.

Repare como os campos `llm` e `tools` no arquivo YAML correspondem aos métodos decorados com `@llm` e `@tool` na classe Python.

## Boas Práticas

* **Nomenclatura Consistente**: Utilize nomenclatura clara e consistente para seus métodos. Por exemplo, métodos de agentes podem ser nomeados de acordo com suas funções (ex: researcher, reporting\_analyst).
* **Variáveis de Ambiente**: Utilize variáveis de ambiente para informações sensíveis como chaves de API.
* **Flexibilidade**: Estruture seu crew de forma flexível, permitindo fácil adição ou remoção de agentes e tarefas.
* **Correspondência YAML-Código**: Assegure que os nomes e estruturas nos arquivos YAML correspondam corretamente aos métodos decorados em seu código Python.

Seguindo essas orientações e utilizando corretamente as anotações, você conseguirá criar crews bem estruturados e de fácil manutenção utilizando o framework CrewAI.


# Conectando a Múltiplos Servidores MCP
Source: https://docs.crewai.com/pt-BR/mcp/multiple-servers

Saiba como usar o MCPServerAdapter no CrewAI para conectar-se simultaneamente a múltiplos servidores MCP e agregar suas ferramentas.

## Visão Geral

O `MCPServerAdapter` em `crewai-tools` permite que você conecte-se a vários servidores MCP simultaneamente. Isso é útil quando seus agentes precisam acessar ferramentas distribuídas entre diferentes serviços ou ambientes. O adaptador agrega as ferramentas de todos os servidores especificados, tornando-as disponíveis para seus agentes CrewAI.

## Configuração

Para conectar-se a múltiplos servidores, você fornece uma lista de dicionários de parâmetros de servidor para o `MCPServerAdapter`. Cada dicionário na lista deve definir os parâmetros para um servidor MCP.

Os tipos de transporte suportados para cada servidor na lista incluem `stdio`, `sse` e `streamable-http`.

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter
from mcp import StdioServerParameters # Needed for Stdio example

# Define parameters for multiple MCP servers
server_params_list = [
    # Streamable HTTP Server
    {
        "url": "http://localhost:8001/mcp",
        "transport": "streamable-http"
    },
    # SSE Server
    {
        "url": "http://localhost:8000/sse",
        "transport": "sse"
    },
    # StdIO Server
    StdioServerParameters(
        command="python3",
        args=["servers/your_stdio_server.py"],
        env={"UV_PYTHON": "3.12", **os.environ},
    )
]

try:
    with MCPServerAdapter(server_params_list) as aggregated_tools:
        print(f"Available aggregated tools: {[tool.name for tool in aggregated_tools]}")

        agente_multiservidor = Agent(
            role="Assistente Versátil",
            goal="Utilizar ferramentas de servidores MCP locais Stdio, remotos SSE e remotos HTTP.",
            backstory="Um agente de IA capaz de aproveitar um conjunto diversificado de ferramentas de múltiplas fontes.",
            tools=aggregated_tools, # Todas as ferramentas estão disponíveis aqui
            verbose=True,
        )

        ... # Your other agent, tasks, and crew code here

except Exception as e:
    print(f"Error connecting to or using multiple MCP servers (Managed): {e}")
    print("Ensure all MCP servers are running and accessible with correct configurations.")

```

## Gerenciamento de Conexão

Ao utilizar o gerenciador de contexto (`with` statement), o `MCPServerAdapter` gerencia o ciclo de vida (início e término) de todas as conexões aos servidores MCP configurados. Isso simplifica o gerenciamento de recursos e garante que todas as conexões sejam devidamente fechadas ao sair do contexto.


# Servidores MCP como Ferramentas no CrewAI
Source: https://docs.crewai.com/pt-BR/mcp/overview

Aprenda como integrar servidores MCP como ferramentas nos seus agentes CrewAI usando a biblioteca `crewai-tools`.

## Visão Geral

O [Model Context Protocol](https://modelcontextprotocol.io/introduction) (MCP) fornece uma maneira padronizada para agentes de IA fornecerem contexto para LLMs comunicando-se com serviços externos, conhecidos como Servidores MCP.
A biblioteca `crewai-tools` expande as capacidades do CrewAI permitindo que você integre facilmente ferramentas desses servidores MCP em seus agentes.
Isso oferece às suas crews acesso a um vasto ecossistema de funcionalidades.

Atualmente, suportamos os seguintes mecanismos de transporte:

* **Stdio**: para servidores locais (comunicação via entrada/saída padrão entre processos na mesma máquina)
* **Server-Sent Events (SSE)**: para servidores remotos (transmissão de dados unidirecional em tempo real do servidor para o cliente via HTTP)
* **Streamable HTTP**: para servidores remotos (comunicação flexível e potencialmente bidirecional via HTTP, geralmente utilizando SSE para streams do servidor para o cliente)

## Tutorial em Vídeo

Assista a este tutorial em vídeo para um guia abrangente sobre a integração do MCP com o CrewAI:

<iframe width="100%" height="400" src="https://www.youtube.com/embed/TpQ45lAZh48" title="CrewAI MCP Integration Guide" frameborder="0" style={{ borderRadius: '10px' }} allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

## Instalação

Antes de começar a usar MCP com `crewai-tools`, é necessário instalar a dependência extra `mcp` do `crewai-tools` com o seguinte comando:

```shell
uv pip install 'crewai-tools[mcp]'
```

## Conceitos Chave & Primeiros Passos

A classe `MCPServerAdapter` da `crewai-tools` é a principal forma de conectar-se a um servidor MCP e disponibilizar suas ferramentas aos seus agentes CrewAI. Ela suporta diferentes mecanismos de transporte e simplifica o gerenciamento de conexões.

O uso de um gerenciador de contexto Python (`with`) é a **abordagem recomendada** para o `MCPServerAdapter`. Ele lida automaticamente com a abertura e o fechamento da conexão com o servidor MCP.

```python
from crewai import Agent
from crewai_tools import MCPServerAdapter
from mcp import StdioServerParameters # Para servidor Stdio

# Exemplo de server_params (escolha um baseado no seu tipo de servidor):
# 1. Servidor Stdio:
server_params=StdioServerParameters(
    command="python3",
    args=["servers/your_server.py"],
    env={"UV_PYTHON": "3.12", **os.environ},
)

# 2. Servidor SSE:
server_params = {
    "url": "http://localhost:8000/sse",
    "transport": "sse"
}

# 3. Servidor Streamable HTTP:
server_params = {
    "url": "http://localhost:8001/mcp",
    "transport": "streamable-http"
}

# Exemplo de uso (descomente e adapte após definir server_params):
with MCPServerAdapter(server_params) as mcp_tools:
    print(f"Available tools: {[tool.name for tool in mcp_tools]}")

    meu_agente = Agent(
        role="Usuário de Ferramentas MCP",
        goal="Utilizar ferramentas de um servidor MCP.",
        backstory="Posso conectar a servidores MCP e usar suas ferramentas.",
        tools=mcp_tools, # Passe as ferramentas carregadas para o seu agente
        reasoning=True,
        verbose=True
    )
    # ... restante da configuração do seu crew ...
```

Este padrão geral mostra como integrar ferramentas. Para exemplos específicos para cada transporte, consulte os guias detalhados abaixo.

## Filtrando Ferramentas

```python
with MCPServerAdapter(server_params) as mcp_tools:
    print(f"Available tools: {[tool.name for tool in mcp_tools]}")

    meu_agente = Agent(
        role="Usuário de Ferramentas MCP",
        goal="Utilizar ferramentas de um servidor MCP.",
        backstory="Posso conectar a servidores MCP e usar suas ferramentas.",
        tools=mcp_tools["tool_name"], # Passe as ferramentas filtradas para o seu agente
        reasoning=True,
        verbose=True
    )
    # ... restante da configuração do seu crew ...
```

## Usando com CrewBase

Para usar ferramentas de servidores MCP dentro de uma classe CrewBase, utilize o método `mcp_tools`. As configurações dos servidores devem ser fornecidas via o atributo mcp\_server\_params. Você pode passar uma configuração única ou uma lista com múltiplas configurações.

```python
@CrewBase
class CrewWithMCP:
  # ... defina o arquivo de configuração de agentes e tasks ...

  mcp_server_params = [
    # Servidor Streamable HTTP
    {
        "url": "http://localhost:8001/mcp",
        "transport": "streamable-http"
    },
    # Servidor SSE
    {
        "url": "http://localhost:8000/sse",
        "transport": "sse"
    },
    # Servidor StdIO
    StdioServerParameters(
        command="python3",
        args=["servers/your_stdio_server.py"],
        env={"UV_PYTHON": "3.12", **os.environ},
    )
  ]

  @agent
  def your_agent(self):
      return Agent(config=self.agents_config["your_agent"], tools=self.get_mcp_tools()) # você também pode filtrar quais ferramentas estarão disponíveis

    # ... restante da configuração do seu crew ...
```

## Explore Integrações MCP

<CardGroup cols={2}>
  <Card title="Transporte Stdio" icon="server" href="/pt-BR/mcp/stdio" color="#3B82F6">
    Conecte-se a servidores MCP locais via entrada/saída padrão. Ideal para scripts e executáveis locais.
  </Card>

  <Card title="Transporte SSE" icon="wifi" href="/pt-BR/mcp/sse" color="#10B981">
    Integre com servidores MCP remotos usando Server-Sent Events para streaming de dados em tempo real.
  </Card>

  <Card title="Transporte HTTP Streamable" icon="globe" href="/pt-BR/mcp/streamable-http" color="#F59E0B">
    Utilize HTTP Streamable para uma comunicação robusta com servidores MCP remotos.
  </Card>

  <Card title="Conectando a Múltiplos Servidores" icon="layer-group" href="/pt-BR/mcp/multiple-servers" color="#8B5CF6">
    Agregue ferramentas de vários servidores MCP simultaneamente usando um único adaptador.
  </Card>

  <Card title="Considerações de Segurança" icon="lock" href="/pt-BR/mcp/security" color="#EF4444">
    Revise práticas importantes de segurança para integração MCP e mantenha seus agentes protegidos.
  </Card>
</CardGroup>

Confira este repositório para demonstrações completas e exemplos de integração MCP com CrewAI! 👇

<Card title="Repositório GitHub" icon="github" href="https://github.com/tonykipkemboi/crewai-mcp-demo" target="_blank">
  Demo MCP do CrewAI
</Card>

## Segurança ao Usar MCP

<Warning>
  Sempre assegure-se de confiar no servidor MCP antes de utilizá-lo.
</Warning>

#### Aviso de Segurança: Ataques de DNS Rebinding

Transportes SSE podem ser vulneráveis a ataques de DNS rebinding se não forem devidamente protegidos.
Para prevenir isso:

1. **Sempre valide os cabeçalhos Origin** das conexões SSE recebidas para garantir que venham de fontes esperadas
2. **Evite vincular servidores a todas as interfaces de rede** (0.0.0.0) quando executando localmente – faça o bind apenas para localhost (127.0.0.1)
3. **Implemente autenticação adequada** para todas as conexões SSE

Sem essas proteções, invasores podem usar DNS rebinding para interagir com servidores MCP locais via sites remotos.

Para mais detalhes, consulte a [documentação de Segurança de Transporte da MCP da Anthropic](https://modelcontextprotocol.io/docs/concepts/transports#security-considerations).

### Limitações

* **Primitivas Suportadas**: Atualmente, o `MCPServerAdapter` suporta principalmente a adaptação de `tools` MCP.
  Outras primitivas MCP como `prompts` ou `resources` não são integradas diretamente como componentes CrewAI através deste adaptador por enquanto.
* **Manipulação de Saída**: O adaptador normalmente processa a saída principal de texto de uma ferramenta MCP (por exemplo, `.content[0].text`). Saídas complexas ou multimodais podem exigir tratamento customizado caso não se encaixem nesse padrão.


# Considerações de Segurança MCP
Source: https://docs.crewai.com/pt-BR/mcp/security

Saiba mais sobre as principais melhores práticas de segurança ao integrar servidores MCP com seus agentes CrewAI.

## Visão Geral

<Warning>
  O aspecto mais crítico da segurança MCP é a **confiança**. Você deve **apenas** conectar seus agentes CrewAI a servidores MCP nos quais confie plenamente.
</Warning>

Ao integrar serviços externos como servidores MCP (Model Context Protocol) aos seus agentes CrewAI, a segurança é fundamental.
Servidores MCP podem executar código, acessar dados ou interagir com outros sistemas com base nas ferramentas que expõem.
É crucial compreender as implicações e seguir as melhores práticas para proteger suas aplicações e dados.

### Riscos

* Executar código arbitrário na máquina onde o agente está rodando (especialmente com o transporte `Stdio` se o servidor puder controlar o comando executado).
* Expor dados sensíveis do seu agente ou do seu ambiente.
* Manipular o comportamento do seu agente de maneiras não intencionais, incluindo realizar chamadas de API não autorizadas em seu nome.
* Sequestrar o processo de raciocínio do agente através de técnicas sofisticadas de prompt injection (veja abaixo).

### 1. Confiando em Servidores MCP

<Warning>
  **Somente conecte-se a servidores MCP em que confie.**
</Warning>

Antes de configurar o `MCPServerAdapter` para conectar a um servidor MCP, certifique-se de saber:

* **Quem opera o servidor?** É um serviço conhecido, de reputação confiável, ou um servidor interno sob o seu controle?
* **Quais ferramentas ele expõe?** Entenda as capacidades das ferramentas. Elas poderiam ser mal utilizadas caso um invasor obtenha controle ou se o próprio servidor for malicioso?
* **Quais dados ele acessa ou processa?** Saiba se há informações sensíveis que possam ser enviadas ou manipuladas pelo servidor MCP.

Evite conectar-se a servidores MCP desconhecidos ou não verificados, especialmente se seus agentes lidam com tarefas ou dados sensíveis.

### 2. Prompt Injection Seguro via Metadados de Ferramentas: O Risco do "Model Control Protocol"

Um risco significativo e sutil é o potencial para prompt injection através dos metadados das ferramentas. Veja como funciona:

1. Quando seu agente CrewAI se conecta a um servidor MCP, ele normalmente solicita uma lista de ferramentas disponíveis.
2. O servidor MCP responde com metadados para cada ferramenta, incluindo nome, descrição e descrições de parâmetros.
3. O LLM (Modelo de Linguagem) subjacente do seu agente usa esses metadados para entender como e quando usar as ferramentas. Muitas vezes esses metadados são incorporados no system prompt ou contexto do LLM.
4. Um servidor MCP malicioso pode construir seus metadados (nomes, descrições) para incluir instruções ocultas ou explícitas. Essas instruções podem atuar como prompt injection, efetivamente fazendo o LLM se comportar de determinada maneira, revelar informações sensíveis ou executar ações maliciosas.

**Crucialmente, esse ataque pode ocorrer simplesmente ao conectar-se a um servidor malicioso e listar suas ferramentas, mesmo que seu agente nunca decida *usar* essas ferramentas.** A mera exposição aos metadados maliciosos pode ser suficiente para comprometer o comportamento do agente.

**Mitigação:**

* **Extrema Cautela com Servidores Não Confiáveis:** Reitere: *Não conecte-se a servidores MCP nos quais você não confie totalmente.* O risco de injection de metadados torna isso fundamental.

### Segurança do Transporte Stdio

O transporte Stdio (Entrada/Saída Padrão) é tipicamente usado para servidores MCP locais, rodando na mesma máquina que sua aplicação CrewAI.

* **Isolamento de Processo**: Embora geralmente seja mais seguro pois não envolve exposição de rede por padrão, assegure-se de que o script ou comando executado pelo `StdioServerParameters` é de uma fonte confiável e possui permissões de sistema de arquivos adequadas. Um script Stdio servidor malicioso pode ainda prejudicar seu sistema local.
* **Saneamento de Entrada**: Se o seu script de servidor Stdio recebe entradas complexas derivadas das interações do agente, garanta que o script saneie essas entradas para evitar injection de comandos ou outras vulnerabilidades na lógica do script.
* **Limite de Recursos**: Esteja atento ao fato de que o processo servidor Stdio consome recursos locais (CPU, memória). Assegure-se de que seja bem comportado, evitando esgotar os recursos do sistema.

### Ataques de Confused Deputy

O [Problema do Confused Deputy](https://en.wikipedia.org/wiki/Confused_deputy_problem) é uma vulnerabilidade clássica de segurança que pode se manifestar em integrações MCP, especialmente quando um servidor MCP atua como proxy para outros serviços de terceiros (ex: Google Calendar, GitHub) que usam OAuth 2.0 para autorização.

**Cenário:**

1. Um servidor MCP (vamos chamá-lo de `MCP-Proxy`) permite que seu agente interaja com o `ThirdPartyAPI`.
2. O `MCP-Proxy` usa seu próprio `client_id` estático ao comunicar-se com o servidor de autorização do `ThirdPartyAPI`.
3. Você, como usuário, autoriza legitimamente o `MCP-Proxy` a acessar o `ThirdPartyAPI` em seu nome. Durante esse processo, o servidor de autenticação pode definir um cookie no seu navegador indicando seu consentimento para o `client_id` do `MCP-Proxy`.
4. Um invasor cria um link malicioso. Esse link inicia um fluxo OAuth com o `MCP-Proxy`, mas é projetado para enganar o servidor de autenticação do `ThirdPartyAPI`.
5. Se você clicar nesse link e o servidor de autenticação do `ThirdPartyAPI` encontrar seu cookie de consentimento existente para o `client_id` do `MCP-Proxy`, pode *deixar de* pedir seu consentimento novamente.
6. O `MCP-Proxy` pode, então, ser enganado a encaminhar um código de autorização (para o `ThirdPartyAPI`) para o atacante, ou um código de autorização MCP que o atacante possa usar para se passar por você perante o `MCP-Proxy`.

**Mitigação (Principalmente para Desenvolvedores de Servidores MCP):**

* Servidores proxy MCP usando IDs de cliente estáticos para serviços downstream **devem** obter consentimento explícito do usuário para *cada aplicação cliente ou agente* conectando-se a eles *antes* de iniciar um fluxo OAuth com o serviço de terceiros. Isso significa que o `MCP-Proxy` deve exibir uma tela de consentimento.

**Implicação para Usuários CrewAI:**

* Fique atento se um servidor MCP redireciona você para múltiplas autenticações OAuth, especialmente se isso for inesperado ou se as permissões solicitadas forem muito amplas.
* Prefira servidores MCP que deixem clara sua própria identidade e a identidade dos serviços de terceiros que possam fazer proxy.

### Segurança no Transporte Remoto (SSE & HTTP Transmitível)

Ao conectar-se a servidores MCP remotos via Server-Sent Events (SSE) ou HTTP transmitível, práticas padrão de segurança web são essenciais.

### Considerações de Segurança SSE

### a. Ataques de DNS Rebinding (Especialmente para SSE)

<Critical>
  **Proteja-se contra ataques de DNS Rebinding.**
</Critical>

DNS rebinding permite que um site controlado por atacante contorne a política de mesma origem e faça requisições para servidores na rede local do usuário (ex: `localhost`) ou intranet. Isso é particularmente arriscado se você roda um servidor MCP localmente (ex: para desenvolvimento) e um agente em um ambiente do tipo navegador (embora menos comum no backend CrewAI) ou se o servidor MCP está em uma rede interna.

**Estratégias de Mitigação para Implementadores de Servidores MCP:**

* **Valide os Headers `Origin` e `Host`**: Servidores MCP (especialmente com SSE) devem validar os headers HTTP `Origin` e/ou `Host` para garantir que as requisições venham dos domínios/clientes esperados.
* **Ligue em `localhost` (127.0.0.1)**: Ao rodar servidores MCP localmente para desenvolvimento, conecte-se a `127.0.0.1` em vez de `0.0.0.0`. Isso impede que sejam acessíveis por outras máquinas na rede.
* **Autenticação**: Exija autenticação para todas as conexões ao seu servidor MCP caso não seja destinado a acesso público anônimo.

### b. Use HTTPS

* **Criptografe Dados em Trânsito**: Sempre use HTTPS (HTTP Seguro) para URLs de servidores MCP remotos. Isso criptografa a comunicação entre sua aplicação CrewAI e o servidor MCP, protegendo contra escuta e ataques Man-in-the-Middle (MitM). O `MCPServerAdapter` respeitará o esquema (`http` ou `https`) fornecido na URL.

### c. Token Passthrough (Anti-Padrão)

Isso é uma preocupação principalmente para desenvolvedores de servidores MCP, mas entender o conceito ajuda a escolher servidores seguros.

"Token passthrough" é quando um servidor MCP aceita um token de acesso do seu agente CrewAI (que pode ser um token para um serviço *diferente*, por exemplo, `ServiceA`) e simplesmente o repassa para outra API ( `ServiceB`) downstream sem validação adequada. Especificamente, `ServiceB` (ou o próprio servidor MCP) só deveria aceitar tokens explicitamente emitidos *para eles* (ou seja, o claim 'audience' no token deve corresponder ao servidor/serviço).

**Riscos:**

* Burlar controles de segurança (como limites de taxa ou permissões granulares) no servidor MCP ou na API downstream.
* Quebra trilhas de auditoria e responsabilização.
* Permite uso indevido de tokens roubados.

**Mitigação (Para Desenvolvedores de Servidores MCP):**

* Servidores MCP **NÃO DEVEM** aceitar tokens que não foram explicitamente emitidos para eles. Devem validar o claim de audiência dos tokens.

**Implicação para Usuários CrewAI:**

* Embora isso não seja diretamente controlável pelo usuário, destaca a importância de conectar-se a servidores MCP bem projetados e que sigam as melhores práticas de segurança.

#### Autenticação e Autorização

* **Verifique a Identidade**: Se o servidor MCP fornece ferramentas sensíveis ou acesso a dados privados, ele DEVE implementar mecanismos de autenticação robustos para verificar a identidade do cliente (sua aplicação CrewAI). Isso pode envolver chaves de API, tokens OAuth ou outros métodos padrão.
* **Princípio do Menor Privilégio**: Certifique-se de que as credenciais usadas pelo `MCPServerAdapter` (se houver) tenham apenas as permissões necessárias para acessar as ferramentas requeridas.

### d. Validação e Saneamento de Entrada

* **Validação de Entrada é Crítica**: Servidores MCP **devem** validar rigorosamente todas as entradas recebidas de agentes *antes* de processá-las ou passá-las para as ferramentas. Esta é a principal defesa contra diversas vulnerabilidades comuns:
  * **Injection de Comando:** Caso uma ferramenta construa comandos de shell, queries SQL ou outras instruções de linguagens interpretadas a partir da entrada, o servidor deve sanitizar cuidadosamente esta entrada para evitar que comandos maliciosos sejam injetados e executados.
  * **Path Traversal:** Se uma ferramenta acessa arquivos com base em parâmetros de entrada, o servidor deve validar e sanitizar esses caminhos para evitar acesso a arquivos ou diretórios não autorizados (por exemplo, bloqueando sequências `../`).
  * **Verificações de Tipo e Faixa de Dados:** Servidores devem garantir que os dados de entrada estejam nos tipos esperados (ex: string, número, booleano) e dentro de faixas aceitáveis ou em formatos definidos (ex: regex para URLs).
  * **Validação de Schema JSON:** Todos os parâmetros das ferramentas devem ser validados estritamente com seus esquemas JSON definidos. Isso ajuda a capturar requisições mal formatadas precocemente.
* **Atenção do Lado do Cliente**: Embora a validação no servidor seja fundamental, como usuário CrewAI, fique atento aos dados que seus agentes são configurados para enviar a ferramentas MCP, especialmente ao interagir com servidores MCP novos ou menos confiáveis.

### e. Limite de Taxa e Gerenciamento de Recursos

* **Previna Abusos**: Servidores MCP devem implementar limite de taxa para prevenir abusos, seja intencional (ataques de negação de serviço) ou não intencional (ex: um agente mal configurado fazendo muitas requisições).
* **Re-tentativas do Lado do Cliente**: Implemente lógica de repetição sensata em suas tarefas CrewAI se problemas de rede transitórios ou limites de taxa do servidor forem esperados, mas evite re-tentativas agressivas que possam aumentar a carga do servidor.

## 4. Conselhos para Implementação de Servidor MCP Seguro (Para Desenvolvedores)

Se você está desenvolvendo um servidor MCP ao qual agentes CrewAI possam se conectar, considere estas melhores práticas além dos pontos acima:

* **Siga Práticas de Código Seguro**: Adote princípios padrão de programação segura para sua linguagem e framework escolhidos (ex: OWASP Top 10).
* **Princípio do Menor Privilégio**: Certifique-se de que o processo que executa o servidor MCP (especialmente para `Stdio`) tenha apenas as permissões mínimas necessárias. As próprias ferramentas também devem operar com o mínimo de privilégio necessário para executar sua função.
* **Gerenciamento de Dependências**: Mantenha todas as dependências do lado do servidor, incluindo pacotes do sistema operacional, runtimes de linguagem e bibliotecas de terceiros, sempre atualizadas para corrigir vulnerabilidades conhecidas. Use ferramentas para escanear por dependências vulneráveis.
* **Padrões Seguros por Padrão**: Projete seu servidor e suas ferramentas para serem seguros por padrão. Por exemplo, recursos potencialmente arriscados devem ser desabilitados por padrão ou requerer ativação explícita, com avisos claros.
* **Controle de Acesso para Ferramentas**: Implemente mecanismos robustos para controlar quais agentes ou usuários autenticados e autorizados podem acessar ferramentas específicas, especialmente as que são poderosas, sensíveis ou incorram em custos.
* **Tratamento Seguro de Erros**: Servidores não devem expor mensagens detalhadas de erro interno, traces de stack ou informações de debug para o cliente, pois estas podem revelar detalhes internos ou potenciais vulnerabilidades. Logue os erros de forma abrangente no lado do servidor para diagnóstico.
* **Log e Monitoramento Abrangentes**: Implemente um log detalhado de eventos relevantes para segurança (ex: tentativas de autenticação, invocações de ferramenta, erros, mudanças de autorização). Monitore esses logs em busca de atividades suspeitas ou padrões de abuso.
* **Aderência à Especificação de Autorização MCP**: Caso implemente autenticação e autorização, siga estritamente a [especificação de autorização MCP](https://modelcontextprotocol.io/specification/draft/basic/authorization) e as [melhores práticas de segurança OAuth 2.0](https://datatracker.ietf.org/doc/html/rfc9700) relevantes.
* **Auditorias de Segurança Regulares**: Caso seu servidor MCP manipule dados sensíveis, realize operações críticas ou seja exposto publicamente, considere auditorias de segurança periódicas conduzidas por profissionais qualificados.

## 5. Leituras Adicionais

Para informações mais detalhadas sobre segurança MCP, consulte a documentação oficial:

* **[Segurança de Transporte MCP](https://modelcontextprotocol.io/docs/concepts/transports#security-considerations)**

Ao entender essas considerações de segurança e implementar as melhores práticas, você pode aproveitar com segurança o poder dos servidores MCP em seus projetos CrewAI.
Estes pontos não esgotam o assunto, mas cobrem as questões de segurança mais comuns e críticas.
As ameaças continuarão a evoluir, por isso é importante se manter informado e adaptar suas medidas de segurança de acordo.


# Transporte SSE
Source: https://docs.crewai.com/pt-BR/mcp/sse

Saiba como conectar o CrewAI a servidores MCP remotos usando Server-Sent Events (SSE) para comunicação em tempo real.

## Visão Geral

Server-Sent Events (SSE) fornecem uma forma padrão para um servidor web enviar atualizações a um cliente através de uma única conexão HTTP de longa duração. No contexto do MCP, SSE é utilizado para que servidores remotos transmitam dados (como respostas de ferramentas) para sua aplicação CrewAI em tempo real.

## Conceitos-Chave

* **Servidores Remotos**: SSE é adequado para servidores MCP hospedados remotamente.
* **Fluxo Unidirecional**: Normalmente, SSE é um canal de comunicação de mão única, do servidor para o cliente.
* **Configuração do `MCPServerAdapter`**: Para SSE, você fornecerá a URL do servidor e especificará o tipo de transporte.

## Conectando via SSE

Você pode se conectar a um servidor MCP baseado em SSE usando duas abordagens principais para gerenciar o ciclo de vida da conexão:

### 1. Conexão Totalmente Gerenciada (Recomendado)

Utilizar um gerenciador de contexto Python (`with` statement) é a abordagem recomendada. Ele lida automaticamente com o estabelecimento e o encerramento da conexão com o servidor MCP SSE.

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter

server_params = {
    "url": "http://localhost:8000/sse", # Replace with your actual SSE server URL
    "transport": "sse"
}

# Using MCPServerAdapter with a context manager
try:
    with MCPServerAdapter(server_params) as tools:
        print(f"Available tools from SSE MCP server: {[tool.name for tool in tools]}")

        # Example: Using a tool from the SSE MCP server
        agente_sse = Agent(
            role="Usuário de Serviço Remoto",
            goal="Utilizar uma ferramenta fornecida por um servidor MCP remoto via SSE.",
            backstory="Um agente de IA que conecta a serviços externos via SSE.",
            tools=tools,
            reasoning=True,
            verbose=True,
        )

        sse_task = Task(
            description="Buscar atualizações em tempo real das ações 'AAPL' usando uma ferramenta SSE.",
            expected_output="O preço mais recente da ação AAPL.",
            agent=agente_sse,
            markdown=True
        )

        sse_crew = Crew(
            agents=[agente_sse],
            tasks=[sse_task],
            verbose=True,
            process=Process.sequential
        )

        if tools: # Only kickoff if tools were loaded
            result = sse_crew.kickoff() # Add inputs={'stock_symbol': 'AAPL'} if tool requires it
            print("\nCrew Task Result (SSE - Managed):\n", result)
        else:
            print("Skipping crew kickoff as tools were not loaded (check server connection).")

except Exception as e:
    print(f"Error connecting to or using SSE MCP server (Managed): {e}")
    print("Ensure the SSE MCP server is running and accessible at the specified URL.")

```

<Note>
  Substitua `"http://localhost:8000/sse"` pela URL real do seu servidor MCP SSE.
</Note>

### 2. Ciclo de Vida Manual da Conexão

Caso precise de um controle mais detalhado, você pode gerenciar manualmente o ciclo de vida da conexão do `MCPServerAdapter`.

<Info>
  Você **DEVE** chamar `mcp_server_adapter.stop()` para garantir que a conexão seja encerrada e os recursos liberados. O uso de um bloco `try...finally` é altamente recomendado.
</Info>

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter

server_params = {
    "url": "http://localhost:8000/sse", # Replace with your actual SSE server URL
    "transport": "sse"
}

mcp_server_adapter = None
try:
    mcp_server_adapter = MCPServerAdapter(server_params)
    mcp_server_adapter.start()
    tools = mcp_server_adapter.tools
    print(f"Available tools (manual SSE): {[tool.name for tool in tools]}")

    manual_sse_agent = Agent(
        role="Analista Remoto de Dados",
        goal="Analisar dados obtidos de um servidor MCP remoto SSE usando gerenciamento manual de conexão.",
        backstory="Um agente de IA especializado em gerenciar conexões SSE explicitamente.",
        tools=tools,
        verbose=True
    )

    analysis_task = Task(
        description="Buscar e analisar as tendências mais recentes de atividade de usuários do servidor SSE.",
        expected_output="Um relatório resumido das tendências de atividade dos usuários.",
        agent=manual_sse_agent
    )

    analysis_crew = Crew(
        agents=[manual_sse_agent],
        tasks=[analysis_task],
        verbose=True,
        process=Process.sequential
    )

    result = analysis_crew.kickoff()
    print("\nCrew Task Result (SSE - Manual):\n", result)

except Exception as e:
    print(f"An error occurred during manual SSE MCP integration: {e}")
    print("Ensure the SSE MCP server is running and accessible.")
finally:
    if mcp_server_adapter and mcp_server_adapter.is_connected:
        print("Stopping SSE MCP server connection (manual)...")
        mcp_server_adapter.stop()  # **Crucial: Ensure stop is called**
    elif mcp_server_adapter:
        print("SSE MCP server adapter was not connected. No stop needed or start failed.")

```

## Considerações de Segurança para SSE

<Warning>
  **Ataques de DNS Rebinding**: Transportes SSE podem ser vulneráveis a ataques de DNS rebinding se o servidor MCP não estiver devidamente protegido. Isso pode permitir que sites maliciosos interajam com servidores MCP locais ou da intranet.
</Warning>

Para mitigar esse risco:

* As implementações do servidor MCP devem **validar os cabeçalhos `Origin`** em conexões SSE recebidas.
* Ao rodar servidores MCP SSE locais para desenvolvimento, **faça o bind apenas em `localhost` (`127.0.0.1`)** ao invés de todas as interfaces de rede (`0.0.0.0`).
* Implemente **autenticação adequada** para todas as conexões SSE caso exponham ferramentas ou dados sensíveis.

Para uma visão abrangente das melhores práticas de segurança, consulte nossa página de [Considerações de Segurança](./security.mdx) e a documentação oficial [MCP Transport Security](https://modelcontextprotocol.io/docs/concepts/transports#security-considerations).


# Transporte Stdio
Source: https://docs.crewai.com/pt-BR/mcp/stdio

Aprenda como conectar o CrewAI a servidores MCP locais usando o mecanismo de transporte Stdio (Entrada/Saída Padrão).

## Visão Geral

O transporte Stdio (Entrada/Saída Padrão) é projetado para conectar o `MCPServerAdapter` a servidores MCP locais que se comunicam por meio de seus fluxos de entrada e saída padrão. Isso é normalmente utilizado quando o servidor MCP é um script ou executável rodando na mesma máquina da sua aplicação CrewAI.

## Conceitos-Chave

* **Execução Local**: O transporte Stdio gerencia um processo localmente em execução para o servidor MCP.
* **`StdioServerParameters`**: Esta classe da biblioteca `mcp` é usada para configurar o comando, argumentos e variáveis de ambiente para iniciar o servidor Stdio.

## Conectando via Stdio

Você pode se conectar a um servidor MCP baseado em Stdio usando duas abordagens principais para gerenciar o ciclo de vida da conexão:

### 1. Conexão Totalmente Gerenciada (Recomendado)

Usar um context manager do Python (declaração `with`) é a abordagem recomendada. Ela lida automaticamente com o início do processo do servidor MCP e sua finalização quando o contexto é encerrado.

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter
from mcp import StdioServerParameters
import os

# Criar um objeto StdioServerParameters
server_params=StdioServerParameters(
    command="python3",
    args=["servers/your_stdio_server.py"],
    env={"UV_PYTHON": "3.12", **os.environ},
)

with MCPServerAdapter(server_params) as tools:
    print(f"Available tools from Stdio MCP server: {[tool.name for tool in tools]}")

    # Exemplo: Usando as ferramentas do servidor MCP Stdio em um Agente CrewAI
    pesquisador_local = Agent(
        role="Processador Local de Dados",
        goal="Processar dados usando uma ferramenta local baseada em Stdio.",
        backstory="Uma IA que utiliza scripts locais via MCP para tarefas especializadas.",
        tools=tools,
        reasoning=True,
        verbose=True,
    )

    processing_task = Task(
        description="Processar o arquivo de dados de entrada 'data.txt' e resumir seu conteúdo.",
        expected_output="Um resumo dos dados processados.",
        agent=pesquisador_local,
        markdown=True
    )

    data_crew = Crew(
        agents=[pesquisador_local],
        tasks=[processing_task],
        verbose=True,
        process=Process.sequential
    )

    result = data_crew.kickoff()
    print("\nCrew Task Result (Stdio - Managed):\n", result)

```

### 2. Ciclo de Vida Manual da Conexão

Se você precisa de um controle mais refinado sobre quando o processo do servidor MCP Stdio é iniciado e finalizado, pode gerenciar o ciclo de vida do `MCPServerAdapter` manualmente.

<Info>
  Você **DEVE** chamar `mcp_server_adapter.stop()` para garantir que o processo do servidor seja finalizado e os recursos, liberados. Recomenda-se fortemente o uso de um bloco `try...finally`.
</Info>

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter
from mcp import StdioServerParameters
import os

# Criar um objeto StdioServerParameters
stdio_params=StdioServerParameters(
    command="python3",
    args=["servers/your_stdio_server.py"],
    env={"UV_PYTHON": "3.12", **os.environ},
)

mcp_server_adapter = MCPServerAdapter(server_params=stdio_params)
try:
    mcp_server_adapter.start()  # Inicia manualmente a conexão e o processo do servidor
    tools = mcp_server_adapter.tools
    print(f"Available tools (manual Stdio): {[tool.name for tool in tools]}")

    # Exemplo: Usando as ferramentas com sua configuração de Agent, Task, Crew
    manual_agent = Agent(
        role="Executor Local de Tarefas",
        goal="Executar uma tarefa local específica usando uma ferramenta Stdio gerenciada manualmente.",
        backstory="Uma IA proficiente em controlar processos locais via MCP.",
        tools=tools,
        verbose=True
    )

    manual_task = Task(
        description="Executar o comando 'perform_analysis' via ferramenta Stdio.",
        expected_output="Resultados da análise.",
        agent=manual_agent
    )

    manual_crew = Crew(
        agents=[manual_agent],
        tasks=[manual_task],
        verbose=True,
        process=Process.sequential
    )


    result = manual_crew.kickoff() # As entradas reais dependem da sua ferramenta
    print("\nCrew Task Result (Stdio - Manual):\n", result)

except Exception as e:
    print(f"An error occurred during manual Stdio MCP integration: {e}")
finally:
    if mcp_server_adapter and mcp_server_adapter.is_connected: # Verifica se está conectado antes de parar
        print("Stopping Stdio MCP server connection (manual)...")
        mcp_server_adapter.stop()  # **Crucial: Assegure que stop seja chamado**
    elif mcp_server_adapter: # Se o adaptador existe mas não está conectado (ex.: start falhou)
        print("Stdio MCP server adapter was not connected. No stop needed or start failed.")

```

Lembre-se de substituir caminhos e comandos de exemplo pelos detalhes reais do seu servidor Stdio. O parâmetro `env` em `StdioServerParameters` pode ser usado para definir variáveis de ambiente para o processo do servidor, o que pode ser útil para configurar seu comportamento ou fornecer caminhos necessários (como `PYTHONPATH`).


# Transporte HTTP Streamable
Source: https://docs.crewai.com/pt-BR/mcp/streamable-http

Saiba como conectar o CrewAI a servidores MCP remotos usando o transporte HTTP Streamable flexível.

## Visão Geral

O transporte HTTP Streamable oferece uma maneira flexível de se conectar a servidores MCP remotos. Ele é frequentemente baseado em HTTP e pode suportar vários padrões de comunicação, incluindo requisição-resposta e streaming, às vezes utilizando Server-Sent Events (SSE) para fluxos do servidor para o cliente dentro de uma interação HTTP mais ampla.

## Conceitos-Chave

* **Servidores Remotos**: Projetado para servidores MCP hospedados remotamente.
* **Flexibilidade**: Pode suportar padrões de interação mais complexos do que SSE puro, potencialmente incluindo comunicação bidirecional se o servidor implementá-la.
* **Configuração do `MCPServerAdapter`**: Você precisará fornecer a URL base do servidor para comunicação MCP e especificar `"streamable-http"` como o tipo de transporte.

## Conectando via HTTP Streamable

Você tem dois métodos principais para gerenciar o ciclo de vida da conexão com um servidor MCP HTTP Streamable:

### 1. Conexão Totalmente Gerenciada (Recomendado)

A abordagem recomendada é usar um gerenciador de contexto Python (`with` statement), que lida automaticamente com a configuração e encerramento da conexão.

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter

server_params = {
    "url": "http://localhost:8001/mcp", # Replace with your actual Streamable HTTP server URL
    "transport": "streamable-http"
}

try:
    with MCPServerAdapter(server_params) as tools:
        print(f"Available tools from Streamable HTTP MCP server: {[tool.name for tool in tools]}")

        agente_http = Agent(
            role="Integrador de Serviços HTTP",
            goal="Utilizar ferramentas de um servidor MCP remoto via Streamable HTTP.",
            backstory="Um agente de IA especializado em interagir com serviços web complexos.",
            tools=tools,
            verbose=True,
        )

        http_task = Task(
            description="Realizar uma consulta de dados complexa usando uma ferramenta do servidor Streamable HTTP.",
            expected_output="O resultado da consulta de dados complexa.",
            agent=agente_http,
        )

        http_crew = Crew(
            agents=[agente_http],
            tasks=[http_task],
            verbose=True,
            process=Process.sequential
        )

        result = http_crew.kickoff()
        print("\nCrew Task Result (Streamable HTTP - Managed):\n", result)

except Exception as e:
    print(f"Error connecting to or using Streamable HTTP MCP server (Managed): {e}")
    print("Ensure the Streamable HTTP MCP server is running and accessible at the specified URL.")

```

**Nota:** Substitua `"http://localhost:8001/mcp"` pela URL real do seu servidor MCP HTTP Streamable.

### 2. Ciclo de Vida da Conexão Manual

Para cenários que exigem controle mais explícito, você pode gerenciar a conexão do `MCPServerAdapter` manualmente.

<Info>
  É **crítico** chamar `mcp_server_adapter.stop()` quando terminar para fechar a conexão e liberar recursos. Usar um bloco `try...finally` é a forma mais segura de garantir isso.
</Info>

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter

server_params = {
    "url": "http://localhost:8001/mcp", # Replace with your actual Streamable HTTP server URL
    "transport": "streamable-http"
}

mcp_server_adapter = None
try:
    mcp_server_adapter = MCPServerAdapter(server_params)
    mcp_server_adapter.start()
    tools = mcp_server_adapter.tools
    print(f"Available tools (manual Streamable HTTP): {[tool.name for tool in tools]}")

    manual_http_agent = Agent(
        role="Usuário Avançado de Serviços Web",
        goal="Interagir com um servidor MCP usando conexões HTTP Streamable gerenciadas manualmente.",
        backstory="Um especialista em IA em ajustar integrações baseadas em HTTP.",
        tools=tools,
        verbose=True
    )

    data_processing_task = Task(
        description="Enviar dados para processamento e recuperar resultados via Streamable HTTP.",
        expected_output="Dados processados ou confirmação.",
        agent=manual_http_agent
    )

    data_crew = Crew(
        agents=[manual_http_agent],
        tasks=[data_processing_task],
        verbose=True,
        process=Process.sequential
    )

    result = data_crew.kickoff()
    print("\nCrew Task Result (Streamable HTTP - Manual):\n", result)

except Exception as e:
    print(f"An error occurred during manual Streamable HTTP MCP integration: {e}")
    print("Ensure the Streamable HTTP MCP server is running and accessible.")
finally:
    if mcp_server_adapter and mcp_server_adapter.is_connected:
        print("Stopping Streamable HTTP MCP server connection (manual)...")
        mcp_server_adapter.stop()  # **Crucial: Ensure stop is called**
    elif mcp_server_adapter:
        print("Streamable HTTP MCP server adapter was not connected. No stop needed or start failed.")
```

## Considerações de Segurança

Ao utilizar o transporte HTTP Streamable, as melhores práticas gerais de segurança web são fundamentais:

* **Use HTTPS**: Sempre prefira HTTPS (HTTP Seguro) para as URLs do seu servidor MCP para criptografar os dados em trânsito.
* **Autenticação**: Implemente mecanismos robustos de autenticação se seu servidor MCP expuser ferramentas ou dados sensíveis.
* **Validação de Entrada**: Garanta que seu servidor MCP valide todas as requisições e parâmetros recebidos.

Para um guia abrangente sobre como proteger suas integrações MCP, consulte nossa página de [Considerações de Segurança](./security.mdx) e a documentação oficial de [Segurança em Transportes MCP](https://modelcontextprotocol.io/docs/concepts/transports#security-considerations).


# Integração com AgentOps
Source: https://docs.crewai.com/pt-BR/observability/agentops

Entendendo e registrando a performance do seu agente com AgentOps.

# Introdução

Observabilidade é um aspecto fundamental no desenvolvimento e implantação de agentes de IA conversacional. Ela permite que desenvolvedores compreendam como seus agentes estão performando,
como eles estão interagindo com os usuários e como utilizam ferramentas externas e APIs.
AgentOps é um produto independente do CrewAI que fornece uma solução completa de observabilidade para agentes.

## AgentOps

[AgentOps](https://agentops.ai/?=crew) oferece replay de sessões, métricas e monitoramento para agentes.

Em um alto nível, o AgentOps oferece a capacidade de monitorar custos, uso de tokens, latência, falhas do agente, estatísticas de sessão e muito mais.
Para mais informações, confira o [Repositório do AgentOps](https://github.com/AgentOps-AI/agentops).

### Visão Geral

AgentOps fornece monitoramento para agentes em desenvolvimento e produção.
Disponibiliza um dashboard para acompanhamento de performance dos agentes, replay de sessões e relatórios personalizados.

Além disso, o AgentOps traz análises detalhadas das sessões para visualizar interações do agente Crew, chamadas LLM e uso de ferramentas em tempo real.
Esse recurso é útil para depuração e entendimento de como os agentes interagem com usuários e entre si.

![Visão geral de uma série selecionada de execuções de sessões do agente](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/agentops-overview.png)
![Visão geral das análises detalhadas de sessões para examinar execuções de agentes](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/agentops-session.png)
![Visualizando um gráfico de execução passo a passo do replay do agente](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/agentops-replay.png)

### Funcionalidades

* **Gerenciamento e Rastreamento de Custos de LLM**: Acompanhe gastos com provedores de modelos fundamentais.
* **Análises de Replay**: Assista gráficos de execução do agente, passo a passo.
* **Detecção de Pensamento Recursivo**: Identifique quando agentes entram em loops infinitos.
* **Relatórios Personalizados**: Crie análises customizadas sobre a performance dos agentes.
* **Dashboard Analítico**: Monitore estatísticas gerais de agentes em desenvolvimento e produção.
* **Teste de Modelos Públicos**: Teste seus agentes em benchmarks e rankings.
* **Testes Personalizados**: Execute seus agentes em testes específicos de domínio.
* **Depuração com Viagem no Tempo**: Reinicie suas sessões a partir de checkpoints.
* **Conformidade e Segurança**: Crie registros de auditoria e detecte possíveis ameaças como uso de palavrões e vazamento de dados pessoais.
* **Detecção de Prompt Injection**: Identifique possíveis injeções de código e vazamentos de segredos.

### Utilizando o AgentOps

<Steps>
  <Step title="Crie uma Chave de API">
    Crie uma chave de API de usuário aqui: [Create API Key](https://app.agentops.ai/account)
  </Step>

  <Step title="Configure seu Ambiente">
    Adicione sua chave API nas variáveis de ambiente:

    ```bash
    AGENTOPS_API_KEY=<YOUR_AGENTOPS_API_KEY>
    ```
  </Step>

  <Step title="Instale o AgentOps">
    Instale o AgentOps com:

    ```bash
    pip install 'crewai[agentops]'
    ```

    ou

    ```bash
    pip install agentops
    ```
  </Step>

  <Step title="Inicialize o AgentOps">
    Antes de utilizar o `Crew` no seu script, inclua estas linhas:

    ```python
    import agentops
    agentops.init()
    ```

    Isso irá iniciar uma sessão do AgentOps e também rastrear automaticamente os agentes Crew. Para mais detalhes sobre como adaptar sistemas de agentes mais complexos,
    confira a [documentação do AgentOps](https://docs.agentops.ai) ou participe do [Discord](https://discord.gg/j4f3KbeH).
  </Step>
</Steps>

### Exemplos de Crew + AgentOps

<CardGroup cols={3}>
  <Card title="Vaga de Emprego" color="#F3A78B" href="https://github.com/joaomdmoura/crewAI-examples/tree/main/job-posting" icon="briefcase" iconType="solid">
    Exemplo de um agente Crew que gera vagas de emprego.
  </Card>

  <Card title="Validador de Markdown" color="#F3A78B" href="https://github.com/joaomdmoura/crewAI-examples/tree/main/markdown_validator" icon="markdown" iconType="solid">
    Exemplo de um agente Crew que valida arquivos Markdown.
  </Card>

  <Card title="Post no Instagram" color="#F3A78B" href="https://github.com/joaomdmoura/crewAI-examples/tree/main/instagram_post" icon="square-instagram" iconType="brands">
    Exemplo de um agente Crew que gera posts para Instagram.
  </Card>
</CardGroup>

### Mais Informações

Para começar, crie uma [conta AgentOps](https://agentops.ai/?=crew).

Para sugestões de funcionalidades ou relatos de bugs, entre em contato com o time do AgentOps pelo [Repositório do AgentOps](https://github.com/AgentOps-AI/agentops).

#### Links Extras

<a href="https://twitter.com/agentopsai/">🐦 Twitter</a>
<span>  •  </span>
<a href="https://discord.gg/JHPt4C7r">📢 Discord</a>
<span>  •  </span>
<a href="https://app.agentops.ai/?=crew">🖇️ Dashboard AgentOps</a>
<span>  •  </span>
<a href="https://docs.agentops.ai/introduction">📙 Documentação</a>


# Arize Phoenix
Source: https://docs.crewai.com/pt-BR/observability/arize-phoenix

Integração do Arize Phoenix para CrewAI com OpenTelemetry e OpenInference

# Integração com Arize Phoenix

Este guia demonstra como integrar o **Arize Phoenix** ao **CrewAI** usando o OpenTelemetry através do [OpenInference](https://github.com/openinference/openinference) SDK. Ao final deste guia, você será capaz de rastrear seus agentes CrewAI e depurá-los com facilidade.

> **O que é o Arize Phoenix?** O [Arize Phoenix](https://phoenix.arize.com) é uma plataforma de observabilidade de LLM que oferece rastreamento e avaliação para aplicações de IA.

[![Assista a um vídeo demonstrando a nossa integração com o Phoenix](https://storage.googleapis.com/arize-assets/fixtures/setup_crewai.png)](https://www.youtube.com/watch?v=Yc5q3l6F7Ww)

## Primeiros Passos

Vamos percorrer um exemplo simples de uso do CrewAI e integração com o Arize Phoenix via OpenTelemetry utilizando o OpenInference.

Você também pode acessar este guia no [Google Colab](https://colab.research.google.com/github/Arize-ai/phoenix/blob/main/tutorials/tracing/crewai_tracing_tutorial.ipynb).

### Passo 1: Instale as Dependências

```bash
pip install openinference-instrumentation-crewai crewai crewai-tools arize-phoenix-otel
```

### Passo 2: Configure as Variáveis de Ambiente

Configure as chaves de API do Phoenix Cloud e ajuste o OpenTelemetry para enviar rastros ao Phoenix. O Phoenix Cloud é uma versão hospedada do Arize Phoenix, mas não é obrigatório para utilizar esta integração.

Você pode obter uma chave de API gratuita do Serper [aqui](https://serper.dev/).

```python
import os
from getpass import getpass

# Obtenha suas credenciais do Phoenix Cloud
PHOENIX_API_KEY = getpass("🔑 Digite sua Phoenix Cloud API Key: ")

# Obtenha as chaves de API para os serviços
OPENAI_API_KEY = getpass("🔑 Digite sua OpenAI API key: ")
SERPER_API_KEY = getpass("🔑 Digite sua Serper API key: ")

# Defina as variáveis de ambiente
os.environ["PHOENIX_CLIENT_HEADERS"] = f"api_key={PHOENIX_API_KEY}"
os.environ["PHOENIX_COLLECTOR_ENDPOINT"] = "https://app.phoenix.arize.com" # Phoenix Cloud, altere para seu endpoint se estiver utilizando uma instância self-hosted
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
os.environ["SERPER_API_KEY"] = SERPER_API_KEY
```

### Passo 3: Inicialize o OpenTelemetry com o Phoenix

Inicialize o SDK de instrumentação OpenTelemetry do OpenInference para começar a capturar rastros e enviá-los ao Phoenix.

```python
from phoenix.otel import register

tracer_provider = register(
    project_name="crewai-tracing-demo",
    auto_instrument=True,
)
```

### Passo 4: Crie uma Aplicação CrewAI

Vamos criar uma aplicação CrewAI em que dois agentes colaboram para pesquisar e escrever um post de blog sobre avanços em IA.

```python
from crewai import Agent, Crew, Process, Task
from crewai_tools import SerperDevTool
from openinference.instrumentation.crewai import CrewAIInstrumentor
from phoenix.otel import register

# configure o monitoramento para seu crew
tracer_provider = register(
    endpoint="http://localhost:6006/v1/traces")
CrewAIInstrumentor().instrument(skip_dep_check=True, tracer_provider=tracer_provider)
search_tool = SerperDevTool()

# Defina seus agentes com papéis e objetivos
pesquisador = Agent(
    role="Analista Sênior de Pesquisa",
    goal="Descobrir os avanços mais recentes em IA e ciência de dados",
    backstory="""
Você trabalha em um importante think tank de tecnologia. Sua especialidade é identificar tendências emergentes. Você tem habilidade para dissecar dados complexos e apresentar insights acionáveis.
""",
    verbose=True,
    allow_delegation=False,
    tools=[search_tool],
)
writer = Agent(
    role="Estrategista de Conteúdo Técnico",
    goal="Criar conteúdo envolvente sobre avanços tecnológicos",
    backstory="Você é um Estrategista de Conteúdo renomado, conhecido por seus artigos perspicazes e envolventes. Você transforma conceitos complexos em narrativas atraentes.",
    verbose=True,
    allow_delegation=True,
)

# Crie tarefas para seus agentes
task1 = Task(
    description="Realize uma análise abrangente dos avanços mais recentes em IA em 2024. Identifique tendências-chave, tecnologias inovadoras e impactos potenciais na indústria.",
    expected_output="Relatório analítico completo em tópicos",
    agent=pesquisador,
)

task2 = Task(
    description="Utilizando os insights fornecidos, desenvolva um blog envolvente destacando os avanços mais significativos em IA. O post deve ser informativo e acessível, voltado para um público técnico. Dê um tom interessante, evite palavras complexas para não soar como IA.",
    expected_output="Post de blog completo com pelo menos 4 parágrafos",
    agent=writer,
)

# Instancie seu crew com um processo sequencial
crew = Crew(
    agents=[pesquisador, writer], tasks=[task1, task2], verbose=1, process=Process.sequential
)

# Coloque seu crew para trabalhar!
result = crew.kickoff()

print("######################")
print(result)
```

### Passo 5: Visualize os Rastros no Phoenix

Após executar o agente, você poderá visualizar os rastros gerados pela sua aplicação CrewAI no Phoenix. Você verá etapas detalhadas das interações dos agentes e chamadas de LLM, o que pode ajudar na depuração e otimização dos seus agentes de IA.

Acesse sua conta Phoenix Cloud e navegue até o projeto que você especificou no parâmetro `project_name`. Você verá uma visualização de linha do tempo do seu rastro, incluindo todas as interações dos agentes, uso de ferramentas e chamadas LLM.

![Exemplo de rastro no Phoenix mostrando interações de agentes](https://storage.googleapis.com/arize-assets/fixtures/crewai_traces.png)

### Informações de Compatibilidade de Versão

* Python 3.8+
* CrewAI >= 0.86.0
* Arize Phoenix >= 7.0.1
* OpenTelemetry SDK >= 1.31.0

### Referências

* [Documentação do Phoenix](https://docs.arize.com/phoenix/) - Visão geral da plataforma Phoenix.
* [Documentação do CrewAI](https://docs.crewai.com/) - Visão geral do framework CrewAI.
* [Documentação do OpenTelemetry](https://opentelemetry.io/docs/) - Guia do OpenTelemetry
* [OpenInference GitHub](https://github.com/openinference/openinference) - Código-fonte do SDK OpenInference.


# Integração Langfuse
Source: https://docs.crewai.com/pt-BR/observability/langfuse

Saiba como integrar o Langfuse ao CrewAI via OpenTelemetry usando OpenLit

# Integre o Langfuse ao CrewAI

Este notebook demonstra como integrar o **Langfuse** ao **CrewAI** usando OpenTelemetry via o SDK **OpenLit**. Ao final deste notebook, você será capaz de rastrear suas aplicações CrewAI com o Langfuse para melhorar a observabilidade e a depuração.

> **O que é Langfuse?** [Langfuse](https://langfuse.com) é uma plataforma open-source de engenharia LLM. Ela fornece recursos de rastreamento e monitoramento para aplicações LLM, ajudando desenvolvedores a depurar, analisar e otimizar seus sistemas de IA. O Langfuse se integra com várias ferramentas e frameworks através de integrações nativas, OpenTelemetry e APIs/SDKs.

[![Vídeo de Visão Geral do Langfuse](https://github.com/user-attachments/assets/3926b288-ff61-4b95-8aa1-45d041c70866)](https://langfuse.com/watch-demo)

## Primeiros Passos

Vamos passar por um exemplo simples usando CrewAI e integrando ao Langfuse via OpenTelemetry utilizando o OpenLit.

### Passo 1: Instale as Dependências

```python
%pip install langfuse openlit crewai crewai_tools
```

### Passo 2: Configure as Variáveis de Ambiente

Defina suas chaves de API do Langfuse e configure as opções de exportação do OpenTelemetry para enviar os traces ao Langfuse. Consulte a [Documentação Langfuse OpenTelemetry](https://langfuse.com/docs/opentelemetry/get-started) para mais informações sobre o endpoint Langfuse OpenTelemetry `/api/public/otel` e autenticação.

```python
import os

# Obtenha as chaves do seu projeto na página de configurações do projeto: https://cloud.langfuse.com
os.environ["LANGFUSE_PUBLIC_KEY"] = "pk-lf-..."
os.environ["LANGFUSE_SECRET_KEY"] = "sk-lf-..."
os.environ["LANGFUSE_HOST"] = "https://cloud.langfuse.com" # 🇪🇺 Região UE
# os.environ["LANGFUSE_HOST"] = "https://us.cloud.langfuse.com" # 🇺🇸 Região EUA


# Sua chave OpenAI
os.environ["OPENAI_API_KEY"] = "sk-proj-..."
```

Com as variáveis de ambiente configuradas, agora podemos inicializar o cliente Langfuse. A função get\_client() inicializa o cliente Langfuse usando as credenciais fornecidas nas variáveis de ambiente.

```python
from langfuse import get_client

langfuse = get_client()

# Verificar conexão
if langfuse.auth_check():
    print("Cliente Langfuse autenticado e pronto!")
else:
    print("Falha na autenticação. Verifique suas credenciais e host.")
```

### Passo 3: Inicialize o OpenLit

Inicialize o SDK de instrumentação OpenTelemetry do OpenLit para começar a capturar traces do OpenTelemetry.

```python
import openlit

openlit.init()
```

### Passo 4: Crie uma Aplicação Simples CrewAI

Vamos criar uma aplicação simples CrewAI onde múltiplos agentes colaboram para responder à pergunta de um usuário.

```python
from crewai import Agent, Task, Crew

from crewai_tools import (
    WebsiteSearchTool
)

web_rag_tool = WebsiteSearchTool()

escritor = Agent(
    role="Escritor",
    goal="Você torna a matemática envolvente e compreensível para crianças pequenas através de poesias",
    backstory="Você é especialista em escrever haicais mas não sabe nada de matemática.",
    tools=[web_rag_tool],
)

tarefa = Task(description=("O que é {multiplicação}?"),
              expected_output=("Componha um haicai que inclua a resposta."),
              agent=escritor)

equipe = Crew(
  agents=[escritor],
  tasks=[tarefa],
  share_crew=False
)
```

### Passo 5: Veja os Traces no Langfuse

Após rodar o agente, você pode visualizar os traces gerados pela sua aplicação CrewAI no [Langfuse](https://cloud.langfuse.com). Você verá etapas detalhadas das interações do LLM, o que pode ajudar na depuração e otimização do seu agente de IA.

![Exemplo de trace CrewAI no Langfuse](https://langfuse.com/images/cookbook/integration_crewai/crewai-example-trace.png)

*[Exemplo público de trace no Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/e2cf380ffc8d47d28da98f136140642b?timestamp=2025-02-05T15%3A12%3A02.717Z\&observation=3b32338ee6a5d9af)*

## Referências

* [Documentação Langfuse OpenTelemetry](https://langfuse.com/docs/opentelemetry/get-started)


# Integração com Langtrace
Source: https://docs.crewai.com/pt-BR/observability/langtrace

Como monitorar custo, latência e desempenho dos Agentes CrewAI usando o Langtrace, uma ferramenta externa de observabilidade.

# Visão Geral do Langtrace

O Langtrace é uma ferramenta externa e open-source que auxilia na configuração de observabilidade e avaliações para Modelos de Linguagem de Grande Porte (LLMs), frameworks de LLM e Bancos de Dados Vetoriais.
Apesar de não ser integrado diretamente ao CrewAI, o Langtrace pode ser utilizado em conjunto com o CrewAI para fornecer uma visibilidade aprofundada sobre o custo, latência e desempenho dos seus Agentes CrewAI.
Essa integração permite o registro de hiperparâmetros, o monitoramento de regressões de desempenho e o estabelecimento de um processo de melhoria contínua dos seus Agentes.

![Visão geral de uma seleção de execuções de sessões de agentes](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/langtrace1.png)
![Visão geral dos traces de agentes](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/langtrace2.png)
![Visão detalhada dos traces de LLM](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/langtrace3.png)

## Instruções de Configuração

<Steps>
  <Step title="Crie uma conta no Langtrace">
    Cadastre-se acessando [https://langtrace.ai/signup](https://langtrace.ai/signup).
  </Step>

  <Step title="Crie um projeto">
    Defina o tipo do projeto como `CrewAI` e gere uma chave de API.
  </Step>

  <Step title="Instale o Langtrace no seu projeto CrewAI">
    Use o seguinte comando:

    ```bash
    pip install langtrace-python-sdk
    ```
  </Step>

  <Step title="Importe o Langtrace">
    Importe e inicialize o Langtrace no início do seu script, antes de quaisquer imports do CrewAI:

    ```python
    from langtrace_python_sdk import langtrace
    langtrace.init(api_key='<SUA_CHAVE_LANGTRACE>')

    # Agora importe os módulos do CrewAI
    from crewai import Agent, Task, Crew
    ```
  </Step>
</Steps>

### Funcionalidades e Sua Aplicação no CrewAI

1. **Rastreamento de Token e Custo do LLM**

   * Monitore o uso de tokens e os custos associados para cada interação dos agentes CrewAI.

2. **Gráfico de Trace para Etapas de Execução**

   * Visualize o fluxo de execução das suas tarefas CrewAI, incluindo latência e logs.
   * Útil para identificar gargalos nos fluxos de trabalho dos seus agentes.

3. **Curadoria de Dataset com Anotação Manual**

   * Crie conjuntos de dados a partir das saídas das suas tarefas CrewAI para futuros treinamentos ou avaliações.

4. **Versionamento e Gerenciamento de Prompt**

   * Acompanhe as diferentes versões de prompts utilizados em seus agentes CrewAI.
   * Útil para testes A/B e otimização de desempenho dos agentes.

5. **Playground de Prompt com Comparações de Modelos**

   * Teste e compare diferentes prompts e modelos para seus agentes CrewAI antes da implantação.

6. **Testes e Avaliações**

   * Configure testes automatizados para seus agentes e tarefas CrewAI.


# Integração Maxim
Source: https://docs.crewai.com/pt-BR/observability/maxim

Inicie o monitoramento, avaliação e observabilidade de agentes

# Integração Maxim

Maxim AI oferece monitoramento completo de agentes, avaliação e observabilidade para suas aplicações CrewAI. Com a integração de uma linha do Maxim, você pode facilmente rastrear e analisar interações dos agentes, métricas de desempenho e muito mais.

## Funcionalidades: Integração com Uma Linha

* **Rastreamento de Agentes de Ponta a Ponta**: Monitore todo o ciclo de vida dos seus agentes
* **Análise de Desempenho**: Acompanhe latência, tokens consumidos e custos
* **Monitoramento de Hiperparâmetros**: Visualize detalhes de configuração das execuções dos agentes
* **Rastreamento de Chamadas de Ferramentas**: Observe quando e como os agentes usam suas ferramentas
* **Visualização Avançada**: Entenda as trajetórias dos agentes através de dashboards intuitivos

## Começando

### Pré-requisitos

* Python versão >=3.10
* Uma conta Maxim ([cadastre-se aqui](https://getmaxim.ai/))
* Um projeto CrewAI

### Instalação

Instale o SDK do Maxim via pip:

```python
pip install maxim-py>=3.6.2
```

Ou adicione ao seu `requirements.txt`:

```
maxim-py>=3.6.2
```

### Configuração Básica

### 1. Configure as variáveis de ambiente

```python
### Configuração de Variáveis de Ambiente

# Crie um arquivo `.env` na raiz do seu projeto:

# Configuração da API Maxim
MAXIM_API_KEY=your_api_key_here
MAXIM_LOG_REPO_ID=your_repo_id_here
```

### 2. Importe os pacotes necessários

```python
from crewai import Agent, Task, Crew, Process
from maxim import Maxim
from maxim.logger.crewai import instrument_crewai
```

### 3. Inicialize o Maxim com sua chave de API

```python
# Inicialize o logger do Maxim
logger = Maxim().logger()

# Instrumente o CrewAI com apenas uma linha
instrument_crewai(logger)
```

### 4. Crie e execute sua aplicação CrewAI normalmente

```python
pesquisador = Agent(
    role='Pesquisador Sênior',
    goal='Descobrir os avanços mais recentes em IA',
    backstory="Você é um pesquisador especialista em um think tank de tecnologia...",
    verbose=True,
    llm=llm
)

# Defina a tarefa
research_task = Task(
    description="Pesquise os avanços mais recentes em IA...",
    expected_output="",
    agent=pesquisador
)

# Configure e execute a crew
crew = Crew(
    agents=[pesquisador],
    tasks=[research_task],
    verbose=True
)

try:
    result = crew.kickoff()
finally:
    maxim.cleanup()  # Garanta o cleanup mesmo em caso de erros
```

É isso! Todas as interações dos seus agentes CrewAI agora serão registradas e estarão disponíveis em seu painel Maxim.

Confira este Google Colab Notebook para referência rápida – [Notebook](https://colab.research.google.com/drive/1ZKIZWsmgQQ46n8TH9zLsT1negKkJA6K8?usp=sharing)

## Visualizando Seus Rastreamentos

Após executar sua aplicação CrewAI:

![Exemplo de rastreamento no Maxim mostrando interações de agentes](https://raw.githubusercontent.com/maximhq/maxim-docs/master/images/Screenshot2025-05-14at12.10.58PM.png)

1. Faça login no seu [Painel Maxim](https://getmaxim.ai/dashboard)
2. Navegue até seu repositório
3. Visualize rastreamentos detalhados de agentes, incluindo:
   * Conversas dos agentes
   * Padrões de uso de ferramentas
   * Métricas de desempenho
   * Análises de custos

## Solução de Problemas

### Problemas Comuns

* **Nenhum rastreamento aparecendo**: Certifique-se de que sua chave de API e o ID do repositório estão corretos

* Certifique-se de que você **chamou `instrument_crewai()`** ***antes*** de executar sua crew. Isso inicializa corretamente os hooks de logging.

* Defina `debug=True` na chamada do `instrument_crewai()` para expor erros internos:

  ```python
  instrument_crewai(logger, debug=True)
  ```

* Configure seus agentes com `verbose=True` para capturar logs detalhados:

  ```python

  agent = CrewAgent(..., verbose=True)
  ```

* Verifique cuidadosamente se `instrument_crewai()` foi chamado **antes** de criar ou executar agentes. Isso pode parecer óbvio, mas é um erro comum.

### Suporte

Se você encontrar algum problema:

* Consulte a [Documentação do Maxim](https://getmaxim.ai/docs)
* Maxim Github [Link](https://github.com/maximhq)


# Integração com MLflow
Source: https://docs.crewai.com/pt-BR/observability/mlflow

Comece rapidamente a monitorar seus Agents com MLflow.

# Visão Geral do MLflow

[MLflow](https://mlflow.org/) é uma plataforma open-source que auxilia profissionais e equipes de machine learning a lidar com as complexidades do processo de aprendizagem de máquina.

Ela oferece um recurso de tracing que aprimora a observabilidade de LLMs em suas aplicações de IA Generativa, capturando informações detalhadas sobre a execução dos serviços de sua aplicação.
O tracing fornece uma forma de registrar os inputs, outputs e metadados associados a cada etapa intermediária de uma requisição, permitindo que você identifique facilmente a origem de bugs e comportamentos inesperados.

![Visão geral do uso de tracing MLflow com crewAI](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/mlflow-tracing.gif)

### Funcionalidades

* **Painel de Tracing**: Monitore as atividades dos seus agentes crewAI com painéis detalhados que incluem entradas, saídas e metadados dos spans.
* **Tracing Automatizado**: Uma integração totalmente automatizada com crewAI, que pode ser habilitada executando `mlflow.crewai.autolog()`.
* **Instrumentação Manual de Tracing com pouco esforço**: Personalize a instrumentação dos traces usando as APIs de alto nível do MLflow, como decorators, wrappers de funções e context managers.
* **Compatibilidade com OpenTelemetry**: O MLflow Tracing suporta a exportação de traces para um OpenTelemetry Collector, que pode então ser usado para exportar traces para diversos backends como Jaeger, Zipkin e AWS X-Ray.
* **Empacote e Faça Deploy dos Agents**: Empacote e faça deploy de seus agents crewAI em um servidor de inferência com diversas opções de destino.
* **Hospede LLMs com Segurança**: Hospede múltiplos LLMs de vários provedores em um endpoint unificado através do gateway do MFflow.
* **Avaliação**: Avalie seus agents crewAI com uma ampla variedade de métricas utilizando a API conveniente `mlflow.evaluate()`.

## Instruções de Configuração

<Steps>
  <Step title="Instale o pacote MLflow">
    ```shell
    # A integração crewAI está disponível no mlflow>=2.19.0
    pip install mlflow
    ```
  </Step>

  <Step title="Inicie o servidor de tracking do MFflow">
    ```shell
    # Este processo é opcional, mas é recomendado utilizar o servidor de tracking do MLflow para melhor visualização e mais funcionalidades.
    mlflow server
    ```
  </Step>

  <Step title="Inicialize o MLflow em sua aplicação">
    Adicione as duas linhas a seguir ao código da sua aplicação:

    ```python
    import mlflow

    mlflow.crewai.autolog()

    # Opcional: Defina uma tracking URI e um nome de experimento caso utilize um servidor de tracking
    mlflow.set_tracking_uri("http://localhost:5000")
    mlflow.set_experiment("CrewAI")
    ```

    Exemplo de uso para tracing de Agents do CrewAI:

    ```python
    from crewai import Agent, Crew, Task
    from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource
    from crewai_tools import SerperDevTool, WebsiteSearchTool

    from textwrap import dedent

    content = "Users name is John. He is 30 years old and lives in San Francisco."
    string_source = StringKnowledgeSource(
        content=content, metadata={"preference": "personal"}
    )

    search_tool = WebsiteSearchTool()


    class TripAgents:
        def city_selection_agent(self):
            especialista_cidades = Agent(
                role="Especialista em Seleção de Cidades",
                goal="Selecionar a melhor cidade com base no clima, estação e preços",
                backstory="Especialista em analisar dados de viagem para escolher destinos ideais",
                tools=[search_tool],
                verbose=True,
            )

        def local_expert(self):
            especialista_local = Agent(
                role="Especialista Local nesta cidade",
                goal="Fornecer as MELHORES informações sobre a cidade selecionada",
                backstory="Um guia local experiente com amplo conhecimento sobre a cidade, suas atrações e costumes",
                tools=[search_tool],
                verbose=True,
            )


    class TripTasks:
        def identify_task(self, agent, origin, cities, interests, range):
            return Task(
                description=dedent(
                    f"""
                    Analise e selecione a melhor cidade para a viagem com base em critérios específicos como padrões climáticos, eventos sazonais e custos de viagem. Esta tarefa envolve comparar várias cidades, considerando fatores como condições climáticas atuais, eventos culturais ou sazonais e despesas gerais de viagem.
                    Sua resposta final deve ser um relatório detalhado sobre a cidade escolhida e tudo o que você descobriu sobre ela, incluindo custos reais de voo, previsão do tempo e atrações.

                    Saindo de: {origin}
                    Opções de cidades: {cities}
                    Data da viagem: {range}
                    Interesses do viajante: {interests}
                """
                ),
                agent=agent,
                expected_output="Relatório detalhado sobre a cidade escolhida incluindo custos de voo, previsão do tempo e atrações",
            )

        def gather_task(self, agent, origin, interests, range):
            return Task(
                description=dedent(
                    f"""
                    Como especialista local nesta cidade, você deve compilar um guia aprofundado para alguém que está viajando para lá e quer ter a MELHOR viagem possível!
                    Reúna informações sobre principais atrações, costumes locais, eventos especiais e recomendações de atividades diárias.
                    Encontre os melhores lugares para ir, aqueles que só um local conhece.
                    Este guia deve fornecer uma visão abrangente do que a cidade tem a oferecer, incluindo joias escondidas, pontos culturais, marcos imperdíveis, previsão do tempo e custos gerais.
                    A resposta final deve ser um guia completo da cidade, rico em insights culturais e dicas práticas, adaptado para aprimorar a experiência de viagem.

                    Data da viagem: {range}
                    Saindo de: {origin}
                    Interesses do viajante: {interests}
                """
                ),
                agent=agent,
                expected_output="Guia completo da cidade incluindo joias escondidas, pontos culturais e dicas práticas",
            )


    class TripCrew:
        def __init__(self, origin, cities, date_range, interests):
            self.cities = cities
            self.origin = origin
            self.interests = interests
            self.date_range = date_range

        def run(self):
            agents = TripAgents()
            tasks = TripTasks()

            city_selector_agent = agents.city_selection_agent()
            local_expert_agent = agents.local_expert()

            identify_task = tasks.identify_task(
                city_selector_agent,
                self.origin,
                self.cities,
                self.interests,
                self.date_range,
            )
            gather_task = tasks.gather_task(
                local_expert_agent, self.origin, self.interests, self.date_range
            )

            crew = Crew(
                agents=[city_selector_agent, local_expert_agent],
                tasks=[identify_task, gather_task],
                verbose=True,
                memory=True,
                knowledge={
                    "sources": [string_source],
                    "metadata": {"preference": "personal"},
                },
            )

            result = crew.kickoff()
            return result


    trip_crew = TripCrew("California", "Tokyo", "Dec 12 - Dec 20", "sports")
    result = trip_crew.run()

    print("Resultado da equipe:", result)
    ```

    Consulte a [Documentação de Tracing do MLflow](https://mlflow.org/docs/latest/llms/tracing/index.html) para mais configurações e casos de uso.
  </Step>

  <Step title="Visualize as atividades dos Agents">
    Agora os traces dos seus agentes crewAI estão sendo capturados pelo MLflow.
    Vamos acessar o servidor de tracking do MLflow para visualizar os traces e obter insights dos seus Agents.

    Abra `127.0.0.1:5000` em seu navegador para acessar o servidor de tracking do MLflow.

    <Frame caption="Painel de Tracing do MLflow">
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/mlflow1.png" alt="Exemplo de tracing do MLflow com crewai" />
    </Frame>
  </Step>
</Steps>


# Integração OpenLIT
Source: https://docs.crewai.com/pt-BR/observability/openlit

Comece a monitorar seus Agentes rapidamente com apenas uma linha de código usando OpenTelemetry.

# Visão Geral do OpenLIT

[OpenLIT](https://github.com/openlit/openlit?src=crewai-docs) é uma ferramenta open-source que simplifica o monitoramento de desempenho de agentes de IA, LLMs, VectorDBs e GPUs com apenas **uma** linha de código.

Ela oferece rastreamento e métricas nativos do OpenTelemetry para acompanhar parâmetros importantes como custo, latência, interações e sequências de tarefas.
Essa configuração permite acompanhar hiperparâmetros e monitorar problemas de desempenho, ajudando a encontrar formas de aprimorar e refinar seus agentes com o tempo.

<Frame caption="Painel do OpenLIT">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/openlit1.png" alt="Visão geral do uso de agentes, incluindo custo e tokens" />

  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/openlit2.png" alt="Visão geral dos rastreamentos e métricas otel do agente" />

  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/openlit3.png" alt="Visão detalhada dos rastreamentos do agente" />
</Frame>

### Funcionalidades

* **Painel Analítico**: Monitore a saúde e desempenho dos seus Agentes com dashboards detalhados que acompanham métricas, custos e interações dos usuários.
* **SDK de Observabilidade Nativo OpenTelemetry**: SDKs neutros de fornecedor para enviar rastreamentos e métricas para suas ferramentas de observabilidade existentes como Grafana, DataDog e outros.
* **Rastreamento de Custos para Modelos Customizados e Ajustados**: Adapte estimativas de custo para modelos específicos usando arquivos de precificação customizados para orçamentos precisos.
* **Painel de Monitoramento de Exceções**: Identifique e solucione rapidamente problemas ao rastrear exceções comuns e erros por meio de um painel de monitoramento.
* **Conformidade e Segurança**: Detecte ameaças potenciais como profanidade e vazamento de dados sensíveis (PII).
* **Detecção de Prompt Injection**: Identifique possíveis injeções de código e vazamentos de segredos.
* **Gerenciamento de Chaves de API e Segredos**: Gerencie suas chaves de API e segredos do LLM de forma centralizada e segura, evitando práticas inseguras.
* **Gerenciamento de Prompt**: Gerencie e versiona prompts de Agente usando o PromptHub para acesso consistente e fácil entre os agentes.
* **Model Playground** Teste e compare diferentes modelos para seus agentes CrewAI antes da implantação.

## Instruções de Configuração

<Steps>
  <Step title="Implantar o OpenLIT">
    <Steps>
      <Step title="Clonar o Repositório do OpenLIT">
        ```shell
        git clone git@github.com:openlit/openlit.git
        ```
      </Step>

      <Step title="Iniciar o Docker Compose">
        A partir do diretório raiz do [Repositório OpenLIT](https://github.com/openlit/openlit), execute o comando abaixo:

        ```shell
        docker compose up -d
        ```
      </Step>
    </Steps>
  </Step>

  <Step title="Instalar o SDK OpenLIT">
    ```shell
    pip install openlit
    ```
  </Step>

  <Step title="Inicializar o OpenLIT em Sua Aplicação">
    Adicione as duas linhas abaixo ao seu código de aplicação:

    <Tabs>
      <Tab title="Configuração usando argumentos de função">
        ```python
        import openlit
        openlit.init(otlp_endpoint="http://127.0.0.1:4318")
        ```

        Exemplo de uso para monitoramento de um Agente CrewAI:

        ```python
        from crewai import Agent, Task, Crew, Process
        import openlit

        openlit.init(disable_metrics=True)
        # Definir seus agentes
        pesquisador = Agent(
            role="Pesquisador",
            goal="Realizar pesquisas e análises aprofundadas sobre IA e agentes de IA",
            backstory="Você é um pesquisador especialista em tecnologia, engenharia de software, IA e startups. Trabalha como freelancer e está atualmente pesquisando para um novo cliente.",
            allow_delegation=False,
            llm='command-r'
        )


        # Definir sua task
        task = Task(
            description="Gere uma lista com 5 ideias interessantes para um artigo e escreva um parágrafo cativante para cada ideia, mostrando o potencial de um artigo completo sobre o tema. Retorne a lista de ideias com seus parágrafos e suas anotações.",
            expected_output="5 tópicos, cada um com um parágrafo e notas complementares.",
        )

        # Definir o agente gerente
        gerente = Agent(
            role="Gerente de Projeto",
            goal="Gerenciar eficientemente a equipe e garantir a conclusão de tarefas de alta qualidade",
            backstory="Você é um gerente de projetos experiente, habilidoso em supervisionar projetos complexos e guiar equipes para o sucesso. Sua função é coordenar os esforços dos membros da equipe, garantindo que cada tarefa seja concluída no prazo e com o mais alto padrão.",
            allow_delegation=True,
            llm='command-r'
        )

        # Instanciar sua crew com um manager personalizado
        crew = Crew(
            agents=[pesquisador],
            tasks=[task],
            manager_agent=gerente,
            process=Process.hierarchical,
        )

        # Iniciar o trabalho da crew
        result = crew.kickoff()

        print(result)
        ```
      </Tab>

      <Tab title="Configuração usando Variáveis de Ambiente">
        Adicione as duas linhas abaixo ao seu código de aplicação:

        ```python
        import openlit

        openlit.init()
        ```

        Execute o seguinte comando para configurar o endpoint de exportação OTEL:

        ```shell
        export OTEL_EXPORTER_OTLP_ENDPOINT = "http://127.0.0.1:4318"
        ```

        Exemplo de uso para monitoramento de um Agente CrewAI Async:

        ```python
        import asyncio
        from crewai import Crew, Agent, Task
        import openlit

        openlit.init(otlp_endpoint="http://127.0.0.1:4318")

        # Criar um agente com execução de código habilitada
        coding_agent = Agent(
          role="Analista de Dados Python",
          goal="Analisar dados e fornecer insights usando Python",
          backstory="Você é um analista de dados experiente com fortes habilidades em Python.",
          allow_code_execution=True,
          llm="command-r"
        )

        # Criar uma task que exige execução de código
        data_analysis_task = Task(
          description="Analise o conjunto de dados fornecido e calcule a idade média dos participantes. Idades: {ages}",
          agent=coding_agent,
          expected_output="5 tópicos, cada um com um parágrafo e notas complementares.",
        )

        # Criar uma crew e adicionar a task
        analysis_crew = Crew(
          agents=[coding_agent],
          tasks=[data_analysis_task]
        )

        # Função async para iniciar a crew de forma assíncrona
        async def async_crew_execution():
            result = await analysis_crew.kickoff_async(inputs={"ages": [25, 30, 35, 40, 45]})
            print("Crew Result:", result)

        # Executar a função async
        asyncio.run(async_crew_execution())
        ```
      </Tab>
    </Tabs>

    Consulte o [repositório do SDK Python do OpenLIT](https://github.com/openlit/openlit/tree/main/sdk/python) para configurações e casos de uso avançados.
  </Step>

  <Step title="Visualizar e Analisar">
    Com os dados de Observabilidade dos Agentes agora sendo coletados e enviados ao OpenLIT, o próximo passo é visualizar e analisar esses dados para obter insights sobre o desempenho, comportamento e identificar oportunidades de melhoria dos seus Agentes.

    Basta acessar o OpenLIT em `127.0.0.1:3000` no seu navegador para começar a explorar. Você pode fazer login usando as credenciais padrão

    * **Email**: `user@openlit.io`
    * **Senha**: `openlituser`

    <Frame caption="Painel do OpenLIT">
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/openlit1.png" alt="Visão geral do uso de agentes, incluindo custo e tokens" />

      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/openlit2.png" alt="Visão geral dos rastreamentos e métricas otel do agente" />
    </Frame>
  </Step>
</Steps>


# Integração Opik
Source: https://docs.crewai.com/pt-BR/observability/opik

Saiba como usar o Comet Opik para depurar, avaliar e monitorar suas aplicações CrewAI com rastreamento abrangente, avaliações automatizadas e dashboards prontos para produção.

# Visão Geral do Opik

Com o [Comet Opik](https://www.comet.com/docs/opik/), depure, avalie e monitore suas aplicações LLM, sistemas RAG e fluxos de trabalho agentic com rastreamento detalhado, avaliações automatizadas e dashboards prontos para produção.

<Frame caption="Dashboard do Agente Opik">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/opik-crewai-dashboard.png" alt="Exemplo de monitoramento de agente Opik com CrewAI" />
</Frame>

O Opik oferece suporte abrangente para cada etapa do desenvolvimento da sua aplicação CrewAI:

* **Registrar Traces e Spans**: Acompanhe automaticamente chamadas LLM e lógica da aplicação para depurar e analisar sistemas em desenvolvimento e em produção. Anote manualmente ou programaticamente, visualize e compare respostas entre projetos.
* **Avalie a Performance da sua Aplicação LLM**: Avalie contra um conjunto de testes personalizado e execute métricas de avaliação nativas ou defina suas próprias métricas via SDK ou UI.
* **Teste no Pipeline CI/CD**: Estabeleça bases de performance confiáveis com os testes unitários LLM do Opik, baseados em PyTest. Execute avaliações online para monitoramento contínuo em produção.
* **Monitore & Analise Dados de Produção**: Entenda a performance dos seus modelos em dados inéditos em produção e gere conjuntos de dados para novas iterações de desenvolvimento.

## Configuração

A Comet oferece uma versão hospedada da plataforma Opik, ou você pode rodar a plataforma localmente.

Para usar a versão hospedada, basta [criar uma conta gratuita na Comet](https://www.comet.com/signup?utm_medium=github\&utm_source=crewai_docs) e obter sua chave de API.

Para rodar a plataforma Opik localmente, veja nosso [guia de instalação](https://www.comet.com/docs/opik/self-host/overview/) para mais informações.

Neste guia, utilizaremos o exemplo de início rápido da CrewAI.

<Steps>
  <Step title="Instale os pacotes necessários">
    ```shell
    pip install crewai crewai-tools opik --upgrade
    ```
  </Step>

  <Step title="Configure o Opik">
    ```python
    import opik
    opik.configure(use_local=False)
    ```
  </Step>

  <Step title="Prepare o ambiente">
    Primeiro, configuramos nossas chaves de API do provedor LLM como variáveis de ambiente:

    ```python
    import os
    import getpass

    if "OPENAI_API_KEY" not in os.environ:
    os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter your OpenAI API key: ")
    ```
  </Step>

  <Step title="Usando a CrewAI">
    O primeiro passo é criar nosso projeto. Vamos utilizar um exemplo da documentação do CrewAI:

    ```python
    from crewai import Agent, Crew, Task, Process


    class NomeDaEquipe:
        def agente_um(self) -> Agent:
            return Agent(
                role="Analista de Dados",
                goal="Analisar tendências de dados no mercado",
                backstory="Analista de dados experiente com formação em economia",
                verbose=True,
            )

        def agente_dois(self) -> Agent:
            return Agent(
                role="Pesquisador de Mercado",
                goal="Coletar informações sobre a dinâmica do mercado",
                backstory="Pesquisador dedicado com olhar atento para detalhes",
                verbose=True,
            )

        def tarefa_um(self) -> Task:
            return Task(
                name="Tarefa de Coleta de Dados",
                description="Coletar dados recentes do mercado e identificar tendências.",
                expected_output="Um relatório resumindo as principais tendências do mercado.",
                agent=self.agente_um(),
            )

        def tarefa_dois(self) -> Task:
            return Task(
                name="Tarefa de Pesquisa de Mercado",
                description="Pesquisar fatores que afetam a dinâmica do mercado.",
                expected_output="Uma análise dos fatores que influenciam o mercado.",
                agent=self.agente_dois(),
            )

        def equipe(self) -> Crew:
            return Crew(
                agents=[self.agente_um(), self.agente_dois()],
                tasks=[self.tarefa_um(), self.tarefa_dois()],
                process=Process.sequential,
                verbose=True,
            )

    ```

    Agora podemos importar o tracker do Opik e executar nossa crew:

    ```python
    from opik.integrations.crewai import track_crewai

    track_crewai(project_name="crewai-integration-demo")

    my_crew = NomeDaEquipe().equipe()
    result = my_crew.kickoff()

    print(result)
    ```

    Após rodar sua aplicação CrewAI, acesse o app Opik para visualizar:

    * Traces LLM, spans e seus metadados
    * Interações dos agentes e fluxo de execução das tarefas
    * Métricas de performance, como latência e uso de tokens
    * Métricas de avaliação (nativas ou personalizadas)
  </Step>
</Steps>

## Recursos

* [🦉 Documentação Opik](https://www.comet.com/docs/opik/)
* [👉 Opik + CrewAI Colab](https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/crewai.ipynb)
* [🐦 X](https://x.com/cometml)
* [💬 Slack](https://slack.comet.com/)


# Visão Geral
Source: https://docs.crewai.com/pt-BR/observability/overview

Monitore, avalie e otimize seus agentes CrewAI com ferramentas de observabilidade abrangentes

## Observabilidade para CrewAI

A observabilidade é fundamental para entender como seus agentes CrewAI estão desempenhando, identificar gargalos e garantir uma operação confiável em ambientes de produção. Esta seção aborda diversas ferramentas e plataformas que oferecem recursos de monitoramento, avaliação e otimização dos fluxos de trabalho dos seus agentes.

## Por que a Observabilidade é Importante

* **Monitoramento de Desempenho**: Acompanhe tempos de execução dos agentes, uso de tokens e consumo de recursos
* **Garantia de Qualidade**: Avalie a qualidade e a consistência das saídas em diferentes cenários
* **Depuração**: Identifique e resolva problemas no comportamento dos agentes e na execução de tarefas
* **Gestão de Custos**: Monitore o uso das APIs do LLM e os custos associados
* **Melhoria Contínua**: Colete insights para otimizar o desempenho dos agentes ao longo do tempo

## Ferramentas de Observabilidade Disponíveis

### Plataformas de Monitoramento e Rastreamento

<CardGroup cols={2}>
  <Card title="AgentOps" icon="paperclip" href="/pt-BR/observability/agentops">
    Replays de sessões, métricas e monitoramento para desenvolvimento e produção de agentes.
  </Card>

  <Card title="OpenLIT" icon="magnifying-glass-chart" href="/pt-BR/observability/openlit">
    Monitoramento nativo OpenTelemetry com rastreamento de custos e análises de desempenho.
  </Card>

  <Card title="MLflow" icon="bars-staggered" href="/pt-BR/observability/mlflow">
    Gerenciamento do ciclo de vida de machine learning com rastreamento e avaliação.
  </Card>

  <Card title="Langfuse" icon="link" href="/pt-BR/observability/langfuse">
    Plataforma de engenharia de LLM com rastreamento detalhado e análises.
  </Card>

  <Card title="Langtrace" icon="chart-line" href="/pt-BR/observability/langtrace">
    Observabilidade open-source para LLMs e frameworks de agentes.
  </Card>

  <Card title="Arize Phoenix" icon="meteor" href="/pt-BR/observability/arize-phoenix">
    Plataforma de observabilidade de IA para monitoramento e solução de problemas.
  </Card>

  <Card title="Portkey" icon="key" href="/pt-BR/observability/portkey">
    Gateway de IA com monitoramento abrangente e recursos de confiabilidade.
  </Card>

  <Card title="Opik" icon="meteor" href="/pt-BR/observability/opik">
    Depure, avalie e monitore aplicações LLM com rastreamento abrangente.
  </Card>

  <Card title="Weave" icon="network-wired" href="/pt-BR/observability/weave">
    Plataforma Weights & Biases para acompanhamento e avaliação de aplicações de IA.
  </Card>
</CardGroup>

### Avaliação & Garantia de Qualidade

<CardGroup cols={2}>
  <Card title="Patronus AI" icon="shield-check" href="/pt-BR/observability/patronus-evaluation">
    Plataforma abrangente de avaliação para saídas de LLM e comportamentos de agentes.
  </Card>
</CardGroup>

## Principais Métricas de Observabilidade

### Métricas de Desempenho

* **Tempo de Execução**: Quanto tempo os agentes levam para concluir as tarefas
* **Uso de Tokens**: Tokens de entrada/saída consumidos pelas chamadas ao LLM
* **Latência de API**: Tempo de resposta de serviços externos
* **Taxa de Sucesso**: Percentual de tarefas concluídas com sucesso

### Métricas de Qualidade

* **Acurácia da Saída**: Correção das respostas dos agentes
* **Consistência**: Confiabilidade em entradas semelhantes
* **Relevância**: Quão bem as saídas correspondem aos resultados esperados
* **Segurança**: Conformidade com políticas de conteúdo e diretrizes

### Métricas de Custo

* **Custos de API**: Gastos decorrentes do uso do provedor LLM
* **Utilização de Recursos**: Consumo de processamento e memória
* **Custo por Tarefa**: Eficiência econômica das operações dos agentes
* **Acompanhamento de Orçamento**: Monitoramento em relação a limites de gastos

## Primeiros Passos

1. **Escolha suas Ferramentas**: Selecione plataformas de observabilidade que atendam às suas necessidades
2. **Instrumente seu Código**: Adicione monitoramento às suas aplicações CrewAI
3. **Configure Dashboards**: Prepare visualizações para as métricas principais
4. **Defina Alertas**: Crie notificações para eventos importantes
5. **Estabeleça Bases de Referência**: Meça o desempenho inicial para comparação futura
6. **Itere e Melhore**: Use os insights para otimizar seus agentes

## Boas Práticas

### Fase de Desenvolvimento

* Utilize rastreamento detalhado para entender o comportamento dos agentes
* Implemente métricas de avaliação desde o início do desenvolvimento
* Monitore o uso de recursos durante os testes
* Estabeleça verificações automatizadas de qualidade

### Fase de Produção

* Implemente monitoramento e alertas abrangentes
* Acompanhe tendências de desempenho ao longo do tempo
* Monitore anomalias e degradações
* Mantenha visibilidade e controle dos custos

### Melhoria Contínua

* Revisões regulares de desempenho e otimização
* Testes A/B de diferentes configurações de agentes
* Ciclos de feedback para aprimoramento da qualidade
* Documentação de lições aprendidas

Escolha as ferramentas de observabilidade que melhor se encaixam no seu caso de uso, infraestrutura e requisitos de monitoramento para garantir que seus agentes CrewAI operem de forma confiável e eficiente.


# Avaliação Patronus AI
Source: https://docs.crewai.com/pt-BR/observability/patronus-evaluation

Monitore e avalie o desempenho de agentes CrewAI utilizando a plataforma abrangente de avaliação da Patronus AI para saídas de LLM e comportamentos de agentes.

# Avaliação Patronus AI

## Visão Geral

[Patronus AI](https://patronus.ai) oferece capacidades abrangentes de avaliação e monitoramento para agentes CrewAI, permitindo avaliar as saídas dos modelos, comportamentos dos agentes e o desempenho geral do sistema. Essa integração possibilita implementar fluxos de avaliação contínuos que ajudam a manter a qualidade e confiabilidade em ambientes de produção.

## Principais Funcionalidades

* **Avaliação Automatizada**: Avaliação em tempo real das saídas e comportamentos dos agentes
* **Critérios Personalizados**: Defina critérios de avaliação específicos para seus casos de uso
* **Monitoramento de Desempenho**: Acompanhe métricas de desempenho dos agentes ao longo do tempo
* **Garantia de Qualidade**: Assegure consistência na qualidade das saídas em diferentes cenários
* **Segurança & Conformidade**: Monitore possíveis problemas e violações de políticas

## Ferramentas de Avaliação

A Patronus disponibiliza três principais ferramentas de avaliação para diferentes casos de uso:

1. **PatronusEvalTool**: Permite que os agentes selecionem o avaliador e os critérios mais apropriados para a tarefa de avaliação.
2. **PatronusPredefinedCriteriaEvalTool**: Utiliza avaliador e critérios predefinidos, especificados pelo usuário.
3. **PatronusLocalEvaluatorTool**: Utiliza avaliadores customizados definidos pelo usuário.

## Instalação

Para utilizar essas ferramentas, é necessário instalar o pacote Patronus:

```shell
uv add patronus
```

Você também precisará configurar sua chave de API da Patronus como uma variável de ambiente:

```shell
export PATRONUS_API_KEY="your_patronus_api_key"
```

## Passos para Começar

Para utilizar as ferramentas de avaliação da Patronus de forma eficaz, siga estes passos:

1. **Instale o Patronus**: Instale o pacote Patronus usando o comando acima.
2. **Configure a Chave de API**: Defina sua chave de API da Patronus como uma variável de ambiente.
3. **Escolha a Ferramenta Certa**: Selecione a ferramenta de avaliação Patronus mais adequada às suas necessidades.
4. **Configure a Ferramenta**: Configure a ferramenta com os parâmetros necessários.

## Exemplos

### Utilizando PatronusEvalTool

O exemplo a seguir demonstra como usar o `PatronusEvalTool`, que permite aos agentes selecionar o avaliador e critérios mais apropriados:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import PatronusEvalTool

# Initialize the tool
patronus_eval_tool = PatronusEvalTool()

# Define an agent that uses the tool
coding_agent = Agent(
    role="Agente de Programação",
    goal="Gerar código de alta qualidade e verificar se a saída é código",
    backstory="Um programador experiente que pode gerar código Python de alta qualidade.",
    tools=[patronus_eval_tool],
    verbose=True,
)

# Example task to generate and evaluate code
generate_code_task = Task(
    description="Crie um programa simples para gerar os N primeiros números da sequência de Fibonacci. Selecione o avaliador e os critérios mais apropriados para avaliar sua saída.",
    expected_output="Programa que gera os N primeiros números da sequência de Fibonacci.",
    agent=coding_agent,
)

# Create and run the crew
crew = Crew(agents=[coding_agent], tasks=[generate_code_task])
result = crew.kickoff()
```

### Utilizando PatronusPredefinedCriteriaEvalTool

O exemplo a seguir demonstra como usar o `PatronusPredefinedCriteriaEvalTool`, que utiliza avaliador e critérios predefinidos:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import PatronusPredefinedCriteriaEvalTool

# Initialize the tool with predefined criteria
patronus_eval_tool = PatronusPredefinedCriteriaEvalTool(
    evaluators=[{"evaluator": "judge", "criteria": "contains-code"}]
)

# Define an agent that uses the tool
coding_agent = Agent(
    role="Agente de Programação",
    goal="Gerar código de alta qualidade",
    backstory="Um programador experiente que pode gerar código Python de alta qualidade.",
    tools=[patronus_eval_tool],
    verbose=True,
)

# Example task to generate code
generate_code_task = Task(
    description="Crie um programa simples para gerar os N primeiros números da sequência de Fibonacci.",
    expected_output="Programa que gera os N primeiros números da sequência de Fibonacci.",
    agent=coding_agent,
)

# Create and run the crew
crew = Crew(agents=[coding_agent], tasks=[generate_code_task])
result = crew.kickoff()
```

### Utilizando PatronusLocalEvaluatorTool

O exemplo a seguir demonstra como usar o `PatronusLocalEvaluatorTool`, que utiliza avaliadores customizados via função:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import PatronusLocalEvaluatorTool
from patronus import Client, EvaluationResult
import random

# Initialize the Patronus client
client = Client()

# Register a custom evaluator
@client.register_local_evaluator("random_evaluator")
def random_evaluator(**kwargs):
    score = random.random()
    return EvaluationResult(
        score_raw=score,
        pass_=score >= 0.5,
        explanation="example explanation",
    )

# Initialize the tool with the custom evaluator
patronus_eval_tool = PatronusLocalEvaluatorTool(
    patronus_client=client,
    evaluator="random_evaluator",
    evaluated_model_gold_answer="example label",
)

# Define an agent that uses the tool
coding_agent = Agent(
    role="Agente de Programação",
    goal="Gerar código de alta qualidade",
    backstory="Um programador experiente que pode gerar código Python de alta qualidade.",
    tools=[patronus_eval_tool],
    verbose=True,
)

# Example task to generate code
generate_code_task = Task(
    description="Crie um programa simples para gerar os N primeiros números da sequência de Fibonacci.",
    expected_output="Programa que gera os N primeiros números da sequência de Fibonacci.",
    agent=coding_agent,
)

# Create and run the crew
crew = Crew(agents=[coding_agent], tasks=[generate_code_task])
result = crew.kickoff()
```

## Parâmetros

### PatronusEvalTool

O `PatronusEvalTool` não exige parâmetros durante a inicialização. Ele busca automaticamente os avaliadores e critérios disponíveis a partir da API da Patronus.

### PatronusPredefinedCriteriaEvalTool

O `PatronusPredefinedCriteriaEvalTool` aceita os seguintes parâmetros durante a inicialização:

* **evaluators**: Obrigatório. Uma lista de dicionários contendo o avaliador e os critérios a serem utilizados. Por exemplo: `[{"evaluator": "judge", "criteria": "contains-code"}]`.

### PatronusLocalEvaluatorTool

O `PatronusLocalEvaluatorTool` aceita os seguintes parâmetros durante a inicialização:

* **patronus\_client**: Obrigatório. Instância do cliente Patronus.
* **evaluator**: Opcional. O nome do avaliador local registrado a ser utilizado. Default é uma string vazia.
* **evaluated\_model\_gold\_answer**: Opcional. A resposta padrão (“gold answer”) para uso na avaliação. O padrão é uma string vazia.

## Uso

Ao utilizar as ferramentas de avaliação Patronus, você fornece a entrada do modelo, a saída e o contexto, e a ferramenta retorna os resultados da avaliação a partir da API da Patronus.

Para o `PatronusEvalTool` e o `PatronusPredefinedCriteriaEvalTool`, os seguintes parâmetros são obrigatórios ao chamar a ferramenta:

* **evaluated\_model\_input**: A descrição da tarefa do agente, em texto simples.
* **evaluated\_model\_output**: A saída da tarefa pelo agente.
* **evaluated\_model\_retrieved\_context**: O contexto do agente.

Para o `PatronusLocalEvaluatorTool`, os mesmos parâmetros são necessários, mas o avaliador e a resposta padrão são especificados durante a inicialização.

## Conclusão

As ferramentas de avaliação da Patronus fornecem uma forma poderosa de avaliar e pontuar entradas e saídas de modelos utilizando a plataforma Patronus AI. Ao possibilitar que agentes avaliem suas próprias saídas ou as de outros agentes, essas ferramentas ajudam a aprimorar a qualidade e confiabilidade dos fluxos de trabalho do CrewAI.


# Integração com Portkey
Source: https://docs.crewai.com/pt-BR/observability/portkey

Como usar Portkey com CrewAI

<img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/main/Portkey-CrewAI.png" alt="Portkey CrewAI Header Image" width="70%" />

## Introdução

Portkey aprimora o CrewAI com recursos prontos para produção, transformando seus crews de agentes experimentais em sistemas robustos ao fornecer:

* **Observabilidade completa** de cada etapa do agente, uso de ferramentas e interações
* **Confiabilidade incorporada** com fallbacks, tentativas automáticas e balanceamento de carga
* **Rastreamento e otimização de custos** para gerenciar seus gastos com IA
* **Acesso a mais de 200 LLMs** por meio de uma única integração
* **Guardrails** para manter o comportamento dos agentes seguro e em conformidade
* **Prompts versionados** para desempenho consistente dos agentes

### Instalação & Configuração

<Steps>
  <Step title="Instale os pacotes necessários">
    ```bash
    pip install -U crewai portkey-ai
    ```
  </Step>

  <Step title="Gere a Chave de API" icon="lock">
    Crie uma chave de API Portkey com limites de orçamento/taxa opcionais no [painel da Portkey](https://app.portkey.ai/). Você também pode adicionar configurações para confiabilidade, cache e outros recursos a essa chave. Mais sobre isso em breve.
  </Step>

  <Step title="Configure o CrewAI com Portkey">
    A integração é simples – basta atualizar a configuração do LLM no seu setup do CrewAI:

    ```python
    from crewai import LLM
    from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

    # Crie uma instância do LLM com integração Portkey
    gpt_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",  # Estamos usando uma chave virtual, então isso é apenas um placeholder
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_LLM_VIRTUAL_KEY",
            trace_id="unique-trace-id",               # Opcional, para rastreamento da requisição
        )
    )

    #Use-os nos seus Crew Agents assim:

    	@agent
    	def lead_market_analyst(self) -> Agent:
    		return Agent(
    			config=self.agents_config['lead_market_analyst'],
    			verbose=True,
    			memory=False,
    			llm=gpt_llm
    		)

    ```

    <Info>
      **O que são Virtual Keys?** Virtual keys no Portkey armazenam com segurança suas chaves de API dos provedores LLM (OpenAI, Anthropic, etc.) em um cofre criptografado. Elas facilitam a rotação de chaves e o gerenciamento de orçamento. [Saiba mais sobre virtual keys aqui](https://portkey.ai/docs/product/ai-gateway/virtual-keys).
    </Info>
  </Step>
</Steps>

## Recursos para Produção

### 1. Observabilidade Avançada

Portkey oferece observabilidade abrangente para seus agentes CrewAI, ajudando você a entender exatamente o que está acontecendo durante cada execução.

<Tabs>
  <Tab title="Traces">
    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20Product%2011.1.webp" />
    </Frame>

    Os traces fornecem uma visão hierárquica da execução do seu crew, mostrando a sequência de chamadas LLM, ativações de ferramentas e transições de estado.

    ```python
    # Adicione trace_id para habilitar o tracing hierárquico no Portkey
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
            trace_id="unique-session-id"  # Adicione um trace ID único
        )
    )
    ```
  </Tab>

  <Tab title="Logs">
    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20Portkey%20Docs%20Metadata.png" />
    </Frame>

    Portkey registra cada interação com LLMs, incluindo:

    * Payloads completos das requisições e respostas
    * Métricas de latência e uso de tokens
    * Cálculos de custo
    * Chamadas de ferramentas e execuções de funções

    Todos os logs podem ser filtrados por metadados, trace IDs, modelos e mais, tornando mais fácil depurar execuções específicas do crew.
  </Tab>

  <Tab title="Métricas & Dashboards">
    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20Dashboard.png" />
    </Frame>

    Portkey oferece dashboards integrados que ajudam você a:

    * Rastrear custos e uso de tokens em todas as execuções do crew
    * Analisar métricas de desempenho, como latência e taxas de sucesso
    * Identificar gargalos nos fluxos de trabalho dos agentes
    * Comparar diferentes configurações de crew e LLMs

    Você pode filtrar e segmentar todas as métricas por metadados personalizados para analisar tipos de crew, grupos de usuários ou casos de uso específicos.
  </Tab>

  <Tab title="Filtragem por Metadados">
    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/Metadata%20Filters%20from%20CrewAI.png" alt="Analytics with metadata filters" />
    </Frame>

    Adicione metadados personalizados à configuração LLM do seu CrewAI para permitir filtragem e segmentação poderosas:

    ```python
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
            metadata={
                "crew_type": "research_crew",
                "environment": "production",
                "_user": "user_123",   # Campo especial _user para analytics de usuários
                "request_source": "mobile_app"
            }
        )
    )
    ```

    Esses metadados podem ser usados para filtrar logs, traces e métricas no painel do Portkey, permitindo analisar execuções específicas do crew, usuários ou ambientes.
  </Tab>
</Tabs>

### 2. Confiabilidade - Mantenha Seus Crews Funcionando Sem Interrupções

Ao executar crews em produção, problemas podem ocorrer – limites de taxa da API, problemas de rede ou indisponibilidade do provedor. Os recursos de confiabilidade do Portkey garantem que seus agentes continuem funcionando mesmo quando problemas surgem.

É simples habilitar fallback na sua configuração CrewAI usando um Config do Portkey:

```python
from crewai import LLM
from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

# Crie LLM com configuração de fallback
portkey_llm = LLM(
    model="gpt-4o",
    max_tokens=1000,
    base_url=PORTKEY_GATEWAY_URL,
    api_key="dummy",
    extra_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        config={
            "strategy": {
                "mode": "fallback"
            },
            "targets": [
                {
                    "provider": "openai",
                    "api_key": "YOUR_OPENAI_API_KEY",
                    "override_params": {"model": "gpt-4o"}
                },
                {
                    "provider": "anthropic",
                    "api_key": "YOUR_ANTHROPIC_API_KEY",
                    "override_params": {"model": "claude-3-opus-20240229"}
                }
            ]
        }
    )
)

# Use essa configuração LLM com seus agentes
```

Essa configuração automaticamente tentará o Claude caso a requisição para o GPT-4o falhe, garantindo que seu crew continue funcionando.

<CardGroup cols="2">
  <Card title="Tentativas Automáticas" icon="rotate" href="https://portkey.ai/docs/product/ai-gateway/automatic-retries">
    Lida automaticamente com falhas temporárias. Se uma chamada LLM falhar, o Portkey fará novas tentativas o número especificado de vezes – perfeito para limites de taxa ou instabilidades de rede.
  </Card>

  <Card title="Timeouts de Requisição" icon="clock" href="https://portkey.ai/docs/product/ai-gateway/request-timeouts">
    Evite que seus agentes fiquem travados. Defina timeouts para garantir respostas (ou falhas controladas) dentro do tempo necessário.
  </Card>

  <Card title="Roteamento Condicional" icon="route" href="https://portkey.ai/docs/product/ai-gateway/conditional-routing">
    Envie diferentes solicitações para diferentes provedores. Direcione raciocínios complexos para o GPT-4, tarefas criativas para Claude e respostas rápidas para Gemini conforme sua necessidade.
  </Card>

  <Card title="Fallbacks" icon="shield" href="https://portkey.ai/docs/product/ai-gateway/fallbacks">
    Mantenha-se em funcionamento mesmo se seu provedor principal falhar. Troque automaticamente para provedores de backup para manter a disponibilidade.
  </Card>

  <Card title="Balanceamento de Carga" icon="scale-balanced" href="https://portkey.ai/docs/product/ai-gateway/load-balancing">
    Distribua solicitações entre várias chaves de API ou provedores. Ótimo para operações de crew em grande escala e para permanecer dentro dos limites de taxa.
  </Card>
</CardGroup>

### 3. Prompting no CrewAI

O Prompt Engineering Studio do Portkey ajuda você a criar, gerenciar e otimizar os prompts usados em seus agentes CrewAI. Em vez de codificar prompts ou instruções manualmente, use a API de renderização de prompts do Portkey para buscar e aplicar dinâmicamente seus prompts versionados.

<Frame caption="Gerencie prompts na Prompt Library do Portkey">
  ![Prompt Playground Interface](https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20Portkey%20Docs.webp)
</Frame>

<Tabs>
  <Tab title="Prompt Playground">
    Prompt Playground é um local para comparar, testar e implantar prompts perfeitos para sua aplicação de IA. É onde você experimenta com diferentes modelos, testa variáveis, compara saídas e refina sua estratégia de engenharia de prompts antes de implantar em produção. Ele permite:

    1. Desenvolver prompts de forma iterativa antes de usá-los em seus agentes
    2. Testar prompts com diferentes variáveis e modelos
    3. Comparar saídas entre diferentes versões de prompts
    4. Colaborar com membros da equipe no desenvolvimento de prompts

    Esse ambiente visual facilita a criação de prompts eficazes para cada etapa do fluxo de trabalho dos seus agentes CrewAI.
  </Tab>

  <Tab title="Usando Templates de Prompt">
    A API Prompt Render recupera seus templates de prompt com todos os parâmetros configurados:

    ```python
    from crewai import Agent, LLM
    from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL, Portkey

    # Inicialize o cliente admin do Portkey
    portkey_admin = Portkey(api_key="YOUR_PORTKEY_API_KEY")

    # Recupere o prompt usando a render API
    prompt_data = portkey_client.prompts.render(
        prompt_id="YOUR_PROMPT_ID",
        variables={
            "agent_role": "Senior Research Scientist",
        }
    )

    backstory_agent_prompt=prompt_data.data.messages[0]["content"]


    # Configure o LLM com integração Portkey
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_OPENAI_VIRTUAL_KEY"
        )
    )

    # Crie o agente utilizando o prompt renderizado
    researcher = Agent(
        role="Senior Research Scientist",
        goal="Discover groundbreaking insights about the assigned topic",
        backstory=backstory_agent,  # Use o prompt renderizado
        verbose=True,
        llm=portkey_llm
    )
    ```
  </Tab>

  <Tab title="Versionamento de Prompts">
    Você pode:

    * Criar múltiplas versões do mesmo prompt
    * Comparar o desempenho entre versões
    * Voltar a versões anteriores se necessário
    * Especificar qual versão usar em seu código:

    ```python
    # Use uma versão específica do prompt
    prompt_data = portkey_admin.prompts.render(
        prompt_id="YOUR_PROMPT_ID@version_number",
        variables={
            "agent_role": "Senior Research Scientist",
            "agent_goal": "Discover groundbreaking insights"
        }
    )
    ```
  </Tab>

  <Tab title="Mustache Templating para variáveis">
    Os prompts do Portkey usam modelos estilo Mustache para fácil substituição de variáveis:

    ```
    You are a {{agent_role}} with expertise in {{domain}}.

    Your mission is to {{agent_goal}} by leveraging your knowledge
    and experience in the field.

    Always maintain a {{tone}} tone and focus on providing {{focus_area}}.
    ```

    Ao renderizar, basta passar as variáveis:

    ```python
    prompt_data = portkey_admin.prompts.render(
        prompt_id="YOUR_PROMPT_ID",
        variables={
            "agent_role": "Senior Research Scientist",
            "domain": "artificial intelligence",
            "agent_goal": "discover groundbreaking insights",
            "tone": "professional",
            "focus_area": "practical applications"
        }
    )
    ```
  </Tab>
</Tabs>

<Card title="Prompt Engineering Studio" icon="wand-magic-sparkles" href="https://portkey.ai/docs/product/prompt-library">
  Saiba mais sobre os recursos de gerenciamento de prompts do Portkey
</Card>

### 4. Guardrails para Crews Seguros

Guardrails garantem que seus agentes CrewAI operem com segurança e respondam adequadamente em todas as situações.

**Por que usar Guardrails?**

Os agentes CrewAI podem apresentar falhas de diversos tipos:

* Gerar conteúdo nocivo ou inapropriado
* Vazamento de informações sensíveis como PII
* Alucinar informações incorretas
* Gerar saídas em formatos incorretos

Os guardrails do Portkey fornecem proteções tanto para entradas quanto para saídas.

**Implementando Guardrails**

```python
from crewai import Agent, LLM
from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

# Crie LLM com guardrails
portkey_llm = LLM(
    model="gpt-4o",
    base_url=PORTKEY_GATEWAY_URL,
    api_key="dummy",
    extra_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
        config={
            "input_guardrails": ["guardrails-id-xxx", "guardrails-id-yyy"],
            "output_guardrails": ["guardrails-id-zzz"]
        }
    )
)

# Crie agente com LLM guardrailed
researcher = Agent(
    role="Senior Research Scientist",
    goal="Discover groundbreaking insights about the assigned topic",
    backstory="You are an expert researcher with deep domain knowledge.",
    verbose=True,
    llm=portkey_llm
)
```

Os guardrails do Portkey podem:

* Detectar e redigir PII tanto em entradas quanto em saídas
* Filtrar conteúdo prejudicial ou inapropriado
* Validar formatos de resposta contra schemas
* Verificar alucinações comparando com ground truth
* Aplicar lógica e regras de negócio personalizadas

<Card title="Saiba Mais Sobre Guardrails" icon="shield-check" href="https://portkey.ai/docs/product/guardrails">
  Explore os recursos de guardrails do Portkey para aumentar a segurança dos agentes
</Card>

### 5. Rastreamento de Usuário com Metadados

Rastreie usuários individuais através dos seus agentes CrewAI utilizando o sistema de metadados do Portkey.

**O que é Metadata no Portkey?**

Metadados permitem associar dados personalizados a cada requisição, possibilitando filtragem, segmentação e analytics. O campo especial `_user` é projetado especificamente para rastreamento de usuário.

```python
from crewai import Agent, LLM
from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

# Configure o LLM com rastreamento de usuário
portkey_llm = LLM(
    model="gpt-4o",
    base_url=PORTKEY_GATEWAY_URL,
    api_key="dummy",
    extra_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
        metadata={
            "_user": "user_123",  # Campo especial _user para analytics de usuários
            "user_tier": "premium",
            "user_company": "Acme Corp",
            "session_id": "abc-123"
        }
    )
)

# Crie agente com LLM rastreado
researcher = Agent(
    role="Senior Research Scientist",
    goal="Discover groundbreaking insights about the assigned topic",
    backstory="You are an expert researcher with deep domain knowledge.",
    verbose=True,
    llm=portkey_llm
)
```

**Filtre Analytics por Usuário**

Com os metadados configurados, você pode filtrar analytics por usuário e analisar métricas de desempenho individualmente:

<Frame caption="Filtre analytics por usuário">
  <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/Metadata%20Filters%20from%20CrewAI.png" />
</Frame>

Isso permite:

* Rastreamento de custos e orçamento por usuário
* Analytics personalizados por usuário
* Métricas por equipe ou organização
* Monitoramento específico por ambiente (homologação x produção)

<Card title="Saiba Mais Sobre Metadata" icon="tags" href="https://portkey.ai/docs/product/observability/metadata">
  Veja como usar metadados personalizados para aprimorar seus analytics
</Card>

### 6. Cache para Crews Eficientes

Implemente caching para tornar seus agentes CrewAI mais eficientes e econômicos:

<Tabs>
  <Tab title="Caching Simples">
    ```python
    from crewai import Agent, LLM
    from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

    # Configure o LLM com caching simples
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
            config={
                "cache": {
                    "mode": "simple"
                }
            }
        )
    )

    # Crie agente com LLM cacheado
    researcher = Agent(
        role="Senior Research Scientist",
        goal="Discover groundbreaking insights about the assigned topic",
        backstory="You are an expert researcher with deep domain knowledge.",
        verbose=True,
        llm=portkey_llm
    )
    ```

    O caching simples realiza correspondências exatas de prompts de entrada, cacheando requisições idênticas para evitar execuções redundantes do modelo.
  </Tab>

  <Tab title="Cache Semântico">
    ```python
    from crewai import Agent, LLM
    from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

    # Configure o LLM com cache semântico
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
            config={
                "cache": {
                    "mode": "semantic"
                }
            }
        )
    )

    # Crie agente com LLM com cache semântico
    researcher = Agent(
        role="Senior Research Scientist",
        goal="Discover groundbreaking insights about the assigned topic",
        backstory="You are an expert researcher with deep domain knowledge.",
        verbose=True,
        llm=portkey_llm
    )
    ```

    O cache semântico considera a similaridade contextual entre solicitações de entrada, armazenando respostas para entradas semanticamente similares.
  </Tab>
</Tabs>

### 7. Interoperabilidade de Modelos

O CrewAI oferece suporte a múltiplos provedores de LLM, e o Portkey amplia essa capacidade fornecendo acesso a mais de 200 LLMs por meio de uma interface unificada. Você pode facilmente alternar entre diferentes modelos sem alterar a lógica central do seu agente:

```python
from crewai import Agent, LLM
from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

# Configure LLMs com diferentes provedores
openai_llm = LLM(
    model="gpt-4o",
    base_url=PORTKEY_GATEWAY_URL,
    api_key="dummy",
    extra_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        virtual_key="YOUR_OPENAI_VIRTUAL_KEY"
    )
)

anthropic_llm = LLM(
    model="claude-3-5-sonnet-latest",
    max_tokens=1000,
    base_url=PORTKEY_GATEWAY_URL,
    api_key="dummy",
    extra_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        virtual_key="YOUR_ANTHROPIC_VIRTUAL_KEY"
    )
)

# Escolha qual LLM usar para cada agente conforme necessário
researcher = Agent(
    role="Senior Research Scientist",
    goal="Discover groundbreaking insights about the assigned topic",
    backstory="You are an expert researcher with deep domain knowledge.",
    verbose=True,
    llm=openai_llm  # Use anthropic_llm para Anthropic
)
```

Portkey oferece acesso a LLMs de provedores como:

* OpenAI (GPT-4o, GPT-4 Turbo, etc.)
* Anthropic (Claude 3.5 Sonnet, Claude 3 Opus, etc.)
* Mistral AI (Mistral Large, Mistral Medium, etc.)
* Google Vertex AI (Gemini 1.5 Pro, etc.)
* Cohere (Command, Command-R, etc.)
* AWS Bedrock (Claude, Titan, etc.)
* Modelos locais/privados

<Card title="Provedores Suportados" icon="server" href="https://portkey.ai/docs/integrations/llms">
  Veja a lista completa de provedores LLM suportados pelo Portkey
</Card>

## Configure Governança Corporativa para o CrewAI

**Por que Governança Corporativa?**
Se você utiliza CrewAI dentro de sua organização, é importante considerar diversos aspectos de governança:

* **Gestão de Custos**: Controlar e rastrear os gastos com IA entre equipes
* **Controle de Acesso**: Gerenciar quais equipes podem usar modelos específicos
* **Analytics de Uso**: Compreender como a IA está sendo utilizada na organização
* **Segurança & Compliance**: Manutenção de padrões corporativos de segurança
* **Confiabilidade**: Garantir serviço consistente para todos os usuários

O Portkey adiciona uma camada abrangente de governança para atender a essas necessidades corporativas. Vamos implementar esses controles passo a passo.

<Steps>
  <Step title="Crie uma Virtual Key">
    Virtual Keys são a maneira segura do Portkey para gerenciar as chaves de API dos provedores de LLM. Elas fornecem controles essenciais como:

    * Limites de orçamento para uso da API
    * Capacidade de rate limiting
    * Armazenamento seguro das chaves de API

    Para criar uma virtual key:
    Vá até [Virtual Keys](https://app.portkey.ai/virtual-keys) no app Portkey. Salve e copie o ID da virtual key

    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/Virtual%20Key%20from%20Portkey%20Docs.png" width="500" />
    </Frame>

    <Note>
      Salve o ID da sua virtual key – você precisará dele no próximo passo.
    </Note>
  </Step>

  <Step title="Crie um Config Padrão">
    Os Configs no Portkey definem como suas requisições são roteadas, com recursos como roteamento avançado, fallbacks e tentativas automáticas.

    Para criar seu config:

    1. Vá até [Configs](https://app.portkey.ai/configs) no painel Portkey
    2. Crie um novo config com:
       ```json
       {
           "virtual_key": "YOUR_VIRTUAL_KEY_FROM_STEP1",
          	"override_params": {
             "model": "gpt-4o" // Nome do seu modelo preferido
           }
       }
       ```
    3. Salve e anote o nome do Config para o próximo passo

    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20Portkey%20Docs%20Config.png" width="500" />
    </Frame>
  </Step>

  <Step title="Configure a Chave de API Portkey">
    Agora crie uma chave de API Portkey e anexe a config criada no Passo 2:

    1. Vá até [API Keys](https://app.portkey.ai/api-keys) na Portkey e crie uma nova chave de API
    2. Selecione sua config do `Passo 2`
    3. Gere e salve sua chave de API

    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20API%20Key.png" width="500" />
    </Frame>
  </Step>

  <Step title="Conecte ao CrewAI">
    Após configurar sua chave de API Portkey com a config anexada, conecte-a aos seus agentes CrewAI:

    ```python
    from crewai import Agent, LLM
    from portkey_ai import PORTKEY_GATEWAY_URL

    # Configure o LLM com sua chave de API
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="YOUR_PORTKEY_API_KEY"
    )

    # Crie agente com LLM habilitado para Portkey
    researcher = Agent(
        role="Senior Research Scientist",
        goal="Discover groundbreaking insights about the assigned topic",
        backstory="You are an expert researcher with deep domain knowledge.",
        verbose=True,
        llm=portkey_llm
    )
    ```
  </Step>
</Steps>

<AccordionGroup>
  <Accordion title="Etapa 1: Implementar Controles de Orçamento & Rate Limits">
    ### Etapa 1: Implementar Controles de Orçamento & Rate Limits

    Virtual Keys permitem controle granular sobre o acesso ao LLM por equipe/departamento. Isso ajuda você a:

    * Definir [limites de orçamento](https://portkey.ai/docs/product/ai-gateway/virtual-keys/budget-limits)
    * Prevenir picos inesperados de uso através de Rate limits
    * Rastrear gastos por departamento

    #### Configurando controles específicos de departamento:

    1. Vá até [Virtual Keys](https://app.portkey.ai/virtual-keys) no painel Portkey
    2. Crie uma nova Virtual Key para cada departamento com limites de orçamento e rate limits
    3. Configure limites específicos por departamento

    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/Virtual%20Key%20from%20Portkey%20Docs.png" width="500" />
    </Frame>
  </Accordion>

  <Accordion title="Etapa 2: Definir Regras de Acesso a Modelos">
    ### Etapa 2: Definir Regras de Acesso a Modelos

    À medida que o uso de IA cresce, controlar quais equipes têm acesso a quais modelos se torna fundamental. Os Configs do Portkey fornecem essa camada de controle com recursos como:

    #### Recursos de Controle de Acesso:

    * **Restrições de Modelo**: Limite o acesso a modelos específicos
    * **Proteção de Dados**: Implemente guardrails para dados sensíveis
    * **Controles de Confiabilidade**: Adicione fallbacks e tentativas automáticas

    #### Exemplo de Configuração:

    Aqui está um exemplo básico para rotear requisições ao OpenAI, usando especificamente o GPT-4o:

    ```json
    {
    	"strategy": {
    		"mode": "single"
    	},
    	"targets": [
    		{
    			"virtual_key": "YOUR_OPENAI_VIRTUAL_KEY",
    			"override_params": {
    				"model": "gpt-4o"
    			}
    		}
    	]
    }
    ```

    Crie seu config na [página de Configs](https://app.portkey.ai/configs) no painel do Portkey.

    <Note>
      Os configs podem ser atualizados a qualquer momento para ajustar controles sem afetar aplicações em execução.
    </Note>
  </Accordion>

  <Accordion title="Etapa 3: Implementar Controles de Acesso">
    ### Etapa 3: Implementar Controles de Acesso

    Crie chaves de API específicas por usuário que automaticamente:

    * Rastreiam uso por usuário/equipe com o auxílio das virtual keys
    * Aplicam configs adequadas para rotear requisições
    * Coletam metadados relevantes para filtragem de logs
    * Impõem permissões de acesso

    Crie chaves de API através de:

    * [Portkey App](https://app.portkey.ai/)
    * [API Key Management API](/pt-BR/api-reference/admin-api/control-plane/api-keys/create-api-key)

    Exemplo usando Python SDK:

    ```python
    from portkey_ai import Portkey

    portkey = Portkey(api_key="YOUR_ADMIN_API_KEY")

    api_key = portkey.api_keys.create(
        name="engineering-team",
        type="organisation",
        workspace_id="YOUR_WORKSPACE_ID",
        defaults={
            "config_id": "your-config-id",
            "metadata": {
                "environment": "production",
                "department": "engineering"
            }
        },
        scopes=["logs.view", "configs.read"]
    )
    ```

    Para instruções detalhadas de gerenciamento de chaves, veja nossa [documentação de API Keys](/pt-BR/api-reference/admin-api/control-plane/api-keys/create-api-key).
  </Accordion>

  <Accordion title="Etapa 4: Implante & Monitore">
    ### Etapa 4: Implante & Monitore

    Após distribuir as chaves de API para os membros da equipe, seu setup corporativo CrewAI está pronto. Cada membro pode agora usar suas chaves designadas com os níveis de acesso e controles de orçamento apropriados.

    Monitore o uso no painel Portkey:

    * Rastreamento de custos por departamento
    * Padrões de uso de modelos
    * Volume de requisições
    * Taxa de erros
  </Accordion>
</AccordionGroup>

<Note>
  ### Recursos Corporativos Agora Disponíveis

  **Sua integração CrewAI agora conta com:**

  * Controles de orçamento departamental
  * Governança de acesso a modelos
  * Rastreamento de uso & atribuição
  * Guardrails de segurança
  * Recursos de confiabilidade
</Note>

## Perguntas Frequentes

<AccordionGroup>
  <Accordion title="Como o Portkey aprimora o CrewAI?">
    Portkey adiciona prontidão para produção ao CrewAI através de observabilidade abrangente (traces, logs, métricas), recursos de confiabilidade (fallbacks, tentativas automáticas, cache) e acesso a mais de 200 LLMs por meio de uma interface unificada. Isso facilita depurar, otimizar e escalar suas aplicações de agentes.
  </Accordion>

  <Accordion title="Posso usar Portkey com aplicações CrewAI existentes?">
    Sim! Portkey integra-se perfeitamente a aplicações CrewAI existentes. Basta atualizar o código de configuração do LLM com a versão habilitada do Portkey. O restante do seu código de agente e crew permanece inalterado.
  </Accordion>

  <Accordion title="Portkey funciona com todos os recursos do CrewAI?">
    Portkey suporta todos os recursos do CrewAI, incluindo agentes, ferramentas, workflows human-in-the-loop e todos os tipos de processo de tarefas (sequencial, hierárquico, etc.). Ele adiciona observabilidade e confiabilidade sem limitar nenhuma funcionalidade do framework.
  </Accordion>

  <Accordion title="Posso rastrear o uso em múltiplos agentes de um crew?">
    Sim, o Portkey permite que você use um `trace_id` consistente em múltiplos agentes de um crew para rastrear todo o fluxo de trabalho. Isso é especialmente útil para crews complexos onde você deseja entender o caminho completo de execução entre os agentes.
  </Accordion>

  <Accordion title="Como filtro logs e traces para execuções específicas de crew?">
    O Portkey permite adicionar metadados personalizados à configuração do seu LLM, que podem ser usados para filtragem. Adicione campos como `crew_name`, `crew_type`, ou `session_id` para encontrar e analisar facilmente execuções específicas do crew.
  </Accordion>

  <Accordion title="Posso usar minhas próprias chaves de API com o Portkey?">
    Sim! O Portkey utiliza suas próprias chaves de API dos provedores LLM. Elas são armazenadas com segurança como virtual keys, permitindo que você gerencie e gire as chaves facilmente sem alterar seu código.
  </Accordion>
</AccordionGroup>

## Recursos

<CardGroup cols="3">
  <Card title="CrewAI Docs" icon="book" href="https://docs.crewai.com/">
    <p>Documentação oficial do CrewAI</p>
  </Card>

  <Card title="Agende uma Demonstração" icon="calendar" href="https://calendly.com/portkey-ai">
    <p>Receba orientação personalizada sobre como implementar essa integração</p>
  </Card>
</CardGroup>


# Integração com Weave
Source: https://docs.crewai.com/pt-BR/observability/weave

Saiba como usar o Weights & Biases (W&B) Weave para rastrear, experimentar, avaliar e melhorar suas aplicações CrewAI.

# Visão Geral do Weave

[Weights & Biases (W\&B) Weave](https://weave-docs.wandb.ai/) é um framework para rastreamento, experimentação, avaliação, implementação e aprimoramento de aplicações baseadas em LLM.

![Visão geral do uso do tracing do W\&B Weave com CrewAI](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/weave-tracing.gif)

O Weave oferece suporte completo para todas as etapas do desenvolvimento da sua aplicação CrewAI:

* **Rastreamento e Monitoramento**: Acompanhe automaticamente chamadas LLM e a lógica da aplicação para depuração e análise de sistemas em produção
* **Iteração Sistemática**: Aperfeiçoe e itere em prompts, conjuntos de dados e modelos
* **Avaliação**: Utilize avaliadores personalizados ou pré-construídos para avaliar e aprimorar sistematicamente o desempenho dos agentes
* **Guardrails**: Proteja seus agentes com salvaguardas pré e pós-execução para moderação de conteúdo e segurança de prompts

O Weave captura automaticamente rastreamentos (traces) de suas aplicações CrewAI, permitindo monitorar e analisar o desempenho, as interações e o fluxo de execução dos seus agentes. Isso te ajuda a construir melhores conjuntos de dados para avaliação e a otimizar os fluxos de trabalho dos agentes.

## Instruções de Configuração

<Steps>
  <Step title="Instale os pacotes necessários">
    ```shell
    pip install crewai weave
    ```
  </Step>

  <Step title="Crie uma conta no W&B">
    Cadastre-se em uma [conta Weights & Biases](https://wandb.ai) caso ainda não tenha uma. Você precisará dela para visualizar rastreamentos e métricas.
  </Step>

  <Step title="Inicialize o Weave na sua aplicação">
    Adicione o seguinte código à sua aplicação:

    ```python
    import weave

    # Inicialize o Weave com o nome do seu projeto
    weave.init(project_name="crewai_demo")
    ```

    Após a inicialização, o Weave fornecerá uma URL onde você poderá visualizar seus rastreamentos e métricas.
  </Step>

  <Step title="Crie seus Crews/Flows">
    ```python
    from crewai import Agent, Task, Crew, LLM, Process

    # Crie um LLM com temperatura 0 para garantir saídas determinísticas
    llm = LLM(model="gpt-4o", temperature=0)

    # Crie os agentes
    pesquisador = Agent(
        role='Analista de Pesquisa',
        goal='Encontrar e analisar as melhores oportunidades de investimento',
        backstory='Especialista em análise financeira e pesquisa de mercado',
        llm=llm,
        verbose=True,
        allow_delegation=False,
    )

    redator = Agent(
        role='Redator de Relatórios',
        goal='Escrever relatórios de investimento claros e concisos',
        backstory='Experiente na criação de relatórios financeiros detalhados',
        llm=llm,
        verbose=True,
        allow_delegation=False,
    )

    # Crie as tarefas
    pesquisa = Task(
        description='Pesquisa aprofundada sobre o {tema}',
        expected_output='Dados de mercado abrangentes incluindo principais players, tamanho de mercado e tendências de crescimento.',
        agent=pesquisador
    )

    redacao = Task(
        description='Escreva um relatório detalhado com base na pesquisa',
        expected_output='O relatório deve ser fácil de ler e entender. Use tópicos quando aplicável.',
        agent=redator
    )

    # Crie o crew
    equipe = Crew(
        agents=[pesquisador, redator],
        tasks=[pesquisa, redacao],
        verbose=True,
        process=Process.sequential,
    )

    # Execute o crew
    resultado = equipe.kickoff(inputs={"tema": "IA em ciência dos materiais"})
    print(resultado)
    ```
  </Step>

  <Step title="Visualize rastreamentos no Weave">
    Após executar sua aplicação CrewAI, acesse a URL do Weave fornecida durante a inicialização para visualizar:

    * Chamadas LLM e seus metadados
    * Interações dos agentes e fluxo de execução das tarefas
    * Métricas de desempenho como latência e uso de tokens
    * Quaisquer erros ou problemas ocorridos durante a execução

    <Frame caption="Painel de Rastreamento do Weave">
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/weave-tracing.png" alt="Exemplo de rastreamento do Weave com CrewAI" />
    </Frame>
  </Step>
</Steps>

## Funcionalidades

* O Weave captura automaticamente todas as operações do CrewAI: interações dos agentes e execuções das tarefas; chamadas LLM com metadados e uso de tokens; uso de ferramentas e resultados.
* A integração suporta todos os métodos de execução do CrewAI: `kickoff()`, `kickoff_for_each()`, `kickoff_async()` e `kickoff_for_each_async()`.
* Rastreamento automático de todas as [crewAI-tools](https://github.com/crewAIInc/crewAI-tools).
* Suporte ao recurso flow com patching por decorador (`@start`, `@listen`, `@router`, `@or_`, `@and_`).
* Rastreie guardrails personalizados passados para o `Task` do CrewAI com `@weave.op()`.

Para informações detalhadas sobre o que é suportado, acesse a [documentação do Weave CrewAI](https://weave-docs.wandb.ai/guides/integrations/crewai/#getting-started-with-flow).

## Recursos

* [📘 Documentação do Weave](https://weave-docs.wandb.ai)
* [📊 Exemplo de dashboard Weave x CrewAI](https://wandb.ai/ayut/crewai_demo/weave/traces?cols=%7B%22wb_run_id%22%3Afalse%2C%22attributes.weave.client_version%22%3Afalse%2C%22attributes.weave.os_name%22%3Afalse%2C%22attributes.weave.os_release%22%3Afalse%2C%22attributes.weave.os_version%22%3Afalse%2C%22attributes.weave.source%22%3Afalse%2C%22attributes.weave.sys_version%22%3Afalse%7D\&peekPath=%2Fayut%2Fcrewai_demo%2Fcalls%2F0195c838-38cb-71a2-8a15-651ecddf9d89)
* [🐦 X](https://x.com/weave_wb)


# Guia Rápido
Source: https://docs.crewai.com/pt-BR/quickstart

Construa seu primeiro agente de IA com a CrewAI em menos de 5 minutos.

## Construa seu primeiro Agente CrewAI

Vamos criar uma tripulação simples que nos ajudará a `pesquisar` e `relatar` sobre os `últimos avanços em IA` para um determinado tópico ou assunto.

Antes de prosseguir, certifique-se de ter concluído a instalação da CrewAI.
Se ainda não instalou, faça isso seguindo o [guia de instalação](/pt-BR/installation).

Siga os passos abaixo para começar a tripular! 🚣‍♂️

<Steps>
  <Step title="Crie sua tripulação">
    Crie um novo projeto de tripulação executando o comando abaixo em seu terminal.
    Isso criará um novo diretório chamado `latest-ai-development` com a estrutura básica para sua tripulação.

    <CodeGroup>
      ```shell Terminal
      crewai create crew latest-ai-development
      ```
    </CodeGroup>
  </Step>

  <Step title="Navegue até o novo projeto da sua tripulação">
    <CodeGroup>
      ```shell Terminal
      cd latest-ai-development
      ```
    </CodeGroup>
  </Step>

  <Step title="Modifique seu arquivo `agents.yaml`">
    <Tip>
      Você também pode modificar os agentes conforme necessário para atender ao seu caso de uso ou copiar e colar como está para seu projeto.
      Qualquer variável interpolada nos seus arquivos `agents.yaml` e `tasks.yaml`, como `{topic}`, será substituída pelo valor da variável no arquivo `main.py`.
    </Tip>

    ```yaml agents.yaml
    # src/latest_ai_development/config/agents.yaml
    researcher:
      role: >
        Pesquisador Sênior de Dados em {topic}
      goal: >
        Descobrir os avanços mais recentes em {topic}
      backstory: >
        Você é um pesquisador experiente com talento para descobrir os últimos avanços em {topic}. Conhecido por sua habilidade em encontrar as informações mais relevantes e apresentá-las de forma clara e concisa.

    reporting_analyst:
      role: >
        Analista de Relatórios em {topic}
      goal: >
        Criar relatórios detalhados com base na análise de dados e descobertas de pesquisa em {topic}
      backstory: >
        Você é um analista meticuloso com um olhar atento aos detalhes. É conhecido por sua capacidade de transformar dados complexos em relatórios claros e concisos, facilitando o entendimento e a tomada de decisão por parte dos outros.
    ```
  </Step>

  <Step title="Modifique seu arquivo `tasks.yaml`">
    ````yaml tasks.yaml
    # src/latest_ai_development/config/tasks.yaml
    research_task:
      description: >
        Realize uma pesquisa aprofundada sobre {topic}.
        Certifique-se de encontrar informações interessantes e relevantes considerando que o ano atual é 2025.
      expected_output: >
        Uma lista com 10 tópicos dos dados mais relevantes sobre {topic}
      agent: researcher

    reporting_task:
      description: >
        Revise o contexto obtido e expanda cada tópico em uma seção completa para um relatório.
        Certifique-se de que o relatório seja detalhado e contenha todas as informações relevantes.
      expected_output: >
        Um relatório completo com os principais tópicos, cada um com uma seção detalhada de informações.
        Formate como markdown sem usar '```'
      agent: reporting_analyst
      output_file: report.md
    ````
  </Step>

  <Step title="Modifique seu arquivo `crew.py`">
    ```python crew.py
    # src/latest_ai_development/crew.py
    from crewai import Agent, Crew, Process, Task
    from crewai.project import CrewBase, agent, crew, task
    from crewai_tools import SerperDevTool
    from crewai.agents.agent_builder.base_agent import BaseAgent
    from typing import List

    @CrewBase
    class LatestAiDevelopmentCrew():
      """LatestAiDevelopment crew"""

      agents: List[BaseAgent]
      tasks: List[Task]

      @agent
      def researcher(self) -> Agent:
        return Agent(
          config=self.agents_config['researcher'], # type: ignore[index]
          verbose=True,
          tools=[SerperDevTool()]
        )

      @agent
      def reporting_analyst(self) -> Agent:
        return Agent(
          config=self.agents_config['reporting_analyst'], # type: ignore[index]
          verbose=True
        )

      @task
      def research_task(self) -> Task:
        return Task(
          config=self.tasks_config['research_task'], # type: ignore[index]
        )

      @task
      def reporting_task(self) -> Task:
        return Task(
          config=self.tasks_config['reporting_task'], # type: ignore[index]
          output_file='output/report.md' # Este é o arquivo que conterá o relatório final.
        )

      @crew
      def crew(self) -> Crew:
        """Creates the LatestAiDevelopment crew"""
        return Crew(
          agents=self.agents, # Criado automaticamente pelo decorador @agent
          tasks=self.tasks, # Criado automaticamente pelo decorador @task
          process=Process.sequential,
          verbose=True,
        )
    ```
  </Step>

  <Step title="[Opcional] Adicione funções de pré e pós execução da tripulação">
    ```python crew.py
    # src/latest_ai_development/crew.py
    from crewai import Agent, Crew, Process, Task
    from crewai.project import CrewBase, agent, crew, task, before_kickoff, after_kickoff
    from crewai_tools import SerperDevTool

    @CrewBase
    class LatestAiDevelopmentCrew():
      """LatestAiDevelopment crew"""

      @before_kickoff
      def before_kickoff_function(self, inputs):
        print(f"Before kickoff function with inputs: {inputs}")
        return inputs # You can return the inputs or modify them as needed

      @after_kickoff
      def after_kickoff_function(self, result):
        print(f"After kickoff function with result: {result}")
        return result # You can return the result or modify it as needed

      # ... remaining code
    ```
  </Step>

  <Step title="Fique à vontade para passar entradas personalizadas para sua tripulação">
    Por exemplo, você pode passar o input `topic` para sua tripulação para personalizar a pesquisa e o relatório.

    ```python main.py
    #!/usr/bin/env python
    # src/latest_ai_development/main.py
    import sys
    from latest_ai_development.crew import LatestAiDevelopmentCrew

    def run():
      """
      Run the crew.
      """
      inputs = {
        'topic': 'AI Agents'
      }
      LatestAiDevelopmentCrew().crew().kickoff(inputs=inputs)
    ```
  </Step>

  <Step title="Defina suas variáveis de ambiente">
    Antes de executar sua tripulação, certifique-se de ter as seguintes chaves configuradas como variáveis de ambiente no seu arquivo `.env`:

    * Uma chave da API do [Serper.dev](https://serper.dev/): `SERPER_API_KEY=YOUR_KEY_HERE`
    * A configuração do modelo de sua escolha, como uma chave de API. Veja o
      [guia de configuração do LLM](/pt-BR/concepts/llms#setting-up-your-llm) para aprender como configurar modelos de qualquer provedor.
  </Step>

  <Step title="Trave e instale as dependências">
    * Trave e instale as dependências utilizando o comando da CLI:
      <CodeGroup>
        ```shell Terminal
        crewai install
        ```
      </CodeGroup>
    * Se quiser instalar pacotes adicionais, faça isso executando:
      <CodeGroup>
        ```shell Terminal
        uv add <package-name>
        ```
      </CodeGroup>
  </Step>

  <Step title="Execute sua tripulação">
    * Para executar sua tripulação, rode o seguinte comando na raiz do projeto:
      <CodeGroup>
        ```bash Terminal
        crewai run
        ```
      </CodeGroup>
  </Step>

  <Step title="Alternativa para Empresas: Crie no Crew Studio">
    Para usuários do CrewAI Enterprise, você pode criar a mesma tripulação sem escrever código:

    1. Faça login na sua conta CrewAI Enterprise (crie uma conta gratuita em [app.crewai.com](https://app.crewai.com))
    2. Abra o Crew Studio
    3. Digite qual automação deseja construir
    4. Crie suas tarefas visualmente e conecte-as em sequência
    5. Configure seus inputs e clique em "Download Code" ou "Deploy"

    ![Crew Studio Quickstart](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-studio-interface.png)

    <Card title="Experimente o CrewAI Enterprise" icon="rocket" href="https://app.crewai.com">
      Comece sua conta gratuita no CrewAI Enterprise
    </Card>
  </Step>

  <Step title="Veja seu relatório final">
    Você verá a saída no console e o arquivo `report.md` deve ser criado na raiz do seu projeto com o relatório final.

    Veja um exemplo de como o relatório deve ser:

    <CodeGroup>
      ```markdown output/report.md
      # Relatório Abrangente sobre a Ascensão e o Impacto dos Agentes de IA em 2025

      ## 1. Introduction to AI Agents
      In 2025, Artificial Intelligence (AI) agents are at the forefront of innovation across various industries. As intelligent systems that can perform tasks typically requiring human cognition, AI agents are paving the way for significant advancements in operational efficiency, decision-making, and overall productivity within sectors like Human Resources (HR) and Finance. This report aims to detail the rise of AI agents, their frameworks, applications, and potential implications on the workforce.

      ## 2. Benefits of AI Agents
      AI agents bring numerous advantages that are transforming traditional work environments. Key benefits include:

      - **Task Automation**: AI agents can carry out repetitive tasks such as data entry, scheduling, and payroll processing without human intervention, greatly reducing the time and resources spent on these activities.
      - **Improved Efficiency**: By quickly processing large datasets and performing analyses that would take humans significantly longer, AI agents enhance operational efficiency. This allows teams to focus on strategic tasks that require higher-level thinking.
      - **Enhanced Decision-Making**: AI agents can analyze trends and patterns in data, provide insights, and even suggest actions, helping stakeholders make informed decisions based on factual data rather than intuition alone.

      ## 3. Popular AI Agent Frameworks
      Several frameworks have emerged to facilitate the development of AI agents, each with its own unique features and capabilities. Some of the most popular frameworks include:

      - **Autogen**: A framework designed to streamline the development of AI agents through automation of code generation.
      - **Semantic Kernel**: Focuses on natural language processing and understanding, enabling agents to comprehend user intentions better.
      - **Promptflow**: Provides tools for developers to create conversational agents that can navigate complex interactions seamlessly.
      - **Langchain**: Specializes in leveraging various APIs to ensure agents can access and utilize external data effectively.
      - **CrewAI**: Aimed at collaborative environments, CrewAI strengthens teamwork by facilitating communication through AI-driven insights.
      - **MemGPT**: Combines memory-optimized architectures with generative capabilities, allowing for more personalized interactions with users.

      These frameworks empower developers to build versatile and intelligent agents that can engage users, perform advanced analytics, and execute various tasks aligned with organizational goals.

      ## 4. AI Agents in Human Resources
      AI agents are revolutionizing HR practices by automating and optimizing key functions:

      - **Recruiting**: AI agents can screen resumes, schedule interviews, and even conduct initial assessments, thus accelerating the hiring process while minimizing biases.
      - **Succession Planning**: AI systems analyze employee performance data and potential, helping organizations identify future leaders and plan appropriate training.
      - **Employee Engagement**: Chatbots powered by AI can facilitate feedback loops between employees and management, promoting an open culture and addressing concerns promptly.

      As AI continues to evolve, HR departments leveraging these agents can realize substantial improvements in both efficiency and employee satisfaction.

      ## 5. AI Agents in Finance
      The finance sector is seeing extensive integration of AI agents that enhance financial practices:

      - **Expense Tracking**: Automated systems manage and monitor expenses, flagging anomalies and offering recommendations based on spending patterns.
      - **Risk Assessment**: AI models assess credit risk and uncover potential fraud by analyzing transaction data and behavioral patterns.
      - **Investment Decisions**: AI agents provide stock predictions and analytics based on historical data and current market conditions, empowering investors with informative insights.

      The incorporation of AI agents into finance is fostering a more responsive and risk-aware financial landscape.

      ## 6. Market Trends and Investments
      The growth of AI agents has attracted significant investment, especially amidst the rising popularity of chatbots and generative AI technologies. Companies and entrepreneurs are eager to explore the potential of these systems, recognizing their ability to streamline operations and improve customer engagement.

      Conversely, corporations like Microsoft are taking strides to integrate AI agents into their product offerings, with enhancements to their Copilot 365 applications. This strategic move emphasizes the importance of AI literacy in the modern workplace and indicates the stabilizing of AI agents as essential business tools.

      ## 7. Future Predictions and Implications
      Experts predict that AI agents will transform essential aspects of work life. As we look toward the future, several anticipated changes include:

      - Enhanced integration of AI agents across all business functions, creating interconnected systems that leverage data from various departmental silos for comprehensive decision-making.
      - Continued advancement of AI technologies, resulting in smarter, more adaptable agents capable of learning and evolving from user interactions.
      - Increased regulatory scrutiny to ensure ethical use, especially concerning data privacy and employee surveillance as AI agents become more prevalent.

      To stay competitive and harness the full potential of AI agents, organizations must remain vigilant about latest developments in AI technology and consider continuous learning and adaptation in their strategic planning.

      ## 8. Conclusion
      The emergence of AI agents is undeniably reshaping the workplace landscape in 5. With their ability to automate tasks, enhance efficiency, and improve decision-making, AI agents are critical in driving operational success. Organizations must embrace and adapt to AI developments to thrive in an increasingly digital business environment.
      ```
    </CodeGroup>
  </Step>
</Steps>

<Check>
  Parabéns!

  Você configurou seu projeto de tripulação com sucesso e está pronto para começar a construir seus próprios fluxos de trabalho baseados em agentes!
</Check>

### Observação sobre Consistência nos Nomes

Os nomes utilizados nos seus arquivos YAML (`agents.yaml` e `tasks.yaml`) devem corresponder aos nomes dos métodos no seu código Python.
Por exemplo, você pode referenciar o agente para tarefas específicas a partir do arquivo `tasks.yaml`.
Essa consistência de nomes permite que a CrewAI conecte automaticamente suas configurações ao seu código; caso contrário, sua tarefa não reconhecerá a referência corretamente.

#### Exemplos de Referências

<Tip>
  Observe como usamos o mesmo nome para o agente no arquivo `agents.yaml` (`email_summarizer`) e no método do arquivo `crew.py` (`email_summarizer`).
</Tip>

```yaml agents.yaml
email_summarizer:
    role: >
      Email Summarizer
    goal: >
      Summarize emails into a concise and clear summary
    backstory: >
      You will create a 5 bullet point summary of the report
    llm: provider/model-id  # Add your choice of model here
```

<Tip>
  Observe como usamos o mesmo nome para a tarefa no arquivo `tasks.yaml` (`email_summarizer_task`) e no método no arquivo `crew.py` (`email_summarizer_task`).
</Tip>

```yaml tasks.yaml
email_summarizer_task:
    description: >
      Summarize the email into a 5 bullet point summary
    expected_output: >
      A 5 bullet point summary of the email
    agent: email_summarizer
    context:
      - reporting_task
      - research_task
```

## Fazendo o Deploy da Sua Tripulação

A forma mais fácil de fazer deploy da sua tripulação em produção é através da [CrewAI Enterprise](http://app.crewai.com).

Assista a este vídeo tutorial para uma demonstração detalhada de como fazer deploy da sua tripulação na [CrewAI Enterprise](http://app.crewai.com) usando a CLI.

<iframe width="100%" height="400" src="https://www.youtube.com/embed/3EqSV-CYDZA" title="CrewAI Deployment Guide" frameborder="0" style={{ borderRadius: '10px' }} allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

<CardGroup cols={2}>
  <Card title="Deploy no Enterprise" icon="rocket" href="http://app.crewai.com">
    Comece com o CrewAI Enterprise e faça o deploy da sua tripulação em ambiente de produção com apenas alguns cliques.
  </Card>

  <Card title="Junte-se à Comunidade" icon="comments" href="https://community.crewai.com">
    Participe da nossa comunidade open source para discutir ideias, compartilhar seus projetos e conectar-se com outros desenvolvedores CrewAI.
  </Card>
</CardGroup>


# null
Source: https://docs.crewai.com/pt-BR/snippets/snippet-intro



Um dos princípios fundamentais do desenvolvimento de software é o DRY (Don't Repeat Yourself, ou Não Se Repita). Esse princípio também se aplica à documentação. Se você perceber que está repetindo o mesmo conteúdo em vários lugares, considere criar um snippet personalizado para manter seu conteúdo sincronizado.


# Telemetria
Source: https://docs.crewai.com/pt-BR/telemetry

Entendendo os dados de telemetria coletados pelo CrewAI e como eles contribuem para o aprimoramento da biblioteca.

## Telemetria

<Note>
  Por padrão, não coletamos dados que possam ser considerados informações pessoais segundo a GDPR e outras regulamentações de privacidade.
  Coletamos nomes das ferramentas e funções dos agentes, portanto, evite incluir qualquer informação pessoal nos nomes das ferramentas ou nas funções dos agentes.
  Como nenhuma informação pessoal é coletada, não é necessário se preocupar com localidade dos dados.
  Quando `share_crew` está ativado, dados adicionais são coletados e podem conter informações pessoais caso sejam incluídas pelo usuário.
  Usuários devem tomar cuidado ao habilitar este recurso para garantir conformidade com regulamentações de privacidade.
</Note>

O CrewAI utiliza telemetria anônima para coletar estatísticas de uso com o objetivo principal de aprimorar a biblioteca.
Nosso foco está em melhorar e desenvolver as funcionalidades, integrações e ferramentas mais utilizadas pelos usuários.

É fundamental compreender que, por padrão, **NENHUM dado pessoal é coletado** referente a prompts, descrições de tarefas, histórias ou objetivos dos agentes,
uso de ferramentas, chamadas de API, respostas, quaisquer dados processados pelos agentes ou segredos e variáveis de ambiente.
Quando o recurso `share_crew` está ativado, dados detalhados, incluindo descrições das tarefas, histórias ou objetivos dos agentes e outros atributos específicos são coletados
para fornecer insights mais detalhados. Essa coleta expandida pode incluir informações pessoais caso o usuário as tenha inserido em seus crews ou tarefas.
Usuários devem considerar cuidadosamente o conteúdo de seus crews e tarefas antes de habilitar o `share_crew`.
A telemetria pode ser desabilitada ao definir a variável de ambiente `CREWAI_DISABLE_TELEMETRY` como `true` ou ao definir `OTEL_SDK_DISABLED` como `true` (observe que esta última desabilita toda instrumentação OpenTelemetry globalmente).

### Exemplos:

```python
# Desabilitar apenas a telemetria do CrewAI
os.environ['CREWAI_DISABLE_TELEMETRY'] = 'true'

# Desabilitar todo o OpenTelemetry (incluindo CrewAI)
os.environ['OTEL_SDK_DISABLED'] = 'true'
```

### Explicação dos Dados:

| Padrão | Dados                                          | Razão e Especificidades                                                                                                                                                                                                                                                                                                                                        |
| ------ | ---------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Sim    | Versão do CrewAI e Python                      | Rastreia versões dos softwares. Exemplo: CrewAI v1.2.3, Python 3.8.10. Sem dados pessoais.                                                                                                                                                                                                                                                                     |
| Sim    | Metadados do Crew                              | Inclui: chave e ID gerados aleatoriamente, tipo de processo (ex: 'sequential', 'parallel'), flag booleana para uso de memória (true/false), quantidade de tarefas, quantidade de agentes. Tudo não pessoal.                                                                                                                                                    |
| Sim    | Dados do Agente                                | Inclui: chave e ID gerados aleatoriamente, nome da função (não deve incluir info pessoal), configurações booleanas (verbose, delegação habilitada, execução de código permitida), máximo de iterações, máximo de RPM, limite de tentativas, info do LLM (ver Atributos LLM), lista de nomes de ferramentas (não deve conter info pessoal). Sem dados pessoais. |
| Sim    | Metadados da Tarefa                            | Inclui: chave e ID gerados aleatoriamente, configurações de execução booleanas (async\_execution, human\_input), função e chave do agente associado, lista de nomes de ferramentas. Tudo não pessoal.                                                                                                                                                          |
| Sim    | Estatísticas de Uso de Ferramentas             | Inclui: nome da ferramenta (não deve incluir info pessoal), número de tentativas de uso (inteiro), atributos LLM utilizados. Sem dados pessoais.                                                                                                                                                                                                               |
| Sim    | Dados de Execução de Testes                    | Inclui: chave e ID aleatórias do crew, número de iterações, nome do modelo usado, score de qualidade (float), tempo de execução (em segundos). Tudo não pessoal.                                                                                                                                                                                               |
| Sim    | Dados do Ciclo de Vida da Tarefa               | Inclui: horários de criação, início/fim de execução, identificadores de crew e tarefa. Armazenado como spans com timestamps. Sem dados pessoais.                                                                                                                                                                                                               |
| Sim    | Atributos do LLM                               | Inclui: nome, model\_name, model, top\_k, temperatura e nome da classe do LLM. Todos técnicos, sem dados pessoais.                                                                                                                                                                                                                                             |
| Sim    | Tentativa de Deploy do Crew pelo CLI do crewAI | Inclui: O fato de um deploy estar sendo realizado e o crew id, e se está tentando buscar logs, sem mais dados.                                                                                                                                                                                                                                                 |
| Não    | Dados Expandidos do Agente                     | Inclui: descrição do objetivo, texto da história, identificador de arquivo i18n prompt. Usuários devem garantir que não haja info pessoal nesses campos de texto.                                                                                                                                                                                              |
| Não    | Informações Detalhadas da Tarefa               | Inclui: descrição da tarefa, descrição do resultado esperado, referências de contexto. Usuários devem garantir que não haja info pessoal nessas áreas.                                                                                                                                                                                                         |
| Não    | Informações de Ambiente                        | Inclui: plataforma, release, sistema, versão e quantidade de CPUs. Exemplo: 'Windows 10', 'x86\_64'. Sem dados pessoais.                                                                                                                                                                                                                                       |
| Não    | Entradas e Saídas de Crew e Tarefas            | Inclui: parâmetros de entrada e resultados como dados não identificáveis. Usuários devem garantir que não haja info pessoal.                                                                                                                                                                                                                                   |
| Não    | Dados Abrangentes de Execução do Crew          | Inclui: logs detalhados das operações do crew, dados de todos os agentes e tarefas, resultado final. Tudo de natureza técnica, sem dados pessoais.                                                                                                                                                                                                             |

<Note>
  "Não" na coluna "Padrão" indica que esse dado só é coletado quando `share_crew` está configurado como `true`.
</Note>

### Compartilhamento Avançado de Telemetria (Opt-In)

Usuários podem optar por compartilhar toda a telemetria habilitando o atributo `share_crew` como `True` nas configurações do seu crew.
Ao habilitar `share_crew`, há coleta detalhada dos dados de execução do crew e das tarefas, incluindo `goal`, `backstory`, `context` e `output` das tarefas.
Isso permite uma compreensão mais profunda dos padrões de uso.

<Warning>
  Se você habilitar o `share_crew`, os dados coletados podem incluir informações pessoais caso estas estejam presentes nas configurações do crew, descrições de tarefas ou outputs.
  Os usuários devem revisar cuidadosamente seus dados e garantir conformidade com a GDPR e outras regulamentações de privacidade antes de habilitar esse recurso.
</Warning>


# AI Mind Tool
Source: https://docs.crewai.com/pt-BR/tools/ai-ml/aimindtool

O `AIMindTool` foi desenvolvido para consultar fontes de dados em linguagem natural.

# `AIMindTool`

## Descrição

O `AIMindTool` é um wrapper em torno do [AI-Minds](https://mindsdb.com/minds) fornecido pela [MindsDB](https://mindsdb.com/). Ele permite que você consulte fontes de dados em linguagem natural, bastando configurar os parâmetros de conexão. Essa ferramenta é útil quando você precisa de respostas para perguntas utilizando dados armazenados em diversas fontes, incluindo PostgreSQL, MySQL, MariaDB, ClickHouse, Snowflake e Google BigQuery.

Minds são sistemas de IA que funcionam de forma similar aos grandes modelos de linguagem (LLMs), mas vão além ao responder qualquer pergunta sobre qualquer dado. Isso é realizado por meio de:

* Seleção dos dados mais relevantes para a resposta utilizando busca paramétrica
* Compreensão do significado e fornecimento de respostas dentro do contexto correto através de busca semântica
* Entrega de respostas precisas ao analisar dados e utilizar modelos de machine learning (ML)

## Instalação

Para incorporar esta ferramenta ao seu projeto, é necessário instalar o Minds SDK:

```shell
uv add minds-sdk
```

## Passos para Começar

Para utilizar o `AIMindTool` de maneira eficaz, siga estes passos:

1. **Instalação de Pacotes**: Verifique se os pacotes `crewai[tools]` e `minds-sdk` estão instalados no seu ambiente Python.
2. **Obtenção da Chave de API**: Cadastre-se para uma conta Minds [aqui](https://mdb.ai/register) e obtenha uma chave de API.
3. **Configuração do Ambiente**: Armazene sua chave de API obtida em uma variável de ambiente chamada `MINDS_API_KEY` para facilitar seu uso pela ferramenta.

## Exemplo

O exemplo a seguir demonstra como inicializar a ferramenta e executar uma consulta:

```python Code
from crewai_tools import AIMindTool

# Initialize the AIMindTool
aimind_tool = AIMindTool(
    datasources=[
        {
            "description": "house sales data",
            "engine": "postgres",
            "connection_data": {
                "user": "demo_user",
                "password": "demo_password",
                "host": "samples.mindsdb.com",
                "port": 5432,
                "database": "demo",
                "schema": "demo_data"
            },
            "tables": ["house_sales"]
        }
    ]
)

# Run a natural language query
result = aimind_tool.run("How many 3 bedroom houses were sold in 2008?")
print(result)
```

## Parâmetros

O `AIMindTool` aceita os seguintes parâmetros:

* **api\_key**: Opcional. Sua chave de API da Minds. Se não for fornecida, será lida da variável de ambiente `MINDS_API_KEY`.
* **datasources**: Uma lista de dicionários, cada um contendo as seguintes chaves:
  * **description**: Uma descrição dos dados contidos na fonte de dados.
  * **engine**: O engine (ou tipo) da fonte de dados.
  * **connection\_data**: Um dicionário contendo os parâmetros de conexão da fonte de dados.
  * **tables**: Uma lista de tabelas que a fonte de dados irá utilizar. Isso é opcional e pode ser omitido caso todas as tabelas da fonte de dados devam ser utilizadas.

Uma lista das fontes de dados suportadas e seus parâmetros de conexão pode ser encontrada [aqui](https://docs.mdb.ai/docs/data_sources).

## Exemplo de Integração com Agente

Veja como integrar o `AIMindTool` com um agente CrewAI:

```python Code
from crewai import Agent
from crewai.project import agent
from crewai_tools import AIMindTool

# Initialize the tool
aimind_tool = AIMindTool(
    datasources=[
        {
            "description": "sales data",
            "engine": "postgres",
            "connection_data": {
                "user": "your_user",
                "password": "your_password",
                "host": "your_host",
                "port": 5432,
                "database": "your_db",
                "schema": "your_schema"
            },
            "tables": ["sales"]
        }
    ]
)

# Define an agent with the AIMindTool
@agent
def data_analyst(self) -> Agent:
    return Agent(
        config=self.agents_config["data_analyst"],
        allow_delegation=False,
        tools=[aimind_tool]
    )
```

## Conclusão

O `AIMindTool` oferece uma forma poderosa de consultar suas fontes de dados utilizando linguagem natural, facilitando a extração de insights sem a necessidade de escrever consultas SQL complexas. Ao conectar diversas fontes de dados e aproveitar a tecnologia AI-Minds, essa ferramenta permite que agentes acessem e analisem dados de maneira eficiente.


# Interpretador de Código
Source: https://docs.crewai.com/pt-BR/tools/ai-ml/codeinterpretertool

O `CodeInterpreterTool` é uma poderosa ferramenta projetada para executar código Python 3 em um ambiente seguro e isolado.

# `CodeInterpreterTool`

## Descrição

O `CodeInterpreterTool` permite que agentes CrewAI executem códigos Python 3 gerados autonomamente. Essa funcionalidade é particularmente valiosa, pois permite que os agentes criem códigos, os executem, obtenham os resultados e usem essas informações para orientar decisões e ações subsequentes.

Há diversas formas de usar esta ferramenta:

### Container Docker (Recomendado)

Esta é a opção principal. O código é executado em um container Docker seguro e isolado, garantindo a segurança independentemente de seu conteúdo.
Certifique-se de que o Docker esteja instalado e em funcionamento em seu sistema. Se ainda não tiver, você pode instalá-lo a partir [deste link](https://docs.docker.com/get-docker/).

### Ambiente Sandbox

Se o Docker não estiver disponível — seja por não estar instalado ou inacessível por qualquer motivo — o código será executado em um ambiente Python restrito, chamado de sandbox.
Esse ambiente é bastante limitado, com restrições severas a vários módulos e funções embutidas.

### Execução Não Segura

**NÃO RECOMENDADO PARA PRODUÇÃO**
Este modo permite a execução de qualquer código Python, inclusive chamadas perigosas para os módulos `sys, os..` e semelhantes. [Veja aqui](/pt-BR/tools/ai-ml/codeinterpretertool#enabling-unsafe-mode) como habilitar este modo.

## Registro de Logs

O `CodeInterpreterTool` registra a estratégia de execução selecionada no STDOUT.

## Instalação

Para utilizar esta ferramenta, você precisa instalar o pacote de ferramentas CrewAI:

```shell
pip install 'crewai[tools]'
```

## Exemplo

O exemplo a seguir demonstra como usar o `CodeInterpreterTool` com um agente CrewAI:

```python Code
from crewai import Agent, Task, Crew, Process
from crewai_tools import CodeInterpreterTool

# Initialize the tool
code_interpreter = CodeInterpreterTool()

# Define an agent that uses the tool
programmer_agent = Agent(
    role="Python Programmer",
    goal="Write and execute Python code to solve problems",
    backstory="An expert Python programmer who can write efficient code to solve complex problems.",
    tools=[code_interpreter],
    verbose=True,
)

# Example task to generate and execute code
coding_task = Task(
    description="Write a Python function to calculate the Fibonacci sequence up to the 10th number and print the result.",
    expected_output="The Fibonacci sequence up to the 10th number.",
    agent=programmer_agent,
)

# Create and run the crew
crew = Crew(
    agents=[programmer_agent],
    tasks=[coding_task],
    verbose=True,
    process=Process.sequential,
)
result = crew.kickoff()
```

Você também pode habilitar a execução de código diretamente ao criar um agente:

```python Code
from crewai import Agent

# Create an agent with code execution enabled
programmer_agent = Agent(
    role="Python Programmer",
    goal="Write and execute Python code to solve problems",
    backstory="An expert Python programmer who can write efficient code to solve complex problems.",
    allow_code_execution=True,  # This automatically adds the CodeInterpreterTool
    verbose=True,
)
```

### Habilitando o `unsafe_mode`

```python Code
from crewai_tools import CodeInterpreterTool

code = """
import os
os.system("ls -la")
"""

CodeInterpreterTool(unsafe_mode=True).run(code=code)
```

## Parâmetros

O `CodeInterpreterTool` aceita os seguintes parâmetros durante a inicialização:

* **user\_dockerfile\_path**: Opcional. Caminho para um Dockerfile personalizado a ser utilizado pelo container do interpretador de código.
* **user\_docker\_base\_url**: Opcional. URL do daemon Docker que será usado para rodar o container.
* **unsafe\_mode**: Opcional. Indica se o código será executado diretamente na máquina hospedeira ao invés de um container Docker ou sandbox. O padrão é `False`. Use com cautela!
* **default\_image\_tag**: Opcional. Tag padrão da imagem Docker. O padrão é `code-interpreter:latest`

Ao utilizar a ferramenta com um agente, o agente precisará fornecer:

* **code**: Obrigatório. O código Python 3 a ser executado.
* **libraries\_used**: Opcional. Uma lista de bibliotecas usadas no código que precisam ser instaladas. O padrão é `[]`

## Exemplo de Integração com Agente

Aqui está um exemplo mais detalhado de como integrar o `CodeInterpreterTool` com um agente CrewAI:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import CodeInterpreterTool

# Initialize the tool
code_interpreter = CodeInterpreterTool()

# Define an agent that uses the tool
data_analyst = Agent(
    role="Data Analyst",
    goal="Analyze data using Python code",
    backstory="""You are an expert data analyst who specializes in using Python
    to analyze and visualize data. You can write efficient code to process
    large datasets and extract meaningful insights.""",
    tools=[code_interpreter],
    verbose=True,
)

# Create a task for the agent
analysis_task = Task(
    description="""
    Write Python code to:
    1. Generate a random dataset of 100 points with x and y coordinates
    2. Calculate the correlation coefficient between x and y
    3. Create a scatter plot of the data
    4. Print the correlation coefficient and save the plot as 'scatter.png'

    Make sure to handle any necessary imports and print the results.
    """,
    expected_output="The correlation coefficient and confirmation that the scatter plot has been saved.",
    agent=data_analyst,
)

# Run the task
crew = Crew(
    agents=[data_analyst],
    tasks=[analysis_task],
    verbose=True,
    process=Process.sequential,
)
result = crew.kickoff()
```

## Detalhes de Implementação

O `CodeInterpreterTool` utiliza Docker para criar um ambiente seguro para execução de código:

```python Code
class CodeInterpreterTool(BaseTool):
    name: str = "Code Interpreter"
    description: str = "Interprets Python3 code strings with a final print statement."
    args_schema: Type[BaseModel] = CodeInterpreterSchema
    default_image_tag: str = "code-interpreter:latest"

    def _run(self, **kwargs) -> str:
        code = kwargs.get("code", self.code)
        libraries_used = kwargs.get("libraries_used", [])

        if self.unsafe_mode:
            return self.run_code_unsafe(code, libraries_used)
        else:
            return self.run_code_safety(code, libraries_used)
```

A ferramenta executa os seguintes passos:

1. Verifica se a imagem Docker existe ou a constrói, caso necessário
2. Cria um container Docker com o diretório de trabalho atual montado
3. Instala quaisquer bibliotecas necessárias especificadas pelo agente
4. Executa o código Python dentro do container
5. Retorna a saída da execução do código
6. Limpa o ambiente, parando e removendo o container

## Considerações de Segurança

Por padrão, o `CodeInterpreterTool` executa o código em um container Docker isolado, fornecendo uma camada de segurança. No entanto, ainda há algumas considerações importantes:

1. O container Docker tem acesso ao diretório de trabalho atual, então arquivos sensíveis podem ser potencialmente acessados.
2. Caso o container Docker não esteja disponível e o código precise ser executado de forma segura, ele será executado em um ambiente sandbox. Por motivos de segurança, a instalação de bibliotecas arbitrárias não é permitida
3. O parâmetro `unsafe_mode` permite que códigos sejam executados diretamente na máquina hospedeira, o que deve ser usado apenas em ambientes confiáveis.
4. Tenha cautela ao permitir que agentes instalem bibliotecas arbitrárias, pois estas podem incluir códigos maliciosos.

## Conclusão

O `CodeInterpreterTool` oferece uma maneira poderosa para que agentes CrewAI executem código Python em um ambiente relativamente seguro. Permitindo que agentes escrevam e executem códigos, ele amplia significativamente sua capacidade de resolução de problemas, especialmente para tarefas que envolvem análise de dados, cálculos ou outros trabalhos computacionais. Esta ferramenta é especialmente útil para agentes que precisam realizar operações complexas que são mais eficientemente expressas em código do que em linguagem natural.


# Ferramenta DALL-E
Source: https://docs.crewai.com/pt-BR/tools/ai-ml/dalletool

A `DallETool` é uma ferramenta poderosa projetada para gerar imagens a partir de descrições textuais.

# `DallETool`

## Descrição

Esta ferramenta é utilizada para dar ao Agente a capacidade de gerar imagens usando o modelo DALL-E. Trata-se de um modelo baseado em transformer que gera imagens a partir de descrições textuais.
Esta ferramenta permite que o Agente gere imagens com base no texto de entrada fornecido pelo usuário.

## Instalação

Instale o pacote crewai\_tools

```shell
pip install 'crewai[tools]'
```

## Exemplo

Lembre-se de que, ao usar esta ferramenta, o texto deve ser gerado pelo próprio Agente. O texto deve ser uma descrição da imagem que você deseja gerar.

```python Code
from crewai_tools import DallETool

Agent(
    ...
    tools=[DallETool()],
)
```

Se necessário, você também pode ajustar os parâmetros do modelo DALL-E passando-os como argumentos para a classe `DallETool`. Por exemplo:

```python Code
from crewai_tools import DallETool

dalle_tool = DallETool(model="dall-e-3",
                       size="1024x1024",
                       quality="standard",
                       n=1)

Agent(
    ...
    tools=[dalle_tool]
)
```

Os parâmetros são baseados no método `client.images.generate` da API OpenAI. Para mais informações sobre os parâmetros,
consulte a [documentação da API OpenAI](https://platform.openai.com/docs/guides/images/introduction?lang=python).


# Ferramenta LangChain
Source: https://docs.crewai.com/pt-BR/tools/ai-ml/langchaintool

O `LangChainTool` é um wrapper para ferramentas LangChain e mecanismos de consulta.

## `LangChainTool`

<Info>
  CrewAI integra-se perfeitamente com a abrangente [lista de ferramentas](https://python.langchain.com/docs/integrations/tools/) do LangChain, todas as quais podem ser usadas com CrewAI.
</Info>

```python Code
import os
from dotenv import load_dotenv
from crewai import Agent, Task, Crew
from crewai.tools import BaseTool
from pydantic import Field
from langchain_community.utilities import GoogleSerperAPIWrapper

# Set up your SERPER_API_KEY key in an .env file, eg:
# SERPER_API_KEY=<your api key>
load_dotenv()

search = GoogleSerperAPIWrapper()

class SearchTool(BaseTool):
    name: str = "Search"
    description: str = "Useful for search-based queries. Use this to find current information about markets, companies, and trends."
    search: GoogleSerperAPIWrapper = Field(default_factory=GoogleSerperAPIWrapper)

    def _run(self, query: str) -> str:
        """Execute the search query and return results"""
        try:
            return self.search.run(query)
        except Exception as e:
            return f"Error performing search: {str(e)}"

# Create Agents
researcher = Agent(
    role='Research Analyst',
    goal='Gather current market data and trends',
    backstory="""You are an expert research analyst with years of experience in
    gathering market intelligence. You're known for your ability to find
    relevant and up-to-date market information and present it in a clear,
    actionable format.""",
    tools=[SearchTool()],
    verbose=True
)

# rest of the code ...
```

## Conclusão

As ferramentas são fundamentais para ampliar as capacidades dos agentes CrewAI, permitindo que realizem uma ampla variedade de tarefas e colaborem de forma eficaz.
Ao construir soluções com CrewAI, aproveite tanto ferramentas personalizadas quanto existentes para potencializar seus agentes e aprimorar o ecossistema de IA. Considere utilizar tratamento de erros, mecanismos de cache e a flexibilidade dos argumentos das ferramentas para otimizar o desempenho e as capacidades dos seus agentes.


# Ferramenta LlamaIndex
Source: https://docs.crewai.com/pt-BR/tools/ai-ml/llamaindextool

A `LlamaIndexTool` é um wrapper para ferramentas e mecanismos de consulta do LlamaIndex.

# `LlamaIndexTool`

## Descrição

A `LlamaIndexTool` foi projetada para ser um wrapper geral em torno das ferramentas e mecanismos de consulta do LlamaIndex, permitindo que você aproveite os recursos do LlamaIndex em pipelines de RAG/agent como ferramentas que podem ser acopladas aos agentes do CrewAI. Essa ferramenta permite integrar de forma transparente as poderosas capacidades de processamento e recuperação de dados do LlamaIndex em seus fluxos de trabalho com o CrewAI.

## Instalação

Para utilizar esta ferramenta, é necessário instalar o LlamaIndex:

```shell
uv add llama-index
```

## Passos para Começar

Para utilizar a `LlamaIndexTool` de forma eficaz, siga os passos abaixo:

1. **Instale o LlamaIndex**: Instale o pacote LlamaIndex usando o comando acima.
2. **Configure o LlamaIndex**: Siga a [documentação do LlamaIndex](https://docs.llamaindex.ai/) para configurar um pipeline de RAG/agent.
3. **Crie uma Ferramenta ou Mecanismo de Consulta**: Crie uma ferramenta ou mecanismo de consulta do LlamaIndex que você deseja usar com o CrewAI.

## Exemplo

Os exemplos a seguir demonstram como inicializar a ferramenta a partir de diferentes componentes do LlamaIndex:

### A partir de uma ferramenta do LlamaIndex

```python Code
from crewai_tools import LlamaIndexTool
from crewai import Agent
from llama_index.core.tools import FunctionTool

# Exemplo 1: Inicializando a partir do FunctionTool
def search_data(query: str) -> str:
    """Busca por informações nos dados."""
    # Sua implementação aqui
    return f"Results for: {query}"

# Criação de um LlamaIndex FunctionTool
og_tool = FunctionTool.from_defaults(
    search_data,
    name="DataSearchTool",
    description="Search for information in the data"
)

# Envolvendo com a LlamaIndexTool
tool = LlamaIndexTool.from_tool(og_tool)

# Definindo um agente que utiliza a ferramenta
@agent
def researcher(self) -> Agent:
    '''
    Este agente usa a LlamaIndexTool para buscar informações.
    '''
    return Agent(
        config=self.agents_config["researcher"],
        tools=[tool]
    )
```

### A partir de Ferramentas do LlamaHub

```python Code
from crewai_tools import LlamaIndexTool
from llama_index.tools.wolfram_alpha import WolframAlphaToolSpec

# Inicializando a partir das ferramentas do LlamaHub
wolfram_spec = WolframAlphaToolSpec(app_id="your_app_id")
wolfram_tools = wolfram_spec.to_tool_list()
tools = [LlamaIndexTool.from_tool(t) for t in wolfram_tools]
```

### A partir de um mecanismo de consulta do LlamaIndex

```python Code
from crewai_tools import LlamaIndexTool
from llama_index.core import VectorStoreIndex
from llama_index.core.readers import SimpleDirectoryReader

# Carregar documentos
documents = SimpleDirectoryReader("./data").load_data()

# Criar um índice
index = VectorStoreIndex.from_documents(documents)

# Criar um mecanismo de consulta
query_engine = index.as_query_engine()

# Criar uma LlamaIndexTool a partir do mecanismo de consulta
query_tool = LlamaIndexTool.from_query_engine(
    query_engine,
    name="Company Data Query Tool",
    description="Use this tool to lookup information in company documents"
)
```

## Métodos da Classe

A `LlamaIndexTool` oferece dois métodos de classe principais para criar instâncias:

### from\_tool

Cria uma `LlamaIndexTool` a partir de uma ferramenta do LlamaIndex.

```python Code
@classmethod
def from_tool(cls, tool: Any, **kwargs: Any) -> "LlamaIndexTool":
    # Implementation details
```

### from\_query\_engine

Cria uma `LlamaIndexTool` a partir de um mecanismo de consulta do LlamaIndex.

```python Code
@classmethod
def from_query_engine(
    cls,
    query_engine: Any,
    name: Optional[str] = None,
    description: Optional[str] = None,
    return_direct: bool = False,
    **kwargs: Any,
) -> "LlamaIndexTool":
    # Implementation details
```

## Parâmetros

O método `from_query_engine` aceita os seguintes parâmetros:

* **query\_engine**: Obrigatório. O mecanismo de consulta do LlamaIndex a ser envolvido.
* **name**: Opcional. O nome da ferramenta.
* **description**: Opcional. A descrição da ferramenta.
* **return\_direct**: Opcional. Define se deve retornar a resposta diretamente. O padrão é `False`.

## Conclusão

A `LlamaIndexTool` oferece uma maneira poderosa de integrar as capacidades do LlamaIndex aos agentes do CrewAI. Ao envolver ferramentas e mecanismos de consulta do LlamaIndex, ela permite que os agentes utilizem funcionalidades sofisticadas de recuperação e processamento de dados, aprimorando sua capacidade de trabalhar com fontes de informação complexas.


# Visão Geral
Source: https://docs.crewai.com/pt-BR/tools/ai-ml/overview

Aproveite serviços de IA, gere imagens, processe visão e construa sistemas inteligentes

Essas ferramentas se integram com serviços de IA e machine learning para aprimorar seus agentes com capacidades avançadas como geração de imagens, processamento de visão e execução inteligente de código.

## **Ferramentas Disponíveis**

<CardGroup cols={2}>
  <Card title="DALL-E Tool" icon="image" href="/pt-BR/tools/ai-ml/dalletool">
    Gere imagens com IA utilizando o modelo DALL-E da OpenAI.
  </Card>

  <Card title="Vision Tool" icon="eye" href="/pt-BR/tools/ai-ml/visiontool">
    Processe e analise imagens com capacidades de visão computacional.
  </Card>

  <Card title="AI Mind Tool" icon="brain" href="/pt-BR/tools/ai-ml/aimindtool">
    Capacidades avançadas de raciocínio e tomada de decisão com IA.
  </Card>

  <Card title="LlamaIndex Tool" icon="llama" href="/pt-BR/tools/ai-ml/llamaindextool">
    Construa bases de conhecimento e sistemas de recuperação com LlamaIndex.
  </Card>

  <Card title="LangChain Tool" icon="link" href="/pt-BR/tools/ai-ml/langchaintool">
    Integre com LangChain para fluxos de trabalho de IA complexos.
  </Card>

  <Card title="RAG Tool" icon="database" href="/pt-BR/tools/ai-ml/ragtool">
    Implemente sistemas de Geração Aumentada por Recuperação (RAG).
  </Card>

  <Card title="Code Interpreter Tool" icon="code" href="/pt-BR/tools/ai-ml/codeinterpretertool">
    Execute código Python e realize análises de dados.
  </Card>
</CardGroup>

## **Casos de Uso Comuns**

* **Geração de Conteúdo**: Crie imagens, textos e conteúdo multimídia
* **Análise de Dados**: Execute código e analise conjuntos de dados complexos
* **Sistemas de Conhecimento**: Construa sistemas RAG e bancos de dados inteligentes
* **Visão Computacional**: Processe e compreenda conteúdo visual
* **Segurança em IA**: Implemente moderação de conteúdo e checagens de segurança

```python
from crewai_tools import DallETool, VisionTool, CodeInterpreterTool

# Create AI tools
image_generator = DallETool()
vision_processor = VisionTool()
code_executor = CodeInterpreterTool()

# Add to your agent
agent = Agent(
    role="AI Specialist",
    tools=[image_generator, vision_processor, code_executor],
    goal="Create and analyze content using AI capabilities"
)
```


# Ferramenta RAG
Source: https://docs.crewai.com/pt-BR/tools/ai-ml/ragtool

O `RagTool` é uma ferramenta dinâmica de base de conhecimento para responder perguntas usando Geração Aumentada por Recuperação.

# `RagTool`

## Descrição

O `RagTool` foi desenvolvido para responder perguntas aproveitando o poder da Geração Aumentada por Recuperação (RAG) através do EmbedChain.
Ele fornece uma base de conhecimento dinâmica que pode ser consultada para recuperar informações relevantes de várias fontes de dados.
Esta ferramenta é particularmente útil para aplicações que exigem acesso a uma ampla variedade de informações e precisam fornecer respostas contextualmente relevantes.

## Exemplo

O exemplo a seguir demonstra como inicializar a ferramenta e usá-la com diferentes fontes de dados:

```python Code
from crewai_tools import RagTool

# Create a RAG tool with default settings
rag_tool = RagTool()

# Add content from a file
rag_tool.add(data_type="file", path="path/to/your/document.pdf")

# Add content from a web page
rag_tool.add(data_type="web_page", url="https://example.com")

# Define an agent with the RagTool
@agent
def knowledge_expert(self) -> Agent:
    '''
    This agent uses the RagTool to answer questions about the knowledge base.
    '''
    return Agent(
        config=self.agents_config["knowledge_expert"],
        allow_delegation=False,
        tools=[rag_tool]
    )
```

## Fontes de Dados Suportadas

O `RagTool` pode ser utilizado com uma grande variedade de fontes de dados, incluindo:

* 📰 Arquivos PDF
* 📊 Arquivos CSV
* 📃 Arquivos JSON
* 📝 Texto
* 📁 Diretórios/Pastas
* 🌐 Páginas web em HTML
* 📽️ Canais do YouTube
* 📺 Vídeos do YouTube
* 📚 Sites de documentação
* 📝 Arquivos MDX
* 📄 Arquivos DOCX
* 🧾 Arquivos XML
* 📬 Gmail
* 📝 Repositórios GitHub
* 🐘 Bancos de dados PostgreSQL
* 🐬 Bancos de dados MySQL
* 🤖 Conversas no Slack
* 💬 Mensagens do Discord
* 🗨️ Fóruns Discourse
* 📝 Newsletters do Substack
* 🐝 Conteúdo do Beehiiv
* 💾 Arquivos Dropbox
* 🖼️ Imagens
* ⚙️ Fontes de dados personalizadas

## Parâmetros

O `RagTool` aceita os seguintes parâmetros:

* **summarize**: Opcional. Indica se o conteúdo recuperado deve ser resumido. O padrão é `False`.
* **adapter**: Opcional. Um adaptador personalizado para a base de conhecimento. Se não for fornecido, será utilizado o EmbedchainAdapter.
* **config**: Opcional. Configuração para o aplicativo EmbedChain subjacente.

## Adicionando Conteúdo

Você pode adicionar conteúdo à base de conhecimento utilizando o método `add`:

```python Code
# Add a PDF file
rag_tool.add(data_type="file", path="path/to/your/document.pdf")

# Add a web page
rag_tool.add(data_type="web_page", url="https://example.com")

# Add a YouTube video
rag_tool.add(data_type="youtube_video", url="https://www.youtube.com/watch?v=VIDEO_ID")

# Add a directory of files
rag_tool.add(data_type="directory", path="path/to/your/directory")
```

## Exemplo de Integração com Agente

Veja como integrar o `RagTool` com um agente do CrewAI:

```python Code
from crewai import Agent
from crewai.project import agent
from crewai_tools import RagTool

# Initialize the tool and add content
rag_tool = RagTool()
rag_tool.add(data_type="web_page", url="https://docs.crewai.com")
rag_tool.add(data_type="file", path="company_data.pdf")

# Define an agent with the RagTool
@agent
def knowledge_expert(self) -> Agent:
    return Agent(
        config=self.agents_config["knowledge_expert"],
        allow_delegation=False,
        tools=[rag_tool]
    )
```

## Configuração Avançada

É possível personalizar o comportamento do `RagTool` fornecendo um dicionário de configuração:

```python Code
from crewai_tools import RagTool

# Create a RAG tool with custom configuration
config = {
    "app": {
        "name": "custom_app",
    },
    "llm": {
        "provider": "openai",
        "config": {
            "model": "gpt-4",
        }
    },
    "embedding_model": {
        "provider": "openai",
        "config": {
            "model": "text-embedding-ada-002"
        }
    },
    "vectordb": {
        "provider": "elasticsearch",
        "config": {
            "collection_name": "my-collection",
            "cloud_id": "deployment-name:xxxx",
            "api_key": "your-key",
            "verify_certs": False
        }
    },
    "chunker": {
        "chunk_size": 400,
        "chunk_overlap": 100,
        "length_function": "len",
        "min_chunk_size": 0
    }
}

rag_tool = RagTool(config=config, summarize=True)
```

A ferramenta RAG interna utiliza o adaptador Embedchain, possibilitando que você forneça quaisquer opções de configuração suportadas pelo Embedchain.
Você pode consultar a [documentação do Embedchain](https://docs.embedchain.ai/components/introduction) para mais detalhes.
Certifique-se de revisar as opções de configuração disponíveis no arquivo .yaml.

## Conclusão

O `RagTool` oferece uma maneira poderosa de criar e consultar bases de conhecimento a partir de diversas fontes de dados. Ao explorar a Geração Aumentada por Recuperação, ele permite que agentes acessem e recuperem informações relevantes de forma eficiente, ampliando a capacidade de fornecer respostas precisas e contextualmente apropriadas.


# Vision Tool
Source: https://docs.crewai.com/pt-BR/tools/ai-ml/visiontool

O `VisionTool` foi projetado para extrair texto de imagens.

# `VisionTool`

## Descrição

Esta ferramenta é utilizada para extrair texto de imagens. Quando passada para o agente, ela extrai o texto da imagem e depois o utiliza para gerar uma resposta, relatório ou qualquer outra saída.
A URL ou o CAMINHO da imagem deve ser passado para o Agente.

## Instalação

Instale o pacote crewai\_tools

```shell
pip install 'crewai[tools]'
```

## Uso

Para usar o VisionTool, a chave da API da OpenAI deve ser definida na variável de ambiente `OPENAI_API_KEY`.

```python Code
from crewai_tools import VisionTool

vision_tool = VisionTool()

@agent
def researcher(self) -> Agent:
    '''
    This agent uses the VisionTool to extract text from images.
    '''
    return Agent(
        config=self.agents_config["researcher"],
        allow_delegation=False,
        tools=[vision_tool]
    )
```

## Argumentos

O VisionTool requer os seguintes argumentos:

| Argumento            | Tipo     | Descrição                                                                          |
| :------------------- | :------- | :--------------------------------------------------------------------------------- |
| **image\_path\_url** | `string` | **Obrigatório**. O caminho para o arquivo de imagem do qual o texto será extraído. |


# Apify Actors
Source: https://docs.crewai.com/pt-BR/tools/automation/apifyactorstool

`ApifyActorsTool` permite que você execute Apify Actors para adicionar recursos de raspagem de dados na web, coleta, extração de dados e automação web aos seus fluxos de trabalho CrewAI.

# `ApifyActorsTool`

Integre [Apify Actors](https://apify.com/actors) nos seus fluxos de trabalho CrewAI.

## Descrição

O `ApifyActorsTool` conecta [Apify Actors](https://apify.com/actors), programas em nuvem para raspagem e automação web, aos seus fluxos de trabalho CrewAI.
Utilize qualquer um dos mais de 4.000 Actors disponíveis na [Apify Store](https://apify.com/store) para casos de uso como extração de dados de redes sociais, motores de busca, mapas online, sites de e-commerce, portais de viagem ou sites em geral.

Para mais detalhes, consulte a [integração Apify CrewAI](https://docs.apify.com/platform/integrations/crewai) na documentação do Apify.

## Passos para começar

<Steps>
  <Step title="Instale as dependências">
    Instale `crewai[tools]` e `langchain-apify` usando pip: `pip install 'crewai[tools]' langchain-apify`.
  </Step>

  <Step title="Obtenha um token de API do Apify">
    Cadastre-se no [Apify Console](https://console.apify.com/) e obtenha seu [token de API do Apify](https://console.apify.com/settings/integrations).
  </Step>

  <Step title="Configure o ambiente">
    Defina seu token de API do Apify na variável de ambiente `APIFY_API_TOKEN` para habilitar a funcionalidade da ferramenta.
  </Step>
</Steps>

## Exemplo de uso

Use o `ApifyActorsTool` manualmente para executar o [RAG Web Browser Actor](https://apify.com/apify/rag-web-browser) e realizar uma busca na web:

```python
from crewai_tools import ApifyActorsTool

# Inicialize a ferramenta com um Apify Actor
tool = ApifyActorsTool(actor_name="apify/rag-web-browser")

# Execute a ferramenta com parâmetros de entrada
results = tool.run(run_input={"query": "What is CrewAI?", "maxResults": 5})

# Processe os resultados
for result in results:
    print(f"URL: {result['metadata']['url']}")
    print(f"Content: {result.get('markdown', 'N/A')[:100]}...")
```

### Saída esperada

Veja abaixo a saída do código acima:

```text
URL: https://www.example.com/crewai-intro
Content: CrewAI is a framework for building AI-powered workflows...
URL: https://docs.crewai.com/
Content: Official documentation for CrewAI...
```

O `ApifyActorsTool` busca automaticamente a definição do Actor e o esquema de entrada no Apify utilizando o `actor_name` fornecido e então constrói a descrição da ferramenta e o esquema dos argumentos. Isso significa que você só precisa informar um `actor_name` válido, e a ferramenta faz o resto quando usada com agentes—não é necessário especificar o `run_input`. Veja como funciona:

```python
from crewai import Agent
from crewai_tools import ApifyActorsTool

rag_browser = ApifyActorsTool(actor_name="apify/rag-web-browser")

agent = Agent(
    role="Research Analyst",
    goal="Find and summarize information about specific topics",
    backstory="You are an experienced researcher with attention to detail",
    tools=[rag_browser],
)
```

Você pode executar outros Actors da [Apify Store](https://apify.com/store) apenas alterando o `actor_name` e, ao usar manualmente, ajustando o `run_input` de acordo com o esquema de entrada do Actor.

Para um exemplo de uso com agentes, consulte o [template CrewAI Actor](https://apify.com/templates/python-crewai).

## Configuração

O `ApifyActorsTool` exige os seguintes inputs para funcionar:

* **`actor_name`**
  O ID do Apify Actor a ser executado, por exemplo, `"apify/rag-web-browser"`. Explore todos os Actors na [Apify Store](https://apify.com/store).
* **`run_input`**
  Um dicionário de parâmetros de entrada para o Actor ao executar a ferramenta manualmente.
  * Por exemplo, para o Actor `apify/rag-web-browser`: `{"query": "search term", "maxResults": 5}`
  * Veja o [schema de entrada do Actor](https://apify.com/apify/rag-web-browser/input-schema) para a lista de parâmetros de entrada.

## Recursos

* **[Apify](https://apify.com/)**: Explore a plataforma Apify.
* **[Como criar um agente de IA no Apify](https://blog.apify.com/how-to-build-an-ai-agent/)** - Um guia completo, passo a passo, para criar, publicar e monetizar agentes de IA na plataforma Apify.
* **[RAG Web Browser Actor](https://apify.com/apify/rag-web-browser)**: Um Actor popular para busca na web para LLMs.
* **[Guia de Integração CrewAI](https://docs.apify.com/platform/integrations/crewai)**: Siga o guia oficial para integrar Apify e CrewAI.


# Ferramenta Composio
Source: https://docs.crewai.com/pt-BR/tools/automation/composiotool

O Composio oferece mais de 250 ferramentas prontas para produção para agentes de IA com gerenciamento de autenticação flexível.

# `ComposioToolSet`

## Descrição

Composio é uma plataforma de integração que permite conectar seus agentes de IA a mais de 250 ferramentas. Os principais recursos incluem:

* **Autenticação de Nível Empresarial**: Suporte integrado para OAuth, Chaves de API, JWT com atualização automática de token
* **Observabilidade Completa**: Logs detalhados de uso das ferramentas, registros de execução, e muito mais

## Instalação

Para incorporar as ferramentas Composio em seu projeto, siga as instruções abaixo:

```shell
pip install composio-crewai
pip install crewai
```

Após a conclusão da instalação, execute `composio login` ou exporte sua chave de API do composio como `COMPOSIO_API_KEY`. Obtenha sua chave de API Composio [aqui](https://app.composio.dev)

## Exemplo

O exemplo a seguir demonstra como inicializar a ferramenta e executar uma ação do github:

1. Inicialize o conjunto de ferramentas Composio

```python Code
from composio_crewai import ComposioToolSet, App, Action
from crewai import Agent, Task, Crew

toolset = ComposioToolSet()
```

2. Conecte sua conta do GitHub

<CodeGroup>
  ```shell CLI
  composio add github
  ```

  ```python Code
  request = toolset.initiate_connection(app=App.GITHUB)
  print(f"Open this URL to authenticate: {request.redirectUrl}")
  ```
</CodeGroup>

3. Obtenha ferramentas

* Recuperando todas as ferramentas de um app (não recomendado em produção):

```python Code
tools = toolset.get_tools(apps=[App.GITHUB])
```

* Filtrando ferramentas com base em tags:

```python Code
tag = "users"

filtered_action_enums = toolset.find_actions_by_tags(
    App.GITHUB,
    tags=[tag],
)

tools = toolset.get_tools(actions=filtered_action_enums)
```

* Filtrando ferramentas com base no caso de uso:

```python Code
use_case = "Star a repository on GitHub"

filtered_action_enums = toolset.find_actions_by_use_case(
    App.GITHUB, use_case=use_case, advanced=False
)

tools = toolset.get_tools(actions=filtered_action_enums)
```

<Tip>Defina `advanced` como True para obter ações para casos de uso complexos</Tip>

* Usando ferramentas específicas:

Neste exemplo, usaremos a ação `GITHUB_STAR_A_REPOSITORY_FOR_THE_AUTHENTICATED_USER` do app GitHub.

```python Code
tools = toolset.get_tools(
    actions=[Action.GITHUB_STAR_A_REPOSITORY_FOR_THE_AUTHENTICATED_USER]
)
```

Saiba mais sobre como filtrar ações [aqui](https://docs.composio.dev/patterns/tools/use-tools/use-specific-actions)

4. Defina o agente

```python Code
crewai_agent = Agent(
    role="GitHub Agent",
    goal="You take action on GitHub using GitHub APIs",
    backstory="You are AI agent that is responsible for taking actions on GitHub on behalf of users using GitHub APIs",
    verbose=True,
    tools=tools,
    llm= # pass an llm
)
```

5. Execute a tarefa

```python Code
task = Task(
    description="Star a repo composiohq/composio on GitHub",
    agent=crewai_agent,
    expected_output="Status of the operation",
)

crew = Crew(agents=[crewai_agent], tasks=[task])

crew.kickoff()
```

* Uma lista mais detalhada de ferramentas pode ser encontrada [aqui](https://app.composio.dev)


# MultiOn Tool
Source: https://docs.crewai.com/pt-BR/tools/automation/multiontool

O `MultiOnTool` permite que agentes CrewAI naveguem e interajam com a web por meio de instruções em linguagem natural.

## Visão Geral

O `MultiOnTool` foi projetado para envolver as capacidades de navegação web do [MultiOn](https://docs.multion.ai/welcome), permitindo que agentes CrewAI controlem navegadores web usando instruções em linguagem natural. Esta ferramenta facilita a navegação fluida, tornando-se um recurso essencial para projetos que requerem interação dinâmica com dados web e automação de tarefas baseadas na web.

## Instalação

Para utilizar esta ferramenta, é necessário instalar o pacote MultiOn:

```shell
uv add multion
```

Você também precisará instalar a extensão de navegador do MultiOn e habilitar o uso da API.

## Passos para Começar

Para usar o `MultiOnTool` de forma eficaz, siga estes passos:

1. **Instale o CrewAI**: Certifique-se de que o pacote `crewai[tools]` esteja instalado em seu ambiente Python.
2. **Instale e utilize o MultiOn**: Siga a [documentação do MultiOn](https://docs.multion.ai/learn/browser-extension) para instalar a extensão de navegador do MultiOn.
3. **Habilite o Uso da API**: Clique na extensão do MultiOn na pasta de extensões do seu navegador (não no ícone flutuante do MultiOn na página web) para abrir as configurações da extensão. Clique na opção para habilitar a API (API Enabled).

## Exemplo

O exemplo a seguir demonstra como inicializar a ferramenta e executar uma tarefa de navegação web:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import MultiOnTool

# Initialize the tool
multion_tool = MultiOnTool(api_key="YOUR_MULTION_API_KEY", local=False)

# Define an agent that uses the tool
browser_agent = Agent(
    role="Browser Agent",
    goal="Control web browsers using natural language",
    backstory="An expert browsing agent.",
    tools=[multion_tool],
    verbose=True,
)

# Example task to search and summarize news
browse_task = Task(
    description="Summarize the top 3 trending AI News headlines",
    expected_output="A summary of the top 3 trending AI News headlines",
    agent=browser_agent,
)

# Create and run the crew
crew = Crew(agents=[browser_agent], tasks=[browse_task])
result = crew.kickoff()
```

## Parâmetros

O `MultiOnTool` aceita os seguintes parâmetros durante a inicialização:

* **api\_key**: Opcional. Especifica a chave da API do MultiOn. Se não for fornecida, a ferramenta procurará pela variável de ambiente `MULTION_API_KEY`.
* **local**: Opcional. Defina como `True` para executar o agente localmente em seu navegador. Certifique-se de que a extensão do MultiOn está instalada e a opção API Enabled está marcada. O padrão é `False`.
* **max\_steps**: Opcional. Define o número máximo de etapas que o agente MultiOn pode executar para um comando. O padrão é `3`.

## Uso

Ao utilizar o `MultiOnTool`, o agente fornecerá instruções em linguagem natural que a ferramenta traduzirá em ações de navegação web. A ferramenta retorna os resultados da sessão de navegação juntamente com um status.

```python Code
# Example of using the tool with an agent
browser_agent = Agent(
    role="Web Browser Agent",
    goal="Search for and summarize information from the web",
    backstory="An expert at finding and extracting information from websites.",
    tools=[multion_tool],
    verbose=True,
)

# Create a task for the agent
search_task = Task(
    description="Search for the latest AI news on TechCrunch and summarize the top 3 headlines",
    expected_output="A summary of the top 3 AI news headlines from TechCrunch",
    agent=browser_agent,
)

# Run the task
crew = Crew(agents=[browser_agent], tasks=[search_task])
result = crew.kickoff()
```

Se o status retornado for `CONTINUE`, o agente deve ser instruído a reenviar a mesma instrução para continuar a execução.

## Detalhes de Implementação

O `MultiOnTool` é implementado como uma subclasse de `BaseTool` do CrewAI. Ele envolve o cliente MultiOn para fornecer capacidades de navegação web:

```python Code
class MultiOnTool(BaseTool):
    """Tool to wrap MultiOn Browse Capabilities."""

    name: str = "Multion Browse Tool"
    description: str = """Multion gives the ability for LLMs to control web browsers using natural language instructions.
            If the status is 'CONTINUE', reissue the same instruction to continue execution
        """

    # Implementation details...

    def _run(self, cmd: str, *args: Any, **kwargs: Any) -> str:
        """
        Run the Multion client with the given command.

        Args:
            cmd (str): The detailed and specific natural language instruction for web browsing
            *args (Any): Additional arguments to pass to the Multion client
            **kwargs (Any): Additional keyword arguments to pass to the Multion client
        """
        # Implementation details...
```

## Conclusão

O `MultiOnTool` oferece uma maneira poderosa de integrar capacidades de navegação web em agentes CrewAI. Ao permitir que agentes interajam com sites por meio de instruções em linguagem natural, amplia significativamente as possibilidades para tarefas baseadas na web, desde coleta de dados e pesquisa até interações automatizadas com serviços online.


# Visão Geral
Source: https://docs.crewai.com/pt-BR/tools/automation/overview

Automatize fluxos de trabalho e integre com plataformas e serviços externos

Essas ferramentas permitem que seus agentes automatizem fluxos de trabalho, integrem com plataformas externas e conectem-se a diversos serviços de terceiros para funcionalidades aprimoradas.

## **Ferramentas Disponíveis**

<CardGroup cols={2}>
  <Card title="Apify Actor Tool" icon="spider" href="/pt-BR/tools/automation/apifyactorstool">
    Execute atores do Apify para tarefas de automação e raspagem de dados web.
  </Card>

  <Card title="Composio Tool" icon="puzzle-piece" href="/pt-BR/tools/automation/composiotool">
    Integre com centenas de aplicativos e serviços através do Composio.
  </Card>

  <Card title="Multion Tool" icon="window-restore" href="/pt-BR/tools/automation/multiontool">
    Automatize interações no navegador e fluxos de trabalho baseados na web.
  </Card>
</CardGroup>

## **Casos de Uso Comuns**

* **Automação de Fluxos de Trabalho**: Automatize tarefas e processos repetitivos
* **Integração com APIs**: Conecte-se a APIs e serviços externos
* **Sincronização de Dados**: Sincronize dados entre diferentes plataformas
* **Orquestração de Processos**: Coordene fluxos de trabalho complexos e com múltiplas etapas
* **Serviços de Terceiros**: Aproveite ferramentas e plataformas externas

```python
from crewai_tools import ApifyActorTool, ComposioTool, MultiOnTool

# Create automation tools
apify_automation = ApifyActorTool()
platform_integration = ComposioTool()
browser_automation = MultiOnTool()

# Add to your agent
agent = Agent(
    role="Automation Specialist",
    tools=[apify_automation, platform_integration, browser_automation],
    goal="Automate workflows and integrate systems"
)
```

## **Benefícios da Integração**

* **Eficiência**: Reduza o trabalho manual por meio da automação
* **Escalabilidade**: Gerencie cargas de trabalho crescentes automaticamente
* **Confiabilidade**: Execução consistente de fluxos de trabalho
* **Conectividade**: Integre diferentes sistemas e plataformas
* **Produtividade**: Foque em tarefas de alto valor enquanto a automação cuida das rotinas


# Ferramenta Bedrock Invoke Agent
Source: https://docs.crewai.com/pt-BR/tools/cloud-storage/bedrockinvokeagenttool

Permite que agentes CrewAI invoquem Amazon Bedrock Agents e aproveitem suas capacidades em seus fluxos de trabalho

# `BedrockInvokeAgentTool`

A `BedrockInvokeAgentTool` permite que agentes CrewAI invoquem Amazon Bedrock Agents e aproveitem suas capacidades em seus fluxos de trabalho.

## Instalação

```bash
uv pip install 'crewai[tools]'
```

## Requisitos

* Credenciais AWS configuradas (através de variáveis de ambiente ou AWS CLI)
* Pacotes `boto3` e `python-dotenv`
* Acesso aos Amazon Bedrock Agents

## Uso

Veja como usar a ferramenta com um agente CrewAI:

```python {2, 4-8}
from crewai import Agent, Task, Crew
from crewai_tools.aws.bedrock.agents.invoke_agent_tool import BedrockInvokeAgentTool

# Initialize the tool
agent_tool = BedrockInvokeAgentTool(
    agent_id="your-agent-id",
    agent_alias_id="your-agent-alias-id"
)

# Create a CrewAI agent that uses the tool
aws_expert = Agent(
    role='AWS Service Expert',
    goal='Help users understand AWS services and quotas',
    backstory='I am an expert in AWS services and can provide detailed information about them.',
    tools=[agent_tool],
    verbose=True
)

# Create a task for the agent
quota_task = Task(
    description="Find out the current service quotas for EC2 in us-west-2 and explain any recent changes.",
    agent=aws_expert
)

# Create a crew with the agent
crew = Crew(
    agents=[aws_expert],
    tasks=[quota_task],
    verbose=2
)

# Run the crew
result = crew.kickoff()
print(result)
```

## Argumentos da Ferramenta

| Argumento            | Tipo   | Obrigatório | Padrão    | Descrição                                            |
| :------------------- | :----- | :---------- | :-------- | :--------------------------------------------------- |
| **agent\_id**        | `str`  | Sim         | None      | O identificador único do agente Bedrock              |
| **agent\_alias\_id** | `str`  | Sim         | None      | O identificador único do alias do agente             |
| **session\_id**      | `str`  | Não         | timestamp | O identificador único da sessão                      |
| **enable\_trace**    | `bool` | Não         | False     | Define se o trace deve ser habilitado para debug     |
| **end\_session**     | `bool` | Não         | False     | Define se a sessão deve ser encerrada após invocação |
| **description**      | `str`  | Não         | None      | Descrição personalizada para a ferramenta            |

## Variáveis de Ambiente

```bash
BEDROCK_AGENT_ID=your-agent-id           # Alternativa para passar agent_id
BEDROCK_AGENT_ALIAS_ID=your-agent-alias-id # Alternativa para passar agent_alias_id
AWS_REGION=your-aws-region               # Padrão é us-west-2
AWS_ACCESS_KEY_ID=your-access-key        # Necessário para autenticação AWS
AWS_SECRET_ACCESS_KEY=your-secret-key    # Necessário para autenticação AWS
```

## Uso Avançado

### Fluxo de Trabalho Multiagente com Gerenciamento de Sessão

```python {2, 4-22}
from crewai import Agent, Task, Crew, Process
from crewai_tools.aws.bedrock.agents.invoke_agent_tool import BedrockInvokeAgentTool

# Initialize tools with session management
initial_tool = BedrockInvokeAgentTool(
    agent_id="your-agent-id",
    agent_alias_id="your-agent-alias-id",
    session_id="custom-session-id"
)

followup_tool = BedrockInvokeAgentTool(
    agent_id="your-agent-id",
    agent_alias_id="your-agent-alias-id",
    session_id="custom-session-id"
)

final_tool = BedrockInvokeAgentTool(
    agent_id="your-agent-id",
    agent_alias_id="your-agent-alias-id",
    session_id="custom-session-id",
    end_session=True
)

# Create agents for different stages
researcher = Agent(
    role='AWS Service Researcher',
    goal='Gather information about AWS services',
    backstory='I am specialized in finding detailed AWS service information.',
    tools=[initial_tool]
)

analyst = Agent(
    role='Service Compatibility Analyst',
    goal='Analyze service compatibility and requirements',
    backstory='I analyze AWS services for compatibility and integration possibilities.',
    tools=[followup_tool]
)

summarizer = Agent(
    role='Technical Documentation Writer',
    goal='Create clear technical summaries',
    backstory='I specialize in creating clear, concise technical documentation.',
    tools=[final_tool]
)

# Create tasks
research_task = Task(
    description="Find all available AWS services in us-west-2 region.",
    agent=researcher
)

analysis_task = Task(
    description="Analyze which services support IPv6 and their implementation requirements.",
    agent=analyst
)

summary_task = Task(
    description="Create a summary of IPv6-compatible services and their key features.",
    agent=summarizer
)

# Create a crew with the agents and tasks
crew = Crew(
    agents=[researcher, analyst, summarizer],
    tasks=[research_task, analysis_task, summary_task],
    process=Process.sequential,
    verbose=2
)

# Run the crew
result = crew.kickoff()
```

## Casos de Uso

### Colaborações Híbridas Multiagente

* Crie fluxos de trabalho onde agentes CrewAI colaboram com agentes Bedrock gerenciados executando como serviços na AWS
* Permita cenários em que o processamento de dados sensíveis ocorre dentro do seu ambiente AWS enquanto outros agentes operam externamente
* Conecte agentes CrewAI on-premises a agentes Bedrock baseados na nuvem para fluxos de trabalho distribuídos de inteligência

### Soberania e Conformidade de Dados

* Mantenha fluxos de trabalho agentivos sensíveis a dados dentro do seu ambiente AWS enquanto permite que agentes CrewAI externos orquestrem tarefas
* Mantenha conformidade com requisitos de residência de dados processando informações sensíveis somente em sua conta AWS
* Permita colaborações multiagentes seguras onde alguns agentes não podem acessar dados privados da sua organização

### Integração Transparente com Serviços AWS

* Acesse qualquer serviço AWS por meio do Amazon Bedrock Actions sem escrever código de integração complexo
* Permita que agentes CrewAI interajam com serviços AWS usando solicitações em linguagem natural
* Aproveite as capacidades pré-construídas dos agentes Bedrock para interagir com serviços AWS como Bedrock Knowledge Bases, Lambda e outros

### Arquiteturas de Agentes Híbridos Escaláveis

* Realize tarefas computacionalmente intensivas em agentes Bedrock gerenciados enquanto tarefas leves rodam em CrewAI
* Escale o processamento de agentes distribuindo cargas de trabalho entre agentes CrewAI locais e agentes Bedrock na nuvem

### Colaboração de Agentes Entre Organizações

* Permita colaboração segura entre agentes CrewAI da sua organização e agentes Bedrock de organizações parceiras
* Crie fluxos de trabalho onde a expertise externa de agentes Bedrock pode ser incorporada sem expor dados sensíveis
* Construa ecossistemas de agentes que abrangem fronteiras organizacionais mantendo segurança e controle de dados


# Bedrock Knowledge Base Retriever
Source: https://docs.crewai.com/pt-BR/tools/cloud-storage/bedrockkbretriever

Recupere informações das Bases de Conhecimento do Amazon Bedrock usando consultas em linguagem natural

# `BedrockKBRetrieverTool`

A `BedrockKBRetrieverTool` permite que agentes CrewAI recuperem informações das Bases de Conhecimento do Amazon Bedrock usando consultas em linguagem natural.

## Instalação

```bash
uv pip install 'crewai[tools]'
```

## Requisitos

* Credenciais AWS configuradas (via variáveis de ambiente ou AWS CLI)
* Pacotes `boto3` e `python-dotenv`
* Acesso à Base de Conhecimento do Amazon Bedrock

## Uso

Veja como utilizar a ferramenta com um agente CrewAI:

```python {2, 4-17}
from crewai import Agent, Task, Crew
from crewai_tools.aws.bedrock.knowledge_base.retriever_tool import BedrockKBRetrieverTool

# Initialize the tool
kb_tool = BedrockKBRetrieverTool(
    knowledge_base_id="your-kb-id",
    number_of_results=5
)

# Create a CrewAI agent that uses the tool
researcher = Agent(
    role='Knowledge Base Researcher',
    goal='Find information about company policies',
    backstory='I am a researcher specialized in retrieving and analyzing company documentation.',
    tools=[kb_tool],
    verbose=True
)

# Create a task for the agent
research_task = Task(
    description="Find our company's remote work policy and summarize the key points.",
    agent=researcher
)

# Create a crew with the agent
crew = Crew(
    agents=[researcher],
    tasks=[research_task],
    verbose=2
)

# Run the crew
result = crew.kickoff()
print(result)
```

## Argumentos da Ferramenta

| Argumento                    | Tipo   | Obrigatório | Padrão | Descrição                                                                     |
| :--------------------------- | :----- | :---------- | :----- | :---------------------------------------------------------------------------- |
| **knowledge\_base\_id**      | `str`  | Sim         | Nenhum | O identificador único da base de conhecimento (0-10 caracteres alfanuméricos) |
| **number\_of\_results**      | `int`  | Não         | 5      | Número máximo de resultados a serem retornados                                |
| **retrieval\_configuration** | `dict` | Não         | Nenhum | Configurações personalizadas para a consulta da base de conhecimento          |
| **guardrail\_configuration** | `dict` | Não         | Nenhum | Configurações de filtragem de conteúdo                                        |
| **next\_token**              | `str`  | Não         | Nenhum | Token para paginação                                                          |

## Variáveis de Ambiente

```bash
BEDROCK_KB_ID=your-knowledge-base-id  # Alternativa ao uso de knowledge_base_id
AWS_REGION=your-aws-region            # Padrão: us-east-1
AWS_ACCESS_KEY_ID=your-access-key     # Obrigatório para autenticação AWS
AWS_SECRET_ACCESS_KEY=your-secret-key # Obrigatório para autenticação AWS
```

## Formato da Resposta

A ferramenta retorna resultados em formato JSON:

```json
{
  "results": [
    {
      "content": "Retrieved text content",
      "content_type": "text",
      "source_type": "S3",
      "source_uri": "s3://bucket/document.pdf",
      "score": 0.95,
      "metadata": {
        "additional": "metadata"
      }
    }
  ],
  "nextToken": "pagination-token",
  "guardrailAction": "NONE"
}
```

## Uso Avançado

### Configuração de Recuperação Personalizada

```python
kb_tool = BedrockKBRetrieverTool(
    knowledge_base_id="your-kb-id",
    retrieval_configuration={
        "vectorSearchConfiguration": {
            "numberOfResults": 10,
            "overrideSearchType": "HYBRID"
        }
    }
)

policy_expert = Agent(
    role='Policy Expert',
    goal='Analyze company policies in detail',
    backstory='I am an expert in corporate policy analysis with deep knowledge of regulatory requirements.',
    tools=[kb_tool]
)
```

## Fontes de Dados Suportadas

* Amazon S3
* Confluence
* Salesforce
* SharePoint
* Páginas web
* Locais de documentos personalizados
* Amazon Kendra
* Bancos de dados SQL

## Casos de Uso

### Integração de Conhecimento Corporativo

* Permita que agentes CrewAI acessem o conhecimento proprietário da sua organização sem expor dados sensíveis
* Permita que agentes tomem decisões baseadas nas políticas, procedimentos e documentações específicas da sua empresa
* Crie agentes capazes de responder perguntas com base na sua documentação interna mantendo a segurança dos dados

### Conhecimento Especializado de Domínio

* Conecte agentes CrewAI a bases de conhecimento específicas do domínio (jurídico, médico, técnico) sem re-treinamento de modelos
* Aproveite repositórios de conhecimento existentes que já são mantidos no seu ambiente AWS
* Combine o raciocínio do CrewAI com informações de domínio provenientes das suas bases de conhecimento

### Tomada de Decisão Orientada por Dados

* Baseie as respostas dos agentes CrewAI nos dados reais da sua empresa, e não apenas em conhecimento geral
* Assegure que os agentes forneçam recomendações baseadas no contexto e documentação do seu negócio
* Reduza alucinações ao recuperar informações factuais das suas bases de conhecimento

### Acesso Escalável à Informação

* Acesse terabytes de conhecimento organizacional sem precisar incorporar tudo aos seus modelos
* Consulte dinamicamente apenas as informações relevantes conforme a necessidade de cada tarefa
* Aproveite a infraestrutura escalável da AWS para lidar com grandes bases de conhecimento de forma eficiente

### Conformidade e Governança

* Garanta que agentes CrewAI forneçam respostas alinhadas com a documentação aprovada da sua empresa
* Crie trilhas de auditoria das fontes de informação usadas pelos agentes
* Mantenha controle sobre quais fontes de informação os seus agentes podem acessar


# Visão Geral
Source: https://docs.crewai.com/pt-BR/tools/cloud-storage/overview

Interaja com serviços em nuvem, sistemas de armazenamento e plataformas de IA baseadas em nuvem

Essas ferramentas permitem que seus agentes interajam com serviços em nuvem, acessem o armazenamento em nuvem e aproveitem plataformas de IA baseadas em nuvem para operações em escala.

## **Ferramentas Disponíveis**

<CardGroup cols={2}>
  <Card title="S3 Reader Tool" icon="cloud" href="/pt-BR/tools/cloud-storage/s3readertool">
    Leia arquivos e dados de buckets Amazon S3.
  </Card>

  <Card title="S3 Writer Tool" icon="cloud-arrow-up" href="/pt-BR/tools/cloud-storage/s3writertool">
    Escreva e faça upload de arquivos para o armazenamento Amazon S3.
  </Card>

  <Card title="Bedrock Invoke Agent" icon="aws" href="/pt-BR/tools/cloud-storage/bedrockinvokeagenttool">
    Acione agentes Amazon Bedrock para tarefas orientadas por IA.
  </Card>

  <Card title="Bedrock KB Retriever" icon="database" href="/pt-BR/tools/cloud-storage/bedrockkbretriever">
    Recupere informações das bases de conhecimento Amazon Bedrock.
  </Card>
</CardGroup>

## **Casos de Uso Comuns**

* **Armazenamento de Arquivos**: Armazene e recupere arquivos de sistemas de armazenamento em nuvem
* **Backup de Dados**: Faça backup de dados importantes no armazenamento em nuvem
* **Serviços de IA**: Acesse modelos e serviços de IA baseados em nuvem
* **Recuperação de Conhecimento**: Consulte bases de conhecimento hospedadas na nuvem
* **Operações Escaláveis**: Aproveite a infraestrutura de nuvem para processamento

```python
from crewai_tools import S3ReaderTool, S3WriterTool, BedrockInvokeAgentTool

# Create cloud tools
s3_reader = S3ReaderTool()
s3_writer = S3WriterTool()
bedrock_agent = BedrockInvokeAgentTool()

# Add to your agent
agent = Agent(
    role="Cloud Operations Specialist",
    tools=[s3_reader, s3_writer, bedrock_agent],
    goal="Manage cloud resources and AI services"
)
```


# S3 Reader Tool
Source: https://docs.crewai.com/pt-BR/tools/cloud-storage/s3readertool

O `S3ReaderTool` permite que agentes CrewAI leiam arquivos de buckets Amazon S3.

# `S3ReaderTool`

## Descrição

O `S3ReaderTool` foi projetado para ler arquivos de buckets Amazon S3. Esta ferramenta permite que os agentes CrewAI acessem e recuperem conteúdos armazenados no S3, tornando-a ideal para fluxos de trabalho que exigem leitura de dados, arquivos de configuração ou qualquer outro conteúdo armazenado no AWS S3.

## Instalação

Para utilizar esta ferramenta, é necessário instalar as dependências requeridas:

```shell
uv add boto3
```

## Passos para Começar

Para usar o `S3ReaderTool` efetivamente, siga estes passos:

1. **Instale as Dependências**: Instale os pacotes necessários usando o comando acima.
2. **Configure as Credenciais AWS**: Defina suas credenciais AWS como variáveis de ambiente.
3. **Inicialize a Ferramenta**: Crie uma instância da ferramenta.
4. **Especifique o Caminho S3**: Forneça o caminho S3 do arquivo que deseja ler.

## Exemplo

O exemplo a seguir demonstra como utilizar o `S3ReaderTool` para ler um arquivo de um bucket S3:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools.aws.s3 import S3ReaderTool

# Initialize the tool
s3_reader_tool = S3ReaderTool()

# Define an agent that uses the tool
file_reader_agent = Agent(
    role="File Reader",
    goal="Read files from S3 buckets",
    backstory="An expert in retrieving and processing files from cloud storage.",
    tools=[s3_reader_tool],
    verbose=True,
)

# Example task to read a configuration file
read_task = Task(
    description="Read the configuration file from {my_bucket} and summarize its contents.",
    expected_output="A summary of the configuration file contents.",
    agent=file_reader_agent,
)

# Create and run the crew
crew = Crew(agents=[file_reader_agent], tasks=[read_task])
result = crew.kickoff(inputs={"my_bucket": "s3://my-bucket/config/app-config.json"})
```

## Parâmetros

O `S3ReaderTool` aceita o seguinte parâmetro quando utilizado por um agente:

* **file\_path**: Obrigatório. O caminho do arquivo S3 no formato `s3://nome-do-bucket/nome-do-arquivo`.

## Credenciais AWS

A ferramenta requer credenciais AWS para acessar buckets S3. Você pode configurar essas credenciais usando variáveis de ambiente:

* **CREW\_AWS\_REGION**: Região AWS onde seu bucket S3 está localizado. O padrão é `us-east-1`.
* **CREW\_AWS\_ACCESS\_KEY\_ID**: Sua AWS access key ID.
* **CREW\_AWS\_SEC\_ACCESS\_KEY**: Sua AWS secret access key.

## Uso

Ao utilizar o `S3ReaderTool` com um agente, o agente deverá fornecer o caminho do arquivo S3:

```python Code
# Example of using the tool with an agent
file_reader_agent = Agent(
    role="File Reader",
    goal="Read files from S3 buckets",
    backstory="An expert in retrieving and processing files from cloud storage.",
    tools=[s3_reader_tool],
    verbose=True,
)

# Create a task for the agent to read a specific file
read_config_task = Task(
    description="Read the application configuration file from {my_bucket} and extract the database connection settings.",
    expected_output="The database connection settings from the configuration file.",
    agent=file_reader_agent,
)

# Run the task
crew = Crew(agents=[file_reader_agent], tasks=[read_config_task])
result = crew.kickoff(inputs={"my_bucket": "s3://my-bucket/config/app-config.json"})
```

## Tratamento de Erros

O `S3ReaderTool` inclui tratamento para erros comuns do S3:

* Formato inválido de caminho S3
* Arquivos ausentes ou inacessíveis
* Problemas de permissão
* Problemas com credenciais AWS

Quando um erro ocorre, a ferramenta retorna uma mensagem de erro com detalhes sobre o problema.

## Detalhes da Implementação

O `S3ReaderTool` utiliza o AWS SDK for Python (boto3) para interagir com o S3:

```python Code
class S3ReaderTool(BaseTool):
    name: str = "S3 Reader Tool"
    description: str = "Reads a file from Amazon S3 given an S3 file path"

    def _run(self, file_path: str) -> str:
        try:
            bucket_name, object_key = self._parse_s3_path(file_path)

            s3 = boto3.client(
                's3',
                region_name=os.getenv('CREW_AWS_REGION', 'us-east-1'),
                aws_access_key_id=os.getenv('CREW_AWS_ACCESS_KEY_ID'),
                aws_secret_access_key=os.getenv('CREW_AWS_SEC_ACCESS_KEY')
            )

            # Read file content from S3
            response = s3.get_object(Bucket=bucket_name, Key=object_key)
            file_content = response['Body'].read().decode('utf-8')

            return file_content
        except ClientError as e:
            return f"Error reading file from S3: {str(e)}"
```

## Conclusão

O `S3ReaderTool` oferece uma maneira simples de ler arquivos de buckets Amazon S3. Ao permitir que agentes acessem conteúdos armazenados no S3, facilita fluxos de trabalho que necessitam de acesso a arquivos na nuvem. Esta ferramenta é especialmente útil para processamento de dados, gestão de configurações e qualquer tarefa que envolva a obtenção de informações do armazenamento AWS S3.


# Ferramenta S3 Writer
Source: https://docs.crewai.com/pt-BR/tools/cloud-storage/s3writertool

A `S3WriterTool` permite que agentes CrewAI escrevam conteúdo em arquivos em buckets Amazon S3.

# `S3WriterTool`

## Descrição

A `S3WriterTool` foi projetada para escrever conteúdo em arquivos em buckets Amazon S3. Esta ferramenta permite que agentes CrewAI criem ou atualizem arquivos no S3, tornando-a ideal para fluxos de trabalho que exigem armazenamento de dados, salvamento de arquivos de configuração ou persistência de qualquer outro conteúdo no armazenamento AWS S3.

## Instalação

Para usar esta ferramenta, você precisa instalar as dependências necessárias:

```shell
uv add boto3
```

## Passos para Começar

Para usar a `S3WriterTool` de forma eficaz, siga estes passos:

1. **Instale as Dependências**: Instale os pacotes necessários usando o comando acima.
2. **Configure as Credenciais AWS**: Defina suas credenciais AWS como variáveis de ambiente.
3. **Inicialize a Ferramenta**: Crie uma instância da ferramenta.
4. **Especifique o Caminho no S3 e o Conteúdo**: Forneça o caminho no S3 onde deseja gravar o arquivo e o conteúdo a ser escrito.

## Exemplo

O exemplo a seguir demonstra como usar a `S3WriterTool` para gravar conteúdo em um arquivo em um bucket S3:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools.aws.s3 import S3WriterTool

# Initialize the tool
s3_writer_tool = S3WriterTool()

# Define an agent that uses the tool
file_writer_agent = Agent(
    role="File Writer",
    goal="Write content to files in S3 buckets",
    backstory="An expert in storing and managing files in cloud storage.",
    tools=[s3_writer_tool],
    verbose=True,
)

# Example task to write a report
write_task = Task(
    description="Generate a summary report of the quarterly sales data and save it to {my_bucket}.",
    expected_output="Confirmation that the report was successfully saved to S3.",
    agent=file_writer_agent,
)

# Create and run the crew
crew = Crew(agents=[file_writer_agent], tasks=[write_task])
result = crew.kickoff(inputs={"my_bucket": "s3://my-bucket/reports/quarterly-summary.txt"})
```

## Parâmetros

A `S3WriterTool` aceita os seguintes parâmetros quando utilizada por um agente:

* **file\_path**: Obrigatório. O caminho do arquivo S3 no formato `s3://bucket-name/file-name`.
* **content**: Obrigatório. O conteúdo a ser escrito no arquivo.

## Credenciais AWS

A ferramenta requer credenciais AWS para acessar os buckets S3. Você pode configurar essas credenciais usando variáveis de ambiente:

* **CREW\_AWS\_REGION**: A região AWS onde seu bucket S3 está localizado. O padrão é `us-east-1`.
* **CREW\_AWS\_ACCESS\_KEY\_ID**: Sua AWS access key ID.
* **CREW\_AWS\_SEC\_ACCESS\_KEY**: Sua AWS secret access key.

## Uso

Ao usar a `S3WriterTool` com um agente, o agente precisará fornecer tanto o caminho do arquivo no S3 quanto o conteúdo a ser gravado:

```python Code
# Example of using the tool with an agent
file_writer_agent = Agent(
    role="File Writer",
    goal="Write content to files in S3 buckets",
    backstory="An expert in storing and managing files in cloud storage.",
    tools=[s3_writer_tool],
    verbose=True,
)

# Create a task for the agent to write a specific file
write_config_task = Task(
    description="""
    Create a configuration file with the following database settings:
    - host: db.example.com
    - port: 5432
    - username: app_user
    - password: secure_password

    Save this configuration as JSON to {my_bucket}.
    """,
    expected_output="Confirmation that the configuration file was successfully saved to S3.",
    agent=file_writer_agent,
)

# Run the task
crew = Crew(agents=[file_writer_agent], tasks=[write_config_task])
result = crew.kickoff(inputs={"my_bucket": "s3://my-bucket/config/db-config.json"})
```

## Tratamento de Erros

A `S3WriterTool` inclui tratamento de erros para problemas comuns no S3:

* Formato de caminho S3 inválido
* Problemas de permissão (ex: sem acesso de gravação ao bucket)
* Problemas com credenciais AWS
* Bucket inexistente

Quando ocorre um erro, a ferramenta retorna uma mensagem de erro que inclui detalhes sobre o problema.

## Detalhes de Implementação

A `S3WriterTool` utiliza o AWS SDK para Python (boto3) para interagir com o S3:

```python Code
class S3WriterTool(BaseTool):
    name: str = "S3 Writer Tool"
    description: str = "Writes content to a file in Amazon S3 given an S3 file path"

    def _run(self, file_path: str, content: str) -> str:
        try:
            bucket_name, object_key = self._parse_s3_path(file_path)

            s3 = boto3.client(
                's3',
                region_name=os.getenv('CREW_AWS_REGION', 'us-east-1'),
                aws_access_key_id=os.getenv('CREW_AWS_ACCESS_KEY_ID'),
                aws_secret_access_key=os.getenv('CREW_AWS_SEC_ACCESS_KEY')
            )

            s3.put_object(Bucket=bucket_name, Key=object_key, Body=content.encode('utf-8'))
            return f"Successfully wrote content to {file_path}"
        except ClientError as e:
            return f"Error writing file to S3: {str(e)}"
```

## Conclusão

A `S3WriterTool` oferece uma maneira direta de gravar conteúdo em arquivos em buckets Amazon S3. Ao permitir que agentes criem e atualizem arquivos no S3, ela facilita fluxos de trabalho que exigem armazenamento de arquivos em nuvem. Esta ferramenta é particularmente útil para persistência de dados, gerenciamento de configurações, geração de relatórios e qualquer tarefa que envolva armazenar informações no AWS S3.


# Busca RAG no MySQL
Source: https://docs.crewai.com/pt-BR/tools/database-data/mysqltool

O `MySQLSearchTool` foi projetado para buscar em bancos de dados MySQL e retornar os resultados mais relevantes.

## Visão Geral

Esta ferramenta foi desenvolvida para facilitar buscas semânticas em tabelas de bancos de dados MySQL. Utilizando a tecnologia RAG (Retrieve and Generate),
o MySQLSearchTool oferece aos usuários um meio eficiente de consultar o conteúdo de tabelas do banco de dados, especificamente adaptado para bancos MySQL.
Ela simplifica o processo de encontrar dados relevantes por meio de consultas de busca semântica, tornando-se um recurso valioso para quem precisa
realizar consultas avançadas em grandes conjuntos de dados dentro de um banco de dados MySQL.

## Instalação

Para instalar o pacote `crewai_tools` e utilizar o MySQLSearchTool, execute o seguinte comando no seu terminal:

```shell
pip install 'crewai[tools]'
```

## Exemplo

Abaixo está um exemplo demonstrando como usar o MySQLSearchTool para realizar uma busca semântica em uma tabela de um banco de dados MySQL:

```python Code
from crewai_tools import MySQLSearchTool

# Inicialize a ferramenta com o URI do banco de dados e o nome da tabela de destino
tool = MySQLSearchTool(
    db_uri='mysql://user:password@localhost:3306/mydatabase',
    table_name='employees'
)
```

## Argumentos

O MySQLSearchTool requer os seguintes argumentos para sua operação:

* `db_uri`: Uma string representando o URI do banco de dados MySQL a ser consultado. Este argumento é obrigatório e deve incluir os detalhes de autenticação necessários e o local do banco de dados.
* `table_name`: Uma string especificando o nome da tabela dentro do banco de dados na qual será realizada a busca semântica. Este argumento é obrigatório.

## Modelo e embeddings personalizados

Por padrão, a ferramenta utiliza o OpenAI tanto para embeddings quanto para sumarização. Para customizar o modelo, você pode usar um dicionário de configuração conforme o exemplo:

```python Code
tool = MySQLSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google",
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# NL2SQL Tool
Source: https://docs.crewai.com/pt-BR/tools/database-data/nl2sqltool

O `NL2SQLTool` foi projetado para converter linguagem natural em consultas SQL.

## Visão Geral

Esta ferramenta é utilizada para converter linguagem natural em consultas SQL. Quando passada para o agente, ela irá gerar as consultas e, em seguida, utilizá-las para interagir com o banco de dados.

Isso possibilita múltiplos fluxos de trabalho, como por exemplo ter um Agente acessando o banco de dados para buscar informações com base em um objetivo e, então, usar essas informações para gerar uma resposta, relatório ou qualquer outro tipo de saída. Além disso, permite que o Agente atualize o banco de dados de acordo com seu objetivo.

**Atenção**: Certifique-se de que o Agente tenha acesso a um Read-Replica ou que seja permitido que o Agente execute consultas de inserção/atualização no banco de dados.

## Requisitos

* SqlAlchemy
* Qualquer biblioteca compatível com o banco de dados (ex.: psycopg2, mysql-connector-python)

## Instalação

Instale o pacote crewai\_tools

```shell
pip install 'crewai[tools]'
```

## Uso

Para utilizar o NL2SQLTool, você precisa passar a URI do banco de dados para a ferramenta. O formato da URI deve ser `dialect+driver://username:password@host:port/database`.

```python Code
from crewai_tools import NL2SQLTool

# psycopg2 foi instalado para rodar este exemplo com PostgreSQL
nl2sql = NL2SQLTool(db_uri="postgresql://example@localhost:5432/test_db")

@agent
def researcher(self) -> Agent:
    return Agent(
        config=self.agents_config["researcher"],
        allow_delegation=False,
        tools=[nl2sql]
    )
```

## Exemplo

O objetivo principal da tarefa era:

"Recupere a receita mensal média, máxima e mínima para cada cidade, mas inclua apenas cidades que tenham mais de um usuário. Além disso, conte o número de usuários em cada cidade e classifique os resultados pela receita mensal média em ordem decrescente"

Assim, o Agente tentou obter informações do banco de dados; a primeira vez está errada, então o Agente tenta novamente, consegue a informação correta e repassa para o próximo agente.

![alt text](https://github.com/crewAIInc/crewAI-tools/blob/main/crewai_tools/tools/nl2sql/images/image-2.png?raw=true)
![alt text](https://github.com/crewAIInc/crewAI-tools/raw/main/crewai_tools/tools/nl2sql/images/image-3.png)

O segundo objetivo da tarefa foi:

"Revise os dados e crie um relatório detalhado e, em seguida, crie a tabela no banco de dados com os campos baseados nos dados fornecidos. Inclua informações sobre a receita mensal média, máxima e mínima para cada cidade, mas apenas inclua cidades que possuam mais de um usuário. Também conte o número de usuários em cada cidade e classifique os resultados pela receita mensal média em ordem decrescente."

Agora as coisas começam a ficar interessantes: o Agente gera a consulta SQL não só para criar a tabela, mas também inserir os dados na tabela. E, ao final, o Agente ainda retorna o relatório final que condiz exatamente com o que estava no banco de dados.

![alt text](https://github.com/crewAIInc/crewAI-tools/raw/main/crewai_tools/tools/nl2sql/images/image-4.png)
![alt text](https://github.com/crewAIInc/crewAI-tools/raw/main/crewai_tools/tools/nl2sql/images/image-5.png)

![alt text](https://github.com/crewAIInc/crewAI-tools/raw/main/crewai_tools/tools/nl2sql/images/image-9.png)
![alt text](https://github.com/crewAIInc/crewAI-tools/raw/main/crewai_tools/tools/nl2sql/images/image-7.png)

Este é um exemplo simples de como o NL2SQLTool pode ser utilizado para interagir com o banco de dados e gerar relatórios baseados nos dados do banco.

A ferramenta oferece possibilidades infinitas para a lógica do Agente e como ele pode interagir com o banco de dados.

```md
 DB -> Agent -> ... -> Agent -> DB
```


# Visão Geral
Source: https://docs.crewai.com/pt-BR/tools/database-data/overview

Conecte-se a bancos de dados, armazenamentos vetoriais e data warehouses para acesso abrangente aos dados

Essas ferramentas permitem que seus agentes interajam com diversos sistemas de banco de dados, desde bancos de dados SQL tradicionais até armazenamentos vetoriais modernos e data warehouses.

## **Ferramentas Disponíveis**

<CardGroup cols={2}>
  <Card title="MySQL Tool" icon="database" href="/pt-BR/tools/database-data/mysqltool">
    Conecte-se e faça consultas a bancos de dados MySQL com operações SQL.
  </Card>

  <Card title="PostgreSQL Search" icon="elephant" href="/pt-BR/tools/database-data/pgsearchtool">
    Pesquise e consulte bancos de dados PostgreSQL de forma eficiente.
  </Card>

  <Card title="Snowflake Search" icon="snowflake" href="/pt-BR/tools/database-data/snowflakesearchtool">
    Acesse o data warehouse Snowflake para análises e relatórios.
  </Card>

  <Card title="NL2SQL Tool" icon="language" href="/pt-BR/tools/database-data/nl2sqltool">
    Converta automaticamente consultas em linguagem natural para comandos SQL.
  </Card>

  <Card title="Qdrant Vector Search" icon="vector-square" href="/pt-BR/tools/database-data/qdrantvectorsearchtool">
    Pesquise embeddings vetoriais usando o banco de dados vetorial Qdrant.
  </Card>

  <Card title="Weaviate Vector Search" icon="network-wired" href="/pt-BR/tools/database-data/weaviatevectorsearchtool">
    Realize buscas semânticas com o banco de dados vetorial Weaviate.
  </Card>
</CardGroup>

## **Casos de Uso Comuns**

* **Análise de Dados**: Consulte bancos de dados para inteligência de negócios e relatórios
* **Busca Vetorial**: Encontre conteúdos similares utilizando embeddings semânticos
* **Operações ETL**: Extraia, transforme e carregue dados entre sistemas
* **Análise em Tempo Real**: Acesse dados ao vivo para tomada de decisões

```python
from crewai_tools import MySQLTool, QdrantVectorSearchTool, NL2SQLTool

# Create database tools
mysql_db = MySQLTool()
vector_search = QdrantVectorSearchTool()
nl_to_sql = NL2SQLTool()

# Add to your agent
agent = Agent(
    role="Data Analyst",
    tools=[mysql_db, vector_search, nl_to_sql],
    goal="Extract insights from various data sources"
)
```


# PG RAG Search
Source: https://docs.crewai.com/pt-BR/tools/database-data/pgsearchtool

O `PGSearchTool` foi desenvolvido para pesquisar bancos de dados PostgreSQL e retornar os resultados mais relevantes.

## Visão geral

<Note>
  O PGSearchTool está atualmente em desenvolvimento. Este documento descreve a funcionalidade e a interface pretendidas.
  Conforme o desenvolvimento avança, esteja ciente de que alguns recursos podem não estar disponíveis ou podem mudar.
</Note>

## Descrição

O PGSearchTool é concebido como uma ferramenta poderosa para facilitar buscas semânticas em tabelas de bancos de dados PostgreSQL. Aproveitando tecnologia avançada de Recuperação e Geração (RAG),
ele visa fornecer um meio eficiente para consultar o conteúdo de tabelas de banco de dados, especificamente voltado para bancos de dados PostgreSQL.
O objetivo da ferramenta é simplificar o processo de encontrar dados relevantes por meio de consultas semânticas, oferecendo um recurso valioso para usuários que precisam realizar buscas avançadas em
grandes volumes de dados dentro de um ambiente PostgreSQL.

## Instalação

O pacote `crewai_tools`, que incluirá o PGSearchTool assim que for lançado, pode ser instalado usando o comando abaixo:

```shell
pip install 'crewai[tools]'
```

<Note>
  O PGSearchTool ainda não está disponível na versão atual do pacote `crewai_tools`. Este comando de instalação será atualizado assim que a ferramenta for lançada.
</Note>

## Exemplo de Uso

Abaixo está um exemplo proposto mostrando como utilizar o PGSearchTool para realizar uma busca semântica em uma tabela dentro de um banco de dados PostgreSQL:

```python Code
from crewai_tools import PGSearchTool

# Inicialize a ferramenta com a URI do banco de dados e o nome da tabela alvo
tool = PGSearchTool(
    db_uri='postgresql://user:password@localhost:5432/mydatabase',
    table_name='employees'
)
```

## Argumentos

O PGSearchTool foi projetado para exigir os seguintes argumentos para seu funcionamento:

| Argumento       | Tipo     | Descrição                                                                                                                                                                                                                 |
| :-------------- | :------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **db\_uri**     | `string` | **Obrigatório**. Uma string que representa a URI do banco de dados PostgreSQL a ser consultado. Este argumento será obrigatório e deve incluir os detalhes necessários de autenticação e a localização do banco de dados. |
| **table\_name** | `string` | **Obrigatório**. Uma string que especifica o nome da tabela dentro do banco de dados na qual a busca semântica será realizada. Este argumento também será obrigatório.                                                    |

## Modelo Personalizado e Embeddings

A ferramenta pretende usar OpenAI tanto para embeddings quanto para sumarização por padrão. Os usuários terão a opção de personalizar o modelo usando um dicionário de configuração, conforme mostrado abaixo:

```python Code
tool = PGSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Qdrant Vector Search Tool
Source: https://docs.crewai.com/pt-BR/tools/database-data/qdrantvectorsearchtool

Capacidades de busca semântica para agentes CrewAI usando o banco de dados vetorial Qdrant

## Visão Geral

A ferramenta Qdrant Vector Search permite adicionar capacidades de busca semântica aos seus agentes CrewAI utilizando o [Qdrant](https://qdrant.tech/), um mecanismo de busca por similaridade vetorial. Com essa ferramenta, seus agentes podem pesquisar em documentos armazenados em uma coleção Qdrant usando similaridade semântica.

## Instalação

Instale os pacotes necessários:

```bash
uv add qdrant-client
```

## Uso Básico

Veja um exemplo mínimo de como utilizar a ferramenta:

```python
from crewai import Agent
from crewai_tools import QdrantVectorSearchTool

# Inicialize a ferramenta
qdrant_tool = QdrantVectorSearchTool(
    qdrant_url="your_qdrant_url",
    qdrant_api_key="your_qdrant_api_key",
    collection_name="your_collection"
)

# Crie um agente que utiliza a ferramenta
agent = Agent(
    role="Research Assistant",
    goal="Find relevant information in documents",
    tools=[qdrant_tool]
)

# A ferramenta usará automaticamente embeddings da OpenAI
# e retornará os 3 resultados mais relevantes com pontuação > 0.35
```

## Exemplo Completo e Funcional

Veja um exemplo completo mostrando como:

1. Extrair texto de um PDF
2. Gerar embeddings usando OpenAI
3. Armazenar no Qdrant
4. Criar um fluxo de trabalho RAG agente CrewAI para busca semântica

```python
import os
import uuid
import pdfplumber
from openai import OpenAI
from dotenv import load_dotenv
from crewai import Agent, Task, Crew, Process, LLM
from crewai_tools import QdrantVectorSearchTool
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct, Distance, VectorParams

# Carregar variáveis de ambiente
load_dotenv()

# Inicializar cliente OpenAI
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Extrair texto do PDF
def extract_text_from_pdf(pdf_path):
    text = []
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text.append(page_text.strip())
    return text

# Gerar embeddings da OpenAI
def get_openai_embedding(text):
    response = client.embeddings.create(
        input=text,
        model="text-embedding-3-small"
    )
    return response.data[0].embedding

# Armazenar texto e embeddings no Qdrant
def load_pdf_to_qdrant(pdf_path, qdrant, collection_name):
    # Extrair texto do PDF
    text_chunks = extract_text_from_pdf(pdf_path)

    # Criar coleção no Qdrant
    if qdrant.collection_exists(collection_name):
        qdrant.delete_collection(collection_name)
    qdrant.create_collection(
        collection_name=collection_name,
        vectors_config=VectorParams(size=1536, distance=Distance.COSINE)
    )

    # Armazenar embeddings
    points = []
    for chunk in text_chunks:
        embedding = get_openai_embedding(chunk)
        points.append(PointStruct(
            id=str(uuid.uuid4()),
            vector=embedding,
            payload={"text": chunk}
        ))
    qdrant.upsert(collection_name=collection_name, points=points)

# Inicializar cliente Qdrant e carregar dados
qdrant = QdrantClient(
    url=os.getenv("QDRANT_URL"),
    api_key=os.getenv("QDRANT_API_KEY")
)
collection_name = "example_collection"
pdf_path = "path/to/your/document.pdf"
load_pdf_to_qdrant(pdf_path, qdrant, collection_name)

# Inicializar ferramenta de busca Qdrant
qdrant_tool = QdrantVectorSearchTool(
    qdrant_url=os.getenv("QDRANT_URL"),
    qdrant_api_key=os.getenv("QDRANT_API_KEY"),
    collection_name=collection_name,
    limit=3,
    score_threshold=0.35
)

# Criar agentes CrewAI
search_agent = Agent(
    role="Senior Semantic Search Agent",
    goal="Find and analyze documents based on semantic search",
    backstory="""You are an expert research assistant who can find relevant
    information using semantic search in a Qdrant database.""",
    tools=[qdrant_tool],
    verbose=True
)

answer_agent = Agent(
    role="Senior Answer Assistant",
    goal="Generate answers to questions based on the context provided",
    backstory="""You are an expert answer assistant who can generate
    answers to questions based on the context provided.""",
    tools=[qdrant_tool],
    verbose=True
)

# Definir tarefas
search_task = Task(
    description="""Search for relevant documents about the {query}.
    Your final answer should include:
    - The relevant information found
    - The similarity scores of the results
    - The metadata of the relevant documents""",
    agent=search_agent
)

answer_task = Task(
    description="""Given the context and metadata of relevant documents,
    generate a final answer based on the context.""",
    agent=answer_agent
)

# Executar fluxo CrewAI
crew = Crew(
    agents=[search_agent, answer_agent],
    tasks=[search_task, answer_task],
    process=Process.sequential,
    verbose=True
)

result = crew.kickoff(
    inputs={"query": "What is the role of X in the document?"}
)
print(result)
```

## Parâmetros da Ferramenta

### Parâmetros Obrigatórios

* `qdrant_url` (str): URL do seu servidor Qdrant
* `qdrant_api_key` (str): Chave de API para autenticação com o Qdrant
* `collection_name` (str): Nome da coleção Qdrant a ser pesquisada

### Parâmetros Opcionais

* `limit` (int): Número máximo de resultados a serem retornados (padrão: 3)
* `score_threshold` (float): Limite mínimo de similaridade (padrão: 0.35)
* `custom_embedding_fn` (Callable\[\[str], list\[float]]): Função personalizada para vetorização de textos

## Parâmetros de Busca

A ferramenta aceita estes parâmetros em seu schema:

* `query` (str): Consulta de busca para encontrar documentos similares
* `filter_by` (str, opcional): Campo de metadado para filtrar
* `filter_value` (str, opcional): Valor para filtrar

## Formato de Retorno

A ferramenta retorna resultados no formato JSON:

```json
[
  {
    "metadata": {
      // Todos os metadados armazenados junto com o documento
    },
    "context": "O conteúdo textual real do documento",
    "distance": 0.95  // Pontuação de similaridade
  }
]
```

## Embedding Padrão

Por padrão, a ferramenta utiliza o modelo `text-embedding-3-small` da OpenAI para vetorização. Isso requer:

* Chave de API da OpenAI definida na variável de ambiente: `OPENAI_API_KEY`

## Embeddings Personalizados

Em vez de utilizar o modelo padrão de embeddings, você pode utilizar sua própria função de embeddings nos casos em que:

1. Deseja usar um modelo de embeddings diferente (ex: Cohere, HuggingFace, modelos Ollama)
2. Precisa reduzir custos utilizando modelos de código aberto
3. Tem requisitos específicos quanto à dimensão dos vetores ou à qualidade dos embeddings
4. Deseja utilizar embeddings específicos para determinado domínio (ex: textos médicos ou jurídicos)

Veja um exemplo utilizando um modelo HuggingFace:

```python
from transformers import AutoTokenizer, AutoModel
import torch

# Carregar modelo e tokenizer
tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')
model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')

def custom_embeddings(text: str) -> list[float]:
    # Tokenizar e obter saídas do modelo
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True)
    outputs = model(**inputs)

    # Usar mean pooling para obter o embedding do texto
    embeddings = outputs.last_hidden_state.mean(dim=1)

    # Converter para lista de floats e retornar
    return embeddings[0].tolist()

# Usar embeddings personalizados com a ferramenta
tool = QdrantVectorSearchTool(
    qdrant_url="your_url",
    qdrant_api_key="your_key",
    collection_name="your_collection",
    custom_embedding_fn=custom_embeddings  # Passe sua função personalizada
)
```

## Tratamento de Erros

A ferramenta trata os seguintes erros específicos:

* Lança ImportError se `qdrant-client` não estiver instalado (com opção de instalar automaticamente)
* Lança ValueError se `QDRANT_URL` não estiver definido
* Solicita instalação de `qdrant-client` se estiver ausente utilizando `uv add qdrant-client`

## Variáveis de Ambiente

Variáveis de ambiente obrigatórias:

```bash
export QDRANT_URL="your_qdrant_url"  # Se não for informado no construtor
export QDRANT_API_KEY="your_api_key"  # Se não for informado no construtor
export OPENAI_API_KEY="your_openai_key"  # Se estiver usando embeddings padrão
```


# Snowflake Search Tool
Source: https://docs.crewai.com/pt-BR/tools/database-data/snowflakesearchtool

O `SnowflakeSearchTool` permite que agentes CrewAI executem consultas SQL e realizem buscas semânticas em data warehouses Snowflake.

# `SnowflakeSearchTool`

## Descrição

O `SnowflakeSearchTool` foi desenvolvido para conectar-se a data warehouses Snowflake e executar consultas SQL com recursos avançados como pool de conexões, lógica de tentativas e execução assíncrona. Esta ferramenta permite que agentes CrewAI interajam com bases de dados Snowflake, sendo ideal para tarefas de análise de dados, relatórios e inteligência de negócios que requerem acesso a dados empresariais armazenados no Snowflake.

## Instalação

Para utilizar esta ferramenta, é necessário instalar as dependências requeridas:

```shell
uv add cryptography snowflake-connector-python snowflake-sqlalchemy
```

Ou, alternativamente:

```shell
uv sync --extra snowflake
```

## Passos para Começar

Para usar eficazmente o `SnowflakeSearchTool`, siga estes passos:

1. **Instale as Dependências**: Instale os pacotes necessários usando um dos comandos acima.
2. **Configure a Conexão com o Snowflake**: Crie um objeto `SnowflakeConfig` com suas credenciais do Snowflake.
3. **Inicialize a Ferramenta**: Crie uma instância da ferramenta com a configuração necessária.
4. **Execute Consultas**: Utilize a ferramenta para rodar consultas SQL no seu banco de dados Snowflake.

## Exemplo

O exemplo a seguir demonstra como usar o `SnowflakeSearchTool` para consultar dados de um banco de dados Snowflake:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import SnowflakeSearchTool, SnowflakeConfig

# Create Snowflake configuration
config = SnowflakeConfig(
    account="your_account",
    user="your_username",
    password="your_password",
    warehouse="COMPUTE_WH",
    database="your_database",
    snowflake_schema="your_schema"
)

# Initialize the tool
snowflake_tool = SnowflakeSearchTool(config=config)

# Define an agent that uses the tool
data_analyst_agent = Agent(
    role="Data Analyst",
    goal="Analyze data from Snowflake database",
    backstory="An expert data analyst who can extract insights from enterprise data.",
    tools=[snowflake_tool],
    verbose=True,
)

# Example task to query sales data
query_task = Task(
    description="Query the sales data for the last quarter and summarize the top 5 products by revenue.",
    expected_output="A summary of the top 5 products by revenue for the last quarter.",
    agent=data_analyst_agent,
)

# Create and run the crew
crew = Crew(agents=[data_analyst_agent],
            tasks=[query_task])
result = crew.kickoff()
```

Você também pode customizar a ferramenta com parâmetros adicionais:

```python Code
# Initialize the tool with custom parameters
snowflake_tool = SnowflakeSearchTool(
    config=config,
    pool_size=10,
    max_retries=5,
    retry_delay=2.0,
    enable_caching=True
)
```

## Parâmetros

### Parâmetros do SnowflakeConfig

A classe `SnowflakeConfig` aceita os seguintes parâmetros:

* **account**: Obrigatório. Identificador da conta Snowflake.
* **user**: Obrigatório. Nome de usuário do Snowflake.
* **password**: Opcional\*. Senha do Snowflake.
* **private\_key\_path**: Opcional\*. Caminho para o arquivo de chave privada (alternativa à senha).
* **warehouse**: Obrigatório. Nome do warehouse do Snowflake.
* **database**: Obrigatório. Banco de dados padrão.
* **snowflake\_schema**: Obrigatório. Schema padrão.
* **role**: Opcional. Papel de usuário Snowflake.
* **session\_parameters**: Opcional. Parâmetros de sessão personalizados como dicionário.

\*É necessário fornecer `password` ou `private_key_path`.

### Parâmetros do SnowflakeSearchTool

O `SnowflakeSearchTool` aceita os seguintes parâmetros durante a inicialização:

* **config**: Obrigatório. Um objeto `SnowflakeConfig` contendo detalhes da conexão.
* **pool\_size**: Opcional. Número de conexões no pool. O padrão é 5.
* **max\_retries**: Opcional. Número máximo de tentativas para consultas que falharem. Padrão é 3.
* **retry\_delay**: Opcional. Intervalo entre tentativas em segundos. Padrão é 1.0.
* **enable\_caching**: Opcional. Define se o cache de resultados de consultas será habilitado. Padrão é True.

## Uso

Ao utilizar o `SnowflakeSearchTool`, você deve fornecer os seguintes parâmetros:

* **query**: Obrigatório. Consulta SQL a ser executada.
* **database**: Opcional. Sobrescreve o banco de dados padrão especificado na configuração.
* **snowflake\_schema**: Opcional. Sobrescreve o schema padrão especificado na configuração.
* **timeout**: Opcional. Tempo limite da consulta em segundos. O padrão é 300.

A ferramenta retornará os resultados da consulta como uma lista de dicionários, onde cada dicionário representa uma linha com os nomes das colunas como chaves.

```python Code
# Example of using the tool with an agent
data_analyst = Agent(
    role="Data Analyst",
    goal="Analyze sales data from Snowflake",
    backstory="An expert data analyst with experience in SQL and data visualization.",
    tools=[snowflake_tool],
    verbose=True
)

# The agent will use the tool with parameters like:
# query="SELECT product_name, SUM(revenue) as total_revenue FROM sales GROUP BY product_name ORDER BY total_revenue DESC LIMIT 5"
# timeout=600

# Create a task for the agent
analysis_task = Task(
    description="Query the sales database and identify the top 5 products by revenue for the last quarter.",
    expected_output="A detailed analysis of the top 5 products by revenue.",
    agent=data_analyst
)

# Run the task
crew = Crew(
    agents=[data_analyst],
    tasks=[analysis_task]
)
result = crew.kickoff()
```

## Recursos Avançados

### Pool de Conexões

O `SnowflakeSearchTool` implementa pool de conexões para melhorar a performance reutilizando conexões com o banco de dados. Você pode controlar o tamanho do pool com o parâmetro `pool_size`.

### Tentativas Automáticas

A ferramenta tenta novamente consultas que falharem automaticamente, usando backoff exponencial. O comportamento das tentativas pode ser ajustado pelos parâmetros `max_retries` e `retry_delay`.

### Cache de Resultados de Consultas

Para melhorar a performance em consultas repetidas, a ferramenta pode armazenar resultados em cache. Este recurso está habilitado por padrão, mas pode ser desativado ao definir `enable_caching=False`.

### Autenticação por Par de Chaves

Além de autenticação por senha, a ferramenta também suporta autenticação por par de chaves para maior segurança:

```python Code
config = SnowflakeConfig(
    account="your_account",
    user="your_username",
    private_key_path="/path/to/your/private/key.p8",
    warehouse="COMPUTE_WH",
    database="your_database",
    snowflake_schema="your_schema"
)
```

## Tratamento de Erros

O `SnowflakeSearchTool` inclui uma gestão abrangente de erros para situações comuns no Snowflake:

* Falhas de conexão
* Timeout de consultas
* Erros de autenticação
* Erros de banco de dados e schema

Quando um erro ocorrer, a ferramenta tentará repetir a operação (se estiver configurado) e fornecerá informações detalhadas sobre o erro.

## Conclusão

O `SnowflakeSearchTool` oferece uma maneira poderosa de integrar data warehouses Snowflake com agentes CrewAI. Com recursos como pool de conexões, tentativas automáticas e cache de consultas, ele possibilita acesso eficiente e confiável aos dados empresariais. Esta ferramenta é particularmente útil para tarefas de análise de dados, relatórios e inteligência de negócios que demandam acesso a dados estruturados armazenados no Snowflake.


# Busca Vetorial Weaviate
Source: https://docs.crewai.com/pt-BR/tools/database-data/weaviatevectorsearchtool

O `WeaviateVectorSearchTool` foi projetado para buscar documentos semanticamente similares em um banco de dados vetorial Weaviate.

## Visão Geral

O `WeaviateVectorSearchTool` foi especificamente desenvolvido para realizar buscas semânticas em documentos armazenados em um banco de dados vetorial Weaviate. Essa ferramenta permite encontrar documentos semanticamente similares a uma determinada consulta, aproveitando o poder das embeddings vetoriais para resultados de busca mais precisos e contextualmente relevantes.

[Weaviate](https://weaviate.io/) é um banco de dados vetorial que armazena e consulta embeddings vetoriais, possibilitando recursos de busca semântica.

## Instalação

Para incorporar esta ferramenta ao seu projeto, é necessário instalar o cliente Weaviate:

```shell
uv add weaviate-client
```

## Etapas para Começar

Para utilizar efetivamente o `WeaviateVectorSearchTool`, siga as etapas abaixo:

1. **Instalação dos Pacotes**: Confirme que os pacotes `crewai[tools]` e `weaviate-client` estão instalados em seu ambiente Python.
2. **Configuração do Weaviate**: Configure um cluster Weaviate. Você pode seguir as instruções na [documentação do Weaviate](https://weaviate.io/developers/wcs/manage-clusters/connect).
3. **Chaves de API**: Obtenha a URL do seu cluster Weaviate e a chave de API correspondente.
4. **Chave de API da OpenAI**: Certifique-se de que você tenha uma chave de API da OpenAI definida nas variáveis de ambiente como `OPENAI_API_KEY`.

## Exemplo

O exemplo a seguir demonstra como inicializar a ferramenta e executar uma busca:

```python Code
from crewai_tools import WeaviateVectorSearchTool

# Inicializar a ferramenta
tool = WeaviateVectorSearchTool(
    collection_name='example_collections',
    limit=3,
    weaviate_cluster_url="https://your-weaviate-cluster-url.com",
    weaviate_api_key="your-weaviate-api-key",
)

@agent
def search_agent(self) -> Agent:
    '''
    Este agente utiliza o WeaviateVectorSearchTool para buscar
    documentos semanticamente similares em um banco de dados vetorial Weaviate.
    '''
    return Agent(
        config=self.agents_config["search_agent"],
        tools=[tool]
    )
```

## Parâmetros

O `WeaviateVectorSearchTool` aceita os seguintes parâmetros:

* **collection\_name**: Obrigatório. O nome da coleção a ser pesquisada.
* **weaviate\_cluster\_url**: Obrigatório. A URL do cluster Weaviate.
* **weaviate\_api\_key**: Obrigatório. A chave de API para o cluster Weaviate.
* **limit**: Opcional. O número de resultados a serem retornados. O padrão é `3`.
* **vectorizer**: Opcional. O vetorizador a ser utilizado. Se não for informado, será utilizado o `text2vec_openai` com o modelo `nomic-embed-text`.
* **generative\_model**: Opcional. O modelo generativo a ser utilizado. Se não for informado, será utilizado o `gpt-4o` da OpenAI.

## Configuração Avançada

Você pode personalizar o vetorizador e o modelo generativo utilizados pela ferramenta:

```python Code
from crewai_tools import WeaviateVectorSearchTool
from weaviate.classes.config import Configure

# Configurar modelo personalizado para vetorizador e modelo generativo
tool = WeaviateVectorSearchTool(
    collection_name='example_collections',
    limit=3,
    vectorizer=Configure.Vectorizer.text2vec_openai(model="nomic-embed-text"),
    generative_model=Configure.Generative.openai(model="gpt-4o-mini"),
    weaviate_cluster_url="https://your-weaviate-cluster-url.com",
    weaviate_api_key="your-weaviate-api-key",
)
```

## Pré-carregando Documentos

Você pode pré-carregar seu banco de dados Weaviate com documentos antes de utilizar a ferramenta:

```python Code
import os
from crewai_tools import WeaviateVectorSearchTool
import weaviate
from weaviate.classes.init import Auth

# Conectar ao Weaviate
client = weaviate.connect_to_weaviate_cloud(
    cluster_url="https://your-weaviate-cluster-url.com",
    auth_credentials=Auth.api_key("your-weaviate-api-key"),
    headers={"X-OpenAI-Api-Key": "your-openai-api-key"}
)

# Obter ou criar coleção
test_docs = client.collections.get("example_collections")
if not test_docs:
    test_docs = client.collections.create(
        name="example_collections",
        vectorizer_config=Configure.Vectorizer.text2vec_openai(model="nomic-embed-text"),
        generative_config=Configure.Generative.openai(model="gpt-4o"),
    )

# Carregar documentos
docs_to_load = os.listdir("knowledge")
with test_docs.batch.dynamic() as batch:
    for d in docs_to_load:
        with open(os.path.join("knowledge", d), "r") as f:
            content = f.read()
        batch.add_object(
            {
                "content": content,
                "year": d.split("_")[0],
            }
        )

# Inicializar a ferramenta
tool = WeaviateVectorSearchTool(
    collection_name='example_collections',
    limit=3,
    weaviate_cluster_url="https://your-weaviate-cluster-url.com",
    weaviate_api_key="your-weaviate-api-key",
)
```

## Exemplo de Integração com Agente

Veja como integrar o `WeaviateVectorSearchTool` com um agente CrewAI:

```python Code
from crewai import Agent
from crewai_tools import WeaviateVectorSearchTool

# Inicializar a ferramenta
weaviate_tool = WeaviateVectorSearchTool(
    collection_name='example_collections',
    limit=3,
    weaviate_cluster_url="https://your-weaviate-cluster-url.com",
    weaviate_api_key="your-weaviate-api-key",
)

# Criar um agente com a ferramenta
rag_agent = Agent(
    name="rag_agent",
    role="Você é um assistente útil que pode responder perguntas com a ajuda do WeaviateVectorSearchTool.",
    llm="gpt-4o-mini",
    tools=[weaviate_tool],
)
```

## Conclusão

O `WeaviateVectorSearchTool` fornece uma maneira poderosa de buscar documentos semanticamente similares em um banco de dados vetorial Weaviate. Ao utilizar embeddings vetoriais, ele permite resultados de busca mais precisos e relevantes em termos de contexto, quando comparado a buscas tradicionais baseadas em palavras-chave. Essa ferramenta é especialmente útil para aplicações que precisam encontrar informações a partir do significado e não apenas de correspondências exatas.


# Busca RAG em CSV
Source: https://docs.crewai.com/pt-BR/tools/file-document/csvsearchtool

O `CSVSearchTool` é uma poderosa ferramenta RAG (Geração com Recuperação Aprimorada) projetada para buscas semânticas no conteúdo de arquivos CSV.

# `CSVSearchTool`

<Note>
  **Experimental**: Ainda estamos trabalhando na melhoria das ferramentas, portanto podem ocorrer comportamentos inesperados ou mudanças futuras.
</Note>

## Descrição

Esta ferramenta é utilizada para realizar buscas RAG (Geração com Recuperação Aprimorada) no conteúdo de um arquivo CSV. Ela permite que usuários façam buscas semânticas por consultas no conteúdo de um arquivo CSV especificado.
Este recurso é particularmente útil para extrair informações de grandes datasets CSV, em que métodos de busca tradicionais poderiam ser ineficientes. Todas as ferramentas com "Search" no nome, incluindo o CSVSearchTool,
são ferramentas RAG projetadas para busca em diferentes fontes de dados.

## Instalação

Instale o pacote crewai\_tools

```shell
pip install 'crewai[tools]'
```

## Exemplo

```python Code
from crewai_tools import CSVSearchTool

# Inicialize a ferramenta com um arquivo CSV específico.
# Esta configuração permite que o agente busque somente no arquivo CSV fornecido.
tool = CSVSearchTool(csv='path/to/your/csvfile.csv')

# OU

# Inicialize a ferramenta sem um arquivo CSV específico.
# O agente precisará informar o caminho do CSV em tempo de execução.
tool = CSVSearchTool()
```

## Argumentos

Os seguintes parâmetros podem ser utilizados para personalizar o comportamento do `CSVSearchTool`:

| Argumento | Tipo     | Descrição                                                                                                                                                                                    |
| :-------- | :------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **csv**   | `string` | *Opcional*. O caminho para o arquivo CSV que você deseja buscar. Este é um argumento obrigatório se a ferramenta for inicializada sem um arquivo CSV específico; caso contrário, é opcional. |

## Modelo e embeddings personalizados

Por padrão, a ferramenta utiliza OpenAI tanto para embeddings quanto para sumarização. Para personalizar o modelo, você pode usar um dicionário de configuração como segue:

```python Code
tool = CSVSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Leitura de Diretório
Source: https://docs.crewai.com/pt-BR/tools/file-document/directoryreadtool

O `DirectoryReadTool` é uma poderosa utilidade projetada para fornecer uma listagem abrangente do conteúdo de diretórios.

# `DirectoryReadTool`

<Note>
  Ainda estamos trabalhando para melhorar as ferramentas, então pode haver comportamentos inesperados ou alterações no futuro.
</Note>

## Descrição

O DirectoryReadTool é uma poderosa utilidade projetada para fornecer uma listagem abrangente do conteúdo de diretórios.
Ele pode navegar recursivamente pelo diretório especificado, oferecendo aos usuários uma enumeração detalhada de todos os arquivos, incluindo aqueles que estão dentro de subdiretórios.
Essa ferramenta é fundamental para tarefas que exigem um inventário completo das estruturas de diretórios ou para validar a organização de arquivos em diretórios.

## Instalação

Para utilizar o DirectoryReadTool em seu projeto, instale o pacote `crewai_tools`. Se este pacote ainda não faz parte do seu ambiente, você pode instalá-lo usando o pip com o comando abaixo:

```shell
pip install 'crewai[tools]'
```

Esse comando instala a versão mais recente do pacote `crewai_tools`, permitindo o acesso ao DirectoryReadTool, entre outras utilidades.

## Exemplo

Empregar o DirectoryReadTool é simples. O snippet de código a seguir demonstra como configurá-lo e usar a ferramenta para listar o conteúdo de um diretório especificado:

```python Code
from crewai_tools import DirectoryReadTool

# Initialize the tool so the agent can read any directory's content
# it learns about during execution
tool = DirectoryReadTool()

# OR

# Initialize the tool with a specific directory,
# so the agent can only read the content of the specified directory
tool = DirectoryReadTool(directory='/path/to/your/directory')
```

## Argumentos

Os seguintes parâmetros podem ser usados para personalizar o comportamento do `DirectoryReadTool`:

| Argumento     | Tipo     | Descrição                                                                                                                                                                                                                    |
| :------------ | :------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **directory** | `string` | *Opcional*. Um argumento que especifica o caminho para o diretório cujo conteúdo você deseja listar. Aceita caminhos absolutos e relativos, direcionando a ferramenta para o diretório desejado para a listagem do conteúdo. |


# Busca RAG em Diretório
Source: https://docs.crewai.com/pt-BR/tools/file-document/directorysearchtool

O `DirectorySearchTool` é uma poderosa ferramenta RAG (Retrieval-Augmented Generation) desenvolvida para buscas semânticas no conteúdo de um diretório.

# `DirectorySearchTool`

<Note>
  **Experimental**: O DirectorySearchTool está em desenvolvimento contínuo. As funcionalidades e recursos podem evoluir, e comportamentos inesperados podem ocorrer enquanto aprimoramos a ferramenta.
</Note>

## Descrição

O DirectorySearchTool permite a busca semântica dentro do conteúdo de diretórios especificados, aproveitando a metodologia de Recuperação com Geração Aumentada (RAG) para uma navegação eficiente entre arquivos. Projetada para flexibilidade, a ferramenta possibilita que usuários especifiquem dinamicamente os diretórios de busca em tempo de execução ou definam um diretório fixo durante a configuração inicial.

## Instalação

Para utilizar o DirectorySearchTool, comece instalando o pacote crewai\_tools. Execute o seguinte comando no seu terminal:

```shell
pip install 'crewai[tools]'
```

## Inicialização e Uso

Importe o DirectorySearchTool do pacote `crewai_tools` para começar. Você pode inicializar a ferramenta sem especificar um diretório, permitindo definir o diretório de busca em tempo de execução. Alternativamente, a ferramenta pode ser inicializada já com um diretório predefinido.

```python Code
from crewai_tools import DirectorySearchTool

# Para especificação dinâmica de diretório em tempo de execução
tool = DirectorySearchTool()

# Para buscas em diretório fixo
tool = DirectorySearchTool(directory='/path/to/directory')
```

## Argumentos

* `directory`: Um argumento do tipo string que especifica o diretório de busca. Este parâmetro é opcional durante a inicialização, mas obrigatório para buscas caso não tenha sido definido inicialmente.

## Modelo Personalizado e Embeddings

O DirectorySearchTool utiliza OpenAI para embeddings e sumarização por padrão. As opções de personalização dessas configurações incluem a alteração do provedor de modelo e configurações, ampliando a flexibilidade para usuários avançados.

```python Code
tool = DirectorySearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # As opções incluem ollama, google, anthropic, llama2 e mais
            config=dict(
                model="llama2",
                # Configurações adicionais aqui
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Pesquisa RAG em DOCX
Source: https://docs.crewai.com/pt-BR/tools/file-document/docxsearchtool

A `DOCXSearchTool` é uma ferramenta RAG projetada para busca semântica em documentos DOCX.

# `DOCXSearchTool`

<Note>
  Ainda estamos trabalhando na melhoria das ferramentas, portanto pode haver comportamentos inesperados ou alterações no futuro.
</Note>

## Descrição

A `DOCXSearchTool` é uma ferramenta RAG desenvolvida para buscas semânticas dentro de documentos DOCX.
Ela permite que os usuários pesquisem e extraiam informações relevantes de arquivos DOCX de forma eficiente, utilizando buscas baseadas em consultas.
Esta ferramenta é inestimável para análise de dados, gestão da informação e tarefas de pesquisa,
otimizando o processo de encontrar informações específicas em grandes coleções de documentos.

## Instalação

Instale o pacote crewai\_tools executando o seguinte comando no seu terminal:

```shell
uv pip install docx2txt 'crewai[tools]'
```

## Exemplo

O exemplo a seguir demonstra a inicialização da DOCXSearchTool para buscar dentro do conteúdo de qualquer arquivo DOCX ou com o caminho de um arquivo DOCX específico.

```python Code
from crewai_tools import DOCXSearchTool

# Inicialize a ferramenta para buscar dentro do conteúdo de qualquer arquivo DOCX
tool = DOCXSearchTool()

# OU

# Inicialize a ferramenta com um arquivo DOCX específico,
# assim o agente só poderá buscar dentro do conteúdo do arquivo DOCX especificado
tool = DOCXSearchTool(docx='path/to/your/document.docx')
```

## Argumentos

Os seguintes parâmetros podem ser usados para customizar o comportamento da `DOCXSearchTool`:

| Argumento | Tipo     | Descrição                                                                                                                                                                                                                                     |
| :-------- | :------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **docx**  | `string` | *Opcional*. Um argumento que especifica o caminho para o arquivo DOCX que você deseja pesquisar. Se não for fornecido durante a inicialização, a ferramenta permite a especificação posterior do caminho de qualquer arquivo DOCX para busca. |

## Modelo e embeddings personalizados

Por padrão, a ferramenta utiliza o OpenAI tanto para embeddings quanto para sumarização. Para customizar o modelo, você pode usar um dicionário de configuração como no exemplo:

```python Code
tool = DOCXSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Leitura de Arquivo
Source: https://docs.crewai.com/pt-BR/tools/file-document/filereadtool

O `FileReadTool` foi desenvolvido para ler arquivos do sistema de arquivos local.

## Visão Geral

<Note>
  Ainda estamos trabalhando para melhorar as ferramentas, portanto pode haver comportamentos inesperados ou alterações no futuro.
</Note>

O FileReadTool representa conceitualmente um conjunto de funcionalidades dentro do pacote crewai\_tools voltadas para facilitar a leitura e a recuperação de conteúdo de arquivos.
Esse conjunto inclui ferramentas para processar arquivos de texto em lote, ler arquivos de configuração em tempo de execução e importar dados para análise.
Ele suporta uma variedade de formatos de arquivo baseados em texto, como `.txt`, `.csv`, `.json` e outros. Dependendo do tipo de arquivo, o conjunto oferece funcionalidades especializadas,
como converter conteúdo JSON em um dicionário Python para facilitar o uso.

## Instalação

Para utilizar as funcionalidades anteriormente atribuídas ao FileReadTool, instale o pacote crewai\_tools:

```shell
pip install 'crewai[tools]'
```

## Exemplo de Uso

Para começar a usar o FileReadTool:

```python Code
from crewai_tools import FileReadTool

# Inicialize a ferramenta para ler quaisquer arquivos que os agentes conhecem ou informe o caminho para
file_read_tool = FileReadTool()

# OU

# Inicialize a ferramenta com um caminho de arquivo específico, assim o agente poderá ler apenas o conteúdo do arquivo especificado
file_read_tool = FileReadTool(file_path='path/to/your/file.txt')
```

## Argumentos

* `file_path`: O caminho para o arquivo que você deseja ler. Aceita caminhos absolutos e relativos. Certifique-se de que o arquivo exista e de que você tenha as permissões necessárias para acessá-lo.


# Escrita de Arquivo
Source: https://docs.crewai.com/pt-BR/tools/file-document/filewritetool

O `FileWriterTool` foi projetado para escrever conteúdo em arquivos.

# `FileWriterTool`

## Descrição

O `FileWriterTool` é um componente do pacote crewai\_tools, projetado para simplificar o processo de escrita de conteúdo em arquivos com compatibilidade multiplataforma (Windows, Linux, macOS).\
É particularmente útil em cenários como geração de relatórios, salvamento de logs, criação de arquivos de configuração e mais.\
Essa ferramenta lida com diferenças de caminhos entre sistemas operacionais, suporta codificação UTF-8 e cria diretórios automaticamente caso eles não existam, facilitando a organização da sua saída de forma confiável em diferentes plataformas.

## Instalação

Instale o pacote crewai\_tools para utilizar o `FileWriterTool` em seus projetos:

```shell
pip install 'crewai[tools]'
```

## Exemplo

Para começar a usar o `FileWriterTool`:

```python Code
from crewai_tools import FileWriterTool

# Inicialize a ferramenta
file_writer_tool = FileWriterTool()

# Escreva conteúdo em um arquivo em um diretório especificado
result = file_writer_tool._run('example.txt', 'This is a test content.', 'test_directory')
print(result)
```

## Argumentos

* `filename`: O nome do arquivo que você deseja criar ou sobrescrever.
* `content`: O conteúdo a ser escrito no arquivo.
* `directory` (opcional): O caminho para o diretório onde o arquivo será criado. Por padrão, utiliza o diretório atual (`.`). Se o diretório não existir, ele será criado.

## Conclusão

Ao integrar o `FileWriterTool` aos seus crews, os agentes podem escrever conteúdo em arquivos de forma confiável em diferentes sistemas operacionais.\
Esta ferramenta é essencial para tarefas que exigem salvamento de dados de saída, criação de sistemas de arquivos estruturados e manipulação de operações de arquivos multiplataforma.\
É especialmente recomendada para usuários do Windows que possam enfrentar problemas ao escrever arquivos com as operações padrão do Python.

Seguindo as orientações de configuração e uso fornecidas, incorporar essa ferramenta em projetos é simples e garante um comportamento consistente de escrita de arquivos em todas as plataformas.


# Busca JSON RAG
Source: https://docs.crewai.com/pt-BR/tools/file-document/jsonsearchtool

O `JSONSearchTool` foi projetado para buscar arquivos JSON e retornar os resultados mais relevantes.

# `JSONSearchTool`

<Note>
  O JSONSearchTool está atualmente em fase experimental. Isso significa que a ferramenta
  está em desenvolvimento ativo, e os usuários podem encontrar comportamentos inesperados ou
  alterações. Incentivamos fortemente o envio de feedback sobre quaisquer problemas ou sugestões de
  melhorias.
</Note>

## Descrição

O JSONSearchTool foi projetado para facilitar buscas eficientes e precisas dentro do conteúdo de arquivos JSON. Ele utiliza um mecanismo de busca RAG (Retrieve and Generate), permitindo que os usuários especifiquem um caminho JSON para buscas direcionadas dentro de um arquivo JSON específico. Essa capacidade melhora significativamente a precisão e relevância dos resultados de busca.

## Instalação

Para instalar o JSONSearchTool, utilize o seguinte comando pip:

```shell
pip install 'crewai[tools]'
```

## Exemplos de Uso

Aqui estão exemplos atualizados de como utilizar o JSONSearchTool de forma eficaz para buscar dentro de arquivos JSON. Esses exemplos consideram a implementação e padrões de uso atuais identificados na base de código.

```python Code
from crewai_tools import JSONSearchTool

# Busca geral em conteúdo JSON
# Esta abordagem é adequada quando o caminho JSON já é conhecido ou pode ser identificado dinamicamente.
tool = JSONSearchTool()

# Restringindo a busca a um arquivo JSON específico
# Use este método de inicialização quando desejar limitar o escopo de busca a um arquivo específico.
tool = JSONSearchTool(json_path='./path/to/your/file.json')
```

## Argumentos

* `json_path` (str, opcional): Especifica o caminho para o arquivo JSON a ser buscado. Este argumento não é obrigatório se a ferramenta for inicializada para uma busca geral. Quando fornecido, limita a busca ao arquivo JSON especificado.

## Opções de Configuração

O JSONSearchTool oferece ampla personalização através de um dicionário de configuração. Isso permite que os usuários selecionem diferentes modelos para embeddings e sumarização conforme suas necessidades.

```python Code
tool = JSONSearchTool(
    config={
        "llm": {
            "provider": "ollama",  # Outras opções incluem google, openai, anthropic, llama2, etc.
            "config": {
                "model": "llama2",
                # Configurações opcionais adicionais podem ser especificadas aqui.
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            },
        },
        "embedding_model": {
            "provider": "google", # ou openai, ollama, ...
            "config": {
                "model": "models/embedding-001",
                "task_type": "retrieval_document",
                # Mais opções de personalização podem ser adicionadas aqui.
            },
        },
    }
)
```


# Pesquisa MDX RAG
Source: https://docs.crewai.com/pt-BR/tools/file-document/mdxsearchtool

O `MDXSearchTool` foi projetado para pesquisar arquivos MDX e retornar os resultados mais relevantes.

# `MDXSearchTool`

<Note>
  O MDXSearchTool está em desenvolvimento contínuo. Recursos podem ser adicionados ou removidos, e a funcionalidade pode mudar de forma imprevisível à medida que refinamos a ferramenta.
</Note>

## Descrição

A Ferramenta de Pesquisa MDX é um componente do pacote `crewai_tools` focado em facilitar a extração avançada de dados do markdown. Ela permite que usuários pesquisem e extraiam informações relevantes de arquivos MD utilizando buscas baseadas em consulta. Esta ferramenta é indispensável para análise de dados, gestão de informações e tarefas de pesquisa, agilizando o processo de encontrar informações específicas em grandes coleções de documentos.

## Instalação

Antes de utilizar a Ferramenta de Pesquisa MDX, certifique-se de que o pacote `crewai_tools` está instalado. Caso não esteja, você pode instalá-lo com o comando abaixo:

```shell
pip install 'crewai[tools]'
```

## Exemplo de Uso

Para utilizar a Ferramenta de Pesquisa MDX, primeiro defina as variáveis de ambiente necessárias. Em seguida, integre a ferramenta ao seu projeto crewAI para começar sua pesquisa de mercado. Veja abaixo um exemplo básico de como fazer isso:

```python Code
from crewai_tools import MDXSearchTool

# Inicialize a ferramenta para pesquisar qualquer conteúdo MDX que ela conheça durante a execução
tool = MDXSearchTool()

# OU

# Inicialize a ferramenta com um caminho específico para o arquivo MDX, realizando buscas exclusivamente neste documento
tool = MDXSearchTool(mdx='path/to/your/document.mdx')
```

## Parâmetros

* mdx: **Opcional**. Especifica o caminho do arquivo MDX para pesquisa. Pode ser informado durante a inicialização.

## Personalização do Modelo e Embeddings

A ferramenta utiliza, por padrão, o OpenAI para embeddings e sumarização. Para personalizar, utilize um dicionário de configuração conforme exemplo abaixo:

```python Code
tool = MDXSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # As opções incluem google, openai, anthropic, llama2, etc.
            config=dict(
                model="llama2",
                # Parâmetros opcionais podem ser incluídos aqui.
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # Um título opcional para os embeddings pode ser adicionado aqui.
                # title="Embeddings",
            ),
        ),
    )
)
```


# Visão Geral
Source: https://docs.crewai.com/pt-BR/tools/file-document/overview

Leia, escreva e pesquise em diversos formatos de arquivos com as ferramentas de processamento de documentos do CrewAI

Estas ferramentas permitem que seus agentes trabalhem com diversos formatos e tipos de documentos. De leitura de PDFs ao processamento de dados em JSON, essas ferramentas atendem a todas as suas necessidades de processamento de documentos.

## **Ferramentas Disponíveis**

<CardGroup cols={2}>
  <Card title="Ferramenta de Leitura de Arquivos" icon="folders" href="/pt-BR/tools/file-document/filereadtool">
    Leia conteúdo de qualquer tipo de arquivo, incluindo texto, markdown e mais.
  </Card>

  <Card title="Ferramenta de Escrita de Arquivos" icon="file-pen" href="/pt-BR/tools/file-document/filewritetool">
    Escreva conteúdo em arquivos, crie novos documentos e salve dados processados.
  </Card>

  <Card title="Ferramenta de Pesquisa em PDF" icon="file-pdf" href="/pt-BR/tools/file-document/pdfsearchtool">
    Pesquise e extraia conteúdo de texto de documentos PDF de forma eficiente.
  </Card>

  <Card title="Ferramenta de Pesquisa em DOCX" icon="file-word" href="/pt-BR/tools/file-document/docxsearchtool">
    Pesquise em documentos do Microsoft Word e extraia conteúdo relevante.
  </Card>

  <Card title="Ferramenta de Pesquisa em JSON" icon="brackets-curly" href="/pt-BR/tools/file-document/jsonsearchtool">
    Faça a análise e pesquisa em arquivos JSON com recursos avançados de consulta.
  </Card>

  <Card title="Ferramenta de Pesquisa em CSV" icon="table" href="/pt-BR/tools/file-document/csvsearchtool">
    Processe e pesquise em arquivos CSV, extraia linhas e colunas específicas.
  </Card>

  <Card title="Ferramenta de Pesquisa em XML" icon="code" href="/pt-BR/tools/file-document/xmlsearchtool">
    Analise arquivos XML e pesquise elementos e atributos específicos.
  </Card>

  <Card title="Ferramenta de Pesquisa em MDX" icon="markdown" href="/pt-BR/tools/file-document/mdxsearchtool">
    Pesquise em arquivos MDX e extraia conteúdo de documentações.
  </Card>

  <Card title="Ferramenta de Pesquisa em TXT" icon="file-lines" href="/pt-BR/tools/file-document/txtsearchtool">
    Pesquise em arquivos de texto simples com recursos de busca por padrões.
  </Card>

  <Card title="Ferramenta de Pesquisa em Diretório" icon="folder-open" href="/pt-BR/tools/file-document/directorysearchtool">
    Pesquise arquivos e pastas dentro de estruturas de diretórios.
  </Card>

  <Card title="Ferramenta de Leitura de Diretório" icon="folder" href="/pt-BR/tools/file-document/directoryreadtool">
    Leia e liste conteúdos de diretórios, estruturas de arquivos e metadados.
  </Card>
</CardGroup>

## **Casos de Uso Comuns**

* **Processamento de Documentos**: Extraia e analise conteúdo de vários formatos de arquivos
* **Importação de Dados**: Leia dados estruturados de arquivos CSV, JSON e XML
* **Busca por Conteúdo**: Encontre informações específicas em grandes coleções de documentos
* **Gerenciamento de Arquivos**: Organize e manipule arquivos e diretórios
* **Exportação de Dados**: Salve os resultados processados em vários formatos de arquivo

## **Exemplo Rápido de Início**

```python
from crewai_tools import FileReadTool, PDFSearchTool, JSONSearchTool

# Create tools
file_reader = FileReadTool()
pdf_searcher = PDFSearchTool()
json_processor = JSONSearchTool()

# Add to your agent
agent = Agent(
    role="Document Analyst",
    tools=[file_reader, pdf_searcher, json_processor],
    goal="Process and analyze various document types"
)
```

## **Dicas para Processamento de Documentos**

* **Permissões de Arquivo**: Certifique-se de que seu agente possui as permissões adequadas de leitura/escrita
* **Arquivos Grandes**: Considere dividir documentos muito grandes em partes menores
* **Suporte de Formatos**: Consulte a documentação da ferramenta para saber quais formatos de arquivos são suportados
* **Tratamento de Erros**: Implemente tratamento de erros adequado para arquivos corrompidos ou inacessíveis


# Busca RAG em PDF
Source: https://docs.crewai.com/pt-BR/tools/file-document/pdfsearchtool

O `PDFSearchTool` é projetado para pesquisar arquivos PDF e retornar os resultados mais relevantes.

# `PDFSearchTool`

<Note>
  Ainda estamos trabalhando para melhorar as ferramentas, então pode haver comportamentos inesperados ou mudanças futuras.
</Note>

## Descrição

O PDFSearchTool é uma ferramenta RAG projetada para buscas semânticas dentro do conteúdo de PDFs. Ela permite inserir uma consulta de busca e um documento PDF, aproveitando técnicas avançadas de busca para encontrar conteúdos relevantes de forma eficiente.
Essa capacidade a torna especialmente útil para extrair informações específicas de arquivos PDF grandes rapidamente.

## Instalação

Para começar a usar o PDFSearchTool, primeiro, garanta que o pacote crewai\_tools está instalado com o seguinte comando:

```shell
pip install 'crewai[tools]'
```

## Exemplo

Veja como utilizar o PDFSearchTool para buscar dentro de um documento PDF:

```python Code
from crewai_tools import PDFSearchTool

# Inicialize a ferramenta permitindo buscas em qualquer conteúdo PDF caso o caminho seja informado durante a execução
tool = PDFSearchTool()

# OU

# Inicialize a ferramenta com um caminho PDF específico para buscas exclusivas naquele documento
tool = PDFSearchTool(pdf='path/to/your/document.pdf')
```

## Argumentos

* `pdf`: **Opcional** O caminho do PDF para busca. Pode ser fornecido na inicialização ou nos argumentos do método `run`. Caso seja fornecido na inicialização, a ferramenta confinará suas buscas ao documento especificado.

## Modelo e embeddings personalizados

Por padrão, a ferramenta utiliza OpenAI tanto para embeddings quanto para sumarização. Para personalizar o modelo, você pode usar um dicionário de configuração como no exemplo abaixo:

```python Code
tool = PDFSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Pesquisa TXT RAG
Source: https://docs.crewai.com/pt-BR/tools/file-document/txtsearchtool

O `TXTSearchTool` foi projetado para realizar uma busca RAG (Geração Aumentada por Recuperação) dentro do conteúdo de um arquivo de texto.

## Visão Geral

<Note>
  Ainda estamos trabalhando para melhorar as ferramentas, por isso pode haver comportamentos inesperados ou mudanças no futuro.
</Note>

Esta ferramenta é utilizada para realizar uma busca RAG (Geração Aumentada por Recuperação) dentro do conteúdo de um arquivo de texto.
Ela permite uma busca semântica de uma consulta dentro do conteúdo de um arquivo de texto especificado,
tornando-se um recurso valioso para extrair rapidamente informações ou encontrar seções específicas do texto com base na consulta fornecida.

## Instalação

Para usar o `TXTSearchTool`, primeiro é necessário instalar o pacote `crewai_tools`.
Isso pode ser feito usando o pip, um gerenciador de pacotes para Python.
Abra seu terminal ou prompt de comando e digite o seguinte comando:

```shell
pip install 'crewai[tools]'
```

Este comando fará o download e instalará o TXTSearchTool junto com todas as dependências necessárias.

## Exemplo

O exemplo a seguir demonstra como usar o TXTSearchTool para pesquisar dentro de um arquivo de texto.
Este exemplo mostra tanto a inicialização da ferramenta com um arquivo de texto específico quanto a pesquisa subsequente dentro do conteúdo desse arquivo.

```python Code
from crewai_tools import TXTSearchTool

# Inicialize a ferramenta para pesquisar no conteúdo de qualquer arquivo de texto
# que o agente aprender durante sua execução
tool = TXTSearchTool()

# OU

# Inicialize a ferramenta com um arquivo de texto específico,
# para que o agente possa pesquisar dentro do conteúdo desse arquivo de texto
tool = TXTSearchTool(txt='path/to/text/file.txt')
```

## Argumentos

* `txt` (str): **Opcional**. O caminho para o arquivo de texto que você deseja pesquisar.
  Este argumento só é necessário se a ferramenta não foi inicializada com um arquivo de texto específico;
  caso contrário, a pesquisa será realizada no arquivo de texto fornecido inicialmente.

## Modelo e embeddings personalizados

Por padrão, a ferramenta utiliza o OpenAI tanto para embeddings quanto para sumarização.
Para personalizar o modelo, você pode usar um dicionário de configuração como o exemplo a seguir:

```python Code
tool = TXTSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Busca RAG em XML
Source: https://docs.crewai.com/pt-BR/tools/file-document/xmlsearchtool

O `XMLSearchTool` foi projetado para realizar uma busca RAG (Geração Aumentada por Recuperação) dentro do conteúdo de um arquivo XML.

# `XMLSearchTool`

<Note>
  Ainda estamos trabalhando na melhoria das ferramentas, então pode haver comportamentos inesperados ou mudanças no futuro.
</Note>

## Descrição

O XMLSearchTool é uma ferramenta RAG de ponta, desenvolvida para realizar buscas semânticas em arquivos XML.
Ideal para usuários que precisam analisar e extrair informações do conteúdo XML de forma eficiente, esta ferramenta permite inserir uma consulta de busca e um caminho opcional para o arquivo XML.
Ao especificar um caminho de arquivo XML, o usuário pode direcionar sua busca de forma mais precisa ao conteúdo daquele arquivo, obtendo assim resultados mais relevantes.

## Instalação

Para começar a usar o XMLSearchTool, é necessário instalar primeiro o pacote crewai\_tools. Isso pode ser feito facilmente com o seguinte comando:

```shell
pip install 'crewai[tools]'
```

## Exemplo

Aqui estão dois exemplos demonstrando como usar o XMLSearchTool.
O primeiro exemplo mostra a busca dentro de um arquivo XML específico, enquanto o segundo exemplo ilustra como iniciar uma busca sem definir previamente um caminho XML, oferecendo flexibilidade no escopo da busca.

```python Code
from crewai_tools import XMLSearchTool

# Permite que agentes busquem no conteúdo de qualquer arquivo XML
# conforme aprendem seus caminhos durante a execução
tool = XMLSearchTool()

# OU

# Inicializa a ferramenta com um caminho específico para arquivo XML
# para busca exclusiva dentro desse documento
tool = XMLSearchTool(xml='path/to/your/xmlfile.xml')
```

## Argumentos

* `xml`: Este é o caminho para o arquivo XML que você deseja buscar.
  Este parâmetro é opcional durante a inicialização da ferramenta, mas deve ser fornecido ou na inicialização ou como parte dos argumentos do método `run` para executar a busca.

## Modelo customizado e embeddings

Por padrão, a ferramenta utiliza a OpenAI tanto para embeddings quanto para sumarização. Para personalizar o modelo, você pode usar um dicionário de configuração conforme o exemplo a seguir:

```python Code
tool = XMLSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Visão Geral das Ferramentas
Source: https://docs.crewai.com/pt-BR/tools/overview

Descubra a vasta biblioteca do CrewAI com mais de 40 ferramentas para potencializar seus agentes de IA

O CrewAI oferece uma biblioteca extensa de ferramentas pré-construídas para aprimorar as capacidades dos seus agentes. De processamento de arquivos a web scraping, consultas em bancos de dados a serviços de IA — temos tudo o que você precisa.

## **Categorias de Ferramentas**

<CardGroup cols={2}>
  <Card title="Arquivo & Documento" icon="file-check" href="/pt-BR/tools/file-document/overview" color="#3B82F6">
    Leia, escreva e pesquise em diversos formatos de arquivo, incluindo PDF, DOCX, JSON, CSV e muito mais. Perfeito para fluxos de processamento de documentos.
  </Card>

  <Card title="Web Scraping & Navegação" icon="globe" href="/pt-BR/tools/web-scraping/overview" color="#10B981">
    Extraia dados de sites, automatize interações com navegadores e faça scraping de conteúdo em escala com ferramentas como Firecrawl, Selenium e outras.
  </Card>

  <Card title="Pesquisa & Busca" icon="magnifying-glass" href="/pt-BR/tools/search-research/overview" color="#F59E0B">
    Realize buscas na web, encontre repositórios de código, pesquise conteúdo no YouTube e descubra informações em toda a internet.
  </Card>

  <Card title="Banco de Dados & Dados" icon="database" href="/pt-BR/tools/database-data/overview" color="#8B5CF6">
    Conecte-se a bancos de dados SQL, repositórios vetoriais e data warehouses. Consulte MySQL, PostgreSQL, Snowflake, Qdrant e Weaviate.
  </Card>

  <Card title="IA & Aprendizado de Máquina" icon="brain" href="/pt-BR/tools/ai-ml/overview" color="#EF4444">
    Gere imagens com DALL-E, execute tarefas de visão computacional, integre com LangChain, construa sistemas RAG e aproveite interpretadores de código.
  </Card>

  <Card title="Nuvem & Armazenamento" icon="cloud" href="/pt-BR/tools/cloud-storage/overview" color="#06B6D4">
    Interaja com serviços em nuvem incluindo AWS S3, Amazon Bedrock e outros serviços de armazenamento e IA na nuvem.
  </Card>

  <Card title="Automação & Integração" icon="bolt" href="/pt-BR/tools/automation/overview" color="#84CC16">
    Automatize fluxos de trabalho com Apify, Composio e outras plataformas de integração para conectar seus agentes a serviços externos.
  </Card>
</CardGroup>

## **Acesso Rápido**

Precisa de uma ferramenta específica? Aqui estão algumas opções populares:

<CardGroup cols={3}>
  <Card title="RAG Tool" icon="image" href="/pt-BR/tools/ai-ml/ragtool">
    Implemente Geração com Recuperação de Dados (RAG)
  </Card>

  <Card title="Serper Dev" icon="book-atlas" href="/pt-BR/tools/search-research/serperdevtool">
    API de busca do Google
  </Card>

  <Card title="File Read" icon="file" href="/pt-BR/tools/file-document/filereadtool">
    Leia qualquer tipo de arquivo
  </Card>

  <Card title="Scrape Website" icon="globe" href="/pt-BR/tools/web-scraping/scrapewebsitetool">
    Extraia conteúdo da web
  </Card>

  <Card title="Code Interpreter" icon="code" href="/pt-BR/tools/ai-ml/codeinterpretertool">
    Execute código Python
  </Card>

  <Card title="S3 Reader" icon="cloud" href="/pt-BR/tools/cloud-storage/s3readertool">
    Acesse arquivos no AWS S3
  </Card>
</CardGroup>

## **Primeiros Passos**

Para usar qualquer ferramenta em seu projeto CrewAI:

1. **Importe** a ferramenta na configuração da sua crew
2. **Adicione** à lista de ferramentas do seu agente
3. **Configure** as chaves de API ou ajustes necessários

```python
from crewai_tools import FileReadTool, SerperDevTool

# Adicione as ferramentas ao seu agente
agent = Agent(
    role="Research Analyst",
    tools=[FileReadTool(), SerperDevTool()],
    # ... outrAs configurações
)
```

Pronto para explorar? Escolha uma categoria acima para descobrir as ferramentas que se encaixam no seu caso de uso!


# Brave Search
Source: https://docs.crewai.com/pt-BR/tools/search-research/bravesearchtool

O `BraveSearchTool` foi projetado para pesquisar na internet usando a Brave Search API.

# `BraveSearchTool`

## Descrição

Esta ferramenta foi desenvolvida para realizar buscas na web utilizando a Brave Search API. Ela permite que você pesquise na internet com uma consulta especificada e recupere resultados relevantes. A ferramenta suporta a personalização do número de resultados e buscas específicas por país.

## Instalação

Para incorporar esta ferramenta ao seu projeto, siga as instruções de instalação abaixo:

```shell
pip install 'crewai[tools]'
```

## Passos para Começar

Para utilizar o `BraveSearchTool` de forma eficaz, siga estes passos:

1. **Instalação do Pacote**: Confirme que o pacote `crewai[tools]` está instalado no seu ambiente Python.
2. **Obtenção da Chave de API**: Obtenha uma chave de API do Brave Search registrando-se em [Brave Search API](https://api.search.brave.com/app/keys).
3. **Configuração do Ambiente**: Armazene a chave de API obtida em uma variável de ambiente chamada `BRAVE_API_KEY` para facilitar seu uso pela ferramenta.

## Exemplo

O exemplo a seguir demonstra como inicializar a ferramenta e executar uma busca com uma determinada consulta:

```python Code
from crewai_tools import BraveSearchTool

# Inicialize a ferramenta para capacidades de busca na internet
tool = BraveSearchTool()

# Execute uma busca
results = tool.run(search_query="CrewAI agent framework")
print(results)
```

## Parâmetros

O `BraveSearchTool` aceita os seguintes parâmetros:

* **search\_query**: Obrigatório. A consulta de pesquisa que você deseja usar para pesquisar na internet.
* **country**: Opcional. Especifique o país dos resultados da pesquisa. O padrão é string vazia.
* **n\_results**: Opcional. Número de resultados de pesquisa a serem retornados. O padrão é `10`.
* **save\_file**: Opcional. Se os resultados da pesquisa devem ser salvos em um arquivo. O padrão é `False`.

## Exemplo com Parâmetros

Veja um exemplo demonstrando como usar a ferramenta com parâmetros adicionais:

```python Code
from crewai_tools import BraveSearchTool

# Inicialize a ferramenta com parâmetros personalizados
tool = BraveSearchTool(
    country="US",
    n_results=5,
    save_file=True
)

# Execute uma busca
results = tool.run(search_query="Latest AI developments")
print(results)
```

## Exemplo de Integração com Agente

Veja como integrar o `BraveSearchTool` com um agente CrewAI:

```python Code
from crewai import Agent
from crewai.project import agent
from crewai_tools import BraveSearchTool

# Inicialize a ferramenta
brave_search_tool = BraveSearchTool()

# Defina um agente com o BraveSearchTool
@agent
def researcher(self) -> Agent:
    return Agent(
        config=self.agents_config["researcher"],
        allow_delegation=False,
        tools=[brave_search_tool]
    )
```

## Conclusão

Ao integrar o `BraveSearchTool` em projetos Python, os usuários ganham a capacidade de realizar buscas em tempo real e relevantes na internet diretamente de suas aplicações. A ferramenta oferece uma interface simples para a poderosa Brave Search API, facilitando a recuperação e o processamento programático dos resultados de pesquisa. Seguindo as orientações de configuração e uso fornecidas, a incorporação desta ferramenta em projetos é simplificada e direta.


# Pesquisa com RAG em Documentação de Código
Source: https://docs.crewai.com/pt-BR/tools/search-research/codedocssearchtool

O `CodeDocsSearchTool` é uma poderosa ferramenta RAG (Geração Aumentada por Recuperação) projetada para buscas semânticas em documentação de código.

# `CodeDocsSearchTool`

<Note>
  **Experimental**: Ainda estamos trabalhando para melhorar as ferramentas, então pode haver comportamentos inesperados ou mudanças no futuro.
</Note>

## Descrição

O CodeDocsSearchTool é uma poderosa ferramenta RAG (Geração Aumentada por Recuperação) projetada para buscas semânticas em documentação de código.
Ela permite que usuários encontrem de forma eficiente informações ou tópicos específicos dentro da documentação de código. Ao fornecer um `docs_url` durante a inicialização,
a ferramenta restringe a busca àquele site de documentação em particular. Alternativamente, sem um `docs_url` específico,
ela realiza buscas em uma ampla variedade de documentações de código conhecidas ou descobertas durante sua execução, tornando-a versátil para diversas necessidades de busca em documentação.

## Instalação

Para começar a usar o CodeDocsSearchTool, primeiro instale o pacote crewai\_tools via pip:

```shell
pip install 'crewai[tools]'
```

## Exemplo

Utilize o CodeDocsSearchTool conforme abaixo para realizar buscas em documentação de código:

```python Code
from crewai_tools import CodeDocsSearchTool

# Para buscar qualquer conteúdo de documentação de código
# se a URL for conhecida ou descoberta durante a execução:
tool = CodeDocsSearchTool()

# OU

# Para focar sua busca especificamente em um site de documentação
# fornecendo sua URL:
tool = CodeDocsSearchTool(docs_url='https://docs.example.com/reference')
```

<Note>
  Substitua '[https://docs.example.com/reference](https://docs.example.com/reference)' pela URL da documentação desejada
  e 'How to use search tool' pela consulta de busca relevante às suas necessidades.
</Note>

## Argumentos

Os seguintes parâmetros podem ser usados para personalizar o comportamento do `CodeDocsSearchTool`:

| Argumento     | Tipo     | Descrição                                                                |
| :------------ | :------- | :----------------------------------------------------------------------- |
| **docs\_url** | `string` | *Opcional*. Especifica a URL da documentação de código a ser pesquisada. |

## Modelo e embeddings personalizados

Por padrão, a ferramenta utiliza a OpenAI tanto para embeddings quanto para sumarização. Para customizar o modelo, você pode usar um dicionário de configuração conforme abaixo:

```python Code
tool = CodeDocsSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Carregador Web EXA Search
Source: https://docs.crewai.com/pt-BR/tools/search-research/exasearchtool

O `EXASearchTool` foi projetado para realizar uma busca semântica para uma consulta especificada a partir do conteúdo de um texto em toda a internet.

# `EXASearchTool`

## Descrição

O EXASearchTool foi projetado para realizar uma busca semântica para uma consulta especificada a partir do conteúdo de um texto em toda a internet.
Ele utiliza a API da [exa.ai](https://exa.ai/) para buscar e exibir os resultados de pesquisa mais relevantes com base na consulta fornecida pelo usuário.

## Instalação

Para incorporar esta ferramenta em seu projeto, siga as instruções de instalação abaixo:

```shell
pip install 'crewai[tools]'
```

## Exemplo

O exemplo a seguir demonstra como inicializar a ferramenta e executar uma busca com uma consulta determinada:

```python Code
from crewai_tools import EXASearchTool

# Initialize the tool for internet searching capabilities
tool = EXASearchTool()
```

## Etapas para Começar

Para usar o EXASearchTool de forma eficaz, siga estas etapas:

<Steps>
  <Step title="Instalação do Pacote">
    Confirme se o pacote `crewai[tools]` está instalado em seu ambiente Python.
  </Step>

  <Step title="Obtenção da Chave de API">
    Adquira uma chave de API da [exa.ai](https://exa.ai/) registrando-se gratuitamente em [exa.ai](https://exa.ai/).
  </Step>

  <Step title="Configuração de Ambiente">
    Armazene a chave de API obtida em uma variável de ambiente chamada `EXA_API_KEY` para facilitar o uso pela ferramenta.
  </Step>
</Steps>

## Conclusão

Ao integrar o `EXASearchTool` em projetos Python, os usuários ganham a capacidade de realizar buscas relevantes e em tempo real pela internet diretamente de suas aplicações.
Seguindo as orientações de configuração e uso fornecidas, a incorporação desta ferramenta em projetos torna-se simples e direta.


# Github Search
Source: https://docs.crewai.com/pt-BR/tools/search-research/githubsearchtool

O `GithubSearchTool` foi desenvolvido para pesquisar sites e convertê-los em markdown limpo ou dados estruturados.

# `GithubSearchTool`

<Note>
  Ainda estamos trabalhando para melhorar as ferramentas, portanto pode haver comportamentos inesperados ou mudanças no futuro.
</Note>

## Descrição

O GithubSearchTool é uma ferramenta de Recuperação Aprimorada por Geração (RAG) especificamente projetada para realizar buscas semânticas em repositórios GitHub. Utilizando funcionalidades avançadas de busca semântica, ele examina códigos, pull requests, issues e repositórios, tornando-se uma ferramenta essencial para desenvolvedores, pesquisadores ou qualquer pessoa que precise de informações precisas do GitHub.

## Instalação

Para usar o GithubSearchTool, primeiro certifique-se de que o pacote crewai\_tools está instalado em seu ambiente Python:

```shell
pip install 'crewai[tools]'
```

Esse comando instala o pacote necessário para rodar o GithubSearchTool juntamente com outras ferramentas incluídas no pacote crewai\_tools.

## Exemplo

Veja como você pode usar o GithubSearchTool para realizar buscas semânticas dentro de um repositório GitHub:

```python Code
from crewai_tools import GithubSearchTool

# Inicialize a ferramenta para buscas semânticas em um repositório GitHub específico
tool = GithubSearchTool(
	github_repo='https://github.com/example/repo',
	gh_token='your_github_personal_access_token',
	content_types=['code', 'issue'] # Opções: code, repo, pr, issue
)

# OU

# Inicialize a ferramenta para buscas semânticas em um repositório GitHub específico, permitindo que o agente pesquise em qualquer repositório caso tome conhecimento durante a execução
tool = GithubSearchTool(
	gh_token='your_github_personal_access_token',
	content_types=['code', 'issue'] # Opções: code, repo, pr, issue
)
```

## Argumentos

* `github_repo` : A URL do repositório GitHub onde a busca será realizada. Este é um campo obrigatório e especifica o repositório alvo para sua pesquisa.
* `gh_token` : Seu Personal Access Token (PAT) do GitHub necessário para autenticação. Você pode criar um nas configurações da sua conta GitHub em Developer Settings > Personal Access Tokens.
* `content_types` : Especifica os tipos de conteúdo a serem incluídos na busca. É necessário fornecer uma lista dos tipos de conteúdo das seguintes opções: `code` para pesquisar dentro do código,
  `repo` para pesquisar nas informações gerais do repositório, `pr` para pesquisar em pull requests, e `issue` para pesquisar nas issues.
  Este campo é obrigatório e permite adaptar a busca para tipos específicos de conteúdo dentro do repositório GitHub.

## Modelo e embeddings personalizados

Por padrão, a ferramenta utiliza o OpenAI tanto para embeddings quanto para sumarização. Para personalizar o modelo, você pode usar um dicionário de configuração como no exemplo:

```python Code
tool = GithubSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Linkup Search Tool
Source: https://docs.crewai.com/pt-BR/tools/search-research/linkupsearchtool

O `LinkupSearchTool` permite consultar a API do Linkup para obter informações contextuais.

# `LinkupSearchTool`

## Descrição

O `LinkupSearchTool` fornece a capacidade de consultar a API do Linkup para obter informações contextuais e recuperar resultados estruturados. Esta ferramenta é ideal para enriquecer fluxos de trabalho com informações atualizadas e confiáveis do Linkup, permitindo que agentes acessem dados relevantes durante a execução de suas tarefas.

## Instalação

Para utilizar esta ferramenta, é necessário instalar o Linkup SDK:

```shell
uv add linkup-sdk
```

## Passos para começar

Para usar efetivamente o `LinkupSearchTool`, siga estes passos:

1. **Chave de API**: Obtenha uma chave de API do Linkup.
2. **Configuração do Ambiente**: Configure seu ambiente com a chave de API.
3. **Instalar SDK**: Instale o Linkup SDK usando o comando acima.

## Exemplo

O exemplo a seguir demonstra como inicializar a ferramenta e usá-la em um agente:

```python Code
from crewai_tools import LinkupSearchTool
from crewai import Agent
import os

# Inicialize a ferramenta com sua chave de API
linkup_ferramenta = LinkupSearchTool(api_key=os.getenv("LINKUP_API_KEY"))

# Defina um agente que usa a ferramenta
@agent
def pesquisador(self) -> Agent:
    '''
    Este agente usa o LinkupSearchTool para recuperar informações contextuais
    da API do Linkup.
    '''
    return Agent(
        config=self.agentes_config["pesquisador"],
        tools=[linkup_ferramenta]
    )
```


# Visão Geral
Source: https://docs.crewai.com/pt-BR/tools/search-research/overview

Realize pesquisas na web, encontre repositórios e pesquise informações em toda a internet

Essas ferramentas permitem que seus agentes pesquisem na web, explorem tópicos e encontrem informações em diversas plataformas, incluindo motores de busca, GitHub e YouTube.

## **Ferramentas Disponíveis**

<CardGroup cols={2}>
  <Card title="Serper Dev Tool" icon="google" href="/pt-BR/tools/search-research/serperdevtool">
    Integração com a API de busca do Google para capacidades abrangentes de pesquisa na web.
  </Card>

  <Card title="Brave Search Tool" icon="shield" href="/pt-BR/tools/search-research/bravesearchtool">
    Pesquisa voltada para privacidade com o índice independente de busca do Brave.
  </Card>

  <Card title="Exa Search Tool" icon="magnifying-glass" href="/pt-BR/tools/search-research/exasearchtool">
    Pesquisa impulsionada por IA para encontrar conteúdo específico e relevante.
  </Card>

  <Card title="LinkUp Search Tool" icon="link" href="/pt-BR/tools/search-research/linkupsearchtool">
    Pesquisa em tempo real na web com indexação de conteúdo atualizado.
  </Card>

  <Card title="GitHub Search Tool" icon="github" href="/pt-BR/tools/search-research/githubsearchtool">
    Pesquise repositórios do GitHub, códigos, issues e documentação.
  </Card>

  <Card title="Website Search Tool" icon="globe" href="/pt-BR/tools/search-research/websitesearchtool">
    Pesquisa dentro de sites e domínios específicos.
  </Card>

  <Card title="Code Docs Search Tool" icon="code" href="/pt-BR/tools/search-research/codedocssearchtool">
    Pesquise em documentação de código e recursos técnicos.
  </Card>

  <Card title="YouTube Channel Search" icon="youtube" href="/pt-BR/tools/search-research/youtubechannelsearchtool">
    Pesquise canais do YouTube para encontrar conteúdos e criadores específicos.
  </Card>

  <Card title="YouTube Video Search" icon="play" href="/pt-BR/tools/search-research/youtubevideosearchtool">
    Encontre e analise vídeos do YouTube por assunto, palavra-chave ou critério.
  </Card>
</CardGroup>

## **Casos de Uso Comuns**

* **Pesquisa de Mercado**: Pesquise tendências de mercado e análise de concorrentes
* **Descoberta de Conteúdo**: Encontre artigos, vídeos e recursos relevantes
* **Pesquisa de Código**: Pesquise repositórios e documentação em busca de soluções
* **Geração de Leads**: Pesquise empresas e pessoas
* **Pesquisa Acadêmica**: Encontre artigos científicos e trabalhos técnicos

```python
from crewai_tools import SerperDevTool, GitHubSearchTool, YoutubeVideoSearchTool

# Create research tools
web_search = SerperDevTool()
code_search = GitHubSearchTool()
video_research = YoutubeVideoSearchTool()

# Add to your agent
agent = Agent(
    role="Research Analyst",
    tools=[web_search, code_search, video_research],
    goal="Gather comprehensive information on any topic"
)
```


# Pesquisa Serper Google
Source: https://docs.crewai.com/pt-BR/tools/search-research/serperdevtool

O `SerperDevTool` é projetado para pesquisar na internet e retornar os resultados mais relevantes.

# `SerperDevTool`

<Note>
  Ainda estamos trabalhando na melhoria das ferramentas, portanto, pode haver comportamentos inesperados ou mudanças no futuro.
</Note>

## Descrição

Esta ferramenta foi projetada para realizar buscas semânticas para uma consulta especificada a partir do conteúdo de um texto na internet. Ela utiliza a API do [serper.dev](https://serper.dev)
para buscar e exibir os resultados de pesquisa mais relevantes com base na consulta fornecida pelo usuário.

## Instalação

Para incorporar esta ferramenta em seu projeto, siga as instruções de instalação abaixo:

```shell
pip install 'crewai[tools]'
```

## Exemplo

O exemplo a seguir demonstra como inicializar a ferramenta e executar uma busca com uma consulta fornecida:

```python Code
from crewai_tools import SerperDevTool

# Inicializar a ferramenta para capacidades de busca na internet
tool = SerperDevTool()
```

## Etapas para Começar

Para utilizar o `SerperDevTool` de forma eficaz, siga estes passos:

1. **Instalação do Pacote**: Confirme se o pacote `crewai[tools]` está instalado em seu ambiente Python.
2. **Obtenção da Chave de API**: Adquira uma chave de API do `serper.dev` registrando-se para uma conta gratuita em `serper.dev`.
3. **Configuração do Ambiente**: Armazene sua chave de API obtida em uma variável de ambiente chamada `SERPER_API_KEY` para facilitar o uso pela ferramenta.

## Parâmetros

O `SerperDevTool` possui vários parâmetros que serão passados para a API:

* **search\_url**: O endpoint da URL para a API de busca. (Padrão é `https://google.serper.dev/search`)

* **country**: Opcional. Especifica o país para os resultados de busca.

* **location**: Opcional. Especifica a localização para os resultados de busca.

* **locale**: Opcional. Especifica o local para os resultados de busca.

* **n\_results**: Número de resultados de busca a serem retornados. O padrão é `10`.

Os valores para `country`, `location`, `locale` e `search_url` podem ser encontrados no [Serper Playground](https://serper.dev/playground).

## Exemplo com Parâmetros

Aqui está um exemplo demonstrando como usar a ferramenta com parâmetros adicionais:

```python Code
from crewai_tools import SerperDevTool

tool = SerperDevTool(
    search_url="https://google.serper.dev/scholar",
    n_results=2,
)

print(tool.run(search_query="ChatGPT"))

# Using Tool: Search the internet

# Search results: Title: Role of chat gpt in public health
# Link: https://link.springer.com/article/10.1007/s10439-023-03172-7
# Snippet: … ChatGPT in public health. In this overview, we will examine the potential uses of ChatGPT in
# ---
# Title: Potential use of chat gpt in global warming
# Link: https://link.springer.com/article/10.1007/s10439-023-03171-8
# Snippet: … as ChatGPT, have the potential to play a critical role in advancing our understanding of climate
# ---

```

```python Code
from crewai_tools import SerperDevTool

tool = SerperDevTool(
    country="fr",
    locale="fr",
    location="Paris, Paris, Ile-de-France, France",
    n_results=2,
)

print(tool.run(search_query="Jeux Olympiques"))

# Using Tool: Search the internet

# Search results: Title: Jeux Olympiques de Paris 2024 - Actualités, calendriers, résultats
# Link: https://olympics.com/fr/paris-2024
# Snippet: Quels sont les sports présents aux Jeux Olympiques de Paris 2024 ? · Athlétisme · Aviron · Badminton · Basketball · Basketball 3x3 · Boxe · Breaking · Canoë ...
# ---
# Title: Billetterie Officielle de Paris 2024 - Jeux Olympiques et Paralympiques
# Link: https://tickets.paris2024.org/
# Snippet: Achetez vos billets exclusivement sur le site officiel de la billetterie de Paris 2024 pour participer au plus grand événement sportif au monde.
# ---
```

## Conclusão

Ao integrar o `SerperDevTool` em projetos Python, os usuários obtêm a capacidade de realizar buscas em tempo real e relevantes na internet diretamente de suas aplicações.
Os parâmetros atualizados permitem resultados de busca mais personalizados e localizados. Seguindo as diretrizes de configuração e uso fornecidas, a incorporação desta ferramenta nos projetos é simplificada e direta.


# Pesquisa RAG em Sites
Source: https://docs.crewai.com/pt-BR/tools/search-research/websitesearchtool

O `WebsiteSearchTool` foi projetado para realizar uma busca RAG (Geração Aumentada por Recuperação) dentro do conteúdo de um site.

# `WebsiteSearchTool`

<Note>
  O WebsiteSearchTool está atualmente em fase experimental. Estamos trabalhando ativamente para incorporar esta ferramenta em nosso conjunto de ofertas e atualizaremos a documentação conforme necessário.
</Note>

## Descrição

O WebsiteSearchTool foi concebido como um conceito para realizar buscas semânticas dentro do conteúdo de sites.
Ele visa aproveitar modelos avançados de aprendizado de máquina, como a Geração Aumentada por Recuperação (RAG), para navegar e extrair informações de URLs especificadas de forma eficiente.
Esta ferramenta pretende oferecer flexibilidade, permitindo que usuários realizem buscas em qualquer site ou foquem em sites específicos de seu interesse.
Por favor, note que os detalhes da implementação atual do WebsiteSearchTool estão em desenvolvimento, e as funcionalidades aqui descritas podem ainda não estar acessíveis.

## Instalação

Para preparar seu ambiente para quando o WebsiteSearchTool estiver disponível, você pode instalar o pacote fundamental com:

```shell
pip install 'crewai[tools]'
```

Este comando instala as dependências necessárias para garantir que, assim que a ferramenta estiver totalmente integrada, os usuários possam começar a usá-la imediatamente.

## Exemplo de Uso

Abaixo estão exemplos de como o WebsiteSearchTool poderá ser utilizado em diferentes cenários. Por favor, observe que esses exemplos são ilustrativos e representam funcionalidades planejadas:

```python Code
from crewai_tools import WebsiteSearchTool

# Exemplo de inicialização da ferramenta que agentes podem usar
# para pesquisar em quaisquer sites descobertos
tool = WebsiteSearchTool()

# Exemplo de limitação da busca ao conteúdo de um site específico,
# assim os agentes podem buscar somente dentro desse site
tool = WebsiteSearchTool(website='https://example.com')
```

## Argumentos

* `website`: Um argumento opcional destinado a especificar a URL do site para buscas direcionadas. Este argumento foi projetado para aumentar a flexibilidade da ferramenta, permitindo buscas mais focadas quando necessário.

## Opções de Personalização

Por padrão, a ferramenta utiliza a OpenAI tanto para embeddings quanto para sumarização. Para personalizar o modelo, você pode usar um dicionário de configuração, conforme o exemplo abaixo:

```python Code
tool = WebsiteSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Busca RAG em Canal do YouTube
Source: https://docs.crewai.com/pt-BR/tools/search-research/youtubechannelsearchtool

O `YoutubeChannelSearchTool` foi desenvolvido para realizar buscas RAG (Retrieval-Augmented Generation) no conteúdo de um canal do Youtube.

# `YoutubeChannelSearchTool`

<Note>
  Ainda estamos trabalhando para melhorar as ferramentas, então pode haver comportamentos inesperados ou alterações no futuro.
</Note>

## Descrição

Esta ferramenta foi desenvolvida para realizar buscas semânticas dentro do conteúdo de um canal específico do Youtube.
Aproveitando a metodologia RAG (Retrieval-Augmented Generation), ela fornece resultados de busca relevantes,
tornando-se indispensável para extrair informações ou encontrar conteúdos específicos sem a necessidade de percorrer manualmente os vídeos.
Ela otimiza o processo de busca em canais do Youtube, sendo ideal para pesquisadores, criadores de conteúdo e espectadores que buscam informações ou temas específicos.

## Instalação

Para utilizar o YoutubeChannelSearchTool, é necessário instalar o pacote `crewai_tools`. Execute o seguinte comando no seu terminal para instalar:

```shell
pip install 'crewai[tools]'
```

## Exemplo

O exemplo a seguir demonstra como utilizar o `YoutubeChannelSearchTool` com um agente CrewAI:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import YoutubeChannelSearchTool

# Inicializa a ferramenta para buscas gerais em canais do YouTube
youtube_channel_tool = YoutubeChannelSearchTool()

# Define um agente que utiliza a ferramenta
channel_researcher = Agent(
    role="Channel Researcher",
    goal="Extrair informações relevantes de canais do YouTube",
    backstory="Um pesquisador especialista em analisar conteúdos de canais do YouTube.",
    tools=[youtube_channel_tool],
    verbose=True,
)

# Exemplo de tarefa para buscar informações em um canal específico
research_task = Task(
    description="Buscar informações sobre tutoriais de machine learning no canal do YouTube {youtube_channel_handle}",
    expected_output="Um resumo dos principais tutoriais de machine learning disponíveis no canal.",
    agent=channel_researcher,
)

# Cria e executa o crew
crew = Crew(agents=[channel_researcher], tasks=[research_task])
result = crew.kickoff(inputs={"youtube_channel_handle": "@exampleChannel"})
```

Você também pode inicializar a ferramenta com um handle específico de canal do YouTube:

```python Code
# Inicializa a ferramenta com o handle específico de um canal do YouTube
youtube_channel_tool = YoutubeChannelSearchTool(
    youtube_channel_handle='@exampleChannel'
)

# Define um agente que utiliza a ferramenta
channel_researcher = Agent(
    role="Channel Researcher",
    goal="Extrair informações relevantes de um canal específico do YouTube",
    backstory="Um pesquisador especialista em analisar conteúdos de canais do YouTube.",
    tools=[youtube_channel_tool],
    verbose=True,
)
```

## Parâmetros

O `YoutubeChannelSearchTool` aceita os seguintes parâmetros:

* **youtube\_channel\_handle**: Opcional. O handle do canal do YouTube para realizar a busca. Se fornecido durante a inicialização, o agente não precisará informá-lo ao utilizar a ferramenta. Se o handle não começar com '@', será adicionado automaticamente.
* **config**: Opcional. Configurações para o sistema RAG subjacente, incluindo parâmetros de LLM e embedder.
* **summarize**: Opcional. Indica se o conteúdo recuperado deve ser resumido. O padrão é `False`.

Ao utilizar a ferramenta com um agente, o agente deverá fornecer:

* **search\_query**: Obrigatório. A consulta de busca para encontrar informações relevantes no conteúdo do canal.
* **youtube\_channel\_handle**: Obrigatório apenas se não for fornecido durante a inicialização. O handle do canal do YouTube onde realizar a busca.

## Modelo Personalizado e Embeddings

Por padrão, a ferramenta utiliza o OpenAI tanto para embeddings quanto para sumarização. Para personalizar o modelo, é possível usar um dicionário de configuração como no exemplo:

```python Code
youtube_channel_tool = YoutubeChannelSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```

## Exemplo de Integração com Agente

Veja um exemplo mais detalhado de como integrar o `YoutubeChannelSearchTool` com um agente CrewAI:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import YoutubeChannelSearchTool

# Inicializa a ferramenta
youtube_channel_tool = YoutubeChannelSearchTool()

# Define um agente que utiliza a ferramenta
channel_researcher = Agent(
    role="Channel Researcher",
    goal="Extrair e analisar informações de canais do YouTube",
    backstory="""Você é um pesquisador especialista em canais, com experiência
    em extrair e analisar informações de canais do YouTube. Você possui olho clínico para detalhes
    e pode rapidamente identificar pontos-chave e insights a partir do conteúdo em vídeo de todo o canal.""",
    tools=[youtube_channel_tool],
    verbose=True,
)

# Crie uma tarefa para o agente
research_task = Task(
    description="""
    Buscar informações sobre projetos e tutoriais de ciência de dados
    no canal do YouTube {youtube_channel_handle}.

    Foque em:
    1. Principais técnicas de ciência de dados abordadas
    2. Séries de tutoriais populares
    3. Vídeos mais vistos ou recomendados

    Forneça um resumo abrangente sobre esses pontos.
    """,
    expected_output="Um resumo detalhado sobre o conteúdo de ciência de dados disponível no canal.",
    agent=channel_researcher,
)

# Execute a tarefa
crew = Crew(agents=[channel_researcher], tasks=[research_task])
result = crew.kickoff(inputs={"youtube_channel_handle": "@exampleDataScienceChannel"})
```

## Detalhes da Implementação

O `YoutubeChannelSearchTool` é implementado como uma subclasse de `RagTool`, que fornece a funcionalidade base para Retrieval-Augmented Generation:

```python Code
class YoutubeChannelSearchTool(RagTool):
    name: str = "Search a Youtube Channels content"
    description: str = "A tool that can be used to semantic search a query from a Youtube Channels content."
    args_schema: Type[BaseModel] = YoutubeChannelSearchToolSchema

    def __init__(self, youtube_channel_handle: Optional[str] = None, **kwargs):
        super().__init__(**kwargs)
        if youtube_channel_handle is not None:
            kwargs["data_type"] = DataType.YOUTUBE_CHANNEL
            self.add(youtube_channel_handle)
            self.description = f"A tool that can be used to semantic search a query the {youtube_channel_handle} Youtube Channels content."
            self.args_schema = FixedYoutubeChannelSearchToolSchema
            self._generate_description()

    def add(
        self,
        youtube_channel_handle: str,
        **kwargs: Any,
    ) -> None:
        if not youtube_channel_handle.startswith("@"):
            youtube_channel_handle = f"@{youtube_channel_handle}"
        super().add(youtube_channel_handle, **kwargs)
```

## Conclusão

O `YoutubeChannelSearchTool` oferece uma forma poderosa de buscar e extrair informações do conteúdo de canais do YouTube utilizando técnicas RAG. Ao possibilitar que agentes busquem entre todos os vídeos de um canal, facilita tarefas de extração e análise de informações que seriam difíceis de executar manualmente. Esta ferramenta é especialmente útil para pesquisa, análise de conteúdo e extração de conhecimento de canais do YouTube.


# Pesquisa RAG em Vídeos do YouTube
Source: https://docs.crewai.com/pt-BR/tools/search-research/youtubevideosearchtool

O `YoutubeVideoSearchTool` foi projetado para realizar uma busca RAG (Geração Auxiliada por Recuperação) no conteúdo de um vídeo do Youtube.

# `YoutubeVideoSearchTool`

<Note>
  Ainda estamos trabalhando para melhorar as ferramentas, portanto podem ocorrer comportamentos inesperados ou mudanças no futuro.
</Note>

## Descrição

Esta ferramenta faz parte do pacote `crewai_tools` e foi projetada para realizar buscas semânticas dentro do conteúdo de vídeos do Youtube, utilizando técnicas de Geração Auxiliada por Recuperação (RAG).
É uma das diversas ferramentas de "Pesquisa" do pacote que aproveitam RAG para diferentes fontes.
O YoutubeVideoSearchTool permite flexibilidade nas buscas: usuários podem pesquisar em qualquer conteúdo de vídeo do Youtube sem especificar uma URL,
ou podem direcionar sua busca para um vídeo específico fornecendo sua URL.

## Instalação

Para utilizar o `YoutubeVideoSearchTool`, é necessário primeiro instalar o pacote `crewai_tools`.
Esse pacote contém o `YoutubeVideoSearchTool` entre outras utilidades desenvolvidas para melhorar suas tarefas de análise e processamento de dados.
Instale o pacote executando o seguinte comando em seu terminal:

```shell
pip install 'crewai[tools]'
```

## Exemplo

O exemplo a seguir demonstra como usar o `YoutubeVideoSearchTool` com um agente CrewAI:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import YoutubeVideoSearchTool

# Inicialize a ferramenta para buscas gerais em vídeos do YouTube
youtube_search_tool = YoutubeVideoSearchTool()

# Defina um agente que usa a ferramenta
video_researcher = Agent(
    role="Video Researcher",
    goal="Extract relevant information from YouTube videos",
    backstory="An expert researcher who specializes in analyzing video content.",
    tools=[youtube_search_tool],
    verbose=True,
)

# Exemplo de tarefa para buscar informações em um vídeo específico
research_task = Task(
    description="Search for information about machine learning frameworks in the YouTube video at {youtube_video_url}",
    expected_output="A summary of the key machine learning frameworks mentioned in the video.",
    agent=video_researcher,
)

# Crie e execute a crew
crew = Crew(agents=[video_researcher], tasks=[research_task])
result = crew.kickoff(inputs={"youtube_video_url": "https://youtube.com/watch?v=example"})
```

Você também pode inicializar a ferramenta com a URL de um vídeo específico do YouTube:

```python Code
# Inicialize a ferramenta com a URL de um vídeo específico do YouTube
youtube_search_tool = YoutubeVideoSearchTool(
    youtube_video_url='https://youtube.com/watch?v=example'
)

# Defina um agente que usa a ferramenta
video_researcher = Agent(
    role="Video Researcher",
    goal="Extract relevant information from a specific YouTube video",
    backstory="An expert researcher who specializes in analyzing video content.",
    tools=[youtube_search_tool],
    verbose=True,
)
```

## Parâmetros

O `YoutubeVideoSearchTool` aceita os seguintes parâmetros:

* **youtube\_video\_url**: Opcional. A URL do vídeo do YouTube para pesquisa. Se fornecida durante a inicialização, o agente não precisará especificar ao utilizar a ferramenta.
* **config**: Opcional. Configuração para o sistema RAG subjacente, incluindo definições de LLM e embedder.
* **summarize**: Opcional. Indica se o conteúdo recuperado deve ser resumido. O padrão é `False`.

Ao usar a ferramenta com um agente, é necessário fornecer:

* **search\_query**: Obrigatório. A consulta de busca para encontrar informações relevantes no conteúdo do vídeo.
* **youtube\_video\_url**: Obrigatório somente se não for fornecida na inicialização. A URL do vídeo do YouTube a ser pesquisado.

## Modelo e Embeddings Personalizados

Por padrão, a ferramenta utiliza OpenAI tanto para embeddings quanto para sumarização. Para personalizar o modelo, utilize um dicionário de configuração conforme exemplo:

```python Code
youtube_search_tool = YoutubeVideoSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```

## Exemplo de Integração com Agente

Aqui está um exemplo mais detalhado de como integrar o `YoutubeVideoSearchTool` com um agente CrewAI:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import YoutubeVideoSearchTool

# Inicialize a ferramenta
youtube_search_tool = YoutubeVideoSearchTool()

# Defina um agente que usa a ferramenta
video_researcher = Agent(
    role="Video Researcher",
    goal="Extract and analyze information from YouTube videos",
    backstory="""You are an expert video researcher who specializes in extracting
    and analyzing information from YouTube videos. You have a keen eye for detail
    and can quickly identify key points and insights from video content.""",
    tools=[youtube_search_tool],
    verbose=True,
)

# Crie uma tarefa para o agente
research_task = Task(
    description="""
    Search for information about recent advancements in artificial intelligence
    in the YouTube video at {youtube_video_url}.

    Focus on:
    1. Key AI technologies mentioned
    2. Real-world applications discussed
    3. Future predictions made by the speaker

    Provide a comprehensive summary of these points.
    """,
    expected_output="A detailed summary of AI advancements, applications, and future predictions from the video.",
    agent=video_researcher,
)

# Execute a tarefa
crew = Crew(agents=[video_researcher], tasks=[research_task])
result = crew.kickoff(inputs={"youtube_video_url": "https://youtube.com/watch?v=example"})
```

## Detalhes de Implementação

O `YoutubeVideoSearchTool` é implementado como uma subclasse de `RagTool`, que fornece a funcionalidade base para Geração Auxiliada por Recuperação:

```python Code
class YoutubeVideoSearchTool(RagTool):
    name: str = "Search a Youtube Video content"
    description: str = "A tool that can be used to semantic search a query from a Youtube Video content."
    args_schema: Type[BaseModel] = YoutubeVideoSearchToolSchema

    def __init__(self, youtube_video_url: Optional[str] = None, **kwargs):
        super().__init__(**kwargs)
        if youtube_video_url is not None:
            kwargs["data_type"] = DataType.YOUTUBE_VIDEO
            self.add(youtube_video_url)
            self.description = f"A tool that can be used to semantic search a query the {youtube_video_url} Youtube Video content."
            self.args_schema = FixedYoutubeVideoSearchToolSchema
            self._generate_description()
```

## Conclusão

O `YoutubeVideoSearchTool` oferece uma maneira poderosa de pesquisar e extrair informações de conteúdos de vídeos do YouTube utilizando técnicas RAG. Ao possibilitar que agentes pesquisem dentro do conteúdo dos vídeos, facilita tarefas de extração e análise de informação que anteriormente seriam difíceis de realizar. Esta ferramenta é especialmente útil para pesquisas, análise de conteúdo e extração de conhecimento a partir de fontes em vídeo.


# Carregador Web Browserbase
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/browserbaseloadtool

O Browserbase é uma plataforma para desenvolvedores para executar, gerenciar e monitorar navegadores headless de forma confiável.

# `BrowserbaseLoadTool`

## Descrição

[Browserbase](https://browserbase.com) é uma plataforma para desenvolvedores que permite executar, gerenciar e monitorar navegadores headless de forma confiável.

Potencialize suas buscas de dados para IA com:

* [Infraestrutura Serverless](https://docs.browserbase.com/under-the-hood) fornecendo navegadores confiáveis para extrair dados de interfaces complexas
* [Modo Stealth](https://docs.browserbase.com/features/stealth-mode) com táticas de fingerprinting e resolução automática de captcha incluídas
* [Depurador de Sessão](https://docs.browserbase.com/features/sessions) para inspecionar sua Sessão do Navegador com linha do tempo de rede e logs
* [Depuração Ao Vivo](https://docs.browserbase.com/guides/session-debug-connection/browser-remote-control) para depurar rapidamente sua automação

## Instalação

* Obtenha uma chave de API e o Project ID em [browserbase.com](https://browserbase.com) e defina-os nas variáveis de ambiente (`BROWSERBASE_API_KEY`, `BROWSERBASE_PROJECT_ID`).
* Instale o [SDK do Browserbase](http://github.com/browserbase/python-sdk) juntamente com o pacote `crewai[tools]`:

```shell
pip install browserbase 'crewai[tools]'
```

## Exemplo

Utilize o BrowserbaseLoadTool conforme abaixo para permitir que seu agente carregue sites:

```python Code
from crewai_tools import BrowserbaseLoadTool

# Inicialize a ferramenta com a chave da API do Browserbase e o Project ID
tool = BrowserbaseLoadTool()
```

## Argumentos

Os parâmetros a seguir podem ser usados para customizar o comportamento do `BrowserbaseLoadTool`:

| Argumento         | Tipo     | Descrição                                                                                        |
| :---------------- | :------- | :----------------------------------------------------------------------------------------------- |
| **api\_key**      | `string` | *Opcional*. Chave de API do Browserbase. Padrão é a variável de ambiente `BROWSERBASE_API_KEY`.  |
| **project\_id**   | `string` | *Opcional*. Project ID do Browserbase. Padrão é a variável de ambiente `BROWSERBASE_PROJECT_ID`. |
| **text\_content** | `bool`   | *Opcional*. Recuperar somente o conteúdo em texto. O padrão é `False`.                           |
| **session\_id**   | `string` | *Opcional*. Forneça um Session ID existente.                                                     |
| **proxy**         | `bool`   | *Opcional*. Habilitar/Desabilitar proxies. O padrão é `False`.                                   |


# Firecrawl Crawl Website
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/firecrawlcrawlwebsitetool

O `FirecrawlCrawlWebsiteTool` foi projetado para rastrear e converter sites em markdown limpo ou dados estruturados.

# `FirecrawlCrawlWebsiteTool`

## Descrição

[Firecrawl](https://firecrawl.dev) é uma plataforma para rastrear e converter qualquer site em markdown limpo ou dados estruturados.

## Instalação

* Obtenha uma chave de API em [firecrawl.dev](https://firecrawl.dev) e defina-a nas variáveis de ambiente (`FIRECRAWL_API_KEY`).
* Instale o [SDK do Firecrawl](https://github.com/mendableai/firecrawl) junto com o pacote `crewai[tools]`:

```shell
pip install firecrawl-py 'crewai[tools]'
```

## Exemplo

Utilize o FirecrawlScrapeFromWebsiteTool como a seguir para permitir que seu agente carregue sites:

```python Code
from crewai_tools import FirecrawlCrawlWebsiteTool

tool = FirecrawlCrawlWebsiteTool(url='firecrawl.dev')
```

## Argumentos

* `api_key`: Opcional. Especifica a chave de API do Firecrawl. Por padrão, utiliza a variável de ambiente `FIRECRAWL_API_KEY`.
* `url`: A URL base para iniciar o rastreamento.
* `page_options`: Opcional.
  * `onlyMainContent`: Opcional. Retorna apenas o conteúdo principal da página, excluindo cabeçalhos, navegações, rodapés, etc.
  * `includeHtml`: Opcional. Inclui o conteúdo HTML bruto da página. Vai adicionar uma chave html na resposta.
* `crawler_options`: Opcional. Opções para controlar o comportamento do rastreamento.
  * `includes`: Opcional. Padrões de URL para incluir no rastreamento.
  * `exclude`: Opcional. Padrões de URL para excluir do rastreamento.
  * `generateImgAltText`: Opcional. Gera texto alternativo para imagens usando LLMs (requer um plano pago).
  * `returnOnlyUrls`: Opcional. Se verdadeiro, retorna apenas as URLs como uma lista no status do rastreamento. Nota: a resposta será uma lista de URLs dentro do campo data, não uma lista de documentos.
  * `maxDepth`: Opcional. Profundidade máxima de rastreamento. Profundidade 1 é a URL base, profundidade 2 inclui a URL base e seus filhos diretos, e assim por diante.
  * `mode`: Opcional. O modo de rastreamento a ser utilizado. O modo rápido rastreia 4x mais rápido em sites sem sitemap, mas pode não ser tão preciso e não deve ser usado em sites fortemente renderizados com JavaScript.
  * `limit`: Opcional. Número máximo de páginas a serem rastreadas.
  * `timeout`: Opcional. Tempo limite em milissegundos para a operação de rastreamento.


# Firecrawl Scrape Website
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/firecrawlscrapewebsitetool

A ferramenta `FirecrawlScrapeWebsiteTool` foi projetada para fazer scraping de sites e convertê-los em markdown limpo ou dados estruturados.

# `FirecrawlScrapeWebsiteTool`

## Descrição

[Firecrawl](https://firecrawl.dev) é uma plataforma para rastrear e converter qualquer site em markdown limpo ou dados estruturados.

## Instalação

* Obtenha uma chave de API em [firecrawl.dev](https://firecrawl.dev) e defina-a nas variáveis de ambiente (`FIRECRAWL_API_KEY`).
* Instale o [Firecrawl SDK](https://github.com/mendableai/firecrawl) junto com o pacote `crewai[tools]`:

```shell
pip install firecrawl-py 'crewai[tools]'
```

## Exemplo

Utilize o FirecrawlScrapeWebsiteTool da seguinte forma para permitir que seu agente carregue sites:

```python Code
from crewai_tools import FirecrawlScrapeWebsiteTool

tool = FirecrawlScrapeWebsiteTool(url='firecrawl.dev')
```

## Argumentos

* `api_key`: Opcional. Especifica a chave de API do Firecrawl. O padrão é a variável de ambiente `FIRECRAWL_API_KEY`.
* `url`: A URL a ser raspada.
* `page_options`: Opcional.
  * `onlyMainContent`: Opcional. Retorna apenas o conteúdo principal da página, excluindo cabeçalhos, navegações, rodapés, etc.
  * `includeHtml`: Opcional. Inclui o conteúdo HTML bruto da página. Irá gerar uma chave html na resposta.
* `extractor_options`: Opcional. Opções para extração baseada em LLM de informações estruturadas do conteúdo da página
  * `mode`: O modo de extração a ser utilizado, atualmente suporta 'llm-extraction'
  * `extractionPrompt`: Opcional. Um prompt descrevendo quais informações extrair da página
  * `extractionSchema`: Opcional. O esquema para os dados a serem extraídos
* `timeout`: Opcional. Timeout em milissegundos para a requisição


# Firecrawl Search
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/firecrawlsearchtool

O `FirecrawlSearchTool` foi projetado para pesquisar sites e convertê-los em markdown limpo ou dados estruturados.

# `FirecrawlSearchTool`

## Descrição

[Firecrawl](https://firecrawl.dev) é uma plataforma para rastrear e converter qualquer site em markdown limpo ou dados estruturados.

## Instalação

* Obtenha uma chave de API em [firecrawl.dev](https://firecrawl.dev) e defina-a nas variáveis de ambiente (`FIRECRAWL_API_KEY`).
* Instale o [Firecrawl SDK](https://github.com/mendableai/firecrawl) junto com o pacote `crewai[tools]`:

```shell
pip install firecrawl-py 'crewai[tools]'
```

## Exemplo

Utilize o FirecrawlSearchTool da seguinte forma para permitir que seu agente carregue sites:

```python Code
from crewai_tools import FirecrawlSearchTool

tool = FirecrawlSearchTool(query='what is firecrawl?')
```

## Argumentos

* `api_key`: Opcional. Especifica a chave de API do Firecrawl. O padrão é a variável de ambiente `FIRECRAWL_API_KEY`.
* `query`: A string da consulta de busca a ser utilizada na pesquisa.
* `page_options`: Opcional. Opções para formatação dos resultados.
  * `onlyMainContent`: Opcional. Retorna somente o conteúdo principal da página, excluindo cabeçalhos, navegações, rodapés, etc.
  * `includeHtml`: Opcional. Inclui o conteúdo HTML bruto da página. Vai gerar uma chave html na resposta.
  * `fetchPageContent`: Opcional. Busca o conteúdo completo da página.
* `search_options`: Opcional. Opções para controle do comportamento de rastreamento.
  * `limit`: Opcional. Número máximo de páginas a rastrear.


# Hyperbrowser Load Tool
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/hyperbrowserloadtool

O `HyperbrowserLoadTool` permite realizar web scraping e crawling utilizando o Hyperbrowser.

# `HyperbrowserLoadTool`

## Descrição

O `HyperbrowserLoadTool` permite realizar web scraping e crawling utilizando o [Hyperbrowser](https://hyperbrowser.ai), uma plataforma para executar e escalar browsers headless. Essa ferramenta possibilita extrair dados de uma única página ou rastrear um site inteiro, retornando o conteúdo em markdown ou HTML corretamente formatado.

Principais Características:

* Escalabilidade Instantânea – Inicie centenas de sessões de browser em segundos sem se preocupar com infraestrutura
* Integração Simples – Funciona perfeitamente com ferramentas populares como Puppeteer e Playwright
* APIs Poderosas – APIs fáceis de usar para scraping/crawling de qualquer site
* Supera Medidas Anti-Bot – Inclui modo stealth, bloqueio de anúncios, resolução automática de CAPTCHA e proxies rotativos

## Instalação

Para utilizar esta ferramenta, você precisa instalar o SDK do Hyperbrowser:

```shell
uv add hyperbrowser
```

## Passos para Começar

Para usar efetivamente o `HyperbrowserLoadTool`, siga estes passos:

1. **Cadastre-se**: Vá até o [Hyperbrowser](https://app.hyperbrowser.ai/) para criar uma conta e gerar uma chave de API.
2. **Chave de API**: Defina a variável de ambiente `HYPERBROWSER_API_KEY` ou passe-a diretamente no construtor da ferramenta.
3. **Instale o SDK**: Instale o SDK do Hyperbrowser usando o comando acima.

## Exemplo

O exemplo a seguir demonstra como inicializar a ferramenta e utilizá-la para extrair dados de um site:

```python Code
from crewai_tools import HyperbrowserLoadTool
from crewai import Agent

# Initialize the tool with your API key
tool = HyperbrowserLoadTool(api_key="your_api_key")  # Or use environment variable

# Define an agent that uses the tool
@agent
def web_researcher(self) -> Agent:
    '''
    This agent uses the HyperbrowserLoadTool to scrape websites
    and extract information.
    '''
    return Agent(
        config=self.agents_config["web_researcher"],
        tools=[tool]
    )
```

## Parâmetros

O `HyperbrowserLoadTool` aceita os seguintes parâmetros:

### Parâmetros do Construtor

* **api\_key**: Opcional. Sua chave de API do Hyperbrowser. Se não fornecida, será lida da variável de ambiente `HYPERBROWSER_API_KEY`.

### Parâmetros de Execução

* **url**: Obrigatório. A URL do site a ser extraído ou rastreado.
* **operation**: Opcional. A operação a ser realizada no site. Pode ser 'scrape' ou 'crawl'. O padrão é 'scrape'.
* **params**: Opcional. Parâmetros adicionais para a operação de scraping ou crawling.

## Parâmetros Suportados

Para informações detalhadas sobre todos os parâmetros suportados, acesse:

* [Parâmetros de Scrape](https://docs.hyperbrowser.ai/reference/sdks/python/scrape#start-scrape-job-and-wait)
* [Parâmetros de Crawl](https://docs.hyperbrowser.ai/reference/sdks/python/crawl#start-crawl-job-and-wait)

## Formato de Retorno

A ferramenta retorna o conteúdo nos seguintes formatos:

* Para operações **scrape**: O conteúdo da página no formato markdown ou HTML.
* Para operações **crawl**: O conteúdo de cada página separado por divisores, incluindo a URL de cada página.

## Conclusão

O `HyperbrowserLoadTool` oferece uma maneira poderosa de realizar scraping e crawling em sites, lidando com cenários complexos como medidas anti-bot, CAPTCHAs e muito mais. Aproveitando a plataforma do Hyperbrowser, essa ferramenta permite que agentes acessem e extraiam conteúdo da web de forma eficiente.


# Visão Geral
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/overview

Extraia dados de websites e automatize interações com o navegador utilizando poderosas ferramentas de scraping

Essas ferramentas permitem que seus agentes interajam com a web, extraiam dados de websites e automatizem tarefas baseadas em navegador. De raspagem simples a automação complexa de navegador, essas ferramentas cobrem todas as suas necessidades de interação com a web.

## **Ferramentas Disponíveis**

<CardGroup cols={2}>
  <Card title="Ferramenta de Scrape de Website" icon="globe" href="/pt-BR/tools/web-scraping/scrapewebsitetool">
    Ferramenta de raspagem de uso geral para extrair conteúdo de qualquer site.
  </Card>

  <Card title="Ferramenta de Scrape de Elemento" icon="crosshairs" href="/pt-BR/tools/web-scraping/scrapeelementfromwebsitetool">
    Extraia elementos específicos de páginas web com capacidades de raspagem precisa.
  </Card>

  <Card title="Ferramenta Firecrawl Crawl" icon="spider" href="/pt-BR/tools/web-scraping/firecrawlcrawlwebsitetool">
    Rastreie sites inteiros de forma sistemática com o poderoso mecanismo do Firecrawl.
  </Card>

  <Card title="Ferramenta Firecrawl Scrape" icon="fire" href="/pt-BR/tools/web-scraping/firecrawlscrapewebsitetool">
    Raspagem web de alta performance com as capacidades avançadas do Firecrawl.
  </Card>

  <Card title="Ferramenta Firecrawl Search" icon="magnifying-glass" href="/pt-BR/tools/web-scraping/firecrawlsearchtool">
    Pesquise e extraia conteúdos específicos utilizando os recursos de busca do Firecrawl.
  </Card>

  <Card title="Ferramenta Selenium Scraping" icon="robot" href="/pt-BR/tools/web-scraping/seleniumscrapingtool">
    Automação de navegador e scraping com as capacidades do Selenium WebDriver.
  </Card>

  <Card title="Ferramenta ScrapFly" icon="plane" href="/pt-BR/tools/web-scraping/scrapflyscrapetool">
    Raspagem profissional de web com o serviço premium do ScrapFly.
  </Card>

  <Card title="Ferramenta ScrapGraph" icon="network-wired" href="/pt-BR/tools/web-scraping/scrapegraphscrapetool">
    Raspagem baseada em grafos para relacionamentos de dados complexos.
  </Card>

  <Card title="Ferramenta Spider" icon="spider" href="/pt-BR/tools/web-scraping/spidertool">
    Rastreio abrangente de sites e capacidades de extração de dados.
  </Card>

  <Card title="Ferramenta BrowserBase" icon="browser" href="/pt-BR/tools/web-scraping/browserbaseloadtool">
    Automação de navegador baseada em nuvem com a infraestrutura do BrowserBase.
  </Card>

  <Card title="Ferramenta HyperBrowser" icon="window-maximize" href="/pt-BR/tools/web-scraping/hyperbrowserloadtool">
    Interações rápidas com o navegador através do engine otimizado do HyperBrowser.
  </Card>

  <Card title="Ferramenta Stagehand" icon="hand" href="/pt-BR/tools/web-scraping/stagehandtool">
    Automação inteligente de navegador com comandos em linguagem natural.
  </Card>

  <Card title="Ferramenta Oxylabs Scraper" icon="globe" href="/pt-BR/tools/web-scraping/oxylabsscraperstool">
    Acesse dados web em escala com o Oxylabs.
  </Card>
</CardGroup>

## **Casos de Uso Comuns**

* **Extração de Dados**: Raspagem de informações de produtos, preços e avaliações
* **Monitoramento de Conteúdo**: Acompanhe mudanças em sites e fontes de notícias
* **Geração de Leads**: Extraia informações de contato e dados de empresas
* **Pesquisa de Mercado**: Coleta de inteligência competitiva e dados de mercado
* **Testes & QA**: Automatize fluxos de teste e validação em navegadores
* **Mídias Sociais**: Extraia posts, comentários e análises de redes sociais

## **Exemplo de Início Rápido**

```python
from crewai_tools import ScrapeWebsiteTool, FirecrawlScrapeWebsiteTool, SeleniumScrapingTool

# Create scraping tools
simple_scraper = ScrapeWebsiteTool()
advanced_scraper = FirecrawlScrapeWebsiteTool()
browser_automation = SeleniumScrapingTool()

# Add to your agent
agent = Agent(
    role="Web Research Specialist",
    tools=[simple_scraper, advanced_scraper, browser_automation],
    goal="Extract and analyze web data efficiently"
)
```

## **Boas Práticas de Scraping**

* **Respeite o robots.txt**: Sempre verifique e siga as políticas de scraping do website
* **Controle de Taxa (Rate Limiting)**: Implemente atrasos entre as requisições para evitar sobrecarregar servidores
* **User Agents**: Use strings de user agent apropriadas para identificar o seu bot
* **Conformidade Legal**: Certifique-se de que suas atividades de scraping estejam em conformidade com os termos de serviço
* **Tratamento de Erros**: Implemente um tratamento de erros robusto para problemas de rede e requisições bloqueadas
* **Qualidade dos Dados**: Valide e limpe os dados extraídos antes de processar

## **Guia de Seleção de Ferramentas**

* **Tarefas Simples**: Use `ScrapeWebsiteTool` para extração básica de conteúdo
* **Sites Dinâmicos com JavaScript**: Use `SeleniumScrapingTool` para conteúdo dinâmico
* **Escala & Performance**: Use `FirecrawlScrapeWebsiteTool` para scraping em grande volume
* **Infraestrutura em Nuvem**: Use `BrowserBaseLoadTool` para automação de navegador escalável
* **Fluxos Complexos**: Use `StagehandTool` para interações inteligentes com o navegador


# Oxylabs Scrapers
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/oxylabsscraperstool

Os Scrapers da Oxylabs permitem acessar facilmente informações de fontes específicas. Veja abaixo a lista de fontes disponíveis:
  - `Amazon Product`
  - `Amazon Search`
  - `Google Seach`
  - `Universal`


## Instalação

Obtenha as credenciais criando uma conta na Oxylabs [aqui](https://oxylabs.io).

```shell
pip install 'crewai[tools]' oxylabs
```

Confira a [Documentação da Oxylabs](https://developers.oxylabs.io/scraping-solutions/web-scraper-api/targets) para mais informações sobre os parâmetros da API.

# `OxylabsAmazonProductScraperTool`

### Exemplo

```python
from crewai_tools import OxylabsAmazonProductScraperTool

# certifique-se de que as variáveis OXYLABS_USERNAME e OXYLABS_PASSWORD estejam definidas
tool = OxylabsAmazonProductScraperTool()

result = tool.run(query="AAAAABBBBCC")

print(result)
```

### Parâmetros

* `query` - código ASIN de 10 caracteres.
* `domain` - domínio de localização da Amazon.
* `geo_location` - local de entrega (*Deliver to*).
* `user_agent_type` - tipo de dispositivo e navegador.
* `render` - ativa o renderizador JavaScript ao definir como `html`.
* `callback_url` - URL do seu endpoint de callback.
* `context` - Configurações avançadas adicionais e controles para requisitos especializados.
* `parse` - retorna os dados já processados quando definido como true.
* `parsing_instructions` - defina sua própria lógica de parsing e transformação de dados que será executada no resultado de scraping HTML.

### Exemplo avançado

```python
from crewai_tools import OxylabsAmazonProductScraperTool

# certifique-se de que as variáveis OXYLABS_USERNAME e OXYLABS_PASSWORD estejam definidas
tool = OxylabsAmazonProductScraperTool(
    config={
        "domain": "com",
        "parse": True,
        "context": [
            {
                "key": "autoselect_variant",
                "value": True
            }
        ]
    }
)

result = tool.run(query="AAAAABBBBCC")

print(result)
```

# `OxylabsAmazonSearchScraperTool`

### Exemplo

```python
from crewai_tools import OxylabsAmazonSearchScraperTool

# certifique-se de que as variáveis OXYLABS_USERNAME e OXYLABS_PASSWORD estejam definidas
tool = OxylabsAmazonSearchScraperTool()

result = tool.run(query="headsets")

print(result)
```

### Parâmetros

* `query` - termo de busca da Amazon.
* `domain` - Domínio de localização para Bestbuy.
* `start_page` - número da página inicial.
* `pages` - quantidade de páginas a ser recuperada.
* `geo_location` - local de entrega (*Deliver to*).
* `user_agent_type` - tipo de dispositivo e navegador.
* `render` - ativa o renderizador JavaScript ao definir como `html`.
* `callback_url` - URL do seu endpoint de callback.
* `context` - Configurações avançadas adicionais e controles para requisitos especializados.
* `parse` - retorna os dados já processados quando definido como true.
* `parsing_instructions` - defina sua própria lógica de parsing e transformação de dados que será executada no resultado de scraping HTML.

### Exemplo avançado

```python
from crewai_tools import OxylabsAmazonSearchScraperTool

# certifique-se de que as variáveis OXYLABS_USERNAME e OXYLABS_PASSWORD estejam definidas
tool = OxylabsAmazonSearchScraperTool(
    config={
        "domain": 'nl',
        "start_page": 2,
        "pages": 2,
        "parse": True,
        "context": [
            {'key': 'category_id', 'value': 16391693031}
        ],
    }
)

result = tool.run(query='nirvana tshirt')

print(result)
```

# `OxylabsGoogleSearchScraperTool`

### Exemplo

```python
from crewai_tools import OxylabsGoogleSearchScraperTool

# certifique-se de que as variáveis OXYLABS_USERNAME e OXYLABS_PASSWORD estejam definidas
tool = OxylabsGoogleSearchScraperTool()

result = tool.run(query="iPhone 16")

print(result)
```

### Parâmetros

* `query` - palavra-chave de busca.
* `domain` - domínio de localização do Google.
* `start_page` - número da página inicial.
* `pages` - número de páginas a ser recuperado.
* `limit` - quantidade de resultados a ser recuperada em cada página.
* `locale` - valor do header `Accept-Language`, que altera o idioma da interface da página de pesquisa do Google.
* `geo_location` - a localização geográfica para a qual o resultado deve ser adaptado. Usar este parâmetro corretamente é extremamente importante para obter os dados corretos.
* `user_agent_type` - tipo de dispositivo e navegador.
* `render` - ativa o renderizador JavaScript ao definir como `html`.
* `callback_url` - URL do seu endpoint de callback.
* `context` - Configurações avançadas adicionais e controles para requisitos especializados.
* `parse` - retorna os dados já processados quando definido como true.
* `parsing_instructions` - defina sua própria lógica de parsing e transformação de dados que será executada no resultado de scraping HTML.

### Exemplo avançado

```python
from crewai_tools import OxylabsGoogleSearchScraperTool

# certifique-se de que as variáveis OXYLABS_USERNAME e OXYLABS_PASSWORD estejam definidas
tool = OxylabsGoogleSearchScraperTool(
    config={
        "parse": True,
        "geo_location": "Paris, France",
        "user_agent_type": "tablet",
    }
)

result = tool.run(query="iPhone 16")

print(result)
```

# `OxylabsUniversalScraperTool`

### Exemplo

```python
from crewai_tools import OxylabsUniversalScraperTool

# certifique-se de que as variáveis OXYLABS_USERNAME e OXYLABS_PASSWORD estejam definidas
tool = OxylabsUniversalScraperTool()

result = tool.run(url="https://ip.oxylabs.io")

print(result)
```

### Parâmetros

* `url` - URL do site a ser raspada.
* `user_agent_type` - tipo de dispositivo e navegador.
* `geo_location` - define a geolocalização do proxy para coletar os dados.
* `render` - ativa o renderizador JavaScript ao definir como `html`.
* `callback_url` - URL do seu endpoint de callback.
* `context` - Configurações avançadas adicionais e controles para requisitos especializados.
* `parse` - retorna os dados já processados quando definido como `true`, desde que exista um parser dedicado para o tipo de página da URL fornecida.
* `parsing_instructions` - defina sua própria lógica de parsing e transformação de dados que será executada no resultado de scraping HTML.

### Exemplo avançado

```python
from crewai_tools import OxylabsUniversalScraperTool

# certifique-se de que as variáveis OXYLABS_USERNAME e OXYLABS_PASSWORD estejam definidas
tool = OxylabsUniversalScraperTool(
    config={
        "render": "html",
        "user_agent_type": "mobile",
        "context": [
            {"key": "force_headers", "value": True},
            {"key": "force_cookies", "value": True},
            {
                "key": "headers",
                "value": {
                    "Custom-Header-Name": "custom header content",
                },
            },
            {
                "key": "cookies",
                "value": [
                    {"key": "NID", "value": "1234567890"},
                    {"key": "1P JAR", "value": "0987654321"},
                ],
            },
            {"key": "http_method", "value": "get"},
            {"key": "follow_redirects", "value": True},
            {"key": "successful_status_codes", "value": [808, 909]},
        ],
    }
)

result = tool.run(url="https://ip.oxylabs.io")

print(result)
```


# Ferramenta de Extração de Elementos de Website
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/scrapeelementfromwebsitetool

A `ScrapeElementFromWebsiteTool` permite que agentes CrewAI extraiam elementos específicos de websites usando seletores CSS.

# `ScrapeElementFromWebsiteTool`

## Descrição

A `ScrapeElementFromWebsiteTool` foi projetada para extrair elementos específicos de websites utilizando seletores CSS. Esta ferramenta permite que agentes CrewAI capturem conteúdos direcionados de páginas web, tornando-se útil para tarefas de extração de dados em que apenas partes específicas de uma página são necessárias.

## Instalação

Para utilizar esta ferramenta, você precisa instalar as dependências necessárias:

```shell
uv add requests beautifulsoup4
```

## Passos para Começar

Para usar a `ScrapeElementFromWebsiteTool` de maneira eficaz, siga estes passos:

1. **Instale as Dependências**: Instale os pacotes necessários com o comando acima.
2. **Identifique os Seletores CSS**: Determine os seletores CSS dos elementos que deseja extrair do site.
3. **Inicialize a Ferramenta**: Crie uma instância da ferramenta com os parâmetros necessários.

## Exemplo

O exemplo abaixo demonstra como usar a `ScrapeElementFromWebsiteTool` para extrair elementos específicos de um website:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import ScrapeElementFromWebsiteTool

# Inicie a ferramenta
scrape_tool = ScrapeElementFromWebsiteTool()

# Defina um agente que utilizará a ferramenta
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extrair informações específicas de websites",
    backstory="Um especialista em web scraping capaz de capturar conteúdos direcionados de páginas web.",
    tools=[scrape_tool],
    verbose=True,
)

# Exemplo de tarefa para extrair manchetes de um site de notícias
scrape_task = Task(
    description="Extraia as principais manchetes da página inicial da CNN. Use o seletor CSS '.headline' para atingir os elementos de manchete.",
    expected_output="Uma lista das principais manchetes da CNN.",
    agent=web_scraper_agent,
)

# Crie e execute o crew
crew = Crew(agents=[web_scraper_agent], tasks=[scrape_task])
result = crew.kickoff()
```

Você também pode inicializar a ferramenta com parâmetros pré-definidos:

```python Code
# Inicialize a ferramenta com parâmetros pré-definidos
scrape_tool = ScrapeElementFromWebsiteTool(
    website_url="https://www.example.com",
    css_element=".main-content"
)
```

## Parâmetros

A `ScrapeElementFromWebsiteTool` aceita os seguintes parâmetros durante a inicialização:

* **website\_url**: Opcional. A URL do website a ser extraído. Se fornecido na inicialização, o agente não precisará especificá-lo ao utilizar a ferramenta.
* **css\_element**: Opcional. O seletor CSS para os elementos a serem extraídos. Se fornecido na inicialização, o agente não precisará especificá-lo ao utilizar a ferramenta.
* **cookies**: Opcional. Um dicionário contendo cookies a serem enviados com a requisição. Isso pode ser útil para sites que requerem autenticação.

## Uso

Ao utilizar a `ScrapeElementFromWebsiteTool` com um agente, o agente precisará fornecer os seguintes parâmetros (a menos que já tenham sido especificados na inicialização):

* **website\_url**: A URL do website a ser extraído.
* **css\_element**: O seletor CSS dos elementos a serem extraídos.

A ferramenta retornará o conteúdo de texto de todos os elementos que correspondam ao seletor CSS, separados por quebras de linha.

```python Code
# Exemplo de uso da ferramenta com um agente
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extrair elementos específicos de websites",
    backstory="Um especialista em web scraping capaz de extrair conteúdo direcionado por meio de seletores CSS.",
    tools=[scrape_tool],
    verbose=True,
)

# Crie uma tarefa para o agente extrair elementos específicos
extract_task = Task(
    description="""
    Extraia todos os títulos de produtos da seção de produtos em destaque no example.com.
    Use o seletor CSS '.product-title' para atingir os elementos de título.
    """,
    expected_output="Uma lista de títulos de produtos do site",
    agent=web_scraper_agent,
)

# Execute a tarefa utilizando um crew
crew = Crew(agents=[web_scraper_agent], tasks=[extract_task])
result = crew.kickoff()
```

## Detalhes de Implementação

A `ScrapeElementFromWebsiteTool` utiliza a biblioteca `requests` para buscar a página web e `BeautifulSoup` para analisar o HTML e extrair os elementos especificados:

```python Code
class ScrapeElementFromWebsiteTool(BaseTool):
    name: str = "Read a website content"
    description: str = "A tool that can be used to read a website content."

    # Implementation details...

    def _run(self, **kwargs: Any) -> Any:
        website_url = kwargs.get("website_url", self.website_url)
        css_element = kwargs.get("css_element", self.css_element)
        page = requests.get(
            website_url,
            headers=self.headers,
            cookies=self.cookies if self.cookies else {},
        )
        parsed = BeautifulSoup(page.content, "html.parser")
        elements = parsed.select(css_element)
        return "\n".join([element.get_text() for element in elements])
```

## Conclusão

A `ScrapeElementFromWebsiteTool` oferece uma maneira poderosa de extrair elementos específicos de websites utilizando seletores CSS. Ao possibilitar que agentes direcionem apenas o conteúdo que necessitam, ela torna as tarefas de web scraping mais eficientes e objetivas. Esta ferramenta é particularmente útil para extração de dados, monitoramento de conteúdos e tarefas de pesquisa em que informações específicas precisam ser extraídas de páginas web.


# Ferramenta de Extração Scrapegraph
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/scrapegraphscrapetool

A `ScrapegraphScrapeTool` utiliza a API SmartScraper da Scrapegraph AI para extrair conteúdo de sites de forma inteligente.

# `ScrapegraphScrapeTool`

## Descrição

A `ScrapegraphScrapeTool` foi projetada para utilizar a API SmartScraper da Scrapegraph AI e extrair conteúdo de sites de maneira inteligente. Esta ferramenta oferece recursos avançados de web scraping com extração de conteúdo potencializada por IA, tornando-se ideal para coleta de dados direcionada e tarefas de análise de conteúdo. Diferente dos scrapers tradicionais, ela entende o contexto e a estrutura das páginas da web para extrair as informações mais relevantes, com base em instruções em linguagem natural.

## Instalação

Para utilizar esta ferramenta, é necessário instalar o cliente Python do Scrapegraph:

```shell
uv add scrapegraph-py
```

Você também precisa definir sua chave de API do Scrapegraph como uma variável de ambiente:

```shell
export SCRAPEGRAPH_API_KEY="your_api_key"
```

Você pode obter uma chave de API em [Scrapegraph AI](https://scrapegraphai.com).

## Passos para Começar

Para usar efetivamente a `ScrapegraphScrapeTool`, siga estes passos:

1. **Instale as dependências**: Instale o pacote necessário usando o comando acima.
2. **Configure a chave de API**: Defina sua chave de API do Scrapegraph como variável de ambiente ou forneça-a durante a inicialização.
3. **Inicialize a ferramenta**: Crie uma instância da ferramenta com os parâmetros necessários.
4. **Defina instruções de extração**: Crie prompts em linguagem natural para guiar a extração de conteúdos específicos.

## Exemplo

O exemplo a seguir demonstra como usar a `ScrapegraphScrapeTool` para extrair conteúdo de um site:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import ScrapegraphScrapeTool

# Initialize the tool
scrape_tool = ScrapegraphScrapeTool(api_key="your_api_key")

# Define an agent that uses the tool
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract specific information from websites",
    backstory="An expert in web scraping who can extract targeted content from web pages.",
    tools=[scrape_tool],
    verbose=True,
)

# Example task to extract product information from an e-commerce site
scrape_task = Task(
    description="Extract product names, prices, and descriptions from the featured products section of example.com.",
    expected_output="A structured list of product information including names, prices, and descriptions.",
    agent=web_scraper_agent,
)

# Create and run the crew
crew = Crew(agents=[web_scraper_agent], tasks=[scrape_task])
result = crew.kickoff()
```

Você também pode inicializar a ferramenta com parâmetros pré-definidos:

```python Code
# Initialize the tool with predefined parameters
scrape_tool = ScrapegraphScrapeTool(
    website_url="https://www.example.com",
    user_prompt="Extract all product prices and descriptions",
    api_key="your_api_key"
)
```

## Parâmetros

A `ScrapegraphScrapeTool` aceita os seguintes parâmetros durante a inicialização:

* **api\_key**: Opcional. Sua chave de API do Scrapegraph. Se não for fornecida, será procurada a variável de ambiente `SCRAPEGRAPH_API_KEY`.
* **website\_url**: Opcional. A URL do site a ser extraído. Se fornecida na inicialização, o agente não precisa especificá-la ao usar a ferramenta.
* **user\_prompt**: Opcional. Instruções customizadas para extração de conteúdo. Se fornecida na inicialização, o agente não precisa especificá-la ao usar a ferramenta.
* **enable\_logging**: Opcional. Define se o registro (logging) na Scrapegraph deve ser ativado. O padrão é `False`.

## Uso

Ao usar a `ScrapegraphScrapeTool` com um agente, será necessário fornecer os seguintes parâmetros (a menos que tenham sido especificados durante a inicialização):

* **website\_url**: A URL do site a ser extraída.
* **user\_prompt**: Opcional. Instruções customizadas para extração de conteúdo. O padrão é "Extract the main content of the webpage".

A ferramenta retornará o conteúdo extraído com base no prompt fornecido.

```python Code
# Example of using the tool with an agent
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract specific information from websites",
    backstory="An expert in web scraping who can extract targeted content from web pages.",
    tools=[scrape_tool],
    verbose=True,
)

# Create a task for the agent to extract specific content
extract_task = Task(
    description="Extract the main heading and summary from example.com",
    expected_output="The main heading and summary from the website",
    agent=web_scraper_agent,
)

# Run the task
crew = Crew(agents=[web_scraper_agent], tasks=[extract_task])
result = crew.kickoff()
```

## Tratamento de Erros

A `ScrapegraphScrapeTool` pode lançar as seguintes exceções:

* **ValueError**: Quando a chave da API está ausente ou o formato da URL é inválido.
* **RateLimitError**: Quando o limite de requisições da API é excedido.
* **RuntimeError**: Quando a operação de extração falha (problemas de rede, erros da API).

Recomenda-se instruir os agentes a lidarem com potenciais erros de forma apropriada:

```python Code
# Create a task that includes error handling instructions
robust_extract_task = Task(
    description="""
    Extract the main heading from example.com.
    Be aware that you might encounter errors such as:
    - Invalid URL format
    - Missing API key
    - Rate limit exceeded
    - Network or API errors

    If you encounter any errors, provide a clear explanation of what went wrong
    and suggest possible solutions.
    """,
    expected_output="Either the extracted heading or a clear error explanation",
    agent=web_scraper_agent,
)
```

## Limitações de Taxa

A API do Scrapegraph possui limites de requisição que variam conforme o seu plano de assinatura. Considere as seguintes boas práticas:

* Implemente atrasos apropriados entre requisições ao processar múltiplas URLs.
* Trate erros de limite de requisição de forma apropriada em sua aplicação.
* Verifique os limites do seu plano de API no painel do Scrapegraph.

## Detalhes de Implementação

A `ScrapegraphScrapeTool` utiliza o cliente Python do Scrapegraph para se comunicar com a API SmartScraper:

```python Code
class ScrapegraphScrapeTool(BaseTool):
    """
    A tool that uses Scrapegraph AI to intelligently scrape website content.
    """

    # Implementation details...

    def _run(self, **kwargs: Any) -> Any:
        website_url = kwargs.get("website_url", self.website_url)
        user_prompt = (
            kwargs.get("user_prompt", self.user_prompt)
            or "Extract the main content of the webpage"
        )

        if not website_url:
            raise ValueError("website_url is required")

        # Validate URL format
        self._validate_url(website_url)

        try:
            # Make the SmartScraper request
            response = self._client.smartscraper(
                website_url=website_url,
                user_prompt=user_prompt,
            )

            return response
        # Error handling...
```

## Conclusão

A `ScrapegraphScrapeTool` oferece uma maneira poderosa de extrair conteúdo de sites utilizando o entendimento do formato das páginas pela IA. Ao permitir que os agentes direcionem informações específicas por meio de prompts em linguagem natural, ela torna tarefas de web scraping mais eficientes e focadas. Esta ferramenta é especialmente útil para extração de dados, monitoramento de conteúdo e pesquisas em que informações específicas precisam ser extraídas de páginas web.


# Raspar Site
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/scrapewebsitetool

O `ScrapeWebsiteTool` foi desenvolvido para extrair e ler o conteúdo de um site especificado.

# `ScrapeWebsiteTool`

<Note>
  Ainda estamos trabalhando para melhorar as ferramentas, então pode haver comportamentos inesperados ou mudanças futuras.
</Note>

## Descrição

Uma ferramenta desenvolvida para extrair e ler o conteúdo de um site especificado. Ela é capaz de lidar com diversos tipos de páginas web fazendo requisições HTTP e analisando o conteúdo HTML recebido.
Esta ferramenta pode ser especialmente útil para tarefas de raspagem de dados, coleta de dados ou extração de informações específicas de sites.

## Instalação

Instale o pacote crewai\_tools

```shell
pip install 'crewai[tools]'
```

## Exemplo

```python
from crewai_tools import ScrapeWebsiteTool

# Para permitir a raspagem de qualquer site encontrado durante a execução
tool = ScrapeWebsiteTool()

# Inicialize a ferramenta com a URL do site,
# assim o agente só poderá raspar o conteúdo do site especificado
tool = ScrapeWebsiteTool(website_url='https://www.example.com')

# Extraia o texto do site
text = tool.run()
print(text)
```

## Argumentos

| Argumento        | Tipo     | Descrição                                                                                                                                                     |
| :--------------- | :------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **website\_url** | `string` | **Obrigatório** URL do site para leitura do arquivo. Esta é a entrada principal da ferramenta, especificando de qual site o conteúdo deve ser raspado e lido. |


# Ferramenta de Raspagem de Sites Scrapfly
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/scrapflyscrapetool

A `ScrapflyScrapeWebsiteTool` aproveita a API de web scraping da Scrapfly para extrair conteúdo de sites em diversos formatos.

# `ScrapflyScrapeWebsiteTool`

## Descrição

A `ScrapflyScrapeWebsiteTool` foi desenvolvida para aproveitar a API de web scraping da [Scrapfly](https://scrapfly.io/) para extrair conteúdo de sites. Esta ferramenta oferece recursos avançados de raspagem com suporte a navegador headless, proxies e recursos de bypass de anti-bot. Permite extrair dados de páginas web em vários formatos, incluindo HTML bruto, markdown e texto simples, sendo ideal para uma ampla variedade de tarefas de raspagem de sites.

## Instalação

Para utilizar esta ferramenta, é necessário instalar o Scrapfly SDK:

```shell
uv add scrapfly-sdk
```

Você também precisará obter uma chave de API da Scrapfly registrando-se em [scrapfly.io/register](https://www.scrapfly.io/register/).

## Passos para Começar

Para usar a `ScrapflyScrapeWebsiteTool` de forma eficaz, siga estas etapas:

1. **Instale as Dependências**: Instale o Scrapfly SDK usando o comando acima.
2. **Obtenha a Chave de API**: Cadastre-se na Scrapfly para obter sua chave de API.
3. **Inicialize a Ferramenta**: Crie uma instância da ferramenta com sua chave de API.
4. **Configure os Parâmetros de Raspagem**: Personalize os parâmetros de raspagem conforme suas necessidades.

## Exemplo

O exemplo a seguir demonstra como usar a `ScrapflyScrapeWebsiteTool` para extrair conteúdo de um site:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import ScrapflyScrapeWebsiteTool

# Initialize the tool
scrape_tool = ScrapflyScrapeWebsiteTool(api_key="your_scrapfly_api_key")

# Define an agent that uses the tool
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract information from websites",
    backstory="An expert in web scraping who can extract content from any website.",
    tools=[scrape_tool],
    verbose=True,
)

# Example task to extract content from a website
scrape_task = Task(
    description="Extract the main content from the product page at https://web-scraping.dev/products and summarize the available products.",
    expected_output="A summary of the products available on the website.",
    agent=web_scraper_agent,
)

# Create and run the crew
crew = Crew(agents=[web_scraper_agent], tasks=[scrape_task])
result = crew.kickoff()
```

Você também pode personalizar os parâmetros de raspagem:

```python Code
# Example with custom scraping parameters
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract information from websites with custom parameters",
    backstory="An expert in web scraping who can extract content from any website.",
    tools=[scrape_tool],
    verbose=True,
)

# The agent will use the tool with parameters like:
# url="https://web-scraping.dev/products"
# scrape_format="markdown"
# ignore_scrape_failures=True
# scrape_config={
#     "asp": True,  # Bypass scraping blocking solutions, like Cloudflare
#     "render_js": True,  # Enable JavaScript rendering with a cloud headless browser
#     "proxy_pool": "public_residential_pool",  # Select a proxy pool
#     "country": "us",  # Select a proxy location
#     "auto_scroll": True,  # Auto scroll the page
# }

scrape_task = Task(
    description="Extract the main content from the product page at https://web-scraping.dev/products using advanced scraping options including JavaScript rendering and proxy settings.",
    expected_output="A detailed summary of the products with all available information.",
    agent=web_scraper_agent,
)
```

## Parâmetros

A `ScrapflyScrapeWebsiteTool` aceita os seguintes parâmetros:

### Parâmetros de Inicialização

* **api\_key**: Obrigatório. Sua chave de API da Scrapfly.

### Parâmetros de Execução

* **url**: Obrigatório. A URL do site a ser raspado.
* **scrape\_format**: Opcional. O formato em que o conteúdo da página será extraído. As opções são "raw" (HTML), "markdown" ou "text". O padrão é "markdown".
* **scrape\_config**: Opcional. Um dicionário contendo opções adicionais de configuração de raspagem da Scrapfly.
* **ignore\_scrape\_failures**: Opcional. Determina se as falhas de raspagem devem ser ignoradas. Se definido como `True`, a ferramenta irá retornar `None` ao invés de lançar uma exceção caso ocorra uma falha na raspagem.

## Opções de Configuração Scrapfly

O parâmetro `scrape_config` permite personalizar o comportamento da raspagem com as seguintes opções:

* **asp**: Ativa o bypass de proteção anti-scraping.
* **render\_js**: Ativa a renderização de JavaScript com um navegador headless na nuvem.
* **proxy\_pool**: Seleciona um pool de proxies (por exemplo, "public\_residential\_pool", "datacenter").
* **country**: Seleciona a localização do proxy (por exemplo, "us", "uk").
* **auto\_scroll**: Rola automaticamente a página para carregar conteúdo lazy-loaded.
* **js**: Executa código JavaScript personalizado via o navegador headless.

Para uma lista completa de opções de configuração, consulte a [documentação da API Scrapfly](https://scrapfly.io/docs/scrape-api/getting-started).

## Uso

Ao usar a `ScrapflyScrapeWebsiteTool` com um agente, o agente deverá fornecer a URL do site a ser raspado e pode opcionalmente especificar o formato e opções adicionais de configuração:

```python Code
# Example of using the tool with an agent
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract information from websites",
    backstory="An expert in web scraping who can extract content from any website.",
    tools=[scrape_tool],
    verbose=True,
)

# Create a task for the agent
scrape_task = Task(
    description="Extract the main content from example.com in markdown format.",
    expected_output="The main content of example.com in markdown format.",
    agent=web_scraper_agent,
)

# Run the task
crew = Crew(agents=[web_scraper_agent], tasks=[scrape_task])
result = crew.kickoff()
```

Para um uso mais avançado com configurações personalizadas:

```python Code
# Create a task with more specific instructions
advanced_scrape_task = Task(
    description="""
    Extract content from example.com with the following requirements:
    - Convert the content to plain text format
    - Enable JavaScript rendering
    - Use a US-based proxy
    - Handle any scraping failures gracefully
    """,
    expected_output="The extracted content from example.com",
    agent=web_scraper_agent,
)
```

## Tratamento de Erros

Por padrão, a `ScrapflyScrapeWebsiteTool` irá lançar uma exceção se a raspagem falhar. Os agentes podem ser instruídos a tratar falhas de forma mais flexível especificando o parâmetro `ignore_scrape_failures`:

```python Code
# Create a task that instructs the agent to handle errors
error_handling_task = Task(
    description="""
    Extract content from a potentially problematic website and make sure to handle any
    scraping failures gracefully by setting ignore_scrape_failures to True.
    """,
    expected_output="Either the extracted content or a graceful error message",
    agent=web_scraper_agent,
)
```

## Detalhes de Implementação

A `ScrapflyScrapeWebsiteTool` utiliza o Scrapfly SDK para interagir com a API Scrapfly:

```python Code
class ScrapflyScrapeWebsiteTool(BaseTool):
    name: str = "Scrapfly web scraping API tool"
    description: str = (
        "Scrape a webpage url using Scrapfly and return its content as markdown or text"
    )

    # Implementation details...

    def _run(
        self,
        url: str,
        scrape_format: str = "markdown",
        scrape_config: Optional[Dict[str, Any]] = None,
        ignore_scrape_failures: Optional[bool] = None,
    ):
        from scrapfly import ScrapeApiResponse, ScrapeConfig

        scrape_config = scrape_config if scrape_config is not None else {}
        try:
            response: ScrapeApiResponse = self.scrapfly.scrape(
                ScrapeConfig(url, format=scrape_format, **scrape_config)
            )
            return response.scrape_result["content"]
        except Exception as e:
            if ignore_scrape_failures:
                logger.error(f"Error fetching data from {url}, exception: {e}")
                return None
            else:
                raise e
```

## Conclusão

A `ScrapflyScrapeWebsiteTool` oferece uma forma poderosa de extrair conteúdo de sites usando as avançadas capacidades de web scraping da Scrapfly. Com recursos como suporte a navegador headless, proxies e bypass de anti-bot, ela consegue lidar com sites complexos e extrair conteúdo em diversos formatos. Esta ferramenta é especialmente útil em tarefas de extração de dados, monitoramento de conteúdo e pesquisa, onde a raspagem confiável de sites é necessária.


# Selenium Scraper
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/seleniumscrapingtool

O `SeleniumScrapingTool` foi desenvolvido para extrair e ler o conteúdo de um site específico utilizando o Selenium.

# `SeleniumScrapingTool`

<Note>
  Esta ferramenta está atualmente em desenvolvimento. Conforme aprimoramos suas capacidades, os usuários podem encontrar comportamentos inesperados.
  Seu feedback é inestimável para que possamos melhorar.
</Note>

## Descrição

O `SeleniumScrapingTool` foi criado para tarefas de raspagem web de alta eficiência.
Permite a extração precisa de conteúdo de páginas web utilizando seletores CSS para direcionar elementos específicos.
Seu design atende a uma ampla gama de necessidades de scraping, oferecendo flexibilidade para trabalhar com qualquer URL de site fornecida.

## Instalação

Para utilizar esta ferramenta, é necessário instalar o pacote CrewAI tools e o Selenium:

```shell
pip install 'crewai[tools]'
uv add selenium webdriver-manager
```

Você também precisará ter o Chrome instalado em seu sistema, pois a ferramenta utiliza o Chrome WebDriver para automação do navegador.

## Exemplo

O exemplo a seguir demonstra como usar o `SeleniumScrapingTool` com um agente CrewAI:

```python Code
from crewai import Agent, Task, Crew, Process
from crewai_tools import SeleniumScrapingTool

# Inicializa a ferramenta
selenium_tool = SeleniumScrapingTool()

# Define um agente que utiliza a ferramenta
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract information from websites using Selenium",
    backstory="An expert web scraper who can extract content from dynamic websites.",
    tools=[selenium_tool],
    verbose=True,
)

# Exemplo de tarefa para extrair conteúdo de um site
scrape_task = Task(
    description="Extract the main content from the homepage of example.com. Use the CSS selector 'main' to target the main content area.",
    expected_output="The main content from example.com's homepage.",
    agent=web_scraper_agent,
)

# Cria e executa o crew
crew = Crew(
    agents=[web_scraper_agent],
    tasks=[scrape_task],
    verbose=True,
    process=Process.sequential,
)
result = crew.kickoff()
```

Você também pode inicializar a ferramenta com parâmetros predefinidos:

```python Code
# Inicializa a ferramenta com parâmetros predefinidos
selenium_tool = SeleniumScrapingTool(
    website_url='https://example.com',
    css_element='.main-content',
    wait_time=5
)

# Define um agente que utiliza a ferramenta
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract information from websites using Selenium",
    backstory="An expert web scraper who can extract content from dynamic websites.",
    tools=[selenium_tool],
    verbose=True,
)
```

## Parâmetros

O `SeleniumScrapingTool` aceita os seguintes parâmetros durante a inicialização:

* **website\_url**: Opcional. A URL do site a ser raspado. Se fornecido durante a inicialização, o agente não precisará especificá-lo ao utilizar a ferramenta.
* **css\_element**: Opcional. O seletor CSS dos elementos a serem extraídos. Se fornecido durante a inicialização, o agente não precisará especificá-lo ao utilizar a ferramenta.
* **cookie**: Opcional. Um dicionário contendo informações de cookies, útil para simular uma sessão logada e acessar conteúdo restrito.
* **wait\_time**: Opcional. Especifica o atraso (em segundos) antes da raspagem, permitindo que o site e qualquer conteúdo dinâmico carreguem totalmente. O padrão é `3` segundos.
* **return\_html**: Opcional. Indica se o conteúdo HTML deve ser retornado em vez do texto simples. O padrão é `False`.

Ao usar a ferramenta com um agente, o agente precisará fornecer os seguintes parâmetros (a menos que tenham sido especificados durante a inicialização):

* **website\_url**: Obrigatório. A URL do site a ser raspado.
* **css\_element**: Obrigatório. O seletor CSS dos elementos a serem extraídos.

## Exemplo de Integração com Agente

Aqui está um exemplo mais detalhado de como integrar o `SeleniumScrapingTool` com um agente CrewAI:

```python Code
from crewai import Agent, Task, Crew, Process
from crewai_tools import SeleniumScrapingTool

# Inicializa a ferramenta
selenium_tool = SeleniumScrapingTool()

# Define um agente que utiliza a ferramenta
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract and analyze information from dynamic websites",
    backstory="""You are an expert web scraper who specializes in extracting
    content from dynamic websites that require browser automation. You have
    extensive knowledge of CSS selectors and can identify the right selectors
    to target specific content on any website.""",
    tools=[selenium_tool],
    verbose=True,
)

# Cria uma tarefa para o agente
scrape_task = Task(
    description="""
    Extract the following information from the news website at {website_url}:

    1. The headlines of all featured articles (CSS selector: '.headline')
    2. The publication dates of these articles (CSS selector: '.pub-date')
    3. The author names where available (CSS selector: '.author')

    Compile this information into a structured format with each article's details grouped together.
    """,
    expected_output="A structured list of articles with their headlines, publication dates, and authors.",
    agent=web_scraper_agent,
)

# Executa a tarefa
crew = Crew(
    agents=[web_scraper_agent],
    tasks=[scrape_task],
    verbose=True,
    process=Process.sequential,
)
result = crew.kickoff(inputs={"website_url": "https://news-example.com"})
```

## Detalhes de Implementação

O `SeleniumScrapingTool` utiliza o Selenium WebDriver para automatizar interações com o navegador:

```python Code
class SeleniumScrapingTool(BaseTool):
    name: str = "Read a website content"
    description: str = "A tool that can be used to read a website content."
    args_schema: Type[BaseModel] = SeleniumScrapingToolSchema

    def _run(self, **kwargs: Any) -> Any:
        website_url = kwargs.get("website_url", self.website_url)
        css_element = kwargs.get("css_element", self.css_element)
        return_html = kwargs.get("return_html", self.return_html)
        driver = self._create_driver(website_url, self.cookie, self.wait_time)

        content = self._get_content(driver, css_element, return_html)
        driver.close()

        return "\n".join(content)
```

A ferramenta executa as seguintes etapas:

1. Cria uma instância do Chrome em modo headless
2. Navega até a URL especificada
3. Aguarda o tempo especificado para permitir o carregamento da página
4. Adiciona cookies se fornecidos
5. Extrai conteúdo baseado no seletor CSS
6. Retorna o conteúdo extraído como texto ou HTML
7. Encerra a instância do navegador

## Tratamento de Conteúdo Dinâmico

O `SeleniumScrapingTool` é especialmente útil para extrair sites com conteúdo dinâmico carregado via JavaScript. Usando uma instância real de navegador, ele pode:

1. Executar JavaScript na página
2. Aguardar o carregamento do conteúdo dinâmico
3. Interagir com elementos se necessário
4. Extrair conteúdo que não estaria disponível usando apenas requisições HTTP simples

Você pode ajustar o parâmetro `wait_time` para garantir que todo o conteúdo dinâmico tenha sido carregado antes da extração.

## Conclusão

O `SeleniumScrapingTool` fornece uma maneira poderosa de extrair conteúdo de sites utilizando automação de navegador. Ao permitir que agentes interajam com sites como um usuário real, ele facilita a raspagem de conteúdo dinâmico que seria difícil ou impossível de extrair utilizando métodos mais simples. Esta ferramenta é especialmente útil para pesquisas, coleta de dados e tarefas de monitoramento que envolvem aplicações web modernas com conteúdo renderizado por JavaScript.


# Spider Scraper
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/spidertool

O `SpiderTool` foi projetado para extrair e ler o conteúdo de um site especificado usando o Spider.

# `SpiderTool`

## Descrição

[Spider](https://spider.cloud/?ref=crewai) é o [scraper](https://github.com/spider-rs/spider/blob/main/benches/BENCHMARKS.md#benchmark-results) e crawler de código aberto mais rápido que retorna dados prontos para LLM.\
Ele converte qualquer site em HTML puro, markdown, metadados ou texto e permite que você faça crawling com ações personalizadas utilizando IA.

## Instalação

Para usar o `SpiderTool` você precisa baixar o [Spider SDK](https://pypi.org/project/spider-client/)\
e também o SDK `crewai[tools]`:

```shell
pip install spider-client 'crewai[tools]'
```

## Exemplo

Este exemplo mostra como você pode usar o `SpiderTool` para permitir que seu agente faça scraping e crawling de websites.\
Os dados retornados pela API do Spider já estão prontos para LLM, então não é necessário fazer nenhuma limpeza adicional.

```python Code
from crewai_tools import SpiderTool

def main():
    spider_tool = SpiderTool()

    searcher = Agent(
        role="Web Research Expert",
        goal="Find related information from specific URL's",
        backstory="An expert web researcher that uses the web extremely well",
        tools=[spider_tool],
        verbose=True,
    )

    return_metadata = Task(
        description="Scrape https://spider.cloud with a limit of 1 and enable metadata",
        expected_output="Metadata and 10 word summary of spider.cloud",
        agent=searcher
    )

    crew = Crew(
        agents=[searcher],
        tasks=[
            return_metadata,
        ],
        verbose=2
    )

    crew.kickoff()

if __name__ == "__main__":
    main()
```

## Argumentos

| Argumento               | Tipo     | Descrição                                                                                                                                                       |
| :---------------------- | :------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **api\_key**            | `string` | Especifica a chave da API do Spider. Se não for definida, procura por `SPIDER_API_KEY` nas variáveis de ambiente.                                               |
| **params**              | `object` | Parâmetros opcionais para a requisição. O padrão é `{"return_format": "markdown"}` para otimizar o conteúdo para LLMs.                                          |
| **request**             | `string` | Tipo de requisição a ser realizada (`http`, `chrome`, `smart`). `smart` tem como padrão HTTP, alterando para renderização JavaScript se necessário.             |
| **limit**               | `int`    | Máximo de páginas a serem rastreadas por site. Defina como `0` ou omita para ilimitado.                                                                         |
| **depth**               | `int`    | Profundidade máxima do crawl. Defina como `0` para sem limite.                                                                                                  |
| **cache**               | `bool`   | Habilita cache HTTP para acelerar execuções repetidas. O padrão é `true`.                                                                                       |
| **budget**              | `object` | Define limites baseados em caminho para páginas rastreadas, ex.: `{"*":1}` apenas para a página raiz.                                                           |
| **locale**              | `string` | Localidade da requisição, ex.: `en-US`.                                                                                                                         |
| **cookies**             | `string` | Cookies HTTP para a requisição.                                                                                                                                 |
| **stealth**             | `bool`   | Habilita modo furtivo para requisições Chrome para evitar detecção. O padrão é `true`.                                                                          |
| **headers**             | `object` | Headers HTTP como um mapa de chave-valor para todas as requisições.                                                                                             |
| **metadata**            | `bool`   | Armazena metadados sobre as páginas e conteúdos, auxiliando interoperabilidade com IA. O padrão é `false`.                                                      |
| **viewport**            | `object` | Define as dimensões de viewport do Chrome. O padrão é `800x600`.                                                                                                |
| **encoding**            | `string` | Especifica o tipo de codificação, ex.: `UTF-8`, `SHIFT_JIS`.                                                                                                    |
| **subdomains**          | `bool`   | Inclui subdomínios no crawl. O padrão é `false`.                                                                                                                |
| **user\_agent**         | `string` | User agent HTTP personalizado. Padrão é um agente aleatório.                                                                                                    |
| **store\_data**         | `bool`   | Habilita o armazenamento dos dados para a requisição. Sobrescreve `storageless` quando definido. O padrão é `false`.                                            |
| **gpt\_config**         | `object` | Permite à IA gerar ações de crawl, com encadeamento de etapas opcional via array para `"prompt"`.                                                               |
| **fingerprint**         | `bool`   | Habilita fingerprint avançado para o Chrome.                                                                                                                    |
| **storageless**         | `bool`   | Impede todo o armazenamento de dados, incluindo embeddings de IA. O padrão é `false`.                                                                           |
| **readability**         | `bool`   | Pré-processa conteúdo para leitura via [Mozilla’s readability](https://github.com/mozilla/readability). Melhora o conteúdo para LLMs.                           |
| **return\_format**      | `string` | Formato para retorno dos dados: `markdown`, `raw`, `text`, `html2text`. Use `raw` para formato padrão da página.                                                |
| **proxy\_enabled**      | `bool`   | Habilita proxies de alta performance para evitar bloqueios em nível de rede.                                                                                    |
| **query\_selector**     | `string` | CSS query selector para extração de conteúdo a partir do markup.                                                                                                |
| **full\_resources**     | `bool`   | Baixa todos os recursos vinculados ao site.                                                                                                                     |
| **request\_timeout**    | `int`    | Timeout em segundos para as requisições (5-60). O padrão é `30`.                                                                                                |
| **run\_in\_background** | `bool`   | Executa a requisição em segundo plano. Útil para armazenamento de dados e acionamento de crawls no dashboard. Não tem efeito se `storageless` estiver definido. |


# Ferramenta Stagehand
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/stagehandtool

Ferramenta de automação web que integra o Stagehand ao CrewAI para interação e automação em navegadores

# Visão Geral

A `StagehandTool` integra o framework [Stagehand](https://docs.stagehand.dev/get_started/introduction) com o CrewAI, permitindo que agentes interajam com sites e automatizem tarefas no navegador utilizando instruções em linguagem natural.

## Visão Geral

O Stagehand é um poderoso framework de automação de navegador criado pela Browserbase que permite aos agentes de IA:

* Navegar por sites
* Clicar em botões, links e outros elementos
* Preencher formulários
* Extrair dados de páginas web
* Observar e identificar elementos
* Realizar fluxos de trabalho complexos

A StagehandTool encapsula o SDK Python do Stagehand para fornecer aos agentes do CrewAI capacidades de controle do navegador através de três primitivas principais:

1. **Act**: Executar ações como clicar, digitar ou navegar
2. **Extract**: Extrair dados estruturados de páginas web
3. **Observe**: Identificar e analisar elementos na página

## Pré-requisitos

Antes de utilizar esta ferramenta, certifique-se de que você possui:

1. Uma conta [Browserbase](https://www.browserbase.com/) com chave API e ID de projeto
2. Uma chave API para um LLM (OpenAI ou Anthropic Claude)
3. O SDK Python do Stagehand instalado

Instale a dependência necessária:

```bash
pip install stagehand-py
```

## Uso

### Implementação Básica

A StagehandTool pode ser implementada de duas maneiras:

#### 1. Usando Context Manager (Recomendado)

<Tip>
  A abordagem de context manager é recomendada, pois garante o encerramento adequado dos recursos mesmo em caso de exceções.
</Tip>

```python
from crewai import Agent, Task, Crew
from crewai_tools import StagehandTool
from stagehand.schemas import AvailableModel

# Initialize the tool with your API keys using a context manager
with StagehandTool(
    api_key="your-browserbase-api-key",
    project_id="your-browserbase-project-id",
    model_api_key="your-llm-api-key",  # OpenAI or Anthropic API key
    model_name=AvailableModel.CLAUDE_3_7_SONNET_LATEST,  # Optional: specify which model to use
) as stagehand_tool:
    # Create an agent with the tool
    researcher = Agent(
        role="Web Researcher",
        goal="Find and summarize information from websites",
        backstory="I'm an expert at finding information online.",
        verbose=True,
        tools=[stagehand_tool],
    )

    # Create a task that uses the tool
    research_task = Task(
        description="Go to https://www.example.com and tell me what you see on the homepage.",
        agent=researcher,
    )

    # Run the crew
    crew = Crew(
        agents=[researcher],
        tasks=[research_task],
        verbose=True,
    )

    result = crew.kickoff()
    print(result)
```

#### 2. Gerenciamento Manual de Recursos

```python
from crewai import Agent, Task, Crew
from crewai_tools import StagehandTool
from stagehand.schemas import AvailableModel

# Initialize the tool with your API keys
stagehand_tool = StagehandTool(
    api_key="your-browserbase-api-key",
    project_id="your-browserbase-project-id",
    model_api_key="your-llm-api-key",
    model_name=AvailableModel.CLAUDE_3_7_SONNET_LATEST,
)

try:
    # Create an agent with the tool
    researcher = Agent(
        role="Web Researcher",
        goal="Find and summarize information from websites",
        backstory="I'm an expert at finding information online.",
        verbose=True,
        tools=[stagehand_tool],
    )

    # Create a task that uses the tool
    research_task = Task(
        description="Go to https://www.example.com and tell me what you see on the homepage.",
        agent=researcher,
    )

    # Run the crew
    crew = Crew(
        agents=[researcher],
        tasks=[research_task],
        verbose=True,
    )

    result = crew.kickoff()
    print(result)
finally:
    # Explicitly clean up resources
    stagehand_tool.close()
```

## Tipos de Comando

A StagehandTool suporta três tipos diferentes de comando para tarefas específicas de automação web:

### 1. Comando Act

O tipo de comando `act` (padrão) permite interações em páginas web como clicar em botões, preencher formulários e navegar.

```python
# Perform an action (default behavior)
result = stagehand_tool.run(
    instruction="Click the login button",
    url="https://example.com",
    command_type="act"  # Default, so can be omitted
)

# Fill out a form
result = stagehand_tool.run(
    instruction="Fill the contact form with name 'John Doe', email 'john@example.com', and message 'Hello world'",
    url="https://example.com/contact"
)
```

### 2. Comando Extract

O tipo de comando `extract` recupera dados estruturados de páginas web.

```python
# Extract all product information
result = stagehand_tool.run(
    instruction="Extract all product names, prices, and descriptions",
    url="https://example.com/products",
    command_type="extract"
)

# Extract specific information with a selector
result = stagehand_tool.run(
    instruction="Extract the main article title and content",
    url="https://example.com/blog/article",
    command_type="extract",
    selector=".article-container"  # Optional CSS selector
)
```

### 3. Comando Observe

O tipo de comando `observe` identifica e analisa elementos da página web.

```python
# Find interactive elements
result = stagehand_tool.run(
    instruction="Find all interactive elements in the navigation menu",
    url="https://example.com",
    command_type="observe"
)

# Identify form fields
result = stagehand_tool.run(
    instruction="Identify all the input fields in the registration form",
    url="https://example.com/register",
    command_type="observe",
    selector="#registration-form"
)
```

## Opções de Configuração

Personalize o comportamento da StagehandTool com estes parâmetros:

```python
stagehand_tool = StagehandTool(
    api_key="your-browserbase-api-key",
    project_id="your-browserbase-project-id",
    model_api_key="your-llm-api-key",
    model_name=AvailableModel.CLAUDE_3_7_SONNET_LATEST,
    dom_settle_timeout_ms=5000,  # Wait longer for DOM to settle
    headless=True,  # Run browser in headless mode
    self_heal=True,  # Attempt to recover from errors
    wait_for_captcha_solves=True,  # Wait for CAPTCHA solving
    verbose=1,  # Control logging verbosity (0-3)
)
```

## Boas Práticas

1. **Seja Específico**: Forneça instruções detalhadas para melhores resultados
2. **Escolha o Tipo de Comando Apropriado**: Selecione o comando correto para sua tarefa
3. **Use Selectors**: Utilize seletores CSS para aumentar a precisão
4. **Divida Tarefas Complexas**: Separe fluxos de trabalho complexos em múltiplas chamadas da ferramenta
5. **Implemente Tratamento de Erros**: Adicione tratamento de erros para possíveis problemas

## Solução de Problemas

Problemas comuns e soluções:

* **Problemas de Sessão**: Verifique as chaves de API tanto da Browserbase quanto do provedor de LLM
* **Elemento Não Encontrado**: Aumente o `dom_settle_timeout_ms` para páginas mais lentas
* **Falhas em Ações**: Use o `observe` para identificar corretamente os elementos antes
* **Dados Incompletos**: Refine as instruções ou forneça seletores específicos

## Recursos Adicionais

Para dúvidas sobre a integração com o CrewAI:

* Participe da comunidade [Slack do Stagehand](https://stagehand.dev/slack)
* Abra uma issue no [repositório Stagehand](https://github.com/browserbase/stagehand)
* Visite a [documentação do Stagehand](https://docs.stagehand.dev/)
