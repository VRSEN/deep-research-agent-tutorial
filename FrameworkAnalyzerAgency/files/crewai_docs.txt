# Get Execution Status
Source: https://docs.crewai.com/api-reference/get-execution-status

enterprise-api.yaml get /status/{kickoff_id}
**üìã Reference Example Only** - *This shows the request format. To test with your actual crew, copy the cURL example and replace the URL + token with your real values.*

Retrieves the current status and results of a crew execution using its kickoff ID.

The response structure varies depending on the execution state:
- **running**: Execution in progress with current task info
- **completed**: Execution finished with full results
- **error**: Execution failed with error details




# Get Required Inputs
Source: https://docs.crewai.com/api-reference/get-required-inputs

enterprise-api.yaml get /inputs
**üìã Reference Example Only** - *This shows the request format. To test with your actual crew, copy the cURL example and replace the URL + token with your real values.*

Retrieves the list of all required input parameters that your crew expects for execution.
Use this endpoint to discover what inputs you need to provide when starting a crew execution.




# Start Crew Execution
Source: https://docs.crewai.com/api-reference/start-crew-execution

enterprise-api.yaml post /kickoff
**üìã Reference Example Only** - *This shows the request format. To test with your actual crew, copy the cURL example and replace the URL + token with your real values.*

Initiates a new crew execution with the provided inputs. Returns a kickoff ID that can be used
to track the execution progress and retrieve results.

Crew executions can take anywhere from seconds to minutes depending on their complexity.
Consider using webhooks for real-time notifications or implement polling with the status endpoint.




# Introduction
Source: https://docs.crewai.com/en/api-reference/introduction

Complete reference for the CrewAI Enterprise REST API

# CrewAI Enterprise API

Welcome to the CrewAI Enterprise API reference. This API allows you to programmatically interact with your deployed crews, enabling integration with your applications, workflows, and services.

## Quick Start

<Steps>
  <Step title="Get Your API Credentials">
    Navigate to your crew's detail page in the CrewAI Enterprise dashboard and copy your Bearer Token from the Status tab.
  </Step>

  <Step title="Discover Required Inputs">
    Use the `GET /inputs` endpoint to see what parameters your crew expects.
  </Step>

  <Step title="Start a Crew Execution">
    Call `POST /kickoff` with your inputs to start the crew execution and receive a `kickoff_id`.
  </Step>

  <Step title="Monitor Progress">
    Use `GET /status/{kickoff_id}` to check execution status and retrieve results.
  </Step>
</Steps>

## Authentication

All API requests require authentication using a Bearer token. Include your token in the `Authorization` header:

```bash
curl -H "Authorization: Bearer YOUR_CREW_TOKEN" \
  https://your-crew-url.crewai.com/inputs
```

### Token Types

| Token Type            | Scope                     | Use Case                                                     |
| :-------------------- | :------------------------ | :----------------------------------------------------------- |
| **Bearer Token**      | Organization-level access | Full crew operations, ideal for server-to-server integration |
| **User Bearer Token** | User-scoped access        | Limited permissions, suitable for user-specific operations   |

<Tip>
  You can find both token types in the Status tab of your crew's detail page in the CrewAI Enterprise dashboard.
</Tip>

## Base URL

Each deployed crew has its own unique API endpoint:

```
https://your-crew-name.crewai.com
```

Replace `your-crew-name` with your actual crew's URL from the dashboard.

## Typical Workflow

1. **Discovery**: Call `GET /inputs` to understand what your crew needs
2. **Execution**: Submit inputs via `POST /kickoff` to start processing
3. **Monitoring**: Poll `GET /status/{kickoff_id}` until completion
4. **Results**: Extract the final output from the completed response

## Error Handling

The API uses standard HTTP status codes:

| Code  | Meaning                                    |
| ----- | :----------------------------------------- |
| `200` | Success                                    |
| `400` | Bad Request - Invalid input format         |
| `401` | Unauthorized - Invalid bearer token        |
| `404` | Not Found - Resource doesn't exist         |
| `422` | Validation Error - Missing required inputs |
| `500` | Server Error - Contact support             |

## Interactive Testing

<Info>
  **Why no "Send" button?** Since each CrewAI Enterprise user has their own unique crew URL, we use **reference mode** instead of an interactive playground to avoid confusion. This shows you exactly what the requests should look like without non-functional send buttons.
</Info>

Each endpoint page shows you:

* ‚úÖ **Exact request format** with all parameters
* ‚úÖ **Response examples** for success and error cases
* ‚úÖ **Code samples** in multiple languages (cURL, Python, JavaScript, etc.)
* ‚úÖ **Authentication examples** with proper Bearer token format

### **To Test Your Actual API:**

<CardGroup cols={2}>
  <Card title="Copy cURL Examples" icon="terminal">
    Copy the cURL examples and replace the URL + token with your real values
  </Card>

  <Card title="Use Postman/Insomnia" icon="play">
    Import the examples into your preferred API testing tool
  </Card>
</CardGroup>

**Example workflow:**

1. **Copy this cURL example** from any endpoint page
2. **Replace `your-actual-crew-name.crewai.com`** with your real crew URL
3. **Replace the Bearer token** with your real token from the dashboard
4. **Run the request** in your terminal or API client

## Need Help?

<CardGroup cols={2}>
  <Card title="Enterprise Support" icon="headset" href="mailto:support@crewai.com">
    Get help with API integration and troubleshooting
  </Card>

  <Card title="Enterprise Dashboard" icon="chart-line" href="https://app.crewai.com">
    Manage your crews and view execution logs
  </Card>
</CardGroup>


# Agents
Source: https://docs.crewai.com/en/concepts/agents

Detailed guide on creating and managing agents within the CrewAI framework.

## Overview of an Agent

In the CrewAI framework, an `Agent` is an autonomous unit that can:

* Perform specific tasks
* Make decisions based on its role and goal
* Use tools to accomplish objectives
* Communicate and collaborate with other agents
* Maintain memory of interactions
* Delegate tasks when allowed

<Tip>
  Think of an agent as a specialized team member with specific skills, expertise, and responsibilities. For example, a `Researcher` agent might excel at gathering and analyzing information, while a `Writer` agent might be better at creating content.
</Tip>

<Note type="info" title="Enterprise Enhancement: Visual Agent Builder">
  CrewAI Enterprise includes a Visual Agent Builder that simplifies agent creation and configuration without writing code. Design your agents visually and test them in real-time.

  ![Visual Agent Builder Screenshot](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-studio-interface.png)

  The Visual Agent Builder enables:

  * Intuitive agent configuration with form-based interfaces
  * Real-time testing and validation
  * Template library with pre-configured agent types
  * Easy customization of agent attributes and behaviors
</Note>

## Agent Attributes

| Attribute                               | Parameter                | Type                                  | Description                                                                                              |
| :-------------------------------------- | :----------------------- | :------------------------------------ | :------------------------------------------------------------------------------------------------------- |
| **Role**                                | `role`                   | `str`                                 | Defines the agent's function and expertise within the crew.                                              |
| **Goal**                                | `goal`                   | `str`                                 | The individual objective that guides the agent's decision-making.                                        |
| **Backstory**                           | `backstory`              | `str`                                 | Provides context and personality to the agent, enriching interactions.                                   |
| **LLM** *(optional)*                    | `llm`                    | `Union[str, LLM, Any]`                | Language model that powers the agent. Defaults to the model specified in `OPENAI_MODEL_NAME` or "gpt-4". |
| **Tools** *(optional)*                  | `tools`                  | `List[BaseTool]`                      | Capabilities or functions available to the agent. Defaults to an empty list.                             |
| **Function Calling LLM** *(optional)*   | `function_calling_llm`   | `Optional[Any]`                       | Language model for tool calling, overrides crew's LLM if specified.                                      |
| **Max Iterations** *(optional)*         | `max_iter`               | `int`                                 | Maximum iterations before the agent must provide its best answer. Default is 20.                         |
| **Max RPM** *(optional)*                | `max_rpm`                | `Optional[int]`                       | Maximum requests per minute to avoid rate limits.                                                        |
| **Max Execution Time** *(optional)*     | `max_execution_time`     | `Optional[int]`                       | Maximum time (in seconds) for task execution.                                                            |
| **Verbose** *(optional)*                | `verbose`                | `bool`                                | Enable detailed execution logs for debugging. Default is False.                                          |
| **Allow Delegation** *(optional)*       | `allow_delegation`       | `bool`                                | Allow the agent to delegate tasks to other agents. Default is False.                                     |
| **Step Callback** *(optional)*          | `step_callback`          | `Optional[Any]`                       | Function called after each agent step, overrides crew callback.                                          |
| **Cache** *(optional)*                  | `cache`                  | `bool`                                | Enable caching for tool usage. Default is True.                                                          |
| **System Template** *(optional)*        | `system_template`        | `Optional[str]`                       | Custom system prompt template for the agent.                                                             |
| **Prompt Template** *(optional)*        | `prompt_template`        | `Optional[str]`                       | Custom prompt template for the agent.                                                                    |
| **Response Template** *(optional)*      | `response_template`      | `Optional[str]`                       | Custom response template for the agent.                                                                  |
| **Allow Code Execution** *(optional)*   | `allow_code_execution`   | `Optional[bool]`                      | Enable code execution for the agent. Default is False.                                                   |
| **Max Retry Limit** *(optional)*        | `max_retry_limit`        | `int`                                 | Maximum number of retries when an error occurs. Default is 2.                                            |
| **Respect Context Window** *(optional)* | `respect_context_window` | `bool`                                | Keep messages under context window size by summarizing. Default is True.                                 |
| **Code Execution Mode** *(optional)*    | `code_execution_mode`    | `Literal["safe", "unsafe"]`           | Mode for code execution: 'safe' (using Docker) or 'unsafe' (direct). Default is 'safe'.                  |
| **Multimodal** *(optional)*             | `multimodal`             | `bool`                                | Whether the agent supports multimodal capabilities. Default is False.                                    |
| **Inject Date** *(optional)*            | `inject_date`            | `bool`                                | Whether to automatically inject the current date into tasks. Default is False.                           |
| **Date Format** *(optional)*            | `date_format`            | `str`                                 | Format string for date when inject\_date is enabled. Default is "%Y-%m-%d" (ISO format).                 |
| **Reasoning** *(optional)*              | `reasoning`              | `bool`                                | Whether the agent should reflect and create a plan before executing a task. Default is False.            |
| **Max Reasoning Attempts** *(optional)* | `max_reasoning_attempts` | `Optional[int]`                       | Maximum number of reasoning attempts before executing the task. If None, will try until ready.           |
| **Embedder** *(optional)*               | `embedder`               | `Optional[Dict[str, Any]]`            | Configuration for the embedder used by the agent.                                                        |
| **Knowledge Sources** *(optional)*      | `knowledge_sources`      | `Optional[List[BaseKnowledgeSource]]` | Knowledge sources available to the agent.                                                                |
| **Use System Prompt** *(optional)*      | `use_system_prompt`      | `Optional[bool]`                      | Whether to use system prompt (for o1 model support). Default is True.                                    |

## Creating Agents

There are two ways to create agents in CrewAI: using **YAML configuration (recommended)** or defining them **directly in code**.

### YAML Configuration (Recommended)

Using YAML configuration provides a cleaner, more maintainable way to define agents. We strongly recommend using this approach in your CrewAI projects.

After creating your CrewAI project as outlined in the [Installation](/en/installation) section, navigate to the `src/latest_ai_development/config/agents.yaml` file and modify the template to match your requirements.

<Note>
  Variables in your YAML files (like `{topic}`) will be replaced with values from your inputs when running the crew:

  ```python Code
  crew.kickoff(inputs={'topic': 'AI Agents'})
  ```
</Note>

Here's an example of how to configure agents using YAML:

```yaml agents.yaml
# src/latest_ai_development/config/agents.yaml
researcher:
  role: >
    {topic} Senior Data Researcher
  goal: >
    Uncover cutting-edge developments in {topic}
  backstory: >
    You're a seasoned researcher with a knack for uncovering the latest
    developments in {topic}. Known for your ability to find the most relevant
    information and present it in a clear and concise manner.

reporting_analyst:
  role: >
    {topic} Reporting Analyst
  goal: >
    Create detailed reports based on {topic} data analysis and research findings
  backstory: >
    You're a meticulous analyst with a keen eye for detail. You're known for
    your ability to turn complex data into clear and concise reports, making
    it easy for others to understand and act on the information you provide.
```

To use this YAML configuration in your code, create a crew class that inherits from `CrewBase`:

```python Code
# src/latest_ai_development/crew.py
from crewai import Agent, Crew, Process
from crewai.project import CrewBase, agent, crew
from crewai_tools import SerperDevTool

@CrewBase
class LatestAiDevelopmentCrew():
  """LatestAiDevelopment crew"""

  agents_config = "config/agents.yaml"

  @agent
  def researcher(self) -> Agent:
    return Agent(
      config=self.agents_config['researcher'], # type: ignore[index]
      verbose=True,
      tools=[SerperDevTool()]
    )

  @agent
  def reporting_analyst(self) -> Agent:
    return Agent(
      config=self.agents_config['reporting_analyst'], # type: ignore[index]
      verbose=True
    )
```

<Note>
  The names you use in your YAML files (`agents.yaml`) should match the method names in your Python code.
</Note>

### Direct Code Definition

You can create agents directly in code by instantiating the `Agent` class. Here's a comprehensive example showing all available parameters:

```python Code
from crewai import Agent
from crewai_tools import SerperDevTool

# Create an agent with all available parameters
agent = Agent(
    role="Senior Data Scientist",
    goal="Analyze and interpret complex datasets to provide actionable insights",
    backstory="With over 10 years of experience in data science and machine learning, "
              "you excel at finding patterns in complex datasets.",
    llm="gpt-4",  # Default: OPENAI_MODEL_NAME or "gpt-4"
    function_calling_llm=None,  # Optional: Separate LLM for tool calling
    verbose=False,  # Default: False
    allow_delegation=False,  # Default: False
    max_iter=20,  # Default: 20 iterations
    max_rpm=None,  # Optional: Rate limit for API calls
    max_execution_time=None,  # Optional: Maximum execution time in seconds
    max_retry_limit=2,  # Default: 2 retries on error
    allow_code_execution=False,  # Default: False
    code_execution_mode="safe",  # Default: "safe" (options: "safe", "unsafe")
    respect_context_window=True,  # Default: True
    use_system_prompt=True,  # Default: True
    multimodal=False,  # Default: False
    inject_date=False,  # Default: False
    date_format="%Y-%m-%d",  # Default: ISO format
    reasoning=False,  # Default: False
    max_reasoning_attempts=None,  # Default: None
    tools=[SerperDevTool()],  # Optional: List of tools
    knowledge_sources=None,  # Optional: List of knowledge sources
    embedder=None,  # Optional: Custom embedder configuration
    system_template=None,  # Optional: Custom system prompt template
    prompt_template=None,  # Optional: Custom prompt template
    response_template=None,  # Optional: Custom response template
    step_callback=None,  # Optional: Callback function for monitoring
)
```

Let's break down some key parameter combinations for common use cases:

#### Basic Research Agent

```python Code
research_agent = Agent(
    role="Research Analyst",
    goal="Find and summarize information about specific topics",
    backstory="You are an experienced researcher with attention to detail",
    tools=[SerperDevTool()],
    verbose=True  # Enable logging for debugging
)
```

#### Code Development Agent

```python Code
dev_agent = Agent(
    role="Senior Python Developer",
    goal="Write and debug Python code",
    backstory="Expert Python developer with 10 years of experience",
    allow_code_execution=True,
    code_execution_mode="safe",  # Uses Docker for safety
    max_execution_time=300,  # 5-minute timeout
    max_retry_limit=3  # More retries for complex code tasks
)
```

#### Long-Running Analysis Agent

```python Code
analysis_agent = Agent(
    role="Data Analyst",
    goal="Perform deep analysis of large datasets",
    backstory="Specialized in big data analysis and pattern recognition",
    memory=True,
    respect_context_window=True,
    max_rpm=10,  # Limit API calls
    function_calling_llm="gpt-4o-mini"  # Cheaper model for tool calls
)
```

#### Custom Template Agent

```python Code
custom_agent = Agent(
    role="Customer Service Representative",
    goal="Assist customers with their inquiries",
    backstory="Experienced in customer support with a focus on satisfaction",
    system_template="""<|start_header_id|>system<|end_header_id|>
                        {{ .System }}<|eot_id|>""",
    prompt_template="""<|start_header_id|>user<|end_header_id|>
                        {{ .Prompt }}<|eot_id|>""",
    response_template="""<|start_header_id|>assistant<|end_header_id|>
                        {{ .Response }}<|eot_id|>""",
)
```

#### Date-Aware Agent with Reasoning

```python Code
strategic_agent = Agent(
    role="Market Analyst",
    goal="Track market movements with precise date references and strategic planning",
    backstory="Expert in time-sensitive financial analysis and strategic reporting",
    inject_date=True,  # Automatically inject current date into tasks
    date_format="%B %d, %Y",  # Format as "May 21, 2025"
    reasoning=True,  # Enable strategic planning
    max_reasoning_attempts=2,  # Limit planning iterations
    verbose=True
)
```

#### Reasoning Agent

```python Code
reasoning_agent = Agent(
    role="Strategic Planner",
    goal="Analyze complex problems and create detailed execution plans",
    backstory="Expert strategic planner who methodically breaks down complex challenges",
    reasoning=True,  # Enable reasoning and planning
    max_reasoning_attempts=3,  # Limit reasoning attempts
    max_iter=30,  # Allow more iterations for complex planning
    verbose=True
)
```

#### Multimodal Agent

```python Code
multimodal_agent = Agent(
    role="Visual Content Analyst",
    goal="Analyze and process both text and visual content",
    backstory="Specialized in multimodal analysis combining text and image understanding",
    multimodal=True,  # Enable multimodal capabilities
    verbose=True
)
```

### Parameter Details

#### Critical Parameters

* `role`, `goal`, and `backstory` are required and shape the agent's behavior
* `llm` determines the language model used (default: OpenAI's GPT-4)

#### Memory and Context

* `memory`: Enable to maintain conversation history
* `respect_context_window`: Prevents token limit issues
* `knowledge_sources`: Add domain-specific knowledge bases

#### Execution Control

* `max_iter`: Maximum attempts before giving best answer
* `max_execution_time`: Timeout in seconds
* `max_rpm`: Rate limiting for API calls
* `max_retry_limit`: Retries on error

#### Code Execution

* `allow_code_execution`: Must be True to run code
* `code_execution_mode`:
  * `"safe"`: Uses Docker (recommended for production)
  * `"unsafe"`: Direct execution (use only in trusted environments)

<Note>
  This runs a default Docker image. If you want to configure the docker image, the checkout the Code Interpreter Tool in the tools section.
  Add the code interpreter tool as a tool in the agent as a tool parameter.
</Note>

#### Advanced Features

* `multimodal`: Enable multimodal capabilities for processing text and visual content
* `reasoning`: Enable agent to reflect and create plans before executing tasks
* `inject_date`: Automatically inject current date into task descriptions

#### Templates

* `system_template`: Defines agent's core behavior
* `prompt_template`: Structures input format
* `response_template`: Formats agent responses

<Note>
  When using custom templates, ensure that both `system_template` and `prompt_template` are defined. The `response_template` is optional but recommended for consistent output formatting.
</Note>

<Note>
  When using custom templates, you can use variables like `{role}`, `{goal}`, and `{backstory}` in your templates. These will be automatically populated during execution.
</Note>

## Agent Tools

Agents can be equipped with various tools to enhance their capabilities. CrewAI supports tools from:

* [CrewAI Toolkit](https://github.com/joaomdmoura/crewai-tools)
* [LangChain Tools](https://python.langchain.com/docs/integrations/tools)

Here's how to add tools to an agent:

```python Code
from crewai import Agent
from crewai_tools import SerperDevTool, WikipediaTools

# Create tools
search_tool = SerperDevTool()
wiki_tool = WikipediaTools()

# Add tools to agent
researcher = Agent(
    role="AI Technology Researcher",
    goal="Research the latest AI developments",
    tools=[search_tool, wiki_tool],
    verbose=True
)
```

## Agent Memory and Context

Agents can maintain memory of their interactions and use context from previous tasks. This is particularly useful for complex workflows where information needs to be retained across multiple tasks.

```python Code
from crewai import Agent

analyst = Agent(
    role="Data Analyst",
    goal="Analyze and remember complex data patterns",
    memory=True,  # Enable memory
    verbose=True
)
```

<Note>
  When `memory` is enabled, the agent will maintain context across multiple interactions, improving its ability to handle complex, multi-step tasks.
</Note>

## Context Window Management

CrewAI includes sophisticated automatic context window management to handle situations where conversations exceed the language model's token limits. This powerful feature is controlled by the `respect_context_window` parameter.

### How Context Window Management Works

When an agent's conversation history grows too large for the LLM's context window, CrewAI automatically detects this situation and can either:

1. **Automatically summarize content** (when `respect_context_window=True`)
2. **Stop execution with an error** (when `respect_context_window=False`)

### Automatic Context Handling (`respect_context_window=True`)

This is the **default and recommended setting** for most use cases. When enabled, CrewAI will:

```python Code
# Agent with automatic context management (default)
smart_agent = Agent(
    role="Research Analyst",
    goal="Analyze large documents and datasets",
    backstory="Expert at processing extensive information",
    respect_context_window=True,  # üîë Default: auto-handle context limits
    verbose=True
)
```

**What happens when context limits are exceeded:**

* ‚ö†Ô∏è **Warning message**: `"Context length exceeded. Summarizing content to fit the model context window."`
* üîÑ **Automatic summarization**: CrewAI intelligently summarizes the conversation history
* ‚úÖ **Continued execution**: Task execution continues seamlessly with the summarized context
* üìù **Preserved information**: Key information is retained while reducing token count

### Strict Context Limits (`respect_context_window=False`)

When you need precise control and prefer execution to stop rather than lose any information:

```python Code
# Agent with strict context limits
strict_agent = Agent(
    role="Legal Document Reviewer",
    goal="Provide precise legal analysis without information loss",
    backstory="Legal expert requiring complete context for accurate analysis",
    respect_context_window=False,  # ‚ùå Stop execution on context limit
    verbose=True
)
```

**What happens when context limits are exceeded:**

* ‚ùå **Error message**: `"Context length exceeded. Consider using smaller text or RAG tools from crewai_tools."`
* üõë **Execution stops**: Task execution halts immediately
* üîß **Manual intervention required**: You need to modify your approach

### Choosing the Right Setting

#### Use `respect_context_window=True` (Default) when:

* **Processing large documents** that might exceed context limits
* **Long-running conversations** where some summarization is acceptable
* **Research tasks** where general context is more important than exact details
* **Prototyping and development** where you want robust execution

```python Code
# Perfect for document processing
document_processor = Agent(
    role="Document Analyst",
    goal="Extract insights from large research papers",
    backstory="Expert at analyzing extensive documentation",
    respect_context_window=True,  # Handle large documents gracefully
    max_iter=50,  # Allow more iterations for complex analysis
    verbose=True
)
```

#### Use `respect_context_window=False` when:

* **Precision is critical** and information loss is unacceptable
* **Legal or medical tasks** requiring complete context
* **Code review** where missing details could introduce bugs
* **Financial analysis** where accuracy is paramount

```python Code
# Perfect for precision tasks
precision_agent = Agent(
    role="Code Security Auditor",
    goal="Identify security vulnerabilities in code",
    backstory="Security expert requiring complete code context",
    respect_context_window=False,  # Prefer failure over incomplete analysis
    max_retry_limit=1,  # Fail fast on context issues
    verbose=True
)
```

### Alternative Approaches for Large Data

When dealing with very large datasets, consider these strategies:

#### 1. Use RAG Tools

```python Code
from crewai_tools import RagTool

# Create RAG tool for large document processing
rag_tool = RagTool()

rag_agent = Agent(
    role="Research Assistant",
    goal="Query large knowledge bases efficiently",
    backstory="Expert at using RAG tools for information retrieval",
    tools=[rag_tool],  # Use RAG instead of large context windows
    respect_context_window=True,
    verbose=True
)
```

#### 2. Use Knowledge Sources

```python Code
# Use knowledge sources instead of large prompts
knowledge_agent = Agent(
    role="Knowledge Expert",
    goal="Answer questions using curated knowledge",
    backstory="Expert at leveraging structured knowledge sources",
    knowledge_sources=[your_knowledge_sources],  # Pre-processed knowledge
    respect_context_window=True,
    verbose=True
)
```

### Context Window Best Practices

1. **Monitor Context Usage**: Enable `verbose=True` to see context management in action
2. **Design for Efficiency**: Structure tasks to minimize context accumulation
3. **Use Appropriate Models**: Choose LLMs with context windows suitable for your tasks
4. **Test Both Settings**: Try both `True` and `False` to see which works better for your use case
5. **Combine with RAG**: Use RAG tools for very large datasets instead of relying solely on context windows

### Troubleshooting Context Issues

**If you're getting context limit errors:**

```python Code
# Quick fix: Enable automatic handling
agent.respect_context_window = True

# Better solution: Use RAG tools for large data
from crewai_tools import RagTool
agent.tools = [RagTool()]

# Alternative: Break tasks into smaller pieces
# Or use knowledge sources instead of large prompts
```

**If automatic summarization loses important information:**

```python Code
# Disable auto-summarization and use RAG instead
agent = Agent(
    role="Detailed Analyst",
    goal="Maintain complete information accuracy",
    backstory="Expert requiring full context",
    respect_context_window=False,  # No summarization
    tools=[RagTool()],  # Use RAG for large data
    verbose=True
)
```

<Note>
  The context window management feature works automatically in the background. You don't need to call any special functions - just set `respect_context_window` to your preferred behavior and CrewAI handles the rest!
</Note>

## Important Considerations and Best Practices

### Security and Code Execution

* When using `allow_code_execution`, be cautious with user input and always validate it
* Use `code_execution_mode: "safe"` (Docker) in production environments
* Consider setting appropriate `max_execution_time` limits to prevent infinite loops

### Performance Optimization

* Use `respect_context_window: true` to prevent token limit issues
* Set appropriate `max_rpm` to avoid rate limiting
* Enable `cache: true` to improve performance for repetitive tasks
* Adjust `max_iter` and `max_retry_limit` based on task complexity

### Memory and Context Management

* Leverage `knowledge_sources` for domain-specific information
* Configure `embedder` when using custom embedding models
* Use custom templates (`system_template`, `prompt_template`, `response_template`) for fine-grained control over agent behavior

### Advanced Features

* Enable `reasoning: true` for agents that need to plan and reflect before executing complex tasks
* Set appropriate `max_reasoning_attempts` to control planning iterations (None for unlimited attempts)
* Use `inject_date: true` to provide agents with current date awareness for time-sensitive tasks
* Customize the date format with `date_format` using standard Python datetime format codes
* Enable `multimodal: true` for agents that need to process both text and visual content

### Agent Collaboration

* Enable `allow_delegation: true` when agents need to work together
* Use `step_callback` to monitor and log agent interactions
* Consider using different LLMs for different purposes:
  * Main `llm` for complex reasoning
  * `function_calling_llm` for efficient tool usage

### Date Awareness and Reasoning

* Use `inject_date: true` to provide agents with current date awareness for time-sensitive tasks
* Customize the date format with `date_format` using standard Python datetime format codes
* Valid format codes include: %Y (year), %m (month), %d (day), %B (full month name), etc.
* Invalid date formats will be logged as warnings and will not modify the task description
* Enable `reasoning: true` for complex tasks that benefit from upfront planning and reflection

### Model Compatibility

* Set `use_system_prompt: false` for older models that don't support system messages
* Ensure your chosen `llm` supports the features you need (like function calling)

## Troubleshooting Common Issues

1. **Rate Limiting**: If you're hitting API rate limits:
   * Implement appropriate `max_rpm`
   * Use caching for repetitive operations
   * Consider batching requests

2. **Context Window Errors**: If you're exceeding context limits:
   * Enable `respect_context_window`
   * Use more efficient prompts
   * Clear agent memory periodically

3. **Code Execution Issues**: If code execution fails:
   * Verify Docker is installed for safe mode
   * Check execution permissions
   * Review code sandbox settings

4. **Memory Issues**: If agent responses seem inconsistent:
   * Check knowledge source configuration
   * Review conversation history management

Remember that agents are most effective when configured according to their specific use case. Take time to understand your requirements and adjust these parameters accordingly.


# CLI
Source: https://docs.crewai.com/en/concepts/cli

Learn how to use the CrewAI CLI to interact with CrewAI.

<Warning>Since release 0.140.0, CrewAI Enterprise started a process of migrating their login provider. As such, the authentication flow via CLI was updated. Users that use Google to login, or that created their account after July 3rd, 2025 will be unable to log in with older versions of the `crewai` library.</Warning>

## Overview

The CrewAI CLI provides a set of commands to interact with CrewAI, allowing you to create, train, run, and manage crews & flows.

## Installation

To use the CrewAI CLI, make sure you have CrewAI installed:

```shell Terminal
pip install crewai
```

## Basic Usage

The basic structure of a CrewAI CLI command is:

```shell Terminal
crewai [COMMAND] [OPTIONS] [ARGUMENTS]
```

## Available Commands

### 1. Create

Create a new crew or flow.

```shell Terminal
crewai create [OPTIONS] TYPE NAME
```

* `TYPE`: Choose between "crew" or "flow"
* `NAME`: Name of the crew or flow

Example:

```shell Terminal
crewai create crew my_new_crew
crewai create flow my_new_flow
```

### 2. Version

Show the installed version of CrewAI.

```shell Terminal
crewai version [OPTIONS]
```

* `--tools`: (Optional) Show the installed version of CrewAI tools

Example:

```shell Terminal
crewai version
crewai version --tools
```

### 3. Train

Train the crew for a specified number of iterations.

```shell Terminal
crewai train [OPTIONS]
```

* `-n, --n_iterations INTEGER`: Number of iterations to train the crew (default: 5)
* `-f, --filename TEXT`: Path to a custom file for training (default: "trained\_agents\_data.pkl")

Example:

```shell Terminal
crewai train -n 10 -f my_training_data.pkl
```

### 4. Replay

Replay the crew execution from a specific task.

```shell Terminal
crewai replay [OPTIONS]
```

* `-t, --task_id TEXT`: Replay the crew from this task ID, including all subsequent tasks

Example:

```shell Terminal
crewai replay -t task_123456
```

### 5. Log-tasks-outputs

Retrieve your latest crew\.kickoff() task outputs.

```shell Terminal
crewai log-tasks-outputs
```

### 6. Reset-memories

Reset the crew memories (long, short, entity, latest\_crew\_kickoff\_outputs).

```shell Terminal
crewai reset-memories [OPTIONS]
```

* `-l, --long`: Reset LONG TERM memory
* `-s, --short`: Reset SHORT TERM memory
* `-e, --entities`: Reset ENTITIES memory
* `-k, --kickoff-outputs`: Reset LATEST KICKOFF TASK OUTPUTS
* `-kn, --knowledge`: Reset KNOWLEDGE storage
* `-akn, --agent-knowledge`: Reset AGENT KNOWLEDGE storage
* `-a, --all`: Reset ALL memories

Example:

```shell Terminal
crewai reset-memories --long --short
crewai reset-memories --all
```

### 7. Test

Test the crew and evaluate the results.

```shell Terminal
crewai test [OPTIONS]
```

* `-n, --n_iterations INTEGER`: Number of iterations to test the crew (default: 3)
* `-m, --model TEXT`: LLM Model to run the tests on the Crew (default: "gpt-4o-mini")

Example:

```shell Terminal
crewai test -n 5 -m gpt-3.5-turbo
```

### 8. Run

Run the crew or flow.

```shell Terminal
crewai run
```

<Note>
  Starting from version 0.103.0, the `crewai run` command can be used to run both standard crews and flows. For flows, it automatically detects the type from pyproject.toml and runs the appropriate command. This is now the recommended way to run both crews and flows.
</Note>

<Note>
  Make sure to run these commands from the directory where your CrewAI project is set up.
  Some commands may require additional configuration or setup within your project structure.
</Note>

### 9. Chat

Starting in version `0.98.0`, when you run the `crewai chat` command, you start an interactive session with your crew. The AI assistant will guide you by asking for necessary inputs to execute the crew. Once all inputs are provided, the crew will execute its tasks.

After receiving the results, you can continue interacting with the assistant for further instructions or questions.

```shell Terminal
crewai chat
```

<Note>
  Ensure you execute these commands from your CrewAI project's root directory.
</Note>

<Note>
  IMPORTANT: Set the `chat_llm` property in your `crew.py` file to enable this command.

  ```python
  @crew
  def crew(self) -> Crew:
      return Crew(
          agents=self.agents,
          tasks=self.tasks,
          process=Process.sequential,
          verbose=True,
          chat_llm="gpt-4o",  # LLM for chat orchestration
      )
  ```
</Note>

### 10. Deploy

Deploy the crew or flow to [CrewAI Enterprise](https://app.crewai.com).

* **Authentication**: You need to be authenticated to deploy to CrewAI Enterprise.
  You can login or create an account with:
  ```shell Terminal
  crewai login
  ```

* **Create a deployment**: Once you are authenticated, you can create a deployment for your crew or flow from the root of your localproject.
  ```shell Terminal
  crewai deploy create
  ```
  * Reads your local project configuration.
  * Prompts you to confirm the environment variables (like `OPENAI_API_KEY`, `SERPER_API_KEY`) found locally. These will be securely stored with the deployment on the Enterprise platform. Ensure your sensitive keys are correctly configured locally (e.g., in a `.env` file) before running this.

### 11. Organization Management

Manage your CrewAI Enterprise organizations.

```shell Terminal
crewai org [COMMAND] [OPTIONS]
```

#### Commands:

* `list`: List all organizations you belong to

```shell Terminal
crewai org list
```

* `current`: Display your currently active organization

```shell Terminal
crewai org current
```

* `switch`: Switch to a specific organization

```shell Terminal
crewai org switch <organization_id>
```

<Note>
  You must be authenticated to CrewAI Enterprise to use these organization management commands.
</Note>

* **Create a deployment** (continued):
  * Links the deployment to the corresponding remote GitHub repository (it usually detects this automatically).

* **Deploy the Crew**: Once you are authenticated, you can deploy your crew or flow to CrewAI Enterprise.
  ```shell Terminal
  crewai deploy push
  ```
  * Initiates the deployment process on the CrewAI Enterprise platform.
  * Upon successful initiation, it will output the Deployment created successfully! message along with the Deployment Name and a unique Deployment ID (UUID).

* **Deployment Status**: You can check the status of your deployment with:
  ```shell Terminal
  crewai deploy status
  ```
  This fetches the latest deployment status of your most recent deployment attempt (e.g., `Building Images for Crew`, `Deploy Enqueued`, `Online`).

* **Deployment Logs**: You can check the logs of your deployment with:
  ```shell Terminal
  crewai deploy logs
  ```
  This streams the deployment logs to your terminal.

* **List deployments**: You can list all your deployments with:
  ```shell Terminal
  crewai deploy list
  ```
  This lists all your deployments.

* **Delete a deployment**: You can delete a deployment with:
  ```shell Terminal
  crewai deploy remove
  ```
  This deletes the deployment from the CrewAI Enterprise platform.

* **Help Command**: You can get help with the CLI with:
  ```shell Terminal
  crewai deploy --help
  ```
  This shows the help message for the CrewAI Deploy CLI.

Watch this video tutorial for a step-by-step demonstration of deploying your crew to [CrewAI Enterprise](http://app.crewai.com) using the CLI.

<iframe width="100%" height="400" src="https://www.youtube.com/embed/3EqSV-CYDZA" title="CrewAI Deployment Guide" frameborder="0" style={{ borderRadius: '10px' }} allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

### 11. API Keys

When running `crewai create crew` command, the CLI will show you a list of available LLM providers to choose from, followed by model selection for your chosen provider.

Once you've selected an LLM provider and model, you will be prompted for API keys.

#### Available LLM Providers

Here's a list of the most popular LLM providers suggested by the CLI:

* OpenAI
* Groq
* Anthropic
* Google Gemini
* SambaNova

When you select a provider, the CLI will then show you available models for that provider and prompt you to enter your API key.

#### Other Options

If you select "other", you will be able to select from a list of LiteLLM supported providers.

When you select a provider, the CLI will prompt you to enter the Key name and the API key.

See the following link for each provider's key name:

* [LiteLLM Providers](https://docs.litellm.ai/docs/providers)


# Collaboration
Source: https://docs.crewai.com/en/concepts/collaboration

How to enable agents to work together, delegate tasks, and communicate effectively within CrewAI teams.

## Overview

Collaboration in CrewAI enables agents to work together as a team by delegating tasks and asking questions to leverage each other's expertise. When `allow_delegation=True`, agents automatically gain access to powerful collaboration tools.

## Quick Start: Enable Collaboration

```python
from crewai import Agent, Crew, Task

# Enable collaboration for agents
researcher = Agent(
    role="Research Specialist",
    goal="Conduct thorough research on any topic",
    backstory="Expert researcher with access to various sources",
    allow_delegation=True,  # üîë Key setting for collaboration
    verbose=True
)

writer = Agent(
    role="Content Writer",
    goal="Create engaging content based on research",
    backstory="Skilled writer who transforms research into compelling content",
    allow_delegation=True,  # üîë Enables asking questions to other agents
    verbose=True
)

# Agents can now collaborate automatically
crew = Crew(
    agents=[researcher, writer],
    tasks=[...],
    verbose=True
)
```

## How Agent Collaboration Works

When `allow_delegation=True`, CrewAI automatically provides agents with two powerful tools:

### 1. **Delegate Work Tool**

Allows agents to assign tasks to teammates with specific expertise.

```python
# Agent automatically gets this tool:
# Delegate work to coworker(task: str, context: str, coworker: str)
```

### 2. **Ask Question Tool**

Enables agents to ask specific questions to gather information from colleagues.

```python
# Agent automatically gets this tool:
# Ask question to coworker(question: str, context: str, coworker: str)
```

## Collaboration in Action

Here's a complete example showing agents collaborating on a content creation task:

```python
from crewai import Agent, Crew, Task, Process

# Create collaborative agents
researcher = Agent(
    role="Research Specialist",
    goal="Find accurate, up-to-date information on any topic",
    backstory="""You're a meticulous researcher with expertise in finding
    reliable sources and fact-checking information across various domains.""",
    allow_delegation=True,
    verbose=True
)

writer = Agent(
    role="Content Writer",
    goal="Create engaging, well-structured content",
    backstory="""You're a skilled content writer who excels at transforming
    research into compelling, readable content for different audiences.""",
    allow_delegation=True,
    verbose=True
)

editor = Agent(
    role="Content Editor",
    goal="Ensure content quality and consistency",
    backstory="""You're an experienced editor with an eye for detail,
    ensuring content meets high standards for clarity and accuracy.""",
    allow_delegation=True,
    verbose=True
)

# Create a task that encourages collaboration
article_task = Task(
    description="""Write a comprehensive 1000-word article about 'The Future of AI in Healthcare'.

    The article should include:
    - Current AI applications in healthcare
    - Emerging trends and technologies
    - Potential challenges and ethical considerations
    - Expert predictions for the next 5 years

    Collaborate with your teammates to ensure accuracy and quality.""",
    expected_output="A well-researched, engaging 1000-word article with proper structure and citations",
    agent=writer  # Writer leads, but can delegate research to researcher
)

# Create collaborative crew
crew = Crew(
    agents=[researcher, writer, editor],
    tasks=[article_task],
    process=Process.sequential,
    verbose=True
)

result = crew.kickoff()
```

## Collaboration Patterns

### Pattern 1: Research ‚Üí Write ‚Üí Edit

```python
research_task = Task(
    description="Research the latest developments in quantum computing",
    expected_output="Comprehensive research summary with key findings and sources",
    agent=researcher
)

writing_task = Task(
    description="Write an article based on the research findings",
    expected_output="Engaging 800-word article about quantum computing",
    agent=writer,
    context=[research_task]  # Gets research output as context
)

editing_task = Task(
    description="Edit and polish the article for publication",
    expected_output="Publication-ready article with improved clarity and flow",
    agent=editor,
    context=[writing_task]  # Gets article draft as context
)
```

### Pattern 2: Collaborative Single Task

```python
collaborative_task = Task(
    description="""Create a marketing strategy for a new AI product.

    Writer: Focus on messaging and content strategy
    Researcher: Provide market analysis and competitor insights

    Work together to create a comprehensive strategy.""",
    expected_output="Complete marketing strategy with research backing",
    agent=writer  # Lead agent, but can delegate to researcher
)
```

## Hierarchical Collaboration

For complex projects, use a hierarchical process with a manager agent:

```python
from crewai import Agent, Crew, Task, Process

# Manager agent coordinates the team
manager = Agent(
    role="Project Manager",
    goal="Coordinate team efforts and ensure project success",
    backstory="Experienced project manager skilled at delegation and quality control",
    allow_delegation=True,
    verbose=True
)

# Specialist agents
researcher = Agent(
    role="Researcher",
    goal="Provide accurate research and analysis",
    backstory="Expert researcher with deep analytical skills",
    allow_delegation=False,  # Specialists focus on their expertise
    verbose=True
)

writer = Agent(
    role="Writer",
    goal="Create compelling content",
    backstory="Skilled writer who creates engaging content",
    allow_delegation=False,
    verbose=True
)

# Manager-led task
project_task = Task(
    description="Create a comprehensive market analysis report with recommendations",
    expected_output="Executive summary, detailed analysis, and strategic recommendations",
    agent=manager  # Manager will delegate to specialists
)

# Hierarchical crew
crew = Crew(
    agents=[manager, researcher, writer],
    tasks=[project_task],
    process=Process.hierarchical,  # Manager coordinates everything
    manager_llm="gpt-4o",  # Specify LLM for manager
    verbose=True
)
```

## Best Practices for Collaboration

### 1. **Clear Role Definition**

```python
# ‚úÖ Good: Specific, complementary roles
researcher = Agent(role="Market Research Analyst", ...)
writer = Agent(role="Technical Content Writer", ...)

# ‚ùå Avoid: Overlapping or vague roles
agent1 = Agent(role="General Assistant", ...)
agent2 = Agent(role="Helper", ...)
```

### 2. **Strategic Delegation Enabling**

```python
# ‚úÖ Enable delegation for coordinators and generalists
lead_agent = Agent(
    role="Content Lead",
    allow_delegation=True,  # Can delegate to specialists
    ...
)

# ‚úÖ Disable for focused specialists (optional)
specialist_agent = Agent(
    role="Data Analyst",
    allow_delegation=False,  # Focuses on core expertise
    ...
)
```

### 3. **Context Sharing**

```python
# ‚úÖ Use context parameter for task dependencies
writing_task = Task(
    description="Write article based on research",
    agent=writer,
    context=[research_task],  # Shares research results
    ...
)
```

### 4. **Clear Task Descriptions**

```python
# ‚úÖ Specific, actionable descriptions
Task(
    description="""Research competitors in the AI chatbot space.
    Focus on: pricing models, key features, target markets.
    Provide data in a structured format.""",
    ...
)

# ‚ùå Vague descriptions that don't guide collaboration
Task(description="Do some research about chatbots", ...)
```

## Troubleshooting Collaboration

### Issue: Agents Not Collaborating

**Symptoms:** Agents work in isolation, no delegation occurs

```python
# ‚úÖ Solution: Ensure delegation is enabled
agent = Agent(
    role="...",
    allow_delegation=True,  # This is required!
    ...
)
```

### Issue: Too Much Back-and-Forth

**Symptoms:** Agents ask excessive questions, slow progress

```python
# ‚úÖ Solution: Provide better context and specific roles
Task(
    description="""Write a technical blog post about machine learning.

    Context: Target audience is software developers with basic ML knowledge.
    Length: 1200 words
    Include: code examples, practical applications, best practices

    If you need specific technical details, delegate research to the researcher.""",
    ...
)
```

### Issue: Delegation Loops

**Symptoms:** Agents delegate back and forth indefinitely

```python
# ‚úÖ Solution: Clear hierarchy and responsibilities
manager = Agent(role="Manager", allow_delegation=True)
specialist1 = Agent(role="Specialist A", allow_delegation=False)  # No re-delegation
specialist2 = Agent(role="Specialist B", allow_delegation=False)
```

## Advanced Collaboration Features

### Custom Collaboration Rules

```python
# Set specific collaboration guidelines in agent backstory
agent = Agent(
    role="Senior Developer",
    backstory="""You lead development projects and coordinate with team members.

    Collaboration guidelines:
    - Delegate research tasks to the Research Analyst
    - Ask the Designer for UI/UX guidance
    - Consult the QA Engineer for testing strategies
    - Only escalate blocking issues to the Project Manager""",
    allow_delegation=True
)
```

### Monitoring Collaboration

```python
def track_collaboration(output):
    """Track collaboration patterns"""
    if "Delegate work to coworker" in output.raw:
        print("ü§ù Delegation occurred")
    if "Ask question to coworker" in output.raw:
        print("‚ùì Question asked")

crew = Crew(
    agents=[...],
    tasks=[...],
    step_callback=track_collaboration,  # Monitor collaboration
    verbose=True
)
```

## Memory and Learning

Enable agents to remember past collaborations:

```python
agent = Agent(
    role="Content Lead",
    memory=True,  # Remembers past interactions
    allow_delegation=True,
    verbose=True
)
```

With memory enabled, agents learn from previous collaborations and improve their delegation decisions over time.

## Next Steps

* **Try the examples**: Start with the basic collaboration example
* **Experiment with roles**: Test different agent role combinations
* **Monitor interactions**: Use `verbose=True` to see collaboration in action
* **Optimize task descriptions**: Clear tasks lead to better collaboration
* **Scale up**: Try hierarchical processes for complex projects

Collaboration transforms individual AI agents into powerful teams that can tackle complex, multi-faceted challenges together.


# Crews
Source: https://docs.crewai.com/en/concepts/crews

Understanding and utilizing crews in the crewAI framework with comprehensive attributes and functionalities.

## Overview

A crew in crewAI represents a collaborative group of agents working together to achieve a set of tasks. Each crew defines the strategy for task execution, agent collaboration, and the overall workflow.

## Crew Attributes

| Attribute                             | Parameters             | Description                                                                                                                                                                                           |
| :------------------------------------ | :--------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Tasks**                             | `tasks`                | A list of tasks assigned to the crew.                                                                                                                                                                 |
| **Agents**                            | `agents`               | A list of agents that are part of the crew.                                                                                                                                                           |
| **Process** *(optional)*              | `process`              | The process flow (e.g., sequential, hierarchical) the crew follows. Default is `sequential`.                                                                                                          |
| **Verbose** *(optional)*              | `verbose`              | The verbosity level for logging during execution. Defaults to `False`.                                                                                                                                |
| **Manager LLM** *(optional)*          | `manager_llm`          | The language model used by the manager agent in a hierarchical process. **Required when using a hierarchical process.**                                                                               |
| **Function Calling LLM** *(optional)* | `function_calling_llm` | If passed, the crew will use this LLM to do function calling for tools for all agents in the crew. Each agent can have its own LLM, which overrides the crew's LLM for function calling.              |
| **Config** *(optional)*               | `config`               | Optional configuration settings for the crew, in `Json` or `Dict[str, Any]` format.                                                                                                                   |
| **Max RPM** *(optional)*              | `max_rpm`              | Maximum requests per minute the crew adheres to during execution. Defaults to `None`.                                                                                                                 |
| **Memory** *(optional)*               | `memory`               | Utilized for storing execution memories (short-term, long-term, entity memory).                                                                                                                       |
| **Memory Config** *(optional)*        | `memory_config`        | Configuration for the memory provider to be used by the crew.                                                                                                                                         |
| **Cache** *(optional)*                | `cache`                | Specifies whether to use a cache for storing the results of tools' execution. Defaults to `True`.                                                                                                     |
| **Embedder** *(optional)*             | `embedder`             | Configuration for the embedder to be used by the crew. Mostly used by memory for now. Default is `{"provider": "openai"}`.                                                                            |
| **Step Callback** *(optional)*        | `step_callback`        | A function that is called after each step of every agent. This can be used to log the agent's actions or to perform other operations; it won't override the agent-specific `step_callback`.           |
| **Task Callback** *(optional)*        | `task_callback`        | A function that is called after the completion of each task. Useful for monitoring or additional operations post-task execution.                                                                      |
| **Share Crew** *(optional)*           | `share_crew`           | Whether you want to share the complete crew information and execution with the crewAI team to make the library better, and allow us to train models.                                                  |
| **Output Log File** *(optional)*      | `output_log_file`      | Set to True to save logs as logs.txt in the current directory or provide a file path. Logs will be in JSON format if the filename ends in .json, otherwise .txt. Defaults to `None`.                  |
| **Manager Agent** *(optional)*        | `manager_agent`        | `manager` sets a custom agent that will be used as a manager.                                                                                                                                         |
| **Prompt File** *(optional)*          | `prompt_file`          | Path to the prompt JSON file to be used for the crew.                                                                                                                                                 |
| **Planning** *(optional)*             | `planning`             | Adds planning ability to the Crew. When activated before each Crew iteration, all Crew data is sent to an AgentPlanner that will plan the tasks and this plan will be added to each task description. |
| **Planning LLM** *(optional)*         | `planning_llm`         | The language model used by the AgentPlanner in a planning process.                                                                                                                                    |

<Tip>
  **Crew Max RPM**: The `max_rpm` attribute sets the maximum number of requests per minute the crew can perform to avoid rate limits and will override individual agents' `max_rpm` settings if you set it.
</Tip>

## Creating Crews

There are two ways to create crews in CrewAI: using **YAML configuration (recommended)** or defining them **directly in code**.

### YAML Configuration (Recommended)

Using YAML configuration provides a cleaner, more maintainable way to define crews and is consistent with how agents and tasks are defined in CrewAI projects.

After creating your CrewAI project as outlined in the [Installation](/en/installation) section, you can define your crew in a class that inherits from `CrewBase` and uses decorators to define agents, tasks, and the crew itself.

#### Example Crew Class with Decorators

```python code
from crewai import Agent, Crew, Task, Process
from crewai.project import CrewBase, agent, task, crew, before_kickoff, after_kickoff
from crewai.agents.agent_builder.base_agent import BaseAgent
from typing import List

@CrewBase
class YourCrewName:
    """Description of your crew"""

    agents: List[BaseAgent]
    tasks: List[Task]

    # Paths to your YAML configuration files
    # To see an example agent and task defined in YAML, checkout the following:
    # - Task: https://docs.crewai.com/concepts/tasks#yaml-configuration-recommended
    # - Agents: https://docs.crewai.com/concepts/agents#yaml-configuration-recommended
    agents_config = 'config/agents.yaml'
    tasks_config = 'config/tasks.yaml'

    @before_kickoff
    def prepare_inputs(self, inputs):
        # Modify inputs before the crew starts
        inputs['additional_data'] = "Some extra information"
        return inputs

    @after_kickoff
    def process_output(self, output):
        # Modify output after the crew finishes
        output.raw += "\nProcessed after kickoff."
        return output

    @agent
    def agent_one(self) -> Agent:
        return Agent(
            config=self.agents_config['agent_one'], # type: ignore[index]
            verbose=True
        )

    @agent
    def agent_two(self) -> Agent:
        return Agent(
            config=self.agents_config['agent_two'], # type: ignore[index]
            verbose=True
        )

    @task
    def task_one(self) -> Task:
        return Task(
            config=self.tasks_config['task_one'] # type: ignore[index]
        )

    @task
    def task_two(self) -> Task:
        return Task(
            config=self.tasks_config['task_two'] # type: ignore[index]
        )

    @crew
    def crew(self) -> Crew:
        return Crew(
            agents=self.agents,  # Automatically collected by the @agent decorator
            tasks=self.tasks,    # Automatically collected by the @task decorator.
            process=Process.sequential,
            verbose=True,
        )
```

How to run the above code:

```python code
YourCrewName().crew().kickoff(inputs={"any": "input here"})
```

<Note>
  Tasks will be executed in the order they are defined.
</Note>

The `CrewBase` class, along with these decorators, automates the collection of agents and tasks, reducing the need for manual management.

#### Decorators overview from `annotations.py`

CrewAI provides several decorators in the `annotations.py` file that are used to mark methods within your crew class for special handling:

* `@CrewBase`: Marks the class as a crew base class.
* `@agent`: Denotes a method that returns an `Agent` object.
* `@task`: Denotes a method that returns a `Task` object.
* `@crew`: Denotes the method that returns the `Crew` object.
* `@before_kickoff`: (Optional) Marks a method to be executed before the crew starts.
* `@after_kickoff`: (Optional) Marks a method to be executed after the crew finishes.

These decorators help in organizing your crew's structure and automatically collecting agents and tasks without manually listing them.

### Direct Code Definition (Alternative)

Alternatively, you can define the crew directly in code without using YAML configuration files.

```python code
from crewai import Agent, Crew, Task, Process
from crewai_tools import YourCustomTool

class YourCrewName:
    def agent_one(self) -> Agent:
        return Agent(
            role="Data Analyst",
            goal="Analyze data trends in the market",
            backstory="An experienced data analyst with a background in economics",
            verbose=True,
            tools=[YourCustomTool()]
        )

    def agent_two(self) -> Agent:
        return Agent(
            role="Market Researcher",
            goal="Gather information on market dynamics",
            backstory="A diligent researcher with a keen eye for detail",
            verbose=True
        )

    def task_one(self) -> Task:
        return Task(
            description="Collect recent market data and identify trends.",
            expected_output="A report summarizing key trends in the market.",
            agent=self.agent_one()
        )

    def task_two(self) -> Task:
        return Task(
            description="Research factors affecting market dynamics.",
            expected_output="An analysis of factors influencing the market.",
            agent=self.agent_two()
        )

    def crew(self) -> Crew:
        return Crew(
            agents=[self.agent_one(), self.agent_two()],
            tasks=[self.task_one(), self.task_two()],
            process=Process.sequential,
            verbose=True
        )
```

How to run the above code:

```python code
YourCrewName().crew().kickoff(inputs={})
```

In this example:

* Agents and tasks are defined directly within the class without decorators.
* We manually create and manage the list of agents and tasks.
* This approach provides more control but can be less maintainable for larger projects.

## Crew Output

The output of a crew in the CrewAI framework is encapsulated within the `CrewOutput` class.
This class provides a structured way to access results of the crew's execution, including various formats such as raw strings, JSON, and Pydantic models.
The `CrewOutput` includes the results from the final task output, token usage, and individual task outputs.

### Crew Output Attributes

| Attribute        | Parameters     | Type                       | Description                                                                                          |
| :--------------- | :------------- | :------------------------- | :--------------------------------------------------------------------------------------------------- |
| **Raw**          | `raw`          | `str`                      | The raw output of the crew. This is the default format for the output.                               |
| **Pydantic**     | `pydantic`     | `Optional[BaseModel]`      | A Pydantic model object representing the structured output of the crew.                              |
| **JSON Dict**    | `json_dict`    | `Optional[Dict[str, Any]]` | A dictionary representing the JSON output of the crew.                                               |
| **Tasks Output** | `tasks_output` | `List[TaskOutput]`         | A list of `TaskOutput` objects, each representing the output of a task in the crew.                  |
| **Token Usage**  | `token_usage`  | `Dict[str, Any]`           | A summary of token usage, providing insights into the language model's performance during execution. |

### Crew Output Methods and Properties

| Method/Property | Description                                                                                       |
| :-------------- | :------------------------------------------------------------------------------------------------ |
| **json**        | Returns the JSON string representation of the crew output if the output format is JSON.           |
| **to\_dict**    | Converts the JSON and Pydantic outputs to a dictionary.                                           |
| \***\*str\*\*** | Returns the string representation of the crew output, prioritizing Pydantic, then JSON, then raw. |

### Accessing Crew Outputs

Once a crew has been executed, its output can be accessed through the `output` attribute of the `Crew` object. The `CrewOutput` class provides various ways to interact with and present this output.

#### Example

```python Code
# Example crew execution
crew = Crew(
    agents=[research_agent, writer_agent],
    tasks=[research_task, write_article_task],
    verbose=True
)

crew_output = crew.kickoff()

# Accessing the crew output
print(f"Raw Output: {crew_output.raw}")
if crew_output.json_dict:
    print(f"JSON Output: {json.dumps(crew_output.json_dict, indent=2)}")
if crew_output.pydantic:
    print(f"Pydantic Output: {crew_output.pydantic}")
print(f"Tasks Output: {crew_output.tasks_output}")
print(f"Token Usage: {crew_output.token_usage}")
```

## Accessing Crew Logs

You can see real time log of the crew execution, by setting `output_log_file` as a `True(Boolean)` or a `file_name(str)`. Supports logging of events as both `file_name.txt` and `file_name.json`.
In case of `True(Boolean)` will save as `logs.txt`.

In case of `output_log_file` is set as `False(Boolean)` or `None`, the logs will not be populated.

```python Code
# Save crew logs
crew = Crew(output_log_file = True)  # Logs will be saved as logs.txt
crew = Crew(output_log_file = file_name)  # Logs will be saved as file_name.txt
crew = Crew(output_log_file = file_name.txt)  # Logs will be saved as file_name.txt
crew = Crew(output_log_file = file_name.json)  # Logs will be saved as file_name.json
```

## Memory Utilization

Crews can utilize memory (short-term, long-term, and entity memory) to enhance their execution and learning over time. This feature allows crews to store and recall execution memories, aiding in decision-making and task execution strategies.

## Cache Utilization

Caches can be employed to store the results of tools' execution, making the process more efficient by reducing the need to re-execute identical tasks.

## Crew Usage Metrics

After the crew execution, you can access the `usage_metrics` attribute to view the language model (LLM) usage metrics for all tasks executed by the crew. This provides insights into operational efficiency and areas for improvement.

```python Code
# Access the crew's usage metrics
crew = Crew(agents=[agent1, agent2], tasks=[task1, task2])
crew.kickoff()
print(crew.usage_metrics)
```

## Crew Execution Process

* **Sequential Process**: Tasks are executed one after another, allowing for a linear flow of work.
* **Hierarchical Process**: A manager agent coordinates the crew, delegating tasks and validating outcomes before proceeding. **Note**: A `manager_llm` or `manager_agent` is required for this process and it's essential for validating the process flow.

### Kicking Off a Crew

Once your crew is assembled, initiate the workflow with the `kickoff()` method. This starts the execution process according to the defined process flow.

```python Code
# Start the crew's task execution
result = my_crew.kickoff()
print(result)
```

### Different Ways to Kick Off a Crew

Once your crew is assembled, initiate the workflow with the appropriate kickoff method. CrewAI provides several methods for better control over the kickoff process: `kickoff()`, `kickoff_for_each()`, `kickoff_async()`, and `kickoff_for_each_async()`.

* `kickoff()`: Starts the execution process according to the defined process flow.
* `kickoff_for_each()`: Executes tasks sequentially for each provided input event or item in the collection.
* `kickoff_async()`: Initiates the workflow asynchronously.
* `kickoff_for_each_async()`: Executes tasks concurrently for each provided input event or item, leveraging asynchronous processing.

```python Code
# Start the crew's task execution
result = my_crew.kickoff()
print(result)

# Example of using kickoff_for_each
inputs_array = [{'topic': 'AI in healthcare'}, {'topic': 'AI in finance'}]
results = my_crew.kickoff_for_each(inputs=inputs_array)
for result in results:
    print(result)

# Example of using kickoff_async
inputs = {'topic': 'AI in healthcare'}
async_result = await my_crew.kickoff_async(inputs=inputs)
print(async_result)

# Example of using kickoff_for_each_async
inputs_array = [{'topic': 'AI in healthcare'}, {'topic': 'AI in finance'}]
async_results = await my_crew.kickoff_for_each_async(inputs=inputs_array)
for async_result in async_results:
    print(async_result)
```

These methods provide flexibility in how you manage and execute tasks within your crew, allowing for both synchronous and asynchronous workflows tailored to your needs.

### Replaying from a Specific Task

You can now replay from a specific task using our CLI command `replay`.

The replay feature in CrewAI allows you to replay from a specific task using the command-line interface (CLI). By running the command `crewai replay -t <task_id>`, you can specify the `task_id` for the replay process.

Kickoffs will now save the latest kickoffs returned task outputs locally for you to be able to replay from.

### Replaying from a Specific Task Using the CLI

To use the replay feature, follow these steps:

1. Open your terminal or command prompt.
2. Navigate to the directory where your CrewAI project is located.
3. Run the following command:

To view the latest kickoff task IDs, use:

```shell
crewai log-tasks-outputs
```

Then, to replay from a specific task, use:

```shell
crewai replay -t <task_id>
```

These commands let you replay from your latest kickoff tasks, still retaining context from previously executed tasks.


# Event Listeners
Source: https://docs.crewai.com/en/concepts/event-listener

Tap into CrewAI events to build custom integrations and monitoring

## Overview

CrewAI provides a powerful event system that allows you to listen for and react to various events that occur during the execution of your Crew. This feature enables you to build custom integrations, monitoring solutions, logging systems, or any other functionality that needs to be triggered based on CrewAI's internal events.

## How It Works

CrewAI uses an event bus architecture to emit events throughout the execution lifecycle. The event system is built on the following components:

1. **CrewAIEventsBus**: A singleton event bus that manages event registration and emission
2. **BaseEvent**: Base class for all events in the system
3. **BaseEventListener**: Abstract base class for creating custom event listeners

When specific actions occur in CrewAI (like a Crew starting execution, an Agent completing a task, or a tool being used), the system emits corresponding events. You can register handlers for these events to execute custom code when they occur.

<Note type="info" title="Enterprise Enhancement: Prompt Tracing">
  CrewAI Enterprise provides a built-in Prompt Tracing feature that leverages the event system to track, store, and visualize all prompts, completions, and associated metadata. This provides powerful debugging capabilities and transparency into your agent operations.

  ![Prompt Tracing Dashboard](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/traces-overview.png)

  With Prompt Tracing you can:

  * View the complete history of all prompts sent to your LLM
  * Track token usage and costs
  * Debug agent reasoning failures
  * Share prompt sequences with your team
  * Compare different prompt strategies
  * Export traces for compliance and auditing
</Note>

## Creating a Custom Event Listener

To create a custom event listener, you need to:

1. Create a class that inherits from `BaseEventListener`
2. Implement the `setup_listeners` method
3. Register handlers for the events you're interested in
4. Create an instance of your listener in the appropriate file

Here's a simple example of a custom event listener class:

```python
from crewai.utilities.events import (
    CrewKickoffStartedEvent,
    CrewKickoffCompletedEvent,
    AgentExecutionCompletedEvent,
)
from crewai.utilities.events.base_event_listener import BaseEventListener

class MyCustomListener(BaseEventListener):
    def __init__(self):
        super().__init__()

    def setup_listeners(self, crewai_event_bus):
        @crewai_event_bus.on(CrewKickoffStartedEvent)
        def on_crew_started(source, event):
            print(f"Crew '{event.crew_name}' has started execution!")

        @crewai_event_bus.on(CrewKickoffCompletedEvent)
        def on_crew_completed(source, event):
            print(f"Crew '{event.crew_name}' has completed execution!")
            print(f"Output: {event.output}")

        @crewai_event_bus.on(AgentExecutionCompletedEvent)
        def on_agent_execution_completed(source, event):
            print(f"Agent '{event.agent.role}' completed task")
            print(f"Output: {event.output}")
```

## Properly Registering Your Listener

Simply defining your listener class isn't enough. You need to create an instance of it and ensure it's imported in your application. This ensures that:

1. The event handlers are registered with the event bus
2. The listener instance remains in memory (not garbage collected)
3. The listener is active when events are emitted

### Option 1: Import and Instantiate in Your Crew or Flow Implementation

The most important thing is to create an instance of your listener in the file where your Crew or Flow is defined and executed:

#### For Crew-based Applications

Create and import your listener at the top of your Crew implementation file:

```python
# In your crew.py file
from crewai import Agent, Crew, Task
from my_listeners import MyCustomListener

# Create an instance of your listener
my_listener = MyCustomListener()

class MyCustomCrew:
    # Your crew implementation...

    def crew(self):
        return Crew(
            agents=[...],
            tasks=[...],
            # ...
        )
```

#### For Flow-based Applications

Create and import your listener at the top of your Flow implementation file:

```python
# In your main.py or flow.py file
from crewai.flow import Flow, listen, start
from my_listeners import MyCustomListener

# Create an instance of your listener
my_listener = MyCustomListener()

class MyCustomFlow(Flow):
    # Your flow implementation...

    @start()
    def first_step(self):
        # ...
```

This ensures that your listener is loaded and active when your Crew or Flow is executed.

### Option 2: Create a Package for Your Listeners

For a more structured approach, especially if you have multiple listeners:

1. Create a package for your listeners:

```
my_project/
  ‚îú‚îÄ‚îÄ listeners/
  ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
  ‚îÇ   ‚îú‚îÄ‚îÄ my_custom_listener.py
  ‚îÇ   ‚îî‚îÄ‚îÄ another_listener.py
```

2. In `my_custom_listener.py`, define your listener class and create an instance:

```python
# my_custom_listener.py
from crewai.utilities.events.base_event_listener import BaseEventListener
# ... import events ...

class MyCustomListener(BaseEventListener):
    # ... implementation ...

# Create an instance of your listener
my_custom_listener = MyCustomListener()
```

3. In `__init__.py`, import the listener instances to ensure they're loaded:

```python
# __init__.py
from .my_custom_listener import my_custom_listener
from .another_listener import another_listener

# Optionally export them if you need to access them elsewhere
__all__ = ['my_custom_listener', 'another_listener']
```

4. Import your listeners package in your Crew or Flow file:

```python
# In your crew.py or flow.py file
import my_project.listeners  # This loads all your listeners

class MyCustomCrew:
    # Your crew implementation...
```

This is exactly how CrewAI's built-in `agentops_listener` is registered. In the CrewAI codebase, you'll find:

```python
# src/crewai/utilities/events/third_party/__init__.py
from .agentops_listener import agentops_listener
```

This ensures the `agentops_listener` is loaded when the `crewai.utilities.events` package is imported.

## Available Event Types

CrewAI provides a wide range of events that you can listen for:

### Crew Events

* **CrewKickoffStartedEvent**: Emitted when a Crew starts execution
* **CrewKickoffCompletedEvent**: Emitted when a Crew completes execution
* **CrewKickoffFailedEvent**: Emitted when a Crew fails to complete execution
* **CrewTestStartedEvent**: Emitted when a Crew starts testing
* **CrewTestCompletedEvent**: Emitted when a Crew completes testing
* **CrewTestFailedEvent**: Emitted when a Crew fails to complete testing
* **CrewTrainStartedEvent**: Emitted when a Crew starts training
* **CrewTrainCompletedEvent**: Emitted when a Crew completes training
* **CrewTrainFailedEvent**: Emitted when a Crew fails to complete training

### Agent Events

* **AgentExecutionStartedEvent**: Emitted when an Agent starts executing a task
* **AgentExecutionCompletedEvent**: Emitted when an Agent completes executing a task
* **AgentExecutionErrorEvent**: Emitted when an Agent encounters an error during execution

### Task Events

* **TaskStartedEvent**: Emitted when a Task starts execution
* **TaskCompletedEvent**: Emitted when a Task completes execution
* **TaskFailedEvent**: Emitted when a Task fails to complete execution
* **TaskEvaluationEvent**: Emitted when a Task is evaluated

### Tool Usage Events

* **ToolUsageStartedEvent**: Emitted when a tool execution is started
* **ToolUsageFinishedEvent**: Emitted when a tool execution is completed
* **ToolUsageErrorEvent**: Emitted when a tool execution encounters an error
* **ToolValidateInputErrorEvent**: Emitted when a tool input validation encounters an error
* **ToolExecutionErrorEvent**: Emitted when a tool execution encounters an error
* **ToolSelectionErrorEvent**: Emitted when there's an error selecting a tool

### Knowledge Events

* **KnowledgeRetrievalStartedEvent**: Emitted when a knowledge retrieval is started
* **KnowledgeRetrievalCompletedEvent**: Emitted when a knowledge retrieval is completed
* **KnowledgeQueryStartedEvent**: Emitted when a knowledge query is started
* **KnowledgeQueryCompletedEvent**: Emitted when a knowledge query is completed
* **KnowledgeQueryFailedEvent**: Emitted when a knowledge query fails
* **KnowledgeSearchQueryFailedEvent**: Emitted when a knowledge search query fails

### LLM Guardrail Events

* **LLMGuardrailStartedEvent**: Emitted when a guardrail validation starts. Contains details about the guardrail being applied and retry count.
* **LLMGuardrailCompletedEvent**: Emitted when a guardrail validation completes. Contains details about validation success/failure, results, and error messages if any.

### Flow Events

* **FlowCreatedEvent**: Emitted when a Flow is created
* **FlowStartedEvent**: Emitted when a Flow starts execution
* **FlowFinishedEvent**: Emitted when a Flow completes execution
* **FlowPlotEvent**: Emitted when a Flow is plotted
* **MethodExecutionStartedEvent**: Emitted when a Flow method starts execution
* **MethodExecutionFinishedEvent**: Emitted when a Flow method completes execution
* **MethodExecutionFailedEvent**: Emitted when a Flow method fails to complete execution

### LLM Events

* **LLMCallStartedEvent**: Emitted when an LLM call starts
* **LLMCallCompletedEvent**: Emitted when an LLM call completes
* **LLMCallFailedEvent**: Emitted when an LLM call fails
* **LLMStreamChunkEvent**: Emitted for each chunk received during streaming LLM responses

### Memory Events

* **MemoryQueryStartedEvent**: Emitted when a memory query is started. Contains the query, limit, and optional score threshold.
* **MemoryQueryCompletedEvent**: Emitted when a memory query is completed successfully. Contains the query, results, limit, score threshold, and query execution time.
* **MemoryQueryFailedEvent**: Emitted when a memory query fails. Contains the query, limit, score threshold, and error message.
* **MemorySaveStartedEvent**: Emitted when a memory save operation is started. Contains the value to be saved, metadata, and optional agent role.
* **MemorySaveCompletedEvent**: Emitted when a memory save operation is completed successfully. Contains the saved value, metadata, agent role, and save execution time.
* **MemorySaveFailedEvent**: Emitted when a memory save operation fails. Contains the value, metadata, agent role, and error message.
* **MemoryRetrievalStartedEvent**: Emitted when memory retrieval for a task prompt starts. Contains the optional task ID.
* **MemoryRetrievalCompletedEvent**: Emitted when memory retrieval for a task prompt completes successfully. Contains the task ID, memory content, and retrieval execution time.

## Event Handler Structure

Each event handler receives two parameters:

1. **source**: The object that emitted the event
2. **event**: The event instance, containing event-specific data

The structure of the event object depends on the event type, but all events inherit from `BaseEvent` and include:

* **timestamp**: The time when the event was emitted
* **type**: A string identifier for the event type

Additional fields vary by event type. For example, `CrewKickoffCompletedEvent` includes `crew_name` and `output` fields.

## Real-World Example: Integration with AgentOps

CrewAI includes an example of a third-party integration with [AgentOps](https://github.com/AgentOps-AI/agentops), a monitoring and observability platform for AI agents. Here's how it's implemented:

```python
from typing import Optional

from crewai.utilities.events import (
    CrewKickoffCompletedEvent,
    ToolUsageErrorEvent,
    ToolUsageStartedEvent,
)
from crewai.utilities.events.base_event_listener import BaseEventListener
from crewai.utilities.events.crew_events import CrewKickoffStartedEvent
from crewai.utilities.events.task_events import TaskEvaluationEvent

try:
    import agentops
    AGENTOPS_INSTALLED = True
except ImportError:
    AGENTOPS_INSTALLED = False

class AgentOpsListener(BaseEventListener):
    tool_event: Optional["agentops.ToolEvent"] = None
    session: Optional["agentops.Session"] = None

    def __init__(self):
        super().__init__()

    def setup_listeners(self, crewai_event_bus):
        if not AGENTOPS_INSTALLED:
            return

        @crewai_event_bus.on(CrewKickoffStartedEvent)
        def on_crew_kickoff_started(source, event: CrewKickoffStartedEvent):
            self.session = agentops.init()
            for agent in source.agents:
                if self.session:
                    self.session.create_agent(
                        name=agent.role,
                        agent_id=str(agent.id),
                    )

        @crewai_event_bus.on(CrewKickoffCompletedEvent)
        def on_crew_kickoff_completed(source, event: CrewKickoffCompletedEvent):
            if self.session:
                self.session.end_session(
                    end_state="Success",
                    end_state_reason="Finished Execution",
                )

        @crewai_event_bus.on(ToolUsageStartedEvent)
        def on_tool_usage_started(source, event: ToolUsageStartedEvent):
            self.tool_event = agentops.ToolEvent(name=event.tool_name)
            if self.session:
                self.session.record(self.tool_event)

        @crewai_event_bus.on(ToolUsageErrorEvent)
        def on_tool_usage_error(source, event: ToolUsageErrorEvent):
            agentops.ErrorEvent(exception=event.error, trigger_event=self.tool_event)
```

This listener initializes an AgentOps session when a Crew starts, registers agents with AgentOps, tracks tool usage, and ends the session when the Crew completes.

The AgentOps listener is registered in CrewAI's event system through the import in `src/crewai/utilities/events/third_party/__init__.py`:

```python
from .agentops_listener import agentops_listener
```

This ensures the `agentops_listener` is loaded when the `crewai.utilities.events` package is imported.

## Advanced Usage: Scoped Handlers

For temporary event handling (useful for testing or specific operations), you can use the `scoped_handlers` context manager:

```python
from crewai.utilities.events import crewai_event_bus, CrewKickoffStartedEvent

with crewai_event_bus.scoped_handlers():
    @crewai_event_bus.on(CrewKickoffStartedEvent)
    def temp_handler(source, event):
        print("This handler only exists within this context")

    # Do something that emits events

# Outside the context, the temporary handler is removed
```

## Use Cases

Event listeners can be used for a variety of purposes:

1. **Logging and Monitoring**: Track the execution of your Crew and log important events
2. **Analytics**: Collect data about your Crew's performance and behavior
3. **Debugging**: Set up temporary listeners to debug specific issues
4. **Integration**: Connect CrewAI with external systems like monitoring platforms, databases, or notification services
5. **Custom Behavior**: Trigger custom actions based on specific events

## Best Practices

1. **Keep Handlers Light**: Event handlers should be lightweight and avoid blocking operations
2. **Error Handling**: Include proper error handling in your event handlers to prevent exceptions from affecting the main execution
3. **Cleanup**: If your listener allocates resources, ensure they're properly cleaned up
4. **Selective Listening**: Only listen for events you actually need to handle
5. **Testing**: Test your event listeners in isolation to ensure they behave as expected

By leveraging CrewAI's event system, you can extend its functionality and integrate it seamlessly with your existing infrastructure.


# Flows
Source: https://docs.crewai.com/en/concepts/flows

Learn how to create and manage AI workflows using CrewAI Flows.

## Overview

CrewAI Flows is a powerful feature designed to streamline the creation and management of AI workflows. Flows allow developers to combine and coordinate coding tasks and Crews efficiently, providing a robust framework for building sophisticated AI automations.

Flows allow you to create structured, event-driven workflows. They provide a seamless way to connect multiple tasks, manage state, and control the flow of execution in your AI applications. With Flows, you can easily design and implement multi-step processes that leverage the full potential of CrewAI's capabilities.

1. **Simplified Workflow Creation**: Easily chain together multiple Crews and tasks to create complex AI workflows.

2. **State Management**: Flows make it super easy to manage and share state between different tasks in your workflow.

3. **Event-Driven Architecture**: Built on an event-driven model, allowing for dynamic and responsive workflows.

4. **Flexible Control Flow**: Implement conditional logic, loops, and branching within your workflows.

## Getting Started

Let's create a simple Flow where you will use OpenAI to generate a random city in one task and then use that city to generate a fun fact in another task.

```python Code

from crewai.flow.flow import Flow, listen, start
from dotenv import load_dotenv
from litellm import completion


class ExampleFlow(Flow):
    model = "gpt-4o-mini"

    @start()
    def generate_city(self):
        print("Starting flow")
        # Each flow state automatically gets a unique ID
        print(f"Flow State ID: {self.state['id']}")

        response = completion(
            model=self.model,
            messages=[
                {
                    "role": "user",
                    "content": "Return the name of a random city in the world.",
                },
            ],
        )

        random_city = response["choices"][0]["message"]["content"]
        # Store the city in our state
        self.state["city"] = random_city
        print(f"Random City: {random_city}")

        return random_city

    @listen(generate_city)
    def generate_fun_fact(self, random_city):
        response = completion(
            model=self.model,
            messages=[
                {
                    "role": "user",
                    "content": f"Tell me a fun fact about {random_city}",
                },
            ],
        )

        fun_fact = response["choices"][0]["message"]["content"]
        # Store the fun fact in our state
        self.state["fun_fact"] = fun_fact
        return fun_fact



flow = ExampleFlow()
flow.plot()
result = flow.kickoff()

print(f"Generated fun fact: {result}")
```

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-1.png)
In the above example, we have created a simple Flow that generates a random city using OpenAI and then generates a fun fact about that city. The Flow consists of two tasks: `generate_city` and `generate_fun_fact`. The `generate_city` task is the starting point of the Flow, and the `generate_fun_fact` task listens for the output of the `generate_city` task.

Each Flow instance automatically receives a unique identifier (UUID) in its state, which helps track and manage flow executions. The state can also store additional data (like the generated city and fun fact) that persists throughout the flow's execution.

When you run the Flow, it will:

1. Generate a unique ID for the flow state
2. Generate a random city and store it in the state
3. Generate a fun fact about that city and store it in the state
4. Print the results to the console

The state's unique ID and stored data can be useful for tracking flow executions and maintaining context between tasks.

**Note:** Ensure you have set up your `.env` file to store your `OPENAI_API_KEY`. This key is necessary for authenticating requests to the OpenAI API.

### @start()

The `@start()` decorator is used to mark a method as the starting point of a Flow. When a Flow is started, all the methods decorated with `@start()` are executed in parallel. You can have multiple start methods in a Flow, and they will all be executed when the Flow is started.

### @listen()

The `@listen()` decorator is used to mark a method as a listener for the output of another task in the Flow. The method decorated with `@listen()` will be executed when the specified task emits an output. The method can access the output of the task it is listening to as an argument.

#### Usage

The `@listen()` decorator can be used in several ways:

1. **Listening to a Method by Name**: You can pass the name of the method you want to listen to as a string. When that method completes, the listener method will be triggered.

   ```python Code
   @listen("generate_city")
   def generate_fun_fact(self, random_city):
       # Implementation
   ```

2. **Listening to a Method Directly**: You can pass the method itself. When that method completes, the listener method will be triggered.
   ```python Code
   @listen(generate_city)
   def generate_fun_fact(self, random_city):
       # Implementation
   ```

### Flow Output

Accessing and handling the output of a Flow is essential for integrating your AI workflows into larger applications or systems. CrewAI Flows provide straightforward mechanisms to retrieve the final output, access intermediate results, and manage the overall state of your Flow.

#### Retrieving the Final Output

When you run a Flow, the final output is determined by the last method that completes. The `kickoff()` method returns the output of this final method.

Here's how you can access the final output:

<CodeGroup>
  ```python Code
  from crewai.flow.flow import Flow, listen, start

  class OutputExampleFlow(Flow):
      @start()
      def first_method(self):
          return "Output from first_method"

      @listen(first_method)
      def second_method(self, first_output):
          return f"Second method received: {first_output}"


  flow = OutputExampleFlow()
  flow.plot("my_flow_plot")
  final_output = flow.kickoff()

  print("---- Final Output ----")
  print(final_output)
  ```

  ```text Output
  ---- Final Output ----
  Second method received: Output from first_method
  ```
</CodeGroup>

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-2.png)

In this example, the `second_method` is the last method to complete, so its output will be the final output of the Flow.
The `kickoff()` method will return the final output, which is then printed to the console. The `plot()` method will generate the HTML file, which will help you understand the flow.

#### Accessing and Updating State

In addition to retrieving the final output, you can also access and update the state within your Flow. The state can be used to store and share data between different methods in the Flow. After the Flow has run, you can access the state to retrieve any information that was added or updated during the execution.

Here's an example of how to update and access the state:

<CodeGroup>
  ```python Code
  from crewai.flow.flow import Flow, listen, start
  from pydantic import BaseModel

  class ExampleState(BaseModel):
      counter: int = 0
      message: str = ""

  class StateExampleFlow(Flow[ExampleState]):

      @start()
      def first_method(self):
          self.state.message = "Hello from first_method"
          self.state.counter += 1

      @listen(first_method)
      def second_method(self):
          self.state.message += " - updated by second_method"
          self.state.counter += 1
          return self.state.message

  flow = StateExampleFlow()
  flow.plot("my_flow_plot")
  final_output = flow.kickoff()
  print(f"Final Output: {final_output}")
  print("Final State:")
  print(flow.state)
  ```

  ```text Output
  Final Output: Hello from first_method - updated by second_method
  Final State:
  counter=2 message='Hello from first_method - updated by second_method'
  ```
</CodeGroup>

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-2.png)

In this example, the state is updated by both `first_method` and `second_method`.
After the Flow has run, you can access the final state to see the updates made by these methods.

By ensuring that the final method's output is returned and providing access to the state, CrewAI Flows make it easy to integrate the results of your AI workflows into larger applications or systems,
while also maintaining and accessing the state throughout the Flow's execution.

## Flow State Management

Managing state effectively is crucial for building reliable and maintainable AI workflows. CrewAI Flows provides robust mechanisms for both unstructured and structured state management,
allowing developers to choose the approach that best fits their application's needs.

### Unstructured State Management

In unstructured state management, all state is stored in the `state` attribute of the `Flow` class.
This approach offers flexibility, enabling developers to add or modify state attributes on the fly without defining a strict schema.
Even with unstructured states, CrewAI Flows automatically generates and maintains a unique identifier (UUID) for each state instance.

```python Code
from crewai.flow.flow import Flow, listen, start

class UnstructuredExampleFlow(Flow):

    @start()
    def first_method(self):
        # The state automatically includes an 'id' field
        print(f"State ID: {self.state['id']}")
        self.state['counter'] = 0
        self.state['message'] = "Hello from structured flow"

    @listen(first_method)
    def second_method(self):
        self.state['counter'] += 1
        self.state['message'] += " - updated"

    @listen(second_method)
    def third_method(self):
        self.state['counter'] += 1
        self.state['message'] += " - updated again"

        print(f"State after third_method: {self.state}")


flow = UnstructuredExampleFlow()
flow.plot("my_flow_plot")
flow.kickoff()
```

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-3.png)

**Note:** The `id` field is automatically generated and preserved throughout the flow's execution. You don't need to manage or set it manually, and it will be maintained even when updating the state with new data.

**Key Points:**

* **Flexibility:** You can dynamically add attributes to `self.state` without predefined constraints.
* **Simplicity:** Ideal for straightforward workflows where state structure is minimal or varies significantly.

### Structured State Management

Structured state management leverages predefined schemas to ensure consistency and type safety across the workflow.
By using models like Pydantic's `BaseModel`, developers can define the exact shape of the state, enabling better validation and auto-completion in development environments.

Each state in CrewAI Flows automatically receives a unique identifier (UUID) to help track and manage state instances. This ID is automatically generated and managed by the Flow system.

```python Code
from crewai.flow.flow import Flow, listen, start
from pydantic import BaseModel


class ExampleState(BaseModel):
    # Note: 'id' field is automatically added to all states
    counter: int = 0
    message: str = ""


class StructuredExampleFlow(Flow[ExampleState]):

    @start()
    def first_method(self):
        # Access the auto-generated ID if needed
        print(f"State ID: {self.state.id}")
        self.state.message = "Hello from structured flow"

    @listen(first_method)
    def second_method(self):
        self.state.counter += 1
        self.state.message += " - updated"

    @listen(second_method)
    def third_method(self):
        self.state.counter += 1
        self.state.message += " - updated again"

        print(f"State after third_method: {self.state}")


flow = StructuredExampleFlow()
flow.kickoff()
```

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-3.png)

**Key Points:**

* **Defined Schema:** `ExampleState` clearly outlines the state structure, enhancing code readability and maintainability.
* **Type Safety:** Leveraging Pydantic ensures that state attributes adhere to the specified types, reducing runtime errors.
* **Auto-Completion:** IDEs can provide better auto-completion and error checking based on the defined state model.

### Choosing Between Unstructured and Structured State Management

* **Use Unstructured State Management when:**

  * The workflow's state is simple or highly dynamic.
  * Flexibility is prioritized over strict state definitions.
  * Rapid prototyping is required without the overhead of defining schemas.

* **Use Structured State Management when:**
  * The workflow requires a well-defined and consistent state structure.
  * Type safety and validation are important for your application's reliability.
  * You want to leverage IDE features like auto-completion and type checking for better developer experience.

By providing both unstructured and structured state management options, CrewAI Flows empowers developers to build AI workflows that are both flexible and robust, catering to a wide range of application requirements.

## Flow Persistence

The @persist decorator enables automatic state persistence in CrewAI Flows, allowing you to maintain flow state across restarts or different workflow executions. This decorator can be applied at either the class level or method level, providing flexibility in how you manage state persistence.

### Class-Level Persistence

When applied at the class level, the @persist decorator automatically persists all flow method states:

```python
@persist  # Using SQLiteFlowPersistence by default
class MyFlow(Flow[MyState]):
    @start()
    def initialize_flow(self):
        # This method will automatically have its state persisted
        self.state.counter = 1
        print("Initialized flow. State ID:", self.state.id)

    @listen(initialize_flow)
    def next_step(self):
        # The state (including self.state.id) is automatically reloaded
        self.state.counter += 1
        print("Flow state is persisted. Counter:", self.state.counter)
```

### Method-Level Persistence

For more granular control, you can apply @persist to specific methods:

```python
class AnotherFlow(Flow[dict]):
    @persist  # Persists only this method's state
    @start()
    def begin(self):
        if "runs" not in self.state:
            self.state["runs"] = 0
        self.state["runs"] += 1
        print("Method-level persisted runs:", self.state["runs"])
```

### How It Works

1. **Unique State Identification**
   * Each flow state automatically receives a unique UUID
   * The ID is preserved across state updates and method calls
   * Supports both structured (Pydantic BaseModel) and unstructured (dictionary) states

2. **Default SQLite Backend**
   * SQLiteFlowPersistence is the default storage backend
   * States are automatically saved to a local SQLite database
   * Robust error handling ensures clear messages if database operations fail

3. **Error Handling**
   * Comprehensive error messages for database operations
   * Automatic state validation during save and load
   * Clear feedback when persistence operations encounter issues

### Important Considerations

* **State Types**: Both structured (Pydantic BaseModel) and unstructured (dictionary) states are supported
* **Automatic ID**: The `id` field is automatically added if not present
* **State Recovery**: Failed or restarted flows can automatically reload their previous state
* **Custom Implementation**: You can provide your own FlowPersistence implementation for specialized storage needs

### Technical Advantages

1. **Precise Control Through Low-Level Access**
   * Direct access to persistence operations for advanced use cases
   * Fine-grained control via method-level persistence decorators
   * Built-in state inspection and debugging capabilities
   * Full visibility into state changes and persistence operations

2. **Enhanced Reliability**
   * Automatic state recovery after system failures or restarts
   * Transaction-based state updates for data integrity
   * Comprehensive error handling with clear error messages
   * Robust validation during state save and load operations

3. **Extensible Architecture**
   * Customizable persistence backend through FlowPersistence interface
   * Support for specialized storage solutions beyond SQLite
   * Compatible with both structured (Pydantic) and unstructured (dict) states
   * Seamless integration with existing CrewAI flow patterns

The persistence system's architecture emphasizes technical precision and customization options, allowing developers to maintain full control over state management while benefiting from built-in reliability features.

## Flow Control

### Conditional Logic: `or`

The `or_` function in Flows allows you to listen to multiple methods and trigger the listener method when any of the specified methods emit an output.

<CodeGroup>
  ```python Code
  from crewai.flow.flow import Flow, listen, or_, start

  class OrExampleFlow(Flow):

      @start()
      def start_method(self):
          return "Hello from the start method"

      @listen(start_method)
      def second_method(self):
          return "Hello from the second method"

      @listen(or_(start_method, second_method))
      def logger(self, result):
          print(f"Logger: {result}")



  flow = OrExampleFlow()
  flow.plot("my_flow_plot")
  flow.kickoff()
  ```

  ```text Output
  Logger: Hello from the start method
  Logger: Hello from the second method
  ```
</CodeGroup>

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-4.png)

When you run this Flow, the `logger` method will be triggered by the output of either the `start_method` or the `second_method`.
The `or_` function is used to listen to multiple methods and trigger the listener method when any of the specified methods emit an output.

### Conditional Logic: `and`

The `and_` function in Flows allows you to listen to multiple methods and trigger the listener method only when all the specified methods emit an output.

<CodeGroup>
  ```python Code
  from crewai.flow.flow import Flow, and_, listen, start

  class AndExampleFlow(Flow):

      @start()
      def start_method(self):
          self.state["greeting"] = "Hello from the start method"

      @listen(start_method)
      def second_method(self):
          self.state["joke"] = "What do computers eat? Microchips."

      @listen(and_(start_method, second_method))
      def logger(self):
          print("---- Logger ----")
          print(self.state)

  flow = AndExampleFlow()
  flow.plot()
  flow.kickoff()
  ```

  ```text Output
  ---- Logger ----
  {'greeting': 'Hello from the start method', 'joke': 'What do computers eat? Microchips.'}
  ```
</CodeGroup>

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-5.png)

When you run this Flow, the `logger` method will be triggered only when both the `start_method` and the `second_method` emit an output.
The `and_` function is used to listen to multiple methods and trigger the listener method only when all the specified methods emit an output.

### Router

The `@router()` decorator in Flows allows you to define conditional routing logic based on the output of a method.
You can specify different routes based on the output of the method, allowing you to control the flow of execution dynamically.

<CodeGroup>
  ```python Code
  import random
  from crewai.flow.flow import Flow, listen, router, start
  from pydantic import BaseModel

  class ExampleState(BaseModel):
      success_flag: bool = False

  class RouterFlow(Flow[ExampleState]):

      @start()
      def start_method(self):
          print("Starting the structured flow")
          random_boolean = random.choice([True, False])
          self.state.success_flag = random_boolean

      @router(start_method)
      def second_method(self):
          if self.state.success_flag:
              return "success"
          else:
              return "failed"

      @listen("success")
      def third_method(self):
          print("Third method running")

      @listen("failed")
      def fourth_method(self):
          print("Fourth method running")


  flow = RouterFlow()
  flow.plot("my_flow_plot")
  flow.kickoff()
  ```

  ```text Output
  Starting the structured flow
  Third method running
  Fourth method running
  ```
</CodeGroup>

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-6.png)

In the above example, the `start_method` generates a random boolean value and sets it in the state.
The `second_method` uses the `@router()` decorator to define conditional routing logic based on the value of the boolean.
If the boolean is `True`, the method returns `"success"`, and if it is `False`, the method returns `"failed"`.
The `third_method` and `fourth_method` listen to the output of the `second_method` and execute based on the returned value.

When you run this Flow, the output will change based on the random boolean value generated by the `start_method`.

## Adding Agents to Flows

Agents can be seamlessly integrated into your flows, providing a lightweight alternative to full Crews when you need simpler, focused task execution. Here's an example of how to use an Agent within a flow to perform market research:

```python
import asyncio
from typing import Any, Dict, List

from crewai_tools import SerperDevTool
from pydantic import BaseModel, Field

from crewai.agent import Agent
from crewai.flow.flow import Flow, listen, start


# Define a structured output format
class MarketAnalysis(BaseModel):
    key_trends: List[str] = Field(description="List of identified market trends")
    market_size: str = Field(description="Estimated market size")
    competitors: List[str] = Field(description="Major competitors in the space")


# Define flow state
class MarketResearchState(BaseModel):
    product: str = ""
    analysis: MarketAnalysis | None = None


# Create a flow class
class MarketResearchFlow(Flow[MarketResearchState]):
    @start()
    def initialize_research(self) -> Dict[str, Any]:
        print(f"Starting market research for {self.state.product}")
        return {"product": self.state.product}

    @listen(initialize_research)
    async def analyze_market(self) -> Dict[str, Any]:
        # Create an Agent for market research
        analyst = Agent(
            role="Market Research Analyst",
            goal=f"Analyze the market for {self.state.product}",
            backstory="You are an experienced market analyst with expertise in "
            "identifying market trends and opportunities.",
            tools=[SerperDevTool()],
            verbose=True,
        )

        # Define the research query
        query = f"""
        Research the market for {self.state.product}. Include:
        1. Key market trends
        2. Market size
        3. Major competitors

        Format your response according to the specified structure.
        """

        # Execute the analysis with structured output format
        result = await analyst.kickoff_async(query, response_format=MarketAnalysis)
        if result.pydantic:
            print("result", result.pydantic)
        else:
            print("result", result)

        # Return the analysis to update the state
        return {"analysis": result.pydantic}

    @listen(analyze_market)
    def present_results(self, analysis) -> None:
        print("\nMarket Analysis Results")
        print("=====================")

        if isinstance(analysis, dict):
            # If we got a dict with 'analysis' key, extract the actual analysis object
            market_analysis = analysis.get("analysis")
        else:
            market_analysis = analysis

        if market_analysis and isinstance(market_analysis, MarketAnalysis):
            print("\nKey Market Trends:")
            for trend in market_analysis.key_trends:
                print(f"- {trend}")

            print(f"\nMarket Size: {market_analysis.market_size}")

            print("\nMajor Competitors:")
            for competitor in market_analysis.competitors:
                print(f"- {competitor}")
        else:
            print("No structured analysis data available.")
            print("Raw analysis:", analysis)


# Usage example
async def run_flow():
    flow = MarketResearchFlow()
    flow.plot("MarketResearchFlowPlot")
    result = await flow.kickoff_async(inputs={"product": "AI-powered chatbots"})
    return result


# Run the flow
if __name__ == "__main__":
    asyncio.run(run_flow())
```

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-7.png)

This example demonstrates several key features of using Agents in flows:

1. **Structured Output**: Using Pydantic models to define the expected output format (`MarketAnalysis`) ensures type safety and structured data throughout the flow.

2. **State Management**: The flow state (`MarketResearchState`) maintains context between steps and stores both inputs and outputs.

3. **Tool Integration**: Agents can use tools (like `WebsiteSearchTool`) to enhance their capabilities.

## Adding Crews to Flows

Creating a flow with multiple crews in CrewAI is straightforward.

You can generate a new CrewAI project that includes all the scaffolding needed to create a flow with multiple crews by running the following command:

```bash
crewai create flow name_of_flow
```

This command will generate a new CrewAI project with the necessary folder structure. The generated project includes a prebuilt crew called `poem_crew` that is already working. You can use this crew as a template by copying, pasting, and editing it to create other crews.

### Folder Structure

After running the `crewai create flow name_of_flow` command, you will see a folder structure similar to the following:

| Directory/File         | Description                                                         |
| :--------------------- | :------------------------------------------------------------------ |
| `name_of_flow/`        | Root directory for the flow.                                        |
| ‚îú‚îÄ‚îÄ `crews/`           | Contains directories for specific crews.                            |
| ‚îÇ ‚îî‚îÄ‚îÄ `poem_crew/`     | Directory for the "poem\_crew" with its configurations and scripts. |
| ‚îÇ ‚îú‚îÄ‚îÄ `config/`        | Configuration files directory for the "poem\_crew".                 |
| ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ `agents.yaml`  | YAML file defining the agents for "poem\_crew".                     |
| ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ `tasks.yaml`   | YAML file defining the tasks for "poem\_crew".                      |
| ‚îÇ ‚îú‚îÄ‚îÄ `poem_crew.py`   | Script for "poem\_crew" functionality.                              |
| ‚îú‚îÄ‚îÄ `tools/`           | Directory for additional tools used in the flow.                    |
| ‚îÇ ‚îî‚îÄ‚îÄ `custom_tool.py` | Custom tool implementation.                                         |
| ‚îú‚îÄ‚îÄ `main.py`          | Main script for running the flow.                                   |
| ‚îú‚îÄ‚îÄ `README.md`        | Project description and instructions.                               |
| ‚îú‚îÄ‚îÄ `pyproject.toml`   | Configuration file for project dependencies and settings.           |
| ‚îî‚îÄ‚îÄ `.gitignore`       | Specifies files and directories to ignore in version control.       |

### Building Your Crews

In the `crews` folder, you can define multiple crews. Each crew will have its own folder containing configuration files and the crew definition file. For example, the `poem_crew` folder contains:

* `config/agents.yaml`: Defines the agents for the crew.
* `config/tasks.yaml`: Defines the tasks for the crew.
* `poem_crew.py`: Contains the crew definition, including agents, tasks, and the crew itself.

You can copy, paste, and edit the `poem_crew` to create other crews.

### Connecting Crews in `main.py`

The `main.py` file is where you create your flow and connect the crews together. You can define your flow by using the `Flow` class and the decorators `@start` and `@listen` to specify the flow of execution.

Here's an example of how you can connect the `poem_crew` in the `main.py` file:

```python Code
#!/usr/bin/env python
from random import randint

from pydantic import BaseModel
from crewai.flow.flow import Flow, listen, start
from .crews.poem_crew.poem_crew import PoemCrew

class PoemState(BaseModel):
    sentence_count: int = 1
    poem: str = ""

class PoemFlow(Flow[PoemState]):

    @start()
    def generate_sentence_count(self):
        print("Generating sentence count")
        self.state.sentence_count = randint(1, 5)

    @listen(generate_sentence_count)
    def generate_poem(self):
        print("Generating poem")
        result = PoemCrew().crew().kickoff(inputs={"sentence_count": self.state.sentence_count})

        print("Poem generated", result.raw)
        self.state.poem = result.raw

    @listen(generate_poem)
    def save_poem(self):
        print("Saving poem")
        with open("poem.txt", "w") as f:
            f.write(self.state.poem)

def kickoff():
    poem_flow = PoemFlow()
    poem_flow.kickoff()


def plot():
    poem_flow = PoemFlow()
    poem_flow.plot("PoemFlowPlot")

if __name__ == "__main__":
    kickoff()
    plot()
```

In this example, the `PoemFlow` class defines a flow that generates a sentence count, uses the `PoemCrew` to generate a poem, and then saves the poem to a file. The flow is kicked off by calling the `kickoff()` method. The PoemFlowPlot will be generated by `plot()` method.

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-8.png)

### Running the Flow

(Optional) Before running the flow, you can install the dependencies by running:

```bash
crewai install
```

Once all of the dependencies are installed, you need to activate the virtual environment by running:

```bash
source .venv/bin/activate
```

After activating the virtual environment, you can run the flow by executing one of the following commands:

```bash
crewai flow kickoff
```

or

```bash
uv run kickoff
```

The flow will execute, and you should see the output in the console.

## Plot Flows

Visualizing your AI workflows can provide valuable insights into the structure and execution paths of your flows. CrewAI offers a powerful visualization tool that allows you to generate interactive plots of your flows, making it easier to understand and optimize your AI workflows.

### What are Plots?

Plots in CrewAI are graphical representations of your AI workflows. They display the various tasks, their connections, and the flow of data between them. This visualization helps in understanding the sequence of operations, identifying bottlenecks, and ensuring that the workflow logic aligns with your expectations.

### How to Generate a Plot

CrewAI provides two convenient methods to generate plots of your flows:

#### Option 1: Using the `plot()` Method

If you are working directly with a flow instance, you can generate a plot by calling the `plot()` method on your flow object. This method will create an HTML file containing the interactive plot of your flow.

```python Code
# Assuming you have a flow instance
flow.plot("my_flow_plot")
```

This will generate a file named `my_flow_plot.html` in your current directory. You can open this file in a web browser to view the interactive plot.

#### Option 2: Using the Command Line

If you are working within a structured CrewAI project, you can generate a plot using the command line. This is particularly useful for larger projects where you want to visualize the entire flow setup.

```bash
crewai flow plot
```

This command will generate an HTML file with the plot of your flow, similar to the `plot()` method. The file will be saved in your project directory, and you can open it in a web browser to explore the flow.

### Understanding the Plot

The generated plot will display nodes representing the tasks in your flow, with directed edges indicating the flow of execution. The plot is interactive, allowing you to zoom in and out, and hover over nodes to see additional details.

By visualizing your flows, you can gain a clearer understanding of the workflow's structure, making it easier to debug, optimize, and communicate your AI processes to others.

### Conclusion

Plotting your flows is a powerful feature of CrewAI that enhances your ability to design and manage complex AI workflows. Whether you choose to use the `plot()` method or the command line, generating plots will provide you with a visual representation of your workflows, aiding in both development and presentation.

## Next Steps

If you're interested in exploring additional examples of flows, we have a variety of recommendations in our examples repository. Here are four specific flow examples, each showcasing unique use cases to help you match your current problem type to a specific example:

1. **Email Auto Responder Flow**: This example demonstrates an infinite loop where a background job continually runs to automate email responses. It's a great use case for tasks that need to be performed repeatedly without manual intervention. [View Example](https://github.com/crewAIInc/crewAI-examples/tree/main/email_auto_responder_flow)

2. **Lead Score Flow**: This flow showcases adding human-in-the-loop feedback and handling different conditional branches using the router. It's an excellent example of how to incorporate dynamic decision-making and human oversight into your workflows. [View Example](https://github.com/crewAIInc/crewAI-examples/tree/main/lead-score-flow)

3. **Write a Book Flow**: This example excels at chaining multiple crews together, where the output of one crew is used by another. Specifically, one crew outlines an entire book, and another crew generates chapters based on the outline. Eventually, everything is connected to produce a complete book. This flow is perfect for complex, multi-step processes that require coordination between different tasks. [View Example](https://github.com/crewAIInc/crewAI-examples/tree/main/write_a_book_with_flows)

4. **Meeting Assistant Flow**: This flow demonstrates how to broadcast one event to trigger multiple follow-up actions. For instance, after a meeting is completed, the flow can update a Trello board, send a Slack message, and save the results. It's a great example of handling multiple outcomes from a single event, making it ideal for comprehensive task management and notification systems. [View Example](https://github.com/crewAIInc/crewAI-examples/tree/main/meeting_assistant_flow)

By exploring these examples, you can gain insights into how to leverage CrewAI Flows for various use cases, from automating repetitive tasks to managing complex, multi-step processes with dynamic decision-making and human feedback.

Also, check out our YouTube video on how to use flows in CrewAI below!

<iframe width="560" height="315" src="https://www.youtube.com/embed/MTb5my6VOT8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen />

## Running Flows

There are two ways to run a flow:

### Using the Flow API

You can run a flow programmatically by creating an instance of your flow class and calling the `kickoff()` method:

```python
flow = ExampleFlow()
result = flow.kickoff()
```

### Using the CLI

Starting from version 0.103.0, you can run flows using the `crewai run` command:

```shell
crewai run
```

This command automatically detects if your project is a flow (based on the `type = "flow"` setting in your pyproject.toml) and runs it accordingly. This is the recommended way to run flows from the command line.

For backward compatibility, you can also use:

```shell
crewai flow kickoff
```

However, the `crewai run` command is now the preferred method as it works for both crews and flows.


# Knowledge
Source: https://docs.crewai.com/en/concepts/knowledge

What is knowledge in CrewAI and how to use it.

## Overview

Knowledge in CrewAI is a powerful system that allows AI agents to access and utilize external information sources during their tasks.
Think of it as giving your agents a reference library they can consult while working.

<Info>
  Key benefits of using Knowledge:

  * Enhance agents with domain-specific information
  * Support decisions with real-world data
  * Maintain context across conversations
  * Ground responses in factual information
</Info>

## Quickstart Examples

<Tip>
  For file-based Knowledge Sources, make sure to place your files in a `knowledge` directory at the root of your project.
  Also, use relative paths from the `knowledge` directory when creating the source.
</Tip>

### Basic String Knowledge Example

```python Code
from crewai import Agent, Task, Crew, Process, LLM
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# Create a knowledge source
content = "Users name is John. He is 30 years old and lives in San Francisco."
string_source = StringKnowledgeSource(content=content)

# Create an LLM with a temperature of 0 to ensure deterministic outputs
llm = LLM(model="gpt-4o-mini", temperature=0)

# Create an agent with the knowledge store
agent = Agent(
    role="About User",
    goal="You know everything about the user.",
    backstory="You are a master at understanding people and their preferences.",
    verbose=True,
    allow_delegation=False,
    llm=llm,
)

task = Task(
    description="Answer the following questions about the user: {question}",
    expected_output="An answer to the question.",
    agent=agent,
)

crew = Crew(
    agents=[agent],
    tasks=[task],
    verbose=True,
    process=Process.sequential,
    knowledge_sources=[string_source], # Enable knowledge by adding the sources here
)

result = crew.kickoff(inputs={"question": "What city does John live in and how old is he?"})
```

### Web Content Knowledge Example

<Note>
  You need to install `docling` for the following example to work: `uv add docling`
</Note>

```python Code
from crewai import LLM, Agent, Crew, Process, Task
from crewai.knowledge.source.crew_docling_source import CrewDoclingSource

# Create a knowledge source from web content
content_source = CrewDoclingSource(
    file_paths=[
        "https://lilianweng.github.io/posts/2024-11-28-reward-hacking",
        "https://lilianweng.github.io/posts/2024-07-07-hallucination",
    ],
)

# Create an LLM with a temperature of 0 to ensure deterministic outputs
llm = LLM(model="gpt-4o-mini", temperature=0)

# Create an agent with the knowledge store
agent = Agent(
    role="About papers",
    goal="You know everything about the papers.",
    backstory="You are a master at understanding papers and their content.",
    verbose=True,
    allow_delegation=False,
    llm=llm,
)

task = Task(
    description="Answer the following questions about the papers: {question}",
    expected_output="An answer to the question.",
    agent=agent,
)

crew = Crew(
    agents=[agent],
    tasks=[task],
    verbose=True,
    process=Process.sequential,
    knowledge_sources=[content_source],
)

result = crew.kickoff(
    inputs={"question": "What is the reward hacking paper about? Be sure to provide sources."}
)
```

## Supported Knowledge Sources

CrewAI supports various types of knowledge sources out of the box:

<CardGroup cols={2}>
  <Card title="Text Sources" icon="text">
    * Raw strings
    * Text files (.txt)
    * PDF documents
  </Card>

  <Card title="Structured Data" icon="table">
    * CSV files
    * Excel spreadsheets
    * JSON documents
  </Card>
</CardGroup>

### Text File Knowledge Source

```python
from crewai.knowledge.source.text_file_knowledge_source import TextFileKnowledgeSource

text_source = TextFileKnowledgeSource(
    file_paths=["document.txt", "another.txt"]
)
```

### PDF Knowledge Source

```python
from crewai.knowledge.source.pdf_knowledge_source import PDFKnowledgeSource

pdf_source = PDFKnowledgeSource(
    file_paths=["document.pdf", "another.pdf"]
)
```

### CSV Knowledge Source

```python
from crewai.knowledge.source.csv_knowledge_source import CSVKnowledgeSource

csv_source = CSVKnowledgeSource(
    file_paths=["data.csv"]
)
```

### Excel Knowledge Source

```python
from crewai.knowledge.source.excel_knowledge_source import ExcelKnowledgeSource

excel_source = ExcelKnowledgeSource(
    file_paths=["spreadsheet.xlsx"]
)
```

### JSON Knowledge Source

```python
from crewai.knowledge.source.json_knowledge_source import JSONKnowledgeSource

json_source = JSONKnowledgeSource(
    file_paths=["data.json"]
)
```

<Note>
  Please ensure that you create the ./knowledge folder. All source files (e.g., .txt, .pdf, .xlsx, .json) should be placed in this folder for centralized management.
</Note>

## Agent vs Crew Knowledge: Complete Guide

<Info>
  **Understanding Knowledge Levels**: CrewAI supports knowledge at both agent and crew levels. This section clarifies exactly how each works, when they're initialized, and addresses common misconceptions about dependencies.
</Info>

### How Knowledge Initialization Actually Works

Here's exactly what happens when you use knowledge:

#### Agent-Level Knowledge (Independent)

```python
from crewai import Agent, Task, Crew
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# Agent with its own knowledge - NO crew knowledge needed
specialist_knowledge = StringKnowledgeSource(
    content="Specialized technical information for this agent only"
)

specialist_agent = Agent(
    role="Technical Specialist",
    goal="Provide technical expertise",
    backstory="Expert in specialized technical domains",
    knowledge_sources=[specialist_knowledge]  # Agent-specific knowledge
)

task = Task(
    description="Answer technical questions",
    agent=specialist_agent,
    expected_output="Technical answer"
)

# No crew-level knowledge required
crew = Crew(
    agents=[specialist_agent],
    tasks=[task]
)

result = crew.kickoff()  # Agent knowledge works independently
```

#### What Happens During `crew.kickoff()`

When you call `crew.kickoff()`, here's the exact sequence:

```python
# During kickoff
for agent in self.agents:
    agent.crew = self  # Agent gets reference to crew
    agent.set_knowledge(crew_embedder=self.embedder)  # Agent knowledge initialized
    agent.create_agent_executor()
```

#### Storage Independence

Each knowledge level uses independent storage collections:

```python
# Agent knowledge storage
agent_collection_name = agent.role  # e.g., "Technical Specialist"

# Crew knowledge storage
crew_collection_name = "crew"

# Both stored in same ChromaDB instance but different collections
# Path: ~/.local/share/CrewAI/{project}/knowledge/
#   ‚îú‚îÄ‚îÄ crew/                    # Crew knowledge collection
#   ‚îú‚îÄ‚îÄ Technical Specialist/    # Agent knowledge collection
#   ‚îî‚îÄ‚îÄ Another Agent Role/      # Another agent's collection
```

### Complete Working Examples

#### Example 1: Agent-Only Knowledge

```python
from crewai import Agent, Task, Crew
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# Agent-specific knowledge
agent_knowledge = StringKnowledgeSource(
    content="Agent-specific information that only this agent needs"
)

agent = Agent(
    role="Specialist",
    goal="Use specialized knowledge",
    backstory="Expert with specific knowledge",
    knowledge_sources=[agent_knowledge],
    embedder={  # Agent can have its own embedder
        "provider": "openai",
        "config": {"model": "text-embedding-3-small"}
    }
)

task = Task(
    description="Answer using your specialized knowledge",
    agent=agent,
    expected_output="Answer based on agent knowledge"
)

# No crew knowledge needed
crew = Crew(agents=[agent], tasks=[task])
result = crew.kickoff()  # Works perfectly
```

#### Example 2: Both Agent and Crew Knowledge

```python
# Crew-wide knowledge (shared by all agents)
crew_knowledge = StringKnowledgeSource(
    content="Company policies and general information for all agents"
)

# Agent-specific knowledge
specialist_knowledge = StringKnowledgeSource(
    content="Technical specifications only the specialist needs"
)

specialist = Agent(
    role="Technical Specialist",
    goal="Provide technical expertise",
    backstory="Technical expert",
    knowledge_sources=[specialist_knowledge]  # Agent-specific
)

generalist = Agent(
    role="General Assistant",
    goal="Provide general assistance",
    backstory="General helper"
    # No agent-specific knowledge
)

crew = Crew(
    agents=[specialist, generalist],
    tasks=[...],
    knowledge_sources=[crew_knowledge]  # Crew-wide knowledge
)

# Result:
# - specialist gets: crew_knowledge + specialist_knowledge
# - generalist gets: crew_knowledge only
```

#### Example 3: Multiple Agents with Different Knowledge

```python
# Different knowledge for different agents
sales_knowledge = StringKnowledgeSource(content="Sales procedures and pricing")
tech_knowledge = StringKnowledgeSource(content="Technical documentation")
support_knowledge = StringKnowledgeSource(content="Support procedures")

sales_agent = Agent(
    role="Sales Representative",
    knowledge_sources=[sales_knowledge],
    embedder={"provider": "openai", "config": {"model": "text-embedding-3-small"}}
)

tech_agent = Agent(
    role="Technical Expert",
    knowledge_sources=[tech_knowledge],
    embedder={"provider": "ollama", "config": {"model": "mxbai-embed-large"}}
)

support_agent = Agent(
    role="Support Specialist",
    knowledge_sources=[support_knowledge]
    # Will use crew embedder as fallback
)

crew = Crew(
    agents=[sales_agent, tech_agent, support_agent],
    tasks=[...],
    embedder={  # Fallback embedder for agents without their own
        "provider": "google",
        "config": {"model": "text-embedding-004"}
    }
)

# Each agent gets only their specific knowledge
# Each can use different embedding providers
```

<Tip>
  Unlike retrieval from a vector database using a tool, agents preloaded with knowledge will not need a retrieval persona or task.
  Simply add the relevant knowledge sources your agent or crew needs to function.

  Knowledge sources can be added at the agent or crew level.
  Crew level knowledge sources will be used by **all agents** in the crew.
  Agent level knowledge sources will be used by the **specific agent** that is preloaded with the knowledge.
</Tip>

## Knowledge Configuration

You can configure the knowledge configuration for the crew or agent.

```python Code
from crewai.knowledge.knowledge_config import KnowledgeConfig

knowledge_config = KnowledgeConfig(results_limit=10, score_threshold=0.5)

agent = Agent(
    ...
    knowledge_config=knowledge_config
)
```

<Tip>
  `results_limit`: is the number of relevant documents to return. Default is 3.
  `score_threshold`: is the minimum score for a document to be considered relevant. Default is 0.35.
</Tip>

## Supported Knowledge Parameters

<ParamField body="sources" type="List[BaseKnowledgeSource]" required="Yes">
  List of knowledge sources that provide content to be stored and queried. Can include PDF, CSV, Excel, JSON, text files, or string content.
</ParamField>

<ParamField body="collection_name" type="str">
  Name of the collection where the knowledge will be stored. Used to identify different sets of knowledge. Defaults to "knowledge" if not provided.
</ParamField>

<ParamField body="storage" type="Optional[KnowledgeStorage]">
  Custom storage configuration for managing how the knowledge is stored and retrieved. If not provided, a default storage will be created.
</ParamField>

## Knowledge Storage Transparency

<Info>
  **Understanding Knowledge Storage**: CrewAI automatically stores knowledge sources in platform-specific directories using ChromaDB for vector storage. Understanding these locations and defaults helps with production deployments, debugging, and storage management.
</Info>

### Where CrewAI Stores Knowledge Files

By default, CrewAI uses the same storage system as memory, storing knowledge in platform-specific directories:

#### Default Storage Locations by Platform

**macOS:**

```
~/Library/Application Support/CrewAI/{project_name}/
‚îî‚îÄ‚îÄ knowledge/                    # Knowledge ChromaDB files
    ‚îú‚îÄ‚îÄ chroma.sqlite3           # ChromaDB metadata
    ‚îú‚îÄ‚îÄ {collection_id}/         # Vector embeddings
    ‚îî‚îÄ‚îÄ knowledge_{collection}/  # Named collections
```

**Linux:**

```
~/.local/share/CrewAI/{project_name}/
‚îî‚îÄ‚îÄ knowledge/
    ‚îú‚îÄ‚îÄ chroma.sqlite3
    ‚îú‚îÄ‚îÄ {collection_id}/
    ‚îî‚îÄ‚îÄ knowledge_{collection}/
```

**Windows:**

```
C:\Users\{username}\AppData\Local\CrewAI\{project_name}\
‚îî‚îÄ‚îÄ knowledge\
    ‚îú‚îÄ‚îÄ chroma.sqlite3
    ‚îú‚îÄ‚îÄ {collection_id}\
    ‚îî‚îÄ‚îÄ knowledge_{collection}\
```

### Finding Your Knowledge Storage Location

To see exactly where CrewAI is storing your knowledge files:

```python
from crewai.utilities.paths import db_storage_path
import os

# Get the knowledge storage path
knowledge_path = os.path.join(db_storage_path(), "knowledge")
print(f"Knowledge storage location: {knowledge_path}")

# List knowledge collections and files
if os.path.exists(knowledge_path):
    print("\nKnowledge storage contents:")
    for item in os.listdir(knowledge_path):
        item_path = os.path.join(knowledge_path, item)
        if os.path.isdir(item_path):
            print(f"üìÅ Collection: {item}/")
            # Show collection contents
            try:
                for subitem in os.listdir(item_path):
                    print(f"   ‚îî‚îÄ‚îÄ {subitem}")
            except PermissionError:
                print(f"   ‚îî‚îÄ‚îÄ (permission denied)")
        else:
            print(f"üìÑ {item}")
else:
    print("No knowledge storage found yet.")
```

### Controlling Knowledge Storage Locations

#### Option 1: Environment Variable (Recommended)

```python
import os
from crewai import Crew

# Set custom storage location for all CrewAI data
os.environ["CREWAI_STORAGE_DIR"] = "./my_project_storage"

# All knowledge will now be stored in ./my_project_storage/knowledge/
crew = Crew(
    agents=[...],
    tasks=[...],
    knowledge_sources=[...]
)
```

#### Option 2: Custom Knowledge Storage

```python
from crewai.knowledge.storage.knowledge_storage import KnowledgeStorage
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# Create custom storage with specific embedder
custom_storage = KnowledgeStorage(
    embedder={
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    },
    collection_name="my_custom_knowledge"
)

# Use with knowledge sources
knowledge_source = StringKnowledgeSource(
    content="Your knowledge content here"
)
knowledge_source.storage = custom_storage
```

#### Option 3: Project-Specific Knowledge Storage

```python
import os
from pathlib import Path

# Store knowledge in project directory
project_root = Path(__file__).parent
knowledge_dir = project_root / "knowledge_storage"

os.environ["CREWAI_STORAGE_DIR"] = str(knowledge_dir)

# Now all knowledge will be stored in your project directory
```

### Default Embedding Provider Behavior

<Info>
  **Default Embedding Provider**: CrewAI defaults to OpenAI embeddings (`text-embedding-3-small`) for knowledge storage, even when using different LLM providers. You can easily customize this to match your setup.
</Info>

#### Understanding Default Behavior

```python
from crewai import Agent, Crew, LLM
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# When using Claude as your LLM...
agent = Agent(
    role="Researcher",
    goal="Research topics",
    backstory="Expert researcher",
    llm=LLM(provider="anthropic", model="claude-3-sonnet")  # Using Claude
)

# CrewAI will still use OpenAI embeddings by default for knowledge
# This ensures consistency but may not match your LLM provider preference
knowledge_source = StringKnowledgeSource(content="Research data...")

crew = Crew(
    agents=[agent],
    tasks=[...],
    knowledge_sources=[knowledge_source]
    # Default: Uses OpenAI embeddings even with Claude LLM
)
```

#### Customizing Knowledge Embedding Providers

```python
# Option 1: Use Voyage AI (recommended by Anthropic for Claude users)
crew = Crew(
    agents=[agent],
    tasks=[...],
    knowledge_sources=[knowledge_source],
    embedder={
        "provider": "voyageai",  # Recommended for Claude users
        "config": {
            "api_key": "your-voyage-api-key",
            "model": "voyage-3"  # or "voyage-3-large" for best quality
        }
    }
)

# Option 2: Use local embeddings (no external API calls)
crew = Crew(
    agents=[agent],
    tasks=[...],
    knowledge_sources=[knowledge_source],
    embedder={
        "provider": "ollama",
        "config": {
            "model": "mxbai-embed-large",
            "url": "http://localhost:11434/api/embeddings"
        }
    }
)

# Option 3: Agent-level embedding customization
agent = Agent(
    role="Researcher",
    goal="Research topics",
    backstory="Expert researcher",
    knowledge_sources=[knowledge_source],
    embedder={
        "provider": "google",
        "config": {
            "model": "models/text-embedding-004",
            "api_key": "your-google-key"
        }
    }
)
```

#### Configuring Azure OpenAI Embeddings

When using Azure OpenAI embeddings:

1. Make sure you deploy the embedding model in Azure platform first
2. Then you need to use the following configuration:

```python
agent = Agent(
    role="Researcher",
    goal="Research topics",
    backstory="Expert researcher",
    knowledge_sources=[knowledge_source],
    embedder={
        "provider": "azure",
        "config": {
            "api_key": "your-azure-api-key",
            "model": "text-embedding-ada-002", # change to the model you are using and is deployed in Azure
            "api_base": "https://your-azure-endpoint.openai.azure.com/",
            "api_version": "2024-02-01"
        }
    }
)
```

## Advanced Features

### Query Rewriting

CrewAI implements an intelligent query rewriting mechanism to optimize knowledge retrieval. When an agent needs to search through knowledge sources, the raw task prompt is automatically transformed into a more effective search query.

#### How Query Rewriting Works

1. When an agent executes a task with knowledge sources available, the `_get_knowledge_search_query` method is triggered
2. The agent's LLM is used to transform the original task prompt into an optimized search query
3. This optimized query is then used to retrieve relevant information from knowledge sources

#### Benefits of Query Rewriting

<CardGroup cols={2}>
  <Card title="Improved Retrieval Accuracy" icon="bullseye-arrow">
    By focusing on key concepts and removing irrelevant content, query rewriting helps retrieve more relevant information.
  </Card>

  <Card title="Context Awareness" icon="brain">
    The rewritten queries are designed to be more specific and context-aware for vector database retrieval.
  </Card>
</CardGroup>

#### Example

```python
# Original task prompt
task_prompt = "Answer the following questions about the user's favorite movies: What movie did John watch last week? Format your answer in JSON."

# Behind the scenes, this might be rewritten as:
rewritten_query = "What movies did John watch last week?"
```

The rewritten query is more focused on the core information need and removes irrelevant instructions about output formatting.

<Tip>
  This mechanism is fully automatic and requires no configuration from users. The agent's LLM is used to perform the query rewriting, so using a more capable LLM can improve the quality of rewritten queries.
</Tip>

### Knowledge Events

CrewAI emits events during the knowledge retrieval process that you can listen for using the event system. These events allow you to monitor, debug, and analyze how knowledge is being retrieved and used by your agents.

#### Available Knowledge Events

* **KnowledgeRetrievalStartedEvent**: Emitted when an agent starts retrieving knowledge from sources
* **KnowledgeRetrievalCompletedEvent**: Emitted when knowledge retrieval is completed, including the query used and the retrieved content
* **KnowledgeQueryStartedEvent**: Emitted when a query to knowledge sources begins
* **KnowledgeQueryCompletedEvent**: Emitted when a query completes successfully
* **KnowledgeQueryFailedEvent**: Emitted when a query to knowledge sources fails
* **KnowledgeSearchQueryFailedEvent**: Emitted when a search query fails

#### Example: Monitoring Knowledge Retrieval

```python
from crewai.utilities.events import (
    KnowledgeRetrievalStartedEvent,
    KnowledgeRetrievalCompletedEvent,
)
from crewai.utilities.events.base_event_listener import BaseEventListener

class KnowledgeMonitorListener(BaseEventListener):
    def setup_listeners(self, crewai_event_bus):
        @crewai_event_bus.on(KnowledgeRetrievalStartedEvent)
        def on_knowledge_retrieval_started(source, event):
            print(f"Agent '{event.agent.role}' started retrieving knowledge")

        @crewai_event_bus.on(KnowledgeRetrievalCompletedEvent)
        def on_knowledge_retrieval_completed(source, event):
            print(f"Agent '{event.agent.role}' completed knowledge retrieval")
            print(f"Query: {event.query}")
            print(f"Retrieved {len(event.retrieved_knowledge)} knowledge chunks")

# Create an instance of your listener
knowledge_monitor = KnowledgeMonitorListener()
```

For more information on using events, see the [Event Listeners](https://docs.crewai.com/concepts/event-listener) documentation.

### Custom Knowledge Sources

CrewAI allows you to create custom knowledge sources for any type of data by extending the `BaseKnowledgeSource` class. Let's create a practical example that fetches and processes space news articles.

#### Space News Knowledge Source Example

<CodeGroup>
  ```python Code
  from crewai import Agent, Task, Crew, Process, LLM
  from crewai.knowledge.source.base_knowledge_source import BaseKnowledgeSource
  import requests
  from datetime import datetime
  from typing import Dict, Any
  from pydantic import BaseModel, Field

  class SpaceNewsKnowledgeSource(BaseKnowledgeSource):
      """Knowledge source that fetches data from Space News API."""

      api_endpoint: str = Field(description="API endpoint URL")
      limit: int = Field(default=10, description="Number of articles to fetch")

      def load_content(self) -> Dict[Any, str]:
          """Fetch and format space news articles."""
          try:
              response = requests.get(
                  f"{self.api_endpoint}?limit={self.limit}"
              )
              response.raise_for_status()

              data = response.json()
              articles = data.get('results', [])

              formatted_data = self.validate_content(articles)
              return {self.api_endpoint: formatted_data}
          except Exception as e:
              raise ValueError(f"Failed to fetch space news: {str(e)}")

      def validate_content(self, articles: list) -> str:
          """Format articles into readable text."""
          formatted = "Space News Articles:\n\n"
          for article in articles:
              formatted += f"""
                  Title: {article['title']}
                  Published: {article['published_at']}
                  Summary: {article['summary']}
                  News Site: {article['news_site']}
                  URL: {article['url']}
                  -------------------"""
          return formatted

      def add(self) -> None:
          """Process and store the articles."""
          content = self.load_content()
          for _, text in content.items():
              chunks = self._chunk_text(text)
              self.chunks.extend(chunks)

          self._save_documents()

  # Create knowledge source
  recent_news = SpaceNewsKnowledgeSource(
      api_endpoint="https://api.spaceflightnewsapi.net/v4/articles",
      limit=10,
  )

  # Create specialized agent
  space_analyst = Agent(
      role="Space News Analyst",
      goal="Answer questions about space news accurately and comprehensively",
      backstory="""You are a space industry analyst with expertise in space exploration,
      satellite technology, and space industry trends. You excel at answering questions
      about space news and providing detailed, accurate information.""",
      knowledge_sources=[recent_news],
      llm=LLM(model="gpt-4", temperature=0.0)
  )

  # Create task that handles user questions
  analysis_task = Task(
      description="Answer this question about space news: {user_question}",
      expected_output="A detailed answer based on the recent space news articles",
      agent=space_analyst
  )

  # Create and run the crew
  crew = Crew(
      agents=[space_analyst],
      tasks=[analysis_task],
      verbose=True,
      process=Process.sequential
  )

  # Example usage
  result = crew.kickoff(
      inputs={"user_question": "What are the latest developments in space exploration?"}
  )
  ```

  ```output Output
  # Agent: Space News Analyst
  ## Task: Answer this question about space news: What are the latest developments in space exploration?


  # Agent: Space News Analyst
  ## Final Answer:
  The latest developments in space exploration, based on recent space news articles, include the following:

  1. SpaceX has received the final regulatory approvals to proceed with the second integrated Starship/Super Heavy launch, scheduled for as soon as the morning of Nov. 17, 2023. This is a significant step in SpaceX's ambitious plans for space exploration and colonization. [Source: SpaceNews](https://spacenews.com/starship-cleared-for-nov-17-launch/)

  2. SpaceX has also informed the US Federal Communications Commission (FCC) that it plans to begin launching its first next-generation Starlink Gen2 satellites. This represents a major upgrade to the Starlink satellite internet service, which aims to provide high-speed internet access worldwide. [Source: Teslarati](https://www.teslarati.com/spacex-first-starlink-gen2-satellite-launch-2022/)

  3. AI startup Synthetaic has raised $15 million in Series B funding. The company uses artificial intelligence to analyze data from space and air sensors, which could have significant applications in space exploration and satellite technology. [Source: SpaceNews](https://spacenews.com/ai-startup-synthetaic-raises-15-million-in-series-b-funding/)

  4. The Space Force has formally established a unit within the U.S. Indo-Pacific Command, marking a permanent presence in the Indo-Pacific region. This could have significant implications for space security and geopolitics. [Source: SpaceNews](https://spacenews.com/space-force-establishes-permanent-presence-in-indo-pacific-region/)

  5. Slingshot Aerospace, a space tracking and data analytics company, is expanding its network of ground-based optical telescopes to increase coverage of low Earth orbit. This could improve our ability to track and analyze objects in low Earth orbit, including satellites and space debris. [Source: SpaceNews](https://spacenews.com/slingshots-space-tracking-network-to-extend-coverage-of-low-earth-orbit/)

  6. The National Natural Science Foundation of China has outlined a five-year project for researchers to study the assembly of ultra-large spacecraft. This could lead to significant advancements in spacecraft technology and space exploration capabilities. [Source: SpaceNews](https://spacenews.com/china-researching-challenges-of-kilometer-scale-ultra-large-spacecraft/)

  7. The Center for AEroSpace Autonomy Research (CAESAR) at Stanford University is focusing on spacecraft autonomy. The center held a kickoff event on May 22, 2024, to highlight the industry, academia, and government collaboration it seeks to foster. This could lead to significant advancements in autonomous spacecraft technology. [Source: SpaceNews](https://spacenews.com/stanford-center-focuses-on-spacecraft-autonomy/)
  ```
</CodeGroup>

## Debugging and Troubleshooting

### Debugging Knowledge Issues

#### Check Agent Knowledge Initialization

```python
from crewai import Agent, Crew, Task
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

knowledge_source = StringKnowledgeSource(content="Test knowledge")

agent = Agent(
    role="Test Agent",
    goal="Test knowledge",
    backstory="Testing",
    knowledge_sources=[knowledge_source]
)

crew = Crew(agents=[agent], tasks=[Task(...)])

# Before kickoff - knowledge not initialized
print(f"Before kickoff - Agent knowledge: {getattr(agent, 'knowledge', None)}")

crew.kickoff()

# After kickoff - knowledge initialized
print(f"After kickoff - Agent knowledge: {agent.knowledge}")
print(f"Agent knowledge collection: {agent.knowledge.storage.collection_name}")
print(f"Number of sources: {len(agent.knowledge.sources)}")
```

#### Verify Knowledge Storage Locations

```python
import os
from crewai.utilities.paths import db_storage_path

# Check storage structure
storage_path = db_storage_path()
knowledge_path = os.path.join(storage_path, "knowledge")

if os.path.exists(knowledge_path):
    print("Knowledge collections found:")
    for collection in os.listdir(knowledge_path):
        collection_path = os.path.join(knowledge_path, collection)
        if os.path.isdir(collection_path):
            print(f"  - {collection}/")
            # Show collection contents
            for item in os.listdir(collection_path):
                print(f"    ‚îî‚îÄ‚îÄ {item}")
```

#### Test Knowledge Retrieval

```python
# Test agent knowledge retrieval
if hasattr(agent, 'knowledge') and agent.knowledge:
    test_query = ["test query"]
    results = agent.knowledge.query(test_query)
    print(f"Agent knowledge results: {len(results)} documents found")

    # Test crew knowledge retrieval (if exists)
    if hasattr(crew, 'knowledge') and crew.knowledge:
        crew_results = crew.query_knowledge(test_query)
        print(f"Crew knowledge results: {len(crew_results)} documents found")
```

#### Inspect Knowledge Collections

```python
import chromadb
from crewai.utilities.paths import db_storage_path
import os

# Connect to CrewAI's knowledge ChromaDB
knowledge_path = os.path.join(db_storage_path(), "knowledge")

if os.path.exists(knowledge_path):
    client = chromadb.PersistentClient(path=knowledge_path)
    collections = client.list_collections()

    print("Knowledge Collections:")
    for collection in collections:
        print(f"  - {collection.name}: {collection.count()} documents")

        # Sample a few documents to verify content
        if collection.count() > 0:
            sample = collection.peek(limit=2)
            print(f"    Sample content: {sample['documents'][0][:100]}...")
else:
    print("No knowledge storage found")
```

#### Check Knowledge Processing

```python
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# Create a test knowledge source
test_source = StringKnowledgeSource(
    content="Test knowledge content for debugging",
    chunk_size=100,  # Small chunks for testing
    chunk_overlap=20
)

# Check chunking behavior
print(f"Original content length: {len(test_source.content)}")
print(f"Chunk size: {test_source.chunk_size}")
print(f"Chunk overlap: {test_source.chunk_overlap}")

# Process and inspect chunks
test_source.add()
print(f"Number of chunks created: {len(test_source.chunks)}")
for i, chunk in enumerate(test_source.chunks[:3]):  # Show first 3 chunks
    print(f"Chunk {i+1}: {chunk[:50]}...")
```

### Common Knowledge Storage Issues

**"File not found" errors:**

```python
# Ensure files are in the correct location
from crewai.utilities.constants import KNOWLEDGE_DIRECTORY
import os

knowledge_dir = KNOWLEDGE_DIRECTORY  # Usually "knowledge"
file_path = os.path.join(knowledge_dir, "your_file.pdf")

if not os.path.exists(file_path):
    print(f"File not found: {file_path}")
    print(f"Current working directory: {os.getcwd()}")
    print(f"Expected knowledge directory: {os.path.abspath(knowledge_dir)}")
```

**"Embedding dimension mismatch" errors:**

```python
# This happens when switching embedding providers
# Reset knowledge storage to clear old embeddings
crew.reset_memories(command_type='knowledge')

# Or use consistent embedding providers
crew = Crew(
    agents=[...],
    tasks=[...],
    knowledge_sources=[...],
    embedder={"provider": "openai", "config": {"model": "text-embedding-3-small"}}
)
```

**"ChromaDB permission denied" errors:**

```bash
# Fix storage permissions
chmod -R 755 ~/.local/share/CrewAI/
```

**Knowledge not persisting between runs:**

```python
# Verify storage location consistency
import os
from crewai.utilities.paths import db_storage_path

print("CREWAI_STORAGE_DIR:", os.getenv("CREWAI_STORAGE_DIR"))
print("Computed storage path:", db_storage_path())
print("Knowledge path:", os.path.join(db_storage_path(), "knowledge"))
```

### Knowledge Reset Commands

```python
# Reset only agent-specific knowledge
crew.reset_memories(command_type='agent_knowledge')

# Reset both crew and agent knowledge
crew.reset_memories(command_type='knowledge')

# CLI commands
# crewai reset-memories --agent-knowledge  # Agent knowledge only
# crewai reset-memories --knowledge        # All knowledge
```

### Clearing Knowledge

If you need to clear the knowledge stored in CrewAI, you can use the `crewai reset-memories` command with the `--knowledge` option.

```bash Command
crewai reset-memories --knowledge
```

This is useful when you've updated your knowledge sources and want to ensure that the agents are using the most recent information.

## Best Practices

<AccordionGroup>
  <Accordion title="Content Organization">
    * Keep chunk sizes appropriate for your content type
    * Consider content overlap for context preservation
    * Organize related information into separate knowledge sources
  </Accordion>

  <Accordion title="Performance Tips">
    * Adjust chunk sizes based on content complexity
    * Configure appropriate embedding models
    * Consider using local embedding providers for faster processing
  </Accordion>

  <Accordion title="One Time Knowledge">
    * With the typical file structure provided by CrewAI, knowledge sources are embedded every time the kickoff is triggered.
    * If the knowledge sources are large, this leads to inefficiency and increased latency, as the same data is embedded each time.
    * To resolve this, directly initialize the knowledge parameter instead of the knowledge\_sources parameter.
    * Link to the issue to get complete idea [Github Issue](https://github.com/crewAIInc/crewAI/issues/2755)
  </Accordion>

  <Accordion title="Knowledge Management">
    * Use agent-level knowledge for role-specific information
    * Use crew-level knowledge for shared information all agents need
    * Set embedders at agent level if you need different embedding strategies
    * Use consistent collection naming by keeping agent roles descriptive
    * Test knowledge initialization by checking agent.knowledge after kickoff
    * Monitor storage locations to understand where knowledge is stored
    * Reset knowledge appropriately using the correct command types
  </Accordion>

  <Accordion title="Production Best Practices">
    * Set `CREWAI_STORAGE_DIR` to a known location in production
    * Choose explicit embedding providers to match your LLM setup and avoid API key conflicts
    * Monitor knowledge storage size as it grows with document additions
    * Organize knowledge sources by domain or purpose using collection names
    * Include knowledge directories in your backup and deployment strategies
    * Set appropriate file permissions for knowledge files and storage directories
    * Use environment variables for API keys and sensitive configuration
  </Accordion>
</AccordionGroup>


# LLMs
Source: https://docs.crewai.com/en/concepts/llms

A comprehensive guide to configuring and using Large Language Models (LLMs) in your CrewAI projects

## Overview

CrewAI integrates with multiple LLM providers through LiteLLM, giving you the flexibility to choose the right model for your specific use case. This guide will help you understand how to configure and use different LLM providers in your CrewAI projects.

## What are LLMs?

Large Language Models (LLMs) are the core intelligence behind CrewAI agents. They enable agents to understand context, make decisions, and generate human-like responses. Here's what you need to know:

<CardGroup cols={2}>
  <Card title="LLM Basics" icon="brain">
    Large Language Models are AI systems trained on vast amounts of text data. They power the intelligence of your CrewAI agents, enabling them to understand and generate human-like text.
  </Card>

  <Card title="Context Window" icon="window">
    The context window determines how much text an LLM can process at once. Larger windows (e.g., 128K tokens) allow for more context but may be more expensive and slower.
  </Card>

  <Card title="Temperature" icon="temperature-three-quarters">
    Temperature (0.0 to 1.0) controls response randomness. Lower values (e.g., 0.2) produce more focused, deterministic outputs, while higher values (e.g., 0.8) increase creativity and variability.
  </Card>

  <Card title="Provider Selection" icon="server">
    Each LLM provider (e.g., OpenAI, Anthropic, Google) offers different models with varying capabilities, pricing, and features. Choose based on your needs for accuracy, speed, and cost.
  </Card>
</CardGroup>

## Setting up your LLM

There are different places in CrewAI code where you can specify the model to use. Once you specify the model you are using, you will need to provide the configuration (like an API key) for each of the model providers you use. See the [provider configuration examples](#provider-configuration-examples) section for your provider.

<Tabs>
  <Tab title="1. Environment Variables">
    The simplest way to get started. Set the model in your environment directly, through an `.env` file or in your app code. If you used `crewai create` to bootstrap your project, it will be set already.

    ```bash .env
    MODEL=model-id  # e.g. gpt-4o, gemini-2.0-flash, claude-3-sonnet-...

    # Be sure to set your API keys here too. See the Provider
    # section below.
    ```

    <Warning>
      Never commit API keys to version control. Use environment files (.env) or your system's secret management.
    </Warning>
  </Tab>

  <Tab title="2. YAML Configuration">
    Create a YAML file to define your agent configurations. This method is great for version control and team collaboration:

    ```yaml agents.yaml {6}
    researcher:
        role: Research Specialist
        goal: Conduct comprehensive research and analysis
        backstory: A dedicated research professional with years of experience
        verbose: true
        llm: provider/model-id  # e.g. openai/gpt-4o, google/gemini-2.0-flash, anthropic/claude...
        # (see provider configuration examples below for more)
    ```

    <Info>
      The YAML configuration allows you to:

      * Version control your agent settings
      * Easily switch between different models
      * Share configurations across team members
      * Document model choices and their purposes
    </Info>
  </Tab>

  <Tab title="3. Direct Code">
    For maximum flexibility, configure LLMs directly in your Python code:

    ```python {4,8}
    from crewai import LLM

    # Basic configuration
    llm = LLM(model="model-id-here")  # gpt-4o, gemini-2.0-flash, anthropic/claude...

    # Advanced configuration with detailed parameters
    llm = LLM(
        model="model-id-here",  # gpt-4o, gemini-2.0-flash, anthropic/claude...
        temperature=0.7,        # Higher for more creative outputs
        timeout=120,            # Seconds to wait for response
        max_tokens=4000,        # Maximum length of response
        top_p=0.9,              # Nucleus sampling parameter
        frequency_penalty=0.1 , # Reduce repetition
        presence_penalty=0.1,   # Encourage topic diversity
        response_format={"type": "json"},  # For structured outputs
        seed=42                 # For reproducible results
    )
    ```

    <Info>
      Parameter explanations:

      * `temperature`: Controls randomness (0.0-1.0)
      * `timeout`: Maximum wait time for response
      * `max_tokens`: Limits response length
      * `top_p`: Alternative to temperature for sampling
      * `frequency_penalty`: Reduces word repetition
      * `presence_penalty`: Encourages new topics
      * `response_format`: Specifies output structure
      * `seed`: Ensures consistent outputs
    </Info>
  </Tab>
</Tabs>

## Provider Configuration Examples

CrewAI supports a multitude of LLM providers, each offering unique features, authentication methods, and model capabilities.
In this section, you'll find detailed examples that help you select, configure, and optimize the LLM that best fits your project's needs.

<AccordionGroup>
  <Accordion title="OpenAI">
    Set the following environment variables in your `.env` file:

    ```toml Code
    # Required
    OPENAI_API_KEY=sk-...

    # Optional
    OPENAI_API_BASE=<custom-base-url>
    OPENAI_ORGANIZATION=<your-org-id>
    ```

    Example usage in your CrewAI project:

    ```python Code
    from crewai import LLM

    llm = LLM(
        model="openai/gpt-4", # call model by provider/model_name
        temperature=0.8,
        max_tokens=150,
        top_p=0.9,
        frequency_penalty=0.1,
        presence_penalty=0.1,
        stop=["END"],
        seed=42
    )
    ```

    OpenAI is one of the leading providers of LLMs with a wide range of models and features.

    | Model                | Context Window | Best For                                |
    | -------------------- | -------------- | --------------------------------------- |
    | GPT-4                | 8,192 tokens   | High-accuracy tasks, complex reasoning  |
    | GPT-4 Turbo          | 128,000 tokens | Long-form content, document analysis    |
    | GPT-4o & GPT-4o-mini | 128,000 tokens | Cost-effective large context processing |
    | o3-mini              | 200,000 tokens | Fast reasoning, complex reasoning       |
    | o1-mini              | 128,000 tokens | Fast reasoning, complex reasoning       |
    | o1-preview           | 128,000 tokens | Fast reasoning, complex reasoning       |
    | o1                   | 200,000 tokens | Fast reasoning, complex reasoning       |
  </Accordion>

  <Accordion title="Meta-Llama">
    Meta's Llama API provides access to Meta's family of large language models.
    The API is available through the [Meta Llama API](https://llama.developer.meta.com?utm_source=partner-crewai\&utm_medium=website).
    Set the following environment variables in your `.env` file:

    ```toml Code
    # Meta Llama API Key Configuration
    LLAMA_API_KEY=LLM|your_api_key_here
    ```

    Example usage in your CrewAI project:

    ```python Code
    from crewai import LLM

    # Initialize Meta Llama LLM
    llm = LLM(
        model="meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8",
        temperature=0.8,
        stop=["END"],
        seed=42
    )
    ```

    All models listed here [https://llama.developer.meta.com/docs/models/](https://llama.developer.meta.com/docs/models/) are supported.

    | Model ID                                            | Input context length | Output context length | Input Modalities | Output Modalities |
    | --------------------------------------------------- | -------------------- | --------------------- | ---------------- | ----------------- |
    | `meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8`     | 128k                 | 4028                  | Text, Image      | Text              |
    | `meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8` | 128k                 | 4028                  | Text, Image      | Text              |
    | `meta_llama/Llama-3.3-70B-Instruct`                 | 128k                 | 4028                  | Text             | Text              |
    | `meta_llama/Llama-3.3-8B-Instruct`                  | 128k                 | 4028                  | Text             | Text              |
  </Accordion>

  <Accordion title="Anthropic">
    ```toml Code
    # Required
    ANTHROPIC_API_KEY=sk-ant-...

    # Optional
    ANTHROPIC_API_BASE=<custom-base-url>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="anthropic/claude-3-sonnet-20240229-v1:0",
        temperature=0.7
    )
    ```
  </Accordion>

  <Accordion title="Google (Gemini API)">
    Set your API key in your `.env` file. If you need a key, or need to find an
    existing key, check [AI Studio](https://aistudio.google.com/apikey).

    ```toml .env
    # https://ai.google.dev/gemini-api/docs/api-key
    GEMINI_API_KEY=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    from crewai import LLM

    llm = LLM(
        model="gemini/gemini-2.0-flash",
        temperature=0.7,
    )
    ```

    ### Gemini models

    Google offers a range of powerful models optimized for different use cases.

    | Model                          | Context Window | Best For                                                                                                         |
    | ------------------------------ | -------------- | ---------------------------------------------------------------------------------------------------------------- |
    | gemini-2.5-flash-preview-04-17 | 1M tokens      | Adaptive thinking, cost efficiency                                                                               |
    | gemini-2.5-pro-preview-05-06   | 1M tokens      | Enhanced thinking and reasoning, multimodal understanding, advanced coding, and more                             |
    | gemini-2.0-flash               | 1M tokens      | Next generation features, speed, thinking, and realtime streaming                                                |
    | gemini-2.0-flash-lite          | 1M tokens      | Cost efficiency and low latency                                                                                  |
    | gemini-1.5-flash               | 1M tokens      | Balanced multimodal model, good for most tasks                                                                   |
    | gemini-1.5-flash-8B            | 1M tokens      | Fastest, most cost-efficient, good for high-frequency tasks                                                      |
    | gemini-1.5-pro                 | 2M tokens      | Best performing, wide variety of reasoning tasks including logical reasoning, coding, and creative collaboration |

    The full list of models is available in the [Gemini model docs](https://ai.google.dev/gemini-api/docs/models).

    ### Gemma

    The Gemini API also allows you to use your API key to access [Gemma models](https://ai.google.dev/gemma/docs) hosted on Google infrastructure.

    | Model          | Context Window |
    | -------------- | -------------- |
    | gemma-3-1b-it  | 32k tokens     |
    | gemma-3-4b-it  | 32k tokens     |
    | gemma-3-12b-it | 32k tokens     |
    | gemma-3-27b-it | 128k tokens    |
  </Accordion>

  <Accordion title="Google (Vertex AI)">
    Get credentials from your Google Cloud Console and save it to a JSON file, then load it with the following code:

    ```python Code
    import json

    file_path = 'path/to/vertex_ai_service_account.json'

    # Load the JSON file
    with open(file_path, 'r') as file:
        vertex_credentials = json.load(file)

    # Convert the credentials to a JSON string
    vertex_credentials_json = json.dumps(vertex_credentials)
    ```

    Example usage in your CrewAI project:

    ```python Code
    from crewai import LLM

    llm = LLM(
        model="gemini/gemini-1.5-pro-latest",
        temperature=0.7,
        vertex_credentials=vertex_credentials_json
    )
    ```

    Google offers a range of powerful models optimized for different use cases:

    | Model                          | Context Window | Best For                                                                                                         |
    | ------------------------------ | -------------- | ---------------------------------------------------------------------------------------------------------------- |
    | gemini-2.5-flash-preview-04-17 | 1M tokens      | Adaptive thinking, cost efficiency                                                                               |
    | gemini-2.5-pro-preview-05-06   | 1M tokens      | Enhanced thinking and reasoning, multimodal understanding, advanced coding, and more                             |
    | gemini-2.0-flash               | 1M tokens      | Next generation features, speed, thinking, and realtime streaming                                                |
    | gemini-2.0-flash-lite          | 1M tokens      | Cost efficiency and low latency                                                                                  |
    | gemini-1.5-flash               | 1M tokens      | Balanced multimodal model, good for most tasks                                                                   |
    | gemini-1.5-flash-8B            | 1M tokens      | Fastest, most cost-efficient, good for high-frequency tasks                                                      |
    | gemini-1.5-pro                 | 2M tokens      | Best performing, wide variety of reasoning tasks including logical reasoning, coding, and creative collaboration |
  </Accordion>

  <Accordion title="Azure">
    ```toml Code
    # Required
    AZURE_API_KEY=<your-api-key>
    AZURE_API_BASE=<your-resource-url>
    AZURE_API_VERSION=<api-version>

    # Optional
    AZURE_AD_TOKEN=<your-azure-ad-token>
    AZURE_API_TYPE=<your-azure-api-type>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="azure/gpt-4",
        api_version="2023-05-15"
    )
    ```
  </Accordion>

  <Accordion title="AWS Bedrock">
    ```toml Code
    AWS_ACCESS_KEY_ID=<your-access-key>
    AWS_SECRET_ACCESS_KEY=<your-secret-key>
    AWS_DEFAULT_REGION=<your-region>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="bedrock/anthropic.claude-3-sonnet-20240229-v1:0"
    )
    ```

    Before using Amazon Bedrock, make sure you have boto3 installed in your environment

    [Amazon Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/models-regions.html) is a managed service that provides access to multiple foundation models from top AI companies through a unified API, enabling secure and responsible AI application development.

    | Model                   | Context Window     | Best For                                                                                                                              |
    | ----------------------- | ------------------ | ------------------------------------------------------------------------------------------------------------------------------------- |
    | Amazon Nova Pro         | Up to 300k tokens  | High-performance, model balancing accuracy, speed, and cost-effectiveness across diverse tasks.                                       |
    | Amazon Nova Micro       | Up to 128k tokens  | High-performance, cost-effective text-only model optimized for lowest latency responses.                                              |
    | Amazon Nova Lite        | Up to 300k tokens  | High-performance, affordable multimodal processing for images, video, and text with real-time capabilities.                           |
    | Claude 3.7 Sonnet       | Up to 128k tokens  | High-performance, best for complex reasoning, coding & AI agents                                                                      |
    | Claude 3.5 Sonnet v2    | Up to 200k tokens  | State-of-the-art model specialized in software engineering, agentic capabilities, and computer interaction at optimized cost.         |
    | Claude 3.5 Sonnet       | Up to 200k tokens  | High-performance model delivering superior intelligence and reasoning across diverse tasks with optimal speed-cost balance.           |
    | Claude 3.5 Haiku        | Up to 200k tokens  | Fast, compact multimodal model optimized for quick responses and seamless human-like interactions                                     |
    | Claude 3 Sonnet         | Up to 200k tokens  | Multimodal model balancing intelligence and speed for high-volume deployments.                                                        |
    | Claude 3 Haiku          | Up to 200k tokens  | Compact, high-speed multimodal model optimized for quick responses and natural conversational interactions                            |
    | Claude 3 Opus           | Up to 200k tokens  | Most advanced multimodal model exceling at complex tasks with human-like reasoning and superior contextual understanding.             |
    | Claude 2.1              | Up to 200k tokens  | Enhanced version with expanded context window, improved reliability, and reduced hallucinations for long-form and RAG applications    |
    | Claude                  | Up to 100k tokens  | Versatile model excelling in sophisticated dialogue, creative content, and precise instruction following.                             |
    | Claude Instant          | Up to 100k tokens  | Fast, cost-effective model for everyday tasks like dialogue, analysis, summarization, and document Q\&A                               |
    | Llama 3.1 405B Instruct | Up to 128k tokens  | Advanced LLM for synthetic data generation, distillation, and inference for chatbots, coding, and domain-specific tasks.              |
    | Llama 3.1 70B Instruct  | Up to 128k tokens  | Powers complex conversations with superior contextual understanding, reasoning and text generation.                                   |
    | Llama 3.1 8B Instruct   | Up to 128k tokens  | Advanced state-of-the-art model with language understanding, superior reasoning, and text generation.                                 |
    | Llama 3 70B Instruct    | Up to 8k tokens    | Powers complex conversations with superior contextual understanding, reasoning and text generation.                                   |
    | Llama 3 8B Instruct     | Up to 8k tokens    | Advanced state-of-the-art LLM with language understanding, superior reasoning, and text generation.                                   |
    | Titan Text G1 - Lite    | Up to 4k tokens    | Lightweight, cost-effective model optimized for English tasks and fine-tuning with focus on summarization and content generation.     |
    | Titan Text G1 - Express | Up to 8k tokens    | Versatile model for general language tasks, chat, and RAG applications with support for English and 100+ languages.                   |
    | Cohere Command          | Up to 4k tokens    | Model specialized in following user commands and delivering practical enterprise solutions.                                           |
    | Jurassic-2 Mid          | Up to 8,191 tokens | Cost-effective model balancing quality and affordability for diverse language tasks like Q\&A, summarization, and content generation. |
    | Jurassic-2 Ultra        | Up to 8,191 tokens | Model for advanced text generation and comprehension, excelling in complex tasks like analysis and content creation.                  |
    | Jamba-Instruct          | Up to 256k tokens  | Model with extended context window optimized for cost-effective text generation, summarization, and Q\&A.                             |
    | Mistral 7B Instruct     | Up to 32k tokens   | This LLM follows instructions, completes requests, and generates creative text.                                                       |
    | Mistral 8x7B Instruct   | Up to 32k tokens   | An MOE LLM that follows instructions, completes requests, and generates creative text.                                                |
  </Accordion>

  <Accordion title="Amazon SageMaker">
    ```toml Code
    AWS_ACCESS_KEY_ID=<your-access-key>
    AWS_SECRET_ACCESS_KEY=<your-secret-key>
    AWS_DEFAULT_REGION=<your-region>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="sagemaker/<my-endpoint>"
    )
    ```
  </Accordion>

  <Accordion title="Mistral">
    Set the following environment variables in your `.env` file:

    ```toml Code
    MISTRAL_API_KEY=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="mistral/mistral-large-latest",
        temperature=0.7
    )
    ```
  </Accordion>

  <Accordion title="Nvidia NIM">
    Set the following environment variables in your `.env` file:

    ```toml Code
    NVIDIA_API_KEY=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="nvidia_nim/meta/llama3-70b-instruct",
        temperature=0.7
    )
    ```

    Nvidia NIM provides a comprehensive suite of models for various use cases, from general-purpose tasks to specialized applications.

    | Model                                       | Context Window | Best For                                                                                                                    |
    | ------------------------------------------- | -------------- | --------------------------------------------------------------------------------------------------------------------------- |
    | nvidia/mistral-nemo-minitron-8b-8k-instruct | 8,192 tokens   | State-of-the-art small language model delivering superior accuracy for chatbot, virtual assistants, and content generation. |
    | nvidia/nemotron-4-mini-hindi-4b-instruct    | 4,096 tokens   | A bilingual Hindi-English SLM for on-device inference, tailored specifically for Hindi Language.                            |
    | nvidia/llama-3.1-nemotron-70b-instruct      | 128k tokens    | Customized for enhanced helpfulness in responses                                                                            |
    | nvidia/llama3-chatqa-1.5-8b                 | 128k tokens    | Advanced LLM to generate high-quality, context-aware responses for chatbots and search engines.                             |
    | nvidia/llama3-chatqa-1.5-70b                | 128k tokens    | Advanced LLM to generate high-quality, context-aware responses for chatbots and search engines.                             |
    | nvidia/vila                                 | 128k tokens    | Multi-modal vision-language model that understands text/img/video and creates informative responses                         |
    | nvidia/neva-22                              | 4,096 tokens   | Multi-modal vision-language model that understands text/images and generates informative responses                          |
    | nvidia/nemotron-mini-4b-instruct            | 8,192 tokens   | General-purpose tasks                                                                                                       |
    | nvidia/usdcode-llama3-70b-instruct          | 128k tokens    | State-of-the-art LLM that answers OpenUSD knowledge queries and generates USD-Python code.                                  |
    | nvidia/nemotron-4-340b-instruct             | 4,096 tokens   | Creates diverse synthetic data that mimics the characteristics of real-world data.                                          |
    | meta/codellama-70b                          | 100k tokens    | LLM capable of generating code from natural language and vice versa.                                                        |
    | meta/llama2-70b                             | 4,096 tokens   | Cutting-edge large language AI model capable of generating text and code in response to prompts.                            |
    | meta/llama3-8b-instruct                     | 8,192 tokens   | Advanced state-of-the-art LLM with language understanding, superior reasoning, and text generation.                         |
    | meta/llama3-70b-instruct                    | 8,192 tokens   | Powers complex conversations with superior contextual understanding, reasoning and text generation.                         |
    | meta/llama-3.1-8b-instruct                  | 128k tokens    | Advanced state-of-the-art model with language understanding, superior reasoning, and text generation.                       |
    | meta/llama-3.1-70b-instruct                 | 128k tokens    | Powers complex conversations with superior contextual understanding, reasoning and text generation.                         |
    | meta/llama-3.1-405b-instruct                | 128k tokens    | Advanced LLM for synthetic data generation, distillation, and inference for chatbots, coding, and domain-specific tasks.    |
    | meta/llama-3.2-1b-instruct                  | 128k tokens    | Advanced state-of-the-art small language model with language understanding, superior reasoning, and text generation.        |
    | meta/llama-3.2-3b-instruct                  | 128k tokens    | Advanced state-of-the-art small language model with language understanding, superior reasoning, and text generation.        |
    | meta/llama-3.2-11b-vision-instruct          | 128k tokens    | Advanced state-of-the-art small language model with language understanding, superior reasoning, and text generation.        |
    | meta/llama-3.2-90b-vision-instruct          | 128k tokens    | Advanced state-of-the-art small language model with language understanding, superior reasoning, and text generation.        |
    | google/gemma-7b                             | 8,192 tokens   | Cutting-edge text generation model text understanding, transformation, and code generation.                                 |
    | google/gemma-2b                             | 8,192 tokens   | Cutting-edge text generation model text understanding, transformation, and code generation.                                 |
    | google/codegemma-7b                         | 8,192 tokens   | Cutting-edge model built on Google's Gemma-7B specialized for code generation and code completion.                          |
    | google/codegemma-1.1-7b                     | 8,192 tokens   | Advanced programming model for code generation, completion, reasoning, and instruction following.                           |
    | google/recurrentgemma-2b                    | 8,192 tokens   | Novel recurrent architecture based language model for faster inference when generating long sequences.                      |
    | google/gemma-2-9b-it                        | 8,192 tokens   | Cutting-edge text generation model text understanding, transformation, and code generation.                                 |
    | google/gemma-2-27b-it                       | 8,192 tokens   | Cutting-edge text generation model text understanding, transformation, and code generation.                                 |
    | google/gemma-2-2b-it                        | 8,192 tokens   | Cutting-edge text generation model text understanding, transformation, and code generation.                                 |
    | google/deplot                               | 512 tokens     | One-shot visual language understanding model that translates images of plots into tables.                                   |
    | google/paligemma                            | 8,192 tokens   | Vision language model adept at comprehending text and visual inputs to produce informative responses.                       |
    | mistralai/mistral-7b-instruct-v0.2          | 32k tokens     | This LLM follows instructions, completes requests, and generates creative text.                                             |
    | mistralai/mixtral-8x7b-instruct-v0.1        | 8,192 tokens   | An MOE LLM that follows instructions, completes requests, and generates creative text.                                      |
    | mistralai/mistral-large                     | 4,096 tokens   | Creates diverse synthetic data that mimics the characteristics of real-world data.                                          |
    | mistralai/mixtral-8x22b-instruct-v0.1       | 8,192 tokens   | Creates diverse synthetic data that mimics the characteristics of real-world data.                                          |
    | mistralai/mistral-7b-instruct-v0.3          | 32k tokens     | This LLM follows instructions, completes requests, and generates creative text.                                             |
    | nv-mistralai/mistral-nemo-12b-instruct      | 128k tokens    | Most advanced language model for reasoning, code, multilingual tasks; runs on a single GPU.                                 |
    | mistralai/mamba-codestral-7b-v0.1           | 256k tokens    | Model for writing and interacting with code across a wide range of programming languages and tasks.                         |
    | microsoft/phi-3-mini-128k-instruct          | 128K tokens    | Lightweight, state-of-the-art open LLM with strong math and logical reasoning skills.                                       |
    | microsoft/phi-3-mini-4k-instruct            | 4,096 tokens   | Lightweight, state-of-the-art open LLM with strong math and logical reasoning skills.                                       |
    | microsoft/phi-3-small-8k-instruct           | 8,192 tokens   | Lightweight, state-of-the-art open LLM with strong math and logical reasoning skills.                                       |
    | microsoft/phi-3-small-128k-instruct         | 128K tokens    | Lightweight, state-of-the-art open LLM with strong math and logical reasoning skills.                                       |
    | microsoft/phi-3-medium-4k-instruct          | 4,096 tokens   | Lightweight, state-of-the-art open LLM with strong math and logical reasoning skills.                                       |
    | microsoft/phi-3-medium-128k-instruct        | 128K tokens    | Lightweight, state-of-the-art open LLM with strong math and logical reasoning skills.                                       |
    | microsoft/phi-3.5-mini-instruct             | 128K tokens    | Lightweight multilingual LLM powering AI applications in latency bound, memory/compute constrained environments             |
    | microsoft/phi-3.5-moe-instruct              | 128K tokens    | Advanced LLM based on Mixture of Experts architecture to deliver compute efficient content generation                       |
    | microsoft/kosmos-2                          | 1,024 tokens   | Groundbreaking multimodal model designed to understand and reason about visual elements in images.                          |
    | microsoft/phi-3-vision-128k-instruct        | 128k tokens    | Cutting-edge open multimodal model exceling in high-quality reasoning from images.                                          |
    | microsoft/phi-3.5-vision-instruct           | 128k tokens    | Cutting-edge open multimodal model exceling in high-quality reasoning from images.                                          |
    | databricks/dbrx-instruct                    | 12k tokens     | A general-purpose LLM with state-of-the-art performance in language understanding, coding, and RAG.                         |
    | snowflake/arctic                            | 1,024 tokens   | Delivers high efficiency inference for enterprise applications focused on SQL generation and coding.                        |
    | aisingapore/sea-lion-7b-instruct            | 4,096 tokens   | LLM to represent and serve the linguistic and cultural diversity of Southeast Asia                                          |
    | ibm/granite-8b-code-instruct                | 4,096 tokens   | Software programming LLM for code generation, completion, explanation, and multi-turn conversion.                           |
    | ibm/granite-34b-code-instruct               | 8,192 tokens   | Software programming LLM for code generation, completion, explanation, and multi-turn conversion.                           |
    | ibm/granite-3.0-8b-instruct                 | 4,096 tokens   | Advanced Small Language Model supporting RAG, summarization, classification, code, and agentic AI                           |
    | ibm/granite-3.0-3b-a800m-instruct           | 4,096 tokens   | Highly efficient Mixture of Experts model for RAG, summarization, entity extraction, and classification                     |
    | mediatek/breeze-7b-instruct                 | 4,096 tokens   | Creates diverse synthetic data that mimics the characteristics of real-world data.                                          |
    | upstage/solar-10.7b-instruct                | 4,096 tokens   | Excels in NLP tasks, particularly in instruction-following, reasoning, and mathematics.                                     |
    | writer/palmyra-med-70b-32k                  | 32k tokens     | Leading LLM for accurate, contextually relevant responses in the medical domain.                                            |
    | writer/palmyra-med-70b                      | 32k tokens     | Leading LLM for accurate, contextually relevant responses in the medical domain.                                            |
    | writer/palmyra-fin-70b-32k                  | 32k tokens     | Specialized LLM for financial analysis, reporting, and data processing                                                      |
    | 01-ai/yi-large                              | 32k tokens     | Powerful model trained on English and Chinese for diverse tasks including chatbot and creative writing.                     |
    | deepseek-ai/deepseek-coder-6.7b-instruct    | 2k tokens      | Powerful coding model offering advanced capabilities in code generation, completion, and infilling                          |
    | rakuten/rakutenai-7b-instruct               | 1,024 tokens   | Advanced state-of-the-art LLM with language understanding, superior reasoning, and text generation.                         |
    | rakuten/rakutenai-7b-chat                   | 1,024 tokens   | Advanced state-of-the-art LLM with language understanding, superior reasoning, and text generation.                         |
    | baichuan-inc/baichuan2-13b-chat             | 4,096 tokens   | Support Chinese and English chat, coding, math, instruction following, solving quizzes                                      |
  </Accordion>

  <Accordion title="Local NVIDIA NIM Deployed using WSL2">
    NVIDIA NIM enables you to run powerful LLMs locally on your Windows machine using WSL2 (Windows Subsystem for Linux).
    This approach allows you to leverage your NVIDIA GPU for private, secure, and cost-effective AI inference without relying on cloud services.
    Perfect for development, testing, or production scenarios where data privacy or offline capabilities are required.

    Here is a step-by-step guide to setting up a local NVIDIA NIM model:

    1. Follow installation instructions from [NVIDIA Website](https://docs.nvidia.com/nim/wsl2/latest/getting-started.html)

    2. Install the local model. For Llama 3.1-8b follow [instructions](https://build.nvidia.com/meta/llama-3_1-8b-instruct/deploy)

    3. Configure your crewai local models:

    ```python Code
    from crewai.llm import LLM

    local_nvidia_nim_llm = LLM(
        model="openai/meta/llama-3.1-8b-instruct", # it's an openai-api compatible model
        base_url="http://localhost:8000/v1",
        api_key="<your_api_key|any text if you have not configured it>", # api_key is required, but you can use any text
    )

    # Then you can use it in your crew:

    @CrewBase
    class MyCrew():
        # ...

        @agent
        def researcher(self) -> Agent:
            return Agent(
                config=self.agents_config['researcher'], # type: ignore[index]
                llm=local_nvidia_nim_llm
            )

        # ...
    ```
  </Accordion>

  <Accordion title="Groq">
    Set the following environment variables in your `.env` file:

    ```toml Code
    GROQ_API_KEY=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="groq/llama-3.2-90b-text-preview",
        temperature=0.7
    )
    ```

    | Model            | Context Window | Best For                              |
    | ---------------- | -------------- | ------------------------------------- |
    | Llama 3.1 70B/8B | 131,072 tokens | High-performance, large context tasks |
    | Llama 3.2 Series | 8,192 tokens   | General-purpose tasks                 |
    | Mixtral 8x7B     | 32,768 tokens  | Balanced performance and context      |
  </Accordion>

  <Accordion title="IBM watsonx.ai">
    Set the following environment variables in your `.env` file:

    ```toml Code
    # Required
    WATSONX_URL=<your-url>
    WATSONX_APIKEY=<your-apikey>
    WATSONX_PROJECT_ID=<your-project-id>

    # Optional
    WATSONX_TOKEN=<your-token>
    WATSONX_DEPLOYMENT_SPACE_ID=<your-space-id>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="watsonx/meta-llama/llama-3-1-70b-instruct",
        base_url="https://api.watsonx.ai/v1"
    )
    ```
  </Accordion>

  <Accordion title="Ollama (Local LLMs)">
    1. Install Ollama: [ollama.ai](https://ollama.ai/)
    2. Run a model: `ollama run llama3`
    3. Configure:

    ```python Code
    llm = LLM(
        model="ollama/llama3:70b",
        base_url="http://localhost:11434"
    )
    ```
  </Accordion>

  <Accordion title="Fireworks AI">
    Set the following environment variables in your `.env` file:

    ```toml Code
    FIREWORKS_API_KEY=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="fireworks_ai/accounts/fireworks/models/llama-v3-70b-instruct",
        temperature=0.7
    )
    ```
  </Accordion>

  <Accordion title="Perplexity AI">
    Set the following environment variables in your `.env` file:

    ```toml Code
    PERPLEXITY_API_KEY=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="llama-3.1-sonar-large-128k-online",
        base_url="https://api.perplexity.ai/"
    )
    ```
  </Accordion>

  <Accordion title="Hugging Face">
    Set the following environment variables in your `.env` file:

    ```toml Code
    HF_TOKEN=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="huggingface/meta-llama/Meta-Llama-3.1-8B-Instruct"
    )
    ```
  </Accordion>

  <Accordion title="SambaNova">
    Set the following environment variables in your `.env` file:

    ```toml Code
    SAMBANOVA_API_KEY=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="sambanova/Meta-Llama-3.1-8B-Instruct",
        temperature=0.7
    )
    ```

    | Model            | Context Window       | Best For                              |
    | ---------------- | -------------------- | ------------------------------------- |
    | Llama 3.1 70B/8B | Up to 131,072 tokens | High-performance, large context tasks |
    | Llama 3.1 405B   | 8,192 tokens         | High-performance and output quality   |
    | Llama 3.2 Series | 8,192 tokens         | General-purpose, multimodal tasks     |
    | Llama 3.3 70B    | Up to 131,072 tokens | High-performance and output quality   |
    | Qwen2 familly    | 8,192 tokens         | High-performance and output quality   |
  </Accordion>

  <Accordion title="Cerebras">
    Set the following environment variables in your `.env` file:

    ```toml Code
    # Required
    CEREBRAS_API_KEY=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="cerebras/llama3.1-70b",
        temperature=0.7,
        max_tokens=8192
    )
    ```

    <Info>
      Cerebras features:

      * Fast inference speeds
      * Competitive pricing
      * Good balance of speed and quality
      * Support for long context windows
    </Info>
  </Accordion>

  <Accordion title="Open Router">
    Set the following environment variables in your `.env` file:

    ```toml Code
    OPENROUTER_API_KEY=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="openrouter/deepseek/deepseek-r1",
        base_url="https://openrouter.ai/api/v1",
        api_key=OPENROUTER_API_KEY
    )
    ```

    <Info>
      Open Router models:

      * openrouter/deepseek/deepseek-r1
      * openrouter/deepseek/deepseek-chat
    </Info>
  </Accordion>

  <Accordion title="Nebius AI Studio">
    Set the following environment variables in your `.env` file:

    ```toml Code
    NEBIUS_API_KEY=<your-api-key>
    ```

    Example usage in your CrewAI project:

    ```python Code
    llm = LLM(
        model="nebius/Qwen/Qwen3-30B-A3B"
    )
    ```

    <Info>
      Nebius AI Studio features:

      * Large collection of open source models
      * Higher rate limits
      * Competitive pricing
      * Good balance of speed and quality
    </Info>
  </Accordion>
</AccordionGroup>

## Streaming Responses

CrewAI supports streaming responses from LLMs, allowing your application to receive and process outputs in real-time as they're generated.

<Tabs>
  <Tab title="Basic Setup">
    Enable streaming by setting the `stream` parameter to `True` when initializing your LLM:

    ```python
    from crewai import LLM

    # Create an LLM with streaming enabled
    llm = LLM(
        model="openai/gpt-4o",
        stream=True  # Enable streaming
    )
    ```

    When streaming is enabled, responses are delivered in chunks as they're generated, creating a more responsive user experience.
  </Tab>

  <Tab title="Event Handling">
    CrewAI emits events for each chunk received during streaming:

    ```python
    from crewai.utilities.events import (
      LLMStreamChunkEvent
    )
    from crewai.utilities.events.base_event_listener import BaseEventListener

    class MyCustomListener(BaseEventListener):
        def setup_listeners(self, crewai_event_bus):
            @crewai_event_bus.on(LLMStreamChunkEvent)
            def on_llm_stream_chunk(self, event: LLMStreamChunkEvent):
              # Process each chunk as it arrives
              print(f"Received chunk: {event.chunk}")

    my_listener = MyCustomListener()
    ```

    <Tip>
      [Click here](https://docs.crewai.com/concepts/event-listener#event-listeners) for more details
    </Tip>
  </Tab>

  <Tab title="Agent & Task Tracking">
    All LLM events in CrewAI include agent and task information, allowing you to track and filter LLM interactions by specific agents or tasks:

    ```python
    from crewai import LLM, Agent, Task, Crew
    from crewai.utilities.events import LLMStreamChunkEvent
    from crewai.utilities.events.base_event_listener import BaseEventListener

    class MyCustomListener(BaseEventListener):
        def setup_listeners(self, crewai_event_bus):
            @crewai_event_bus.on(LLMStreamChunkEvent)
            def on_llm_stream_chunk(source, event):
                if researcher.id == event.agent_id:
                    print("\n==============\n Got event:", event, "\n==============\n")


    my_listener = MyCustomListener()

    llm = LLM(model="gpt-4o-mini", temperature=0, stream=True)

    researcher = Agent(
        role="About User",
        goal="You know everything about the user.",
        backstory="""You are a master at understanding people and their preferences.""",
        llm=llm,
    )

    search = Task(
        description="Answer the following questions about the user: {question}",
        expected_output="An answer to the question.",
        agent=researcher,
    )

    crew = Crew(agents=[researcher], tasks=[search])

    result = crew.kickoff(
        inputs={"question": "..."}
    )
    ```

    <Info>
      This feature is particularly useful for:

      * Debugging specific agent behaviors
      * Logging LLM usage by task type
      * Auditing which agents are making what types of LLM calls
      * Performance monitoring of specific tasks
    </Info>
  </Tab>
</Tabs>

## Structured LLM Calls

CrewAI supports structured responses from LLM calls by allowing you to define a `response_format` using a Pydantic model. This enables the framework to automatically parse and validate the output, making it easier to integrate the response into your application without manual post-processing.

For example, you can define a Pydantic model to represent the expected response structure and pass it as the `response_format` when instantiating the LLM. The model will then be used to convert the LLM output into a structured Python object.

```python Code
from crewai import LLM

class Dog(BaseModel):
    name: str
    age: int
    breed: str


llm = LLM(model="gpt-4o", response_format=Dog)

response = llm.call(
    "Analyze the following messages and return the name, age, and breed. "
    "Meet Kona! She is 3 years old and is a black german shepherd."
)
print(response)

# Output:
# Dog(name='Kona', age=3, breed='black german shepherd')
```

## Advanced Features and Optimization

Learn how to get the most out of your LLM configuration:

<AccordionGroup>
  <Accordion title="Context Window Management">
    CrewAI includes smart context management features:

    ```python
    from crewai import LLM

    # CrewAI automatically handles:
    # 1. Token counting and tracking
    # 2. Content summarization when needed
    # 3. Task splitting for large contexts

    llm = LLM(
        model="gpt-4",
        max_tokens=4000,  # Limit response length
    )
    ```

    <Info>
      Best practices for context management:

      1. Choose models with appropriate context windows
      2. Pre-process long inputs when possible
      3. Use chunking for large documents
      4. Monitor token usage to optimize costs
    </Info>
  </Accordion>

  <Accordion title="Performance Optimization">
    <Steps>
      <Step title="Token Usage Optimization">
        Choose the right context window for your task:

        * Small tasks (up to 4K tokens): Standard models
        * Medium tasks (between 4K-32K): Enhanced models
        * Large tasks (over 32K): Large context models

        ```python
        # Configure model with appropriate settings
        llm = LLM(
            model="openai/gpt-4-turbo-preview",
            temperature=0.7,    # Adjust based on task
            max_tokens=4096,    # Set based on output needs
            timeout=300        # Longer timeout for complex tasks
        )
        ```

        <Tip>
          * Lower temperature (0.1 to 0.3) for factual responses
          * Higher temperature (0.7 to 0.9) for creative tasks
        </Tip>
      </Step>

      <Step title="Best Practices">
        1. Monitor token usage
        2. Implement rate limiting
        3. Use caching when possible
        4. Set appropriate max\_tokens limits
      </Step>
    </Steps>

    <Info>
      Remember to regularly monitor your token usage and adjust your configuration as needed to optimize costs and performance.
    </Info>
  </Accordion>

  <Accordion title="Drop Additional Parameters">
    CrewAI internally uses Litellm for LLM calls, which allows you to drop additional parameters that are not needed for your specific use case. This can help simplify your code and reduce the complexity of your LLM configuration.
    For example, if you don't need to send the <code>stop</code> parameter, you can simply omit it from your LLM call:

    ```python
    from crewai import LLM
    import os

    os.environ["OPENAI_API_KEY"] = "<api-key>"

    o3_llm = LLM(
        model="o3",
        drop_params=True,
        additional_drop_params=["stop"]
    )
    ```
  </Accordion>
</AccordionGroup>

## Common Issues and Solutions

<Tabs>
  <Tab title="Authentication">
    <Warning>
      Most authentication issues can be resolved by checking API key format and environment variable names.
    </Warning>

    ```bash
    # OpenAI
    OPENAI_API_KEY=sk-...

    # Anthropic
    ANTHROPIC_API_KEY=sk-ant-...
    ```
  </Tab>

  <Tab title="Model Names">
    <Check>
      Always include the provider prefix in model names
    </Check>

    ```python
    # Correct
    llm = LLM(model="openai/gpt-4")

    # Incorrect
    llm = LLM(model="gpt-4")
    ```
  </Tab>

  <Tab title="Context Length">
    <Tip>
      Use larger context models for extensive tasks
    </Tip>

    ```python
    # Large context model
    llm = LLM(model="openai/gpt-4o")  # 128K tokens
    ```
  </Tab>
</Tabs>


# Memory
Source: https://docs.crewai.com/en/concepts/memory

Leveraging memory systems in the CrewAI framework to enhance agent capabilities.

## Overview

The CrewAI framework provides a sophisticated memory system designed to significantly enhance AI agent capabilities. CrewAI offers **three distinct memory approaches** that serve different use cases:

1. **Basic Memory System** - Built-in short-term, long-term, and entity memory
2. **User Memory** - User-specific memory with Mem0 integration (legacy approach)
3. **External Memory** - Standalone external memory providers (new approach)

## Memory System Components

| Component             | Description                                                                                                                                                                                                      |
| :-------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Short-Term Memory** | Temporarily stores recent interactions and outcomes using `RAG`, enabling agents to recall and utilize information relevant to their current context during the current executions.                              |
| **Long-Term Memory**  | Preserves valuable insights and learnings from past executions, allowing agents to build and refine their knowledge over time.                                                                                   |
| **Entity Memory**     | Captures and organizes information about entities (people, places, concepts) encountered during tasks, facilitating deeper understanding and relationship mapping. Uses `RAG` for storing entity information.    |
| **Contextual Memory** | Maintains the context of interactions by combining `ShortTermMemory`, `LongTermMemory`, and `EntityMemory`, aiding in the coherence and relevance of agent responses over a sequence of tasks or a conversation. |

## 1. Basic Memory System (Recommended)

The simplest and most commonly used approach. Enable memory for your crew with a single parameter:

### Quick Start

```python
from crewai import Crew, Agent, Task, Process

# Enable basic memory system
crew = Crew(
    agents=[...],
    tasks=[...],
    process=Process.sequential,
    memory=True,  # Enables short-term, long-term, and entity memory
    verbose=True
)
```

### How It Works

* **Short-Term Memory**: Uses ChromaDB with RAG for current context
* **Long-Term Memory**: Uses SQLite3 to store task results across sessions
* **Entity Memory**: Uses RAG to track entities (people, places, concepts)
* **Storage Location**: Platform-specific location via `appdirs` package
* **Custom Storage Directory**: Set `CREWAI_STORAGE_DIR` environment variable

## Storage Location Transparency

<Info>
  **Understanding Storage Locations**: CrewAI uses platform-specific directories to store memory and knowledge files following OS conventions. Understanding these locations helps with production deployments, backups, and debugging.
</Info>

### Where CrewAI Stores Files

By default, CrewAI uses the `appdirs` library to determine storage locations following platform conventions. Here's exactly where your files are stored:

#### Default Storage Locations by Platform

**macOS:**

```
~/Library/Application Support/CrewAI/{project_name}/
‚îú‚îÄ‚îÄ knowledge/           # Knowledge base ChromaDB files
‚îú‚îÄ‚îÄ short_term_memory/   # Short-term memory ChromaDB files
‚îú‚îÄ‚îÄ long_term_memory/    # Long-term memory ChromaDB files
‚îú‚îÄ‚îÄ entities/            # Entity memory ChromaDB files
‚îî‚îÄ‚îÄ long_term_memory_storage.db  # SQLite database
```

**Linux:**

```
~/.local/share/CrewAI/{project_name}/
‚îú‚îÄ‚îÄ knowledge/
‚îú‚îÄ‚îÄ short_term_memory/
‚îú‚îÄ‚îÄ long_term_memory/
‚îú‚îÄ‚îÄ entities/
‚îî‚îÄ‚îÄ long_term_memory_storage.db
```

**Windows:**

```
C:\Users\{username}\AppData\Local\CrewAI\{project_name}\
‚îú‚îÄ‚îÄ knowledge\
‚îú‚îÄ‚îÄ short_term_memory\
‚îú‚îÄ‚îÄ long_term_memory\
‚îú‚îÄ‚îÄ entities\
‚îî‚îÄ‚îÄ long_term_memory_storage.db
```

### Finding Your Storage Location

To see exactly where CrewAI is storing files on your system:

```python
from crewai.utilities.paths import db_storage_path
import os

# Get the base storage path
storage_path = db_storage_path()
print(f"CrewAI storage location: {storage_path}")

# List all CrewAI storage directories
if os.path.exists(storage_path):
    print("\nStored files and directories:")
    for item in os.listdir(storage_path):
        item_path = os.path.join(storage_path, item)
        if os.path.isdir(item_path):
            print(f"üìÅ {item}/")
            # Show ChromaDB collections
            if os.path.exists(item_path):
                for subitem in os.listdir(item_path):
                    print(f"   ‚îî‚îÄ‚îÄ {subitem}")
        else:
            print(f"üìÑ {item}")
else:
    print("No CrewAI storage directory found yet.")
```

### Controlling Storage Locations

#### Option 1: Environment Variable (Recommended)

```python
import os
from crewai import Crew

# Set custom storage location
os.environ["CREWAI_STORAGE_DIR"] = "./my_project_storage"

# All memory and knowledge will now be stored in ./my_project_storage/
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True
)
```

#### Option 2: Custom Storage Paths

```python
import os
from crewai import Crew
from crewai.memory import LongTermMemory
from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage

# Configure custom storage location
custom_storage_path = "./storage"
os.makedirs(custom_storage_path, exist_ok=True)

crew = Crew(
    memory=True,
    long_term_memory=LongTermMemory(
        storage=LTMSQLiteStorage(
            db_path=f"{custom_storage_path}/memory.db"
        )
    )
)
```

#### Option 3: Project-Specific Storage

```python
import os
from pathlib import Path

# Store in project directory
project_root = Path(__file__).parent
storage_dir = project_root / "crewai_storage"

os.environ["CREWAI_STORAGE_DIR"] = str(storage_dir)

# Now all storage will be in your project directory
```

### Embedding Provider Defaults

<Info>
  **Default Embedding Provider**: CrewAI defaults to OpenAI embeddings for consistency and reliability. You can easily customize this to match your LLM provider or use local embeddings.
</Info>

#### Understanding Default Behavior

```python
# When using Claude as your LLM...
from crewai import Agent, LLM

agent = Agent(
    role="Analyst",
    goal="Analyze data",
    backstory="Expert analyst",
    llm=LLM(provider="anthropic", model="claude-3-sonnet")  # Using Claude
)

# CrewAI will use OpenAI embeddings by default for consistency
# You can easily customize this to match your preferred provider
```

#### Customizing Embedding Providers

```python
from crewai import Crew

# Option 1: Match your LLM provider
crew = Crew(
    agents=[agent],
    tasks=[task],
    memory=True,
    embedder={
        "provider": "anthropic",  # Match your LLM provider
        "config": {
            "api_key": "your-anthropic-key",
            "model": "text-embedding-3-small"
        }
    }
)

# Option 2: Use local embeddings (no external API calls)
crew = Crew(
    agents=[agent],
    tasks=[task],
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    }
)
```

### Debugging Storage Issues

#### Check Storage Permissions

```python
import os
from crewai.utilities.paths import db_storage_path

storage_path = db_storage_path()
print(f"Storage path: {storage_path}")
print(f"Path exists: {os.path.exists(storage_path)}")
print(f"Is writable: {os.access(storage_path, os.W_OK) if os.path.exists(storage_path) else 'Path does not exist'}")

# Create with proper permissions
if not os.path.exists(storage_path):
    os.makedirs(storage_path, mode=0o755, exist_ok=True)
    print(f"Created storage directory: {storage_path}")
```

#### Inspect ChromaDB Collections

```python
import chromadb
from crewai.utilities.paths import db_storage_path

# Connect to CrewAI's ChromaDB
storage_path = db_storage_path()
chroma_path = os.path.join(storage_path, "knowledge")

if os.path.exists(chroma_path):
    client = chromadb.PersistentClient(path=chroma_path)
    collections = client.list_collections()

    print("ChromaDB Collections:")
    for collection in collections:
        print(f"  - {collection.name}: {collection.count()} documents")
else:
    print("No ChromaDB storage found")
```

#### Reset Storage (Debugging)

```python
from crewai import Crew

# Reset all memory storage
crew = Crew(agents=[...], tasks=[...], memory=True)

# Reset specific memory types
crew.reset_memories(command_type='short')     # Short-term memory
crew.reset_memories(command_type='long')      # Long-term memory
crew.reset_memories(command_type='entity')    # Entity memory
crew.reset_memories(command_type='knowledge') # Knowledge storage
```

### Production Best Practices

1. **Set `CREWAI_STORAGE_DIR`** to a known location in production for better control
2. **Choose explicit embedding providers** to match your LLM setup
3. **Monitor storage directory size** for large-scale deployments
4. **Include storage directories** in your backup strategy
5. **Set appropriate file permissions** (0o755 for directories, 0o644 for files)
6. **Use project-relative paths** for containerized deployments

### Common Storage Issues

**"ChromaDB permission denied" errors:**

```bash
# Fix permissions
chmod -R 755 ~/.local/share/CrewAI/
```

**"Database is locked" errors:**

```python
# Ensure only one CrewAI instance accesses storage
import fcntl
import os

storage_path = db_storage_path()
lock_file = os.path.join(storage_path, ".crewai.lock")

with open(lock_file, 'w') as f:
    fcntl.flock(f.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
    # Your CrewAI code here
```

**Storage not persisting between runs:**

```python
# Verify storage location is consistent
import os
print("CREWAI_STORAGE_DIR:", os.getenv("CREWAI_STORAGE_DIR"))
print("Current working directory:", os.getcwd())
print("Computed storage path:", db_storage_path())
```

## Custom Embedder Configuration

CrewAI supports multiple embedding providers to give you flexibility in choosing the best option for your use case. Here's a comprehensive guide to configuring different embedding providers for your memory system.

### Why Choose Different Embedding Providers?

* **Cost Optimization**: Local embeddings (Ollama) are free after initial setup
* **Privacy**: Keep your data local with Ollama or use your preferred cloud provider
* **Performance**: Some models work better for specific domains or languages
* **Consistency**: Match your embedding provider with your LLM provider
* **Compliance**: Meet specific regulatory or organizational requirements

### OpenAI Embeddings (Default)

OpenAI provides reliable, high-quality embeddings that work well for most use cases.

```python
from crewai import Crew

# Basic OpenAI configuration (uses environment OPENAI_API_KEY)
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "model": "text-embedding-3-small"  # or "text-embedding-3-large"
        }
    }
)

# Advanced OpenAI configuration
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "api_key": "your-openai-api-key",  # Optional: override env var
            "model": "text-embedding-3-large",
            "dimensions": 1536,  # Optional: reduce dimensions for smaller storage
            "organization_id": "your-org-id"  # Optional: for organization accounts
        }
    }
)
```

### Azure OpenAI Embeddings

For enterprise users with Azure OpenAI deployments.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",  # Use openai provider for Azure
        "config": {
            "api_key": "your-azure-api-key",
            "api_base": "https://your-resource.openai.azure.com/",
            "api_type": "azure",
            "api_version": "2023-05-15",
            "model": "text-embedding-3-small",
            "deployment_id": "your-deployment-name"  # Azure deployment name
        }
    }
)
```

### Google AI Embeddings

Use Google's text embedding models for integration with Google Cloud services.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "google",
        "config": {
            "api_key": "your-google-api-key",
            "model": "text-embedding-004"  # or "text-embedding-preview-0409"
        }
    }
)
```

### Vertex AI Embeddings

For Google Cloud users with Vertex AI access.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "vertexai",
        "config": {
            "project_id": "your-gcp-project-id",
            "region": "us-central1",  # or your preferred region
            "api_key": "your-service-account-key",
            "model_name": "textembedding-gecko"
        }
    }
)
```

### Ollama Embeddings (Local)

Run embeddings locally for privacy and cost savings.

```python
# First, install and run Ollama locally, then pull an embedding model:
# ollama pull mxbai-embed-large

crew = Crew(
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {
            "model": "mxbai-embed-large",  # or "nomic-embed-text"
            "url": "http://localhost:11434/api/embeddings"  # Default Ollama URL
        }
    }
)

# For custom Ollama installations
crew = Crew(
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {
            "model": "mxbai-embed-large",
            "url": "http://your-ollama-server:11434/api/embeddings"
        }
    }
)
```

### Cohere Embeddings

Use Cohere's embedding models for multilingual support.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "cohere",
        "config": {
            "api_key": "your-cohere-api-key",
            "model": "embed-english-v3.0"  # or "embed-multilingual-v3.0"
        }
    }
)
```

### VoyageAI Embeddings

High-performance embeddings optimized for retrieval tasks.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "voyageai",
        "config": {
            "api_key": "your-voyage-api-key",
            "model": "voyage-large-2",  # or "voyage-code-2" for code
            "input_type": "document"  # or "query"
        }
    }
)
```

### AWS Bedrock Embeddings

For AWS users with Bedrock access.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "bedrock",
        "config": {
            "aws_access_key_id": "your-access-key",
            "aws_secret_access_key": "your-secret-key",
            "region_name": "us-east-1",
            "model": "amazon.titan-embed-text-v1"
        }
    }
)
```

### Hugging Face Embeddings

Use open-source models from Hugging Face.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "huggingface",
        "config": {
            "api_key": "your-hf-token",  # Optional for public models
            "model": "sentence-transformers/all-MiniLM-L6-v2",
            "api_url": "https://api-inference.huggingface.co"  # or your custom endpoint
        }
    }
)
```

### IBM Watson Embeddings

For IBM Cloud users.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "watson",
        "config": {
            "api_key": "your-watson-api-key",
            "url": "your-watson-instance-url",
            "model": "ibm/slate-125m-english-rtrvr"
        }
    }
)
```

### Choosing the Right Embedding Provider

| Provider         | Best For                 | Pros                      | Cons                    |
| :--------------- | :----------------------- | :------------------------ | :---------------------- |
| **OpenAI**       | General use, reliability | High quality, well-tested | Cost, requires API key  |
| **Ollama**       | Privacy, cost savings    | Free, local, private      | Requires local setup    |
| **Google AI**    | Google ecosystem         | Good performance          | Requires Google account |
| **Azure OpenAI** | Enterprise, compliance   | Enterprise features       | Complex setup           |
| **Cohere**       | Multilingual content     | Great language support    | Specialized use case    |
| **VoyageAI**     | Retrieval tasks          | Optimized for search      | Newer provider          |

### Environment Variable Configuration

For security, store API keys in environment variables:

```python
import os

# Set environment variables
os.environ["OPENAI_API_KEY"] = "your-openai-key"
os.environ["GOOGLE_API_KEY"] = "your-google-key"
os.environ["COHERE_API_KEY"] = "your-cohere-key"

# Use without exposing keys in code
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "model": "text-embedding-3-small"
            # API key automatically loaded from environment
        }
    }
)
```

### Testing Different Embedding Providers

Compare embedding providers for your specific use case:

```python
from crewai import Crew
from crewai.utilities.paths import db_storage_path

# Test different providers with the same data
providers_to_test = [
    {
        "name": "OpenAI",
        "config": {
            "provider": "openai",
            "config": {"model": "text-embedding-3-small"}
        }
    },
    {
        "name": "Ollama",
        "config": {
            "provider": "ollama",
            "config": {"model": "mxbai-embed-large"}
        }
    }
]

for provider in providers_to_test:
    print(f"\nTesting {provider['name']} embeddings...")

    # Create crew with specific embedder
    crew = Crew(
        agents=[...],
        tasks=[...],
        memory=True,
        embedder=provider['config']
    )

    # Run your test and measure performance
    result = crew.kickoff()
    print(f"{provider['name']} completed successfully")
```

### Troubleshooting Embedding Issues

**Model not found errors:**

```python
# Verify model availability
from crewai.utilities.embedding_configurator import EmbeddingConfigurator

configurator = EmbeddingConfigurator()
try:
    embedder = configurator.configure_embedder({
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    })
    print("Embedder configured successfully")
except Exception as e:
    print(f"Configuration error: {e}")
```

**API key issues:**

```python
import os

# Check if API keys are set
required_keys = ["OPENAI_API_KEY", "GOOGLE_API_KEY", "COHERE_API_KEY"]
for key in required_keys:
    if os.getenv(key):
        print(f"‚úÖ {key} is set")
    else:
        print(f"‚ùå {key} is not set")
```

**Performance comparison:**

```python
import time

def test_embedding_performance(embedder_config, test_text="This is a test document"):
    start_time = time.time()

    crew = Crew(
        agents=[...],
        tasks=[...],
        memory=True,
        embedder=embedder_config
    )

    # Simulate memory operation
    crew.kickoff()

    end_time = time.time()
    return end_time - start_time

# Compare performance
openai_time = test_embedding_performance({
    "provider": "openai",
    "config": {"model": "text-embedding-3-small"}
})

ollama_time = test_embedding_performance({
    "provider": "ollama",
    "config": {"model": "mxbai-embed-large"}
})

print(f"OpenAI: {openai_time:.2f}s")
print(f"Ollama: {ollama_time:.2f}s")
```

## 2. User Memory with Mem0 (Legacy)

<Warning>
  **Legacy Approach**: While fully functional, this approach is considered legacy. For new projects requiring user-specific memory, consider using External Memory instead.
</Warning>

User Memory integrates with [Mem0](https://mem0.ai/) to provide user-specific memory that persists across sessions and integrates with the crew's contextual memory system.

### Prerequisites

```bash
pip install mem0ai
```

### Mem0 Cloud Configuration

```python
import os
from crewai import Crew, Process

# Set your Mem0 API key
os.environ["MEM0_API_KEY"] = "m0-your-api-key"

crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,  # Required for contextual memory integration
    memory_config={
        "provider": "mem0",
        "config": {"user_id": "john"},
        "user_memory": {}  # Required - triggers user memory initialization
    },
    process=Process.sequential,
    verbose=True
)
```

### Advanced Mem0 Configuration

```python
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,
    memory_config={
        "provider": "mem0",
        "config": {
            "user_id": "john",
            "org_id": "my_org_id",        # Optional
            "project_id": "my_project_id", # Optional
            "api_key": "custom-api-key"    # Optional - overrides env var
        },
        "user_memory": {}
    }
)
```

### Local Mem0 Configuration

```python
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,
    memory_config={
        "provider": "mem0",
        "config": {
            "user_id": "john",
            "local_mem0_config": {
                "vector_store": {
                    "provider": "qdrant",
                    "config": {"host": "localhost", "port": 6333}
                },
                "llm": {
                    "provider": "openai",
                    "config": {"api_key": "your-api-key", "model": "gpt-4"}
                },
                "embedder": {
                    "provider": "openai",
                    "config": {"api_key": "your-api-key", "model": "text-embedding-3-small"}
                }
            }
        },
        "user_memory": {}
    }
)
```

## 3. External Memory (New Approach)

External Memory provides a standalone memory system that operates independently from the crew's built-in memory. This is ideal for specialized memory providers or cross-application memory sharing.

### Basic External Memory with Mem0

```python
import os
from crewai import Agent, Crew, Process, Task
from crewai.memory.external.external_memory import ExternalMemory

os.environ["MEM0_API_KEY"] = "your-api-key"

# Create external memory instance
external_memory = ExternalMemory(
    embedder_config={
        "provider": "mem0",
        "config": {"user_id": "U-123"}
    }
)

crew = Crew(
    agents=[...],
    tasks=[...],
    external_memory=external_memory,  # Separate from basic memory
    process=Process.sequential,
    verbose=True
)
```

### Custom Storage Implementation

```python
from crewai.memory.external.external_memory import ExternalMemory
from crewai.memory.storage.interface import Storage

class CustomStorage(Storage):
    def __init__(self):
        self.memories = []

    def save(self, value, metadata=None, agent=None):
        self.memories.append({
            "value": value,
            "metadata": metadata,
            "agent": agent
        })

    def search(self, query, limit=10, score_threshold=0.5):
        # Implement your search logic here
        return [m for m in self.memories if query.lower() in str(m["value"]).lower()]

    def reset(self):
        self.memories = []

# Use custom storage
external_memory = ExternalMemory(storage=CustomStorage())

crew = Crew(
    agents=[...],
    tasks=[...],
    external_memory=external_memory
)
```

## Memory System Comparison

| Feature              | Basic Memory        | User Memory (Legacy)       | External Memory   |
| -------------------- | ------------------- | -------------------------- | ----------------- |
| **Setup Complexity** | Simple              | Medium                     | Medium            |
| **Integration**      | Built-in contextual | Contextual + User-specific | Standalone        |
| **Storage**          | Local files         | Mem0 Cloud/Local           | Custom/Mem0       |
| **Cross-session**    | ‚úÖ                   | ‚úÖ                          | ‚úÖ                 |
| **User-specific**    | ‚ùå                   | ‚úÖ                          | ‚úÖ                 |
| **Custom providers** | Limited             | Mem0 only                  | Any provider      |
| **Recommended for**  | Most use cases      | Legacy projects            | Specialized needs |

## Supported Embedding Providers

### OpenAI (Default)

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {"model": "text-embedding-3-small"}
    }
)
```

### Ollama

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    }
)
```

### Google AI

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "google",
        "config": {
            "api_key": "your-api-key",
            "model": "text-embedding-004"
        }
    }
)
```

### Azure OpenAI

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "api_key": "your-api-key",
            "api_base": "https://your-resource.openai.azure.com/",
            "api_version": "2023-05-15",
            "model_name": "text-embedding-3-small"
        }
    }
)
```

### Vertex AI

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "vertexai",
        "config": {
            "project_id": "your-project-id",
            "region": "your-region",
            "api_key": "your-api-key",
            "model_name": "textembedding-gecko"
        }
    }
)
```

## Security Best Practices

### Environment Variables

```python
import os
from crewai import Crew

# Store sensitive data in environment variables
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "api_key": os.getenv("OPENAI_API_KEY"),
            "model": "text-embedding-3-small"
        }
    }
)
```

### Storage Security

```python
import os
from crewai import Crew
from crewai.memory import LongTermMemory
from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage

# Use secure storage paths
storage_path = os.getenv("CREWAI_STORAGE_DIR", "./storage")
os.makedirs(storage_path, mode=0o700, exist_ok=True)  # Restricted permissions

crew = Crew(
    memory=True,
    long_term_memory=LongTermMemory(
        storage=LTMSQLiteStorage(
            db_path=f"{storage_path}/memory.db"
        )
    )
)
```

## Troubleshooting

### Common Issues

**Memory not persisting between sessions?**

* Check `CREWAI_STORAGE_DIR` environment variable
* Ensure write permissions to storage directory
* Verify memory is enabled with `memory=True`

**Mem0 authentication errors?**

* Verify `MEM0_API_KEY` environment variable is set
* Check API key permissions on Mem0 dashboard
* Ensure `mem0ai` package is installed

**High memory usage with large datasets?**

* Consider using External Memory with custom storage
* Implement pagination in custom storage search methods
* Use smaller embedding models for reduced memory footprint

### Performance Tips

* Use `memory=True` for most use cases (simplest and fastest)
* Only use User Memory if you need user-specific persistence
* Consider External Memory for high-scale or specialized requirements
* Choose smaller embedding models for faster processing
* Set appropriate search limits to control memory retrieval size

## Benefits of Using CrewAI's Memory System

* ü¶æ **Adaptive Learning:** Crews become more efficient over time, adapting to new information and refining their approach to tasks.
* ü´° **Enhanced Personalization:** Memory enables agents to remember user preferences and historical interactions, leading to personalized experiences.
* üß† **Improved Problem Solving:** Access to a rich memory store aids agents in making more informed decisions, drawing on past learnings and contextual insights.

## Memory Events

CrewAI's event system provides powerful insights into memory operations. By leveraging memory events, you can monitor, debug, and optimize your memory system's performance and behavior.

### Available Memory Events

CrewAI emits the following memory-related events:

| Event                             | Description                                                 | Key Properties                                                  |
| :-------------------------------- | :---------------------------------------------------------- | :-------------------------------------------------------------- |
| **MemoryQueryStartedEvent**       | Emitted when a memory query begins                          | `query`, `limit`, `score_threshold`                             |
| **MemoryQueryCompletedEvent**     | Emitted when a memory query completes successfully          | `query`, `results`, `limit`, `score_threshold`, `query_time_ms` |
| **MemoryQueryFailedEvent**        | Emitted when a memory query fails                           | `query`, `limit`, `score_threshold`, `error`                    |
| **MemorySaveStartedEvent**        | Emitted when a memory save operation begins                 | `value`, `metadata`, `agent_role`                               |
| **MemorySaveCompletedEvent**      | Emitted when a memory save operation completes successfully | `value`, `metadata`, `agent_role`, `save_time_ms`               |
| **MemorySaveFailedEvent**         | Emitted when a memory save operation fails                  | `value`, `metadata`, `agent_role`, `error`                      |
| **MemoryRetrievalStartedEvent**   | Emitted when memory retrieval for a task prompt starts      | `task_id`                                                       |
| **MemoryRetrievalCompletedEvent** | Emitted when memory retrieval completes successfully        | `task_id`, `memory_content`, `retrieval_time_ms`                |

### Practical Applications

#### 1. Memory Performance Monitoring

Track memory operation timing to optimize your application:

```python
from crewai.utilities.events.base_event_listener import BaseEventListener
from crewai.utilities.events import (
    MemoryQueryCompletedEvent,
    MemorySaveCompletedEvent
)
import time

class MemoryPerformanceMonitor(BaseEventListener):
    def __init__(self):
        super().__init__()
        self.query_times = []
        self.save_times = []

    def setup_listeners(self, crewai_event_bus):
        @crewai_event_bus.on(MemoryQueryCompletedEvent)
        def on_memory_query_completed(source, event: MemoryQueryCompletedEvent):
            self.query_times.append(event.query_time_ms)
            print(f"Memory query completed in {event.query_time_ms:.2f}ms. Query: '{event.query}'")
            print(f"Average query time: {sum(self.query_times)/len(self.query_times):.2f}ms")

        @crewai_event_bus.on(MemorySaveCompletedEvent)
        def on_memory_save_completed(source, event: MemorySaveCompletedEvent):
            self.save_times.append(event.save_time_ms)
            print(f"Memory save completed in {event.save_time_ms:.2f}ms")
            print(f"Average save time: {sum(self.save_times)/len(self.save_times):.2f}ms")

# Create an instance of your listener
memory_monitor = MemoryPerformanceMonitor()
```

#### 2. Memory Content Logging

Log memory operations for debugging and insights:

```python
from crewai.utilities.events.base_event_listener import BaseEventListener
from crewai.utilities.events import (
    MemorySaveStartedEvent,
    MemoryQueryStartedEvent,
    MemoryRetrievalCompletedEvent
)
import logging

# Configure logging
logger = logging.getLogger('memory_events')

class MemoryLogger(BaseEventListener):
    def setup_listeners(self, crewai_event_bus):
        @crewai_event_bus.on(MemorySaveStartedEvent)
        def on_memory_save_started(source, event: MemorySaveStartedEvent):
            if event.agent_role:
                logger.info(f"Agent '{event.agent_role}' saving memory: {event.value[:50]}...")
            else:
                logger.info(f"Saving memory: {event.value[:50]}...")

        @crewai_event_bus.on(MemoryQueryStartedEvent)
        def on_memory_query_started(source, event: MemoryQueryStartedEvent):
            logger.info(f"Memory query started: '{event.query}' (limit: {event.limit})")

        @crewai_event_bus.on(MemoryRetrievalCompletedEvent)
        def on_memory_retrieval_completed(source, event: MemoryRetrievalCompletedEvent):
            if event.task_id:
                logger.info(f"Memory retrieved for task {event.task_id} in {event.retrieval_time_ms:.2f}ms")
            else:
                logger.info(f"Memory retrieved in {event.retrieval_time_ms:.2f}ms")
            logger.debug(f"Memory content: {event.memory_content}")

# Create an instance of your listener
memory_logger = MemoryLogger()
```

#### 3. Error Tracking and Notifications

Capture and respond to memory errors:

```python
from crewai.utilities.events.base_event_listener import BaseEventListener
from crewai.utilities.events import (
    MemorySaveFailedEvent,
    MemoryQueryFailedEvent
)
import logging
from typing import Optional

# Configure logging
logger = logging.getLogger('memory_errors')

class MemoryErrorTracker(BaseEventListener):
    def __init__(self, notify_email: Optional[str] = None):
        super().__init__()
        self.notify_email = notify_email
        self.error_count = 0

    def setup_listeners(self, crewai_event_bus):
        @crewai_event_bus.on(MemorySaveFailedEvent)
        def on_memory_save_failed(source, event: MemorySaveFailedEvent):
            self.error_count += 1
            agent_info = f"Agent '{event.agent_role}'" if event.agent_role else "Unknown agent"
            error_message = f"Memory save failed: {event.error}. {agent_info}"
            logger.error(error_message)

            if self.notify_email and self.error_count % 5 == 0:
                self._send_notification(error_message)

        @crewai_event_bus.on(MemoryQueryFailedEvent)
        def on_memory_query_failed(source, event: MemoryQueryFailedEvent):
            self.error_count += 1
            error_message = f"Memory query failed: {event.error}. Query: '{event.query}'"
            logger.error(error_message)

            if self.notify_email and self.error_count % 5 == 0:
                self._send_notification(error_message)

    def _send_notification(self, message):
        # Implement your notification system (email, Slack, etc.)
        print(f"[NOTIFICATION] Would send to {self.notify_email}: {message}")

# Create an instance of your listener
error_tracker = MemoryErrorTracker(notify_email="admin@example.com")
```

### Integrating with Analytics Platforms

Memory events can be forwarded to analytics and monitoring platforms to track performance metrics, detect anomalies, and visualize memory usage patterns:

```python
from crewai.utilities.events.base_event_listener import BaseEventListener
from crewai.utilities.events import (
    MemoryQueryCompletedEvent,
    MemorySaveCompletedEvent
)

class MemoryAnalyticsForwarder(BaseEventListener):
    def __init__(self, analytics_client):
        super().__init__()
        self.client = analytics_client

    def setup_listeners(self, crewai_event_bus):
        @crewai_event_bus.on(MemoryQueryCompletedEvent)
        def on_memory_query_completed(source, event: MemoryQueryCompletedEvent):
            # Forward query metrics to analytics platform
            self.client.track_metric({
                "event_type": "memory_query",
                "query": event.query,
                "duration_ms": event.query_time_ms,
                "result_count": len(event.results) if hasattr(event.results, "__len__") else 0,
                "timestamp": event.timestamp
            })

        @crewai_event_bus.on(MemorySaveCompletedEvent)
        def on_memory_save_completed(source, event: MemorySaveCompletedEvent):
            # Forward save metrics to analytics platform
            self.client.track_metric({
                "event_type": "memory_save",
                "agent_role": event.agent_role,
                "duration_ms": event.save_time_ms,
                "timestamp": event.timestamp
            })
```

### Best Practices for Memory Event Listeners

1. **Keep handlers lightweight**: Avoid complex processing in event handlers to prevent performance impacts
2. **Use appropriate logging levels**: Use INFO for normal operations, DEBUG for details, ERROR for issues
3. **Batch metrics when possible**: Accumulate metrics before sending to external systems
4. **Handle exceptions gracefully**: Ensure your event handlers don't crash due to unexpected data
5. **Consider memory consumption**: Be mindful of storing large amounts of event data

## Conclusion

Integrating CrewAI's memory system into your projects is straightforward. By leveraging the provided memory components and configurations,
you can quickly empower your agents with the ability to remember, reason, and learn from their interactions, unlocking new levels of intelligence and capability.


# Planning
Source: https://docs.crewai.com/en/concepts/planning

Learn how to add planning to your CrewAI Crew and improve their performance.

## Overview

The planning feature in CrewAI allows you to add planning capability to your crew. When enabled, before each Crew iteration,
all Crew information is sent to an AgentPlanner that will plan the tasks step by step, and this plan will be added to each task description.

### Using the Planning Feature

Getting started with the planning feature is very easy, the only step required is to add `planning=True` to your Crew:

<CodeGroup>
  ```python Code
  from crewai import Crew, Agent, Task, Process

  # Assemble your crew with planning capabilities
  my_crew = Crew(
      agents=self.agents,
      tasks=self.tasks,
      process=Process.sequential,
      planning=True,
  )
  ```
</CodeGroup>

From this point on, your crew will have planning enabled, and the tasks will be planned before each iteration.

<Warning>
  When planning is enabled, crewAI will use `gpt-4o-mini` as the default LLM for planning, which requires a valid OpenAI API key. Since your agents might be using different LLMs, this could cause confusion if you don't have an OpenAI API key configured or if you're experiencing unexpected behavior related to LLM API calls.
</Warning>

#### Planning LLM

Now you can define the LLM that will be used to plan the tasks.

When running the base case example, you will see something like the output below, which represents the output of the `AgentPlanner`
responsible for creating the step-by-step logic to add to the Agents' tasks.

<CodeGroup>
  ```python Code
  from crewai import Crew, Agent, Task, Process

  # Assemble your crew with planning capabilities and custom LLM
  my_crew = Crew(
      agents=self.agents,
      tasks=self.tasks,
      process=Process.sequential,
      planning=True,
      planning_llm="gpt-4o"
  )

  # Run the crew
  my_crew.kickoff()
  ```

  ````markdown Result
  [2024-07-15 16:49:11][INFO]: Planning the crew execution
  **Step-by-Step Plan for Task Execution**

  **Task Number 1: Conduct a thorough research about AI LLMs**

  **Agent:** AI LLMs Senior Data Researcher

  **Agent Goal:** Uncover cutting-edge developments in AI LLMs

  **Task Expected Output:** A list with 10 bullet points of the most relevant information about AI LLMs

  **Task Tools:** None specified

  **Agent Tools:** None specified

  **Step-by-Step Plan:**

  1. **Define Research Scope:**

     - Determine the specific areas of AI LLMs to focus on, such as advancements in architecture, use cases, ethical considerations, and performance metrics.

  2. **Identify Reliable Sources:**

     - List reputable sources for AI research, including academic journals, industry reports, conferences (e.g., NeurIPS, ACL), AI research labs (e.g., OpenAI, Google AI), and online databases (e.g., IEEE Xplore, arXiv).

  3. **Collect Data:**

     - Search for the latest papers, articles, and reports published in 2024 and early 2025.
     - Use keywords like "Large Language Models 2025", "AI LLM advancements", "AI ethics 2025", etc.

  4. **Analyze Findings:**

     - Read and summarize the key points from each source.
     - Highlight new techniques, models, and applications introduced in the past year.

  5. **Organize Information:**

     - Categorize the information into relevant topics (e.g., new architectures, ethical implications, real-world applications).
     - Ensure each bullet point is concise but informative.

  6. **Create the List:**

     - Compile the 10 most relevant pieces of information into a bullet point list.
     - Review the list to ensure clarity and relevance.

  **Expected Output:**

  A list with 10 bullet points of the most relevant information about AI LLMs.

  ---

  **Task Number 2: Review the context you got and expand each topic into a full section for a report**

  **Agent:** AI LLMs Reporting Analyst

  **Agent Goal:** Create detailed reports based on AI LLMs data analysis and research findings

  **Task Expected Output:** A fully fledged report with the main topics, each with a full section of information. Formatted as markdown without '```'

  **Task Tools:** None specified

  **Agent Tools:** None specified

  **Step-by-Step Plan:**

  1. **Review the Bullet Points:**
     - Carefully read through the list of 10 bullet points provided by the AI LLMs Senior Data Researcher.

  2. **Outline the Report:**
     - Create an outline with each bullet point as a main section heading.
     - Plan sub-sections under each main heading to cover different aspects of the topic.

  3. **Research Further Details:**
     - For each bullet point, conduct additional research if necessary to gather more detailed information.
     - Look for case studies, examples, and statistical data to support each section.

  4. **Write Detailed Sections:**
     - Expand each bullet point into a comprehensive section.
     - Ensure each section includes an introduction, detailed explanation, examples, and a conclusion.
     - Use markdown formatting for headings, subheadings, lists, and emphasis.

  5. **Review and Edit:**
     - Proofread the report for clarity, coherence, and correctness.
     - Make sure the report flows logically from one section to the next.
     - Format the report according to markdown standards.

  6. **Finalize the Report:**
     - Ensure the report is complete with all sections expanded and detailed.
     - Double-check formatting and make any necessary adjustments.

  **Expected Output:**
  A fully fledged report with the main topics, each with a full section of information. Formatted as markdown without '```'.
  ````
</CodeGroup>


# Processes
Source: https://docs.crewai.com/en/concepts/processes

Detailed guide on workflow management through processes in CrewAI, with updated implementation details.

## Overview

<Tip>
  Processes orchestrate the execution of tasks by agents, akin to project management in human teams.
  These processes ensure tasks are distributed and executed efficiently, in alignment with a predefined strategy.
</Tip>

## Process Implementations

* **Sequential**: Executes tasks sequentially, ensuring tasks are completed in an orderly progression.
* **Hierarchical**: Organizes tasks in a managerial hierarchy, where tasks are delegated and executed based on a structured chain of command. A manager language model (`manager_llm`) or a custom manager agent (`manager_agent`) must be specified in the crew to enable the hierarchical process, facilitating the creation and management of tasks by the manager.
* **Consensual Process (Planned)**: Aiming for collaborative decision-making among agents on task execution, this process type introduces a democratic approach to task management within CrewAI. It is planned for future development and is not currently implemented in the codebase.

## The Role of Processes in Teamwork

Processes enable individual agents to operate as a cohesive unit, streamlining their efforts to achieve common objectives with efficiency and coherence.

## Assigning Processes to a Crew

To assign a process to a crew, specify the process type upon crew creation to set the execution strategy. For a hierarchical process, ensure to define `manager_llm` or `manager_agent` for the manager agent.

```python
from crewai import Crew, Process

# Example: Creating a crew with a sequential process
crew = Crew(
    agents=my_agents,
    tasks=my_tasks,
    process=Process.sequential
)

# Example: Creating a crew with a hierarchical process
# Ensure to provide a manager_llm or manager_agent
crew = Crew(
    agents=my_agents,
    tasks=my_tasks,
    process=Process.hierarchical,
    manager_llm="gpt-4o"
    # or
    # manager_agent=my_manager_agent
)
```

**Note:** Ensure `my_agents` and `my_tasks` are defined prior to creating a `Crew` object, and for the hierarchical process, either `manager_llm` or `manager_agent` is also required.

## Sequential Process

This method mirrors dynamic team workflows, progressing through tasks in a thoughtful and systematic manner. Task execution follows the predefined order in the task list, with the output of one task serving as context for the next.

To customize task context, utilize the `context` parameter in the `Task` class to specify outputs that should be used as context for subsequent tasks.

## Hierarchical Process

Emulates a corporate hierarchy, CrewAI allows specifying a custom manager agent or automatically creates one, requiring the specification of a manager language model (`manager_llm`). This agent oversees task execution, including planning, delegation, and validation. Tasks are not pre-assigned; the manager allocates tasks to agents based on their capabilities, reviews outputs, and assesses task completion.

## Process Class: Detailed Overview

The `Process` class is implemented as an enumeration (`Enum`), ensuring type safety and restricting process values to the defined types (`sequential`, `hierarchical`). The consensual process is planned for future inclusion, emphasizing our commitment to continuous development and innovation.

## Conclusion

The structured collaboration facilitated by processes within CrewAI is crucial for enabling systematic teamwork among agents.
This documentation has been updated to reflect the latest features, enhancements, and the planned integration of the Consensual Process, ensuring users have access to the most current and comprehensive information.


# Reasoning
Source: https://docs.crewai.com/en/concepts/reasoning

Learn how to enable and use agent reasoning to improve task execution.

## Overview

Agent reasoning is a feature that allows agents to reflect on a task and create a plan before execution. This helps agents approach tasks more methodically and ensures they're ready to perform the assigned work.

## Usage

To enable reasoning for an agent, simply set `reasoning=True` when creating the agent:

```python
from crewai import Agent

agent = Agent(
    role="Data Analyst",
    goal="Analyze complex datasets and provide insights",
    backstory="You are an experienced data analyst with expertise in finding patterns in complex data.",
    reasoning=True,  # Enable reasoning
    max_reasoning_attempts=3  # Optional: Set a maximum number of reasoning attempts
)
```

## How It Works

When reasoning is enabled, before executing a task, the agent will:

1. Reflect on the task and create a detailed plan
2. Evaluate whether it's ready to execute the task
3. Refine the plan as necessary until it's ready or max\_reasoning\_attempts is reached
4. Inject the reasoning plan into the task description before execution

This process helps the agent break down complex tasks into manageable steps and identify potential challenges before starting.

## Configuration Options

<ParamField body="reasoning" type="bool" default="False">
  Enable or disable reasoning
</ParamField>

<ParamField body="max_reasoning_attempts" type="int" default="None">
  Maximum number of attempts to refine the plan before proceeding with execution. If None (default), the agent will continue refining until it's ready.
</ParamField>

## Example

Here's a complete example:

```python
from crewai import Agent, Task, Crew

# Create an agent with reasoning enabled
analyst = Agent(
    role="Data Analyst",
    goal="Analyze data and provide insights",
    backstory="You are an expert data analyst.",
    reasoning=True,
    max_reasoning_attempts=3  # Optional: Set a limit on reasoning attempts
)

# Create a task
analysis_task = Task(
    description="Analyze the provided sales data and identify key trends.",
    expected_output="A report highlighting the top 3 sales trends.",
    agent=analyst
)

# Create a crew and run the task
crew = Crew(agents=[analyst], tasks=[analysis_task])
result = crew.kickoff()

print(result)
```

## Error Handling

The reasoning process is designed to be robust, with error handling built in. If an error occurs during reasoning, the agent will proceed with executing the task without the reasoning plan. This ensures that tasks can still be executed even if the reasoning process fails.

Here's how to handle potential errors in your code:

```python
from crewai import Agent, Task
import logging

# Set up logging to capture any reasoning errors
logging.basicConfig(level=logging.INFO)

# Create an agent with reasoning enabled
agent = Agent(
    role="Data Analyst",
    goal="Analyze data and provide insights",
    reasoning=True,
    max_reasoning_attempts=3
)

# Create a task
task = Task(
    description="Analyze the provided sales data and identify key trends.",
    expected_output="A report highlighting the top 3 sales trends.",
    agent=agent
)

# Execute the task
# If an error occurs during reasoning, it will be logged and execution will continue
result = agent.execute_task(task)
```

## Example Reasoning Output

Here's an example of what a reasoning plan might look like for a data analysis task:

```
Task: Analyze the provided sales data and identify key trends.

Reasoning Plan:
I'll analyze the sales data to identify the top 3 trends.

1. Understanding of the task:
   I need to analyze sales data to identify key trends that would be valuable for business decision-making.

2. Key steps I'll take:
   - First, I'll examine the data structure to understand what fields are available
   - Then I'll perform exploratory data analysis to identify patterns
   - Next, I'll analyze sales by time periods to identify temporal trends
   - I'll also analyze sales by product categories and customer segments
   - Finally, I'll identify the top 3 most significant trends

3. Approach to challenges:
   - If the data has missing values, I'll decide whether to fill or filter them
   - If the data has outliers, I'll investigate whether they're valid data points or errors
   - If trends aren't immediately obvious, I'll apply statistical methods to uncover patterns

4. Use of available tools:
   - I'll use data analysis tools to explore and visualize the data
   - I'll use statistical tools to identify significant patterns
   - I'll use knowledge retrieval to access relevant information about sales analysis

5. Expected outcome:
   A concise report highlighting the top 3 sales trends with supporting evidence from the data.

READY: I am ready to execute the task.
```

This reasoning plan helps the agent organize its approach to the task, consider potential challenges, and ensure it delivers the expected output.


# Tasks
Source: https://docs.crewai.com/en/concepts/tasks

Detailed guide on managing and creating tasks within the CrewAI framework.

## Overview

In the CrewAI framework, a `Task` is a specific assignment completed by an `Agent`.

Tasks provide all necessary details for execution, such as a description, the agent responsible, required tools, and more, facilitating a wide range of action complexities.

Tasks within CrewAI can be collaborative, requiring multiple agents to work together. This is managed through the task properties and orchestrated by the Crew's process, enhancing teamwork and efficiency.

<Note type="info" title="Enterprise Enhancement: Visual Task Builder">
  CrewAI Enterprise includes a Visual Task Builder in Crew Studio that simplifies complex task creation and chaining. Design your task flows visually and test them in real-time without writing code.

  ![Task Builder Screenshot](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-studio-interface.png)

  The Visual Task Builder enables:

  * Drag-and-drop task creation
  * Visual task dependencies and flow
  * Real-time testing and validation
  * Easy sharing and collaboration
</Note>

### Task Execution Flow

Tasks can be executed in two ways:

* **Sequential**: Tasks are executed in the order they are defined
* **Hierarchical**: Tasks are assigned to agents based on their roles and expertise

The execution flow is defined when creating the crew:

```python Code
crew = Crew(
    agents=[agent1, agent2],
    tasks=[task1, task2],
    process=Process.sequential  # or Process.hierarchical
)
```

## Task Attributes

| Attribute                        | Parameters        | Type                        | Description                                                                                                     |
| :------------------------------- | :---------------- | :-------------------------- | :-------------------------------------------------------------------------------------------------------------- |
| **Description**                  | `description`     | `str`                       | A clear, concise statement of what the task entails.                                                            |
| **Expected Output**              | `expected_output` | `str`                       | A detailed description of what the task's completion looks like.                                                |
| **Name** *(optional)*            | `name`            | `Optional[str]`             | A name identifier for the task.                                                                                 |
| **Agent** *(optional)*           | `agent`           | `Optional[BaseAgent]`       | The agent responsible for executing the task.                                                                   |
| **Tools** *(optional)*           | `tools`           | `List[BaseTool]`            | The tools/resources the agent is limited to use for this task.                                                  |
| **Context** *(optional)*         | `context`         | `Optional[List["Task"]]`    | Other tasks whose outputs will be used as context for this task.                                                |
| **Async Execution** *(optional)* | `async_execution` | `Optional[bool]`            | Whether the task should be executed asynchronously. Defaults to False.                                          |
| **Human Input** *(optional)*     | `human_input`     | `Optional[bool]`            | Whether the task should have a human review the final answer of the agent. Defaults to False.                   |
| **Markdown** *(optional)*        | `markdown`        | `Optional[bool]`            | Whether the task should instruct the agent to return the final answer formatted in Markdown. Defaults to False. |
| **Config** *(optional)*          | `config`          | `Optional[Dict[str, Any]]`  | Task-specific configuration parameters.                                                                         |
| **Output File** *(optional)*     | `output_file`     | `Optional[str]`             | File path for storing the task output.                                                                          |
| **Output JSON** *(optional)*     | `output_json`     | `Optional[Type[BaseModel]]` | A Pydantic model to structure the JSON output.                                                                  |
| **Output Pydantic** *(optional)* | `output_pydantic` | `Optional[Type[BaseModel]]` | A Pydantic model for task output.                                                                               |
| **Callback** *(optional)*        | `callback`        | `Optional[Any]`             | Function/object to be executed after task completion.                                                           |

## Creating Tasks

There are two ways to create tasks in CrewAI: using **YAML configuration (recommended)** or defining them **directly in code**.

### YAML Configuration (Recommended)

Using YAML configuration provides a cleaner, more maintainable way to define tasks. We strongly recommend using this approach to define tasks in your CrewAI projects.

After creating your CrewAI project as outlined in the [Installation](/en/installation) section, navigate to the `src/latest_ai_development/config/tasks.yaml` file and modify the template to match your specific task requirements.

<Note>
  Variables in your YAML files (like `{topic}`) will be replaced with values from your inputs when running the crew:

  ```python Code
  crew.kickoff(inputs={'topic': 'AI Agents'})
  ```
</Note>

Here's an example of how to configure tasks using YAML:

````yaml tasks.yaml
research_task:
  description: >
    Conduct a thorough research about {topic}
    Make sure you find any interesting and relevant information given
    the current year is 2025.
  expected_output: >
    A list with 10 bullet points of the most relevant information about {topic}
  agent: researcher

reporting_task:
  description: >
    Review the context you got and expand each topic into a full section for a report.
    Make sure the report is detailed and contains any and all relevant information.
  expected_output: >
    A fully fledge reports with the mains topics, each with a full section of information.
    Formatted as markdown without '```'
  agent: reporting_analyst
  markdown: true
  output_file: report.md
````

To use this YAML configuration in your code, create a crew class that inherits from `CrewBase`:

```python crew.py
# src/latest_ai_development/crew.py

from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task
from crewai_tools import SerperDevTool

@CrewBase
class LatestAiDevelopmentCrew():
  """LatestAiDevelopment crew"""

  @agent
  def researcher(self) -> Agent:
    return Agent(
      config=self.agents_config['researcher'], # type: ignore[index]
      verbose=True,
      tools=[SerperDevTool()]
    )

  @agent
  def reporting_analyst(self) -> Agent:
    return Agent(
      config=self.agents_config['reporting_analyst'], # type: ignore[index]
      verbose=True
    )

  @task
  def research_task(self) -> Task:
    return Task(
      config=self.tasks_config['research_task'] # type: ignore[index]
    )

  @task
  def reporting_task(self) -> Task:
    return Task(
      config=self.tasks_config['reporting_task'] # type: ignore[index]
    )

  @crew
  def crew(self) -> Crew:
    return Crew(
      agents=[
        self.researcher(),
        self.reporting_analyst()
      ],
      tasks=[
        self.research_task(),
        self.reporting_task()
      ],
      process=Process.sequential
    )
```

<Note>
  The names you use in your YAML files (`agents.yaml` and `tasks.yaml`) should match the method names in your Python code.
</Note>

### Direct Code Definition (Alternative)

Alternatively, you can define tasks directly in your code without using YAML configuration:

```python task.py
from crewai import Task

research_task = Task(
    description="""
        Conduct a thorough research about AI Agents.
        Make sure you find any interesting and relevant information given
        the current year is 2025.
    """,
    expected_output="""
        A list with 10 bullet points of the most relevant information about AI Agents
    """,
    agent=researcher
)

reporting_task = Task(
    description="""
        Review the context you got and expand each topic into a full section for a report.
        Make sure the report is detailed and contains any and all relevant information.
    """,
    expected_output="""
        A fully fledge reports with the mains topics, each with a full section of information.
    """,
    agent=reporting_analyst,
    markdown=True,  # Enable markdown formatting for the final output
    output_file="report.md"
)
```

<Tip>
  Directly specify an `agent` for assignment or let the `hierarchical` CrewAI's process decide based on roles, availability, etc.
</Tip>

## Task Output

Understanding task outputs is crucial for building effective AI workflows. CrewAI provides a structured way to handle task results through the `TaskOutput` class, which supports multiple output formats and can be easily passed between tasks.

The output of a task in CrewAI framework is encapsulated within the `TaskOutput` class. This class provides a structured way to access results of a task, including various formats such as raw output, JSON, and Pydantic models.

By default, the `TaskOutput` will only include the `raw` output. A `TaskOutput` will only include the `pydantic` or `json_dict` output if the original `Task` object was configured with `output_pydantic` or `output_json`, respectively.

### Task Output Attributes

| Attribute         | Parameters      | Type                       | Description                                                                                        |
| :---------------- | :-------------- | :------------------------- | :------------------------------------------------------------------------------------------------- |
| **Description**   | `description`   | `str`                      | Description of the task.                                                                           |
| **Summary**       | `summary`       | `Optional[str]`            | Summary of the task, auto-generated from the first 10 words of the description.                    |
| **Raw**           | `raw`           | `str`                      | The raw output of the task. This is the default format for the output.                             |
| **Pydantic**      | `pydantic`      | `Optional[BaseModel]`      | A Pydantic model object representing the structured output of the task.                            |
| **JSON Dict**     | `json_dict`     | `Optional[Dict[str, Any]]` | A dictionary representing the JSON output of the task.                                             |
| **Agent**         | `agent`         | `str`                      | The agent that executed the task.                                                                  |
| **Output Format** | `output_format` | `OutputFormat`             | The format of the task output, with options including RAW, JSON, and Pydantic. The default is RAW. |

### Task Methods and Properties

| Method/Property | Description                                                                                       |
| :-------------- | :------------------------------------------------------------------------------------------------ |
| **json**        | Returns the JSON string representation of the task output if the output format is JSON.           |
| **to\_dict**    | Converts the JSON and Pydantic outputs to a dictionary.                                           |
| **str**         | Returns the string representation of the task output, prioritizing Pydantic, then JSON, then raw. |

### Accessing Task Outputs

Once a task has been executed, its output can be accessed through the `output` attribute of the `Task` object. The `TaskOutput` class provides various ways to interact with and present this output.

#### Example

```python Code
# Example task
task = Task(
    description='Find and summarize the latest AI news',
    expected_output='A bullet list summary of the top 5 most important AI news',
    agent=research_agent,
    tools=[search_tool]
)

# Execute the crew
crew = Crew(
    agents=[research_agent],
    tasks=[task],
    verbose=True
)

result = crew.kickoff()

# Accessing the task output
task_output = task.output

print(f"Task Description: {task_output.description}")
print(f"Task Summary: {task_output.summary}")
print(f"Raw Output: {task_output.raw}")
if task_output.json_dict:
    print(f"JSON Output: {json.dumps(task_output.json_dict, indent=2)}")
if task_output.pydantic:
    print(f"Pydantic Output: {task_output.pydantic}")
```

## Markdown Output Formatting

The `markdown` parameter enables automatic markdown formatting for task outputs. When set to `True`, the task will instruct the agent to format the final answer using proper Markdown syntax.

### Using Markdown Formatting

```python Code
# Example task with markdown formatting enabled
formatted_task = Task(
    description="Create a comprehensive report on AI trends",
    expected_output="A well-structured report with headers, sections, and bullet points",
    agent=reporter_agent,
    markdown=True  # Enable automatic markdown formatting
)
```

When `markdown=True`, the agent will receive additional instructions to format the output using:

* `#` for headers
* `**text**` for bold text
* `*text*` for italic text
* `-` or `*` for bullet points
* `` `code` `` for inline code
* ` `language \`\`\` for code blocks

### YAML Configuration with Markdown

```yaml tasks.yaml
analysis_task:
  description: >
    Analyze the market data and create a detailed report
  expected_output: >
    A comprehensive analysis with charts and key findings
  agent: analyst
  markdown: true  # Enable markdown formatting
  output_file: analysis.md
```

### Benefits of Markdown Output

* **Consistent Formatting**: Ensures all outputs follow proper markdown conventions
* **Better Readability**: Structured content with headers, lists, and emphasis
* **Documentation Ready**: Output can be directly used in documentation systems
* **Cross-Platform Compatibility**: Markdown is universally supported

<Note>
  The markdown formatting instructions are automatically added to the task prompt when `markdown=True`, so you don't need to specify formatting requirements in your task description.
</Note>

## Task Dependencies and Context

Tasks can depend on the output of other tasks using the `context` attribute. For example:

```python Code
research_task = Task(
    description="Research the latest developments in AI",
    expected_output="A list of recent AI developments",
    agent=researcher
)

analysis_task = Task(
    description="Analyze the research findings and identify key trends",
    expected_output="Analysis report of AI trends",
    agent=analyst,
    context=[research_task]  # This task will wait for research_task to complete
)
```

## Task Guardrails

Task guardrails provide a way to validate and transform task outputs before they
are passed to the next task. This feature helps ensure data quality and provides
feedback to agents when their output doesn't meet specific criteria.

### Using Task Guardrails

To add a guardrail to a task, provide a validation function through the `guardrail` parameter:

```python Code
from typing import Tuple, Union, Dict, Any
from crewai import TaskOutput

def validate_blog_content(result: TaskOutput) -> Tuple[bool, Any]:
    """Validate blog content meets requirements."""
    try:
        # Check word count
        word_count = len(result.split())
        if word_count > 200:
            return (False, "Blog content exceeds 200 words")

        # Additional validation logic here
        return (True, result.strip())
    except Exception as e:
        return (False, "Unexpected error during validation")

blog_task = Task(
    description="Write a blog post about AI",
    expected_output="A blog post under 200 words",
    agent=blog_agent,
    guardrail=validate_blog_content  # Add the guardrail function
)
```

### Guardrail Function Requirements

1. **Function Signature**:
   * Must accept exactly one parameter (the task output)
   * Should return a tuple of `(bool, Any)`
   * Type hints are recommended but optional

2. **Return Values**:
   * On success: it returns a tuple of `(bool, Any)`. For example: `(True, validated_result)`
   * On Failure: it returns a tuple of `(bool, str)`. For example: `(False, "Error message explain the failure")`

### LLMGuardrail

The `LLMGuardrail` class offers a robust mechanism for validating task outputs.

### Error Handling Best Practices

1. **Structured Error Responses**:

```python Code
from crewai import TaskOutput, LLMGuardrail

def validate_with_context(result: TaskOutput) -> Tuple[bool, Any]:
    try:
        # Main validation logic
        validated_data = perform_validation(result)
        return (True, validated_data)
    except ValidationError as e:
        return (False, f"VALIDATION_ERROR: {str(e)}")
    except Exception as e:
        return (False, str(e))
```

2. **Error Categories**:
   * Use specific error codes
   * Include relevant context
   * Provide actionable feedback

3. **Validation Chain**:

```python Code
from typing import Any, Dict, List, Tuple, Union
from crewai import TaskOutput

def complex_validation(result: TaskOutput) -> Tuple[bool, Any]:
    """Chain multiple validation steps."""
    # Step 1: Basic validation
    if not result:
        return (False, "Empty result")

    # Step 2: Content validation
    try:
        validated = validate_content(result)
        if not validated:
            return (False, "Invalid content")

        # Step 3: Format validation
        formatted = format_output(validated)
        return (True, formatted)
    except Exception as e:
        return (False, str(e))
```

### Handling Guardrail Results

When a guardrail returns `(False, error)`:

1. The error is sent back to the agent
2. The agent attempts to fix the issue
3. The process repeats until:
   * The guardrail returns `(True, result)`
   * Maximum retries are reached

Example with retry handling:

```python Code
from typing import Optional, Tuple, Union
from crewai import TaskOutput, Task

def validate_json_output(result: TaskOutput) -> Tuple[bool, Any]:
    """Validate and parse JSON output."""
    try:
        # Try to parse as JSON
        data = json.loads(result)
        return (True, data)
    except json.JSONDecodeError as e:
        return (False, "Invalid JSON format")

task = Task(
    description="Generate a JSON report",
    expected_output="A valid JSON object",
    agent=analyst,
    guardrail=validate_json_output,
    max_retries=3  # Limit retry attempts
)
```

## Getting Structured Consistent Outputs from Tasks

<Note>
  It's also important to note that the output of the final task of a crew becomes the final output of the actual crew itself.
</Note>

### Using `output_pydantic`

The `output_pydantic` property allows you to define a Pydantic model that the task output should conform to. This ensures that the output is not only structured but also validated according to the Pydantic model.

Here's an example demonstrating how to use output\_pydantic:

```python Code
import json

from crewai import Agent, Crew, Process, Task
from pydantic import BaseModel


class Blog(BaseModel):
    title: str
    content: str


blog_agent = Agent(
    role="Blog Content Generator Agent",
    goal="Generate a blog title and content",
    backstory="""You are an expert content creator, skilled in crafting engaging and informative blog posts.""",
    verbose=False,
    allow_delegation=False,
    llm="gpt-4o",
)

task1 = Task(
    description="""Create a blog title and content on a given topic. Make sure the content is under 200 words.""",
    expected_output="A compelling blog title and well-written content.",
    agent=blog_agent,
    output_pydantic=Blog,
)

# Instantiate your crew with a sequential process
crew = Crew(
    agents=[blog_agent],
    tasks=[task1],
    verbose=True,
    process=Process.sequential,
)

result = crew.kickoff()

# Option 1: Accessing Properties Using Dictionary-Style Indexing
print("Accessing Properties - Option 1")
title = result["title"]
content = result["content"]
print("Title:", title)
print("Content:", content)

# Option 2: Accessing Properties Directly from the Pydantic Model
print("Accessing Properties - Option 2")
title = result.pydantic.title
content = result.pydantic.content
print("Title:", title)
print("Content:", content)

# Option 3: Accessing Properties Using the to_dict() Method
print("Accessing Properties - Option 3")
output_dict = result.to_dict()
title = output_dict["title"]
content = output_dict["content"]
print("Title:", title)
print("Content:", content)

# Option 4: Printing the Entire Blog Object
print("Accessing Properties - Option 5")
print("Blog:", result)

```

In this example:

* A Pydantic model Blog is defined with title and content fields.
* The task task1 uses the output\_pydantic property to specify that its output should conform to the Blog model.
* After executing the crew, you can access the structured output in multiple ways as shown.

#### Explanation of Accessing the Output

1. Dictionary-Style Indexing: You can directly access the fields using result\["field\_name"]. This works because the CrewOutput class implements the **getitem** method.
2. Directly from Pydantic Model: Access the attributes directly from the result.pydantic object.
3. Using to\_dict() Method: Convert the output to a dictionary and access the fields.
4. Printing the Entire Object: Simply print the result object to see the structured output.

### Using `output_json`

The `output_json` property allows you to define the expected output in JSON format. This ensures that the task's output is a valid JSON structure that can be easily parsed and used in your application.

Here's an example demonstrating how to use `output_json`:

```python Code
import json

from crewai import Agent, Crew, Process, Task
from pydantic import BaseModel


# Define the Pydantic model for the blog
class Blog(BaseModel):
    title: str
    content: str


# Define the agent
blog_agent = Agent(
    role="Blog Content Generator Agent",
    goal="Generate a blog title and content",
    backstory="""You are an expert content creator, skilled in crafting engaging and informative blog posts.""",
    verbose=False,
    allow_delegation=False,
    llm="gpt-4o",
)

# Define the task with output_json set to the Blog model
task1 = Task(
    description="""Create a blog title and content on a given topic. Make sure the content is under 200 words.""",
    expected_output="A JSON object with 'title' and 'content' fields.",
    agent=blog_agent,
    output_json=Blog,
)

# Instantiate the crew with a sequential process
crew = Crew(
    agents=[blog_agent],
    tasks=[task1],
    verbose=True,
    process=Process.sequential,
)

# Kickoff the crew to execute the task
result = crew.kickoff()

# Option 1: Accessing Properties Using Dictionary-Style Indexing
print("Accessing Properties - Option 1")
title = result["title"]
content = result["content"]
print("Title:", title)
print("Content:", content)

# Option 2: Printing the Entire Blog Object
print("Accessing Properties - Option 2")
print("Blog:", result)
```

In this example:

* A Pydantic model Blog is defined with title and content fields, which is used to specify the structure of the JSON output.
* The task task1 uses the output\_json property to indicate that it expects a JSON output conforming to the Blog model.
* After executing the crew, you can access the structured JSON output in two ways as shown.

#### Explanation of Accessing the Output

1. Accessing Properties Using Dictionary-Style Indexing: You can access the fields directly using result\["field\_name"]. This is possible because the CrewOutput class implements the **getitem** method, allowing you to treat the output like a dictionary. In this option, we're retrieving the title and content from the result.
2. Printing the Entire Blog Object: By printing result, you get the string representation of the CrewOutput object. Since the **str** method is implemented to return the JSON output, this will display the entire output as a formatted string representing the Blog object.

***

By using output\_pydantic or output\_json, you ensure that your tasks produce outputs in a consistent and structured format, making it easier to process and utilize the data within your application or across multiple tasks.

## Integrating Tools with Tasks

Leverage tools from the [CrewAI Toolkit](https://github.com/joaomdmoura/crewai-tools) and [LangChain Tools](https://python.langchain.com/docs/integrations/tools) for enhanced task performance and agent interaction.

## Creating a Task with Tools

```python Code
import os
os.environ["OPENAI_API_KEY"] = "Your Key"
os.environ["SERPER_API_KEY"] = "Your Key" # serper.dev API key

from crewai import Agent, Task, Crew
from crewai_tools import SerperDevTool

research_agent = Agent(
  role='Researcher',
  goal='Find and summarize the latest AI news',
  backstory="""You're a researcher at a large company.
  You're responsible for analyzing data and providing insights
  to the business.""",
  verbose=True
)

# to perform a semantic search for a specified query from a text's content across the internet
search_tool = SerperDevTool()

task = Task(
  description='Find and summarize the latest AI news',
  expected_output='A bullet list summary of the top 5 most important AI news',
  agent=research_agent,
  tools=[search_tool]
)

crew = Crew(
    agents=[research_agent],
    tasks=[task],
    verbose=True
)

result = crew.kickoff()
print(result)
```

This demonstrates how tasks with specific tools can override an agent's default set for tailored task execution.

## Referring to Other Tasks

In CrewAI, the output of one task is automatically relayed into the next one, but you can specifically define what tasks' output, including multiple, should be used as context for another task.

This is useful when you have a task that depends on the output of another task that is not performed immediately after it. This is done through the `context` attribute of the task:

```python Code
# ...

research_ai_task = Task(
    description="Research the latest developments in AI",
    expected_output="A list of recent AI developments",
    async_execution=True,
    agent=research_agent,
    tools=[search_tool]
)

research_ops_task = Task(
    description="Research the latest developments in AI Ops",
    expected_output="A list of recent AI Ops developments",
    async_execution=True,
    agent=research_agent,
    tools=[search_tool]
)

write_blog_task = Task(
    description="Write a full blog post about the importance of AI and its latest news",
    expected_output="Full blog post that is 4 paragraphs long",
    agent=writer_agent,
    context=[research_ai_task, research_ops_task]
)

#...
```

## Asynchronous Execution

You can define a task to be executed asynchronously. This means that the crew will not wait for it to be completed to continue with the next task. This is useful for tasks that take a long time to be completed, or that are not crucial for the next tasks to be performed.

You can then use the `context` attribute to define in a future task that it should wait for the output of the asynchronous task to be completed.

```python Code
#...

list_ideas = Task(
    description="List of 5 interesting ideas to explore for an article about AI.",
    expected_output="Bullet point list of 5 ideas for an article.",
    agent=researcher,
    async_execution=True # Will be executed asynchronously
)

list_important_history = Task(
    description="Research the history of AI and give me the 5 most important events.",
    expected_output="Bullet point list of 5 important events.",
    agent=researcher,
    async_execution=True # Will be executed asynchronously
)

write_article = Task(
    description="Write an article about AI, its history, and interesting ideas.",
    expected_output="A 4 paragraph article about AI.",
    agent=writer,
    context=[list_ideas, list_important_history] # Will wait for the output of the two tasks to be completed
)

#...
```

## Callback Mechanism

The callback function is executed after the task is completed, allowing for actions or notifications to be triggered based on the task's outcome.

```python Code
# ...

def callback_function(output: TaskOutput):
    # Do something after the task is completed
    # Example: Send an email to the manager
    print(f"""
        Task completed!
        Task: {output.description}
        Output: {output.raw}
    """)

research_task = Task(
    description='Find and summarize the latest AI news',
    expected_output='A bullet list summary of the top 5 most important AI news',
    agent=research_agent,
    tools=[search_tool],
    callback=callback_function
)

#...
```

## Accessing a Specific Task Output

Once a crew finishes running, you can access the output of a specific task by using the `output` attribute of the task object:

```python Code
# ...
task1 = Task(
    description='Find and summarize the latest AI news',
    expected_output='A bullet list summary of the top 5 most important AI news',
    agent=research_agent,
    tools=[search_tool]
)

#...

crew = Crew(
    agents=[research_agent],
    tasks=[task1, task2, task3],
    verbose=True
)

result = crew.kickoff()

# Returns a TaskOutput object with the description and results of the task
print(f"""
    Task completed!
    Task: {task1.output.description}
    Output: {task1.output.raw}
""")
```

## Tool Override Mechanism

Specifying tools in a task allows for dynamic adaptation of agent capabilities, emphasizing CrewAI's flexibility.

## Error Handling and Validation Mechanisms

While creating and executing tasks, certain validation mechanisms are in place to ensure the robustness and reliability of task attributes. These include but are not limited to:

* Ensuring only one output type is set per task to maintain clear output expectations.
* Preventing the manual assignment of the `id` attribute to uphold the integrity of the unique identifier system.

These validations help in maintaining the consistency and reliability of task executions within the crewAI framework.

## Task Guardrails

Task guardrails provide a powerful way to validate, transform, or filter task outputs before they are passed to the next task. Guardrails are optional functions that execute before the next task starts, allowing you to ensure that task outputs meet specific requirements or formats.

### Basic Usage

#### Define your own logic to validate

```python Code
from typing import Tuple, Union
from crewai import Task

def validate_json_output(result: str) -> Tuple[bool, Union[dict, str]]:
    """Validate that the output is valid JSON."""
    try:
        json_data = json.loads(result)
        return (True, json_data)
    except json.JSONDecodeError:
        return (False, "Output must be valid JSON")

task = Task(
    description="Generate JSON data",
    expected_output="Valid JSON object",
    guardrail=validate_json_output
)
```

#### Leverage a no-code approach for validation

```python Code
from crewai import Task

task = Task(
    description="Generate JSON data",
    expected_output="Valid JSON object",
    guardrail="Ensure the response is a valid JSON object"
)
```

#### Using YAML

```yaml
research_task:
  ...
  guardrail: make sure each bullet contains a minimum of 100 words
  ...
```

```python Code
@CrewBase
class InternalCrew:
    agents_config = "config/agents.yaml"
    tasks_config = "config/tasks.yaml"

    ...
    @task
    def research_task(self):
        return Task(config=self.tasks_config["research_task"])  # type: ignore[index]
    ...
```

#### Use custom models for code generation

```python Code
from crewai import Task
from crewai.llm import LLM

task = Task(
    description="Generate JSON data",
    expected_output="Valid JSON object",
    guardrail=LLMGuardrail(
        description="Ensure the response is a valid JSON object",
        llm=LLM(model="gpt-4o-mini"),
    )
)
```

### How Guardrails Work

1. **Optional Attribute**: Guardrails are an optional attribute at the task level, allowing you to add validation only where needed.
2. **Execution Timing**: The guardrail function is executed before the next task starts, ensuring valid data flow between tasks.
3. **Return Format**: Guardrails must return a tuple of `(success, data)`:
   * If `success` is `True`, `data` is the validated/transformed result
   * If `success` is `False`, `data` is the error message
4. **Result Routing**:
   * On success (`True`), the result is automatically passed to the next task
   * On failure (`False`), the error is sent back to the agent to generate a new answer

### Common Use Cases

#### Data Format Validation

```python Code
def validate_email_format(result: str) -> Tuple[bool, Union[str, str]]:
    """Ensure the output contains a valid email address."""
    import re
    email_pattern = r'^[\w\.-]+@[\w\.-]+\.\w+$'
    if re.match(email_pattern, result.strip()):
        return (True, result.strip())
    return (False, "Output must be a valid email address")
```

#### Content Filtering

```python Code
def filter_sensitive_info(result: str) -> Tuple[bool, Union[str, str]]:
    """Remove or validate sensitive information."""
    sensitive_patterns = ['SSN:', 'password:', 'secret:']
    for pattern in sensitive_patterns:
        if pattern.lower() in result.lower():
            return (False, f"Output contains sensitive information ({pattern})")
    return (True, result)
```

#### Data Transformation

```python Code
def normalize_phone_number(result: str) -> Tuple[bool, Union[str, str]]:
    """Ensure phone numbers are in a consistent format."""
    import re
    digits = re.sub(r'\D', '', result)
    if len(digits) == 10:
        formatted = f"({digits[:3]}) {digits[3:6]}-{digits[6:]}"
        return (True, formatted)
    return (False, "Output must be a 10-digit phone number")
```

### Advanced Features

#### Chaining Multiple Validations

```python Code
def chain_validations(*validators):
    """Chain multiple validators together."""
    def combined_validator(result):
        for validator in validators:
            success, data = validator(result)
            if not success:
                return (False, data)
            result = data
        return (True, result)
    return combined_validator

# Usage
task = Task(
    description="Get user contact info",
    expected_output="Email and phone",
    guardrail=chain_validations(
        validate_email_format,
        filter_sensitive_info
    )
)
```

#### Custom Retry Logic

```python Code
task = Task(
    description="Generate data",
    expected_output="Valid data",
    guardrail=validate_data,
    max_retries=5  # Override default retry limit
)
```

## Creating Directories when Saving Files

You can now specify if a task should create directories when saving its output to a file. This is particularly useful for organizing outputs and ensuring that file paths are correctly structured.

```python Code
# ...

save_output_task = Task(
    description='Save the summarized AI news to a file',
    expected_output='File saved successfully',
    agent=research_agent,
    tools=[file_save_tool],
    output_file='outputs/ai_news_summary.txt',
    create_directory=True
)

#...
```

Check out the video below to see how to use structured outputs in CrewAI:

<iframe width="560" height="315" src="https://www.youtube.com/embed/dNpKQk5uxHw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen />

## Conclusion

Tasks are the driving force behind the actions of agents in CrewAI.
By properly defining tasks and their outcomes, you set the stage for your AI agents to work effectively, either independently or as a collaborative unit.
Equipping tasks with appropriate tools, understanding the execution process, and following robust validation practices are crucial for maximizing CrewAI's potential,
ensuring agents are effectively prepared for their assignments and that tasks are executed as intended.


# Testing
Source: https://docs.crewai.com/en/concepts/testing

Learn how to test your CrewAI Crew and evaluate their performance.

## Overview

Testing is a crucial part of the development process, and it is essential to ensure that your crew is performing as expected. With crewAI, you can easily test your crew and evaluate its performance using the built-in testing capabilities.

### Using the Testing Feature

We added the CLI command `crewai test` to make it easy to test your crew. This command will run your crew for a specified number of iterations and provide detailed performance metrics. The parameters are `n_iterations` and `model`, which are optional and default to 2 and `gpt-4o-mini` respectively. For now, the only provider available is OpenAI.

```bash
crewai test
```

If you want to run more iterations or use a different model, you can specify the parameters like this:

```bash
crewai test --n_iterations 5 --model gpt-4o
```

or using the short forms:

```bash
crewai test -n 5 -m gpt-4o
```

When you run the `crewai test` command, the crew will be executed for the specified number of iterations, and the performance metrics will be displayed at the end of the run.

A table of scores at the end will show the performance of the crew in terms of the following metrics:

<center>**Tasks Scores (1-10 Higher is better)**</center>

| Tasks/Crew/Agents  | Run 1 | Run 2 | Avg. Total |            Agents            | Additional Info                |
| :----------------- | :---: | :---: | :--------: | :--------------------------: | :----------------------------- |
| Task 1             |  9.0  |  9.5  |   **9.2**  |     Professional Insights    |                                |
|                    |       |       |            |          Researcher          |                                |
| Task 2             |  9.0  |  10.0 |   **9.5**  | Company Profile Investigator |                                |
| Task 3             |  9.0  |  9.0  |   **9.0**  |      Automation Insights     |                                |
|                    |       |       |            |          Specialist          |                                |
| Task 4             |  9.0  |  9.0  |   **9.0**  |     Final Report Compiler    | Automation Insights Specialist |
| Crew               |  9.00 |  9.38 |   **9.2**  |                              |                                |
| Execution Time (s) |  126  |  145  |   **135**  |                              |                                |

The example above shows the test results for two runs of the crew with two tasks, with the average total score for each task and the crew as a whole.


# Tools
Source: https://docs.crewai.com/en/concepts/tools

Understanding and leveraging tools within the CrewAI framework for agent collaboration and task execution.

## Overview

CrewAI tools empower agents with capabilities ranging from web searching and data analysis to collaboration and delegating tasks among coworkers.
This documentation outlines how to create, integrate, and leverage these tools within the CrewAI framework, including a new focus on collaboration tools.

## What is a Tool?

A tool in CrewAI is a skill or function that agents can utilize to perform various actions.
This includes tools from the [CrewAI Toolkit](https://github.com/joaomdmoura/crewai-tools) and [LangChain Tools](https://python.langchain.com/docs/integrations/tools),
enabling everything from simple searches to complex interactions and effective teamwork among agents.

<Note type="info" title="Enterprise Enhancement: Tools Repository">
  CrewAI Enterprise provides a comprehensive Tools Repository with pre-built integrations for common business systems and APIs. Deploy agents with enterprise tools in minutes instead of days.

  The Enterprise Tools Repository includes:

  * Pre-built connectors for popular enterprise systems
  * Custom tool creation interface
  * Version control and sharing capabilities
  * Security and compliance features
</Note>

## Key Characteristics of Tools

* **Utility**: Crafted for tasks such as web searching, data analysis, content generation, and agent collaboration.
* **Integration**: Boosts agent capabilities by seamlessly integrating tools into their workflow.
* **Customizability**: Provides the flexibility to develop custom tools or utilize existing ones, catering to the specific needs of agents.
* **Error Handling**: Incorporates robust error handling mechanisms to ensure smooth operation.
* **Caching Mechanism**: Features intelligent caching to optimize performance and reduce redundant operations.
* **Asynchronous Support**: Handles both synchronous and asynchronous tools, enabling non-blocking operations.

## Using CrewAI Tools

To enhance your agents' capabilities with crewAI tools, begin by installing our extra tools package:

```bash
pip install 'crewai[tools]'
```

Here's an example demonstrating their use:

```python Code
import os
from crewai import Agent, Task, Crew
# Importing crewAI tools
from crewai_tools import (
    DirectoryReadTool,
    FileReadTool,
    SerperDevTool,
    WebsiteSearchTool
)

# Set up API keys
os.environ["SERPER_API_KEY"] = "Your Key" # serper.dev API key
os.environ["OPENAI_API_KEY"] = "Your Key"

# Instantiate tools
docs_tool = DirectoryReadTool(directory='./blog-posts')
file_tool = FileReadTool()
search_tool = SerperDevTool()
web_rag_tool = WebsiteSearchTool()

# Create agents
researcher = Agent(
    role='Market Research Analyst',
    goal='Provide up-to-date market analysis of the AI industry',
    backstory='An expert analyst with a keen eye for market trends.',
    tools=[search_tool, web_rag_tool],
    verbose=True
)

writer = Agent(
    role='Content Writer',
    goal='Craft engaging blog posts about the AI industry',
    backstory='A skilled writer with a passion for technology.',
    tools=[docs_tool, file_tool],
    verbose=True
)

# Define tasks
research = Task(
    description='Research the latest trends in the AI industry and provide a summary.',
    expected_output='A summary of the top 3 trending developments in the AI industry with a unique perspective on their significance.',
    agent=researcher
)

write = Task(
    description='Write an engaging blog post about the AI industry, based on the research analyst's summary. Draw inspiration from the latest blog posts in the directory.',
    expected_output='A 4-paragraph blog post formatted in markdown with engaging, informative, and accessible content, avoiding complex jargon.',
    agent=writer,
    output_file='blog-posts/new_post.md'  # The final blog post will be saved here
)

# Assemble a crew with planning enabled
crew = Crew(
    agents=[researcher, writer],
    tasks=[research, write],
    verbose=True,
    planning=True,  # Enable planning feature
)

# Execute tasks
crew.kickoff()
```

## Available CrewAI Tools

* **Error Handling**: All tools are built with error handling capabilities, allowing agents to gracefully manage exceptions and continue their tasks.
* **Caching Mechanism**: All tools support caching, enabling agents to efficiently reuse previously obtained results, reducing the load on external resources and speeding up the execution time. You can also define finer control over the caching mechanism using the `cache_function` attribute on the tool.

Here is a list of the available tools and their descriptions:

| Tool                             | Description                                                                                    |
| :------------------------------- | :--------------------------------------------------------------------------------------------- |
| **ApifyActorsTool**              | A tool that integrates Apify Actors with your workflows for web scraping and automation tasks. |
| **BrowserbaseLoadTool**          | A tool for interacting with and extracting data from web browsers.                             |
| **CodeDocsSearchTool**           | A RAG tool optimized for searching through code documentation and related technical documents. |
| **CodeInterpreterTool**          | A tool for interpreting python code.                                                           |
| **ComposioTool**                 | Enables use of Composio tools.                                                                 |
| **CSVSearchTool**                | A RAG tool designed for searching within CSV files, tailored to handle structured data.        |
| **DALL-E Tool**                  | A tool for generating images using the DALL-E API.                                             |
| **DirectorySearchTool**          | A RAG tool for searching within directories, useful for navigating through file systems.       |
| **DOCXSearchTool**               | A RAG tool aimed at searching within DOCX documents, ideal for processing Word files.          |
| **DirectoryReadTool**            | Facilitates reading and processing of directory structures and their contents.                 |
| **EXASearchTool**                | A tool designed for performing exhaustive searches across various data sources.                |
| **FileReadTool**                 | Enables reading and extracting data from files, supporting various file formats.               |
| **FirecrawlSearchTool**          | A tool to search webpages using Firecrawl and return the results.                              |
| **FirecrawlCrawlWebsiteTool**    | A tool for crawling webpages using Firecrawl.                                                  |
| **FirecrawlScrapeWebsiteTool**   | A tool for scraping webpages URL using Firecrawl and returning its contents.                   |
| **GithubSearchTool**             | A RAG tool for searching within GitHub repositories, useful for code and documentation search. |
| **SerperDevTool**                | A specialized tool for development purposes, with specific functionalities under development.  |
| **TXTSearchTool**                | A RAG tool focused on searching within text (.txt) files, suitable for unstructured data.      |
| **JSONSearchTool**               | A RAG tool designed for searching within JSON files, catering to structured data handling.     |
| **LlamaIndexTool**               | Enables the use of LlamaIndex tools.                                                           |
| **MDXSearchTool**                | A RAG tool tailored for searching within Markdown (MDX) files, useful for documentation.       |
| **PDFSearchTool**                | A RAG tool aimed at searching within PDF documents, ideal for processing scanned documents.    |
| **PGSearchTool**                 | A RAG tool optimized for searching within PostgreSQL databases, suitable for database queries. |
| **Vision Tool**                  | A tool for generating images using the DALL-E API.                                             |
| **RagTool**                      | A general-purpose RAG tool capable of handling various data sources and types.                 |
| **ScrapeElementFromWebsiteTool** | Enables scraping specific elements from websites, useful for targeted data extraction.         |
| **ScrapeWebsiteTool**            | Facilitates scraping entire websites, ideal for comprehensive data collection.                 |
| **WebsiteSearchTool**            | A RAG tool for searching website content, optimized for web data extraction.                   |
| **XMLSearchTool**                | A RAG tool designed for searching within XML files, suitable for structured data formats.      |
| **YoutubeChannelSearchTool**     | A RAG tool for searching within YouTube channels, useful for video content analysis.           |
| **YoutubeVideoSearchTool**       | A RAG tool aimed at searching within YouTube videos, ideal for video data extraction.          |

## Creating your own Tools

<Tip>
  Developers can craft `custom tools` tailored for their agent's needs or
  utilize pre-built options.
</Tip>

There are two main ways for one to create a CrewAI tool:

### Subclassing `BaseTool`

```python Code
from crewai.tools import BaseTool
from pydantic import BaseModel, Field

class MyToolInput(BaseModel):
    """Input schema for MyCustomTool."""
    argument: str = Field(..., description="Description of the argument.")

class MyCustomTool(BaseTool):
    name: str = "Name of my tool"
    description: str = "What this tool does. It's vital for effective utilization."
    args_schema: Type[BaseModel] = MyToolInput

    def _run(self, argument: str) -> str:
        # Your tool's logic here
        return "Tool's result"
```

## Asynchronous Tool Support

CrewAI supports asynchronous tools, allowing you to implement tools that perform non-blocking operations like network requests, file I/O, or other async operations without blocking the main execution thread.

### Creating Async Tools

You can create async tools in two ways:

#### 1. Using the `tool` Decorator with Async Functions

```python Code
from crewai.tools import tool

@tool("fetch_data_async")
async def fetch_data_async(query: str) -> str:
    """Asynchronously fetch data based on the query."""
    # Simulate async operation
    await asyncio.sleep(1)
    return f"Data retrieved for {query}"
```

#### 2. Implementing Async Methods in Custom Tool Classes

```python Code
from crewai.tools import BaseTool

class AsyncCustomTool(BaseTool):
    name: str = "async_custom_tool"
    description: str = "An asynchronous custom tool"

    async def _run(self, query: str = "") -> str:
        """Asynchronously run the tool"""
        # Your async implementation here
        await asyncio.sleep(1)
        return f"Processed {query} asynchronously"
```

### Using Async Tools

Async tools work seamlessly in both standard Crew workflows and Flow-based workflows:

```python Code
# In standard Crew
agent = Agent(role="researcher", tools=[async_custom_tool])

# In Flow
class MyFlow(Flow):
    @start()
    async def begin(self):
        crew = Crew(agents=[agent])
        result = await crew.kickoff_async()
        return result
```

The CrewAI framework automatically handles the execution of both synchronous and asynchronous tools, so you don't need to worry about how to call them differently.

### Utilizing the `tool` Decorator

```python Code
from crewai.tools import tool
@tool("Name of my tool")
def my_tool(question: str) -> str:
    """Clear description for what this tool is useful for, your agent will need this information to use it."""
    # Function logic here
    return "Result from your custom tool"
```

### Custom Caching Mechanism

<Tip>
  Tools can optionally implement a `cache_function` to fine-tune caching
  behavior. This function determines when to cache results based on specific
  conditions, offering granular control over caching logic.
</Tip>

```python Code
from crewai.tools import tool

@tool
def multiplication_tool(first_number: int, second_number: int) -> str:
    """Useful for when you need to multiply two numbers together."""
    return first_number * second_number

def cache_func(args, result):
    # In this case, we only cache the result if it's a multiple of 2
    cache = result % 2 == 0
    return cache

multiplication_tool.cache_function = cache_func

writer1 = Agent(
        role="Writer",
        goal="You write lessons of math for kids.",
        backstory="You're an expert in writing and you love to teach kids but you know nothing of math.",
        tools=[multiplication_tool],
        allow_delegation=False,
    )
    #...
```

## Conclusion

Tools are pivotal in extending the capabilities of CrewAI agents, enabling them to undertake a broad spectrum of tasks and collaborate effectively.
When building solutions with CrewAI, leverage both custom and existing tools to empower your agents and enhance the AI ecosystem. Consider utilizing error handling,
caching mechanisms, and the flexibility of tool arguments to optimize your agents' performance and capabilities.


# Training
Source: https://docs.crewai.com/en/concepts/training

Learn how to train your CrewAI agents by giving them feedback early on and get consistent results.

## Overview

The training feature in CrewAI allows you to train your AI agents using the command-line interface (CLI).
By running the command `crewai train -n <n_iterations>`, you can specify the number of iterations for the training process.

During training, CrewAI utilizes techniques to optimize the performance of your agents along with human feedback.
This helps the agents improve their understanding, decision-making, and problem-solving abilities.

### Training Your Crew Using the CLI

To use the training feature, follow these steps:

1. Open your terminal or command prompt.
2. Navigate to the directory where your CrewAI project is located.
3. Run the following command:

```shell
crewai train -n <n_iterations> <filename> (optional)
```

<Tip>
  Replace `<n_iterations>` with the desired number of training iterations and `<filename>` with the appropriate filename ending with `.pkl`.
</Tip>

### Training Your Crew Programmatically

To train your crew programmatically, use the following steps:

1. Define the number of iterations for training.
2. Specify the input parameters for the training process.
3. Execute the training command within a try-except block to handle potential errors.

```python Code
n_iterations = 2
inputs = {"topic": "CrewAI Training"}
filename = "your_model.pkl"

try:
    YourCrewName_Crew().crew().train(
      n_iterations=n_iterations,
      inputs=inputs,
      filename=filename
    )

except Exception as e:
    raise Exception(f"An error occurred while training the crew: {e}")
```

### Key Points to Note

* **Positive Integer Requirement:** Ensure that the number of iterations (`n_iterations`) is a positive integer. The code will raise a `ValueError` if this condition is not met.
* **Filename Requirement:** Ensure that the filename ends with `.pkl`. The code will raise a `ValueError` if this condition is not met.
* **Error Handling:** The code handles subprocess errors and unexpected exceptions, providing error messages to the user.

It is important to note that the training process may take some time, depending on the complexity of your agents and will also require your feedback on each iteration.

Once the training is complete, your agents will be equipped with enhanced capabilities and knowledge, ready to tackle complex tasks and provide more consistent and valuable insights.

Remember to regularly update and retrain your agents to ensure they stay up-to-date with the latest information and advancements in the field.

Happy training with CrewAI! üöÄ

## Small Language Model Considerations

<Warning>
  When using smaller language models (‚â§7B parameters) for training data evaluation, be aware that they may face challenges with generating structured outputs and following complex instructions.
</Warning>

### Limitations of Small Models in Training Evaluation

<CardGroup cols={2}>
  <Card title="JSON Output Accuracy" icon="triangle-exclamation">
    Smaller models often struggle with producing valid JSON responses needed for structured training evaluations, leading to parsing errors and incomplete data.
  </Card>

  <Card title="Evaluation Quality" icon="chart-line">
    Models under 7B parameters may provide less nuanced evaluations with limited reasoning depth compared to larger models.
  </Card>

  <Card title="Instruction Following" icon="list-check">
    Complex training evaluation criteria may not be fully followed or considered by smaller models.
  </Card>

  <Card title="Consistency" icon="rotate">
    Evaluations across multiple training iterations may lack consistency with smaller models.
  </Card>
</CardGroup>

### Recommendations for Training

<Tabs>
  <Tab title="Best Practice">
    For optimal training quality and reliable evaluations, we strongly recommend using models with at least 7B parameters or larger:

    ```python
    from crewai import Agent, Crew, Task, LLM

    # Recommended minimum for training evaluation
    llm = LLM(model="mistral/open-mistral-7b")

    # Better options for reliable training evaluation
    llm = LLM(model="anthropic/claude-3-sonnet-20240229-v1:0")
    llm = LLM(model="gpt-4o")

    # Use this LLM with your agents
    agent = Agent(
        role="Training Evaluator",
        goal="Provide accurate training feedback",
        llm=llm
    )
    ```

    <Tip>
      More powerful models provide higher quality feedback with better reasoning, leading to more effective training iterations.
    </Tip>
  </Tab>

  <Tab title="Small Model Usage">
    If you must use smaller models for training evaluation, be aware of these constraints:

    ```python
    # Using a smaller model (expect some limitations)
    llm = LLM(model="huggingface/microsoft/Phi-3-mini-4k-instruct")
    ```

    <Warning>
      While CrewAI includes optimizations for small models, expect less reliable and less nuanced evaluation results that may require more human intervention during training.
    </Warning>
  </Tab>
</Tabs>


# Hallucination Guardrail
Source: https://docs.crewai.com/en/enterprise/features/hallucination-guardrail

Prevent and detect AI hallucinations in your CrewAI tasks

## Overview

The Hallucination Guardrail is an enterprise feature that validates AI-generated content to ensure it's grounded in facts and doesn't contain hallucinations. It analyzes task outputs against reference context and provides detailed feedback when potentially hallucinated content is detected.

## What are Hallucinations?

AI hallucinations occur when language models generate content that appears plausible but is factually incorrect or not supported by the provided context. The Hallucination Guardrail helps prevent these issues by:

* Comparing outputs against reference context
* Evaluating faithfulness to source material
* Providing detailed feedback on problematic content
* Supporting custom thresholds for validation strictness

## Basic Usage

### Setting Up the Guardrail

```python
from crewai.tasks.hallucination_guardrail import HallucinationGuardrail
from crewai import LLM

# Basic usage - will use task's expected_output as context
guardrail = HallucinationGuardrail(
    llm=LLM(model="gpt-4o-mini")
)

# With explicit reference context
context_guardrail = HallucinationGuardrail(
    context="AI helps with various tasks including analysis and generation.",
    llm=LLM(model="gpt-4o-mini")
)
```

### Adding to Tasks

```python
from crewai import Task

# Create your task with the guardrail
task = Task(
    description="Write a summary about AI capabilities",
    expected_output="A factual summary based on the provided context",
    agent=my_agent,
    guardrail=guardrail  # Add the guardrail to validate output
)
```

## Advanced Configuration

### Custom Threshold Validation

For stricter validation, you can set a custom faithfulness threshold (0-10 scale):

```python
# Strict guardrail requiring high faithfulness score
strict_guardrail = HallucinationGuardrail(
    context="Quantum computing uses qubits that exist in superposition states.",
    llm=LLM(model="gpt-4o-mini"),
    threshold=8.0  # Requires score >= 8 to pass validation
)
```

### Including Tool Response Context

When your task uses tools, you can include tool responses for more accurate validation:

```python
# Guardrail with tool response context
weather_guardrail = HallucinationGuardrail(
    context="Current weather information for the requested location",
    llm=LLM(model="gpt-4o-mini"),
    tool_response="Weather API returned: Temperature 22¬∞C, Humidity 65%, Clear skies"
)
```

## How It Works

### Validation Process

1. **Context Analysis**: The guardrail compares task output against the provided reference context
2. **Faithfulness Scoring**: Uses an internal evaluator to assign a faithfulness score (0-10)
3. **Verdict Determination**: Determines if content is faithful or contains hallucinations
4. **Threshold Checking**: If a custom threshold is set, validates against that score
5. **Feedback Generation**: Provides detailed reasons when validation fails

### Validation Logic

* **Default Mode**: Uses verdict-based validation (FAITHFUL vs HALLUCINATED)
* **Threshold Mode**: Requires faithfulness score to meet or exceed the specified threshold
* **Error Handling**: Gracefully handles evaluation errors and provides informative feedback

## Guardrail Results

The guardrail returns structured results indicating validation status:

```python
# Example of guardrail result structure
{
    "valid": False,
    "feedback": "Content appears to be hallucinated (score: 4.2/10, verdict: HALLUCINATED). The output contains information not supported by the provided context."
}
```

### Result Properties

* **valid**: Boolean indicating whether the output passed validation
* **feedback**: Detailed explanation when validation fails, including:
  * Faithfulness score
  * Verdict classification
  * Specific reasons for failure

## Integration with Task System

### Automatic Validation

When a guardrail is added to a task, it automatically validates the output before the task is marked as complete:

```python
# Task output validation flow
task_output = agent.execute_task(task)
validation_result = guardrail(task_output)

if validation_result.valid:
    # Task completes successfully
    return task_output
else:
    # Task fails with validation feedback
    raise ValidationError(validation_result.feedback)
```

### Event Tracking

The guardrail integrates with CrewAI's event system to provide observability:

* **Validation Started**: When guardrail evaluation begins
* **Validation Completed**: When evaluation finishes with results
* **Validation Failed**: When technical errors occur during evaluation

## Best Practices

### Context Guidelines

<Steps>
  <Step title="Provide Comprehensive Context">
    Include all relevant factual information that the AI should base its output on:

    ```python
    context = """
    Company XYZ was founded in 2020 and specializes in renewable energy solutions.
    They have 150 employees and generated $50M revenue in 2023.
    Their main products include solar panels and wind turbines.
    """
    ```
  </Step>

  <Step title="Keep Context Relevant">
    Only include information directly related to the task to avoid confusion:

    ```python
    # Good: Focused context
    context = "The current weather in New York is 18¬∞C with light rain."

    # Avoid: Unrelated information
    context = "The weather is 18¬∞C. The city has 8 million people. Traffic is heavy."
    ```
  </Step>

  <Step title="Update Context Regularly">
    Ensure your reference context reflects current, accurate information.
  </Step>
</Steps>

### Threshold Selection

<Steps>
  <Step title="Start with Default Validation">
    Begin without custom thresholds to understand baseline performance.
  </Step>

  <Step title="Adjust Based on Requirements">
    * **High-stakes content**: Use threshold 8-10 for maximum accuracy
    * **General content**: Use threshold 6-7 for balanced validation
    * **Creative content**: Use threshold 4-5 or default verdict-based validation
  </Step>

  <Step title="Monitor and Iterate">
    Track validation results and adjust thresholds based on false positives/negatives.
  </Step>
</Steps>

## Performance Considerations

### Impact on Execution Time

* **Validation Overhead**: Each guardrail adds \~1-3 seconds per task
* **LLM Efficiency**: Choose efficient models for evaluation (e.g., gpt-4o-mini)

### Cost Optimization

* **Model Selection**: Use smaller, efficient models for guardrail evaluation
* **Context Size**: Keep reference context concise but comprehensive
* **Caching**: Consider caching validation results for repeated content

## Troubleshooting

<Accordion title="Validation Always Fails">
  **Possible Causes:**

  * Context is too restrictive or unrelated to task output
  * Threshold is set too high for the content type
  * Reference context contains outdated information

  **Solutions:**

  * Review and update context to match task requirements
  * Lower threshold or use default verdict-based validation
  * Ensure context is current and accurate
</Accordion>

<Accordion title="False Positives (Valid Content Marked Invalid)">
  **Possible Causes:**

  * Threshold too high for creative or interpretive tasks
  * Context doesn't cover all valid aspects of the output
  * Evaluation model being overly conservative

  **Solutions:**

  * Lower threshold or use default validation
  * Expand context to include broader acceptable content
  * Test with different evaluation models
</Accordion>

<Accordion title="Evaluation Errors">
  **Possible Causes:**

  * Network connectivity issues
  * LLM model unavailable or rate limited
  * Malformed task output or context

  **Solutions:**

  * Check network connectivity and LLM service status
  * Implement retry logic for transient failures
  * Validate task output format before guardrail evaluation
</Accordion>

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with hallucination guardrail configuration or troubleshooting.
</Card>


# Integrations
Source: https://docs.crewai.com/en/enterprise/features/integrations

Connected applications for your agents to take actions.

## Overview

Enable your agents to authenticate with any OAuth enabled provider and take actions. From Salesforce and HubSpot to Google and GitHub, we've got you covered with 16+ integrated services.

<Frame>
  ![Integrations](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew_connectors.png)
</Frame>

## Supported Integrations

### **Communication & Collaboration**

* **Gmail** - Manage emails and drafts
* **Slack** - Workspace notifications and alerts
* **Microsoft** - Office 365 and Teams integration

### **Project Management**

* **Jira** - Issue tracking and project management
* **ClickUp** - Task and productivity management
* **Asana** - Team task and project coordination
* **Notion** - Page and database management
* **Linear** - Software project and bug tracking
* **GitHub** - Repository and issue management

### **Customer Relationship Management**

* **Salesforce** - CRM account and opportunity management
* **HubSpot** - Sales pipeline and contact management
* **Zendesk** - Customer support ticket management

### **Business & Finance**

* **Stripe** - Payment processing and customer management
* **Shopify** - E-commerce store and product management

### **Productivity & Storage**

* **Google Sheets** - Spreadsheet data synchronization
* **Google Calendar** - Event and schedule management
* **Box** - File storage and document management

and more to come!

## Prerequisites

Before using Authentication Integrations, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account. You can get started with a free trial.

## Setting Up Integrations

### 1. Connect Your Account

1. Navigate to [CrewAI Enterprise](https://app.crewai.com)
2. Go to **Integrations** tab - [https://app.crewai.com/crewai\_plus/connectors](https://app.crewai.com/crewai_plus/connectors)
3. Click **Connect** on your desired service from the Authentication Integrations section
4. Complete the OAuth authentication flow
5. Grant necessary permissions for your use case
6. Get your Enterprise Token from your [CrewAI Enterprise](https://app.crewai.com) account page - [https://app.crewai.com/crewai\_plus/settings/account](https://app.crewai.com/crewai_plus/settings/account)

<Frame>
  ![Integrations](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/enterprise_action_auth_token.png)
</Frame>

### 2. Install Integration Tools

All you need is the latest version of `crewai-tools` package.

```bash
uv add crewai-tools
```

## Usage Examples

### Basic Usage

<Tip>
  All the services you are authenticated into will be available as tools. So all you need to do is add the `CrewaiEnterpriseTools` to your agent and you are good to go.
</Tip>

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Gmail tool will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)
# print the tools
print(enterprise_tools)

# Create an agent with Gmail capabilities
email_agent = Agent(
    role="Email Manager",
    goal="Manage and organize email communications",
    backstory="An AI assistant specialized in email management and communication.",
    tools=enterprise_tools
)

# Task to send an email
email_task = Task(
    description="Draft and send a follow-up email to john@example.com about the project update",
    agent=email_agent,
    expected_output="Confirmation that email was sent successfully"
)

# Run the task
crew = Crew(
    agents=[email_agent],
    tasks=[email_task]
)

# Run the crew
crew.kickoff()
```

### Filtering Tools

```python
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    actions_list=["gmail_find_email"] # only gmail_find_email tool will be available
)
gmail_tool = enterprise_tools["gmail_find_email"]

gmail_agent = Agent(
    role="Gmail Manager",
    goal="Manage gmail communications and notifications",
    backstory="An AI assistant that helps coordinate gmail communications.",
    tools=[gmail_tool]
)

notification_task = Task(
    description="Find the email from john@example.com",
    agent=gmail_agent,
    expected_output="Email found from john@example.com"
)

# Run the task
crew = Crew(
    agents=[slack_agent],
    tasks=[notification_task]
)
```

## Best Practices

### Security

* **Principle of Least Privilege**: Only grant the minimum permissions required for your agents' tasks
* **Regular Audits**: Periodically review connected integrations and their permissions
* **Secure Credentials**: Never hardcode credentials; use CrewAI's secure authentication flow

### Filtering Tools

On a deployed crew, you can specify which actions are avialbel for each integration from the settings page of the service you connected to.

<Frame>
  ![Integrations](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/filtering_enterprise_action_tools.png)
</Frame>

### Scoped Deployments for multi user organizations

You can deploy your crew and scope each integration to a specific user. For example, a crew that connects to google can use a specific user's gmail account.

<Tip>
  This is useful for multi user organizations where you want to scope the integration to a specific user.
</Tip>

Use the `user_bearer_token` to scope the integration to a specific user so that when the crew is kicked off, it will use the user's bearer token to authenticate with the integration. If user is not logged in, then the crew will not use any connected integrations. Use the default bearer token to authenticate with the integrations thats deployed with the crew.

<Frame>
  ![Integrations](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/user_bearer_token.png)
</Frame>

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with integration setup or troubleshooting.
</Card>


# Tool Repository
Source: https://docs.crewai.com/en/enterprise/features/tool-repository

Using the Tool Repository to manage your tools

## Overview

The Tool Repository is a package manager for CrewAI tools. It allows users to publish, install, and manage tools that integrate with CrewAI crews and flows.

Tools can be:

* **Private**: accessible only within your organization (default)
* **Public**: accessible to all CrewAI users if published with the `--public` flag

The repository is not a version control system. Use Git to track code changes and enable collaboration.

## Prerequisites

Before using the Tool Repository, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account
* [CrewAI CLI](https://docs.crewai.com/concepts/cli#cli) installed
* uv>=0.5.0 installed. Check out [how to upgrade](https://docs.astral.sh/uv/getting-started/installation/#upgrading-uv)
* [Git](https://git-scm.com) installed and configured
* Access permissions to publish or install tools in your CrewAI Enterprise organization

## Installing Tools

To install a tool:

```bash
crewai tool install <tool-name>
```

This installs the tool and adds it to `pyproject.toml`.

## Creating and Publishing Tools

To create a new tool project:

```bash
crewai tool create <tool-name>
```

This generates a scaffolded tool project locally.

After making changes, initialize a Git repository and commit the code:

```bash
git init
git add .
git commit -m "Initial version"
```

To publish the tool:

```bash
crewai tool publish
```

By default, tools are published as private. To make a tool public:

```bash
crewai tool publish --public
```

For more details on how to build tools, see [Creating your own tools](https://docs.crewai.com/concepts/tools#creating-your-own-tools).

## Updating Tools

To update a published tool:

1. Modify the tool locally
2. Update the version in `pyproject.toml` (e.g., from `0.1.0` to `0.1.1`)
3. Commit the changes and publish

```bash
git commit -m "Update version to 0.1.1"
crewai tool publish
```

## Deleting Tools

To delete a tool:

1. Go to [CrewAI Enterprise](https://app.crewai.com)
2. Navigate to **Tools**
3. Select the tool
4. Click **Delete**

<Warning>
  Deletion is permanent. Deleted tools cannot be restored or re-installed.
</Warning>

## Security Checks

Every published version undergoes automated security checks, and are only available to install after they pass.

You can check the security check status of a tool at:

`CrewAI Enterprise > Tools > Your Tool > Versions`

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with API integration or troubleshooting.
</Card>


# Traces
Source: https://docs.crewai.com/en/enterprise/features/traces

Using Traces to monitor your Crews

## Overview

Traces provide comprehensive visibility into your crew executions, helping you monitor performance, debug issues, and optimize your AI agent workflows.

## What are Traces?

Traces in CrewAI Enterprise are detailed execution records that capture every aspect of your crew's operation, from initial inputs to final outputs. They record:

* Agent thoughts and reasoning
* Task execution details
* Tool usage and outputs
* Token consumption metrics
* Execution times
* Cost estimates

<Frame>
  ![Traces Overview](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/traces-overview.png)
</Frame>

## Accessing Traces

<Steps>
  <Step title="Navigate to the Traces Tab">
    Once in your CrewAI Enterprise dashboard, click on the **Traces** to view all execution records.
  </Step>

  <Step title="Select an Execution">
    You'll see a list of all crew executions, sorted by date. Click on any execution to view its detailed trace.
  </Step>
</Steps>

## Understanding the Trace Interface

The trace interface is divided into several sections, each providing different insights into your crew's execution:

### 1. Execution Summary

The top section displays high-level metrics about the execution:

* **Total Tokens**: Number of tokens consumed across all tasks
* **Prompt Tokens**: Tokens used in prompts to the LLM
* **Completion Tokens**: Tokens generated in LLM responses
* **Requests**: Number of API calls made
* **Execution Time**: Total duration of the crew run
* **Estimated Cost**: Approximate cost based on token usage

<Frame>
  ![Execution Summary](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/trace-summary.png)
</Frame>

### 2. Tasks & Agents

This section shows all tasks and agents that were part of the crew execution:

* Task name and agent assignment
* Agents and LLMs used for each task
* Status (completed/failed)
* Individual execution time of the task

<Frame>
  ![Task List](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/trace-tasks.png)
</Frame>

### 3. Final Output

Displays the final result produced by the crew after all tasks are completed.

<Frame>
  ![Final Output](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/final-output.png)
</Frame>

### 4. Execution Timeline

A visual representation of when each task started and ended, helping you identify bottlenecks or parallel execution patterns.

<Frame>
  ![Execution Timeline](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/trace-timeline.png)
</Frame>

### 5. Detailed Task View

When you click on a specific task in the timeline or task list, you'll see:

<Frame>
  ![Detailed Task View](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/trace-detailed-task.png)
</Frame>

* **Task Key**: Unique identifier for the task
* **Task ID**: Technical identifier in the system
* **Status**: Current state (completed/running/failed)
* **Agent**: Which agent performed the task
* **LLM**: Language model used for this task
* **Start/End Time**: When the task began and completed
* **Execution Time**: Duration of this specific task
* **Task Description**: What the agent was instructed to do
* **Expected Output**: What output format was requested
* **Input**: Any input provided to this task from previous tasks
* **Output**: The actual result produced by the agent

## Using Traces for Debugging

Traces are invaluable for troubleshooting issues with your crews:

<Steps>
  <Step title="Identify Failure Points">
    When a crew execution doesn't produce the expected results, examine the trace to find where things went wrong. Look for:

    * Failed tasks
    * Unexpected agent decisions
    * Tool usage errors
    * Misinterpreted instructions

    <Frame>
      ![Failure Points](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/failure.png)
    </Frame>
  </Step>

  <Step title="Optimize Performance">
    Use execution metrics to identify performance bottlenecks:

    * Tasks that took longer than expected
    * Excessive token usage
    * Redundant tool operations
    * Unnecessary API calls
  </Step>

  <Step title="Improve Cost Efficiency">
    Analyze token usage and cost estimates to optimize your crew's efficiency:

    * Consider using smaller models for simpler tasks
    * Refine prompts to be more concise
    * Cache frequently accessed information
    * Structure tasks to minimize redundant operations
  </Step>
</Steps>

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with trace analysis or any other CrewAI Enterprise features.
</Card>


# Webhook Streaming
Source: https://docs.crewai.com/en/enterprise/features/webhook-streaming

Using Webhook Streaming to stream events to your webhook

## Overview

Enterprise Event Streaming lets you receive real-time webhook updates about your crews and flows deployed to
CrewAI Enterprise, such as model calls, tool usage, and flow steps.

## Usage

When using the Kickoff API, include a `webhooks` object to your request, for example:

```json
{
  "inputs": {"foo": "bar"},
  "webhooks": {
    "events": ["crew_kickoff_started", "llm_call_started"],
    "url": "https://your.endpoint/webhook",
    "realtime": false,
    "authentication": {
      "strategy": "bearer",
      "token": "my-secret-token"
    }
  }
}
```

If `realtime` is set to `true`, each event is delivered individually and immediately, at the cost of crew/flow performance.

## Webhook Format

Each webhook sends a list of events:

```json
{
  "events": [
    {
      "id": "event-id",
      "execution_id": "crew-run-id",
      "timestamp": "2025-02-16T10:58:44.965Z",
      "type": "llm_call_started",
      "data": {
        "model": "gpt-4",
        "messages": [
          {"role": "system", "content": "You are an assistant."},
          {"role": "user", "content": "Summarize this article."}
        ]
      }
    }
  ]
}
```

The `data` object structure varies by event type. Refer to the [event list](https://github.com/crewAIInc/crewAI/tree/main/src/crewai/utilities/events) on GitHub.

As requests are sent over HTTP, the order of events can't be guaranteed. If you need ordering, use the `timestamp` field.

## Supported Events

CrewAI supports both system events and custom events in Enterprise Event Streaming. These events are sent to your configured webhook endpoint during crew and flow execution.

* `crew_kickoff_started`
* `crew_step_started`
* `crew_step_completed`
* `crew_execution_completed`
* `llm_call_started`
* `llm_call_completed`
* `tool_usage_started`
* `tool_usage_completed`
* `crew_test_failed`
* *...and others*

Event names match the internal event bus. See [GitHub source](https://github.com/crewAIInc/crewAI/tree/main/src/crewai/utilities/events) for the full list.

You can emit your own custom events, and they will be delivered through the webhook stream alongside system events.

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with webhook integration or troubleshooting.
</Card>


# Azure OpenAI Setup
Source: https://docs.crewai.com/en/enterprise/guides/azure-openai-setup

Configure Azure OpenAI with Crew Studio for enterprise LLM connections

This guide walks you through connecting Azure OpenAI with Crew Studio for seamless enterprise AI operations.

## Setup Process

<Steps>
  <Step title="Access Azure OpenAI Studio">
    1. In Azure, go to `Azure AI Services > select your deployment > open Azure OpenAI Studio`.
    2. On the left menu, click `Deployments`. If you don't have one, create a deployment with your desired model.
    3. Once created, select your deployment and locate the `Target URI` and `Key` on the right side of the page. Keep this page open, as you'll need this information.
       <Frame>
         <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/azure-openai-studio.png" alt="Azure OpenAI Studio" />
       </Frame>
  </Step>

  <Step title="Configure CrewAI Enterprise Connection">
    4. In another tab, open `CrewAI Enterprise > LLM Connections`. Name your LLM Connection, select Azure as the provider, and choose the same model you selected in Azure.
    5. On the same page, add environment variables from step 3:
       * One named `AZURE_DEPLOYMENT_TARGET_URL` (using the Target URI). The URL should look like this: [https://your-deployment.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-08-01-preview](https://your-deployment.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-08-01-preview)
       * Another named `AZURE_API_KEY` (using the Key).
    6. Click `Add Connection` to save your LLM Connection.
  </Step>

  <Step title="Set Default Configuration">
    7. In `CrewAI Enterprise > Settings > Defaults > Crew Studio LLM Settings`, set the new LLM Connection and model as defaults.
  </Step>

  <Step title="Configure Network Access">
    8. Ensure network access settings:
       * In Azure, go to `Azure OpenAI > select your deployment`.
       * Navigate to `Resource Management > Networking`.
       * Ensure that `Allow access from all networks` is enabled. If this setting is restricted, CrewAI may be blocked from accessing your Azure OpenAI endpoint.
  </Step>
</Steps>

## Verification

You're all set! Crew Studio will now use your Azure OpenAI connection. Test the connection by creating a simple crew or task to ensure everything is working properly.

## Troubleshooting

If you encounter issues:

* Verify the Target URI format matches the expected pattern
* Check that the API key is correct and has proper permissions
* Ensure network access is configured to allow CrewAI connections
* Confirm the deployment model matches what you've configured in CrewAI


# Build Crew
Source: https://docs.crewai.com/en/enterprise/guides/build-crew

A Crew is a group of agents that work together to complete a task.

## Overview

[CrewAI Enterprise](https://app.crewai.com) streamlines the process of **creating**, **deploying**, and **managing** your AI agents in production environments.

## Getting Started

<iframe width="100%" height="400" src="https://www.youtube.com/embed/-kSOTtYzgEw" title="Building Crews with CrewAI CLI" frameborder="0" style={{ borderRadius: '10px' }} allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

### Installation and Setup

<Card title="Follow Standard Installation" icon="wrench" href="/en/installation">
  Follow our standard installation guide to set up CrewAI CLI and create your first project.
</Card>

### Building Your Crew

<Card title="Quickstart Tutorial" icon="rocket" href="/en/quickstart">
  Follow our quickstart guide to create your first agent crew using YAML configuration.
</Card>

## Support and Resources

For Enterprise-specific support or questions, contact our dedicated support team at [support@crewai.com](mailto:support@crewai.com).

<Card title="Schedule a Demo" icon="calendar" href="mailto:support@crewai.com">
  Book time with our team to learn more about Enterprise features and how they can benefit your organization.
</Card>


# Deploy Crew
Source: https://docs.crewai.com/en/enterprise/guides/deploy-crew

Deploying a Crew on CrewAI Enterprise

<Note>
  After creating a crew locally or through Crew Studio, the next step is deploying it to the CrewAI Enterprise platform. This guide covers multiple deployment methods to help you choose the best approach for your workflow.
</Note>

## Prerequisites

<CardGroup cols={2}>
  <Card title="Crew Ready for Deployment" icon="users">
    You should have a working crew either built locally or created through Crew Studio
  </Card>

  <Card title="GitHub Repository" icon="github">
    Your crew code should be in a GitHub repository (for GitHub integration method)
  </Card>
</CardGroup>

## Option 1: Deploy Using CrewAI CLI

The CLI provides the fastest way to deploy locally developed crews to the Enterprise platform.

<Steps>
  <Step title="Install CrewAI CLI">
    If you haven't already, install the CrewAI CLI:

    ```bash
    pip install crewai[tools]
    ```

    <Tip>
      The CLI comes with the main CrewAI package, but the `[tools]` extra ensures you have all deployment dependencies.
    </Tip>
  </Step>

  <Step title="Authenticate with the Enterprise Platform">
    First, you need to authenticate your CLI with the CrewAI Enterprise platform:

    ```bash
    # If you already have a CrewAI Enterprise account, or want to create one:
    crewai login
    ```

    When you run either command, the CLI will:

    1. Display a URL and a unique device code
    2. Open your browser to the authentication page
    3. Prompt you to confirm the device
    4. Complete the authentication process

    Upon successful authentication, you'll see a confirmation message in your terminal!
  </Step>

  <Step title="Create a Deployment">
    From your project directory, run:

    ```bash
    crewai deploy create
    ```

    This command will:

    1. Detect your GitHub repository information
    2. Identify environment variables in your local `.env` file
    3. Securely transfer these variables to the Enterprise platform
    4. Create a new deployment with a unique identifier

    On successful creation, you'll see a message like:

    ```shell
    Deployment created successfully!
    Name: your_project_name
    Deployment ID: 01234567-89ab-cdef-0123-456789abcdef
    Current Status: Deploy Enqueued
    ```
  </Step>

  <Step title="Monitor Deployment Progress">
    Track the deployment status with:

    ```bash
    crewai deploy status
    ```

    For detailed logs of the build process:

    ```bash
    crewai deploy logs
    ```

    <Tip>
      The first deployment typically takes 10-15 minutes as it builds the container images. Subsequent deployments are much faster.
    </Tip>
  </Step>
</Steps>

## Additional CLI Commands

The CrewAI CLI offers several commands to manage your deployments:

```bash
# List all your deployments
crewai deploy list

# Get the status of your deployment
crewai deploy status

# View the logs of your deployment
crewai deploy logs

# Push updates after code changes
crewai deploy push

# Remove a deployment
crewai deploy remove <deployment_id>
```

## Option 2: Deploy Directly via Web Interface

You can also deploy your crews directly through the CrewAI Enterprise web interface by connecting your GitHub account. This approach doesn't require using the CLI on your local machine.

<Steps>
  <Step title="Pushing to GitHub">
    You need to push your crew to a GitHub repository. If you haven't created a crew yet, you can [follow this tutorial](/en/quickstart).
  </Step>

  <Step title="Connecting GitHub to CrewAI Enterprise">
    1. Log in to [CrewAI Enterprise](https://app.crewai.com)
    2. Click on the button "Connect GitHub"

    <Frame>
      ![Connect GitHub Button](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/connect-github.png)
    </Frame>
  </Step>

  <Step title="Select the Repository">
    After connecting your GitHub account, you'll be able to select which repository to deploy:

    <Frame>
      ![Select Repository](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/select-repo.png)
    </Frame>
  </Step>

  <Step title="Set Environment Variables">
    Before deploying, you'll need to set up your environment variables to connect to your LLM provider or other services:

    1. You can add variables individually or in bulk
    2. Enter your environment variables in `KEY=VALUE` format (one per line)

    <Frame>
      ![Set Environment Variables](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/set-env-variables.png)
    </Frame>
  </Step>

  <Step title="Deploy Your Crew">
    1. Click the "Deploy" button to start the deployment process
    2. You can monitor the progress through the progress bar
    3. The first deployment typically takes around 10-15 minutes; subsequent deployments will be faster

    <Frame>
      ![Deploy Progress](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/deploy-progress.png)
    </Frame>

    Once deployment is complete, you'll see:

    * Your crew's unique URL
    * A Bearer token to protect your crew API
    * A "Delete" button if you need to remove the deployment
  </Step>
</Steps>

## ‚ö†Ô∏è Environment Variable Security Requirements

<Warning>
  **Important**: CrewAI Enterprise has security restrictions on environment variable names that can cause deployment failures if not followed.
</Warning>

### Blocked Environment Variable Patterns

For security reasons, the following environment variable naming patterns are **automatically filtered** and will cause deployment issues:

**Blocked Patterns:**

* Variables ending with `_TOKEN` (e.g., `MY_API_TOKEN`)
* Variables ending with `_PASSWORD` (e.g., `DB_PASSWORD`)
* Variables ending with `_SECRET` (e.g., `API_SECRET`)
* Variables ending with `_KEY` in certain contexts

**Specific Blocked Variables:**

* `GITHUB_USER`, `GITHUB_TOKEN`
* `AWS_REGION`, `AWS_DEFAULT_REGION`
* Various internal CrewAI system variables

### Allowed Exceptions

Some variables are explicitly allowed despite matching blocked patterns:

* `AZURE_AD_TOKEN`
* `AZURE_OPENAI_AD_TOKEN`
* `ENTERPRISE_ACTION_TOKEN`
* `CREWAI_ENTEPRISE_TOOLS_TOKEN`

### How to Fix Naming Issues

If your deployment fails due to environment variable restrictions:

```bash
# ‚ùå These will cause deployment failures
OPENAI_TOKEN=sk-...
DATABASE_PASSWORD=mypassword
API_SECRET=secret123

# ‚úÖ Use these naming patterns instead
OPENAI_API_KEY=sk-...
DATABASE_CREDENTIALS=mypassword
API_CONFIG=secret123
```

### Best Practices

1. **Use standard naming conventions**: `PROVIDER_API_KEY` instead of `PROVIDER_TOKEN`
2. **Test locally first**: Ensure your crew works with the renamed variables
3. **Update your code**: Change any references to the old variable names
4. **Document changes**: Keep track of renamed variables for your team

<Tip>
  If you encounter deployment failures with cryptic environment variable errors, check your variable names against these patterns first.
</Tip>

### Interact with Your Deployed Crew

Once deployment is complete, you can access your crew through:

1. **REST API**: The platform generates a unique HTTPS endpoint with these key routes:
   * `/inputs`: Lists the required input parameters
   * `/kickoff`: Initiates an execution with provided inputs
   * `/status/{kickoff_id}`: Checks the execution status

2. **Web Interface**: Visit [app.crewai.com](https://app.crewai.com) to access:
   * **Status tab**: View deployment information, API endpoint details, and authentication token
   * **Run tab**: Visual representation of your crew's structure
   * **Executions tab**: History of all executions
   * **Metrics tab**: Performance analytics
   * **Traces tab**: Detailed execution insights

### Trigger an Execution

From the Enterprise dashboard, you can:

1. Click on your crew's name to open its details
2. Select "Trigger Crew" from the management interface
3. Enter the required inputs in the modal that appears
4. Monitor progress as the execution moves through the pipeline

### Monitoring and Analytics

The Enterprise platform provides comprehensive observability features:

* **Execution Management**: Track active and completed runs
* **Traces**: Detailed breakdowns of each execution
* **Metrics**: Token usage, execution times, and costs
* **Timeline View**: Visual representation of task sequences

### Advanced Features

The Enterprise platform also offers:

* **Environment Variables Management**: Securely store and manage API keys
* **LLM Connections**: Configure integrations with various LLM providers
* **Custom Tools Repository**: Create, share, and install tools
* **Crew Studio**: Build crews through a chat interface without writing code

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with deployment issues or questions about the Enterprise platform.
</Card>


# Enable Crew Studio
Source: https://docs.crewai.com/en/enterprise/guides/enable-crew-studio

Enabling Crew Studio on CrewAI Enterprise

<Tip>
  Crew Studio is a powerful **no-code/low-code** tool that allows you to quickly scaffold or build Crews through a conversational interface.
</Tip>

## What is Crew Studio?

Crew Studio is an innovative way to create AI agent crews without writing code.

<Frame>
  ![Crew Studio Interface](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-studio-interface.png)
</Frame>

With Crew Studio, you can:

* Chat with the Crew Assistant to describe your problem
* Automatically generate agents and tasks
* Select appropriate tools
* Configure necessary inputs
* Generate downloadable code for customization
* Deploy directly to the CrewAI Enterprise platform

## Configuration Steps

Before you can start using Crew Studio, you need to configure your LLM connections:

<Steps>
  <Step title="Set Up LLM Connection">
    Go to the **LLM Connections** tab in your CrewAI Enterprise dashboard and create a new LLM connection.

    <Note>
      Feel free to use any LLM provider you want that is supported by CrewAI.
    </Note>

    Configure your LLM connection:

    * Enter a `Connection Name` (e.g., `OpenAI`)
    * Select your model provider: `openai` or `azure`
    * Select models you'd like to use in your Studio-generated Crews
      * We recommend at least `gpt-4o`, `o1-mini`, and `gpt-4o-mini`
    * Add your API key as an environment variable:
      * For OpenAI: Add `OPENAI_API_KEY` with your API key
      * For Azure OpenAI: Refer to [this article](https://blog.crewai.com/configuring-azure-openai-with-crewai-a-comprehensive-guide/) for configuration details
    * Click `Add Connection` to save your configuration

    <Frame>
      ![LLM Connection Configuration](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/llm-connection-config.png)
    </Frame>
  </Step>

  <Step title="Verify Connection Added">
    Once you complete the setup, you'll see your new connection added to the list of available connections.

    <Frame>
      ![Connection Added](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/connection-added.png)
    </Frame>
  </Step>

  <Step title="Configure LLM Defaults">
    In the main menu, go to **Settings ‚Üí Defaults** and configure the LLM Defaults settings:

    * Select default models for agents and other components
    * Set default configurations for Crew Studio

    Click `Save Settings` to apply your changes.

    <Frame>
      ![LLM Defaults Configuration](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/llm-defaults.png)
    </Frame>
  </Step>
</Steps>

## Using Crew Studio

Now that you've configured your LLM connection and default settings, you're ready to start using Crew Studio!

<Steps>
  <Step title="Access Studio">
    Navigate to the **Studio** section in your CrewAI Enterprise dashboard.
  </Step>

  <Step title="Start a Conversation">
    Start a conversation with the Crew Assistant by describing the problem you want to solve:

    ```md
    I need a crew that can research the latest AI developments and create a summary report.
    ```

    The Crew Assistant will ask clarifying questions to better understand your requirements.
  </Step>

  <Step title="Review Generated Crew">
    Review the generated crew configuration, including:

    * Agents and their roles
    * Tasks to be performed
    * Required inputs
    * Tools to be used

    This is your opportunity to refine the configuration before proceeding.
  </Step>

  <Step title="Deploy or Download">
    Once you're satisfied with the configuration, you can:

    * Download the generated code for local customization
    * Deploy the crew directly to the CrewAI Enterprise platform
    * Modify the configuration and regenerate the crew
  </Step>

  <Step title="Test Your Crew">
    After deployment, test your crew with sample inputs to ensure it performs as expected.
  </Step>
</Steps>

<Tip>
  For best results, provide clear, detailed descriptions of what you want your crew to accomplish. Include specific inputs and expected outputs in your description.
</Tip>

## Example Workflow

Here's a typical workflow for creating a crew with Crew Studio:

<Steps>
  <Step title="Describe Your Problem">
    Start by describing your problem:

    ```md
    I need a crew that can analyze financial news and provide investment recommendations
    ```
  </Step>

  <Step title="Answer Questions">
    Respond to clarifying questions from the Crew Assistant to refine your requirements.
  </Step>

  <Step title="Review the Plan">
    Review the generated crew plan, which might include:

    * A Research Agent to gather financial news
    * An Analysis Agent to interpret the data
    * A Recommendations Agent to provide investment advice
  </Step>

  <Step title="Approve or Modify">
    Approve the plan or request changes if necessary.
  </Step>

  <Step title="Download or Deploy">
    Download the code for customization or deploy directly to the platform.
  </Step>

  <Step title="Test and Refine">
    Test your crew with sample inputs and refine as needed.
  </Step>
</Steps>

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with Crew Studio or any other CrewAI Enterprise features.
</Card>


# HubSpot Trigger
Source: https://docs.crewai.com/en/enterprise/guides/hubspot-trigger

Trigger CrewAI crews directly from HubSpot Workflows

This guide provides a step-by-step process to set up HubSpot triggers for CrewAI Enterprise, enabling you to initiate crews directly from HubSpot Workflows.

## Prerequisites

* A CrewAI Enterprise account
* A HubSpot account with the [HubSpot Workflows](https://knowledge.hubspot.com/workflows/create-workflows) feature

## Setup Steps

<Steps>
  <Step title="Connect your HubSpot account with CrewAI Enterprise">
    * Log in to your `CrewAI Enterprise account > Triggers`
    * Select `HubSpot` from the list of available triggers
    * Choose the HubSpot account you want to connect with CrewAI Enterprise
    * Follow the on-screen prompts to authorize CrewAI Enterprise access to your HubSpot account
    * A confirmation message will appear once HubSpot is successfully connected with CrewAI Enterprise
  </Step>

  <Step title="Create a HubSpot Workflow">
    * Log in to your `HubSpot account > Automations > Workflows > New workflow`
    * Select the workflow type that fits your needs (e.g., Start from scratch)
    * In the workflow builder, click the Plus (+) icon to add a new action.
    * Choose `Integrated apps > CrewAI > Kickoff a Crew`.
    * Select the Crew you want to initiate.
    * Click `Save` to add the action to your workflow

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/hubspot-workflow-1.png" alt="HubSpot Workflow 1" />
    </Frame>
  </Step>

  <Step title="Use Crew results with other actions">
    * After the Kickoff a Crew step, click the Plus (+) icon to add a new action.
    * For example, to send an internal email notification, choose `Communications > Send internal email notification`
    * In the Body field, click `Insert data`, select `View properties or action outputs from > Action outputs > Crew Result` to include Crew data in the email
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/hubspot-workflow-2.png" alt="HubSpot Workflow 2" />
      </Frame>
    * Configure any additional actions as needed
    * Review your workflow steps to ensure everything is set up correctly
    * Activate the workflow
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/hubspot-workflow-3.png" alt="HubSpot Workflow 3" />
      </Frame>
  </Step>
</Steps>

## Additional Resources

For more detailed information on available actions and customization options, refer to the [HubSpot Workflows Documentation](https://knowledge.hubspot.com/workflows/create-workflows).


# HITL Workflows
Source: https://docs.crewai.com/en/enterprise/guides/human-in-the-loop

Learn how to implement Human-In-The-Loop workflows in CrewAI for enhanced decision-making

Human-In-The-Loop (HITL) is a powerful approach that combines artificial intelligence with human expertise to enhance decision-making and improve task outcomes. This guide shows you how to implement HITL within CrewAI.

## Setting Up HITL Workflows

<Steps>
  <Step title="Configure Your Task">
    Set up your task with human input enabled:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-human-input.png" alt="Crew Human Input" />
    </Frame>
  </Step>

  <Step title="Provide Webhook URL">
    When kicking off your crew, include a webhook URL for human input:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-webhook-url.png" alt="Crew Webhook URL" />
    </Frame>
  </Step>

  <Step title="Receive Webhook Notification">
    Once the crew completes the task requiring human input, you'll receive a webhook notification containing:

    * **Execution ID**
    * **Task ID**
    * **Task output**
  </Step>

  <Step title="Review Task Output">
    The system will pause in the `Pending Human Input` state. Review the task output carefully.
  </Step>

  <Step title="Submit Human Feedback">
    Call the resume endpoint of your crew with the following information:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-resume-endpoint.png" alt="Crew Resume Endpoint" />
    </Frame>

    <Warning>
      **Feedback Impact on Task Execution**:
      It's crucial to exercise care when providing feedback, as the entire feedback content will be incorporated as additional context for further task executions.
    </Warning>

    This means:

    * All information in your feedback becomes part of the task's context.
    * Irrelevant details may negatively influence it.
    * Concise, relevant feedback helps maintain task focus and efficiency.
    * Always review your feedback carefully before submission to ensure it contains only pertinent information that will positively guide the task's execution.
  </Step>

  <Step title="Handle Negative Feedback">
    If you provide negative feedback:

    * The crew will retry the task with added context from your feedback.
    * You'll receive another webhook notification for further review.
    * Repeat steps 4-6 until satisfied.
  </Step>

  <Step title="Execution Continuation">
    When you submit positive feedback, the execution will proceed to the next steps.
  </Step>
</Steps>

## Best Practices

* **Be Specific**: Provide clear, actionable feedback that directly addresses the task at hand
* **Stay Relevant**: Only include information that will help improve the task execution
* **Be Timely**: Respond to HITL prompts promptly to avoid workflow delays
* **Review Carefully**: Double-check your feedback before submitting to ensure accuracy

## Common Use Cases

HITL workflows are particularly valuable for:

* Quality assurance and validation
* Complex decision-making scenarios
* Sensitive or high-stakes operations
* Creative tasks requiring human judgment
* Compliance and regulatory reviews


# Kickoff Crew
Source: https://docs.crewai.com/en/enterprise/guides/kickoff-crew

Kickoff a Crew on CrewAI Enterprise

## Overview

Once you've deployed your crew to the CrewAI Enterprise platform, you can kickoff executions through the web interface or the API. This guide covers both approaches.

## Method 1: Using the Web Interface

### Step 1: Navigate to Your Deployed Crew

1. Log in to [CrewAI Enterprise](https://app.crewai.com)
2. Click on the crew name from your projects list
3. You'll be taken to the crew's detail page

<Frame>
  ![Crew Dashboard](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-dashboard.png)
</Frame>

### Step 2: Initiate Execution

From your crew's detail page, you have two options to kickoff an execution:

#### Option A: Quick Kickoff

1. Click the `Kickoff` link in the Test Endpoints section
2. Enter the required input parameters for your crew in the JSON editor
3. Click the `Send Request` button

<Frame>
  ![Kickoff Endpoint](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-endpoint.png)
</Frame>

#### Option B: Using the Visual Interface

1. Click the `Run` tab in the crew detail page
2. Enter the required inputs in the form fields
3. Click the `Run Crew` button

<Frame>
  ![Run Crew](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/run-crew.png)
</Frame>

### Step 3: Monitor Execution Progress

After initiating the execution:

1. You'll receive a response containing a `kickoff_id` - **copy this ID**
2. This ID is essential for tracking your execution

<Frame>
  ![Copy Task ID](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/copy-task-id.png)
</Frame>

### Step 4: Check Execution Status

To monitor the progress of your execution:

1. Click the "Status" endpoint in the Test Endpoints section
2. Paste the `kickoff_id` into the designated field
3. Click the "Get Status" button

<Frame>
  ![Get Status](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/get-status.png)
</Frame>

The status response will show:

* Current execution state (`running`, `completed`, etc.)
* Details about which tasks are in progress
* Any outputs produced so far

### Step 5: View Final Results

Once execution is complete:

1. The status will change to `completed`
2. You can view the full execution results and outputs
3. For a more detailed view, check the `Executions` tab in the crew detail page

## Method 2: Using the API

You can also kickoff crews programmatically using the CrewAI Enterprise REST API.

### Authentication

All API requests require a bearer token for authentication:

```bash
curl -H "Authorization: Bearer YOUR_CREW_TOKEN" https://your-crew-url.crewai.com
```

Your bearer token is available on the Status tab of your crew's detail page.

### Checking Crew Health

Before executing operations, you can verify that your crew is running properly:

```bash
curl -H "Authorization: Bearer YOUR_CREW_TOKEN" https://your-crew-url.crewai.com
```

A successful response will return a message indicating the crew is operational:

```
Healthy%
```

### Step 1: Retrieve Required Inputs

First, determine what inputs your crew requires:

```bash
curl -X GET \
  -H "Authorization: Bearer YOUR_CREW_TOKEN" \
  https://your-crew-url.crewai.com/inputs
```

The response will be a JSON object containing an array of required input parameters, for example:

```json
{"inputs":["topic","current_year"]}
```

This example shows that this particular crew requires two inputs: `topic` and `current_year`.

### Step 2: Kickoff Execution

Initiate execution by providing the required inputs:

```bash
curl -X POST \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_CREW_TOKEN" \
  -d '{"inputs": {"topic": "AI Agent Frameworks", "current_year": "2025"}}' \
  https://your-crew-url.crewai.com/kickoff
```

The response will include a `kickoff_id` that you'll need for tracking:

```json
{"kickoff_id":"abcd1234-5678-90ef-ghij-klmnopqrstuv"}
```

### Step 3: Check Execution Status

Monitor the execution progress using the kickoff\_id:

```bash
curl -X GET \
  -H "Authorization: Bearer YOUR_CREW_TOKEN" \
  https://your-crew-url.crewai.com/status/abcd1234-5678-90ef-ghij-klmnopqrstuv
```

## Handling Executions

### Long-Running Executions

For executions that may take a long time:

1. Consider implementing a polling mechanism to check status periodically
2. Use webhooks (if available) for notification when execution completes
3. Implement error handling for potential timeouts

### Execution Context

The execution context includes:

* Inputs provided at kickoff
* Environment variables configured during deployment
* Any state maintained between tasks

### Debugging Failed Executions

If an execution fails:

1. Check the "Executions" tab for detailed logs
2. Review the "Traces" tab for step-by-step execution details
3. Look for LLM responses and tool usage in the trace details

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with execution issues or questions about the Enterprise platform.
</Card>


# React Component Export
Source: https://docs.crewai.com/en/enterprise/guides/react-component-export

Learn how to export and integrate CrewAI Enterprise React components into your applications

This guide explains how to export CrewAI Enterprise crews as React components and integrate them into your own applications.

## Exporting a React Component

<Steps>
  <Step title="Export the Component">
    Click on the ellipsis (three dots on the right of your deployed crew) and select the export option and save the file locally. We will be using `CrewLead.jsx` for our example.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/export-react-component.png" alt="Export React Component" />
    </Frame>
  </Step>
</Steps>

## Setting Up Your React Environment

To run this React component locally, you'll need to set up a React development environment and integrate this component into a React project.

<Steps>
  <Step title="Install Node.js">
    * Download and install Node.js from the official website: [https://nodejs.org/](https://nodejs.org/)
    * Choose the LTS (Long Term Support) version for stability.
  </Step>

  <Step title="Create a new React project">
    * Open Command Prompt or PowerShell
    * Navigate to the directory where you want to create your project
    * Run the following command to create a new React project:

      ```bash
      npx create-react-app my-crew-app
      ```
    * Change into the project directory:

      ```bash
      cd my-crew-app
      ```
  </Step>

  <Step title="Install necessary dependencies">
    ```bash
    npm install react-dom
    ```
  </Step>

  <Step title="Create the CrewLead component">
    * Move the downloaded file `CrewLead.jsx` into the `src` folder of your project,
  </Step>

  <Step title="Modify your App.js to use the CrewLead component">
    * Open `src/App.js`
    * Replace its contents with something like this:

    ```jsx
    import React from 'react';
    import CrewLead from './CrewLead';

    function App() {
        return (
            <div className="App">
                <CrewLead baseUrl="YOUR_API_BASE_URL" bearerToken="YOUR_BEARER_TOKEN" />
            </div>
        );
    }

    export default App;
    ```

    * Replace `YOUR_API_BASE_URL` and `YOUR_BEARER_TOKEN` with the actual values for your API.
  </Step>

  <Step title="Start the development server">
    * In your project directory, run:

      ```bash
      npm start
      ```
    * This will start the development server, and your default web browser should open automatically to [http://localhost:3000](http://localhost:3000), where you'll see your React app running.
  </Step>
</Steps>

## Customization

You can then customise the `CrewLead.jsx` to add color, title etc

<Frame>
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/customise-react-component.png" alt="Customise React Component" />
</Frame>

<Frame>
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/customise-react-component-2.png" alt="Customise React Component" />
</Frame>

## Next Steps

* Customize the component styling to match your application's design
* Add additional props for configuration
* Integrate with your application's state management
* Add error handling and loading states


# Salesforce Trigger
Source: https://docs.crewai.com/en/enterprise/guides/salesforce-trigger

Trigger CrewAI crews from Salesforce workflows for CRM automation

CrewAI Enterprise can be triggered from Salesforce to automate customer relationship management workflows and enhance your sales operations.

## Overview

Salesforce is a leading customer relationship management (CRM) platform that helps businesses streamline their sales, service, and marketing operations. By setting up CrewAI triggers from Salesforce, you can:

* Automate lead scoring and qualification
* Generate personalized sales materials
* Enhance customer service with AI-powered responses
* Streamline data analysis and reporting

## Demo

<Frame>
  <iframe width="100%" height="400" src="https://www.youtube.com/embed/oJunVqjjfu4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />
</Frame>

## Getting Started

To set up Salesforce triggers:

1. **Contact Support**: Reach out to CrewAI Enterprise support for assistance with Salesforce trigger setup
2. **Review Requirements**: Ensure you have the necessary Salesforce permissions and API access
3. **Configure Connection**: Work with the support team to establish the connection between CrewAI and your Salesforce instance
4. **Test Triggers**: Verify the triggers work correctly with your specific use cases

## Use Cases

Common Salesforce + CrewAI trigger scenarios include:

* **Lead Processing**: Automatically analyze and score incoming leads
* **Proposal Generation**: Create customized proposals based on opportunity data
* **Customer Insights**: Generate analysis reports from customer interaction history
* **Follow-up Automation**: Create personalized follow-up messages and recommendations

## Next Steps

For detailed setup instructions and advanced configuration options, please contact CrewAI Enterprise support who can provide tailored guidance for your specific Salesforce environment and business needs.


# Slack Trigger
Source: https://docs.crewai.com/en/enterprise/guides/slack-trigger

Trigger CrewAI crews directly from Slack using slash commands

This guide explains how to start a crew directly from Slack using CrewAI triggers.

## Prerequisites

* CrewAI Slack trigger installed and connected to your Slack workspace
* At least one crew configured in CrewAI

## Setup Steps

<Steps>
  <Step title="Ensure the CrewAI Slack trigger is set up">
    In the CrewAI dashboard, navigate to the **Triggers** section.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/slack-integration.png" alt="CrewAI Slack Integration" />
    </Frame>

    Verify that Slack is listed and is connected.
  </Step>

  <Step title="Open your Slack channel">
    * Navigate to the channel where you want to kickoff the crew.
    * Type the slash command "**/kickoff**" to initiate the crew kickoff process.
    * You should see a  "**Kickoff crew**" appear as you type:
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-slack-crew.png" alt="Kickoff crew" />
      </Frame>
    * Press Enter or select the "**Kickoff crew**" option. A dialog box titled "**Kickoff an AI Crew**" will appear.
  </Step>

  <Step title="Select the crew you want to start">
    * In the dropdown menu labeled "**Select of the crews online:**", choose the crew you want to start.
    * In the example below, "**prep-for-meeting**" is selected:
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-slack-crew-dropdown.png" alt="Kickoff crew dropdown" />
      </Frame>
    * If your crew requires any inputs, click the "**Add Inputs**" button to provide them.
      <Note>
        The "**Add Inputs**" button is shown in the example above but is not yet clicked.
      </Note>
  </Step>

  <Step title="Click Kickoff and wait for the crew to complete">
    * Once you've selected the crew and added any necessary inputs, click "**Kickoff**" to start the crew.
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-slack-crew-kickoff.png" alt="Kickoff crew" />
      </Frame>
    * The crew will start executing and you will see the results in the Slack channel.
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-slack-crew-results.png" alt="Kickoff crew results" />
      </Frame>
  </Step>
</Steps>

## Tips

* Make sure you have the necessary permissions to use the `/kickoff` command in your Slack workspace.
* If you don't see your desired crew in the dropdown, ensure it's properly configured and online in CrewAI.


# Team Management
Source: https://docs.crewai.com/en/enterprise/guides/team-management

Learn how to invite and manage team members in your CrewAI Enterprise organization

As an administrator of a CrewAI Enterprise account, you can easily invite new team members to join your organization. This guide will walk you through the process step-by-step.

## Inviting Team Members

<Steps>
  <Step title="Access the Settings Page">
    * Log in to your CrewAI Enterprise account
    * Look for the gear icon (‚öôÔ∏è) in the top right corner of the dashboard
    * Click on the gear icon to access the **Settings** page:
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/settings-page.png" alt="Settings Page" />
      </Frame>
  </Step>

  <Step title="Navigate to the Members Section">
    * On the Settings page, you'll see a `Members` tab
    * Click on the `Members` tab to access the **Members** page:
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/members-tab.png" alt="Members Tab" />
      </Frame>
  </Step>

  <Step title="Invite New Members">
    * In the Members section, you'll see a list of current members (including yourself)
    * Locate the `Email` input field
    * Enter the email address of the person you want to invite
    * Click the `Invite` button to send the invitation
  </Step>

  <Step title="Repeat as Needed">
    * You can repeat this process to invite multiple team members
    * Each invited member will receive an email invitation to join your organization
  </Step>
</Steps>

## Adding Roles

You can add roles to your team members to control their access to different parts of the platform.

<Steps>
  <Step title="Access the Settings Page">
    * Log in to your CrewAI Enterprise account
    * Look for the gear icon (‚öôÔ∏è) in the top right corner of the dashboard
    * Click on the gear icon to access the **Settings** page:
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/settings-page.png" alt="Settings Page" />
      </Frame>
  </Step>

  <Step title="Navigate to the Members Section">
    * On the Settings page, you'll see a `Roles` tab
    * Click on the `Roles` tab to access the **Roles** page.
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/roles-tab.png" alt="Roles Tab" />
      </Frame>
    * Click on the `Add Role` button to add a new role.
    * Enter the details and permissions of the role and click the `Create Role` button to create the role.
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/add-role-modal.png" alt="Add Role Modal" />
      </Frame>
  </Step>

  <Step title="Add Roles to Members">
    * In the Members section, you'll see a list of current members (including yourself)
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/member-accepted-invitation.png" alt="Member Accepted Invitation" />
      </Frame>
    * Once the member has accepted the invitation, you can add a role to them.
    * Navigate back to `Roles` tab
    * Go to the member you want to add a role to and under the `Role` column, click on the dropdown
    * Select the role you want to add to the member
    * Click the `Update` button to save the role
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/assign-role.png" alt="Add Role to Member" />
      </Frame>
  </Step>
</Steps>

## Important Notes

* **Admin Privileges**: Only users with administrative privileges can invite new members
* **Email Accuracy**: Ensure you have the correct email addresses for your team members
* **Invitation Acceptance**: Invited members will need to accept the invitation to join your organization
* **Email Notifications**: You may want to inform your team members to check their email (including spam folders) for the invitation

By following these steps, you can easily expand your team and collaborate more effectively within your CrewAI Enterprise organization.


# Update Crew
Source: https://docs.crewai.com/en/enterprise/guides/update-crew

Updating a Crew on CrewAI Enterprise

<Note>
  After deploying your crew to CrewAI Enterprise, you may need to make updates to the code, security settings, or configuration.
  This guide explains how to perform these common update operations.
</Note>

## Why Update Your Crew?

CrewAI won't automatically pick up GitHub updates by default, so you'll need to manually trigger updates, unless you checked the `Auto-update` option when deploying your crew.

There are several reasons you might want to update your crew deployment:

* You want to update the code with a latest commit you pushed to GitHub
* You want to reset the bearer token for security reasons
* You want to update environment variables

## 1. Updating Your Crew Code for a Latest Commit

When you've pushed new commits to your GitHub repository and want to update your deployment:

1. Navigate to your crew in the CrewAI Enterprise platform
2. Click on the `Re-deploy` button on your crew details page

<Frame>
  ![Re-deploy Button](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/redeploy-button.png)
</Frame>

This will trigger an update that you can track using the progress bar. The system will pull the latest code from your repository and rebuild your deployment.

## 2. Resetting Bearer Token

If you need to generate a new bearer token (for example, if you suspect the current token might have been compromised):

1. Navigate to your crew in the CrewAI Enterprise platform
2. Find the `Bearer Token` section
3. Click the `Reset` button next to your current token

<Frame>
  ![Reset Token](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/reset-token.png)
</Frame>

<Warning>
  Resetting your bearer token will invalidate the previous token immediately. Make sure to update any applications or scripts that are using the old token.
</Warning>

## 3. Updating Environment Variables

To update the environment variables for your crew:

1. First access the deployment page by clicking on your crew's name

<Frame>
  ![Environment Variables Button](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/env-vars-button.png)
</Frame>

2. Locate the `Environment Variables` section (you will need to click the `Settings` icon to access it)
3. Edit the existing variables or add new ones in the fields provided
4. Click the `Update` button next to each variable you modify

<Frame>
  ![Update Environment Variables](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/update-env-vars.png)
</Frame>

5. Finally, click the `Update Deployment` button at the bottom of the page to apply the changes

<Note>
  Updating environment variables will trigger a new deployment, but this will only update the environment configuration and not the code itself.
</Note>

## After Updating

After performing any update:

1. The system will rebuild and redeploy your crew
2. You can monitor the deployment progress in real-time
3. Once complete, test your crew to ensure the changes are working as expected

<Tip>
  If you encounter any issues after updating, you can view deployment logs in the platform or contact support for assistance.
</Tip>

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with updating your crew or troubleshooting deployment issues.
</Card>


# Webhook Automation
Source: https://docs.crewai.com/en/enterprise/guides/webhook-automation

Automate CrewAI Enterprise workflows using webhooks with platforms like ActivePieces, Zapier, and Make.com

CrewAI Enterprise allows you to automate your workflow using webhooks. This article will guide you through the process of setting up and using webhooks to kickoff your crew execution, with a focus on integration with ActivePieces, a workflow automation platform similar to Zapier and Make.com.

## Setting Up Webhooks

<Steps>
  <Step title="Accessing the Kickoff Interface">
    * Navigate to the CrewAI Enterprise dashboard
    * Look for the `/kickoff` section, which is used to start the crew execution
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-interface.png" alt="Kickoff Interface" />
      </Frame>
  </Step>

  <Step title="Configuring the JSON Content">
    In the JSON Content section, you'll need to provide the following information:

    * **inputs**: A JSON object containing:
      * `company`: The name of the company (e.g., "tesla")
      * `product_name`: The name of the product (e.g., "crewai")
      * `form_response`: The type of response (e.g., "financial")
      * `icp_description`: A brief description of the Ideal Customer Profile
      * `product_description`: A short description of the product
      * `taskWebhookUrl`, `stepWebhookUrl`, `crewWebhookUrl`: URLs for various webhook endpoints (ActivePieces, Zapier, Make.com or another compatible platform)
  </Step>

  <Step title="Integrating with ActivePieces">
    In this example we will be using ActivePieces. You can use other platforms such as Zapier and Make.com

    To integrate with ActivePieces:

    1. Set up a new flow in ActivePieces

    2. Add a trigger (e.g., `Every Day` schedule)
       <Frame>
         <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-trigger.png" alt="ActivePieces Trigger" />
       </Frame>

    3. Add an HTTP action step
       * Set the action to `Send HTTP request`

       * Use `POST` as the method

       * Set the URL to your CrewAI Enterprise kickoff endpoint

       * Add necessary headers (e.g., `Bearer Token`)
         <Frame>
           <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-headers.png" alt="ActivePieces Headers" />
         </Frame>

       * In the body, include the JSON content as configured in step 2
         <Frame>
           <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-body.png" alt="ActivePieces Body" />
         </Frame>

       * The crew will then kickoff at the pre-defined time.
  </Step>

  <Step title="Setting Up the Webhook">
    1. Create a new flow in ActivePieces and name it
       <Frame>
         <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-flow.png" alt="ActivePieces Flow" />
       </Frame>

    2. Add a webhook step as the trigger:
       * Select `Catch Webhook` as the trigger type

       * This will generate a unique URL that will receive HTTP requests and trigger your flow
         <Frame>
           <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-webhook.png" alt="ActivePieces Webhook" />
         </Frame>

       * Configure the email to use crew webhook body text
         <Frame>
           <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-email.png" alt="ActivePieces Email" />
         </Frame>
  </Step>
</Steps>

## Webhook Output Examples

<Tabs>
  <Tab title="Step Webhook">
    `stepWebhookUrl` - Callback that will be executed upon each agent inner thought

    ```json
    {
        "action": "**Preliminary Research Report on the Financial Industry for crewai Enterprise Solution**\n1. Industry Overview and Trends\nThe financial industry in ....\nConclusion:\nThe financial industry presents a fertile ground for implementing AI solutions like crewai, particularly in areas such as digital customer engagement, risk management, and regulatory compliance. Further engagement with the lead is recommended to better tailor the crewai solution to their specific needs and scale.",
        "task_id": "97eba64f-958c-40a0-b61c-625fe635a3c0"
    }
    ```
  </Tab>

  <Tab title="Task Webhook">
    `taskWebhookUrl` - Callback that will be executed upon the end of each task

    ```json
    {
        "description": "Using the information gathered from the lead's data, conduct preliminary research on the lead's industry, company background, and potential use cases for crewai. Focus on finding relevant data that can aid in scoring the lead and planning a strategy to pitch them crewai.The financial industry presents a fertile ground for implementing AI solutions like crewai, particularly in areas such as digital customer engagement, risk management, and regulatory compliance. Further engagement with the lead is recommended to better tailor the crewai solution to their specific needs and scale.",
        "task_id": "97eba64f-958c-40a0-b61c-625fe635a3c0"
    }
    ```
  </Tab>

  <Tab title="Crew Webhook">
    `crewWebhookUrl` - Callback that will be executed upon the end of the crew execution

    ```json
    {
        "task_id": "97eba64f-958c-40a0-b61c-625fe635a3c0",
        "result": {
            "lead_score": "Customer service enhancement, and compliance are particularly relevant.",
            "talking_points": [
                "Highlight how crewai's AI solutions can transform customer service with automated, personalized experiences and 24/7 support, improving both customer satisfaction and operational efficiency.",
                "Discuss crewai's potential to help the institution achieve its sustainability goals through better data analysis and decision-making, contributing to responsible investing and green initiatives.",
                "Emphasize crewai's ability to enhance compliance with evolving regulations through efficient data processing and reporting, reducing the risk of non-compliance penalties.",
                "Stress the adaptability of crewai to support both extensive multinational operations and smaller, targeted projects, ensuring the solution grows with the institution's needs."
            ]
        }
    }
    ```
  </Tab>
</Tabs>


# Zapier Trigger
Source: https://docs.crewai.com/en/enterprise/guides/zapier-trigger

Trigger CrewAI crews from Zapier workflows to automate cross-app workflows

This guide will walk you through the process of setting up Zapier triggers for CrewAI Enterprise, allowing you to automate workflows between CrewAI Enterprise and other applications.

## Prerequisites

* A CrewAI Enterprise account
* A Zapier account
* A Slack account (for this specific example)

## Step-by-Step Setup

<Steps>
  <Step title="Set Up the Slack Trigger">
    * In Zapier, create a new Zap.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-1.png" alt="Zapier 1" />
    </Frame>
  </Step>

  <Step title="Choose Slack as your trigger app">
    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-2.png" alt="Zapier 2" />
    </Frame>

    * Select `New Pushed Message` as the Trigger Event.
    * Connect your Slack account if you haven't already.
  </Step>

  <Step title="Configure the CrewAI Enterprise Action">
    * Add a new action step to your Zap.
    * Choose CrewAI+ as your action app and Kickoff as the Action Event

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-3.png" alt="Zapier 5" />
    </Frame>
  </Step>

  <Step title="Connect your CrewAI Enterprise account">
    * Connect your CrewAI Enterprise account.
    * Select the appropriate Crew for your workflow.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-4.png" alt="Zapier 6" />
    </Frame>

    * Configure the inputs for the Crew using the data from the Slack message.
  </Step>

  <Step title="Format the CrewAI Enterprise Output">
    * Add another action step to format the text output from CrewAI Enterprise.
    * Use Zapier's formatting tools to convert the Markdown output to HTML.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-5.png" alt="Zapier 8" />
    </Frame>

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-6.png" alt="Zapier 9" />
    </Frame>
  </Step>

  <Step title="Send the Output via Email">
    * Add a final action step to send the formatted output via email.
    * Choose your preferred email service (e.g., Gmail, Outlook).
    * Configure the email details, including recipient, subject, and body.
    * Insert the formatted CrewAI Enterprise output into the email body.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-7.png" alt="Zapier 7" />
    </Frame>
  </Step>

  <Step title="Kick Off the crew from Slack">
    * Enter the text in your Slack channel

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-7b.png" alt="Zapier 10" />
    </Frame>

    * Select the 3 ellipsis button and then chose Push to Zapier

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-8.png" alt="Zapier 11" />
    </Frame>
  </Step>

  <Step title="Select the crew and then Push to Kick Off">
    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-9.png" alt="Zapier 12" />
    </Frame>
  </Step>
</Steps>

## Tips for Success

* Ensure that your CrewAI Enterprise inputs are correctly mapped from the Slack message.
* Test your Zap thoroughly before turning it on to catch any potential issues.
* Consider adding error handling steps to manage potential failures in the workflow.

By following these steps, you'll have successfully set up Zapier triggers for CrewAI Enterprise, allowing for automated workflows triggered by Slack messages and resulting in email notifications with CrewAI Enterprise output.


# Asana Integration
Source: https://docs.crewai.com/en/enterprise/integrations/asana

Team task and project coordination with Asana integration for CrewAI.

## Overview

Enable your agents to manage tasks, projects, and team coordination through Asana. Create tasks, update project status, manage assignments, and streamline your team's workflow with AI-powered automation.

## Prerequisites

Before using the Asana integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* An Asana account with appropriate permissions
* Connected your Asana account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors)

## Setting Up Asana Integration

### 1. Connect Your Asana Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors)
2. Find **Asana** in the Authentication Integrations section
3. Click **Connect** and complete the OAuth flow
4. Grant the necessary permissions for task and project management
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account)

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="ASANA_CREATE_COMMENT">
    **Description:** Create a comment in Asana.

    **Parameters:**

    * `task` (string, required): Task ID - The ID of the Task the comment will be added to. The comment will be authored by the currently authenticated user.
    * `text` (string, required): Text (example: "This is a comment.").
  </Accordion>

  <Accordion title="ASANA_CREATE_PROJECT">
    **Description:** Create a project in Asana.

    **Parameters:**

    * `name` (string, required): Name (example: "Stuff to buy").
    * `workspace` (string, required): Workspace - Use Connect Portal Workflow Settings to allow users to select which Workspace to create Projects in. Defaults to the user's first Workspace if left blank.
    * `team` (string, optional): Team - Use Connect Portal Workflow Settings to allow users to select which Team to share this Project with. Defaults to the user's first Team if left blank.
    * `notes` (string, optional): Notes (example: "These are things we need to purchase.").
  </Accordion>

  <Accordion title="ASANA_GET_PROJECTS">
    **Description:** Get a list of projects in Asana.

    **Parameters:**

    * `archived` (string, optional): Archived - Choose "true" to show archived projects, "false" to display only active projects, or "default" to show both archived and active projects.
      * Options: `default`, `true`, `false`
  </Accordion>

  <Accordion title="ASANA_GET_PROJECT_BY_ID">
    **Description:** Get a project by ID in Asana.

    **Parameters:**

    * `projectFilterId` (string, required): Project ID.
  </Accordion>

  <Accordion title="ASANA_CREATE_TASK">
    **Description:** Create a task in Asana.

    **Parameters:**

    * `name` (string, required): Name (example: "Task Name").
    * `workspace` (string, optional): Workspace - Use Connect Portal Workflow Settings to allow users to select which Workspace to create Tasks in. Defaults to the user's first Workspace if left blank..
    * `project` (string, optional): Project - Use Connect Portal Workflow Settings to allow users to select which Project to create this Task in.
    * `notes` (string, optional): Notes.
    * `dueOnDate` (string, optional): Due On - The date on which this task is due. Cannot be used together with Due At. (example: "YYYY-MM-DD").
    * `dueAtDate` (string, optional): Due At - The date and time (ISO timestamp) at which this task is due. Cannot be used together with Due On. (example: "2019-09-15T02:06:58.147Z").
    * `assignee` (string, optional): Assignee - The ID of the Asana user this task will be assigned to. Use Connect Portal Workflow Settings to allow users to select an Assignee.
    * `gid` (string, optional): External ID - An ID from your application to associate this task with. You can use this ID to sync updates to this task later.
  </Accordion>

  <Accordion title="ASANA_UPDATE_TASK">
    **Description:** Update a task in Asana.

    **Parameters:**

    * `taskId` (string, required): Task ID - The ID of the Task that will be updated.
    * `completeStatus` (string, optional): Completed Status.
      * Options: `true`, `false`
    * `name` (string, optional): Name (example: "Task Name").
    * `notes` (string, optional): Notes.
    * `dueOnDate` (string, optional): Due On - The date on which this task is due. Cannot be used together with Due At. (example: "YYYY-MM-DD").
    * `dueAtDate` (string, optional): Due At - The date and time (ISO timestamp) at which this task is due. Cannot be used together with Due On. (example: "2019-09-15T02:06:58.147Z").
    * `assignee` (string, optional): Assignee - The ID of the Asana user this task will be assigned to. Use Connect Portal Workflow Settings to allow users to select an Assignee.
    * `gid` (string, optional): External ID - An ID from your application to associate this task with. You can use this ID to sync updates to this task later.
  </Accordion>

  <Accordion title="ASANA_GET_TASKS">
    **Description:** Get a list of tasks in Asana.

    **Parameters:**

    * `workspace` (string, optional): Workspace - The ID of the Workspace to filter tasks on. Use Connect Portal Workflow Settings to allow users to select a Workspace.
    * `project` (string, optional): Project - The ID of the Project to filter tasks on. Use Connect Portal Workflow Settings to allow users to select a Project.
    * `assignee` (string, optional): Assignee - The ID of the assignee to filter tasks on. Use Connect Portal Workflow Settings to allow users to select an Assignee.
    * `completedSince` (string, optional): Completed since - Only return tasks that are either incomplete or that have been completed since this time (ISO or Unix timestamp). (example: "2014-04-25T16:15:47-04:00").
  </Accordion>

  <Accordion title="ASANA_GET_TASKS_BY_ID">
    **Description:** Get a list of tasks by ID in Asana.

    **Parameters:**

    * `taskId` (string, required): Task ID.
  </Accordion>

  <Accordion title="ASANA_GET_TASK_BY_EXTERNAL_ID">
    **Description:** Get a task by external ID in Asana.

    **Parameters:**

    * `gid` (string, required): External ID - The ID that this task is associated or synced with, from your application.
  </Accordion>

  <Accordion title="ASANA_ADD_TASK_TO_SECTION">
    **Description:** Add a task to a section in Asana.

    **Parameters:**

    * `sectionId` (string, required): Section ID - The ID of the section to add this task to.
    * `taskId` (string, required): Task ID - The ID of the task. (example: "1204619611402340").
    * `beforeTaskId` (string, optional): Before Task ID - The ID of a task in this section that this task will be inserted before. Cannot be used with After Task ID. (example: "1204619611402340").
    * `afterTaskId` (string, optional): After Task ID - The ID of a task in this section that this task will be inserted after. Cannot be used with Before Task ID. (example: "1204619611402340").
  </Accordion>

  <Accordion title="ASANA_GET_TEAMS">
    **Description:** Get a list of teams in Asana.

    **Parameters:**

    * `workspace` (string, required): Workspace - Returns the teams in this workspace visible to the authorized user.
  </Accordion>

  <Accordion title="ASANA_GET_WORKSPACES">
    **Description:** Get a list of workspaces in Asana.

    **Parameters:** None required.
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Asana Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Asana tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Asana capabilities
asana_agent = Agent(
    role="Project Manager",
    goal="Manage tasks and projects in Asana efficiently",
    backstory="An AI assistant specialized in project management and task coordination.",
    tools=[enterprise_tools]
)

# Task to create a new project
create_project_task = Task(
    description="Create a new project called 'Q1 Marketing Campaign' in the Marketing workspace",
    agent=asana_agent,
    expected_output="Confirmation that the project was created successfully with project ID"
)

# Run the task
crew = Crew(
    agents=[asana_agent],
    tasks=[create_project_task]
)

crew.kickoff()
```

### Filtering Specific Asana Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Asana tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["asana_create_task", "asana_update_task", "asana_get_tasks"]
)

task_manager_agent = Agent(
    role="Task Manager",
    goal="Create and manage tasks efficiently",
    backstory="An AI assistant that focuses on task creation and management.",
    tools=enterprise_tools
)

# Task to create and assign a task
task_management = Task(
    description="Create a task called 'Review quarterly reports' and assign it to the appropriate team member",
    agent=task_manager_agent,
    expected_output="Task created and assigned successfully"
)

crew = Crew(
    agents=[task_manager_agent],
    tasks=[task_management]
)

crew.kickoff()
```

### Advanced Project Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

project_coordinator = Agent(
    role="Project Coordinator",
    goal="Coordinate project activities and track progress",
    backstory="An experienced project coordinator who ensures projects run smoothly.",
    tools=[enterprise_tools]
)

# Complex task involving multiple Asana operations
coordination_task = Task(
    description="""
    1. Get all active projects in the workspace
    2. For each project, get the list of incomplete tasks
    3. Create a summary report task in the 'Management Reports' project
    4. Add comments to overdue tasks to request status updates
    """,
    agent=project_coordinator,
    expected_output="Summary report created and status update requests sent for overdue tasks"
)

crew = Crew(
    agents=[project_coordinator],
    tasks=[coordination_task]
)

crew.kickoff()
```


# Box Integration
Source: https://docs.crewai.com/en/enterprise/integrations/box

File storage and document management with Box integration for CrewAI.

## Overview

Enable your agents to manage files, folders, and documents through Box. Upload files, organize folder structures, search content, and streamline your team's document management with AI-powered automation.

## Prerequisites

Before using the Box integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Box account with appropriate permissions
* Connected your Box account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors)

## Setting Up Box Integration

### 1. Connect Your Box Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors)
2. Find **Box** in the Authentication Integrations section
3. Click **Connect** and complete the OAuth flow
4. Grant the necessary permissions for file and folder management
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account)

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="BOX_SAVE_FILE">
    **Description:** Save a file from URL in Box.

    **Parameters:**

    * `fileAttributes` (object, required): Attributes - File metadata including name, parent folder, and timestamps.
      ```json
      {
        "content_created_at": "2012-12-12T10:53:43-08:00",
        "content_modified_at": "2012-12-12T10:53:43-08:00",
        "name": "qwerty.png",
        "parent": { "id": "1234567" }
      }
      ```
    * `file` (string, required): File URL - Files must be smaller than 50MB in size. (example: "[https://picsum.photos/200/300](https://picsum.photos/200/300)").
  </Accordion>

  <Accordion title="BOX_SAVE_FILE_FROM_OBJECT">
    **Description:** Save a file in Box.

    **Parameters:**

    * `file` (string, required): File - Accepts a File Object containing file data. Files must be smaller than 50MB in size.
    * `fileName` (string, required): File Name (example: "qwerty.png").
    * `folder` (string, optional): Folder - Use Connect Portal Workflow Settings to allow users to select the File's Folder destination. Defaults to the user's root folder if left blank.
  </Accordion>

  <Accordion title="BOX_GET_FILE_BY_ID">
    **Description:** Get a file by ID in Box.

    **Parameters:**

    * `fileId` (string, required): File ID - The unique identifier that represents a file. (example: "12345").
  </Accordion>

  <Accordion title="BOX_LIST_FILES">
    **Description:** List files in Box.

    **Parameters:**

    * `folderId` (string, required): Folder ID - The unique identifier that represents a folder. (example: "0").
    * `filterFormula` (object, optional): A filter in disjunctive normal form - OR of AND groups of single conditions.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "direction",
                "operator": "$stringExactlyMatches",
                "value": "ASC"
              }
            ]
          }
        ]
      }
      ```
  </Accordion>

  <Accordion title="BOX_CREATE_FOLDER">
    **Description:** Create a folder in Box.

    **Parameters:**

    * `folderName` (string, required): Name - The name for the new folder. (example: "New Folder").
    * `folderParent` (object, required): Parent Folder - The parent folder where the new folder will be created.
      ```json
      {
        "id": "123456"
      }
      ```
  </Accordion>

  <Accordion title="BOX_MOVE_FOLDER">
    **Description:** Move a folder in Box.

    **Parameters:**

    * `folderId` (string, required): Folder ID - The unique identifier that represents a folder. (example: "0").
    * `folderName` (string, required): Name - The name for the folder. (example: "New Folder").
    * `folderParent` (object, required): Parent Folder - The new parent folder destination.
      ```json
      {
        "id": "123456"
      }
      ```
  </Accordion>

  <Accordion title="BOX_GET_FOLDER_BY_ID">
    **Description:** Get a folder by ID in Box.

    **Parameters:**

    * `folderId` (string, required): Folder ID - The unique identifier that represents a folder. (example: "0").
  </Accordion>

  <Accordion title="BOX_SEARCH_FOLDERS">
    **Description:** Search folders in Box.

    **Parameters:**

    * `folderId` (string, required): Folder ID - The folder to search within.
    * `filterFormula` (object, optional): A filter in disjunctive normal form - OR of AND groups of single conditions.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "sort",
                "operator": "$stringExactlyMatches",
                "value": "name"
              }
            ]
          }
        ]
      }
      ```
  </Accordion>

  <Accordion title="BOX_DELETE_FOLDER">
    **Description:** Delete a folder in Box.

    **Parameters:**

    * `folderId` (string, required): Folder ID - The unique identifier that represents a folder. (example: "0").
    * `recursive` (boolean, optional): Recursive - Delete a folder that is not empty by recursively deleting the folder and all of its content.
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Box Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Box tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Box capabilities
box_agent = Agent(
    role="Document Manager",
    goal="Manage files and folders in Box efficiently",
    backstory="An AI assistant specialized in document management and file organization.",
    tools=[enterprise_tools]
)

# Task to create a folder structure
create_structure_task = Task(
    description="Create a folder called 'Project Files' in the root directory and upload a document from URL",
    agent=box_agent,
    expected_output="Folder created and file uploaded successfully"
)

# Run the task
crew = Crew(
    agents=[box_agent],
    tasks=[create_structure_task]
)

crew.kickoff()
```

### Filtering Specific Box Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Box tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["box_create_folder", "box_save_file", "box_list_files"]
)

file_organizer_agent = Agent(
    role="File Organizer",
    goal="Organize and manage file storage efficiently",
    backstory="An AI assistant that focuses on file organization and storage management.",
    tools=enterprise_tools
)

# Task to organize files
organization_task = Task(
    description="Create a folder structure for the marketing team and organize existing files",
    agent=file_organizer_agent,
    expected_output="Folder structure created and files organized"
)

crew = Crew(
    agents=[file_organizer_agent],
    tasks=[organization_task]
)

crew.kickoff()
```

### Advanced File Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

file_manager = Agent(
    role="File Manager",
    goal="Maintain organized file structure and manage document lifecycle",
    backstory="An experienced file manager who ensures documents are properly organized and accessible.",
    tools=[enterprise_tools]
)

# Complex task involving multiple Box operations
management_task = Task(
    description="""
    1. List all files in the root folder
    2. Create monthly archive folders for the current year
    3. Move old files to appropriate archive folders
    4. Generate a summary report of the file organization
    """,
    agent=file_manager,
    expected_output="Files organized into archive structure with summary report"
)

crew = Crew(
    agents=[file_manager],
    tasks=[management_task]
)

crew.kickoff()
```


# ClickUp Integration
Source: https://docs.crewai.com/en/enterprise/integrations/clickup

Task and productivity management with ClickUp integration for CrewAI.

## Overview

Enable your agents to manage tasks, projects, and productivity workflows through ClickUp. Create and update tasks, organize projects, manage team assignments, and streamline your productivity management with AI-powered automation.

## Prerequisites

Before using the ClickUp integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A ClickUp account with appropriate permissions
* Connected your ClickUp account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors)

## Setting Up ClickUp Integration

### 1. Connect Your ClickUp Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors)
2. Find **ClickUp** in the Authentication Integrations section
3. Click **Connect** and complete the OAuth flow
4. Grant the necessary permissions for task and project management
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account)

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="CLICKUP_SEARCH_TASKS">
    **Description:** Search for tasks in ClickUp using advanced filters.

    **Parameters:**

    * `taskFilterFormula` (object, optional): A filter in disjunctive normal form - OR of AND groups of single conditions.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "statuses%5B%5D",
                "operator": "$stringExactlyMatches",
                "value": "open"
              }
            ]
          }
        ]
      }
      ```
      Available fields: `space_ids%5B%5D`, `project_ids%5B%5D`, `list_ids%5B%5D`, `statuses%5B%5D`, `include_closed`, `assignees%5B%5D`, `tags%5B%5D`, `due_date_gt`, `due_date_lt`, `date_created_gt`, `date_created_lt`, `date_updated_gt`, `date_updated_lt`
  </Accordion>

  <Accordion title="CLICKUP_GET_TASK_IN_LIST">
    **Description:** Get tasks in a specific list in ClickUp.

    **Parameters:**

    * `listId` (string, required): List - Select a List to get tasks from. Use Connect Portal User Settings to allow users to select a ClickUp List.
    * `taskFilterFormula` (string, optional): Search for tasks that match specified filters. For example: name=task1.
  </Accordion>

  <Accordion title="CLICKUP_CREATE_TASK">
    **Description:** Create a task in ClickUp.

    **Parameters:**

    * `listId` (string, required): List - Select a List to create this task in. Use Connect Portal User Settings to allow users to select a ClickUp List.
    * `name` (string, required): Name - The task name.
    * `description` (string, optional): Description - Task description.
    * `status` (string, optional): Status - Select a Status for this task. Use Connect Portal User Settings to allow users to select a ClickUp Status.
    * `assignees` (string, optional): Assignees - Select a Member (or an array of member IDs) to be assigned to this task. Use Connect Portal User Settings to allow users to select a ClickUp Member.
    * `dueDate` (string, optional): Due Date - Specify a date for this task to be due on.
    * `additionalFields` (string, optional): Additional Fields - Specify additional fields to include on this task as JSON.
  </Accordion>

  <Accordion title="CLICKUP_UPDATE_TASK">
    **Description:** Update a task in ClickUp.

    **Parameters:**

    * `taskId` (string, required): Task ID - The ID of the task to update.
    * `listId` (string, required): List - Select a List to create this task in. Use Connect Portal User Settings to allow users to select a ClickUp List.
    * `name` (string, optional): Name - The task name.
    * `description` (string, optional): Description - Task description.
    * `status` (string, optional): Status - Select a Status for this task. Use Connect Portal User Settings to allow users to select a ClickUp Status.
    * `assignees` (string, optional): Assignees - Select a Member (or an array of member IDs) to be assigned to this task. Use Connect Portal User Settings to allow users to select a ClickUp Member.
    * `dueDate` (string, optional): Due Date - Specify a date for this task to be due on.
    * `additionalFields` (string, optional): Additional Fields - Specify additional fields to include on this task as JSON.
  </Accordion>

  <Accordion title="CLICKUP_DELETE_TASK">
    **Description:** Delete a task in ClickUp.

    **Parameters:**

    * `taskId` (string, required): Task ID - The ID of the task to delete.
  </Accordion>

  <Accordion title="CLICKUP_GET_LIST">
    **Description:** Get List information in ClickUp.

    **Parameters:**

    * `spaceId` (string, required): Space ID - The ID of the space containing the lists.
  </Accordion>

  <Accordion title="CLICKUP_GET_CUSTOM_FIELDS_IN_LIST">
    **Description:** Get Custom Fields in a List in ClickUp.

    **Parameters:**

    * `listId` (string, required): List ID - The ID of the list to get custom fields from.
  </Accordion>

  <Accordion title="CLICKUP_GET_ALL_FIELDS_IN_LIST">
    **Description:** Get All Fields in a List in ClickUp.

    **Parameters:**

    * `listId` (string, required): List ID - The ID of the list to get all fields from.
  </Accordion>

  <Accordion title="CLICKUP_GET_SPACE">
    **Description:** Get Space information in ClickUp.

    **Parameters:**

    * `spaceId` (string, optional): Space ID - The ID of the space to retrieve.
  </Accordion>

  <Accordion title="CLICKUP_GET_FOLDERS">
    **Description:** Get Folders in ClickUp.

    **Parameters:**

    * `spaceId` (string, required): Space ID - The ID of the space containing the folders.
  </Accordion>

  <Accordion title="CLICKUP_GET_MEMBER">
    **Description:** Get Member information in ClickUp.

    **Parameters:** None required.
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic ClickUp Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (ClickUp tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with ClickUp capabilities
clickup_agent = Agent(
    role="Task Manager",
    goal="Manage tasks and projects in ClickUp efficiently",
    backstory="An AI assistant specialized in task management and productivity coordination.",
    tools=[enterprise_tools]
)

# Task to create a new task
create_task = Task(
    description="Create a task called 'Review Q1 Reports' in the Marketing list with high priority",
    agent=clickup_agent,
    expected_output="Task created successfully with task ID"
)

# Run the task
crew = Crew(
    agents=[clickup_agent],
    tasks=[create_task]
)

crew.kickoff()
```

### Filtering Specific ClickUp Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific ClickUp tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["clickup_create_task", "clickup_update_task", "clickup_search_tasks"]
)

task_coordinator = Agent(
    role="Task Coordinator",
    goal="Create and manage tasks efficiently",
    backstory="An AI assistant that focuses on task creation and status management.",
    tools=enterprise_tools
)

# Task to manage task workflow
task_workflow = Task(
    description="Create a task for project planning and assign it to the development team",
    agent=task_coordinator,
    expected_output="Task created and assigned successfully"
)

crew = Crew(
    agents=[task_coordinator],
    tasks=[task_workflow]
)

crew.kickoff()
```

### Advanced Project Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

project_manager = Agent(
    role="Project Manager",
    goal="Coordinate project activities and track team productivity",
    backstory="An experienced project manager who ensures projects are delivered on time.",
    tools=[enterprise_tools]
)

# Complex task involving multiple ClickUp operations
project_coordination = Task(
    description="""
    1. Get all open tasks in the current space
    2. Identify overdue tasks and update their status
    3. Create a weekly report task summarizing project progress
    4. Assign the report task to the team lead
    """,
    agent=project_manager,
    expected_output="Project status updated and weekly report task created and assigned"
)

crew = Crew(
    agents=[project_manager],
    tasks=[project_coordination]
)

crew.kickoff()
```

### Task Search and Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

task_analyst = Agent(
    role="Task Analyst",
    goal="Analyze task patterns and optimize team productivity",
    backstory="An AI assistant that analyzes task data to improve team efficiency.",
    tools=[enterprise_tools]
)

# Task to analyze and optimize task distribution
task_analysis = Task(
    description="""
    Search for all tasks assigned to team members in the last 30 days,
    analyze completion patterns, and create optimization recommendations
    """,
    agent=task_analyst,
    expected_output="Task analysis report with optimization recommendations"
)

crew = Crew(
    agents=[task_analyst],
    tasks=[task_analysis]
)

crew.kickoff()
```

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with ClickUp integration setup or troubleshooting.
</Card>


# GitHub Integration
Source: https://docs.crewai.com/en/enterprise/integrations/github

Repository and issue management with GitHub integration for CrewAI.

## Overview

Enable your agents to manage repositories, issues, and releases through GitHub. Create and update issues, manage releases, track project development, and streamline your software development workflow with AI-powered automation.

## Prerequisites

Before using the GitHub integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A GitHub account with appropriate repository permissions
* Connected your GitHub account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors)

## Setting Up GitHub Integration

### 1. Connect Your GitHub Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors)
2. Find **GitHub** in the Authentication Integrations section
3. Click **Connect** and complete the OAuth flow
4. Grant the necessary permissions for repository and issue management
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account)

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="GITHUB_CREATE_ISSUE">
    **Description:** Create an issue in GitHub.

    **Parameters:**

    * `owner` (string, required): Owner - Specify the name of the account owner of the associated repository for this Issue. (example: "abc").
    * `repo` (string, required): Repository - Specify the name of the associated repository for this Issue.
    * `title` (string, required): Issue Title - Specify the title of the issue to create.
    * `body` (string, optional): Issue Body - Specify the body contents of the issue to create.
    * `assignees` (string, optional): Assignees - Specify the assignee(s)' GitHub login as an array of strings for this issue. (example: `["octocat"]`).
  </Accordion>

  <Accordion title="GITHUB_UPDATE_ISSUE">
    **Description:** Update an issue in GitHub.

    **Parameters:**

    * `owner` (string, required): Owner - Specify the name of the account owner of the associated repository for this Issue. (example: "abc").
    * `repo` (string, required): Repository - Specify the name of the associated repository for this Issue.
    * `issue_number` (string, required): Issue Number - Specify the number of the issue to update.
    * `title` (string, required): Issue Title - Specify the title of the issue to update.
    * `body` (string, optional): Issue Body - Specify the body contents of the issue to update.
    * `assignees` (string, optional): Assignees - Specify the assignee(s)' GitHub login as an array of strings for this issue. (example: `["octocat"]`).
    * `state` (string, optional): State - Specify the updated state of the issue.
      * Options: `open`, `closed`
  </Accordion>

  <Accordion title="GITHUB_GET_ISSUE_BY_NUMBER">
    **Description:** Get an issue by number in GitHub.

    **Parameters:**

    * `owner` (string, required): Owner - Specify the name of the account owner of the associated repository for this Issue. (example: "abc").
    * `repo` (string, required): Repository - Specify the name of the associated repository for this Issue.
    * `issue_number` (string, required): Issue Number - Specify the number of the issue to fetch.
  </Accordion>

  <Accordion title="GITHUB_LOCK_ISSUE">
    **Description:** Lock an issue in GitHub.

    **Parameters:**

    * `owner` (string, required): Owner - Specify the name of the account owner of the associated repository for this Issue. (example: "abc").
    * `repo` (string, required): Repository - Specify the name of the associated repository for this Issue.
    * `issue_number` (string, required): Issue Number - Specify the number of the issue to lock.
    * `lock_reason` (string, required): Lock Reason - Specify a reason for locking the issue or pull request conversation.
      * Options: `off-topic`, `too heated`, `resolved`, `spam`
  </Accordion>

  <Accordion title="GITHUB_SEARCH_ISSUE">
    **Description:** Search for issues in GitHub.

    **Parameters:**

    * `owner` (string, required): Owner - Specify the name of the account owner of the associated repository for this Issue. (example: "abc").
    * `repo` (string, required): Repository - Specify the name of the associated repository for this Issue.
    * `filter` (object, required): A filter in disjunctive normal form - OR of AND groups of single conditions.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "assignee",
                "operator": "$stringExactlyMatches",
                "value": "octocat"
              }
            ]
          }
        ]
      }
      ```
      Available fields: `assignee`, `creator`, `mentioned`, `labels`
  </Accordion>

  <Accordion title="GITHUB_CREATE_RELEASE">
    **Description:** Create a release in GitHub.

    **Parameters:**

    * `owner` (string, required): Owner - Specify the name of the account owner of the associated repository for this Release. (example: "abc").
    * `repo` (string, required): Repository - Specify the name of the associated repository for this Release.
    * `tag_name` (string, required): Name - Specify the name of the release tag to be created. (example: "v1.0.0").
    * `target_commitish` (string, optional): Target - Specify the target of the release. This can either be a branch name or a commit SHA. Defaults to the main branch. (example: "master").
    * `body` (string, optional): Body - Specify a description for this release.
    * `draft` (string, optional): Draft - Specify whether the created release should be a draft (unpublished) release.
      * Options: `true`, `false`
    * `prerelease` (string, optional): Prerelease - Specify whether the created release should be a prerelease.
      * Options: `true`, `false`
    * `discussion_category_name` (string, optional): Discussion Category Name - If specified, a discussion of the specified category is created and linked to the release. The value must be a category that already exists in the repository.
    * `generate_release_notes` (string, optional): Release Notes - Specify whether the created release should automatically create release notes using the provided name and body specified.
      * Options: `true`, `false`
  </Accordion>

  <Accordion title="GITHUB_UPDATE_RELEASE">
    **Description:** Update a release in GitHub.

    **Parameters:**

    * `owner` (string, required): Owner - Specify the name of the account owner of the associated repository for this Release. (example: "abc").
    * `repo` (string, required): Repository - Specify the name of the associated repository for this Release.
    * `id` (string, required): Release ID - Specify the ID of the release to update.
    * `tag_name` (string, optional): Name - Specify the name of the release tag to be updated. (example: "v1.0.0").
    * `target_commitish` (string, optional): Target - Specify the target of the release. This can either be a branch name or a commit SHA. Defaults to the main branch. (example: "master").
    * `body` (string, optional): Body - Specify a description for this release.
    * `draft` (string, optional): Draft - Specify whether the created release should be a draft (unpublished) release.
      * Options: `true`, `false`
    * `prerelease` (string, optional): Prerelease - Specify whether the created release should be a prerelease.
      * Options: `true`, `false`
    * `discussion_category_name` (string, optional): Discussion Category Name - If specified, a discussion of the specified category is created and linked to the release. The value must be a category that already exists in the repository.
    * `generate_release_notes` (string, optional): Release Notes - Specify whether the created release should automatically create release notes using the provided name and body specified.
      * Options: `true`, `false`
  </Accordion>

  <Accordion title="GITHUB_GET_RELEASE_BY_ID">
    **Description:** Get a release by ID in GitHub.

    **Parameters:**

    * `owner` (string, required): Owner - Specify the name of the account owner of the associated repository for this Release. (example: "abc").
    * `repo` (string, required): Repository - Specify the name of the associated repository for this Release.
    * `id` (string, required): Release ID - Specify the release ID of the release to fetch.
  </Accordion>

  <Accordion title="GITHUB_GET_RELEASE_BY_TAG_NAME">
    **Description:** Get a release by tag name in GitHub.

    **Parameters:**

    * `owner` (string, required): Owner - Specify the name of the account owner of the associated repository for this Release. (example: "abc").
    * `repo` (string, required): Repository - Specify the name of the associated repository for this Release.
    * `tag_name` (string, required): Name - Specify the tag of the release to fetch. (example: "v1.0.0").
  </Accordion>

  <Accordion title="GITHUB_DELETE_RELEASE">
    **Description:** Delete a release in GitHub.

    **Parameters:**

    * `owner` (string, required): Owner - Specify the name of the account owner of the associated repository for this Release. (example: "abc").
    * `repo` (string, required): Repository - Specify the name of the associated repository for this Release.
    * `id` (string, required): Release ID - Specify the ID of the release to delete.
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic GitHub Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (GitHub tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with GitHub capabilities
github_agent = Agent(
    role="Repository Manager",
    goal="Manage GitHub repositories, issues, and releases efficiently",
    backstory="An AI assistant specialized in repository management and issue tracking.",
    tools=[enterprise_tools]
)

# Task to create a new issue
create_issue_task = Task(
    description="Create a bug report issue for the login functionality in the main repository",
    agent=github_agent,
    expected_output="Issue created successfully with issue number"
)

# Run the task
crew = Crew(
    agents=[github_agent],
    tasks=[create_issue_task]
)

crew.kickoff()
```

### Filtering Specific GitHub Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific GitHub tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["github_create_issue", "github_update_issue", "github_search_issue"]
)

issue_manager = Agent(
    role="Issue Manager",
    goal="Create and manage GitHub issues efficiently",
    backstory="An AI assistant that focuses on issue tracking and management.",
    tools=enterprise_tools
)

# Task to manage issue workflow
issue_workflow = Task(
    description="Create a feature request issue and assign it to the development team",
    agent=issue_manager,
    expected_output="Feature request issue created and assigned successfully"
)

crew = Crew(
    agents=[issue_manager],
    tasks=[issue_workflow]
)

crew.kickoff()
```

### Release Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

release_manager = Agent(
    role="Release Manager",
    goal="Manage software releases and versioning",
    backstory="An experienced release manager who handles version control and release processes.",
    tools=[enterprise_tools]
)

# Task to create a new release
release_task = Task(
    description="""
    Create a new release v2.1.0 for the project with:
    - Auto-generated release notes
    - Target the main branch
    - Include a description of new features and bug fixes
    """,
    agent=release_manager,
    expected_output="Release v2.1.0 created successfully with release notes"
)

crew = Crew(
    agents=[release_manager],
    tasks=[release_task]
)

crew.kickoff()
```

### Issue Tracking and Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

project_coordinator = Agent(
    role="Project Coordinator",
    goal="Track and coordinate project issues and development progress",
    backstory="An AI assistant that helps coordinate development work and track project progress.",
    tools=[enterprise_tools]
)

# Complex task involving multiple GitHub operations
coordination_task = Task(
    description="""
    1. Search for all open issues assigned to the current milestone
    2. Identify overdue issues and update their priority labels
    3. Create a weekly progress report issue
    4. Lock resolved issues that have been inactive for 30 days
    """,
    agent=project_coordinator,
    expected_output="Project coordination completed with progress report and issue management"
)

crew = Crew(
    agents=[project_coordinator],
    tasks=[coordination_task]
)

crew.kickoff()
```

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with GitHub integration setup or troubleshooting.
</Card>


# Gmail Integration
Source: https://docs.crewai.com/en/enterprise/integrations/gmail

Email and contact management with Gmail integration for CrewAI.

## Overview

Enable your agents to manage emails, contacts, and drafts through Gmail. Send emails, search messages, manage contacts, create drafts, and streamline your email communications with AI-powered automation.

## Prerequisites

Before using the Gmail integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Gmail account with appropriate permissions
* Connected your Gmail account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors)

## Setting Up Gmail Integration

### 1. Connect Your Gmail Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors)
2. Find **Gmail** in the Authentication Integrations section
3. Click **Connect** and complete the OAuth flow
4. Grant the necessary permissions for email and contact management
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account)

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="GMAIL_SEND_EMAIL">
    **Description:** Send an email in Gmail.

    **Parameters:**

    * `toRecipients` (array, required): To - Specify the recipients as either a single string or a JSON array.
      ```json
      [
        "recipient1@domain.com",
        "recipient2@domain.com"
      ]
      ```
    * `from` (string, required): From - Specify the email of the sender.
    * `subject` (string, required): Subject - Specify the subject of the message.
    * `messageContent` (string, required): Message Content - Specify the content of the email message as plain text or HTML.
    * `attachments` (string, optional): Attachments - Accepts either a single file object or a JSON array of file objects.
    * `additionalHeaders` (object, optional): Additional Headers - Specify any additional header fields here.
      ```json
      {
        "reply-to": "Sender Name <sender@domain.com>"
      }
      ```
  </Accordion>

  <Accordion title="GMAIL_GET_EMAIL_BY_ID">
    **Description:** Get an email by ID in Gmail.

    **Parameters:**

    * `userId` (string, required): User ID - Specify the user's email address. (example: "[user@domain.com](mailto:user@domain.com)").
    * `messageId` (string, required): Message ID - Specify the ID of the message to retrieve.
  </Accordion>

  <Accordion title="GMAIL_SEARCH_FOR_EMAIL">
    **Description:** Search for emails in Gmail using advanced filters.

    **Parameters:**

    * `emailFilterFormula` (object, optional): A filter in disjunctive normal form - OR of AND groups of single conditions.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "from",
                "operator": "$stringContains",
                "value": "example@domain.com"
              }
            ]
          }
        ]
      }
      ```
      Available fields: `from`, `to`, `date`, `label`, `subject`, `cc`, `bcc`, `category`, `deliveredto:`, `size`, `filename`, `older_than`, `newer_than`, `list`, `is:important`, `is:unread`, `is:snoozed`, `is:starred`, `is:read`, `has:drive`, `has:document`, `has:spreadsheet`, `has:presentation`, `has:attachment`, `has:youtube`, `has:userlabels`
    * `paginationParameters` (object, optional): Pagination Parameters.
      ```json
      {
        "pageCursor": "page_cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="GMAIL_DELETE_EMAIL">
    **Description:** Delete an email in Gmail.

    **Parameters:**

    * `userId` (string, required): User ID - Specify the user's email address. (example: "[user@domain.com](mailto:user@domain.com)").
    * `messageId` (string, required): Message ID - Specify the ID of the message to trash.
  </Accordion>

  <Accordion title="GMAIL_CREATE_A_CONTACT">
    **Description:** Create a contact in Gmail.

    **Parameters:**

    * `givenName` (string, required): Given Name - Specify the Given Name of the Contact to create. (example: "John").
    * `familyName` (string, required): Family Name - Specify the Family Name of the Contact to create. (example: "Doe").
    * `email` (string, required): Email - Specify the Email Address of the Contact to create.
    * `additionalFields` (object, optional): Additional Fields - Additional contact information.
      ```json
      {
        "addresses": [
          {
            "streetAddress": "1000 North St.",
            "city": "Los Angeles"
          }
        ]
      }
      ```
  </Accordion>

  <Accordion title="GMAIL_GET_CONTACT_BY_RESOURCE_NAME">
    **Description:** Get a contact by resource name in Gmail.

    **Parameters:**

    * `resourceName` (string, required): Resource Name - Specify the resource name of the contact to fetch.
  </Accordion>

  <Accordion title="GMAIL_SEARCH_FOR_CONTACT">
    **Description:** Search for a contact in Gmail.

    **Parameters:**

    * `searchTerm` (string, required): Term - Specify a search term to search for near or exact matches on the names, nickNames, emailAddresses, phoneNumbers, or organizations Contact properties.
  </Accordion>

  <Accordion title="GMAIL_DELETE_CONTACT">
    **Description:** Delete a contact in Gmail.

    **Parameters:**

    * `resourceName` (string, required): Resource Name - Specify the resource name of the contact to delete.
  </Accordion>

  <Accordion title="GMAIL_CREATE_DRAFT">
    **Description:** Create a draft in Gmail.

    **Parameters:**

    * `toRecipients` (array, optional): To - Specify the recipients as either a single string or a JSON array.
      ```json
      [
        "recipient1@domain.com",
        "recipient2@domain.com"
      ]
      ```
    * `from` (string, optional): From - Specify the email of the sender.
    * `subject` (string, optional): Subject - Specify the subject of the message.
    * `messageContent` (string, optional): Message Content - Specify the content of the email message as plain text or HTML.
    * `attachments` (string, optional): Attachments - Accepts either a single file object or a JSON array of file objects.
    * `additionalHeaders` (object, optional): Additional Headers - Specify any additional header fields here.
      ```json
      {
        "reply-to": "Sender Name <sender@domain.com>"
      }
      ```
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Gmail Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Gmail tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Gmail capabilities
gmail_agent = Agent(
    role="Email Manager",
    goal="Manage email communications and contacts efficiently",
    backstory="An AI assistant specialized in email management and communication.",
    tools=[enterprise_tools]
)

# Task to send a follow-up email
send_email_task = Task(
    description="Send a follow-up email to john@example.com about the project update meeting",
    agent=gmail_agent,
    expected_output="Email sent successfully with confirmation"
)

# Run the task
crew = Crew(
    agents=[gmail_agent],
    tasks=[send_email_task]
)

crew.kickoff()
```

### Filtering Specific Gmail Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Gmail tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["gmail_send_email", "gmail_search_for_email", "gmail_create_draft"]
)

email_coordinator = Agent(
    role="Email Coordinator",
    goal="Coordinate email communications and manage drafts",
    backstory="An AI assistant that focuses on email coordination and draft management.",
    tools=enterprise_tools
)

# Task to prepare and send emails
email_coordination = Task(
    description="Search for emails from the marketing team, create a summary draft, and send it to stakeholders",
    agent=email_coordinator,
    expected_output="Summary email sent to stakeholders"
)

crew = Crew(
    agents=[email_coordinator],
    tasks=[email_coordination]
)

crew.kickoff()
```

### Contact Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

contact_manager = Agent(
    role="Contact Manager",
    goal="Manage and organize email contacts efficiently",
    backstory="An experienced contact manager who maintains organized contact databases.",
    tools=[enterprise_tools]
)

# Task to manage contacts
contact_task = Task(
    description="""
    1. Search for contacts from the 'example.com' domain
    2. Create new contacts for recent email senders not in the contact list
    3. Update contact information with recent interaction data
    """,
    agent=contact_manager,
    expected_output="Contact database updated with new contacts and recent interactions"
)

crew = Crew(
    agents=[contact_manager],
    tasks=[contact_task]
)

crew.kickoff()
```

### Email Search and Analysis

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

email_analyst = Agent(
    role="Email Analyst",
    goal="Analyze email patterns and provide insights",
    backstory="An AI assistant that analyzes email data to provide actionable insights.",
    tools=[enterprise_tools]
)

# Task to analyze email patterns
analysis_task = Task(
    description="""
    Search for all unread emails from the last 7 days,
    categorize them by sender domain,
    and create a summary report of communication patterns
    """,
    agent=email_analyst,
    expected_output="Email analysis report with communication patterns and recommendations"
)

crew = Crew(
    agents=[email_analyst],
    tasks=[analysis_task]
)

crew.kickoff()
```

### Automated Email Workflows

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

workflow_manager = Agent(
    role="Email Workflow Manager",
    goal="Automate email workflows and responses",
    backstory="An AI assistant that manages automated email workflows and responses.",
    tools=[enterprise_tools]
)

# Complex task involving multiple Gmail operations
workflow_task = Task(
    description="""
    1. Search for emails with 'urgent' in the subject from the last 24 hours
    2. Create draft responses for each urgent email
    3. Send automated acknowledgment emails to senders
    4. Create a summary report of urgent items requiring attention
    """,
    agent=workflow_manager,
    expected_output="Urgent emails processed with automated responses and summary report"
)

crew = Crew(
    agents=[workflow_manager],
    tasks=[workflow_task]
)

crew.kickoff()
```

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with Gmail integration setup or troubleshooting.
</Card>


# Google Calendar Integration
Source: https://docs.crewai.com/en/enterprise/integrations/google_calendar

Event and schedule management with Google Calendar integration for CrewAI.

## Overview

Enable your agents to manage calendar events, schedules, and availability through Google Calendar. Create and update events, manage attendees, check availability, and streamline your scheduling workflows with AI-powered automation.

## Prerequisites

Before using the Google Calendar integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Google account with Google Calendar access
* Connected your Google account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors)

## Setting Up Google Calendar Integration

### 1. Connect Your Google Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors)
2. Find **Google Calendar** in the Authentication Integrations section
3. Click **Connect** and complete the OAuth flow
4. Grant the necessary permissions for calendar and contact access
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account)

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="GOOGLE_CALENDAR_CREATE_EVENT">
    **Description:** Create an event in Google Calendar.

    **Parameters:**

    * `eventName` (string, required): Event name.
    * `startTime` (string, required): Start time - Accepts Unix timestamp or ISO8601 date formats.
    * `endTime` (string, optional): End time - Defaults to one hour after the start time if left blank.
    * `calendar` (string, optional): Calendar - Use Connect Portal Workflow Settings to allow users to select which calendar the event will be added to. Defaults to the user's primary calendar if left blank.
    * `attendees` (string, optional): Attendees - Accepts an array of email addresses or email addresses separated by commas.
    * `eventLocation` (string, optional): Event location.
    * `eventDescription` (string, optional): Event description.
    * `eventId` (string, optional): Event ID - An ID from your application to associate this event with. You can use this ID to sync updates to this event later.
    * `includeMeetLink` (boolean, optional): Include Google Meet link? - Automatically creates Google Meet conference link for this event.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_UPDATE_EVENT">
    **Description:** Update an existing event in Google Calendar.

    **Parameters:**

    * `eventId` (string, required): Event ID - The ID of the event to update.
    * `eventName` (string, optional): Event name.
    * `startTime` (string, optional): Start time - Accepts Unix timestamp or ISO8601 date formats.
    * `endTime` (string, optional): End time - Defaults to one hour after the start time if left blank.
    * `calendar` (string, optional): Calendar - Use Connect Portal Workflow Settings to allow users to select which calendar the event will be added to. Defaults to the user's primary calendar if left blank.
    * `attendees` (string, optional): Attendees - Accepts an array of email addresses or email addresses separated by commas.
    * `eventLocation` (string, optional): Event location.
    * `eventDescription` (string, optional): Event description.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_LIST_EVENTS">
    **Description:** List events from Google Calendar.

    **Parameters:**

    * `calendar` (string, optional): Calendar - Use Connect Portal Workflow Settings to allow users to select which calendar the event will be added to. Defaults to the user's primary calendar if left blank.
    * `after` (string, optional): After - Filters events that start after the provided date (Unix in milliseconds or ISO timestamp). (example: "2025-04-12T10:00:00Z or 1712908800000").
    * `before` (string, optional): Before - Filters events that end before the provided date (Unix in milliseconds or ISO timestamp). (example: "2025-04-12T10:00:00Z or 1712908800000").
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_GET_EVENT_BY_ID">
    **Description:** Get a specific event by ID from Google Calendar.

    **Parameters:**

    * `eventId` (string, required): Event ID.
    * `calendar` (string, optional): Calendar - Use Connect Portal Workflow Settings to allow users to select which calendar the event will be added to. Defaults to the user's primary calendar if left blank.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_DELETE_EVENT">
    **Description:** Delete an event from Google Calendar.

    **Parameters:**

    * `eventId` (string, required): Event ID - The ID of the calendar event to be deleted.
    * `calendar` (string, optional): Calendar - Use Connect Portal Workflow Settings to allow users to select which calendar the event will be added to. Defaults to the user's primary calendar if left blank.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_GET_CONTACTS">
    **Description:** Get contacts from Google Calendar.

    **Parameters:**

    * `paginationParameters` (object, optional): Pagination Parameters.
      ```json
      {
        "pageCursor": "page_cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_SEARCH_CONTACTS">
    **Description:** Search for contacts in Google Calendar.

    **Parameters:**

    * `query` (string, optional): Search query to search contacts.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_LIST_DIRECTORY_PEOPLE">
    **Description:** List directory people.

    **Parameters:**

    * `paginationParameters` (object, optional): Pagination Parameters.
      ```json
      {
        "pageCursor": "page_cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_SEARCH_DIRECTORY_PEOPLE">
    **Description:** Search directory people.

    **Parameters:**

    * `query` (string, required): Search query to search contacts.
    * `paginationParameters` (object, optional): Pagination Parameters.
      ```json
      {
        "pageCursor": "page_cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_LIST_OTHER_CONTACTS">
    **Description:** List other contacts.

    **Parameters:**

    * `paginationParameters` (object, optional): Pagination Parameters.
      ```json
      {
        "pageCursor": "page_cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_SEARCH_OTHER_CONTACTS">
    **Description:** Search other contacts.

    **Parameters:**

    * `query` (string, optional): Search query to search contacts.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_GET_AVAILABILITY">
    **Description:** Get availability information for calendars.

    **Parameters:**

    * `timeMin` (string, required): The start of the interval. In ISO format.
    * `timeMax` (string, required): The end of the interval. In ISO format.
    * `timeZone` (string, optional): Time zone used in the response. Optional. The default is UTC.
    * `items` (array, optional): List of calendars and/or groups to query. Defaults to the user default calendar.
      ```json
      [
        {
          "id": "calendar_id_1"
        },
        {
          "id": "calendar_id_2"
        }
      ]
      ```
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Calendar Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Google Calendar tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Google Calendar capabilities
calendar_agent = Agent(
    role="Schedule Manager",
    goal="Manage calendar events and scheduling efficiently",
    backstory="An AI assistant specialized in calendar management and scheduling coordination.",
    tools=[enterprise_tools]
)

# Task to create a meeting
create_meeting_task = Task(
    description="Create a team standup meeting for tomorrow at 9 AM with the development team",
    agent=calendar_agent,
    expected_output="Meeting created successfully with Google Meet link"
)

# Run the task
crew = Crew(
    agents=[calendar_agent],
    tasks=[create_meeting_task]
)

crew.kickoff()
```

### Filtering Specific Calendar Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Google Calendar tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["google_calendar_create_event", "google_calendar_list_events", "google_calendar_get_availability"]
)

meeting_coordinator = Agent(
    role="Meeting Coordinator",
    goal="Coordinate meetings and check availability",
    backstory="An AI assistant that focuses on meeting scheduling and availability management.",
    tools=enterprise_tools
)

# Task to schedule a meeting with availability check
schedule_meeting = Task(
    description="Check availability for next week and schedule a project review meeting with stakeholders",
    agent=meeting_coordinator,
    expected_output="Meeting scheduled after checking availability of all participants"
)

crew = Crew(
    agents=[meeting_coordinator],
    tasks=[schedule_meeting]
)

crew.kickoff()
```

### Event Management and Updates

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

event_manager = Agent(
    role="Event Manager",
    goal="Manage and update calendar events efficiently",
    backstory="An experienced event manager who handles event logistics and updates.",
    tools=[enterprise_tools]
)

# Task to manage event updates
event_management = Task(
    description="""
    1. List all events for this week
    2. Update any events that need location changes to include video conference links
    3. Send calendar invitations to new team members for recurring meetings
    """,
    agent=event_manager,
    expected_output="Weekly events updated with proper locations and new attendees added"
)

crew = Crew(
    agents=[event_manager],
    tasks=[event_management]
)

crew.kickoff()
```

### Contact and Availability Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

availability_coordinator = Agent(
    role="Availability Coordinator",
    goal="Coordinate availability and manage contacts for scheduling",
    backstory="An AI assistant that specializes in availability management and contact coordination.",
    tools=[enterprise_tools]
)

# Task to coordinate availability
availability_task = Task(
    description="""
    1. Search for contacts in the engineering department
    2. Check availability for all engineers next Friday afternoon
    3. Create a team meeting for the first available 2-hour slot
    4. Include Google Meet link and send invitations
    """,
    agent=availability_coordinator,
    expected_output="Team meeting scheduled based on availability with all engineers invited"
)

crew = Crew(
    agents=[availability_coordinator],
    tasks=[availability_task]
)

crew.kickoff()
```

### Automated Scheduling Workflows

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

scheduling_automator = Agent(
    role="Scheduling Automator",
    goal="Automate scheduling workflows and calendar management",
    backstory="An AI assistant that automates complex scheduling scenarios and calendar workflows.",
    tools=[enterprise_tools]
)

# Complex scheduling automation task
automation_task = Task(
    description="""
    1. List all upcoming events for the next two weeks
    2. Identify any scheduling conflicts or back-to-back meetings
    3. Suggest optimal meeting times by checking availability
    4. Create buffer time between meetings where needed
    5. Update event descriptions with agenda items and meeting links
    """,
    agent=scheduling_automator,
    expected_output="Calendar optimized with resolved conflicts, buffer times, and updated meeting details"
)

crew = Crew(
    agents=[scheduling_automator],
    tasks=[automation_task]
)

crew.kickoff()
```

## Troubleshooting

### Common Issues

**Authentication Errors**

* Ensure your Google account has the necessary permissions for calendar access
* Verify that the OAuth connection includes all required scopes for Google Calendar API
* Check if calendar sharing settings allow the required access level

**Event Creation Issues**

* Verify that time formats are correct (ISO8601 or Unix timestamps)
* Ensure attendee email addresses are properly formatted
* Check that the target calendar exists and is accessible
* Verify time zones are correctly specified

**Availability and Time Conflicts**

* Use proper ISO format for time ranges when checking availability
* Ensure time zones are consistent across all operations
* Verify that calendar IDs are correct when checking multiple calendars

**Contact and People Search**

* Ensure search queries are properly formatted
* Check that directory access permissions are granted
* Verify that contact information is up to date and accessible

**Event Updates and Deletions**

* Verify that event IDs are correct and events exist
* Ensure you have edit permissions for the events
* Check that calendar ownership allows modifications

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with Google Calendar integration setup or troubleshooting.
</Card>


# Google Sheets Integration
Source: https://docs.crewai.com/en/enterprise/integrations/google_sheets

Spreadsheet data synchronization with Google Sheets integration for CrewAI.

## Overview

Enable your agents to manage spreadsheet data through Google Sheets. Read rows, create new entries, update existing data, and streamline your data management workflows with AI-powered automation. Perfect for data tracking, reporting, and collaborative data management.

## Prerequisites

Before using the Google Sheets integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Google account with Google Sheets access
* Connected your Google account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors)
* Spreadsheets with proper column headers for data operations

## Setting Up Google Sheets Integration

### 1. Connect Your Google Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors)
2. Find **Google Sheets** in the Authentication Integrations section
3. Click **Connect** and complete the OAuth flow
4. Grant the necessary permissions for spreadsheet access
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account)

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="GOOGLE_SHEETS_GET_ROW">
    **Description:** Get rows from a Google Sheets spreadsheet.

    **Parameters:**

    * `spreadsheetId` (string, required): Spreadsheet - Use Connect Portal Workflow Settings to allow users to select a spreadsheet. Defaults to using the first worksheet in the selected spreadsheet.
    * `limit` (string, optional): Limit rows - Limit the maximum number of rows to return.
  </Accordion>

  <Accordion title="GOOGLE_SHEETS_CREATE_ROW">
    **Description:** Create a new row in a Google Sheets spreadsheet.

    **Parameters:**

    * `spreadsheetId` (string, required): Spreadsheet - Use Connect Portal Workflow Settings to allow users to select a spreadsheet. Defaults to using the first worksheet in the selected spreadsheet..
    * `worksheet` (string, required): Worksheet - Your worksheet must have column headers.
    * `additionalFields` (object, required): Fields - Include fields to create this row with, as an object with keys of Column Names. Use Connect Portal Workflow Settings to allow users to select a Column Mapping.
      ```json
      {
        "columnName1": "columnValue1",
        "columnName2": "columnValue2",
        "columnName3": "columnValue3",
        "columnName4": "columnValue4"
      }
      ```
  </Accordion>

  <Accordion title="GOOGLE_SHEETS_UPDATE_ROW">
    **Description:** Update existing rows in a Google Sheets spreadsheet.

    **Parameters:**

    * `spreadsheetId` (string, required): Spreadsheet - Use Connect Portal Workflow Settings to allow users to select a spreadsheet. Defaults to using the first worksheet in the selected spreadsheet.
    * `worksheet` (string, required): Worksheet - Your worksheet must have column headers.
    * `filterFormula` (object, optional): A filter in disjunctive normal form - OR of AND groups of single conditions to identify which rows to update.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "status",
                "operator": "$stringExactlyMatches",
                "value": "pending"
              }
            ]
          }
        ]
      }
      ```
      Available operators: `$stringContains`, `$stringDoesNotContain`, `$stringExactlyMatches`, `$stringDoesNotExactlyMatch`, `$stringStartsWith`, `$stringDoesNotStartWith`, `$stringEndsWith`, `$stringDoesNotEndWith`, `$numberGreaterThan`, `$numberLessThan`, `$numberEquals`, `$numberDoesNotEqual`, `$dateTimeAfter`, `$dateTimeBefore`, `$dateTimeEquals`, `$booleanTrue`, `$booleanFalse`, `$exists`, `$doesNotExist`
    * `additionalFields` (object, required): Fields - Include fields to update, as an object with keys of Column Names. Use Connect Portal Workflow Settings to allow users to select a Column Mapping.
      ```json
      {
        "columnName1": "newValue1",
        "columnName2": "newValue2",
        "columnName3": "newValue3",
        "columnName4": "newValue4"
      }
      ```
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Google Sheets Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Google Sheets tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Google Sheets capabilities
sheets_agent = Agent(
    role="Data Manager",
    goal="Manage spreadsheet data and track information efficiently",
    backstory="An AI assistant specialized in data management and spreadsheet operations.",
    tools=[enterprise_tools]
)

# Task to add new data to a spreadsheet
data_entry_task = Task(
    description="Add a new customer record to the customer database spreadsheet with name, email, and signup date",
    agent=sheets_agent,
    expected_output="New customer record added successfully to the spreadsheet"
)

# Run the task
crew = Crew(
    agents=[sheets_agent],
    tasks=[data_entry_task]
)

crew.kickoff()
```

### Filtering Specific Google Sheets Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Google Sheets tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["google_sheets_get_row", "google_sheets_create_row"]
)

data_collector = Agent(
    role="Data Collector",
    goal="Collect and organize data in spreadsheets",
    backstory="An AI assistant that focuses on data collection and organization.",
    tools=enterprise_tools
)

# Task to collect and organize data
data_collection = Task(
    description="Retrieve current inventory data and add new product entries to the inventory spreadsheet",
    agent=data_collector,
    expected_output="Inventory data retrieved and new products added successfully"
)

crew = Crew(
    agents=[data_collector],
    tasks=[data_collection]
)

crew.kickoff()
```

### Data Analysis and Reporting

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

data_analyst = Agent(
    role="Data Analyst",
    goal="Analyze spreadsheet data and generate insights",
    backstory="An experienced data analyst who extracts insights from spreadsheet data.",
    tools=[enterprise_tools]
)

# Task to analyze data and create reports
analysis_task = Task(
    description="""
    1. Retrieve all sales data from the current month's spreadsheet
    2. Analyze the data for trends and patterns
    3. Create a summary report in a new row with key metrics
    """,
    agent=data_analyst,
    expected_output="Sales data analyzed and summary report created with key insights"
)

crew = Crew(
    agents=[data_analyst],
    tasks=[analysis_task]
)

crew.kickoff()
```

### Automated Data Updates

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

data_updater = Agent(
    role="Data Updater",
    goal="Automatically update and maintain spreadsheet data",
    backstory="An AI assistant that maintains data accuracy and updates records automatically.",
    tools=[enterprise_tools]
)

# Task to update data based on conditions
update_task = Task(
    description="""
    1. Find all pending orders in the orders spreadsheet
    2. Update their status to 'processing'
    3. Add a timestamp for when the status was updated
    4. Log the changes in a separate tracking sheet
    """,
    agent=data_updater,
    expected_output="All pending orders updated to processing status with timestamps logged"
)

crew = Crew(
    agents=[data_updater],
    tasks=[update_task]
)

crew.kickoff()
```

### Complex Data Management Workflow

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

workflow_manager = Agent(
    role="Data Workflow Manager",
    goal="Manage complex data workflows across multiple spreadsheets",
    backstory="An AI assistant that orchestrates complex data operations across multiple spreadsheets.",
    tools=[enterprise_tools]
)

# Complex workflow task
workflow_task = Task(
    description="""
    1. Get all customer data from the main customer spreadsheet
    2. Create monthly summary entries for active customers
    3. Update customer status based on activity in the last 30 days
    4. Generate a monthly report with customer metrics
    5. Archive inactive customer records to a separate sheet
    """,
    agent=workflow_manager,
    expected_output="Monthly customer workflow completed with updated statuses and generated reports"
)

crew = Crew(
    agents=[workflow_manager],
    tasks=[workflow_task]
)

crew.kickoff()
```

## Troubleshooting

### Common Issues

**Permission Errors**

* Ensure your Google account has edit access to the target spreadsheets
* Verify that the OAuth connection includes required scopes for Google Sheets API
* Check that spreadsheets are shared with the authenticated account

**Spreadsheet Structure Issues**

* Ensure worksheets have proper column headers before creating or updating rows
* Verify that column names in `additionalFields` match the actual column headers
* Check that the specified worksheet exists in the spreadsheet

**Data Type and Format Issues**

* Ensure data values match the expected format for each column
* Use proper date formats for date columns (ISO format recommended)
* Verify that numeric values are properly formatted for number columns

**Filter Formula Issues**

* Ensure filter formulas follow the correct JSON structure for disjunctive normal form
* Use valid field names that match actual column headers
* Test simple filters before building complex multi-condition queries
* Verify that operator types match the data types in the columns

**Row Limits and Performance**

* Be mindful of row limits when using `GOOGLE_SHEETS_GET_ROW`
* Consider pagination for large datasets
* Use specific filters to reduce the amount of data processed

**Update Operations**

* Ensure filter conditions properly identify the intended rows for updates
* Test filter conditions with small datasets before large updates
* Verify that all required fields are included in update operations

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with Google Sheets integration setup or troubleshooting.
</Card>


# HubSpot Integration
Source: https://docs.crewai.com/en/enterprise/integrations/hubspot

Manage companies and contacts in HubSpot with CrewAI.

## Overview

Enable your agents to manage companies and contacts within HubSpot. Create new records and streamline your CRM processes with AI-powered automation.

## Prerequisites

Before using the HubSpot integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription.
* A HubSpot account with appropriate permissions.
* Connected your HubSpot account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors).

## Setting Up HubSpot Integration

### 1. Connect Your HubSpot Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors).
2. Find **HubSpot** in the Authentication Integrations section.
3. Click **Connect** and complete the OAuth flow.
4. Grant the necessary permissions for company and contact management.
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account).

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="HUBSPOT_CREATE_RECORD_COMPANIES">
    **Description:** Create a new company record in HubSpot.

    **Parameters:**

    * `name` (string, required): Name of the company.
    * `domain` (string, optional): Company Domain Name.
    * `industry` (string, optional): Industry. Must be one of the predefined values from HubSpot.
    * `phone` (string, optional): Phone Number.
    * `hubspot_owner_id` (string, optional): Company owner ID.
    * `type` (string, optional): Type of the company. Available values: `PROSPECT`, `PARTNER`, `RESELLER`, `VENDOR`, `OTHER`.
    * `city` (string, optional): City.
    * `state` (string, optional): State/Region.
    * `zip` (string, optional): Postal Code.
    * `numberofemployees` (number, optional): Number of Employees.
    * `annualrevenue` (number, optional): Annual Revenue.
    * `timezone` (string, optional): Time Zone.
    * `description` (string, optional): Description.
    * `linkedin_company_page` (string, optional): LinkedIn Company Page URL.
    * `company_email` (string, optional): Company Email.
    * `first_name` (string, optional): First Name of a contact at the company.
    * `last_name` (string, optional): Last Name of a contact at the company.
    * `about_us` (string, optional): About Us.
    * `hs_csm_sentiment` (string, optional): CSM Sentiment. Available values: `at_risk`, `neutral`, `healthy`.
    * `closedate` (string, optional): Close Date.
    * `hs_keywords` (string, optional): Company Keywords. Must be one of the predefined values.
    * `country` (string, optional): Country/Region.
    * `hs_country_code` (string, optional): Country/Region Code.
    * `hs_employee_range` (string, optional): Employee range.
    * `facebook_company_page` (string, optional): Facebook Company Page URL.
    * `facebookfans` (number, optional): Number of Facebook Fans.
    * `hs_gps_coordinates` (string, optional): GPS Coordinates.
    * `hs_gps_error` (string, optional): GPS Error.
    * `googleplus_page` (string, optional): Google Plus Page URL.
    * `owneremail` (string, optional): HubSpot Owner Email.
    * `ownername` (string, optional): HubSpot Owner Name.
    * `hs_ideal_customer_profile` (string, optional): Ideal Customer Profile Tier. Available values: `tier_1`, `tier_2`, `tier_3`.
    * `hs_industry_group` (string, optional): Industry group.
    * `is_public` (boolean, optional): Is Public.
    * `hs_last_metered_enrichment_timestamp` (string, optional): Last Metered Enrichment Timestamp.
    * `hs_lead_status` (string, optional): Lead Status. Available values: `NEW`, `OPEN`, `IN_PROGRESS`, `OPEN_DEAL`, `UNQUALIFIED`, `ATTEMPTED_TO_CONTACT`, `CONNECTED`, `BAD_TIMING`.
    * `lifecyclestage` (string, optional): Lifecycle Stage. Available values: `subscriber`, `lead`, `marketingqualifiedlead`, `salesqualifiedlead`, `opportunity`, `customer`, `evangelist`, `other`.
    * `linkedinbio` (string, optional): LinkedIn Bio.
    * `hs_linkedin_handle` (string, optional): LinkedIn handle.
    * `hs_live_enrichment_deadline` (string, optional): Live enrichment deadline.
    * `hs_logo_url` (string, optional): Logo URL.
    * `hs_analytics_source` (string, optional): Original Traffic Source.
    * `hs_pinned_engagement_id` (number, optional): Pinned Engagement ID.
    * `hs_quick_context` (string, optional): Quick context.
    * `hs_revenue_range` (string, optional): Revenue range.
    * `hs_state_code` (string, optional): State/Region Code.
    * `address` (string, optional): Street Address.
    * `address2` (string, optional): Street Address 2.
    * `hs_is_target_account` (boolean, optional): Target Account.
    * `hs_target_account` (string, optional): Target Account Tier. Available values: `tier_1`, `tier_2`, `tier_3`.
    * `hs_target_account_recommendation_snooze_time` (string, optional): Target Account Recommendation Snooze Time.
    * `hs_target_account_recommendation_state` (string, optional): Target Account Recommendation State. Available values: `DISMISSED`, `NONE`, `SNOOZED`.
    * `total_money_raised` (string, optional): Total Money Raised.
    * `twitterbio` (string, optional): Twitter Bio.
    * `twitterfollowers` (number, optional): Twitter Followers.
    * `twitterhandle` (string, optional): Twitter Handle.
    * `web_technologies` (string, optional): Web Technologies used. Must be one of the predefined values.
    * `website` (string, optional): Website URL.
    * `founded_year` (string, optional): Year Founded.
  </Accordion>

  <Accordion title="HUBSPOT_CREATE_RECORD_CONTACTS">
    **Description:** Create a new contact record in HubSpot.

    **Parameters:**

    * `email` (string, required): Email address of the contact.
    * `firstname` (string, optional): First Name.
    * `lastname` (string, optional): Last Name.
    * `phone` (string, optional): Phone Number.
    * `hubspot_owner_id` (string, optional): Contact owner.
    * `lifecyclestage` (string, optional): Lifecycle Stage. Available values: `subscriber`, `lead`, `marketingqualifiedlead`, `salesqualifiedlead`, `opportunity`, `customer`, `evangelist`, `other`.
    * `hs_lead_status` (string, optional): Lead Status. Available values: `NEW`, `OPEN`, `IN_PROGRESS`, `OPEN_DEAL`, `UNQUALIFIED`, `ATTEMPTED_TO_CONTACT`, `CONNECTED`, `BAD_TIMING`.
    * `annualrevenue` (string, optional): Annual Revenue.
    * `hs_buying_role` (string, optional): Buying Role.
    * `cc_emails` (string, optional): CC Emails.
    * `ch_customer_id` (string, optional): Chargify Customer ID.
    * `ch_customer_reference` (string, optional): Chargify Customer Reference.
    * `chargify_sites` (string, optional): Chargify Site(s).
    * `city` (string, optional): City.
    * `hs_facebook_ad_clicked` (boolean, optional): Clicked Facebook ad.
    * `hs_linkedin_ad_clicked` (string, optional): Clicked LinkedIn Ad.
    * `hs_clicked_linkedin_ad` (string, optional): Clicked on a LinkedIn Ad.
    * `closedate` (string, optional): Close Date.
    * `company` (string, optional): Company Name.
    * `company_size` (string, optional): Company size.
    * `country` (string, optional): Country/Region.
    * `hs_country_region_code` (string, optional): Country/Region Code.
    * `date_of_birth` (string, optional): Date of birth.
    * `degree` (string, optional): Degree.
    * `hs_email_customer_quarantined_reason` (string, optional): Email address quarantine reason.
    * `hs_role` (string, optional): Employment Role. Must be one of the predefined values.
    * `hs_seniority` (string, optional): Employment Seniority. Must be one of the predefined values.
    * `hs_sub_role` (string, optional): Employment Sub Role. Must be one of the predefined values.
    * `hs_employment_change_detected_date` (string, optional): Employment change detected date.
    * `hs_enriched_email_bounce_detected` (boolean, optional): Enriched Email Bounce Detected.
    * `hs_facebookid` (string, optional): Facebook ID.
    * `hs_facebook_click_id` (string, optional): Facebook click id.
    * `fax` (string, optional): Fax Number.
    * `field_of_study` (string, optional): Field of study.
    * `followercount` (number, optional): Follower Count.
    * `gender` (string, optional): Gender.
    * `hs_google_click_id` (string, optional): Google ad click id.
    * `graduation_date` (string, optional): Graduation date.
    * `owneremail` (string, optional): HubSpot Owner Email (legacy).
    * `ownername` (string, optional): HubSpot Owner Name (legacy).
    * `industry` (string, optional): Industry.
    * `hs_inferred_language_codes` (string, optional): Inferred Language Codes. Must be one of the predefined values.
    * `jobtitle` (string, optional): Job Title.
    * `hs_job_change_detected_date` (string, optional): Job change detected date.
    * `job_function` (string, optional): Job function.
    * `hs_journey_stage` (string, optional): Journey Stage. Must be one of the predefined values.
    * `kloutscoregeneral` (number, optional): Klout Score.
    * `hs_last_metered_enrichment_timestamp` (string, optional): Last Metered Enrichment Timestamp.
    * `hs_latest_source` (string, optional): Latest Traffic Source.
    * `hs_latest_source_timestamp` (string, optional): Latest Traffic Source Date.
    * `hs_legal_basis` (string, optional): Legal basis for processing contact's data.
    * `linkedinbio` (string, optional): LinkedIn Bio.
    * `linkedinconnections` (number, optional): LinkedIn Connections.
    * `hs_linkedin_url` (string, optional): LinkedIn URL.
    * `hs_linkedinid` (string, optional): Linkedin ID.
    * `hs_live_enrichment_deadline` (string, optional): Live enrichment deadline.
    * `marital_status` (string, optional): Marital Status.
    * `hs_content_membership_email` (string, optional): Member email.
    * `hs_content_membership_notes` (string, optional): Membership Notes.
    * `message` (string, optional): Message.
    * `military_status` (string, optional): Military status.
    * `mobilephone` (string, optional): Mobile Phone Number.
    * `numemployees` (string, optional): Number of Employees.
    * `hs_analytics_source` (string, optional): Original Traffic Source.
    * `photo` (string, optional): Photo.
    * `hs_pinned_engagement_id` (number, optional): Pinned engagement ID.
    * `zip` (string, optional): Postal Code.
    * `hs_language` (string, optional): Preferred language. Must be one of the predefined values.
    * `associatedcompanyid` (number, optional): Primary Associated Company ID.
    * `hs_email_optout_survey_reason` (string, optional): Reason for opting out of email.
    * `relationship_status` (string, optional): Relationship Status.
    * `hs_returning_to_office_detected_date` (string, optional): Returning to office detected date.
    * `salutation` (string, optional): Salutation.
    * `school` (string, optional): School.
    * `seniority` (string, optional): Seniority.
    * `hs_feedback_show_nps_web_survey` (boolean, optional): Should be shown an NPS web survey.
    * `start_date` (string, optional): Start date.
    * `state` (string, optional): State/Region.
    * `hs_state_code` (string, optional): State/Region Code.
    * `hs_content_membership_status` (string, optional): Status.
    * `address` (string, optional): Street Address.
    * `tax_exempt` (string, optional): Tax Exempt.
    * `hs_timezone` (string, optional): Time Zone. Must be one of the predefined values.
    * `twitterbio` (string, optional): Twitter Bio.
    * `hs_twitterid` (string, optional): Twitter ID.
    * `twitterprofilephoto` (string, optional): Twitter Profile Photo.
    * `twitterhandle` (string, optional): Twitter Username.
    * `vat_number` (string, optional): VAT Number.
    * `ch_verified` (string, optional): Verified for ACH/eCheck Payments.
    * `website` (string, optional): Website URL.
    * `hs_whatsapp_phone_number` (string, optional): WhatsApp Phone Number.
    * `work_email` (string, optional): Work email.
    * `hs_googleplusid` (string, optional): googleplus ID.
  </Accordion>

  <Accordion title="HUBSPOT_CREATE_RECORD_DEALS">
    **Description:** Create a new deal record in HubSpot.

    **Parameters:**

    * `dealname` (string, required): Name of the deal.
    * `amount` (number, optional): The value of the deal.
    * `dealstage` (string, optional): The pipeline stage of the deal.
    * `pipeline` (string, optional): The pipeline the deal belongs to.
    * `closedate` (string, optional): The date the deal is expected to close.
    * `hubspot_owner_id` (string, optional): The owner of the deal.
    * `dealtype` (string, optional): The type of deal. Available values: `newbusiness`, `existingbusiness`.
    * `description` (string, optional): A description of the deal.
    * `hs_priority` (string, optional): The priority of the deal. Available values: `low`, `medium`, `high`.
  </Accordion>

  <Accordion title="HUBSPOT_CREATE_RECORD_ENGAGEMENTS">
    **Description:** Create a new engagement (e.g., note, email, call, meeting, task) in HubSpot.

    **Parameters:**

    * `engagementType` (string, required): The type of engagement. Available values: `NOTE`, `EMAIL`, `CALL`, `MEETING`, `TASK`.
    * `hubspot_owner_id` (string, optional): The user the activity is assigned to.
    * `hs_timestamp` (string, optional): The date and time of the activity.
    * `hs_note_body` (string, optional): The body of the note. (Used for `NOTE`)
    * `hs_task_subject` (string, optional): The title of the task. (Used for `TASK`)
    * `hs_task_body` (string, optional): The notes for the task. (Used for `TASK`)
    * `hs_task_status` (string, optional): The status of the task. (Used for `TASK`)
    * `hs_meeting_title` (string, optional): The title of the meeting. (Used for `MEETING`)
    * `hs_meeting_body` (string, optional): The description for the meeting. (Used for `MEETING`)
    * `hs_meeting_start_time` (string, optional): The start time of the meeting. (Used for `MEETING`)
    * `hs_meeting_end_time` (string, optional): The end time of the meeting. (Used for `MEETING`)
  </Accordion>

  <Accordion title="HUBSPOT_UPDATE_RECORD_COMPANIES">
    **Description:** Update an existing company record in HubSpot.

    **Parameters:**

    * `recordId` (string, required): The ID of the company to update.
    * `name` (string, optional): Name of the company.
    * `domain` (string, optional): Company Domain Name.
    * `industry` (string, optional): Industry.
    * `phone` (string, optional): Phone Number.
    * `city` (string, optional): City.
    * `state` (string, optional): State/Region.
    * `zip` (string, optional): Postal Code.
    * `numberofemployees` (number, optional): Number of Employees.
    * `annualrevenue` (number, optional): Annual Revenue.
    * `description` (string, optional): Description.
  </Accordion>

  <Accordion title="HUBSPOT_CREATE_RECORD_ANY">
    **Description:** Create a record for a specified object type in HubSpot.

    **Parameters:**

    * `recordType` (string, required): The object type ID of the custom object.
    * Additional parameters depend on the custom object's schema.
  </Accordion>

  <Accordion title="HUBSPOT_UPDATE_RECORD_CONTACTS">
    **Description:** Update an existing contact record in HubSpot.

    **Parameters:**

    * `recordId` (string, required): The ID of the contact to update.
    * `firstname` (string, optional): First Name.
    * `lastname` (string, optional): Last Name.
    * `email` (string, optional): Email address.
    * `phone` (string, optional): Phone Number.
    * `company` (string, optional): Company Name.
    * `jobtitle` (string, optional): Job Title.
    * `lifecyclestage` (string, optional): Lifecycle Stage.
  </Accordion>

  <Accordion title="HUBSPOT_UPDATE_RECORD_DEALS">
    **Description:** Update an existing deal record in HubSpot.

    **Parameters:**

    * `recordId` (string, required): The ID of the deal to update.
    * `dealname` (string, optional): Name of the deal.
    * `amount` (number, optional): The value of the deal.
    * `dealstage` (string, optional): The pipeline stage of the deal.
    * `pipeline` (string, optional): The pipeline the deal belongs to.
    * `closedate` (string, optional): The date the deal is expected to close.
    * `dealtype` (string, optional): The type of deal.
  </Accordion>

  <Accordion title="HUBSPOT_UPDATE_RECORD_ENGAGEMENTS">
    **Description:** Update an existing engagement in HubSpot.

    **Parameters:**

    * `recordId` (string, required): The ID of the engagement to update.
    * `hs_note_body` (string, optional): The body of the note.
    * `hs_task_subject` (string, optional): The title of the task.
    * `hs_task_body` (string, optional): The notes for the task.
    * `hs_task_status` (string, optional): The status of the task.
  </Accordion>

  <Accordion title="HUBSPOT_UPDATE_RECORD_ANY">
    **Description:** Update a record for a specified object type in HubSpot.

    **Parameters:**

    * `recordId` (string, required): The ID of the record to update.
    * `recordType` (string, required): The object type ID of the custom object.
    * Additional parameters depend on the custom object's schema.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORDS_COMPANIES">
    **Description:** Get a list of company records from HubSpot.

    **Parameters:**

    * `paginationParameters` (object, optional): Use `pageCursor` to fetch subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORDS_CONTACTS">
    **Description:** Get a list of contact records from HubSpot.

    **Parameters:**

    * `paginationParameters` (object, optional): Use `pageCursor` to fetch subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORDS_DEALS">
    **Description:** Get a list of deal records from HubSpot.

    **Parameters:**

    * `paginationParameters` (object, optional): Use `pageCursor` to fetch subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORDS_ENGAGEMENTS">
    **Description:** Get a list of engagement records from HubSpot.

    **Parameters:**

    * `objectName` (string, required): The type of engagement to fetch (e.g., "notes").
    * `paginationParameters` (object, optional): Use `pageCursor` to fetch subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORDS_ANY">
    **Description:** Get a list of records for any specified object type in HubSpot.

    **Parameters:**

    * `recordType` (string, required): The object type ID of the custom object.
    * `paginationParameters` (object, optional): Use `pageCursor` to fetch subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORD_BY_ID_COMPANIES">
    **Description:** Get a single company record by its ID.

    **Parameters:**

    * `recordId` (string, required): The ID of the company to retrieve.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORD_BY_ID_CONTACTS">
    **Description:** Get a single contact record by its ID.

    **Parameters:**

    * `recordId` (string, required): The ID of the contact to retrieve.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORD_BY_ID_DEALS">
    **Description:** Get a single deal record by its ID.

    **Parameters:**

    * `recordId` (string, required): The ID of the deal to retrieve.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORD_BY_ID_ENGAGEMENTS">
    **Description:** Get a single engagement record by its ID.

    **Parameters:**

    * `recordId` (string, required): The ID of the engagement to retrieve.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORD_BY_ID_ANY">
    **Description:** Get a single record of any specified object type by its ID.

    **Parameters:**

    * `recordType` (string, required): The object type ID of the custom object.
    * `recordId` (string, required): The ID of the record to retrieve.
  </Accordion>

  <Accordion title="HUBSPOT_SEARCH_RECORDS_COMPANIES">
    **Description:** Search for company records in HubSpot using a filter formula.

    **Parameters:**

    * `filterFormula` (object, optional): A filter in disjunctive normal form (OR of ANDs).
    * `paginationParameters` (object, optional): Use `pageCursor` to fetch subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_SEARCH_RECORDS_CONTACTS">
    **Description:** Search for contact records in HubSpot using a filter formula.

    **Parameters:**

    * `filterFormula` (object, optional): A filter in disjunctive normal form (OR of ANDs).
    * `paginationParameters` (object, optional): Use `pageCursor` to fetch subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_SEARCH_RECORDS_DEALS">
    **Description:** Search for deal records in HubSpot using a filter formula.

    **Parameters:**

    * `filterFormula` (object, optional): A filter in disjunctive normal form (OR of ANDs).
    * `paginationParameters` (object, optional): Use `pageCursor` to fetch subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_SEARCH_RECORDS_ENGAGEMENTS">
    **Description:** Search for engagement records in HubSpot using a filter formula.

    **Parameters:**

    * `engagementFilterFormula` (object, optional): A filter for engagements.
    * `paginationParameters` (object, optional): Use `pageCursor` to fetch subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_SEARCH_RECORDS_ANY">
    **Description:** Search for records of any specified object type in HubSpot.

    **Parameters:**

    * `recordType` (string, required): The object type ID to search.
    * `filterFormula` (string, optional): The filter formula to apply.
    * `paginationParameters` (object, optional): Use `pageCursor` to fetch subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_DELETE_RECORD_COMPANIES">
    **Description:** Delete a company record by its ID.

    **Parameters:**

    * `recordId` (string, required): The ID of the company to delete.
  </Accordion>

  <Accordion title="HUBSPOT_DELETE_RECORD_CONTACTS">
    **Description:** Delete a contact record by its ID.

    **Parameters:**

    * `recordId` (string, required): The ID of the contact to delete.
  </Accordion>

  <Accordion title="HUBSPOT_DELETE_RECORD_DEALS">
    **Description:** Delete a deal record by its ID.

    **Parameters:**

    * `recordId` (string, required): The ID of the deal to delete.
  </Accordion>

  <Accordion title="HUBSPOT_DELETE_RECORD_ENGAGEMENTS">
    **Description:** Delete an engagement record by its ID.

    **Parameters:**

    * `recordId` (string, required): The ID of the engagement to delete.
  </Accordion>

  <Accordion title="HUBSPOT_DELETE_RECORD_ANY">
    **Description:** Delete a record of any specified object type by its ID.

    **Parameters:**

    * `recordType` (string, required): The object type ID of the custom object.
    * `recordId` (string, required): The ID of the record to delete.
  </Accordion>

  <Accordion title="HUBSPOT_GET_CONTACTS_BY_LIST_ID">
    **Description:** Get contacts from a specific list by its ID.

    **Parameters:**

    * `listId` (string, required): The ID of the list to get contacts from.
    * `paginationParameters` (object, optional): Use `pageCursor` for subsequent pages.
  </Accordion>

  <Accordion title="HUBSPOT_DESCRIBE_ACTION_SCHEMA">
    **Description:** Get the expected schema for a given object type and operation.

    **Parameters:**

    * `recordType` (string, required): The object type ID (e.g., 'companies').
    * `operation` (string, required): The operation type (e.g., 'CREATE\_RECORD').
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic HubSpot Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (HubSpot tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with HubSpot capabilities
hubspot_agent = Agent(
    role="CRM Manager",
    goal="Manage company and contact records in HubSpot",
    backstory="An AI assistant specialized in CRM management.",
    tools=[enterprise_tools]
)

# Task to create a new company
create_company_task = Task(
    description="Create a new company in HubSpot with name 'Innovate Corp' and domain 'innovatecorp.com'.",
    agent=hubspot_agent,
    expected_output="Company created successfully with confirmation"
)

# Run the task
crew = Crew(
    agents=[hubspot_agent],
    tasks=[create_company_task]
)

crew.kickoff()
```

### Filtering Specific HubSpot Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only the tool to create contacts
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["hubspot_create_record_contacts"]
)

contact_creator = Agent(
    role="Contact Creator",
    goal="Create new contacts in HubSpot",
    backstory="An AI assistant that focuses on creating new contact entries in the CRM.",
    tools=[enterprise_tools]
)

# Task to create a contact
create_contact = Task(
    description="Create a new contact for 'John Doe' with email 'john.doe@example.com'.",
    agent=contact_creator,
    expected_output="Contact created successfully in HubSpot."
)

crew = Crew(
    agents=[contact_creator],
    tasks=[create_contact]
)

crew.kickoff()
```

### Contact Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

crm_manager = Agent(
    role="CRM Manager",
    goal="Manage and organize HubSpot contacts efficiently.",
    backstory="An experienced CRM manager who maintains an organized contact database.",
    tools=[enterprise_tools]
)

# Task to manage contacts
contact_task = Task(
    description="Create a new contact for 'Jane Smith' at 'Global Tech Inc.' with email 'jane.smith@globaltech.com'.",
    agent=crm_manager,
    expected_output="Contact database updated with the new contact."
)

crew = Crew(
    agents=[crm_manager],
    tasks=[contact_task]
)

crew.kickoff()
```

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with HubSpot integration setup or troubleshooting.
</Card>


# Jira Integration
Source: https://docs.crewai.com/en/enterprise/integrations/jira

Issue tracking and project management with Jira integration for CrewAI.

## Overview

Enable your agents to manage issues, projects, and workflows through Jira. Create and update issues, track project progress, manage assignments, and streamline your project management with AI-powered automation.

## Prerequisites

Before using the Jira integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Jira account with appropriate project permissions
* Connected your Jira account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors)

## Setting Up Jira Integration

### 1. Connect Your Jira Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors)
2. Find **Jira** in the Authentication Integrations section
3. Click **Connect** and complete the OAuth flow
4. Grant the necessary permissions for issue and project management
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account)

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="JIRA_CREATE_ISSUE">
    **Description:** Create an issue in Jira.

    **Parameters:**

    * `summary` (string, required): Summary - A brief one-line summary of the issue. (example: "The printer stopped working").
    * `project` (string, optional): Project - The project which the issue belongs to. Defaults to the user's first project if not provided. Use Connect Portal Workflow Settings to allow users to select a Project.
    * `issueType` (string, optional): Issue type - Defaults to Task if not provided.
    * `jiraIssueStatus` (string, optional): Status - Defaults to the project's first status if not provided.
    * `assignee` (string, optional): Assignee - Defaults to the authenticated user if not provided.
    * `descriptionType` (string, optional): Description Type - Select the Description Type.
      * Options: `description`, `descriptionJSON`
    * `description` (string, optional): Description - A detailed description of the issue. This field appears only when 'descriptionType' = 'description'.
    * `additionalFields` (string, optional): Additional Fields - Specify any other fields that should be included in JSON format. Use Connect Portal Workflow Settings to allow users to select which Issue Fields to update.
      ```json
      {
        "customfield_10001": "value"
      }
      ```
  </Accordion>

  <Accordion title="JIRA_UPDATE_ISSUE">
    **Description:** Update an issue in Jira.

    **Parameters:**

    * `issueKey` (string, required): Issue Key (example: "TEST-1234").
    * `summary` (string, optional): Summary - A brief one-line summary of the issue. (example: "The printer stopped working").
    * `issueType` (string, optional): Issue type - Use Connect Portal Workflow Settings to allow users to select an Issue Type.
    * `jiraIssueStatus` (string, optional): Status - Use Connect Portal Workflow Settings to allow users to select a Status.
    * `assignee` (string, optional): Assignee - Use Connect Portal Workflow Settings to allow users to select an Assignee.
    * `descriptionType` (string, optional): Description Type - Select the Description Type.
      * Options: `description`, `descriptionJSON`
    * `description` (string, optional): Description - A detailed description of the issue. This field appears only when 'descriptionType' = 'description'.
    * `additionalFields` (string, optional): Additional Fields - Specify any other fields that should be included in JSON format.
  </Accordion>

  <Accordion title="JIRA_GET_ISSUE_BY_KEY">
    **Description:** Get an issue by key in Jira.

    **Parameters:**

    * `issueKey` (string, required): Issue Key (example: "TEST-1234").
  </Accordion>

  <Accordion title="JIRA_FILTER_ISSUES">
    **Description:** Search issues in Jira using filters.

    **Parameters:**

    * `jqlQuery` (object, optional): A filter in disjunctive normal form - OR of AND groups of single conditions.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "status",
                "operator": "$stringExactlyMatches",
                "value": "Open"
              }
            ]
          }
        ]
      }
      ```
      Available operators: `$stringExactlyMatches`, `$stringDoesNotExactlyMatch`, `$stringIsIn`, `$stringIsNotIn`, `$stringContains`, `$stringDoesNotContain`, `$stringGreaterThan`, `$stringLessThan`
    * `limit` (string, optional): Limit results - Limit the maximum number of issues to return. Defaults to 10 if left blank.
  </Accordion>

  <Accordion title="JIRA_SEARCH_BY_JQL">
    **Description:** Search issues by JQL in Jira.

    **Parameters:**

    * `jqlQuery` (string, required): JQL Query (example: "project = PROJECT").
    * `paginationParameters` (object, optional): Pagination parameters for paginated results.
      ```json
      {
        "pageCursor": "cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="JIRA_UPDATE_ISSUE_ANY">
    **Description:** Update any issue in Jira. Use DESCRIBE\_ACTION\_SCHEMA to get properties schema for this function.

    **Parameters:** No specific parameters - use JIRA\_DESCRIBE\_ACTION\_SCHEMA first to get the expected schema.
  </Accordion>

  <Accordion title="JIRA_DESCRIBE_ACTION_SCHEMA">
    **Description:** Get the expected schema for an issue type. Use this function first if no other function matches the issue type you want to operate on.

    **Parameters:**

    * `issueTypeId` (string, required): Issue Type ID.
    * `projectKey` (string, required): Project key.
    * `operation` (string, required): Operation Type value, for example CREATE\_ISSUE or UPDATE\_ISSUE.
  </Accordion>

  <Accordion title="JIRA_GET_PROJECTS">
    **Description:** Get Projects in Jira.

    **Parameters:**

    * `paginationParameters` (object, optional): Pagination Parameters.
      ```json
      {
        "pageCursor": "cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="JIRA_GET_ISSUE_TYPES_BY_PROJECT">
    **Description:** Get Issue Types by project in Jira.

    **Parameters:**

    * `project` (string, required): Project key.
  </Accordion>

  <Accordion title="JIRA_GET_ISSUE_TYPES">
    **Description:** Get all Issue Types in Jira.

    **Parameters:** None required.
  </Accordion>

  <Accordion title="JIRA_GET_ISSUE_STATUS_BY_PROJECT">
    **Description:** Get issue statuses for a given project.

    **Parameters:**

    * `project` (string, required): Project key.
  </Accordion>

  <Accordion title="JIRA_GET_ALL_ASSIGNEES_BY_PROJECT">
    **Description:** Get assignees for a given project.

    **Parameters:**

    * `project` (string, required): Project key.
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Jira Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Jira tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Jira capabilities
jira_agent = Agent(
    role="Issue Manager",
    goal="Manage Jira issues and track project progress efficiently",
    backstory="An AI assistant specialized in issue tracking and project management.",
    tools=[enterprise_tools]
)

# Task to create a bug report
create_bug_task = Task(
    description="Create a bug report for the login functionality with high priority and assign it to the development team",
    agent=jira_agent,
    expected_output="Bug report created successfully with issue key"
)

# Run the task
crew = Crew(
    agents=[jira_agent],
    tasks=[create_bug_task]
)

crew.kickoff()
```

### Filtering Specific Jira Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Jira tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["jira_create_issue", "jira_update_issue", "jira_search_by_jql"]
)

issue_coordinator = Agent(
    role="Issue Coordinator",
    goal="Create and manage Jira issues efficiently",
    backstory="An AI assistant that focuses on issue creation and management.",
    tools=enterprise_tools
)

# Task to manage issue workflow
issue_workflow = Task(
    description="Create a feature request issue and update the status of related issues",
    agent=issue_coordinator,
    expected_output="Feature request created and related issues updated"
)

crew = Crew(
    agents=[issue_coordinator],
    tasks=[issue_workflow]
)

crew.kickoff()
```

### Project Analysis and Reporting

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

project_analyst = Agent(
    role="Project Analyst",
    goal="Analyze project data and generate insights from Jira",
    backstory="An experienced project analyst who extracts insights from project management data.",
    tools=[enterprise_tools]
)

# Task to analyze project status
analysis_task = Task(
    description="""
    1. Get all projects and their issue types
    2. Search for all open issues across projects
    3. Analyze issue distribution by status and assignee
    4. Create a summary report issue with findings
    """,
    agent=project_analyst,
    expected_output="Project analysis completed with summary report created"
)

crew = Crew(
    agents=[project_analyst],
    tasks=[analysis_task]
)

crew.kickoff()
```

### Automated Issue Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

automation_manager = Agent(
    role="Automation Manager",
    goal="Automate issue management and workflow processes",
    backstory="An AI assistant that automates repetitive issue management tasks.",
    tools=[enterprise_tools]
)

# Task to automate issue management
automation_task = Task(
    description="""
    1. Search for all unassigned issues using JQL
    2. Get available assignees for each project
    3. Automatically assign issues based on workload and expertise
    4. Update issue priorities based on age and type
    5. Create weekly sprint planning issues
    """,
    agent=automation_manager,
    expected_output="Issues automatically assigned and sprint planning issues created"
)

crew = Crew(
    agents=[automation_manager],
    tasks=[automation_task]
)

crew.kickoff()
```

### Advanced Schema-Based Operations

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

schema_specialist = Agent(
    role="Schema Specialist",
    goal="Handle complex Jira operations using dynamic schemas",
    backstory="An AI assistant that can work with dynamic Jira schemas and custom issue types.",
    tools=[enterprise_tools]
)

# Task using schema-based operations
schema_task = Task(
    description="""
    1. Get all projects and their custom issue types
    2. For each custom issue type, describe the action schema
    3. Create issues using the dynamic schema for complex custom fields
    4. Update issues with custom field values based on business rules
    """,
    agent=schema_specialist,
    expected_output="Custom issues created and updated using dynamic schemas"
)

crew = Crew(
    agents=[schema_specialist],
    tasks=[schema_task]
)

crew.kickoff()
```

## Troubleshooting

### Common Issues

**Permission Errors**

* Ensure your Jira account has necessary permissions for the target projects
* Verify that the OAuth connection includes required scopes for Jira API
* Check if you have create/edit permissions for issues in the specified projects

**Invalid Project or Issue Keys**

* Double-check project keys and issue keys for correct format (e.g., "PROJ-123")
* Ensure projects exist and are accessible to your account
* Verify that issue keys reference existing issues

**Issue Type and Status Issues**

* Use JIRA\_GET\_ISSUE\_TYPES\_BY\_PROJECT to get valid issue types for a project
* Use JIRA\_GET\_ISSUE\_STATUS\_BY\_PROJECT to get valid statuses
* Ensure issue types and statuses are available in the target project

**JQL Query Problems**

* Test JQL queries in Jira's issue search before using in API calls
* Ensure field names in JQL are spelled correctly and exist in your Jira instance
* Use proper JQL syntax for complex queries

**Custom Fields and Schema Issues**

* Use JIRA\_DESCRIBE\_ACTION\_SCHEMA to get the correct schema for complex issue types
* Ensure custom field IDs are correct (e.g., "customfield\_10001")
* Verify that custom fields are available in the target project and issue type

**Filter Formula Issues**

* Ensure filter formulas follow the correct JSON structure for disjunctive normal form
* Use valid field names that exist in your Jira configuration
* Test simple filters before building complex multi-condition queries

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with Jira integration setup or troubleshooting.
</Card>


# Linear Integration
Source: https://docs.crewai.com/en/enterprise/integrations/linear

Software project and bug tracking with Linear integration for CrewAI.

## Overview

Enable your agents to manage issues, projects, and development workflows through Linear. Create and update issues, manage project timelines, organize teams, and streamline your software development process with AI-powered automation.

## Prerequisites

Before using the Linear integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Linear account with appropriate workspace permissions
* Connected your Linear account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors)

## Setting Up Linear Integration

### 1. Connect Your Linear Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors)
2. Find **Linear** in the Authentication Integrations section
3. Click **Connect** and complete the OAuth flow
4. Grant the necessary permissions for issue and project management
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account)

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="LINEAR_CREATE_ISSUE">
    **Description:** Create a new issue in Linear.

    **Parameters:**

    * `teamId` (string, required): Team ID - Specify the Team ID of the parent for this new issue. Use Connect Portal Workflow Settings to allow users to select a Team ID. (example: "a70bdf0f-530a-4887-857d-46151b52b47c").
    * `title` (string, required): Title - Specify a title for this issue.
    * `description` (string, optional): Description - Specify a description for this issue.
    * `statusId` (string, optional): Status - Specify the state or status of this issue.
    * `priority` (string, optional): Priority - Specify the priority of this issue as an integer.
    * `dueDate` (string, optional): Due Date - Specify the due date of this issue in ISO 8601 format.
    * `cycleId` (string, optional): Cycle ID - Specify the cycle associated with this issue.
    * `additionalFields` (object, optional): Additional Fields.
      ```json
      {
        "assigneeId": "a70bdf0f-530a-4887-857d-46151b52b47c",
        "labelIds": ["a70bdf0f-530a-4887-857d-46151b52b47c"]
      }
      ```
  </Accordion>

  <Accordion title="LINEAR_UPDATE_ISSUE">
    **Description:** Update an issue in Linear.

    **Parameters:**

    * `issueId` (string, required): Issue ID - Specify the Issue ID of the issue to update. (example: "90fbc706-18cd-42c9-ae66-6bd344cc8977").
    * `title` (string, optional): Title - Specify a title for this issue.
    * `description` (string, optional): Description - Specify a description for this issue.
    * `statusId` (string, optional): Status - Specify the state or status of this issue.
    * `priority` (string, optional): Priority - Specify the priority of this issue as an integer.
    * `dueDate` (string, optional): Due Date - Specify the due date of this issue in ISO 8601 format.
    * `cycleId` (string, optional): Cycle ID - Specify the cycle associated with this issue.
    * `additionalFields` (object, optional): Additional Fields.
      ```json
      {
        "assigneeId": "a70bdf0f-530a-4887-857d-46151b52b47c",
        "labelIds": ["a70bdf0f-530a-4887-857d-46151b52b47c"]
      }
      ```
  </Accordion>

  <Accordion title="LINEAR_GET_ISSUE_BY_ID">
    **Description:** Get an issue by ID in Linear.

    **Parameters:**

    * `issueId` (string, required): Issue ID - Specify the record ID of the issue to fetch. (example: "90fbc706-18cd-42c9-ae66-6bd344cc8977").
  </Accordion>

  <Accordion title="LINEAR_GET_ISSUE_BY_ISSUE_IDENTIFIER">
    **Description:** Get an issue by issue identifier in Linear.

    **Parameters:**

    * `externalId` (string, required): External ID - Specify the human-readable Issue identifier of the issue to fetch. (example: "ABC-1").
  </Accordion>

  <Accordion title="LINEAR_SEARCH_ISSUE">
    **Description:** Search issues in Linear.

    **Parameters:**

    * `queryTerm` (string, required): Query Term - The search term to look for.
    * `issueFilterFormula` (object, optional): A filter in disjunctive normal form - OR of AND groups of single conditions.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "title",
                "operator": "$stringContains",
                "value": "bug"
              }
            ]
          }
        ]
      }
      ```
      Available fields: `title`, `number`, `project`, `createdAt`
      Available operators: `$stringExactlyMatches`, `$stringDoesNotExactlyMatch`, `$stringIsIn`, `$stringIsNotIn`, `$stringStartsWith`, `$stringDoesNotStartWith`, `$stringEndsWith`, `$stringDoesNotEndWith`, `$stringContains`, `$stringDoesNotContain`, `$stringGreaterThan`, `$stringLessThan`, `$numberGreaterThanOrEqualTo`, `$numberLessThanOrEqualTo`, `$numberGreaterThan`, `$numberLessThan`, `$dateTimeAfter`, `$dateTimeBefore`
  </Accordion>

  <Accordion title="LINEAR_DELETE_ISSUE">
    **Description:** Delete an issue in Linear.

    **Parameters:**

    * `issueId` (string, required): Issue ID - Specify the record ID of the issue to delete. (example: "90fbc706-18cd-42c9-ae66-6bd344cc8977").
  </Accordion>

  <Accordion title="LINEAR_ARCHIVE_ISSUE">
    **Description:** Archive an issue in Linear.

    **Parameters:**

    * `issueId` (string, required): Issue ID - Specify the record ID of the issue to archive. (example: "90fbc706-18cd-42c9-ae66-6bd344cc8977").
  </Accordion>

  <Accordion title="LINEAR_CREATE_SUB_ISSUE">
    **Description:** Create a sub-issue in Linear.

    **Parameters:**

    * `parentId` (string, required): Parent ID - Specify the Issue ID for the parent of this new issue.
    * `teamId` (string, required): Team ID - Specify the Team ID of the parent for this new sub-issue. Use Connect Portal Workflow Settings to allow users to select a Team ID. (example: "a70bdf0f-530a-4887-857d-46151b52b47c").
    * `title` (string, required): Title - Specify a title for this issue.
    * `description` (string, optional): Description - Specify a description for this issue.
    * `additionalFields` (object, optional): Additional Fields.
      ```json
      {
        "lead": "linear_user_id"
      }
      ```
  </Accordion>

  <Accordion title="LINEAR_CREATE_PROJECT">
    **Description:** Create a new project in Linear.

    **Parameters:**

    * `teamIds` (object, required): Team ID - Specify the team ID(s) this project is associated with as a string or a JSON array. Use Connect Portal User Settings to allow your user to select a Team ID.
      ```json
      [
        "a70bdf0f-530a-4887-857d-46151b52b47c",
        "4ac7..."
      ]
      ```
    * `projectName` (string, required): Project Name - Specify the name of the project. (example: "My Linear Project").
    * `description` (string, optional): Project Description - Specify a description for this project.
    * `additionalFields` (object, optional): Additional Fields.
      ```json
      {
        "state": "planned",
        "description": ""
      }
      ```
  </Accordion>

  <Accordion title="LINEAR_UPDATE_PROJECT">
    **Description:** Update a project in Linear.

    **Parameters:**

    * `projectId` (string, required): Project ID - Specify the ID of the project to update. (example: "a6634484-6061-4ac7-9739-7dc5e52c796b").
    * `projectName` (string, optional): Project Name - Specify the name of the project to update. (example: "My Linear Project").
    * `description` (string, optional): Project Description - Specify a description for this project.
    * `additionalFields` (object, optional): Additional Fields.
      ```json
      {
        "state": "planned",
        "description": ""
      }
      ```
  </Accordion>

  <Accordion title="LINEAR_GET_PROJECT_BY_ID">
    **Description:** Get a project by ID in Linear.

    **Parameters:**

    * `projectId` (string, required): Project ID - Specify the Project ID of the project to fetch. (example: "a6634484-6061-4ac7-9739-7dc5e52c796b").
  </Accordion>

  <Accordion title="LINEAR_DELETE_PROJECT">
    **Description:** Delete a project in Linear.

    **Parameters:**

    * `projectId` (string, required): Project ID - Specify the Project ID of the project to delete. (example: "a6634484-6061-4ac7-9739-7dc5e52c796b").
  </Accordion>

  <Accordion title="LINEAR_SEARCH_TEAMS">
    **Description:** Search teams in Linear.

    **Parameters:**

    * `teamFilterFormula` (object, optional): A filter in disjunctive normal form - OR of AND groups of single conditions.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "name",
                "operator": "$stringContains",
                "value": "Engineering"
              }
            ]
          }
        ]
      }
      ```
      Available fields: `id`, `name`
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Linear Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Linear tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Linear capabilities
linear_agent = Agent(
    role="Development Manager",
    goal="Manage Linear issues and track development progress efficiently",
    backstory="An AI assistant specialized in software development project management.",
    tools=[enterprise_tools]
)

# Task to create a bug report
create_bug_task = Task(
    description="Create a high-priority bug report for the authentication system and assign it to the backend team",
    agent=linear_agent,
    expected_output="Bug report created successfully with issue ID"
)

# Run the task
crew = Crew(
    agents=[linear_agent],
    tasks=[create_bug_task]
)

crew.kickoff()
```

### Filtering Specific Linear Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Linear tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["linear_create_issue", "linear_update_issue", "linear_search_issue"]
)

issue_manager = Agent(
    role="Issue Manager",
    goal="Create and manage Linear issues efficiently",
    backstory="An AI assistant that focuses on issue creation and lifecycle management.",
    tools=enterprise_tools
)

# Task to manage issue workflow
issue_workflow = Task(
    description="Create a feature request issue and update the status of related issues to reflect current progress",
    agent=issue_manager,
    expected_output="Feature request created and related issues updated"
)

crew = Crew(
    agents=[issue_manager],
    tasks=[issue_workflow]
)

crew.kickoff()
```

### Project and Team Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

project_coordinator = Agent(
    role="Project Coordinator",
    goal="Coordinate projects and teams in Linear efficiently",
    backstory="An experienced project coordinator who manages development cycles and team workflows.",
    tools=[enterprise_tools]
)

# Task to coordinate project setup
project_coordination = Task(
    description="""
    1. Search for engineering teams in Linear
    2. Create a new project for Q2 feature development
    3. Associate the project with relevant teams
    4. Create initial project milestones as issues
    """,
    agent=project_coordinator,
    expected_output="Q2 project created with teams assigned and initial milestones established"
)

crew = Crew(
    agents=[project_coordinator],
    tasks=[project_coordination]
)

crew.kickoff()
```

### Issue Hierarchy and Sub-task Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

task_organizer = Agent(
    role="Task Organizer",
    goal="Organize complex issues into manageable sub-tasks",
    backstory="An AI assistant that breaks down complex development work into organized sub-tasks.",
    tools=[enterprise_tools]
)

# Task to create issue hierarchy
hierarchy_task = Task(
    description="""
    1. Search for large feature issues that need to be broken down
    2. For each complex issue, create sub-issues for different components
    3. Update the parent issues with proper descriptions and links to sub-issues
    4. Assign sub-issues to appropriate team members based on expertise
    """,
    agent=task_organizer,
    expected_output="Complex issues broken down into manageable sub-tasks with proper assignments"
)

crew = Crew(
    agents=[task_organizer],
    tasks=[hierarchy_task]
)

crew.kickoff()
```

### Automated Development Workflow

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

workflow_automator = Agent(
    role="Workflow Automator",
    goal="Automate development workflow processes in Linear",
    backstory="An AI assistant that automates repetitive development workflow tasks.",
    tools=[enterprise_tools]
)

# Complex workflow automation task
automation_task = Task(
    description="""
    1. Search for issues that have been in progress for more than 7 days
    2. Update their priorities based on due dates and project importance
    3. Create weekly sprint planning issues for each team
    4. Archive completed issues from the previous cycle
    5. Generate project status reports as new issues
    """,
    agent=workflow_automator,
    expected_output="Development workflow automated with updated priorities, sprint planning, and status reports"
)

crew = Crew(
    agents=[workflow_automator],
    tasks=[automation_task]
)

crew.kickoff()
```

## Troubleshooting

### Common Issues

**Permission Errors**

* Ensure your Linear account has necessary permissions for the target workspace
* Verify that the OAuth connection includes required scopes for Linear API
* Check if you have create/edit permissions for issues and projects in the workspace

**Invalid IDs and References**

* Double-check team IDs, issue IDs, and project IDs for correct UUID format
* Ensure referenced entities (teams, projects, cycles) exist and are accessible
* Verify that issue identifiers follow the correct format (e.g., "ABC-1")

**Team and Project Association Issues**

* Use LINEAR\_SEARCH\_TEAMS to get valid team IDs before creating issues or projects
* Ensure teams exist and are active in your workspace
* Verify that team IDs are properly formatted as UUIDs

**Issue Status and Priority Problems**

* Check that status IDs reference valid workflow states for the team
* Ensure priority values are within the valid range for your Linear configuration
* Verify that custom fields and labels exist before referencing them

**Date and Time Format Issues**

* Use ISO 8601 format for due dates and timestamps
* Ensure time zones are handled correctly for due date calculations
* Verify that date values are valid and in the future for due dates

**Search and Filter Issues**

* Ensure search queries are properly formatted and not empty
* Use valid field names in filter formulas: `title`, `number`, `project`, `createdAt`
* Test simple filters before building complex multi-condition queries
* Verify that operator types match the data types of the fields being filtered

**Sub-issue Creation Problems**

* Ensure parent issue IDs are valid and accessible
* Verify that the team ID for sub-issues matches or is compatible with the parent issue's team
* Check that parent issues are not already archived or deleted

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with Linear integration setup or troubleshooting.
</Card>


# Notion Integration
Source: https://docs.crewai.com/en/enterprise/integrations/notion

Page and database management with Notion integration for CrewAI.

## Overview

Enable your agents to manage pages, databases, and content through Notion. Create and update pages, manage content blocks, organize knowledge bases, and streamline your documentation workflows with AI-powered automation.

## Prerequisites

Before using the Notion integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Notion account with appropriate workspace permissions
* Connected your Notion account through the [Integrations page](https://app.crewai.com/crewai_plus/connectors)

## Setting Up Notion Integration

### 1. Connect Your Notion Account

1. Navigate to [CrewAI Enterprise Integrations](https://app.crewai.com/crewai_plus/connectors)
2. Find **Notion** in the Authentication Integrations section
3. Click **Connect** and complete the OAuth flow
4. Grant the necessary permissions for page and database management
5. Copy your Enterprise Token from [Account Settings](https://app.crewai.com/crewai_plus/settings/account)

### 2. Install Required Package

```bash
uv add crewai-tools
```

## Available Actions

<AccordionGroup>
  <Accordion title="NOTION_CREATE_PAGE">
    **Description:** Create a page in Notion.

    **Parameters:**

    * `parent` (object, required): Parent - The parent page or database where the new page is inserted, represented as a JSON object with a page\_id or database\_id key.
      ```json
      {
        "database_id": "DATABASE_ID"
      }
      ```
    * `properties` (object, required): Properties - The values of the page's properties. If the parent is a database, then the schema must match the parent database's properties.
      ```json
      {
        "title": [
          {
            "text": {
              "content": "My Page"
            }
          }
        ]
      }
      ```
    * `icon` (object, required): Icon - The page icon.
      ```json
      {
        "emoji": "ü•¨"
      }
      ```
    * `children` (object, optional): Children - Content blocks to add to the page.
      ```json
      [
        {
          "object": "block",
          "type": "heading_2",
          "heading_2": {
            "rich_text": [
              {
                "type": "text",
                "text": {
                  "content": "Lacinato kale"
                }
              }
            ]
          }
        }
      ]
      ```
    * `cover` (object, optional): Cover - The page cover image.
      ```json
      {
        "external": {
          "url": "https://upload.wikimedia.org/wikipedia/commons/6/62/Tuscankale.jpg"
        }
      }
      ```
  </Accordion>

  <Accordion title="NOTION_UPDATE_PAGE">
    **Description:** Update a page in Notion.

    **Parameters:**

    * `pageId` (string, required): Page ID - Specify the ID of the Page to Update. (example: "59833787-2cf9-4fdf-8782-e53db20768a5").
    * `icon` (object, required): Icon - The page icon.
      ```json
      {
        "emoji": "ü•¨"
      }
      ```
    * `archived` (boolean, optional): Archived - Whether the page is archived (deleted). Set to true to archive a page. Set to false to un-archive (restore) a page.
    * `properties` (object, optional): Properties - The property values to update for the page.
      ```json
      {
        "title": [
          {
            "text": {
              "content": "My Updated Page"
            }
          }
        ]
      }
      ```
    * `cover` (object, optional): Cover - The page cover image.
      ```json
      {
        "external": {
          "url": "https://upload.wikimedia.org/wikipedia/commons/6/62/Tuscankale.jpg"
        }
      }
      ```
  </Accordion>

  <Accordion title="NOTION_GET_PAGE_BY_ID">
    **Description:** Get a page by ID in Notion.

    **Parameters:**

    * `pageId` (string, required): Page ID - Specify the ID of the Page to Get. (example: "59833787-2cf9-4fdf-8782-e53db20768a5").
  </Accordion>

  <Accordion title="NOTION_ARCHIVE_PAGE">
    **Description:** Archive a page in Notion.

    **Parameters:**

    * `pageId` (string, required): Page ID - Specify the ID of the Page to Archive. (example: "59833787-2cf9-4fdf-8782-e53db20768a5").
  </Accordion>

  <Accordion title="NOTION_SEARCH_PAGES">
    **Description:** Search pages in Notion using filters.

    **Parameters:**

    * `searchByTitleFilterSearch` (object, optional): A filter in disjunctive normal form - OR of AND groups of single conditions.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "query",
                "operator": "$stringExactlyMatches",
                "value": "meeting notes"
              }
            ]
          }
        ]
      }
      ```
      Available fields: `query`, `filter.value`, `direction`, `page_size`
  </Accordion>

  <Accordion title="NOTION_GET_PAGE_CONTENT">
    **Description:** Get page content (blocks) in Notion.

    **Parameters:**

    * `blockId` (string, required): Page ID - Specify a Block or Page ID to receive all of its block's children in order. (example: "59833787-2cf9-4fdf-8782-e53db20768a5").
  </Accordion>

  <Accordion title="NOTION_UPDATE_BLOCK">
    **Description:** Update a block in Notion.

    **Parameters:**

    * `blockId` (string, required): Block ID - Specify the ID of the Block to Update. (example: "9bc30ad4-9373-46a5-84ab-0a7845ee52e6").
    * `archived` (boolean, optional): Archived - Set to true to archive (delete) a block. Set to false to un-archive (restore) a block.
    * `paragraph` (object, optional): Paragraph content.
      ```json
      {
        "rich_text": [
          {
            "type": "text",
            "text": {
              "content": "Lacinato kale",
              "link": null
            }
          }
        ],
        "color": "default"
      }
      ```
    * `image` (object, optional): Image block.
      ```json
      {
        "type": "external",
        "external": {
          "url": "https://website.domain/images/image.png"
        }
      }
      ```
    * `bookmark` (object, optional): Bookmark block.
      ```json
      {
        "caption": [],
        "url": "https://companywebsite.com"
      }
      ```
    * `code` (object, optional): Code block.
      ```json
      {
        "rich_text": [
          {
            "type": "text",
            "text": {
              "content": "const a = 3"
            }
          }
        ],
        "language": "javascript"
      }
      ```
    * `pdf` (object, optional): PDF block.
      ```json
      {
        "type": "external",
        "external": {
          "url": "https://website.domain/files/doc.pdf"
        }
      }
      ```
    * `table` (object, optional): Table block.
      ```json
      {
        "table_width": 2,
        "has_column_header": false,
        "has_row_header": false
      }
      ```
    * `tableOfContent` (object, optional): Table of Contents block.
      ```json
      {
        "color": "default"
      }
      ```
    * `additionalFields` (object, optional): Additional block types.
      ```json
      {
        "child_page": {
          "title": "Lacinato kale"
        },
        "child_database": {
          "title": "My database"
        }
      }
      ```
  </Accordion>

  <Accordion title="NOTION_GET_BLOCK_BY_ID">
    **Description:** Get a block by ID in Notion.

    **Parameters:**

    * `blockId` (string, required): Block ID - Specify the ID of the Block to Get. (example: "9bc30ad4-9373-46a5-84ab-0a7845ee52e6").
  </Accordion>

  <Accordion title="NOTION_DELETE_BLOCK">
    **Description:** Delete a block in Notion.

    **Parameters:**

    * `blockId` (string, required): Block ID - Specify the ID of the Block to Delete. (example: "9bc30ad4-9373-46a5-84ab-0a7845ee52e6").
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Notion Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Notion tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Notion capabilities
notion_agent = Agent(
    role="Documentation Manager",
    goal="Manage documentation and knowledge base in Notion efficiently",
    backstory="An AI assistant specialized in content management and documentation.",
    tools=[enterprise_tools]
)

# Task to create a meeting notes page
create_notes_task = Task(
    description="Create a new meeting notes page in the team database with today's date and agenda items",
    agent=notion_agent,
    expected_output="Meeting notes page created successfully with structured content"
)

# Run the task
crew = Crew(
    agents=[notion_agent],
    tasks=[create_notes_task]
)

crew.kickoff()
```

### Filtering Specific Notion Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Notion tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["notion_create_page", "notion_update_block", "notion_search_pages"]
)

content_manager = Agent(
    role="Content Manager",
    goal="Create and manage content pages efficiently",
    backstory="An AI assistant that focuses on content creation and management.",
    tools=enterprise_tools
)

# Task to manage content workflow
content_workflow = Task(
    description="Create a new project documentation page and add structured content blocks for requirements and specifications",
    agent=content_manager,
    expected_output="Project documentation created with organized content sections"
)

crew = Crew(
    agents=[content_manager],
    tasks=[content_workflow]
)

crew.kickoff()
```

### Knowledge Base Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

knowledge_curator = Agent(
    role="Knowledge Curator",
    goal="Curate and organize knowledge base content in Notion",
    backstory="An experienced knowledge manager who organizes and maintains comprehensive documentation.",
    tools=[enterprise_tools]
)

# Task to curate knowledge base
curation_task = Task(
    description="""
    1. Search for existing documentation pages related to our new product feature
    2. Create a comprehensive feature documentation page with proper structure
    3. Add code examples, images, and links to related resources
    4. Update existing pages with cross-references to the new documentation
    """,
    agent=knowledge_curator,
    expected_output="Feature documentation created and integrated with existing knowledge base"
)

crew = Crew(
    agents=[knowledge_curator],
    tasks=[curation_task]
)

crew.kickoff()
```

### Content Structure and Organization

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

content_organizer = Agent(
    role="Content Organizer",
    goal="Organize and structure content blocks for optimal readability",
    backstory="An AI assistant that specializes in content structure and user experience.",
    tools=[enterprise_tools]
)

# Task to organize content structure
organization_task = Task(
    description="""
    1. Get content from existing project pages
    2. Analyze the structure and identify improvement opportunities
    3. Update content blocks to use proper headings, tables, and formatting
    4. Add table of contents and improve navigation between related pages
    5. Create templates for future documentation consistency
    """,
    agent=content_organizer,
    expected_output="Content reorganized with improved structure and navigation"
)

crew = Crew(
    agents=[content_organizer],
    tasks=[organization_task]
)

crew.kickoff()
```

### Automated Documentation Workflows

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

doc_automator = Agent(
    role="Documentation Automator",
    goal="Automate documentation workflows and maintenance",
    backstory="An AI assistant that automates repetitive documentation tasks.",
    tools=[enterprise_tools]
)

# Complex documentation automation task
automation_task = Task(
    description="""
    1. Search for pages that haven't been updated in the last 30 days
    2. Review and update outdated content blocks
    3. Create weekly team update pages with consistent formatting
    4. Add status indicators and progress tracking to project pages
    5. Generate monthly documentation health reports
    6. Archive completed project pages and organize them in archive sections
    """,
    agent=doc_automator,
    expected_output="Documentation automated with updated content, weekly reports, and organized archives"
)

crew = Crew(
    agents=[doc_automator],
    tasks=[automation_task]
)

crew.kickoff()
```

## Troubleshooting

### Common Issues

**Permission Errors**

* Ensure your Notion account has edit access to the target workspace
* Verify that the OAuth connection includes required scopes for Notion API
* Check that pages and databases are shared with the authenticated integration

**Invalid Page and Block IDs**

* Double-check page IDs and block IDs for correct UUID format
* Ensure referenced pages and blocks exist and are accessible
* Verify that parent page or database IDs are valid when creating new pages

**Property Schema Issues**

* Ensure page properties match the database schema when creating pages in databases
* Verify that property names and types are correct for the target database
* Check that required properties are included when creating or updating pages

**Content Block Structure**

* Ensure block content follows Notion's rich text format specifications
* Verify that nested block structures are properly formatted
* Check that media URLs are accessible and properly formatted

**Search and Filter Issues**

* Ensure search queries are properly formatted and not empty
* Use valid field names in filter formulas: `query`, `filter.value`, `direction`, `page_size`
* Test simple searches before building complex filter conditions

**Parent-Child Relationships**

* Verify that parent page or database exists before creating child pages
* Ensure proper permissions exist for the parent container
* Check that database schemas allow the properties you're trying to set

**Rich Text and Media Content**

* Ensure URLs for external images, PDFs, and bookmarks are accessible
* Verify that rich text formatting follows Notion's API specifications
* Check that code block language types are supported by Notion

**Archive and Deletion Operations**

* Understand the difference between archiving (reversible) and deleting (permanent)
* Verify that you have permissions to archive or delete the target content
* Be cautious with bulk operations that might affect multiple pages or blocks

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with Notion integration setup or troubleshooting.
</Card>


# Salesforce Integration
Source: https://docs.crewai.com/en/enterprise/integrations/salesforce

CRM and sales automation with Salesforce integration for CrewAI.

## Overview

Enable your agents to manage customer relationships, sales processes, and data through Salesforce. Create and update records, manage leads and opportunities, execute SOQL queries, and streamline your CRM workflows with AI-powered automation.

## Prerequisites

Before using the Salesforce integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Salesforce account with appropriate permissions
* Connected your Salesforce account through the [Integrations page](https://app.crewai.com/integrations)

## Available Tools

### **Record Management**

<AccordionGroup>
  <Accordion title="SALESFORCE_CREATE_RECORD_CONTACT">
    **Description:** Create a new Contact record in Salesforce.

    **Parameters:**

    * `FirstName` (string, optional): First Name
    * `LastName` (string, required): Last Name - This field is required
    * `accountId` (string, optional): Account ID - The Account that the Contact belongs to
    * `Email` (string, optional): Email address
    * `Title` (string, optional): Title of the contact, such as CEO or Vice President
    * `Description` (string, optional): A description of the Contact
    * `additionalFields` (object, optional): Additional fields in JSON format for custom Contact fields
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_RECORD_LEAD">
    **Description:** Create a new Lead record in Salesforce.

    **Parameters:**

    * `FirstName` (string, optional): First Name
    * `LastName` (string, required): Last Name - This field is required
    * `Company` (string, required): Company - This field is required
    * `Email` (string, optional): Email address
    * `Phone` (string, optional): Phone number
    * `Website` (string, optional): Website URL
    * `Title` (string, optional): Title of the contact, such as CEO or Vice President
    * `Status` (string, optional): Lead Status - Use Connect Portal Workflow Settings to select Lead Status
    * `Description` (string, optional): A description of the Lead
    * `additionalFields` (object, optional): Additional fields in JSON format for custom Lead fields
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_RECORD_OPPORTUNITY">
    **Description:** Create a new Opportunity record in Salesforce.

    **Parameters:**

    * `Name` (string, required): The Opportunity name - This field is required
    * `StageName` (string, optional): Opportunity Stage - Use Connect Portal Workflow Settings to select stage
    * `CloseDate` (string, optional): Close Date in YYYY-MM-DD format - Defaults to 30 days from current date
    * `AccountId` (string, optional): The Account that the Opportunity belongs to
    * `Amount` (string, optional): Estimated total sale amount
    * `Description` (string, optional): A description of the Opportunity
    * `OwnerId` (string, optional): The Salesforce user assigned to work on this Opportunity
    * `NextStep` (string, optional): Description of next task in closing Opportunity
    * `additionalFields` (object, optional): Additional fields in JSON format for custom Opportunity fields
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_RECORD_TASK">
    **Description:** Create a new Task record in Salesforce.

    **Parameters:**

    * `whatId` (string, optional): Related to ID - The ID of the Account or Opportunity this Task is related to
    * `whoId` (string, optional): Name ID - The ID of the Contact or Lead this Task is related to
    * `subject` (string, required): Subject of the task
    * `activityDate` (string, optional): Activity Date in YYYY-MM-DD format
    * `description` (string, optional): A description of the Task
    * `taskSubtype` (string, required): Task Subtype - Options: task, email, listEmail, call
    * `Status` (string, optional): Status - Options: Not Started, In Progress, Completed
    * `ownerId` (string, optional): Assigned To ID - The Salesforce user assigned to this Task
    * `callDurationInSeconds` (string, optional): Call Duration in seconds
    * `isReminderSet` (boolean, optional): Whether reminder is set
    * `reminderDateTime` (string, optional): Reminder Date/Time in ISO format
    * `additionalFields` (object, optional): Additional fields in JSON format for custom Task fields
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_RECORD_ACCOUNT">
    **Description:** Create a new Account record in Salesforce.

    **Parameters:**

    * `Name` (string, required): The Account name - This field is required
    * `OwnerId` (string, optional): The Salesforce user assigned to this Account
    * `Website` (string, optional): Website URL
    * `Phone` (string, optional): Phone number
    * `Description` (string, optional): Account description
    * `additionalFields` (object, optional): Additional fields in JSON format for custom Account fields
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_RECORD_ANY">
    **Description:** Create a record of any object type in Salesforce.

    **Note:** This is a flexible tool for creating records of custom or unknown object types.
  </Accordion>
</AccordionGroup>

### **Record Updates**

<AccordionGroup>
  <Accordion title="SALESFORCE_UPDATE_RECORD_CONTACT">
    **Description:** Update an existing Contact record in Salesforce.

    **Parameters:**

    * `recordId` (string, required): The ID of the record to update
    * `FirstName` (string, optional): First Name
    * `LastName` (string, optional): Last Name
    * `accountId` (string, optional): Account ID - The Account that the Contact belongs to
    * `Email` (string, optional): Email address
    * `Title` (string, optional): Title of the contact
    * `Description` (string, optional): A description of the Contact
    * `additionalFields` (object, optional): Additional fields in JSON format for custom Contact fields
  </Accordion>

  <Accordion title="SALESFORCE_UPDATE_RECORD_LEAD">
    **Description:** Update an existing Lead record in Salesforce.

    **Parameters:**

    * `recordId` (string, required): The ID of the record to update
    * `FirstName` (string, optional): First Name
    * `LastName` (string, optional): Last Name
    * `Company` (string, optional): Company name
    * `Email` (string, optional): Email address
    * `Phone` (string, optional): Phone number
    * `Website` (string, optional): Website URL
    * `Title` (string, optional): Title of the contact
    * `Status` (string, optional): Lead Status
    * `Description` (string, optional): A description of the Lead
    * `additionalFields` (object, optional): Additional fields in JSON format for custom Lead fields
  </Accordion>

  <Accordion title="SALESFORCE_UPDATE_RECORD_OPPORTUNITY">
    **Description:** Update an existing Opportunity record in Salesforce.

    **Parameters:**

    * `recordId` (string, required): The ID of the record to update
    * `Name` (string, optional): The Opportunity name
    * `StageName` (string, optional): Opportunity Stage
    * `CloseDate` (string, optional): Close Date in YYYY-MM-DD format
    * `AccountId` (string, optional): The Account that the Opportunity belongs to
    * `Amount` (string, optional): Estimated total sale amount
    * `Description` (string, optional): A description of the Opportunity
    * `OwnerId` (string, optional): The Salesforce user assigned to work on this Opportunity
    * `NextStep` (string, optional): Description of next task in closing Opportunity
    * `additionalFields` (object, optional): Additional fields in JSON format for custom Opportunity fields
  </Accordion>

  <Accordion title="SALESFORCE_UPDATE_RECORD_TASK">
    **Description:** Update an existing Task record in Salesforce.

    **Parameters:**

    * `recordId` (string, required): The ID of the record to update
    * `whatId` (string, optional): Related to ID - The ID of the Account or Opportunity this Task is related to
    * `whoId` (string, optional): Name ID - The ID of the Contact or Lead this Task is related to
    * `subject` (string, optional): Subject of the task
    * `activityDate` (string, optional): Activity Date in YYYY-MM-DD format
    * `description` (string, optional): A description of the Task
    * `Status` (string, optional): Status - Options: Not Started, In Progress, Completed
    * `ownerId` (string, optional): Assigned To ID - The Salesforce user assigned to this Task
    * `callDurationInSeconds` (string, optional): Call Duration in seconds
    * `isReminderSet` (boolean, optional): Whether reminder is set
    * `reminderDateTime` (string, optional): Reminder Date/Time in ISO format
    * `additionalFields` (object, optional): Additional fields in JSON format for custom Task fields
  </Accordion>

  <Accordion title="SALESFORCE_UPDATE_RECORD_ACCOUNT">
    **Description:** Update an existing Account record in Salesforce.

    **Parameters:**

    * `recordId` (string, required): The ID of the record to update
    * `Name` (string, optional): The Account name
    * `OwnerId` (string, optional): The Salesforce user assigned to this Account
    * `Website` (string, optional): Website URL
    * `Phone` (string, optional): Phone number
    * `Description` (string, optional): Account description
    * `additionalFields` (object, optional): Additional fields in JSON format for custom Account fields
  </Accordion>

  <Accordion title="SALESFORCE_UPDATE_RECORD_ANY">
    **Description:** Update a record of any object type in Salesforce.

    **Note:** This is a flexible tool for updating records of custom or unknown object types.
  </Accordion>
</AccordionGroup>

### **Record Retrieval**

<AccordionGroup>
  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_CONTACT">
    **Description:** Get a Contact record by its ID.

    **Parameters:**

    * `recordId` (string, required): Record ID of the Contact
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_LEAD">
    **Description:** Get a Lead record by its ID.

    **Parameters:**

    * `recordId` (string, required): Record ID of the Lead
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_OPPORTUNITY">
    **Description:** Get an Opportunity record by its ID.

    **Parameters:**

    * `recordId` (string, required): Record ID of the Opportunity
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_TASK">
    **Description:** Get a Task record by its ID.

    **Parameters:**

    * `recordId` (string, required): Record ID of the Task
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_ACCOUNT">
    **Description:** Get an Account record by its ID.

    **Parameters:**

    * `recordId` (string, required): Record ID of the Account
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_ANY">
    **Description:** Get a record of any object type by its ID.

    **Parameters:**

    * `recordType` (string, required): Record Type (e.g., "CustomObject\_\_c")
    * `recordId` (string, required): Record ID
  </Accordion>
</AccordionGroup>

### **Record Search**

<AccordionGroup>
  <Accordion title="SALESFORCE_SEARCH_RECORDS_CONTACT">
    **Description:** Search for Contact records with advanced filtering.

    **Parameters:**

    * `filterFormula` (object, optional): Advanced filter in disjunctive normal form with field-specific operators
    * `sortBy` (string, optional): Sort field (e.g., "CreatedDate")
    * `sortDirection` (string, optional): Sort direction - Options: ASC, DESC
    * `includeAllFields` (boolean, optional): Include all fields in results
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_SEARCH_RECORDS_LEAD">
    **Description:** Search for Lead records with advanced filtering.

    **Parameters:**

    * `filterFormula` (object, optional): Advanced filter in disjunctive normal form with field-specific operators
    * `sortBy` (string, optional): Sort field (e.g., "CreatedDate")
    * `sortDirection` (string, optional): Sort direction - Options: ASC, DESC
    * `includeAllFields` (boolean, optional): Include all fields in results
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_SEARCH_RECORDS_OPPORTUNITY">
    **Description:** Search for Opportunity records with advanced filtering.

    **Parameters:**

    * `filterFormula` (object, optional): Advanced filter in disjunctive normal form with field-specific operators
    * `sortBy` (string, optional): Sort field (e.g., "CreatedDate")
    * `sortDirection` (string, optional): Sort direction - Options: ASC, DESC
    * `includeAllFields` (boolean, optional): Include all fields in results
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_SEARCH_RECORDS_TASK">
    **Description:** Search for Task records with advanced filtering.

    **Parameters:**

    * `filterFormula` (object, optional): Advanced filter in disjunctive normal form with field-specific operators
    * `sortBy` (string, optional): Sort field (e.g., "CreatedDate")
    * `sortDirection` (string, optional): Sort direction - Options: ASC, DESC
    * `includeAllFields` (boolean, optional): Include all fields in results
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_SEARCH_RECORDS_ACCOUNT">
    **Description:** Search for Account records with advanced filtering.

    **Parameters:**

    * `filterFormula` (object, optional): Advanced filter in disjunctive normal form with field-specific operators
    * `sortBy` (string, optional): Sort field (e.g., "CreatedDate")
    * `sortDirection` (string, optional): Sort direction - Options: ASC, DESC
    * `includeAllFields` (boolean, optional): Include all fields in results
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_SEARCH_RECORDS_ANY">
    **Description:** Search for records of any object type.

    **Parameters:**

    * `recordType` (string, required): Record Type to search
    * `filterFormula` (string, optional): Filter search criteria
    * `includeAllFields` (boolean, optional): Include all fields in results
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>
</AccordionGroup>

### **List View Retrieval**

<AccordionGroup>
  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_CONTACT">
    **Description:** Get Contact records from a specific List View.

    **Parameters:**

    * `listViewId` (string, required): List View ID
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_LEAD">
    **Description:** Get Lead records from a specific List View.

    **Parameters:**

    * `listViewId` (string, required): List View ID
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_OPPORTUNITY">
    **Description:** Get Opportunity records from a specific List View.

    **Parameters:**

    * `listViewId` (string, required): List View ID
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_TASK">
    **Description:** Get Task records from a specific List View.

    **Parameters:**

    * `listViewId` (string, required): List View ID
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_ACCOUNT">
    **Description:** Get Account records from a specific List View.

    **Parameters:**

    * `listViewId` (string, required): List View ID
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_ANY">
    **Description:** Get records of any object type from a specific List View.

    **Parameters:**

    * `recordType` (string, required): Record Type
    * `listViewId` (string, required): List View ID
    * `paginationParameters` (object, optional): Pagination settings with pageCursor
  </Accordion>
</AccordionGroup>

### **Custom Fields**

<AccordionGroup>
  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_CONTACT">
    **Description:** Deploy custom fields for Contact objects.

    **Parameters:**

    * `label` (string, required): Field Label for displays and internal reference
    * `type` (string, required): Field Type - Options: Checkbox, Currency, Date, Email, Number, Percent, Phone, Picklist, MultiselectPicklist, Text, TextArea, LongTextArea, Html, Time, Url
    * `defaultCheckboxValue` (boolean, optional): Default value for checkbox fields
    * `length` (string, required): Length for numeric/text fields
    * `decimalPlace` (string, required): Decimal places for numeric fields
    * `pickListValues` (string, required): Values for picklist fields (separated by new lines)
    * `visibleLines` (string, required): Visible lines for multiselect/text area fields
    * `description` (string, optional): Field description
    * `helperText` (string, optional): Helper text shown on hover
    * `defaultFieldValue` (string, optional): Default field value
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_LEAD">
    **Description:** Deploy custom fields for Lead objects.

    **Parameters:**

    * `label` (string, required): Field Label for displays and internal reference
    * `type` (string, required): Field Type - Options: Checkbox, Currency, Date, Email, Number, Percent, Phone, Picklist, MultiselectPicklist, Text, TextArea, LongTextArea, Html, Time, Url
    * `defaultCheckboxValue` (boolean, optional): Default value for checkbox fields
    * `length` (string, required): Length for numeric/text fields
    * `decimalPlace` (string, required): Decimal places for numeric fields
    * `pickListValues` (string, required): Values for picklist fields (separated by new lines)
    * `visibleLines` (string, required): Visible lines for multiselect/text area fields
    * `description` (string, optional): Field description
    * `helperText` (string, optional): Helper text shown on hover
    * `defaultFieldValue` (string, optional): Default field value
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_OPPORTUNITY">
    **Description:** Deploy custom fields for Opportunity objects.

    **Parameters:**

    * `label` (string, required): Field Label for displays and internal reference
    * `type` (string, required): Field Type - Options: Checkbox, Currency, Date, Email, Number, Percent, Phone, Picklist, MultiselectPicklist, Text, TextArea, LongTextArea, Html, Time, Url
    * `defaultCheckboxValue` (boolean, optional): Default value for checkbox fields
    * `length` (string, required): Length for numeric/text fields
    * `decimalPlace` (string, required): Decimal places for numeric fields
    * `pickListValues` (string, required): Values for picklist fields (separated by new lines)
    * `visibleLines` (string, required): Visible lines for multiselect/text area fields
    * `description` (string, optional): Field description
    * `helperText` (string, optional): Helper text shown on hover
    * `defaultFieldValue` (string, optional): Default field value
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_TASK">
    **Description:** Deploy custom fields for Task objects.

    **Parameters:**

    * `label` (string, required): Field Label for displays and internal reference
    * `type` (string, required): Field Type - Options: Checkbox, Currency, Date, Email, Number, Percent, Phone, Picklist, MultiselectPicklist, Text, TextArea, Time, Url
    * `defaultCheckboxValue` (boolean, optional): Default value for checkbox fields
    * `length` (string, required): Length for numeric/text fields
    * `decimalPlace` (string, required): Decimal places for numeric fields
    * `pickListValues` (string, required): Values for picklist fields (separated by new lines)
    * `visibleLines` (string, required): Visible lines for multiselect fields
    * `description` (string, optional): Field description
    * `helperText` (string, optional): Helper text shown on hover
    * `defaultFieldValue` (string, optional): Default field value
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_ACCOUNT">
    **Description:** Deploy custom fields for Account objects.

    **Parameters:**

    * `label` (string, required): Field Label for displays and internal reference
    * `type` (string, required): Field Type - Options: Checkbox, Currency, Date, Email, Number, Percent, Phone, Picklist, MultiselectPicklist, Text, TextArea, LongTextArea, Html, Time, Url
    * `defaultCheckboxValue` (boolean, optional): Default value for checkbox fields
    * `length` (string, required): Length for numeric/text fields
    * `decimalPlace` (string, required): Decimal places for numeric fields
    * `pickListValues` (string, required): Values for picklist fields (separated by new lines)
    * `visibleLines` (string, required): Visible lines for multiselect/text area fields
    * `description` (string, optional): Field description
    * `helperText` (string, optional): Helper text shown on hover
    * `defaultFieldValue` (string, optional): Default field value
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_ANY">
    **Description:** Deploy custom fields for any object type.

    **Note:** This is a flexible tool for creating custom fields on custom or unknown object types.
  </Accordion>
</AccordionGroup>

### **Advanced Operations**

<AccordionGroup>
  <Accordion title="SALESFORCE_WRITE_SOQL_QUERY">
    **Description:** Execute custom SOQL queries against your Salesforce data.

    **Parameters:**

    * `query` (string, required): SOQL Query (e.g., "SELECT Id, Name FROM Account WHERE Name = 'Example'")
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_OBJECT">
    **Description:** Deploy a new custom object in Salesforce.

    **Parameters:**

    * `label` (string, required): Object Label for tabs, page layouts, and reports
    * `pluralLabel` (string, required): Plural Label (e.g., "Accounts")
    * `description` (string, optional): A description of the Custom Object
    * `recordName` (string, required): Record Name that appears in layouts and searches (e.g., "Account Name")
  </Accordion>

  <Accordion title="SALESFORCE_DESCRIBE_ACTION_SCHEMA">
    **Description:** Get the expected schema for operations on specific object types.

    **Parameters:**

    * `recordType` (string, required): Record Type to describe
    * `operation` (string, required): Operation Type (e.g., "CREATE\_RECORD" or "UPDATE\_RECORD")

    **Note:** Use this function first when working with custom objects to understand their schema before performing operations.
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Salesforce Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Salesforce tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Salesforce capabilities
salesforce_agent = Agent(
    role="CRM Manager",
    goal="Manage customer relationships and sales processes efficiently",
    backstory="An AI assistant specialized in CRM operations and sales automation.",
    tools=[enterprise_tools]
)

# Task to create a new lead
create_lead_task = Task(
    description="Create a new lead for John Doe from Example Corp with email john.doe@example.com",
    agent=salesforce_agent,
    expected_output="Lead created successfully with lead ID"
)

# Run the task
crew = Crew(
    agents=[salesforce_agent],
    tasks=[create_lead_task]
)

crew.kickoff()
```

### Filtering Specific Salesforce Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Salesforce tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["salesforce_create_record_lead", "salesforce_update_record_opportunity", "salesforce_search_records_contact"]
)

sales_manager = Agent(
    role="Sales Manager",
    goal="Manage leads and opportunities in the sales pipeline",
    backstory="An experienced sales manager who handles lead qualification and opportunity management.",
    tools=enterprise_tools
)

# Task to manage sales pipeline
pipeline_task = Task(
    description="Create a qualified lead and convert it to an opportunity with $50,000 value",
    agent=sales_manager,
    expected_output="Lead created and opportunity established successfully"
)

crew = Crew(
    agents=[sales_manager],
    tasks=[pipeline_task]
)

crew.kickoff()
```

### Contact and Account Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

account_manager = Agent(
    role="Account Manager",
    goal="Manage customer accounts and maintain strong relationships",
    backstory="An AI assistant that specializes in account management and customer relationship building.",
    tools=[enterprise_tools]
)

# Task to manage customer accounts
account_task = Task(
    description="""
    1. Create a new account for TechCorp Inc.
    2. Add John Doe as the primary contact for this account
    3. Create a follow-up task for next week to check on their project status
    """,
    agent=account_manager,
    expected_output="Account, contact, and follow-up task created successfully"
)

crew = Crew(
    agents=[account_manager],
    tasks=[account_task]
)

crew.kickoff()
```

### Advanced SOQL Queries and Reporting

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

data_analyst = Agent(
    role="Sales Data Analyst",
    goal="Generate insights from Salesforce data using SOQL queries",
    backstory="An analytical AI that excels at extracting meaningful insights from CRM data.",
    tools=[enterprise_tools]
)

# Complex task involving SOQL queries and data analysis
analysis_task = Task(
    description="""
    1. Execute a SOQL query to find all opportunities closing this quarter
    2. Search for contacts at companies with opportunities over $100K
    3. Create a summary report of the sales pipeline status
    4. Update high-value opportunities with next steps
    """,
    agent=data_analyst,
    expected_output="Comprehensive sales pipeline analysis with actionable insights"
)

crew = Crew(
    agents=[data_analyst],
    tasks=[analysis_task]
)

crew.kickoff()
```

This comprehensive documentation covers all the Salesforce tools organized by functionality, making it easy for users to find the specific operations they need for their CRM automation tasks.

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with Salesforce integration setup or troubleshooting.
</Card>


# Shopify Integration
Source: https://docs.crewai.com/en/enterprise/integrations/shopify

E-commerce and online store management with Shopify integration for CrewAI.

## Overview

Enable your agents to manage e-commerce operations through Shopify. Handle customers, orders, products, inventory, and store analytics to streamline your online business with AI-powered automation.

## Prerequisites

Before using the Shopify integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Shopify store with appropriate admin permissions
* Connected your Shopify store through the [Integrations page](https://app.crewai.com/integrations)

## Available Tools

### **Customer Management**

<AccordionGroup>
  <Accordion title="SHOPIFY_GET_CUSTOMERS">
    **Description:** Retrieve a list of customers from your Shopify store.

    **Parameters:**

    * `customerIds` (string, optional): Comma-separated list of customer IDs to filter by (example: "207119551, 207119552")
    * `createdAtMin` (string, optional): Only return customers created after this date (ISO or Unix timestamp)
    * `createdAtMax` (string, optional): Only return customers created before this date (ISO or Unix timestamp)
    * `updatedAtMin` (string, optional): Only return customers updated after this date (ISO or Unix timestamp)
    * `updatedAtMax` (string, optional): Only return customers updated before this date (ISO or Unix timestamp)
    * `limit` (string, optional): Maximum number of customers to return (defaults to 250)
  </Accordion>

  <Accordion title="SHOPIFY_SEARCH_CUSTOMERS">
    **Description:** Search for customers using advanced filtering criteria.

    **Parameters:**

    * `filterFormula` (object, optional): Advanced filter in disjunctive normal form with field-specific operators
    * `limit` (string, optional): Maximum number of customers to return (defaults to 250)
  </Accordion>

  <Accordion title="SHOPIFY_CREATE_CUSTOMER">
    **Description:** Create a new customer in your Shopify store.

    **Parameters:**

    * `firstName` (string, required): Customer's first name
    * `lastName` (string, required): Customer's last name
    * `email` (string, required): Customer's email address
    * `company` (string, optional): Company name
    * `streetAddressLine1` (string, optional): Street address
    * `streetAddressLine2` (string, optional): Street address line 2
    * `city` (string, optional): City
    * `state` (string, optional): State or province code
    * `country` (string, optional): Country
    * `zipCode` (string, optional): Zip code
    * `phone` (string, optional): Phone number
    * `tags` (string, optional): Tags as array or comma-separated list
    * `note` (string, optional): Customer note
    * `sendEmailInvite` (boolean, optional): Whether to send email invitation
    * `metafields` (object, optional): Additional metafields in JSON format
  </Accordion>

  <Accordion title="SHOPIFY_UPDATE_CUSTOMER">
    **Description:** Update an existing customer in your Shopify store.

    **Parameters:**

    * `customerId` (string, required): The ID of the customer to update
    * `firstName` (string, optional): Customer's first name
    * `lastName` (string, optional): Customer's last name
    * `email` (string, optional): Customer's email address
    * `company` (string, optional): Company name
    * `streetAddressLine1` (string, optional): Street address
    * `streetAddressLine2` (string, optional): Street address line 2
    * `city` (string, optional): City
    * `state` (string, optional): State or province code
    * `country` (string, optional): Country
    * `zipCode` (string, optional): Zip code
    * `phone` (string, optional): Phone number
    * `tags` (string, optional): Tags as array or comma-separated list
    * `note` (string, optional): Customer note
    * `sendEmailInvite` (boolean, optional): Whether to send email invitation
    * `metafields` (object, optional): Additional metafields in JSON format
  </Accordion>
</AccordionGroup>

### **Order Management**

<AccordionGroup>
  <Accordion title="SHOPIFY_GET_ORDERS">
    **Description:** Retrieve a list of orders from your Shopify store.

    **Parameters:**

    * `orderIds` (string, optional): Comma-separated list of order IDs to filter by (example: "450789469, 450789470")
    * `createdAtMin` (string, optional): Only return orders created after this date (ISO or Unix timestamp)
    * `createdAtMax` (string, optional): Only return orders created before this date (ISO or Unix timestamp)
    * `updatedAtMin` (string, optional): Only return orders updated after this date (ISO or Unix timestamp)
    * `updatedAtMax` (string, optional): Only return orders updated before this date (ISO or Unix timestamp)
    * `limit` (string, optional): Maximum number of orders to return (defaults to 250)
  </Accordion>

  <Accordion title="SHOPIFY_CREATE_ORDER">
    **Description:** Create a new order in your Shopify store.

    **Parameters:**

    * `email` (string, required): Customer email address
    * `lineItems` (object, required): Order line items in JSON format with title, price, quantity, and variant\_id
    * `sendReceipt` (boolean, optional): Whether to send order receipt
    * `fulfillmentStatus` (string, optional): Fulfillment status - Options: fulfilled, null, partial, restocked
    * `financialStatus` (string, optional): Financial status - Options: pending, authorized, partially\_paid, paid, partially\_refunded, refunded, voided
    * `inventoryBehaviour` (string, optional): Inventory behavior - Options: bypass, decrement\_ignoring\_policy, decrement\_obeying\_policy
    * `note` (string, optional): Order note
  </Accordion>

  <Accordion title="SHOPIFY_UPDATE_ORDER">
    **Description:** Update an existing order in your Shopify store.

    **Parameters:**

    * `orderId` (string, required): The ID of the order to update
    * `email` (string, optional): Customer email address
    * `lineItems` (object, optional): Updated order line items in JSON format
    * `sendReceipt` (boolean, optional): Whether to send order receipt
    * `fulfillmentStatus` (string, optional): Fulfillment status - Options: fulfilled, null, partial, restocked
    * `financialStatus` (string, optional): Financial status - Options: pending, authorized, partially\_paid, paid, partially\_refunded, refunded, voided
    * `inventoryBehaviour` (string, optional): Inventory behavior - Options: bypass, decrement\_ignoring\_policy, decrement\_obeying\_policy
    * `note` (string, optional): Order note
  </Accordion>

  <Accordion title="SHOPIFY_GET_ABANDONED_CARTS">
    **Description:** Retrieve abandoned carts from your Shopify store.

    **Parameters:**

    * `createdWithInLast` (string, optional): Restrict results to checkouts created within specified time
    * `createdAfterId` (string, optional): Restrict results to after the specified ID
    * `status` (string, optional): Show checkouts with given status - Options: open, closed (defaults to open)
    * `createdAtMin` (string, optional): Only return carts created after this date (ISO or Unix timestamp)
    * `createdAtMax` (string, optional): Only return carts created before this date (ISO or Unix timestamp)
    * `limit` (string, optional): Maximum number of carts to return (defaults to 250)
  </Accordion>
</AccordionGroup>

### **Product Management (REST API)**

<AccordionGroup>
  <Accordion title="SHOPIFY_GET_PRODUCTS">
    **Description:** Retrieve a list of products from your Shopify store using REST API.

    **Parameters:**

    * `productIds` (string, optional): Comma-separated list of product IDs to filter by (example: "632910392, 632910393")
    * `title` (string, optional): Filter by product title
    * `productType` (string, optional): Filter by product type
    * `vendor` (string, optional): Filter by vendor
    * `status` (string, optional): Filter by status - Options: active, archived, draft
    * `createdAtMin` (string, optional): Only return products created after this date (ISO or Unix timestamp)
    * `createdAtMax` (string, optional): Only return products created before this date (ISO or Unix timestamp)
    * `updatedAtMin` (string, optional): Only return products updated after this date (ISO or Unix timestamp)
    * `updatedAtMax` (string, optional): Only return products updated before this date (ISO or Unix timestamp)
    * `limit` (string, optional): Maximum number of products to return (defaults to 250)
  </Accordion>

  <Accordion title="SHOPIFY_CREATE_PRODUCT">
    **Description:** Create a new product in your Shopify store using REST API.

    **Parameters:**

    * `title` (string, required): Product title
    * `productType` (string, required): Product type/category
    * `vendor` (string, required): Product vendor
    * `productDescription` (string, optional): Product description (accepts plain text or HTML)
    * `tags` (string, optional): Product tags as array or comma-separated list
    * `price` (string, optional): Product price
    * `inventoryPolicy` (string, optional): Inventory policy - Options: deny, continue
    * `imageUrl` (string, optional): Product image URL
    * `isPublished` (boolean, optional): Whether product is published
    * `publishToPointToSale` (boolean, optional): Whether to publish to point of sale
  </Accordion>

  <Accordion title="SHOPIFY_UPDATE_PRODUCT">
    **Description:** Update an existing product in your Shopify store using REST API.

    **Parameters:**

    * `productId` (string, required): The ID of the product to update
    * `title` (string, optional): Product title
    * `productType` (string, optional): Product type/category
    * `vendor` (string, optional): Product vendor
    * `productDescription` (string, optional): Product description (accepts plain text or HTML)
    * `tags` (string, optional): Product tags as array or comma-separated list
    * `price` (string, optional): Product price
    * `inventoryPolicy` (string, optional): Inventory policy - Options: deny, continue
    * `imageUrl` (string, optional): Product image URL
    * `isPublished` (boolean, optional): Whether product is published
    * `publishToPointToSale` (boolean, optional): Whether to publish to point of sale
  </Accordion>
</AccordionGroup>

### **Product Management (GraphQL)**

<AccordionGroup>
  <Accordion title="SHOPIFY_GET_PRODUCTS_GRAPHQL">
    **Description:** Retrieve products using advanced GraphQL filtering capabilities.

    **Parameters:**

    * `productFilterFormula` (object, optional): Advanced filter in disjunctive normal form with support for fields like id, title, vendor, status, handle, tag, created\_at, updated\_at, published\_at
  </Accordion>

  <Accordion title="SHOPIFY_CREATE_PRODUCT_GRAPHQL">
    **Description:** Create a new product using GraphQL API with enhanced media support.

    **Parameters:**

    * `title` (string, required): Product title
    * `productType` (string, required): Product type/category
    * `vendor` (string, required): Product vendor
    * `productDescription` (string, optional): Product description (accepts plain text or HTML)
    * `tags` (string, optional): Product tags as array or comma-separated list
    * `media` (object, optional): Media objects with alt text, content type, and source URL
    * `additionalFields` (object, optional): Additional product fields like status, requiresSellingPlan, giftCard
  </Accordion>

  <Accordion title="SHOPIFY_UPDATE_PRODUCT_GRAPHQL">
    **Description:** Update an existing product using GraphQL API with enhanced media support.

    **Parameters:**

    * `productId` (string, required): The GraphQL ID of the product to update (e.g., "gid://shopify/Product/913144112")
    * `title` (string, optional): Product title
    * `productType` (string, optional): Product type/category
    * `vendor` (string, optional): Product vendor
    * `productDescription` (string, optional): Product description (accepts plain text or HTML)
    * `tags` (string, optional): Product tags as array or comma-separated list
    * `media` (object, optional): Updated media objects with alt text, content type, and source URL
    * `additionalFields` (object, optional): Additional product fields like status, requiresSellingPlan, giftCard
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Shopify Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Shopify tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Shopify capabilities
shopify_agent = Agent(
    role="E-commerce Manager",
    goal="Manage online store operations and customer relationships efficiently",
    backstory="An AI assistant specialized in e-commerce operations and online store management.",
    tools=[enterprise_tools]
)

# Task to create a new customer
create_customer_task = Task(
    description="Create a new VIP customer Jane Smith with email jane.smith@example.com and phone +1-555-0123",
    agent=shopify_agent,
    expected_output="Customer created successfully with customer ID"
)

# Run the task
crew = Crew(
    agents=[shopify_agent],
    tasks=[create_customer_task]
)

crew.kickoff()
```

### Filtering Specific Shopify Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Shopify tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["shopify_create_customer", "shopify_create_order", "shopify_get_products"]
)

store_manager = Agent(
    role="Store Manager",
    goal="Manage customer orders and product catalog",
    backstory="An experienced store manager who handles customer relationships and inventory management.",
    tools=enterprise_tools
)

# Task to manage store operations
store_task = Task(
    description="Create a new customer and process their order for 2 Premium Coffee Mugs",
    agent=store_manager,
    expected_output="Customer created and order processed successfully"
)

crew = Crew(
    agents=[store_manager],
    tasks=[store_task]
)

crew.kickoff()
```

### Product Management with GraphQL

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

product_manager = Agent(
    role="Product Manager",
    goal="Manage product catalog and inventory with advanced GraphQL capabilities",
    backstory="An AI assistant that specializes in product management and catalog optimization.",
    tools=[enterprise_tools]
)

# Task to manage product catalog
catalog_task = Task(
    description="""
    1. Create a new product "Premium Coffee Mug" from Coffee Co vendor
    2. Add high-quality product images and descriptions
    3. Search for similar products from the same vendor
    4. Update product tags and pricing strategy
    """,
    agent=product_manager,
    expected_output="Product created and catalog optimized successfully"
)

crew = Crew(
    agents=[product_manager],
    tasks=[catalog_task]
)

crew.kickoff()
```

### Order and Customer Analytics

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

analytics_agent = Agent(
    role="E-commerce Analyst",
    goal="Analyze customer behavior and order patterns to optimize store performance",
    backstory="An analytical AI that excels at extracting insights from e-commerce data.",
    tools=[enterprise_tools]
)

# Complex task involving multiple operations
analytics_task = Task(
    description="""
    1. Retrieve recent customer data and order history
    2. Identify abandoned carts from the last 7 days
    3. Analyze product performance and inventory levels
    4. Generate recommendations for customer retention
    """,
    agent=analytics_agent,
    expected_output="Comprehensive e-commerce analytics report with actionable insights"
)

crew = Crew(
    agents=[analytics_agent],
    tasks=[analytics_task]
)

crew.kickoff()
```

### Getting Help

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with Shopify integration setup or troubleshooting.
</Card>


# Slack Integration
Source: https://docs.crewai.com/en/enterprise/integrations/slack

Team communication and collaboration with Slack integration for CrewAI.

## Overview

Enable your agents to manage team communication through Slack. Send messages, search conversations, manage channels, and coordinate team activities to streamline your collaboration workflows with AI-powered automation.

## Prerequisites

Before using the Slack integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Slack workspace with appropriate permissions
* Connected your Slack workspace through the [Integrations page](https://app.crewai.com/integrations)

## Available Tools

### **User Management**

<AccordionGroup>
  <Accordion title="SLACK_LIST_MEMBERS">
    **Description:** List all members in a Slack channel.

    **Parameters:**

    * No parameters required - retrieves all channel members
  </Accordion>

  <Accordion title="SLACK_GET_USER_BY_EMAIL">
    **Description:** Find a user in your Slack workspace by their email address.

    **Parameters:**

    * `email` (string, required): The email address of a user in the workspace
  </Accordion>

  <Accordion title="SLACK_GET_USERS_BY_NAME">
    **Description:** Search for users by their name or display name.

    **Parameters:**

    * `name` (string, required): User's real name to search for
    * `displayName` (string, required): User's display name to search for
    * `paginationParameters` (object, optional): Pagination settings
      * `pageCursor` (string, optional): Page cursor for pagination
  </Accordion>
</AccordionGroup>

### **Channel Management**

<AccordionGroup>
  <Accordion title="SLACK_LIST_CHANNELS">
    **Description:** List all channels in your Slack workspace.

    **Parameters:**

    * No parameters required - retrieves all accessible channels
  </Accordion>
</AccordionGroup>

### **Messaging**

<AccordionGroup>
  <Accordion title="SLACK_SEND_MESSAGE">
    **Description:** Send a message to a Slack channel.

    **Parameters:**

    * `channel` (string, required): Channel name or ID - Use Connect Portal Workflow Settings to allow users to select a channel, or enter a channel name to create a new channel
    * `message` (string, required): The message text to send
    * `botName` (string, required): The name of the bot that sends this message
    * `botIcon` (string, required): Bot icon - Can be either an image URL or an emoji (e.g., ":dog:")
    * `blocks` (object, optional): Slack Block Kit JSON for rich message formatting with attachments and interactive elements
    * `authenticatedUser` (boolean, optional): If true, message appears to come from your authenticated Slack user instead of the application (defaults to false)
  </Accordion>

  <Accordion title="SLACK_SEND_DIRECT_MESSAGE">
    **Description:** Send a direct message to a specific user in Slack.

    **Parameters:**

    * `memberId` (string, required): Recipient user ID - Use Connect Portal Workflow Settings to allow users to select a workspace member
    * `message` (string, required): The message text to send
    * `botName` (string, required): The name of the bot that sends this message
    * `botIcon` (string, required): Bot icon - Can be either an image URL or an emoji (e.g., ":dog:")
    * `blocks` (object, optional): Slack Block Kit JSON for rich message formatting with attachments and interactive elements
    * `authenticatedUser` (boolean, optional): If true, message appears to come from your authenticated Slack user instead of the application (defaults to false)
  </Accordion>
</AccordionGroup>

### **Search & Discovery**

<AccordionGroup>
  <Accordion title="SLACK_SEARCH_MESSAGES">
    **Description:** Search for messages across your Slack workspace.

    **Parameters:**

    * `query` (string, required): Search query using Slack search syntax to find messages that match specified criteria

    **Search Query Examples:**

    * `"project update"` - Search for messages containing "project update"
    * `from:@john in:#general` - Search for messages from John in the #general channel
    * `has:link after:2023-01-01` - Search for messages with links after January 1, 2023
    * `in:@channel before:yesterday` - Search for messages in a specific channel before yesterday
  </Accordion>
</AccordionGroup>

## Block Kit Integration

Slack's Block Kit allows you to create rich, interactive messages. Here are some examples of how to use the `blocks` parameter:

### Simple Text with Attachment

```json
[
  {
    "text": "I am a test message",
    "attachments": [
      {
        "text": "And here's an attachment!"
      }
    ]
  }
]
```

### Rich Formatting with Sections

```json
[
  {
    "type": "section",
    "text": {
      "type": "mrkdwn",
      "text": "*Project Update*\nStatus: ‚úÖ Complete"
    }
  },
  {
    "type": "divider"
  },
  {
    "type": "section",
    "text": {
      "type": "plain_text",
      "text": "All tasks have been completed successfully."
    }
  }
]
```

## Usage Examples

### Basic Slack Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Slack tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Slack capabilities
slack_agent = Agent(
    role="Team Communication Manager",
    goal="Facilitate team communication and coordinate collaboration efficiently",
    backstory="An AI assistant specialized in team communication and workspace coordination.",
    tools=[enterprise_tools]
)

# Task to send project updates
update_task = Task(
    description="Send a project status update to the #general channel with current progress",
    agent=slack_agent,
    expected_output="Project update message sent successfully to team channel"
)

# Run the task
crew = Crew(
    agents=[slack_agent],
    tasks=[update_task]
)

crew.kickoff()
```

### Filtering Specific Slack Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Slack tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["slack_send_message", "slack_send_direct_message", "slack_search_messages"]
)

communication_manager = Agent(
    role="Communication Coordinator",
    goal="Manage team communications and ensure important messages reach the right people",
    backstory="An experienced communication coordinator who handles team messaging and notifications.",
    tools=enterprise_tools
)

# Task to coordinate team communication
coordination_task = Task(
    description="Send task completion notifications to team members and update project channels",
    agent=communication_manager,
    expected_output="Team notifications sent and project channels updated successfully"
)

crew = Crew(
    agents=[communication_manager],
    tasks=[coordination_task]
)

crew.kickoff()
```

### Advanced Messaging with Block Kit

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

notification_agent = Agent(
    role="Notification Manager",
    goal="Create rich, interactive notifications and manage workspace communication",
    backstory="An AI assistant that specializes in creating engaging team notifications and updates.",
    tools=[enterprise_tools]
)

# Task to send rich notifications
notification_task = Task(
    description="""
    1. Send a formatted project completion message to #general with progress charts
    2. Send direct messages to team leads with task summaries
    3. Create interactive notification with action buttons for team feedback
    """,
    agent=notification_agent,
    expected_output="Rich notifications sent with interactive elements and formatted content"
)

crew = Crew(
    agents=[notification_agent],
    tasks=[notification_task]
)

crew.kickoff()
```

### Message Search and Analytics

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

analytics_agent = Agent(
    role="Communication Analyst",
    goal="Analyze team communication patterns and extract insights from conversations",
    backstory="An analytical AI that excels at understanding team dynamics through communication data.",
    tools=[enterprise_tools]
)

# Complex task involving search and analysis
analysis_task = Task(
    description="""
    1. Search for recent project-related messages across all channels
    2. Find users by email to identify team members
    3. Analyze communication patterns and response times
    4. Generate weekly team communication summary
    """,
    agent=analytics_agent,
    expected_output="Comprehensive communication analysis with team insights and recommendations"
)

crew = Crew(
    agents=[analytics_agent],
    tasks=[analysis_task]
)

crew.kickoff()
```

## Contact Support

<Card title="Need Help?" icon="headset" href="mailto:support@crewai.com">
  Contact our support team for assistance with Slack integration setup or troubleshooting.
</Card>


# Stripe Integration
Source: https://docs.crewai.com/en/enterprise/integrations/stripe

Payment processing and subscription management with Stripe integration for CrewAI.

## Overview

Enable your agents to manage payments, subscriptions, and customer billing through Stripe. Handle customer data, process subscriptions, manage products, and track financial transactions to streamline your payment workflows with AI-powered automation.

## Prerequisites

Before using the Stripe integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Stripe account with appropriate API permissions
* Connected your Stripe account through the [Integrations page](https://app.crewai.com/integrations)

## Available Tools

### **Customer Management**

<AccordionGroup>
  <Accordion title="STRIPE_CREATE_CUSTOMER">
    **Description:** Create a new customer in your Stripe account.

    **Parameters:**

    * `emailCreateCustomer` (string, required): Customer's email address
    * `name` (string, optional): Customer's full name
    * `description` (string, optional): Customer description for internal reference
    * `metadataCreateCustomer` (object, optional): Additional metadata as key-value pairs (e.g., `{"field1": 1, "field2": 2}`)
  </Accordion>

  <Accordion title="STRIPE_GET_CUSTOMER_BY_ID">
    **Description:** Retrieve a specific customer by their Stripe customer ID.

    **Parameters:**

    * `idGetCustomer` (string, required): The Stripe customer ID to retrieve
  </Accordion>

  <Accordion title="STRIPE_GET_CUSTOMERS">
    **Description:** Retrieve a list of customers with optional filtering.

    **Parameters:**

    * `emailGetCustomers` (string, optional): Filter customers by email address
    * `createdAfter` (string, optional): Filter customers created after this date (Unix timestamp)
    * `createdBefore` (string, optional): Filter customers created before this date (Unix timestamp)
    * `limitGetCustomers` (string, optional): Maximum number of customers to return (defaults to 10)
  </Accordion>

  <Accordion title="STRIPE_UPDATE_CUSTOMER">
    **Description:** Update an existing customer's information.

    **Parameters:**

    * `customerId` (string, required): The ID of the customer to update
    * `emailUpdateCustomer` (string, optional): Updated email address
    * `name` (string, optional): Updated customer name
    * `description` (string, optional): Updated customer description
    * `metadataUpdateCustomer` (object, optional): Updated metadata as key-value pairs
  </Accordion>
</AccordionGroup>

### **Subscription Management**

<AccordionGroup>
  <Accordion title="STRIPE_CREATE_SUBSCRIPTION">
    **Description:** Create a new subscription for a customer.

    **Parameters:**

    * `customerIdCreateSubscription` (string, required): The customer ID for whom the subscription will be created
    * `plan` (string, required): The plan ID for the subscription - Use Connect Portal Workflow Settings to allow users to select a plan
    * `metadataCreateSubscription` (object, optional): Additional metadata for the subscription
  </Accordion>

  <Accordion title="STRIPE_GET_SUBSCRIPTIONS">
    **Description:** Retrieve subscriptions with optional filtering.

    **Parameters:**

    * `customerIdGetSubscriptions` (string, optional): Filter subscriptions by customer ID
    * `subscriptionStatus` (string, optional): Filter by subscription status - Options: incomplete, incomplete\_expired, trialing, active, past\_due, canceled, unpaid
    * `limitGetSubscriptions` (string, optional): Maximum number of subscriptions to return (defaults to 10)
  </Accordion>
</AccordionGroup>

### **Product Management**

<AccordionGroup>
  <Accordion title="STRIPE_CREATE_PRODUCT">
    **Description:** Create a new product in your Stripe catalog.

    **Parameters:**

    * `productName` (string, required): The product name
    * `description` (string, optional): Product description
    * `metadataProduct` (object, optional): Additional product metadata as key-value pairs
  </Accordion>

  <Accordion title="STRIPE_GET_PRODUCT_BY_ID">
    **Description:** Retrieve a specific product by its Stripe product ID.

    **Parameters:**

    * `productId` (string, required): The Stripe product ID to retrieve
  </Accordion>

  <Accordion title="STRIPE_GET_PRODUCTS">
    **Description:** Retrieve a list of products with optional filtering.

    **Parameters:**

    * `createdAfter` (string, optional): Filter products created after this date (Unix timestamp)
    * `createdBefore` (string, optional): Filter products created before this date (Unix timestamp)
    * `limitGetProducts` (string, optional): Maximum number of products to return (defaults to 10)
  </Accordion>
</AccordionGroup>

### **Financial Operations**

<AccordionGroup>
  <Accordion title="STRIPE_GET_BALANCE_TRANSACTIONS">
    **Description:** Retrieve balance transactions from your Stripe account.

    **Parameters:**

    * `balanceTransactionType` (string, optional): Filter by transaction type - Options: charge, refund, payment, payment\_refund
    * `paginationParameters` (object, optional): Pagination settings
      * `pageCursor` (string, optional): Page cursor for pagination
  </Accordion>

  <Accordion title="STRIPE_GET_PLANS">
    **Description:** Retrieve subscription plans from your Stripe account.

    **Parameters:**

    * `isPlanActive` (boolean, optional): Filter by plan status - true for active plans, false for inactive plans
    * `paginationParameters` (object, optional): Pagination settings
      * `pageCursor` (string, optional): Page cursor for pagination
  </Accordion>
</AccordionGroup>

## Usage Examples

### Basic Stripe Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Stripe tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Stripe capabilities
stripe_agent = Agent(
    role="Payment Manager",
    goal="Manage customer payments, subscriptions, and billing operations efficiently",
    backstory="An AI assistant specialized in payment processing and subscription management.",
    tools=[enterprise_tools]
)

# Task to create a new customer
create_customer_task = Task(
    description="Create a new premium customer John Doe with email john.doe@example.com",
    agent=stripe_agent,
    expected_output="Customer created successfully with customer ID"
)

# Run the task
crew = Crew(
    agents=[stripe_agent],
    tasks=[create_customer_task]
)

crew.kickoff()
```

### Filtering Specific Stripe Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Stripe tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["stripe_create_customer", "stripe_create_subscription", "stripe_get_balance_transactions"]
)

billing_manager = Agent(
    role="Billing Manager",
    goal="Handle customer billing, subscriptions, and payment processing",
    backstory="An experienced billing manager who handles subscription lifecycle and payment operations.",
    tools=enterprise_tools
)

# Task to manage billing operations
billing_task = Task(
    description="Create a new customer and set up their premium subscription plan",
    agent=billing_manager,
    expected_output="Customer created and subscription activated successfully"
)

crew = Crew(
    agents=[billing_manager],
    tasks=[billing_task]
)

crew.kickoff()
```

### Subscription Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

subscription_manager = Agent(
    role="Subscription Manager",
    goal="Manage customer subscriptions and optimize recurring revenue",
    backstory="An AI assistant that specializes in subscription lifecycle management and customer retention.",
    tools=[enterprise_tools]
)

# Task to manage subscription operations
subscription_task = Task(
    description="""
    1. Create a new product "Premium Service Plan" with advanced features
    2. Set up subscription plans with different tiers
    3. Create customers and assign them to appropriate plans
    4. Monitor subscription status and handle billing issues
    """,
    agent=subscription_manager,
    expected_output="Subscription management system configured with customers and active plans"
)

crew = Crew(
    agents=[subscription_manager],
    tasks=[subscription_task]
)

crew.kickoff()
```

### Financial Analytics and Reporting

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

financial_analyst = Agent(
    role="Financial Analyst",
    goal="Analyze payment data and generate financial insights",
    backstory="An analytical AI that excels at extracting insights from payment and subscription data.",
    tools=[enterprise_tools]
)

# Complex task involving financial analysis
analytics_task = Task(
    description="""
    1. Retrieve balance transactions for the current month
    2. Analyze customer payment patterns and subscription trends
    3. Identify high-value customers and subscription performance
    4. Generate monthly financial performance report
    """,
    agent=financial_analyst,
    expected_output="Comprehensive financial analysis with payment insights and recommendations"
)

crew = Crew(
    agents=[financial_analyst],
    tasks=[analytics_task]
)

crew.kickoff()
```

## Subscription Status Reference

Understanding subscription statuses:

* **incomplete** - Subscription requires payment method or payment confirmation
* **incomplete\_expired** - Subscription expired before payment was confirmed
* **trialing** - Subscription is in trial period
* **active** - Subscription is active and current
* **past\_due** - Payment failed but subscription is still active
* **canceled** - Subscription has been canceled
* **unpaid** - Payment failed and subscription is no longer active

## Metadata Usage

Metadata allows you to store additional information about customers, subscriptions, and products:

```json
{
  "customer_segment": "enterprise",
  "acquisition_source": "google_ads",
  "lifetime_value": "high",
  "custom_field_1": "value1"
}
```

This integration enables comprehensive payment and subscription management automation, allowing your AI agents to handle billing operations seamlessly within your Stripe ecosystem.


# Zendesk Integration
Source: https://docs.crewai.com/en/enterprise/integrations/zendesk

Customer support and helpdesk management with Zendesk integration for CrewAI.

## Overview

Enable your agents to manage customer support operations through Zendesk. Create and update tickets, manage users, track support metrics, and streamline your customer service workflows with AI-powered automation.

## Prerequisites

Before using the Zendesk integration, ensure you have:

* A [CrewAI Enterprise](https://app.crewai.com) account with an active subscription
* A Zendesk account with appropriate API permissions
* Connected your Zendesk account through the [Integrations page](https://app.crewai.com/integrations)

## Available Tools

### **Ticket Management**

<AccordionGroup>
  <Accordion title="ZENDESK_CREATE_TICKET">
    **Description:** Create a new support ticket in Zendesk.

    **Parameters:**

    * `ticketSubject` (string, required): Ticket subject line (e.g., "Help, my printer is on fire!")
    * `ticketDescription` (string, required): First comment that appears on the ticket (e.g., "The smoke is very colorful.")
    * `requesterName` (string, required): Name of the user requesting support (e.g., "Jane Customer")
    * `requesterEmail` (string, required): Email of the user requesting support (e.g., "[jane@example.com](mailto:jane@example.com)")
    * `assigneeId` (string, optional): Zendesk Agent ID assigned to this ticket - Use Connect Portal Workflow Settings to allow users to select an assignee
    * `ticketType` (string, optional): Ticket type - Options: problem, incident, question, task
    * `ticketPriority` (string, optional): Priority level - Options: urgent, high, normal, low
    * `ticketStatus` (string, optional): Ticket status - Options: new, open, pending, hold, solved, closed
    * `ticketDueAt` (string, optional): Due date for task-type tickets (ISO 8601 timestamp)
    * `ticketTags` (string, optional): Array of tags to apply (e.g., `["enterprise", "other_tag"]`)
    * `ticketExternalId` (string, optional): External ID to link tickets to local records
    * `ticketCustomFields` (object, optional): Custom field values in JSON format
  </Accordion>

  <Accordion title="ZENDESK_UPDATE_TICKET">
    **Description:** Update an existing support ticket in Zendesk.

    **Parameters:**

    * `ticketId` (string, required): ID of the ticket to update (e.g., "35436")
    * `ticketSubject` (string, optional): Updated ticket subject
    * `requesterName` (string, required): Name of the user who requested this ticket
    * `requesterEmail` (string, required): Email of the user who requested this ticket
    * `assigneeId` (string, optional): Updated assignee ID - Use Connect Portal Workflow Settings
    * `ticketType` (string, optional): Updated ticket type - Options: problem, incident, question, task
    * `ticketPriority` (string, optional): Updated priority - Options: urgent, high, normal, low
    * `ticketStatus` (string, optional): Updated status - Options: new, open, pending, hold, solved, closed
    * `ticketDueAt` (string, optional): Updated due date (ISO 8601 timestamp)
    * `ticketTags` (string, optional): Updated tags array
    * `ticketExternalId` (string, optional): Updated external ID
    * `ticketCustomFields` (object, optional): Updated custom field values
  </Accordion>

  <Accordion title="ZENDESK_GET_TICKET_BY_ID">
    **Description:** Retrieve a specific ticket by its ID.

    **Parameters:**

    * `ticketId` (string, required): The ticket ID to retrieve (e.g., "35436")
  </Accordion>

  <Accordion title="ZENDESK_ADD_COMMENT_TO_TICKET">
    **Description:** Add a comment or internal note to an existing ticket.

    **Parameters:**

    * `ticketId` (string, required): ID of the ticket to add comment to (e.g., "35436")
    * `commentBody` (string, required): Comment message (accepts plain text or HTML, e.g., "Thanks for your help!")
    * `isInternalNote` (boolean, optional): Set to true for internal notes instead of public replies (defaults to false)
    * `isPublic` (boolean, optional): True for public comments, false for internal notes
  </Accordion>

  <Accordion title="ZENDESK_SEARCH_TICKETS">
    **Description:** Search for tickets using various filters and criteria.

    **Parameters:**

    * `ticketSubject` (string, optional): Filter by text in ticket subject
    * `ticketDescription` (string, optional): Filter by text in ticket description and comments
    * `ticketStatus` (string, optional): Filter by status - Options: new, open, pending, hold, solved, closed
    * `ticketType` (string, optional): Filter by type - Options: problem, incident, question, task, no\_type
    * `ticketPriority` (string, optional): Filter by priority - Options: urgent, high, normal, low, no\_priority
    * `requesterId` (string, optional): Filter by requester user ID
    * `assigneeId` (string, optional): Filter by assigned agent ID
    * `recipientEmail` (string, optional): Filter by original recipient email address
    * `ticketTags` (string, optional): Filter by ticket tags
    * `ticketExternalId` (string, optional): Filter by external ID
    * `createdDate` (object, optional): Filter by creation date with operator (EQUALS, LESS\_THAN\_EQUALS, GREATER\_THAN\_EQUALS) and value
    * `updatedDate` (object, optional): Filter by update date with operator and value
    * `dueDate` (object, optional): Filter by due date with operator and value
    * `sort_by` (string, optional): Sort field - Options: created\_at, updated\_at, priority, status, ticket\_type
    * `sort_order` (string, optional): Sort direction - Options: asc, desc
  </Accordion>
</AccordionGroup>

### **User Management**

<AccordionGroup>
  <Accordion title="ZENDESK_CREATE_USER">
    **Description:** Create a new user in Zendesk.

    **Parameters:**

    * `name` (string, required): User's full name
    * `email` (string, optional): User's email address (e.g., "[jane@example.com](mailto:jane@example.com)")
    * `phone` (string, optional): User's phone number
    * `role` (string, optional): User role - Options: admin, agent, end-user
    * `externalId` (string, optional): Unique identifier from another system
    * `details` (string, optional): Additional user details
    * `notes` (string, optional): Internal notes about the user
  </Accordion>

  <Accordion title="ZENDESK_UPDATE_USER">
    **Description:** Update an existing user's information.

    **Parameters:**

    * `userId` (string, required): ID of the user to update
    * `name` (string, optional): Updated user name
    * `email` (string, optional): Updated email (adds as secondary email on update)
    * `phone` (string, optional): Updated phone number
    * `role` (string, optional): Updated role - Options: admin, agent, end-user
    * `externalId` (string, optional): Updated external ID
    * `details` (string, optional): Updated user details
    * `notes` (string, optional): Updated internal notes
  </Accordion>

  <Accordion title="ZENDESK_GET_USER_BY_ID">
    **Description:** Retrieve a specific user by their ID.

    **Parameters:**

    * `userId` (string, required): The user ID to retrieve
  </Accordion>

  <Accordion title="ZENDESK_SEARCH_USERS">
    **Description:** Search for users using various criteria.

    **Parameters:**

    * `name` (string, optional): Filter by user name
    * `email` (string, optional): Filter by user email (e.g., "[jane@example.com](mailto:jane@example.com)")
    * `role` (string, optional): Filter by role - Options: admin, agent, end-user
    * `externalId` (string, optional): Filter by external ID
    * `sort_by` (string, optional): Sort field - Options: created\_at, updated\_at
    * `sort_order` (string, optional): Sort direction - Options: asc, desc
  </Accordion>
</AccordionGroup>

### **Administrative Tools**

<AccordionGroup>
  <Accordion title="ZENDESK_GET_TICKET_FIELDS">
    **Description:** Retrieve all standard and custom fields available for tickets.

    **Parameters:**

    * `paginationParameters` (object, optional): Pagination settings
      * `pageCursor` (string, optional): Page cursor for pagination
  </Accordion>

  <Accordion title="ZENDESK_GET_TICKET_AUDITS">
    **Description:** Get audit records (read-only history) for tickets.

    **Parameters:**

    * `ticketId` (string, optional): Get audits for specific ticket (if empty, retrieves audits for all non-archived tickets, e.g., "1234")
    * `paginationParameters` (object, optional): Pagination settings
      * `pageCursor` (string, optional): Page cursor for pagination
  </Accordion>
</AccordionGroup>

## Custom Fields

Custom fields allow you to store additional information specific to your organization:

```json
[
  { "id": 27642, "value": "745" },
  { "id": 27648, "value": "yes" }
]
```

## Ticket Priority Levels

Understanding priority levels:

* **urgent** - Critical issues requiring immediate attention
* **high** - Important issues that should be addressed quickly
* **normal** - Standard priority for most tickets
* **low** - Minor issues that can be addressed when convenient

## Ticket Status Workflow

Standard ticket status progression:

* **new** - Recently created, not yet assigned
* **open** - Actively being worked on
* **pending** - Waiting for customer response or external action
* **hold** - Temporarily paused
* **solved** - Issue resolved, awaiting customer confirmation
* **closed** - Ticket completed and closed

## Usage Examples

### Basic Zendesk Agent Setup

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Zendesk tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Zendesk capabilities
zendesk_agent = Agent(
    role="Support Manager",
    goal="Manage customer support tickets and provide excellent customer service",
    backstory="An AI assistant specialized in customer support operations and ticket management.",
    tools=[enterprise_tools]
)

# Task to create a new support ticket
create_ticket_task = Task(
    description="Create a high-priority support ticket for John Smith who is unable to access his account after password reset",
    agent=zendesk_agent,
    expected_output="Support ticket created successfully with ticket ID"
)

# Run the task
crew = Crew(
    agents=[zendesk_agent],
    tasks=[create_ticket_task]
)

crew.kickoff()
```

### Filtering Specific Zendesk Tools

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Zendesk tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["zendesk_create_ticket", "zendesk_update_ticket", "zendesk_add_comment_to_ticket"]
)

support_agent = Agent(
    role="Customer Support Agent",
    goal="Handle customer inquiries and resolve support issues efficiently",
    backstory="An experienced support agent who specializes in ticket resolution and customer communication.",
    tools=enterprise_tools
)

# Task to manage support workflow
support_task = Task(
    description="Create a ticket for login issues, add troubleshooting comments, and update status to resolved",
    agent=support_agent,
    expected_output="Support ticket managed through complete resolution workflow"
)

crew = Crew(
    agents=[support_agent],
    tasks=[support_task]
)

crew.kickoff()
```

### Advanced Ticket Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

ticket_manager = Agent(
    role="Ticket Manager",
    goal="Manage support ticket workflows and ensure timely resolution",
    backstory="An AI assistant that specializes in support ticket triage and workflow optimization.",
    tools=[enterprise_tools]
)

# Task to manage ticket lifecycle
ticket_workflow = Task(
    description="""
    1. Create a new support ticket for account access issues
    2. Add internal notes with troubleshooting steps
    3. Update ticket priority based on customer tier
    4. Add resolution comments and close the ticket
    """,
    agent=ticket_manager,
    expected_output="Complete ticket lifecycle managed from creation to resolution"
)

crew = Crew(
    agents=[ticket_manager],
    tasks=[ticket_workflow]
)

crew.kickoff()
```

### Support Analytics and Reporting

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

support_analyst = Agent(
    role="Support Analyst",
    goal="Analyze support metrics and generate insights for team performance",
    backstory="An analytical AI that excels at extracting insights from support data and ticket patterns.",
    tools=[enterprise_tools]
)

# Complex task involving analytics and reporting
analytics_task = Task(
    description="""
    1. Search for all open tickets from the last 30 days
    2. Analyze ticket resolution times and customer satisfaction
    3. Identify common issues and support patterns
    4. Generate weekly support performance report
    """,
    agent=support_analyst,
    expected_output="Comprehensive support analytics report with performance insights and recommendations"
)

crew = Crew(
    agents=[support_analyst],
    tasks=[analytics_task]
)

crew.kickoff()
```


# CrewAI Enterprise
Source: https://docs.crewai.com/en/enterprise/introduction

Deploy, monitor, and scale your AI agent workflows

## Introduction

CrewAI Enterprise provides a platform for deploying, monitoring, and scaling your crews and agents in a production environment.

<Frame>
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crewai-enterprise-dashboard.png" alt="CrewAI Enterprise Dashboard" />
</Frame>

CrewAI Enterprise extends the power of the open-source framework with features designed for production deployments, collaboration, and scalability. Deploy your crews to a managed infrastructure and monitor their execution in real-time.

## Key Features

<CardGroup cols={2}>
  <Card title="Crew Deployments" icon="rocket">
    Deploy your crews to a managed infrastructure with a few clicks
  </Card>

  <Card title="API Access" icon="code">
    Access your deployed crews via REST API for integration with existing systems
  </Card>

  <Card title="Observability" icon="chart-line">
    Monitor your crews with detailed execution traces and logs
  </Card>

  <Card title="Tool Repository" icon="toolbox">
    Publish and install tools to enhance your crews' capabilities
  </Card>

  <Card title="Webhook Streaming" icon="webhook">
    Stream real-time events and updates to your systems
  </Card>

  <Card title="Crew Studio" icon="paintbrush">
    Create and customize crews using a no-code/low-code interface
  </Card>
</CardGroup>

## Deployment Options

<CardGroup cols={3}>
  <Card title="GitHub Integration" icon="github">
    Connect directly to your GitHub repositories to deploy code
  </Card>

  <Card title="Crew Studio" icon="palette">
    Deploy crews created through the no-code Crew Studio interface
  </Card>

  <Card title="CLI Deployment" icon="terminal">
    Use the CrewAI CLI for more advanced deployment workflows
  </Card>
</CardGroup>

## Getting Started

<Steps>
  <Step title="Sign up for an account">
    Create your account at [app.crewai.com](https://app.crewai.com)

    <Card title="Sign Up" icon="user" href="https://app.crewai.com/signup">
      Sign Up
    </Card>
  </Step>

  <Step title="Build your first crew">
    Use code or Crew Studio to build your crew

    <Card title="Build Crew" icon="paintbrush" href="/en/enterprise/guides/build-crew">
      Build Crew
    </Card>
  </Step>

  <Step title="Deploy your crew">
    Deploy your crew to the Enterprise platform

    <Card title="Deploy Crew" icon="rocket" href="/en/enterprise/guides/deploy-crew">
      Deploy Crew
    </Card>
  </Step>

  <Step title="Access your crew">
    Integrate with your crew via the generated API endpoints

    <Card title="API Access" icon="code" href="/en/enterprise/guides/kickoff-crew">
      Use the Crew API
    </Card>
  </Step>
</Steps>

For detailed instructions, check out our [deployment guide](/en/enterprise/guides/deploy-crew) or click the button below to get started.


# FAQs
Source: https://docs.crewai.com/en/enterprise/resources/frequently-asked-questions

Frequently asked questions about CrewAI Enterprise

<AccordionGroup>
  <Accordion title="How is task execution handled in the hierarchical process?">
    In the hierarchical process, a manager agent is automatically created and coordinates the workflow, delegating tasks and validating outcomes for streamlined and effective execution. The manager agent utilizes tools to facilitate task delegation and execution by agents under the manager's guidance. The manager LLM is crucial for the hierarchical process and must be set up correctly for proper function.
  </Accordion>

  <Accordion title="Where can I get the latest CrewAI documentation?">
    The most up-to-date documentation for CrewAI is available on our official documentation website: [https://docs.crewai.com/](https://docs.crewai.com/)
    <Card href="https://docs.crewai.com/" icon="books">CrewAI Docs</Card>
  </Accordion>

  <Accordion title="What are the key differences between Hierarchical and Sequential Processes in CrewAI?">
    #### Hierarchical Process:

    * Tasks are delegated and executed based on a structured chain of command
    * A manager language model (`manager_llm`) must be specified for the manager agent
    * Manager agent oversees task execution, planning, delegation, and validation
    * Tasks are not pre-assigned; the manager allocates tasks to agents based on their capabilities

    #### Sequential Process:

    * Tasks are executed one after another, ensuring tasks are completed in an orderly progression
    * Output of one task serves as context for the next
    * Task execution follows the predefined order in the task list

    #### Which Process is Better for Complex Projects?

    The hierarchical process is better suited for complex projects because it allows for:

    * **Dynamic task allocation and delegation**: Manager agent can assign tasks based on agent capabilities
    * **Structured validation and oversight**: Manager agent reviews task outputs and ensures completion
    * **Complex task management**: Precise control over tool availability at the agent level
  </Accordion>

  <Accordion title="What are the benefits of using memory in the CrewAI framework?">
    * **Adaptive Learning**: Crews become more efficient over time, adapting to new information and refining their approach to tasks
    * **Enhanced Personalization**: Memory enables agents to remember user preferences and historical interactions, leading to personalized experiences
    * **Improved Problem Solving**: Access to a rich memory store aids agents in making more informed decisions, drawing on past learnings and contextual insights
  </Accordion>

  <Accordion title="What is the purpose of setting a maximum RPM limit for an agent?">
    Setting a maximum RPM limit for an agent prevents the agent from making too many requests to external services, which can help to avoid rate limits and improve performance.
  </Accordion>

  <Accordion title="What role does human input play in the execution of tasks within a CrewAI crew?">
    Human input allows agents to request additional information or clarification when necessary. This feature is crucial in complex decision-making processes or when agents require more details to complete a task effectively.

    To integrate human input into agent execution, set the `human_input` flag in the task definition. When enabled, the agent prompts the user for input before delivering its final answer. This input can provide extra context, clarify ambiguities, or validate the agent's output.

    For detailed implementation guidance, see our [Human-in-the-Loop guide](/en/how-to/human-in-the-loop).
  </Accordion>

  <Accordion title="What advanced customization options are available for tailoring and enhancing agent behavior and capabilities in CrewAI?">
    CrewAI provides a range of advanced customization options:

    * **Language Model Customization**: Agents can be customized with specific language models (`llm`) and function-calling language models (`function_calling_llm`)
    * **Performance and Debugging Settings**: Adjust an agent's performance and monitor its operations
    * **Verbose Mode**: Enables detailed logging of an agent's actions, useful for debugging and optimization
    * **RPM Limit**: Sets the maximum number of requests per minute (`max_rpm`)
    * **Maximum Iterations**: The `max_iter` attribute allows users to define the maximum number of iterations an agent can perform for a single task
    * **Delegation and Autonomy**: Control an agent's ability to delegate or ask questions with the `allow_delegation` attribute (default: True)
    * **Human Input Integration**: Agents can request additional information or clarification when necessary
  </Accordion>

  <Accordion title="In what scenarios is human input particularly useful in agent execution?">
    Human input is particularly useful when:

    * **Agents require additional information or clarification**: When agents encounter ambiguity or incomplete data
    * **Agents need to make complex or sensitive decisions**: Human input can assist in ethical or nuanced decision-making
    * **Oversight and validation of agent output**: Human input can help validate results and prevent errors
    * **Customizing agent behavior**: Human input can provide feedback to refine agent responses over time
    * **Identifying and resolving errors or limitations**: Human input helps address agent capability gaps
  </Accordion>

  <Accordion title="What are the different types of memory that are available in crewAI?">
    The different types of memory available in CrewAI are:

    * **Short-term memory**: Temporary storage for immediate context
    * **Long-term memory**: Persistent storage for learned patterns and information
    * **Entity memory**: Focused storage for specific entities and their attributes
    * **Contextual memory**: Memory that maintains context across interactions

    Learn more about the different types of memory:
    <Card href="https://docs.crewai.com/concepts/memory" icon="brain">CrewAI Memory</Card>
  </Accordion>

  <Accordion title="How do I use Output Pydantic in a Task?">
    To use Output Pydantic in a task, you need to define the expected output of the task as a Pydantic model. Here's a quick example:

    <Steps>
      <Step title="Define a Pydantic model">
        ```python
        from pydantic import BaseModel

        class User(BaseModel):
            name: str
            age: int
        ```
      </Step>

      <Step title="Create a task with Output Pydantic">
        ```python
        from crewai import Task, Crew, Agent
        from my_models import User

        task = Task(
            description="Create a user with the provided name and age",
            expected_output=User,  # This is the Pydantic model
            agent=agent,
            tools=[tool1, tool2]
        )
        ```
      </Step>

      <Step title="Set the output_pydantic attribute in your agent">
        ```python
        from crewai import Agent
        from my_models import User

        agent = Agent(
            role='User Creator',
            goal='Create users',
            backstory='I am skilled in creating user accounts',
            tools=[tool1, tool2],
            output_pydantic=User
        )
        ```
      </Step>
    </Steps>

    Here's a tutorial on how to consistently get structured outputs from your agents:

    <Frame>
      <iframe height="400" width="100%" src="https://www.youtube.com/embed/dNpKQk5uxHw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />
    </Frame>
  </Accordion>

  <Accordion title="How can I create custom tools for my CrewAI agents?">
    You can create custom tools by subclassing the `BaseTool` class provided by CrewAI or by using the tool decorator. Subclassing involves defining a new class that inherits from `BaseTool`, specifying the name, description, and the `_run` method for operational logic. The tool decorator allows you to create a `Tool` object directly with the required attributes and a functional logic.

    <Card href="https://docs.crewai.com/how-to/create-custom-tools" icon="code">CrewAI Tools Guide</Card>
  </Accordion>

  <Accordion title="How can you control the maximum number of requests per minute that the entire crew can perform?">
    The `max_rpm` attribute sets the maximum number of requests per minute the crew can perform to avoid rate limits and will override individual agents' `max_rpm` settings if you set it.
  </Accordion>
</AccordionGroup>


# CrewAI Examples
Source: https://docs.crewai.com/en/examples/example

A collection of examples that show how to use CrewAI framework to automate workflows.

<CardGroup cols={3}>
  <Card title="Marketing Strategy" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/marketing_strategy" icon="bullhorn" iconType="solid">
    Automate marketing strategy creation with CrewAI.
  </Card>

  <Card title="Surprise Trip" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/surprise_trip" icon="plane" iconType="duotone">
    Create a surprise trip itinerary with CrewAI.
  </Card>

  <Card title="Match Profile to Positions" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/match_profile_to_positions" icon="linkedin" iconType="duotone">
    Match a profile to jobpositions with CrewAI.
  </Card>

  <Card title="Create Job Posting" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/job-posting" icon="newspaper" iconType="duotone">
    Create a job posting with CrewAI.
  </Card>

  <Card title="Game Generator" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/game-builder-crew" icon="gamepad" iconType="duotone">
    Create a game with CrewAI.
  </Card>

  <Card title="Find Job Candidates" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/recruitment" icon="user-group" iconType="duotone">
    Find job candidates with CrewAI.
  </Card>
</CardGroup>


# Customizing Prompts
Source: https://docs.crewai.com/en/guides/advanced/customizing-prompts

Dive deeper into low-level prompt customization for CrewAI, enabling super custom and complex use cases for different models and languages.

## Why Customize Prompts?

Although CrewAI's default prompts work well for many scenarios, low-level customization opens the door to significantly more flexible and powerful agent behavior. Here's why you might want to take advantage of this deeper control:

1. **Optimize for specific LLMs** ‚Äì Different models (such as GPT-4, Claude, or Llama) thrive with prompt formats tailored to their unique architectures.
2. **Change the language** ‚Äì Build agents that operate exclusively in languages beyond English, handling nuances with precision.
3. **Specialize for complex domains** ‚Äì Adapt prompts for highly specialized industries like healthcare, finance, or legal.
4. **Adjust tone and style** ‚Äì Make agents more formal, casual, creative, or analytical.
5. **Support super custom use cases** ‚Äì Utilize advanced prompt structures and formatting to meet intricate, project-specific requirements.

This guide explores how to tap into CrewAI's prompts at a lower level, giving you fine-grained control over how agents think and interact.

## Understanding CrewAI's Prompt System

Under the hood, CrewAI employs a modular prompt system that you can customize extensively:

* **Agent templates** ‚Äì Govern each agent's approach to their assigned role.
* **Prompt slices** ‚Äì Control specialized behaviors such as tasks, tool usage, and output structure.
* **Error handling** ‚Äì Direct how agents respond to failures, exceptions, or timeouts.
* **Tool-specific prompts** ‚Äì Define detailed instructions for how tools are invoked or utilized.

Check out the [original prompt templates in CrewAI's repository](https://github.com/crewAIInc/crewAI/blob/main/src/crewai/translations/en.json) to see how these elements are organized. From there, you can override or adapt them as needed to unlock advanced behaviors.

## Understanding Default System Instructions

<Warning>
  **Production Transparency Issue**: CrewAI automatically injects default instructions into your prompts that you might not be aware of. This section explains what's happening under the hood and how to gain full control.
</Warning>

When you define an agent with `role`, `goal`, and `backstory`, CrewAI automatically adds additional system instructions that control formatting and behavior. Understanding these default injections is crucial for production systems where you need full prompt transparency.

### What CrewAI Automatically Injects

Based on your agent configuration, CrewAI adds different default instructions:

#### For Agents Without Tools

```text
"I MUST use these formats, my job depends on it!"
```

#### For Agents With Tools

```text
"IMPORTANT: Use the following format in your response:

Thought: you should always think about what to do
Action: the action to take, only one name of [tool_names]
Action Input: the input to the action, just a simple JSON object...
```

#### For Structured Outputs (JSON/Pydantic)

````text
"Ensure your final answer contains only the content in the following format: {output_format}
Ensure the final output does not include any code block markers like ```json or ```python."
````

### Viewing the Complete System Prompt

To see exactly what prompt is being sent to your LLM, you can inspect the generated prompt:

```python
from crewai import Agent, Crew, Task
from crewai.utilities.prompts import Prompts

# Create your agent
agent = Agent(
    role="Data Analyst",
    goal="Analyze data and provide insights",
    backstory="You are an expert data analyst with 10 years of experience.",
    verbose=True
)

# Create a sample task
task = Task(
    description="Analyze the sales data and identify trends",
    expected_output="A detailed analysis with key insights and trends",
    agent=agent
)

# Create the prompt generator
prompt_generator = Prompts(
    agent=agent,
    has_tools=len(agent.tools) > 0,
    use_system_prompt=agent.use_system_prompt
)

# Generate and inspect the actual prompt
generated_prompt = prompt_generator.task_execution()

# Print the complete system prompt that will be sent to the LLM
if "system" in generated_prompt:
    print("=== SYSTEM PROMPT ===")
    print(generated_prompt["system"])
    print("\n=== USER PROMPT ===")
    print(generated_prompt["user"])
else:
    print("=== COMPLETE PROMPT ===")
    print(generated_prompt["prompt"])

# You can also see how the task description gets formatted
print("\n=== TASK CONTEXT ===")
print(f"Task Description: {task.description}")
print(f"Expected Output: {task.expected_output}")
```

### Overriding Default Instructions

You have several options to gain full control over the prompts:

#### Option 1: Custom Templates (Recommended)

```python
from crewai import Agent

# Define your own system template without default instructions
custom_system_template = """You are {role}. {backstory}
Your goal is: {goal}

Respond naturally and conversationally. Focus on providing helpful, accurate information."""

custom_prompt_template = """Task: {input}

Please complete this task thoughtfully."""

agent = Agent(
    role="Research Assistant",
    goal="Help users find accurate information",
    backstory="You are a helpful research assistant.",
    system_template=custom_system_template,
    prompt_template=custom_prompt_template,
    use_system_prompt=True  # Use separate system/user messages
)
```

#### Option 2: Custom Prompt File

Create a `custom_prompts.json` file to override specific prompt slices:

```json
{
  "slices": {
    "no_tools": "\nProvide your best answer in a natural, conversational way.",
    "tools": "\nYou have access to these tools: {tools}\n\nUse them when helpful, but respond naturally.",
    "formatted_task_instructions": "Format your response as: {output_format}"
  }
}
```

Then use it in your crew:

```python
crew = Crew(
    agents=[agent],
    tasks=[task],
    prompt_file="custom_prompts.json",
    verbose=True
)
```

#### Option 3: Disable System Prompts for o1 Models

```python
agent = Agent(
    role="Analyst",
    goal="Analyze data",
    backstory="Expert analyst",
    use_system_prompt=False  # Disables system prompt separation
)
```

### Debugging with Observability Tools

For production transparency, integrate with observability platforms to monitor all prompts and LLM interactions. This allows you to see exactly what prompts (including default instructions) are being sent to your LLMs.

See our [Observability documentation](/en/observability/overview) for detailed integration guides with various platforms including Langfuse, MLflow, Weights & Biases, and custom logging solutions.

### Best Practices for Production

1. **Always inspect generated prompts** before deploying to production
2. **Use custom templates** when you need full control over prompt content
3. **Integrate observability tools** for ongoing prompt monitoring (see [Observability docs](/en/observability/overview))
4. **Test with different LLMs** as default instructions may work differently across models
5. **Document your prompt customizations** for team transparency

<Tip>
  The default instructions exist to ensure consistent agent behavior, but they can interfere with domain-specific requirements. Use the customization options above to maintain full control over your agent's behavior in production systems.
</Tip>

## Best Practices for Managing Prompt Files

When engaging in low-level prompt customization, follow these guidelines to keep things organized and maintainable:

1. **Keep files separate** ‚Äì Store your customized prompts in dedicated JSON files outside your main codebase.
2. **Version control** ‚Äì Track changes within your repository, ensuring clear documentation of prompt adjustments over time.
3. **Organize by model or language** ‚Äì Use naming schemes like `prompts_llama.json` or `prompts_es.json` to quickly identify specialized configurations.
4. **Document changes** ‚Äì Provide comments or maintain a README detailing the purpose and scope of your customizations.
5. **Minimize alterations** ‚Äì Only override the specific slices you genuinely need to adjust, keeping default functionality intact for everything else.

## The Simplest Way to Customize Prompts

One straightforward approach is to create a JSON file for the prompts you want to override and then point your Crew at that file:

1. Craft a JSON file with your updated prompt slices.
2. Reference that file via the `prompt_file` parameter in your Crew.

CrewAI then merges your customizations with the defaults, so you don't have to redefine every prompt. Here's how:

### Example: Basic Prompt Customization

Create a `custom_prompts.json` file with the prompts you want to modify. Ensure you list all top-level prompts it should contain, not just your changes:

```json
{
  "slices": {
    "format": "When responding, follow this structure:\n\nTHOUGHTS: Your step-by-step thinking\nACTION: Any tool you're using\nRESULT: Your final answer or conclusion"
  }
}
```

Then integrate it like so:

```python
from crewai import Agent, Crew, Task, Process

# Create agents and tasks as normal
researcher = Agent(
    role="Research Specialist",
    goal="Find information on quantum computing",
    backstory="You are a quantum physics expert",
    verbose=True
)

research_task = Task(
    description="Research quantum computing applications",
    expected_output="A summary of practical applications",
    agent=researcher
)

# Create a crew with your custom prompt file
crew = Crew(
    agents=[researcher],
    tasks=[research_task],
    prompt_file="path/to/custom_prompts.json",
    verbose=True
)

# Run the crew
result = crew.kickoff()
```

With these few edits, you gain low-level control over how your agents communicate and solve tasks.

## Optimizing for Specific Models

Different models thrive on differently structured prompts. Making deeper adjustments can significantly boost performance by aligning your prompts with a model's nuances.

### Example: Llama 3.3 Prompting Template

For instance, when dealing with Meta's Llama 3.3, deeper-level customization may reflect the recommended structure described at:
[https://www.llama.com/docs/model-cards-and-prompt-formats/llama3\_1/#prompt-template](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1/#prompt-template)

Here's an example to highlight how you might fine-tune an Agent to leverage Llama 3.3 in code:

```python
from crewai import Agent, Crew, Task, Process
from crewai_tools import DirectoryReadTool, FileReadTool

# Define templates for system, user (prompt), and assistant (response) messages
system_template = """<|begin_of_text|><|start_header_id|>system<|end_header_id|>{{ .System }}<|eot_id|>"""
prompt_template = """<|start_header_id|>user<|end_header_id|>{{ .Prompt }}<|eot_id|>"""
response_template = """<|start_header_id|>assistant<|end_header_id|>{{ .Response }}<|eot_id|>"""

# Create an Agent using Llama-specific layouts
principal_engineer = Agent(
    role="Principal Engineer",
    goal="Oversee AI architecture and make high-level decisions",
    backstory="You are the lead engineer responsible for critical AI systems",
    verbose=True,
    llm="groq/llama-3.3-70b-versatile",  # Using the Llama 3 model
    system_template=system_template,
    prompt_template=prompt_template,
    response_template=response_template,
    tools=[DirectoryReadTool(), FileReadTool()]
)

# Define a sample task
engineering_task = Task(
    description="Review AI implementation files for potential improvements",
    expected_output="A summary of key findings and recommendations",
    agent=principal_engineer
)

# Create a Crew for the task
llama_crew = Crew(
    agents=[principal_engineer],
    tasks=[engineering_task],
    process=Process.sequential,
    verbose=True
)

# Execute the crew
result = llama_crew.kickoff()
print(result.raw)
```

Through this deeper configuration, you can exercise comprehensive, low-level control over your Llama-based workflows without needing a separate JSON file.

## Conclusion

Low-level prompt customization in CrewAI opens the door to super custom, complex use cases. By establishing well-organized prompt files (or direct inline templates), you can accommodate various models, languages, and specialized domains. This level of flexibility ensures you can craft precisely the AI behavior you need, all while knowing CrewAI still provides reliable defaults when you don't override them.

<Check>
  You now have the foundation for advanced prompt customizations in CrewAI. Whether you're adapting for model-specific structures or domain-specific constraints, this low-level approach lets you shape agent interactions in highly specialized ways.
</Check>


# Fingerprinting
Source: https://docs.crewai.com/en/guides/advanced/fingerprinting

Learn how to use CrewAI's fingerprinting system to uniquely identify and track components throughout their lifecycle.

## Overview

Fingerprints in CrewAI provide a way to uniquely identify and track components throughout their lifecycle. Each `Agent`, `Crew`, and `Task` automatically receives a unique fingerprint when created, which cannot be manually overridden.

These fingerprints can be used for:

* Auditing and tracking component usage
* Ensuring component identity integrity
* Attaching metadata to components
* Creating a traceable chain of operations

## How Fingerprints Work

A fingerprint is an instance of the `Fingerprint` class from the `crewai.security` module. Each fingerprint contains:

* A UUID string: A unique identifier for the component that is automatically generated and cannot be manually set
* A creation timestamp: When the fingerprint was generated, automatically set and cannot be manually modified
* Metadata: A dictionary of additional information that can be customized

Fingerprints are automatically generated and assigned when a component is created. Each component exposes its fingerprint through a read-only property.

## Basic Usage

### Accessing Fingerprints

```python
from crewai import Agent, Crew, Task

# Create components - fingerprints are automatically generated
agent = Agent(
    role="Data Scientist",
    goal="Analyze data",
    backstory="Expert in data analysis"
)

crew = Crew(
    agents=[agent],
    tasks=[]
)

task = Task(
    description="Analyze customer data",
    expected_output="Insights from data analysis",
    agent=agent
)

# Access the fingerprints
agent_fingerprint = agent.fingerprint
crew_fingerprint = crew.fingerprint
task_fingerprint = task.fingerprint

# Print the UUID strings
print(f"Agent fingerprint: {agent_fingerprint.uuid_str}")
print(f"Crew fingerprint: {crew_fingerprint.uuid_str}")
print(f"Task fingerprint: {task_fingerprint.uuid_str}")
```

### Working with Fingerprint Metadata

You can add metadata to fingerprints for additional context:

```python
# Add metadata to the agent's fingerprint
agent.security_config.fingerprint.metadata = {
    "version": "1.0",
    "department": "Data Science",
    "project": "Customer Analysis"
}

# Access the metadata
print(f"Agent metadata: {agent.fingerprint.metadata}")
```

## Fingerprint Persistence

Fingerprints are designed to persist and remain unchanged throughout a component's lifecycle. If you modify a component, the fingerprint remains the same:

```python
original_fingerprint = agent.fingerprint.uuid_str

# Modify the agent
agent.goal = "New goal for analysis"

# The fingerprint remains unchanged
assert agent.fingerprint.uuid_str == original_fingerprint
```

## Deterministic Fingerprints

While you cannot directly set the UUID and creation timestamp, you can create deterministic fingerprints using the `generate` method with a seed:

```python
from crewai.security import Fingerprint

# Create a deterministic fingerprint using a seed string
deterministic_fingerprint = Fingerprint.generate(seed="my-agent-id")

# The same seed always produces the same fingerprint
same_fingerprint = Fingerprint.generate(seed="my-agent-id")
assert deterministic_fingerprint.uuid_str == same_fingerprint.uuid_str

# You can also set metadata
custom_fingerprint = Fingerprint.generate(
    seed="my-agent-id",
    metadata={"version": "1.0"}
)
```

## Advanced Usage

### Fingerprint Structure

Each fingerprint has the following structure:

```python
from crewai.security import Fingerprint

fingerprint = agent.fingerprint

# UUID string - the unique identifier (auto-generated)
uuid_str = fingerprint.uuid_str  # e.g., "123e4567-e89b-12d3-a456-426614174000"

# Creation timestamp (auto-generated)
created_at = fingerprint.created_at  # A datetime object

# Metadata - for additional information (can be customized)
metadata = fingerprint.metadata  # A dictionary, defaults to {}
```


# Crafting Effective Agents
Source: https://docs.crewai.com/en/guides/agents/crafting-effective-agents

Learn best practices for designing powerful, specialized AI agents that collaborate effectively to solve complex problems.

## The Art and Science of Agent Design

At the heart of CrewAI lies the agent - a specialized AI entity designed to perform specific roles within a collaborative framework. While creating basic agents is simple, crafting truly effective agents that produce exceptional results requires understanding key design principles and best practices.

This guide will help you master the art of agent design, enabling you to create specialized AI personas that collaborate effectively, think critically, and produce high-quality outputs tailored to your specific needs.

### Why Agent Design Matters

The way you define your agents significantly impacts:

1. **Output quality**: Well-designed agents produce more relevant, high-quality results
2. **Collaboration effectiveness**: Agents with complementary skills work together more efficiently
3. **Task performance**: Agents with clear roles and goals execute tasks more effectively
4. **System scalability**: Thoughtfully designed agents can be reused across multiple crews and contexts

Let's explore best practices for creating agents that excel in these dimensions.

## The 80/20 Rule: Focus on Tasks Over Agents

When building effective AI systems, remember this crucial principle: **80% of your effort should go into designing tasks, and only 20% into defining agents**.

Why? Because even the most perfectly defined agent will fail with poorly designed tasks, but well-designed tasks can elevate even a simple agent. This means:

* Spend most of your time writing clear task instructions
* Define detailed inputs and expected outputs
* Add examples and context to guide execution
* Dedicate the remaining time to agent role, goal, and backstory

This doesn't mean agent design isn't important - it absolutely is. But task design is where most execution failures occur, so prioritize accordingly.

## Core Principles of Effective Agent Design

### 1. The Role-Goal-Backstory Framework

The most powerful agents in CrewAI are built on a strong foundation of three key elements:

#### Role: The Agent's Specialized Function

The role defines what the agent does and their area of expertise. When crafting roles:

* **Be specific and specialized**: Instead of "Writer," use "Technical Documentation Specialist" or "Creative Storyteller"
* **Align with real-world professions**: Base roles on recognizable professional archetypes
* **Include domain expertise**: Specify the agent's field of knowledge (e.g., "Financial Analyst specializing in market trends")

**Examples of effective roles:**

```yaml
role: "Senior UX Researcher specializing in user interview analysis"
role: "Full-Stack Software Architect with expertise in distributed systems"
role: "Corporate Communications Director specializing in crisis management"
```

#### Goal: The Agent's Purpose and Motivation

The goal directs the agent's efforts and shapes their decision-making process. Effective goals should:

* **Be clear and outcome-focused**: Define what the agent is trying to achieve
* **Emphasize quality standards**: Include expectations about the quality of work
* **Incorporate success criteria**: Help the agent understand what "good" looks like

**Examples of effective goals:**

```yaml
goal: "Uncover actionable user insights by analyzing interview data and identifying recurring patterns, unmet needs, and improvement opportunities"
goal: "Design robust, scalable system architectures that balance performance, maintainability, and cost-effectiveness"
goal: "Craft clear, empathetic crisis communications that address stakeholder concerns while protecting organizational reputation"
```

#### Backstory: The Agent's Experience and Perspective

The backstory gives depth to the agent, influencing how they approach problems and interact with others. Good backstories:

* **Establish expertise and experience**: Explain how the agent gained their skills
* **Define working style and values**: Describe how the agent approaches their work
* **Create a cohesive persona**: Ensure all elements of the backstory align with the role and goal

**Examples of effective backstories:**

```yaml
backstory: "You have spent 15 years conducting and analyzing user research for top tech companies. You have a talent for reading between the lines and identifying patterns that others miss. You believe that good UX is invisible and that the best insights come from listening to what users don't say as much as what they do say."

backstory: "With 20+ years of experience building distributed systems at scale, you've developed a pragmatic approach to software architecture. You've seen both successful and failed systems and have learned valuable lessons from each. You balance theoretical best practices with practical constraints and always consider the maintenance and operational aspects of your designs."

backstory: "As a seasoned communications professional who has guided multiple organizations through high-profile crises, you understand the importance of transparency, speed, and empathy in crisis response. You have a methodical approach to crafting messages that address concerns while maintaining organizational credibility."
```

### 2. Specialists Over Generalists

Agents perform significantly better when given specialized roles rather than general ones. A highly focused agent delivers more precise, relevant outputs:

**Generic (Less Effective):**

```yaml
role: "Writer"
```

**Specialized (More Effective):**

```yaml
role: "Technical Blog Writer specializing in explaining complex AI concepts to non-technical audiences"
```

**Specialist Benefits:**

* Clearer understanding of expected output
* More consistent performance
* Better alignment with specific tasks
* Improved ability to make domain-specific judgments

### 3. Balancing Specialization and Versatility

Effective agents strike the right balance between specialization (doing one thing extremely well) and versatility (being adaptable to various situations):

* **Specialize in role, versatile in application**: Create agents with specialized skills that can be applied across multiple contexts
* **Avoid overly narrow definitions**: Ensure agents can handle variations within their domain of expertise
* **Consider the collaborative context**: Design agents whose specializations complement the other agents they'll work with

### 4. Setting Appropriate Expertise Levels

The expertise level you assign to your agent shapes how they approach tasks:

* **Novice agents**: Good for straightforward tasks, brainstorming, or initial drafts
* **Intermediate agents**: Suitable for most standard tasks with reliable execution
* **Expert agents**: Best for complex, specialized tasks requiring depth and nuance
* **World-class agents**: Reserved for critical tasks where exceptional quality is needed

Choose the appropriate expertise level based on task complexity and quality requirements. For most collaborative crews, a mix of expertise levels often works best, with higher expertise assigned to core specialized functions.

## Practical Examples: Before and After

Let's look at some examples of agent definitions before and after applying these best practices:

### Example 1: Content Creation Agent

**Before:**

```yaml
role: "Writer"
goal: "Write good content"
backstory: "You are a writer who creates content for websites."
```

**After:**

```yaml
role: "B2B Technology Content Strategist"
goal: "Create compelling, technically accurate content that explains complex topics in accessible language while driving reader engagement and supporting business objectives"
backstory: "You have spent a decade creating content for leading technology companies, specializing in translating technical concepts for business audiences. You excel at research, interviewing subject matter experts, and structuring information for maximum clarity and impact. You believe that the best B2B content educates first and sells second, building trust through genuine expertise rather than marketing hype."
```

### Example 2: Research Agent

**Before:**

```yaml
role: "Researcher"
goal: "Find information"
backstory: "You are good at finding information online."
```

**After:**

```yaml
role: "Academic Research Specialist in Emerging Technologies"
goal: "Discover and synthesize cutting-edge research, identifying key trends, methodologies, and findings while evaluating the quality and reliability of sources"
backstory: "With a background in both computer science and library science, you've mastered the art of digital research. You've worked with research teams at prestigious universities and know how to navigate academic databases, evaluate research quality, and synthesize findings across disciplines. You're methodical in your approach, always cross-referencing information and tracing claims to primary sources before drawing conclusions."
```

## Crafting Effective Tasks for Your Agents

While agent design is important, task design is critical for successful execution. Here are best practices for designing tasks that set your agents up for success:

### The Anatomy of an Effective Task

A well-designed task has two key components that serve different purposes:

#### Task Description: The Process

The description should focus on what to do and how to do it, including:

* Detailed instructions for execution
* Context and background information
* Scope and constraints
* Process steps to follow

#### Expected Output: The Deliverable

The expected output should define what the final result should look like:

* Format specifications (markdown, JSON, etc.)
* Structure requirements
* Quality criteria
* Examples of good outputs (when possible)

### Task Design Best Practices

#### 1. Single Purpose, Single Output

Tasks perform best when focused on one clear objective:

**Bad Example (Too Broad):**

```yaml
task_description: "Research market trends, analyze the data, and create a visualization."
```

**Good Example (Focused):**

```yaml
# Task 1
research_task:
  description: "Research the top 5 market trends in the AI industry for 2024."
  expected_output: "A markdown list of the 5 trends with supporting evidence."

# Task 2
analysis_task:
  description: "Analyze the identified trends to determine potential business impacts."
  expected_output: "A structured analysis with impact ratings (High/Medium/Low)."

# Task 3
visualization_task:
  description: "Create a visual representation of the analyzed trends."
  expected_output: "A description of a chart showing trends and their impact ratings."
```

#### 2. Be Explicit About Inputs and Outputs

Always clearly specify what inputs the task will use and what the output should look like:

**Example:**

```yaml
analysis_task:
  description: >
    Analyze the customer feedback data from the CSV file.
    Focus on identifying recurring themes related to product usability.
    Consider sentiment and frequency when determining importance.
  expected_output: >
    A markdown report with the following sections:
    1. Executive summary (3-5 bullet points)
    2. Top 3 usability issues with supporting data
    3. Recommendations for improvement
```

#### 3. Include Purpose and Context

Explain why the task matters and how it fits into the larger workflow:

**Example:**

```yaml
competitor_analysis_task:
  description: >
    Analyze our three main competitors' pricing strategies.
    This analysis will inform our upcoming pricing model revision.
    Focus on identifying patterns in how they price premium features
    and how they structure their tiered offerings.
```

#### 4. Use Structured Output Tools

For machine-readable outputs, specify the format clearly:

**Example:**

```yaml
data_extraction_task:
  description: "Extract key metrics from the quarterly report."
  expected_output: "JSON object with the following keys: revenue, growth_rate, customer_acquisition_cost, and retention_rate."
```

## Common Mistakes to Avoid

Based on lessons learned from real-world implementations, here are the most common pitfalls in agent and task design:

### 1. Unclear Task Instructions

**Problem:** Tasks lack sufficient detail, making it difficult for agents to execute effectively.

**Example of Poor Design:**

```yaml
research_task:
  description: "Research AI trends."
  expected_output: "A report on AI trends."
```

**Improved Version:**

```yaml
research_task:
  description: >
    Research the top emerging AI trends for 2024 with a focus on:
    1. Enterprise adoption patterns
    2. Technical breakthroughs in the past 6 months
    3. Regulatory developments affecting implementation

    For each trend, identify key companies, technologies, and potential business impacts.
  expected_output: >
    A comprehensive markdown report with:
    - Executive summary (5 bullet points)
    - 5-7 major trends with supporting evidence
    - For each trend: definition, examples, and business implications
    - References to authoritative sources
```

### 2. "God Tasks" That Try to Do Too Much

**Problem:** Tasks that combine multiple complex operations into one instruction set.

**Example of Poor Design:**

```yaml
comprehensive_task:
  description: "Research market trends, analyze competitor strategies, create a marketing plan, and design a launch timeline."
```

**Improved Version:**
Break this into sequential, focused tasks:

```yaml
# Task 1: Research
market_research_task:
  description: "Research current market trends in the SaaS project management space."
  expected_output: "A markdown summary of key market trends."

# Task 2: Competitive Analysis
competitor_analysis_task:
  description: "Analyze strategies of the top 3 competitors based on the market research."
  expected_output: "A comparison table of competitor strategies."
  context: [market_research_task]

# Continue with additional focused tasks...
```

### 3. Misaligned Description and Expected Output

**Problem:** The task description asks for one thing while the expected output specifies something different.

**Example of Poor Design:**

```yaml
analysis_task:
  description: "Analyze customer feedback to find areas of improvement."
  expected_output: "A marketing plan for the next quarter."
```

**Improved Version:**

```yaml
analysis_task:
  description: "Analyze customer feedback to identify the top 3 areas for product improvement."
  expected_output: "A report listing the 3 priority improvement areas with supporting customer quotes and data points."
```

### 4. Not Understanding the Process Yourself

**Problem:** Asking agents to execute tasks that you yourself don't fully understand.

**Solution:**

1. Try to perform the task manually first
2. Document your process, decision points, and information sources
3. Use this documentation as the basis for your task description

### 5. Premature Use of Hierarchical Structures

**Problem:** Creating unnecessarily complex agent hierarchies where sequential processes would work better.

**Solution:** Start with sequential processes and only move to hierarchical models when the workflow complexity truly requires it.

### 6. Vague or Generic Agent Definitions

**Problem:** Generic agent definitions lead to generic outputs.

**Example of Poor Design:**

```yaml
agent:
  role: "Business Analyst"
  goal: "Analyze business data"
  backstory: "You are good at business analysis."
```

**Improved Version:**

```yaml
agent:
  role: "SaaS Metrics Specialist focusing on growth-stage startups"
  goal: "Identify actionable insights from business data that can directly impact customer retention and revenue growth"
  backstory: "With 10+ years analyzing SaaS business models, you've developed a keen eye for the metrics that truly matter for sustainable growth. You've helped numerous companies identify the leverage points that turned around their business trajectory. You believe in connecting data to specific, actionable recommendations rather than general observations."
```

## Advanced Agent Design Strategies

### Designing for Collaboration

When creating agents that will work together in a crew, consider:

* **Complementary skills**: Design agents with distinct but complementary abilities
* **Handoff points**: Define clear interfaces for how work passes between agents
* **Constructive tension**: Sometimes, creating agents with slightly different perspectives can lead to better outcomes through productive dialogue

For example, a content creation crew might include:

```yaml
# Research Agent
role: "Research Specialist for technical topics"
goal: "Gather comprehensive, accurate information from authoritative sources"
backstory: "You are a meticulous researcher with a background in library science..."

# Writer Agent
role: "Technical Content Writer"
goal: "Transform research into engaging, clear content that educates and informs"
backstory: "You are an experienced writer who excels at explaining complex concepts..."

# Editor Agent
role: "Content Quality Editor"
goal: "Ensure content is accurate, well-structured, and polished while maintaining consistency"
backstory: "With years of experience in publishing, you have a keen eye for detail..."
```

### Creating Specialized Tool Users

Some agents can be designed specifically to leverage certain tools effectively:

```yaml
role: "Data Analysis Specialist"
goal: "Derive meaningful insights from complex datasets through statistical analysis"
backstory: "With a background in data science, you excel at working with structured and unstructured data..."
tools: [PythonREPLTool, DataVisualizationTool, CSVAnalysisTool]
```

### Tailoring Agents to LLM Capabilities

Different LLMs have different strengths. Design your agents with these capabilities in mind:

```yaml
# For complex reasoning tasks
analyst:
  role: "Data Insights Analyst"
  goal: "..."
  backstory: "..."
  llm: openai/gpt-4o

# For creative content
writer:
  role: "Creative Content Writer"
  goal: "..."
  backstory: "..."
  llm: anthropic/claude-3-opus
```

## Testing and Iterating on Agent Design

Agent design is often an iterative process. Here's a practical approach:

1. **Start with a prototype**: Create an initial agent definition
2. **Test with sample tasks**: Evaluate performance on representative tasks
3. **Analyze outputs**: Identify strengths and weaknesses
4. **Refine the definition**: Adjust role, goal, and backstory based on observations
5. **Test in collaboration**: Evaluate how the agent performs in a crew setting

## Conclusion

Crafting effective agents is both an art and a science. By carefully defining roles, goals, and backstories that align with your specific needs, and combining them with well-designed tasks, you can create specialized AI collaborators that produce exceptional results.

Remember that agent and task design is an iterative process. Start with these best practices, observe your agents in action, and refine your approach based on what you learn. And always keep in mind the 80/20 rule - focus most of your effort on creating clear, focused tasks to get the best results from your agents.

<Check>
  Congratulations! You now understand the principles and practices of effective agent design. Apply these techniques to create powerful, specialized agents that work together seamlessly to accomplish complex tasks.
</Check>

## Next Steps

* Experiment with different agent configurations for your specific use case
* Learn about [building your first crew](/en/guides/crews/first-crew) to see how agents work together
* Explore [CrewAI Flows](/en/guides/flows/first-flow) for more advanced orchestration


# Evaluating Use Cases for CrewAI
Source: https://docs.crewai.com/en/guides/concepts/evaluating-use-cases

Learn how to assess your AI application needs and choose the right approach between Crews and Flows based on complexity and precision requirements.

## Understanding the Decision Framework

When building AI applications with CrewAI, one of the most important decisions you'll make is choosing the right approach for your specific use case. Should you use a Crew? A Flow? A combination of both? This guide will help you evaluate your requirements and make informed architectural decisions.

At the heart of this decision is understanding the relationship between **complexity** and **precision** in your application:

<Frame caption="Complexity vs. Precision Matrix for CrewAI Applications">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/complexity_precision.png" alt="Complexity vs. Precision Matrix" />
</Frame>

This matrix helps visualize how different approaches align with varying requirements for complexity and precision. Let's explore what each quadrant means and how it guides your architectural choices.

## The Complexity-Precision Matrix Explained

### What is Complexity?

In the context of CrewAI applications, **complexity** refers to:

* The number of distinct steps or operations required
* The diversity of tasks that need to be performed
* The interdependencies between different components
* The need for conditional logic and branching
* The sophistication of the overall workflow

### What is Precision?

**Precision** in this context refers to:

* The accuracy required in the final output
* The need for structured, predictable results
* The importance of reproducibility
* The level of control needed over each step
* The tolerance for variation in outputs

### The Four Quadrants

#### 1. Low Complexity, Low Precision

**Characteristics:**

* Simple, straightforward tasks
* Tolerance for some variation in outputs
* Limited number of steps
* Creative or exploratory applications

**Recommended Approach:** Simple Crews with minimal agents

**Example Use Cases:**

* Basic content generation
* Idea brainstorming
* Simple summarization tasks
* Creative writing assistance

#### 2. Low Complexity, High Precision

**Characteristics:**

* Simple workflows that require exact, structured outputs
* Need for reproducible results
* Limited steps but high accuracy requirements
* Often involves data processing or transformation

**Recommended Approach:** Flows with direct LLM calls or simple Crews with structured outputs

**Example Use Cases:**

* Data extraction and transformation
* Form filling and validation
* Structured content generation (JSON, XML)
* Simple classification tasks

#### 3. High Complexity, Low Precision

**Characteristics:**

* Multi-stage processes with many steps
* Creative or exploratory outputs
* Complex interactions between components
* Tolerance for variation in final results

**Recommended Approach:** Complex Crews with multiple specialized agents

**Example Use Cases:**

* Research and analysis
* Content creation pipelines
* Exploratory data analysis
* Creative problem-solving

#### 4. High Complexity, High Precision

**Characteristics:**

* Complex workflows requiring structured outputs
* Multiple interdependent steps with strict accuracy requirements
* Need for both sophisticated processing and precise results
* Often mission-critical applications

**Recommended Approach:** Flows orchestrating multiple Crews with validation steps

**Example Use Cases:**

* Enterprise decision support systems
* Complex data processing pipelines
* Multi-stage document processing
* Regulated industry applications

## Choosing Between Crews and Flows

### When to Choose Crews

Crews are ideal when:

1. **You need collaborative intelligence** - Multiple agents with different specializations need to work together
2. **The problem requires emergent thinking** - The solution benefits from different perspectives and approaches
3. **The task is primarily creative or analytical** - The work involves research, content creation, or analysis
4. **You value adaptability over strict structure** - The workflow can benefit from agent autonomy
5. **The output format can be somewhat flexible** - Some variation in output structure is acceptable

```python
# Example: Research Crew for market analysis
from crewai import Agent, Crew, Process, Task

# Create specialized agents
researcher = Agent(
    role="Market Research Specialist",
    goal="Find comprehensive market data on emerging technologies",
    backstory="You are an expert at discovering market trends and gathering data."
)

analyst = Agent(
    role="Market Analyst",
    goal="Analyze market data and identify key opportunities",
    backstory="You excel at interpreting market data and spotting valuable insights."
)

# Define their tasks
research_task = Task(
    description="Research the current market landscape for AI-powered healthcare solutions",
    expected_output="Comprehensive market data including key players, market size, and growth trends",
    agent=researcher
)

analysis_task = Task(
    description="Analyze the market data and identify the top 3 investment opportunities",
    expected_output="Analysis report with 3 recommended investment opportunities and rationale",
    agent=analyst,
    context=[research_task]
)

# Create the crew
market_analysis_crew = Crew(
    agents=[researcher, analyst],
    tasks=[research_task, analysis_task],
    process=Process.sequential,
    verbose=True
)

# Run the crew
result = market_analysis_crew.kickoff()
```

### When to Choose Flows

Flows are ideal when:

1. **You need precise control over execution** - The workflow requires exact sequencing and state management
2. **The application has complex state requirements** - You need to maintain and transform state across multiple steps
3. **You need structured, predictable outputs** - The application requires consistent, formatted results
4. **The workflow involves conditional logic** - Different paths need to be taken based on intermediate results
5. **You need to combine AI with procedural code** - The solution requires both AI capabilities and traditional programming

```python
# Example: Customer Support Flow with structured processing
from crewai.flow.flow import Flow, listen, router, start
from pydantic import BaseModel
from typing import List, Dict

# Define structured state
class SupportTicketState(BaseModel):
    ticket_id: str = ""
    customer_name: str = ""
    issue_description: str = ""
    category: str = ""
    priority: str = "medium"
    resolution: str = ""
    satisfaction_score: int = 0

class CustomerSupportFlow(Flow[SupportTicketState]):
    @start()
    def receive_ticket(self):
        # In a real app, this might come from an API
        self.state.ticket_id = "TKT-12345"
        self.state.customer_name = "Alex Johnson"
        self.state.issue_description = "Unable to access premium features after payment"
        return "Ticket received"

    @listen(receive_ticket)
    def categorize_ticket(self, _):
        # Use a direct LLM call for categorization
        from crewai import LLM
        llm = LLM(model="openai/gpt-4o-mini")

        prompt = f"""
        Categorize the following customer support issue into one of these categories:
        - Billing
        - Account Access
        - Technical Issue
        - Feature Request
        - Other

        Issue: {self.state.issue_description}

        Return only the category name.
        """

        self.state.category = llm.call(prompt).strip()
        return self.state.category

    @router(categorize_ticket)
    def route_by_category(self, category):
        # Route to different handlers based on category
        return category.lower().replace(" ", "_")

    @listen("billing")
    def handle_billing_issue(self):
        # Handle billing-specific logic
        self.state.priority = "high"
        # More billing-specific processing...
        return "Billing issue handled"

    @listen("account_access")
    def handle_access_issue(self):
        # Handle access-specific logic
        self.state.priority = "high"
        # More access-specific processing...
        return "Access issue handled"

    # Additional category handlers...

    @listen("billing", "account_access", "technical_issue", "feature_request", "other")
    def resolve_ticket(self, resolution_info):
        # Final resolution step
        self.state.resolution = f"Issue resolved: {resolution_info}"
        return self.state.resolution

# Run the flow
support_flow = CustomerSupportFlow()
result = support_flow.kickoff()
```

### When to Combine Crews and Flows

The most sophisticated applications often benefit from combining Crews and Flows:

1. **Complex multi-stage processes** - Use Flows to orchestrate the overall process and Crews for complex subtasks
2. **Applications requiring both creativity and structure** - Use Crews for creative tasks and Flows for structured processing
3. **Enterprise-grade AI applications** - Use Flows to manage state and process flow while leveraging Crews for specialized work

```python
# Example: Content Production Pipeline combining Crews and Flows
from crewai.flow.flow import Flow, listen, start
from crewai import Agent, Crew, Process, Task
from pydantic import BaseModel
from typing import List, Dict

class ContentState(BaseModel):
    topic: str = ""
    target_audience: str = ""
    content_type: str = ""
    outline: Dict = {}
    draft_content: str = ""
    final_content: str = ""
    seo_score: int = 0

class ContentProductionFlow(Flow[ContentState]):
    @start()
    def initialize_project(self):
        # Set initial parameters
        self.state.topic = "Sustainable Investing"
        self.state.target_audience = "Millennial Investors"
        self.state.content_type = "Blog Post"
        return "Project initialized"

    @listen(initialize_project)
    def create_outline(self, _):
        # Use a research crew to create an outline
        researcher = Agent(
            role="Content Researcher",
            goal=f"Research {self.state.topic} for {self.state.target_audience}",
            backstory="You are an expert researcher with deep knowledge of content creation."
        )

        outliner = Agent(
            role="Content Strategist",
            goal=f"Create an engaging outline for a {self.state.content_type}",
            backstory="You excel at structuring content for maximum engagement."
        )

        research_task = Task(
            description=f"Research {self.state.topic} focusing on what would interest {self.state.target_audience}",
            expected_output="Comprehensive research notes with key points and statistics",
            agent=researcher
        )

        outline_task = Task(
            description=f"Create an outline for a {self.state.content_type} about {self.state.topic}",
            expected_output="Detailed content outline with sections and key points",
            agent=outliner,
            context=[research_task]
        )

        outline_crew = Crew(
            agents=[researcher, outliner],
            tasks=[research_task, outline_task],
            process=Process.sequential,
            verbose=True
        )

        # Run the crew and store the result
        result = outline_crew.kickoff()

        # Parse the outline (in a real app, you might use a more robust parsing approach)
        import json
        try:
            self.state.outline = json.loads(result.raw)
        except:
            # Fallback if not valid JSON
            self.state.outline = {"sections": result.raw}

        return "Outline created"

    @listen(create_outline)
    def write_content(self, _):
        # Use a writing crew to create the content
        writer = Agent(
            role="Content Writer",
            goal=f"Write engaging content for {self.state.target_audience}",
            backstory="You are a skilled writer who creates compelling content."
        )

        editor = Agent(
            role="Content Editor",
            goal="Ensure content is polished, accurate, and engaging",
            backstory="You have a keen eye for detail and a talent for improving content."
        )

        writing_task = Task(
            description=f"Write a {self.state.content_type} about {self.state.topic} following this outline: {self.state.outline}",
            expected_output="Complete draft content in markdown format",
            agent=writer
        )

        editing_task = Task(
            description="Edit and improve the draft content for clarity, engagement, and accuracy",
            expected_output="Polished final content in markdown format",
            agent=editor,
            context=[writing_task]
        )

        writing_crew = Crew(
            agents=[writer, editor],
            tasks=[writing_task, editing_task],
            process=Process.sequential,
            verbose=True
        )

        # Run the crew and store the result
        result = writing_crew.kickoff()
        self.state.final_content = result.raw

        return "Content created"

    @listen(write_content)
    def optimize_for_seo(self, _):
        # Use a direct LLM call for SEO optimization
        from crewai import LLM
        llm = LLM(model="openai/gpt-4o-mini")

        prompt = f"""
        Analyze this content for SEO effectiveness for the keyword "{self.state.topic}".
        Rate it on a scale of 1-100 and provide 3 specific recommendations for improvement.

        Content: {self.state.final_content[:1000]}... (truncated for brevity)

        Format your response as JSON with the following structure:
        {{
            "score": 85,
            "recommendations": [
                "Recommendation 1",
                "Recommendation 2",
                "Recommendation 3"
            ]
        }}
        """

        seo_analysis = llm.call(prompt)

        # Parse the SEO analysis
        import json
        try:
            analysis = json.loads(seo_analysis)
            self.state.seo_score = analysis.get("score", 0)
            return analysis
        except:
            self.state.seo_score = 50
            return {"score": 50, "recommendations": ["Unable to parse SEO analysis"]}

# Run the flow
content_flow = ContentProductionFlow()
result = content_flow.kickoff()
```

## Practical Evaluation Framework

To determine the right approach for your specific use case, follow this step-by-step evaluation framework:

### Step 1: Assess Complexity

Rate your application's complexity on a scale of 1-10 by considering:

1. **Number of steps**: How many distinct operations are required?
   * 1-3 steps: Low complexity (1-3)
   * 4-7 steps: Medium complexity (4-7)
   * 8+ steps: High complexity (8-10)

2. **Interdependencies**: How interconnected are the different parts?
   * Few dependencies: Low complexity (1-3)
   * Some dependencies: Medium complexity (4-7)
   * Many complex dependencies: High complexity (8-10)

3. **Conditional logic**: How much branching and decision-making is needed?
   * Linear process: Low complexity (1-3)
   * Some branching: Medium complexity (4-7)
   * Complex decision trees: High complexity (8-10)

4. **Domain knowledge**: How specialized is the knowledge required?
   * General knowledge: Low complexity (1-3)
   * Some specialized knowledge: Medium complexity (4-7)
   * Deep expertise in multiple domains: High complexity (8-10)

Calculate your average score to determine overall complexity.

### Step 2: Assess Precision Requirements

Rate your precision requirements on a scale of 1-10 by considering:

1. **Output structure**: How structured must the output be?
   * Free-form text: Low precision (1-3)
   * Semi-structured: Medium precision (4-7)
   * Strictly formatted (JSON, XML): High precision (8-10)

2. **Accuracy needs**: How important is factual accuracy?
   * Creative content: Low precision (1-3)
   * Informational content: Medium precision (4-7)
   * Critical information: High precision (8-10)

3. **Reproducibility**: How consistent must results be across runs?
   * Variation acceptable: Low precision (1-3)
   * Some consistency needed: Medium precision (4-7)
   * Exact reproducibility required: High precision (8-10)

4. **Error tolerance**: What is the impact of errors?
   * Low impact: Low precision (1-3)
   * Moderate impact: Medium precision (4-7)
   * High impact: High precision (8-10)

Calculate your average score to determine overall precision requirements.

### Step 3: Map to the Matrix

Plot your complexity and precision scores on the matrix:

* **Low Complexity (1-4), Low Precision (1-4)**: Simple Crews
* **Low Complexity (1-4), High Precision (5-10)**: Flows with direct LLM calls
* **High Complexity (5-10), Low Precision (1-4)**: Complex Crews
* **High Complexity (5-10), High Precision (5-10)**: Flows orchestrating Crews

### Step 4: Consider Additional Factors

Beyond complexity and precision, consider:

1. **Development time**: Crews are often faster to prototype
2. **Maintenance needs**: Flows provide better long-term maintainability
3. **Team expertise**: Consider your team's familiarity with different approaches
4. **Scalability requirements**: Flows typically scale better for complex applications
5. **Integration needs**: Consider how the solution will integrate with existing systems

## Conclusion

Choosing between Crews and Flows‚Äîor combining them‚Äîis a critical architectural decision that impacts the effectiveness, maintainability, and scalability of your CrewAI application. By evaluating your use case along the dimensions of complexity and precision, you can make informed decisions that align with your specific requirements.

Remember that the best approach often evolves as your application matures. Start with the simplest solution that meets your needs, and be prepared to refine your architecture as you gain experience and your requirements become clearer.

<Check>
  You now have a framework for evaluating CrewAI use cases and choosing the right approach based on complexity and precision requirements. This will help you build more effective, maintainable, and scalable AI applications.
</Check>

## Next Steps

* Learn more about [crafting effective agents](/en/guides/agents/crafting-effective-agents)
* Explore [building your first crew](/en/guides/crews/first-crew)
* Dive into [mastering flow state management](/en/guides/flows/mastering-flow-state)
* Check out the [core concepts](/en/concepts/agents) for deeper understanding


# Build Your First Crew
Source: https://docs.crewai.com/en/guides/crews/first-crew

Step-by-step tutorial to create a collaborative AI team that works together to solve complex problems.

## Unleashing the Power of Collaborative AI

Imagine having a team of specialized AI agents working together seamlessly to solve complex problems, each contributing their unique skills to achieve a common goal. This is the power of CrewAI - a framework that enables you to create collaborative AI systems that can accomplish tasks far beyond what a single AI could achieve alone.

In this guide, we'll walk through creating a research crew that will help us research and analyze a topic, then create a comprehensive report. This practical example demonstrates how AI agents can collaborate to accomplish complex tasks, but it's just the beginning of what's possible with CrewAI.

### What You'll Build and Learn

By the end of this guide, you'll have:

1. **Created a specialized AI research team** with distinct roles and responsibilities
2. **Orchestrated collaboration** between multiple AI agents
3. **Automated a complex workflow** that involves gathering information, analysis, and report generation
4. **Built foundational skills** that you can apply to more ambitious projects

While we're building a simple research crew in this guide, the same patterns and techniques can be applied to create much more sophisticated teams for tasks like:

* Multi-stage content creation with specialized writers, editors, and fact-checkers
* Complex customer service systems with tiered support agents
* Autonomous business analysts that gather data, create visualizations, and generate insights
* Product development teams that ideate, design, and plan implementation

Let's get started building your first crew!

### Prerequisites

Before starting, make sure you have:

1. Installed CrewAI following the [installation guide](/en/installation)
2. Set up your LLM API key in your environment, following the [LLM setup
   guide](/en/concepts/llms#setting-up-your-llm)
3. Basic understanding of Python

## Step 1: Create a New CrewAI Project

First, let's create a new CrewAI project using the CLI. This command will set up a complete project structure with all the necessary files, allowing you to focus on defining your agents and their tasks rather than setting up boilerplate code.

```bash
crewai create crew research_crew
cd research_crew
```

This will generate a project with the basic structure needed for your crew. The CLI automatically creates:

* A project directory with the necessary files
* Configuration files for agents and tasks
* A basic crew implementation
* A main script to run the crew

<Frame caption="CrewAI Framework Overview">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crews.png" alt="CrewAI Framework Overview" />
</Frame>

## Step 2: Explore the Project Structure

Let's take a moment to understand the project structure created by the CLI. CrewAI follows best practices for Python projects, making it easy to maintain and extend your code as your crews become more complex.

```
research_crew/
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ .env
‚îî‚îÄ‚îÄ src/
    ‚îî‚îÄ‚îÄ research_crew/
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îú‚îÄ‚îÄ main.py
        ‚îú‚îÄ‚îÄ crew.py
        ‚îú‚îÄ‚îÄ tools/
        ‚îÇ   ‚îú‚îÄ‚îÄ custom_tool.py
        ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
        ‚îî‚îÄ‚îÄ config/
            ‚îú‚îÄ‚îÄ agents.yaml
            ‚îî‚îÄ‚îÄ tasks.yaml
```

This structure follows best practices for Python projects and makes it easy to organize your code. The separation of configuration files (in YAML) from implementation code (in Python) makes it easy to modify your crew's behavior without changing the underlying code.

## Step 3: Configure Your Agents

Now comes the fun part - defining your AI agents! In CrewAI, agents are specialized entities with specific roles, goals, and backstories that shape their behavior. Think of them as characters in a play, each with their own personality and purpose.

For our research crew, we'll create two agents:

1. A **researcher** who excels at finding and organizing information
2. An **analyst** who can interpret research findings and create insightful reports

Let's modify the `agents.yaml` file to define these specialized agents. Be sure
to set `llm` to the provider you are using.

```yaml
# src/research_crew/config/agents.yaml
researcher:
  role: >
    Senior Research Specialist for {topic}
  goal: >
    Find comprehensive and accurate information about {topic}
    with a focus on recent developments and key insights
  backstory: >
    You are an experienced research specialist with a talent for
    finding relevant information from various sources. You excel at
    organizing information in a clear and structured manner, making
    complex topics accessible to others.
  llm: provider/model-id  # e.g. openai/gpt-4o, google/gemini-2.0-flash, anthropic/claude...

analyst:
  role: >
    Data Analyst and Report Writer for {topic}
  goal: >
    Analyze research findings and create a comprehensive, well-structured
    report that presents insights in a clear and engaging way
  backstory: >
    You are a skilled analyst with a background in data interpretation
    and technical writing. You have a talent for identifying patterns
    and extracting meaningful insights from research data, then
    communicating those insights effectively through well-crafted reports.
  llm: provider/model-id  # e.g. openai/gpt-4o, google/gemini-2.0-flash, anthropic/claude...
```

Notice how each agent has a distinct role, goal, and backstory. These elements aren't just descriptive - they actively shape how the agent approaches its tasks. By crafting these carefully, you can create agents with specialized skills and perspectives that complement each other.

## Step 4: Define Your Tasks

With our agents defined, we now need to give them specific tasks to perform. Tasks in CrewAI represent the concrete work that agents will perform, with detailed instructions and expected outputs.

For our research crew, we'll define two main tasks:

1. A **research task** for gathering comprehensive information
2. An **analysis task** for creating an insightful report

Let's modify the `tasks.yaml` file:

```yaml
# src/research_crew/config/tasks.yaml
research_task:
  description: >
    Conduct thorough research on {topic}. Focus on:
    1. Key concepts and definitions
    2. Historical development and recent trends
    3. Major challenges and opportunities
    4. Notable applications or case studies
    5. Future outlook and potential developments

    Make sure to organize your findings in a structured format with clear sections.
  expected_output: >
    A comprehensive research document with well-organized sections covering
    all the requested aspects of {topic}. Include specific facts, figures,
    and examples where relevant.
  agent: researcher

analysis_task:
  description: >
    Analyze the research findings and create a comprehensive report on {topic}.
    Your report should:
    1. Begin with an executive summary
    2. Include all key information from the research
    3. Provide insightful analysis of trends and patterns
    4. Offer recommendations or future considerations
    5. Be formatted in a professional, easy-to-read style with clear headings
  expected_output: >
    A polished, professional report on {topic} that presents the research
    findings with added analysis and insights. The report should be well-structured
    with an executive summary, main sections, and conclusion.
  agent: analyst
  context:
    - research_task
  output_file: output/report.md
```

Note the `context` field in the analysis task - this is a powerful feature that allows the analyst to access the output of the research task. This creates a workflow where information flows naturally between agents, just as it would in a human team.

## Step 5: Configure Your Crew

Now it's time to bring everything together by configuring our crew. The crew is the container that orchestrates how agents work together to complete tasks.

Let's modify the `crew.py` file:

```python
# src/research_crew/crew.py
from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task
from crewai_tools import SerperDevTool
from crewai.agents.agent_builder.base_agent import BaseAgent
from typing import List

@CrewBase
class ResearchCrew():
    """Research crew for comprehensive topic analysis and reporting"""

    agents: List[BaseAgent]
    tasks: List[Task]

    @agent
    def researcher(self) -> Agent:
        return Agent(
            config=self.agents_config['researcher'], # type: ignore[index]
            verbose=True,
            tools=[SerperDevTool()]
        )

    @agent
    def analyst(self) -> Agent:
        return Agent(
            config=self.agents_config['analyst'], # type: ignore[index]
            verbose=True
        )

    @task
    def research_task(self) -> Task:
        return Task(
            config=self.tasks_config['research_task'] # type: ignore[index]
        )

    @task
    def analysis_task(self) -> Task:
        return Task(
            config=self.tasks_config['analysis_task'], # type: ignore[index]
            output_file='output/report.md'
        )

    @crew
    def crew(self) -> Crew:
        """Creates the research crew"""
        return Crew(
            agents=self.agents,
            tasks=self.tasks,
            process=Process.sequential,
            verbose=True,
        )
```

In this code, we're:

1. Creating the researcher agent and equipping it with the SerperDevTool to search the web
2. Creating the analyst agent
3. Setting up the research and analysis tasks
4. Configuring the crew to run tasks sequentially (the analyst will wait for the researcher to finish)

This is where the magic happens - with just a few lines of code, we've defined a collaborative AI system where specialized agents work together in a coordinated process.

## Step 6: Set Up Your Main Script

Now, let's set up the main script that will run our crew. This is where we provide the specific topic we want our crew to research.

```python
#!/usr/bin/env python
# src/research_crew/main.py
import os
from research_crew.crew import ResearchCrew

# Create output directory if it doesn't exist
os.makedirs('output', exist_ok=True)

def run():
    """
    Run the research crew.
    """
    inputs = {
        'topic': 'Artificial Intelligence in Healthcare'
    }

    # Create and run the crew
    result = ResearchCrew().crew().kickoff(inputs=inputs)

    # Print the result
    print("\n\n=== FINAL REPORT ===\n\n")
    print(result.raw)

    print("\n\nReport has been saved to output/report.md")

if __name__ == "__main__":
    run()
```

This script prepares the environment, specifies our research topic, and kicks off the crew's work. The power of CrewAI is evident in how simple this code is - all the complexity of managing multiple AI agents is handled by the framework.

## Step 7: Set Up Your Environment Variables

Create a `.env` file in your project root with your API keys:

```sh
SERPER_API_KEY=your_serper_api_key
# Add your provider's API key here too.
```

See the [LLM Setup guide](/en/concepts/llms#setting-up-your-llm) for details on configuring your provider of choice. You can get a Serper API key from [Serper.dev](https://serper.dev/).

## Step 8: Install Dependencies

Install the required dependencies using the CrewAI CLI:

```bash
crewai install
```

This command will:

1. Read the dependencies from your project configuration
2. Create a virtual environment if needed
3. Install all required packages

## Step 9: Run Your Crew

Now for the exciting moment - it's time to run your crew and see AI collaboration in action!

```bash
crewai run
```

When you run this command, you'll see your crew spring to life. The researcher will gather information about the specified topic, and the analyst will then create a comprehensive report based on that research. You'll see the agents' thought processes, actions, and outputs in real-time as they work together to complete their tasks.

## Step 10: Review the Output

Once the crew completes its work, you'll find the final report in the `output/report.md` file. The report will include:

1. An executive summary
2. Detailed information about the topic
3. Analysis and insights
4. Recommendations or future considerations

Take a moment to appreciate what you've accomplished - you've created a system where multiple AI agents collaborated on a complex task, each contributing their specialized skills to produce a result that's greater than what any single agent could achieve alone.

## Exploring Other CLI Commands

CrewAI offers several other useful CLI commands for working with crews:

```bash
# View all available commands
crewai --help

# Run the crew
crewai run

# Test the crew
crewai test

# Reset crew memories
crewai reset-memories

# Replay from a specific task
crewai replay -t <task_id>
```

## The Art of the Possible: Beyond Your First Crew

What you've built in this guide is just the beginning. The skills and patterns you've learned can be applied to create increasingly sophisticated AI systems. Here are some ways you could extend this basic research crew:

### Expanding Your Crew

You could add more specialized agents to your crew:

* A **fact-checker** to verify research findings
* A **data visualizer** to create charts and graphs
* A **domain expert** with specialized knowledge in a particular area
* A **critic** to identify weaknesses in the analysis

### Adding Tools and Capabilities

You could enhance your agents with additional tools:

* Web browsing tools for real-time research
* CSV/database tools for data analysis
* Code execution tools for data processing
* API connections to external services

### Creating More Complex Workflows

You could implement more sophisticated processes:

* Hierarchical processes where manager agents delegate to worker agents
* Iterative processes with feedback loops for refinement
* Parallel processes where multiple agents work simultaneously
* Dynamic processes that adapt based on intermediate results

### Applying to Different Domains

The same patterns can be applied to create crews for:

* **Content creation**: Writers, editors, fact-checkers, and designers working together
* **Customer service**: Triage agents, specialists, and quality control working together
* **Product development**: Researchers, designers, and planners collaborating
* **Data analysis**: Data collectors, analysts, and visualization specialists

## Next Steps

Now that you've built your first crew, you can:

1. Experiment with different agent configurations and personalities
2. Try more complex task structures and workflows
3. Implement custom tools to give your agents new capabilities
4. Apply your crew to different topics or problem domains
5. Explore [CrewAI Flows](/en/guides/flows/first-flow) for more advanced workflows with procedural programming

<Check>
  Congratulations! You've successfully built your first CrewAI crew that can research and analyze any topic you provide. This foundational experience has equipped you with the skills to create increasingly sophisticated AI systems that can tackle complex, multi-stage problems through collaborative intelligence.
</Check>


# Build Your First Flow
Source: https://docs.crewai.com/en/guides/flows/first-flow

Learn how to create structured, event-driven workflows with precise control over execution.

## Taking Control of AI Workflows with Flows

CrewAI Flows represent the next level in AI orchestration - combining the collaborative power of AI agent crews with the precision and flexibility of procedural programming. While crews excel at agent collaboration, flows give you fine-grained control over exactly how and when different components of your AI system interact.

In this guide, we'll walk through creating a powerful CrewAI Flow that generates a comprehensive learning guide on any topic. This tutorial will demonstrate how Flows provide structured, event-driven control over your AI workflows by combining regular code, direct LLM calls, and crew-based processing.

### What Makes Flows Powerful

Flows enable you to:

1. **Combine different AI interaction patterns** - Use crews for complex collaborative tasks, direct LLM calls for simpler operations, and regular code for procedural logic
2. **Build event-driven systems** - Define how components respond to specific events and data changes
3. **Maintain state across components** - Share and transform data between different parts of your application
4. **Integrate with external systems** - Seamlessly connect your AI workflow with databases, APIs, and user interfaces
5. **Create complex execution paths** - Design conditional branches, parallel processing, and dynamic workflows

### What You'll Build and Learn

By the end of this guide, you'll have:

1. **Created a sophisticated content generation system** that combines user input, AI planning, and multi-agent content creation
2. **Orchestrated the flow of information** between different components of your system
3. **Implemented event-driven architecture** where each step responds to the completion of previous steps
4. **Built a foundation for more complex AI applications** that you can expand and customize

This guide creator flow demonstrates fundamental patterns that can be applied to create much more advanced applications, such as:

* Interactive AI assistants that combine multiple specialized subsystems
* Complex data processing pipelines with AI-enhanced transformations
* Autonomous agents that integrate with external services and APIs
* Multi-stage decision-making systems with human-in-the-loop processes

Let's dive in and build your first flow!

## Prerequisites

Before starting, make sure you have:

1. Installed CrewAI following the [installation guide](/en/installation)
2. Set up your LLM API key in your environment, following the [LLM setup
   guide](/en/concepts/llms#setting-up-your-llm)
3. Basic understanding of Python

## Step 1: Create a New CrewAI Flow Project

First, let's create a new CrewAI Flow project using the CLI. This command sets up a scaffolded project with all the necessary directories and template files for your flow.

```bash
crewai create flow guide_creator_flow
cd guide_creator_flow
```

This will generate a project with the basic structure needed for your flow.

<Frame caption="CrewAI Framework Overview">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/flows.png" alt="CrewAI Framework Overview" />
</Frame>

## Step 2: Understanding the Project Structure

The generated project has the following structure. Take a moment to familiarize yourself with it, as understanding this structure will help you create more complex flows in the future.

```
guide_creator_flow/
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ crews/
‚îÇ   ‚îî‚îÄ‚îÄ poem_crew/
‚îÇ       ‚îú‚îÄ‚îÄ config/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ agents.yaml
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ tasks.yaml
‚îÇ       ‚îî‚îÄ‚îÄ poem_crew.py
‚îî‚îÄ‚îÄ tools/
    ‚îî‚îÄ‚îÄ custom_tool.py
```

This structure provides a clear separation between different components of your flow:

* The main flow logic in the `main.py` file
* Specialized crews in the `crews` directory
* Custom tools in the `tools` directory

We'll modify this structure to create our guide creator flow, which will orchestrate the process of generating comprehensive learning guides.

## Step 3: Add a Content Writer Crew

Our flow will need a specialized crew to handle the content creation process. Let's use the CrewAI CLI to add a content writer crew:

```bash
crewai flow add-crew content-crew
```

This command automatically creates the necessary directories and template files for your crew. The content writer crew will be responsible for writing and reviewing sections of our guide, working within the overall flow orchestrated by our main application.

## Step 4: Configure the Content Writer Crew

Now, let's modify the generated files for the content writer crew. We'll set up two specialized agents - a writer and a reviewer - that will collaborate to create high-quality content for our guide.

1. First, update the agents configuration file to define our content creation team:

   Remember to set `llm` to the provider you are using.

```yaml
# src/guide_creator_flow/crews/content_crew/config/agents.yaml
content_writer:
  role: >
    Educational Content Writer
  goal: >
    Create engaging, informative content that thoroughly explains the assigned topic
    and provides valuable insights to the reader
  backstory: >
    You are a talented educational writer with expertise in creating clear, engaging
    content. You have a gift for explaining complex concepts in accessible language
    and organizing information in a way that helps readers build their understanding.
  llm: provider/model-id  # e.g. openai/gpt-4o, google/gemini-2.0-flash, anthropic/claude...

content_reviewer:
  role: >
    Educational Content Reviewer and Editor
  goal: >
    Ensure content is accurate, comprehensive, well-structured, and maintains
    consistency with previously written sections
  backstory: >
    You are a meticulous editor with years of experience reviewing educational
    content. You have an eye for detail, clarity, and coherence. You excel at
    improving content while maintaining the original author's voice and ensuring
    consistent quality across multiple sections.
  llm: provider/model-id  # e.g. openai/gpt-4o, google/gemini-2.0-flash, anthropic/claude...
```

These agent definitions establish the specialized roles and perspectives that will shape how our AI agents approach content creation. Notice how each agent has a distinct purpose and expertise.

2. Next, update the tasks configuration file to define the specific writing and reviewing tasks:

```yaml
# src/guide_creator_flow/crews/content_crew/config/tasks.yaml
write_section_task:
  description: >
    Write a comprehensive section on the topic: "{section_title}"

    Section description: {section_description}
    Target audience: {audience_level} level learners

    Your content should:
    1. Begin with a brief introduction to the section topic
    2. Explain all key concepts clearly with examples
    3. Include practical applications or exercises where appropriate
    4. End with a summary of key points
    5. Be approximately 500-800 words in length

    Format your content in Markdown with appropriate headings, lists, and emphasis.

    Previously written sections:
    {previous_sections}

    Make sure your content maintains consistency with previously written sections
    and builds upon concepts that have already been explained.
  expected_output: >
    A well-structured, comprehensive section in Markdown format that thoroughly
    explains the topic and is appropriate for the target audience.
  agent: content_writer

review_section_task:
  description: >
    Review and improve the following section on "{section_title}":

    {draft_content}

    Target audience: {audience_level} level learners

    Previously written sections:
    {previous_sections}

    Your review should:
    1. Fix any grammatical or spelling errors
    2. Improve clarity and readability
    3. Ensure content is comprehensive and accurate
    4. Verify consistency with previously written sections
    5. Enhance the structure and flow
    6. Add any missing key information

    Provide the improved version of the section in Markdown format.
  expected_output: >
    An improved, polished version of the section that maintains the original
    structure but enhances clarity, accuracy, and consistency.
  agent: content_reviewer
  context:
    - write_section_task
```

These task definitions provide detailed instructions to our agents, ensuring they produce content that meets our quality standards. Note how the `context` parameter in the review task creates a workflow where the reviewer has access to the writer's output.

3. Now, update the crew implementation file to define how our agents and tasks work together:

```python
# src/guide_creator_flow/crews/content_crew/content_crew.py
from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task
from crewai.agents.agent_builder.base_agent import BaseAgent
from typing import List

@CrewBase
class ContentCrew():
    """Content writing crew"""

    agents: List[BaseAgent]
    tasks: List[Task]

    @agent
    def content_writer(self) -> Agent:
        return Agent(
            config=self.agents_config['content_writer'], # type: ignore[index]
            verbose=True
        )

    @agent
    def content_reviewer(self) -> Agent:
        return Agent(
            config=self.agents_config['content_reviewer'], # type: ignore[index]
            verbose=True
        )

    @task
    def write_section_task(self) -> Task:
        return Task(
            config=self.tasks_config['write_section_task'] # type: ignore[index]
        )

    @task
    def review_section_task(self) -> Task:
        return Task(
            config=self.tasks_config['review_section_task'], # type: ignore[index]
            context=[self.write_section_task()]
        )

    @crew
    def crew(self) -> Crew:
        """Creates the content writing crew"""
        return Crew(
            agents=self.agents,
            tasks=self.tasks,
            process=Process.sequential,
            verbose=True,
        )
```

This crew definition establishes the relationship between our agents and tasks, setting up a sequential process where the content writer creates a draft and then the reviewer improves it. While this crew can function independently, in our flow it will be orchestrated as part of a larger system.

## Step 5: Create the Flow

Now comes the exciting part - creating the flow that will orchestrate the entire guide creation process. This is where we'll combine regular Python code, direct LLM calls, and our content creation crew into a cohesive system.

Our flow will:

1. Get user input for a topic and audience level
2. Make a direct LLM call to create a structured guide outline
3. Process each section sequentially using the content writer crew
4. Combine everything into a final comprehensive document

Let's create our flow in the `main.py` file:

```python
#!/usr/bin/env python
import json
import os
from typing import List, Dict
from pydantic import BaseModel, Field
from crewai import LLM
from crewai.flow.flow import Flow, listen, start
from guide_creator_flow.crews.content_crew.content_crew import ContentCrew

# Define our models for structured data
class Section(BaseModel):
    title: str = Field(description="Title of the section")
    description: str = Field(description="Brief description of what the section should cover")

class GuideOutline(BaseModel):
    title: str = Field(description="Title of the guide")
    introduction: str = Field(description="Introduction to the topic")
    target_audience: str = Field(description="Description of the target audience")
    sections: List[Section] = Field(description="List of sections in the guide")
    conclusion: str = Field(description="Conclusion or summary of the guide")

# Define our flow state
class GuideCreatorState(BaseModel):
    topic: str = ""
    audience_level: str = ""
    guide_outline: GuideOutline = None
    sections_content: Dict[str, str] = {}

class GuideCreatorFlow(Flow[GuideCreatorState]):
    """Flow for creating a comprehensive guide on any topic"""

    @start()
    def get_user_input(self):
        """Get input from the user about the guide topic and audience"""
        print("\n=== Create Your Comprehensive Guide ===\n")

        # Get user input
        self.state.topic = input("What topic would you like to create a guide for? ")

        # Get audience level with validation
        while True:
            audience = input("Who is your target audience? (beginner/intermediate/advanced) ").lower()
            if audience in ["beginner", "intermediate", "advanced"]:
                self.state.audience_level = audience
                break
            print("Please enter 'beginner', 'intermediate', or 'advanced'")

        print(f"\nCreating a guide on {self.state.topic} for {self.state.audience_level} audience...\n")
        return self.state

    @listen(get_user_input)
    def create_guide_outline(self, state):
        """Create a structured outline for the guide using a direct LLM call"""
        print("Creating guide outline...")

        # Initialize the LLM
        llm = LLM(model="openai/gpt-4o-mini", response_format=GuideOutline)

        # Create the messages for the outline
        messages = [
            {"role": "system", "content": "You are a helpful assistant designed to output JSON."},
            {"role": "user", "content": f"""
            Create a detailed outline for a comprehensive guide on "{state.topic}" for {state.audience_level} level learners.

            The outline should include:
            1. A compelling title for the guide
            2. An introduction to the topic
            3. 4-6 main sections that cover the most important aspects of the topic
            4. A conclusion or summary

            For each section, provide a clear title and a brief description of what it should cover.
            """}
        ]

        # Make the LLM call with JSON response format
        response = llm.call(messages=messages)

        # Parse the JSON response
        outline_dict = json.loads(response)
        self.state.guide_outline = GuideOutline(**outline_dict)

        # Ensure output directory exists before saving
        os.makedirs("output", exist_ok=True)

        # Save the outline to a file
        with open("output/guide_outline.json", "w") as f:
            json.dump(outline_dict, f, indent=2)

        print(f"Guide outline created with {len(self.state.guide_outline.sections)} sections")
        return self.state.guide_outline

    @listen(create_guide_outline)
    def write_and_compile_guide(self, outline):
        """Write all sections and compile the guide"""
        print("Writing guide sections and compiling...")
        completed_sections = []

        # Process sections one by one to maintain context flow
        for section in outline.sections:
            print(f"Processing section: {section.title}")

            # Build context from previous sections
            previous_sections_text = ""
            if completed_sections:
                previous_sections_text = "# Previously Written Sections\n\n"
                for title in completed_sections:
                    previous_sections_text += f"## {title}\n\n"
                    previous_sections_text += self.state.sections_content.get(title, "") + "\n\n"
            else:
                previous_sections_text = "No previous sections written yet."

            # Run the content crew for this section
            result = ContentCrew().crew().kickoff(inputs={
                "section_title": section.title,
                "section_description": section.description,
                "audience_level": self.state.audience_level,
                "previous_sections": previous_sections_text,
                "draft_content": ""
            })

            # Store the content
            self.state.sections_content[section.title] = result.raw
            completed_sections.append(section.title)
            print(f"Section completed: {section.title}")

        # Compile the final guide
        guide_content = f"# {outline.title}\n\n"
        guide_content += f"## Introduction\n\n{outline.introduction}\n\n"

        # Add each section in order
        for section in outline.sections:
            section_content = self.state.sections_content.get(section.title, "")
            guide_content += f"\n\n{section_content}\n\n"

        # Add conclusion
        guide_content += f"## Conclusion\n\n{outline.conclusion}\n\n"

        # Save the guide
        with open("output/complete_guide.md", "w") as f:
            f.write(guide_content)

        print("\nComplete guide compiled and saved to output/complete_guide.md")
        return "Guide creation completed successfully"

def kickoff():
    """Run the guide creator flow"""
    GuideCreatorFlow().kickoff()
    print("\n=== Flow Complete ===")
    print("Your comprehensive guide is ready in the output directory.")
    print("Open output/complete_guide.md to view it.")

def plot():
    """Generate a visualization of the flow"""
    flow = GuideCreatorFlow()
    flow.plot("guide_creator_flow")
    print("Flow visualization saved to guide_creator_flow.html")

if __name__ == "__main__":
    kickoff()
```

Let's analyze what's happening in this flow:

1. We define Pydantic models for structured data, ensuring type safety and clear data representation
2. We create a state class to maintain data across different steps of the flow
3. We implement three main flow steps:
   * Getting user input with the `@start()` decorator
   * Creating a guide outline with a direct LLM call
   * Processing sections with our content crew
4. We use the `@listen()` decorator to establish event-driven relationships between steps

This is the power of flows - combining different types of processing (user interaction, direct LLM calls, crew-based tasks) into a coherent, event-driven system.

## Step 6: Set Up Your Environment Variables

Create a `.env` file in your project root with your API keys. See the [LLM setup
guide](/en/concepts/llms#setting-up-your-llm) for details on configuring a provider.

```sh .env
OPENAI_API_KEY=your_openai_api_key
# or
GEMINI_API_KEY=your_gemini_api_key
# or
ANTHROPIC_API_KEY=your_anthropic_api_key
```

## Step 7: Install Dependencies

Install the required dependencies:

```bash
crewai install
```

## Step 8: Run Your Flow

Now it's time to see your flow in action! Run it using the CrewAI CLI:

```bash
crewai flow kickoff
```

When you run this command, you'll see your flow spring to life:

1. It will prompt you for a topic and audience level
2. It will create a structured outline for your guide
3. It will process each section, with the content writer and reviewer collaborating on each
4. Finally, it will compile everything into a comprehensive guide

This demonstrates the power of flows to orchestrate complex processes involving multiple components, both AI and non-AI.

## Step 9: Visualize Your Flow

One of the powerful features of flows is the ability to visualize their structure:

```bash
crewai flow plot
```

This will create an HTML file that shows the structure of your flow, including the relationships between different steps and the data that flows between them. This visualization can be invaluable for understanding and debugging complex flows.

## Step 10: Review the Output

Once the flow completes, you'll find two files in the `output` directory:

1. `guide_outline.json`: Contains the structured outline of the guide
2. `complete_guide.md`: The comprehensive guide with all sections

Take a moment to review these files and appreciate what you've built - a system that combines user input, direct AI interactions, and collaborative agent work to produce a complex, high-quality output.

## The Art of the Possible: Beyond Your First Flow

What you've learned in this guide provides a foundation for creating much more sophisticated AI systems. Here are some ways you could extend this basic flow:

### Enhancing User Interaction

You could create more interactive flows with:

* Web interfaces for input and output
* Real-time progress updates
* Interactive feedback and refinement loops
* Multi-stage user interactions

### Adding More Processing Steps

You could expand your flow with additional steps for:

* Research before outline creation
* Image generation for illustrations
* Code snippet generation for technical guides
* Final quality assurance and fact-checking

### Creating More Complex Flows

You could implement more sophisticated flow patterns:

* Conditional branching based on user preferences or content type
* Parallel processing of independent sections
* Iterative refinement loops with feedback
* Integration with external APIs and services

### Applying to Different Domains

The same patterns can be applied to create flows for:

* **Interactive storytelling**: Create personalized stories based on user input
* **Business intelligence**: Process data, generate insights, and create reports
* **Product development**: Facilitate ideation, design, and planning
* **Educational systems**: Create personalized learning experiences

## Key Features Demonstrated

This guide creator flow demonstrates several powerful features of CrewAI:

1. **User interaction**: The flow collects input directly from the user
2. **Direct LLM calls**: Uses the LLM class for efficient, single-purpose AI interactions
3. **Structured data with Pydantic**: Uses Pydantic models to ensure type safety
4. **Sequential processing with context**: Writes sections in order, providing previous sections for context
5. **Multi-agent crews**: Leverages specialized agents (writer and reviewer) for content creation
6. **State management**: Maintains state across different steps of the process
7. **Event-driven architecture**: Uses the `@listen` decorator to respond to events

## Understanding the Flow Structure

Let's break down the key components of flows to help you understand how to build your own:

### 1. Direct LLM Calls

Flows allow you to make direct calls to language models when you need simple, structured responses:

```python
llm = LLM(
    model="model-id-here",  # gpt-4o, gemini-2.0-flash, anthropic/claude...
    response_format=GuideOutline
)
response = llm.call(messages=messages)
```

This is more efficient than using a crew when you need a specific, structured output.

### 2. Event-Driven Architecture

Flows use decorators to establish relationships between components:

```python
@start()
def get_user_input(self):
    # First step in the flow
    # ...

@listen(get_user_input)
def create_guide_outline(self, state):
    # This runs when get_user_input completes
    # ...
```

This creates a clear, declarative structure for your application.

### 3. State Management

Flows maintain state across steps, making it easy to share data:

```python
class GuideCreatorState(BaseModel):
    topic: str = ""
    audience_level: str = ""
    guide_outline: GuideOutline = None
    sections_content: Dict[str, str] = {}
```

This provides a type-safe way to track and transform data throughout your flow.

### 4. Crew Integration

Flows can seamlessly integrate with crews for complex collaborative tasks:

```python
result = ContentCrew().crew().kickoff(inputs={
    "section_title": section.title,
    # ...
})
```

This allows you to use the right tool for each part of your application - direct LLM calls for simple tasks and crews for complex collaboration.

## Next Steps

Now that you've built your first flow, you can:

1. Experiment with more complex flow structures and patterns
2. Try using `@router()` to create conditional branches in your flows
3. Explore the `and_` and `or_` functions for more complex parallel execution
4. Connect your flow to external APIs, databases, or user interfaces
5. Combine multiple specialized crews in a single flow

<Check>
  Congratulations! You've successfully built your first CrewAI Flow that combines regular code, direct LLM calls, and crew-based processing to create a comprehensive guide. These foundational skills enable you to create increasingly sophisticated AI applications that can tackle complex, multi-stage problems through a combination of procedural control and collaborative intelligence.
</Check>


# Mastering Flow State Management
Source: https://docs.crewai.com/en/guides/flows/mastering-flow-state

A comprehensive guide to managing, persisting, and leveraging state in CrewAI Flows for building robust AI applications.

## Understanding the Power of State in Flows

State management is the backbone of any sophisticated AI workflow. In CrewAI Flows, the state system allows you to maintain context, share data between steps, and build complex application logic. Mastering state management is essential for creating reliable, maintainable, and powerful AI applications.

This guide will walk you through everything you need to know about managing state in CrewAI Flows, from basic concepts to advanced techniques, with practical code examples along the way.

### Why State Management Matters

Effective state management enables you to:

1. **Maintain context across execution steps** - Pass information seamlessly between different stages of your workflow
2. **Build complex conditional logic** - Make decisions based on accumulated data
3. **Create persistent applications** - Save and restore workflow progress
4. **Handle errors gracefully** - Implement recovery patterns for more robust applications
5. **Scale your applications** - Support complex workflows with proper data organization
6. **Enable conversational applications** - Store and access conversation history for context-aware AI interactions

Let's explore how to leverage these capabilities effectively.

## State Management Fundamentals

### The Flow State Lifecycle

In CrewAI Flows, the state follows a predictable lifecycle:

1. **Initialization** - When a flow is created, its state is initialized (either as an empty dictionary or a Pydantic model instance)
2. **Modification** - Flow methods access and modify the state as they execute
3. **Transmission** - State is passed automatically between flow methods
4. **Persistence** (optional) - State can be saved to storage and later retrieved
5. **Completion** - The final state reflects the cumulative changes from all executed methods

Understanding this lifecycle is crucial for designing effective flows.

### Two Approaches to State Management

CrewAI offers two ways to manage state in your flows:

1. **Unstructured State** - Using dictionary-like objects for flexibility
2. **Structured State** - Using Pydantic models for type safety and validation

Let's examine each approach in detail.

## Unstructured State Management

Unstructured state uses a dictionary-like approach, offering flexibility and simplicity for straightforward applications.

### How It Works

With unstructured state:

* You access state via `self.state` which behaves like a dictionary
* You can freely add, modify, or remove keys at any point
* All state is automatically available to all flow methods

### Basic Example

Here's a simple example of unstructured state management:

```python
from crewai.flow.flow import Flow, listen, start

class UnstructuredStateFlow(Flow):
    @start()
    def initialize_data(self):
        print("Initializing flow data")
        # Add key-value pairs to state
        self.state["user_name"] = "Alex"
        self.state["preferences"] = {
            "theme": "dark",
            "language": "English"
        }
        self.state["items"] = []

        # The flow state automatically gets a unique ID
        print(f"Flow ID: {self.state['id']}")

        return "Initialized"

    @listen(initialize_data)
    def process_data(self, previous_result):
        print(f"Previous step returned: {previous_result}")

        # Access and modify state
        user = self.state["user_name"]
        print(f"Processing data for {user}")

        # Add items to a list in state
        self.state["items"].append("item1")
        self.state["items"].append("item2")

        # Add a new key-value pair
        self.state["processed"] = True

        return "Processed"

    @listen(process_data)
    def generate_summary(self, previous_result):
        # Access multiple state values
        user = self.state["user_name"]
        theme = self.state["preferences"]["theme"]
        items = self.state["items"]
        processed = self.state.get("processed", False)

        summary = f"User {user} has {len(items)} items with {theme} theme. "
        summary += "Data is processed." if processed else "Data is not processed."

        return summary

# Run the flow
flow = UnstructuredStateFlow()
result = flow.kickoff()
print(f"Final result: {result}")
print(f"Final state: {flow.state}")
```

### When to Use Unstructured State

Unstructured state is ideal for:

* Quick prototyping and simple flows
* Dynamically evolving state needs
* Cases where the structure may not be known in advance
* Flows with simple state requirements

While flexible, unstructured state lacks type checking and schema validation, which can lead to errors in complex applications.

## Structured State Management

Structured state uses Pydantic models to define a schema for your flow's state, providing type safety, validation, and better developer experience.

### How It Works

With structured state:

* You define a Pydantic model that represents your state structure
* You pass this model type to your Flow class as a type parameter
* You access state via `self.state`, which behaves like a Pydantic model instance
* All fields are validated according to their defined types
* You get IDE autocompletion and type checking support

### Basic Example

Here's how to implement structured state management:

```python
from crewai.flow.flow import Flow, listen, start
from pydantic import BaseModel, Field
from typing import List, Dict, Optional

# Define your state model
class UserPreferences(BaseModel):
    theme: str = "light"
    language: str = "English"

class AppState(BaseModel):
    user_name: str = ""
    preferences: UserPreferences = UserPreferences()
    items: List[str] = []
    processed: bool = False
    completion_percentage: float = 0.0

# Create a flow with typed state
class StructuredStateFlow(Flow[AppState]):
    @start()
    def initialize_data(self):
        print("Initializing flow data")
        # Set state values (type-checked)
        self.state.user_name = "Taylor"
        self.state.preferences.theme = "dark"

        # The ID field is automatically available
        print(f"Flow ID: {self.state.id}")

        return "Initialized"

    @listen(initialize_data)
    def process_data(self, previous_result):
        print(f"Processing data for {self.state.user_name}")

        # Modify state (with type checking)
        self.state.items.append("item1")
        self.state.items.append("item2")
        self.state.processed = True
        self.state.completion_percentage = 50.0

        return "Processed"

    @listen(process_data)
    def generate_summary(self, previous_result):
        # Access state (with autocompletion)
        summary = f"User {self.state.user_name} has {len(self.state.items)} items "
        summary += f"with {self.state.preferences.theme} theme. "
        summary += "Data is processed." if self.state.processed else "Data is not processed."
        summary += f" Completion: {self.state.completion_percentage}%"

        return summary

# Run the flow
flow = StructuredStateFlow()
result = flow.kickoff()
print(f"Final result: {result}")
print(f"Final state: {flow.state}")
```

### Benefits of Structured State

Using structured state provides several advantages:

1. **Type Safety** - Catch type errors at development time
2. **Self-Documentation** - The state model clearly documents what data is available
3. **Validation** - Automatic validation of data types and constraints
4. **IDE Support** - Get autocomplete and inline documentation
5. **Default Values** - Easily define fallbacks for missing data

### When to Use Structured State

Structured state is recommended for:

* Complex flows with well-defined data schemas
* Team projects where multiple developers work on the same code
* Applications where data validation is important
* Flows that need to enforce specific data types and constraints

## The Automatic State ID

Both unstructured and structured states automatically receive a unique identifier (UUID) to help track and manage state instances.

### How It Works

* For unstructured state, the ID is accessible as `self.state["id"]`
* For structured state, the ID is accessible as `self.state.id`
* This ID is generated automatically when the flow is created
* The ID remains the same throughout the flow's lifecycle
* The ID can be used for tracking, logging, and retrieving persisted states

This UUID is particularly valuable when implementing persistence or tracking multiple flow executions.

## Dynamic State Updates

Regardless of whether you're using structured or unstructured state, you can update state dynamically throughout your flow's execution.

### Passing Data Between Steps

Flow methods can return values that are then passed as arguments to listening methods:

```python
from crewai.flow.flow import Flow, listen, start

class DataPassingFlow(Flow):
    @start()
    def generate_data(self):
        # This return value will be passed to listening methods
        return "Generated data"

    @listen(generate_data)
    def process_data(self, data_from_previous_step):
        print(f"Received: {data_from_previous_step}")
        # You can modify the data and pass it along
        processed_data = f"{data_from_previous_step} - processed"
        # Also update state
        self.state["last_processed"] = processed_data
        return processed_data

    @listen(process_data)
    def finalize_data(self, processed_data):
        print(f"Received processed data: {processed_data}")
        # Access both the passed data and state
        last_processed = self.state.get("last_processed", "")
        return f"Final: {processed_data} (from state: {last_processed})"
```

This pattern allows you to combine direct data passing with state updates for maximum flexibility.

## Persisting Flow State

One of CrewAI's most powerful features is the ability to persist flow state across executions. This enables workflows that can be paused, resumed, and even recovered after failures.

### The @persist() Decorator

The `@persist()` decorator automates state persistence, saving your flow's state at key points in execution.

#### Class-Level Persistence

When applied at the class level, `@persist()` saves state after every method execution:

```python
from crewai.flow.flow import Flow, listen, start
from crewai.flow.persistence import persist
from pydantic import BaseModel

class CounterState(BaseModel):
    value: int = 0

@persist()  # Apply to the entire flow class
class PersistentCounterFlow(Flow[CounterState]):
    @start()
    def increment(self):
        self.state.value += 1
        print(f"Incremented to {self.state.value}")
        return self.state.value

    @listen(increment)
    def double(self, value):
        self.state.value = value * 2
        print(f"Doubled to {self.state.value}")
        return self.state.value

# First run
flow1 = PersistentCounterFlow()
result1 = flow1.kickoff()
print(f"First run result: {result1}")

# Second run - state is automatically loaded
flow2 = PersistentCounterFlow()
result2 = flow2.kickoff()
print(f"Second run result: {result2}")  # Will be higher due to persisted state
```

#### Method-Level Persistence

For more granular control, you can apply `@persist()` to specific methods:

```python
from crewai.flow.flow import Flow, listen, start
from crewai.flow.persistence import persist

class SelectivePersistFlow(Flow):
    @start()
    def first_step(self):
        self.state["count"] = 1
        return "First step"

    @persist()  # Only persist after this method
    @listen(first_step)
    def important_step(self, prev_result):
        self.state["count"] += 1
        self.state["important_data"] = "This will be persisted"
        return "Important step completed"

    @listen(important_step)
    def final_step(self, prev_result):
        self.state["count"] += 1
        return f"Complete with count {self.state['count']}"
```

## Advanced State Patterns

### State-Based Conditional Logic

You can use state to implement complex conditional logic in your flows:

```python
from crewai.flow.flow import Flow, listen, router, start
from pydantic import BaseModel

class PaymentState(BaseModel):
    amount: float = 0.0
    is_approved: bool = False
    retry_count: int = 0

class PaymentFlow(Flow[PaymentState]):
    @start()
    def process_payment(self):
        # Simulate payment processing
        self.state.amount = 100.0
        self.state.is_approved = self.state.amount < 1000
        return "Payment processed"

    @router(process_payment)
    def check_approval(self, previous_result):
        if self.state.is_approved:
            return "approved"
        elif self.state.retry_count < 3:
            return "retry"
        else:
            return "rejected"

    @listen("approved")
    def handle_approval(self):
        return f"Payment of ${self.state.amount} approved!"

    @listen("retry")
    def handle_retry(self):
        self.state.retry_count += 1
        print(f"Retrying payment (attempt {self.state.retry_count})...")
        # Could implement retry logic here
        return "Retry initiated"

    @listen("rejected")
    def handle_rejection(self):
        return f"Payment of ${self.state.amount} rejected after {self.state.retry_count} retries."
```

### Handling Complex State Transformations

For complex state transformations, you can create dedicated methods:

```python
from crewai.flow.flow import Flow, listen, start
from pydantic import BaseModel
from typing import List, Dict

class UserData(BaseModel):
    name: str
    active: bool = True
    login_count: int = 0

class ComplexState(BaseModel):
    users: Dict[str, UserData] = {}
    active_user_count: int = 0

class TransformationFlow(Flow[ComplexState]):
    @start()
    def initialize(self):
        # Add some users
        self.add_user("alice", "Alice")
        self.add_user("bob", "Bob")
        self.add_user("charlie", "Charlie")
        return "Initialized"

    @listen(initialize)
    def process_users(self, _):
        # Increment login counts
        for user_id in self.state.users:
            self.increment_login(user_id)

        # Deactivate one user
        self.deactivate_user("bob")

        # Update active count
        self.update_active_count()

        return f"Processed {len(self.state.users)} users"

    # Helper methods for state transformations
    def add_user(self, user_id: str, name: str):
        self.state.users[user_id] = UserData(name=name)
        self.update_active_count()

    def increment_login(self, user_id: str):
        if user_id in self.state.users:
            self.state.users[user_id].login_count += 1

    def deactivate_user(self, user_id: str):
        if user_id in self.state.users:
            self.state.users[user_id].active = False
            self.update_active_count()

    def update_active_count(self):
        self.state.active_user_count = sum(
            1 for user in self.state.users.values() if user.active
        )
```

This pattern of creating helper methods keeps your flow methods clean while enabling complex state manipulations.

## State Management with Crews

One of the most powerful patterns in CrewAI is combining flow state management with crew execution.

### Passing State to Crews

You can use flow state to parameterize crews:

```python
from crewai.flow.flow import Flow, listen, start
from crewai import Agent, Crew, Process, Task
from pydantic import BaseModel

class ResearchState(BaseModel):
    topic: str = ""
    depth: str = "medium"
    results: str = ""

class ResearchFlow(Flow[ResearchState]):
    @start()
    def get_parameters(self):
        # In a real app, this might come from user input
        self.state.topic = "Artificial Intelligence Ethics"
        self.state.depth = "deep"
        return "Parameters set"

    @listen(get_parameters)
    def execute_research(self, _):
        # Create agents
        researcher = Agent(
            role="Research Specialist",
            goal=f"Research {self.state.topic} in {self.state.depth} detail",
            backstory="You are an expert researcher with a talent for finding accurate information."
        )

        writer = Agent(
            role="Content Writer",
            goal="Transform research into clear, engaging content",
            backstory="You excel at communicating complex ideas clearly and concisely."
        )

        # Create tasks
        research_task = Task(
            description=f"Research {self.state.topic} with {self.state.depth} analysis",
            expected_output="Comprehensive research notes in markdown format",
            agent=researcher
        )

        writing_task = Task(
            description=f"Create a summary on {self.state.topic} based on the research",
            expected_output="Well-written article in markdown format",
            agent=writer,
            context=[research_task]
        )

        # Create and run crew
        research_crew = Crew(
            agents=[researcher, writer],
            tasks=[research_task, writing_task],
            process=Process.sequential,
            verbose=True
        )

        # Run crew and store result in state
        result = research_crew.kickoff()
        self.state.results = result.raw

        return "Research completed"

    @listen(execute_research)
    def summarize_results(self, _):
        # Access the stored results
        result_length = len(self.state.results)
        return f"Research on {self.state.topic} completed with {result_length} characters of results."
```

### Handling Crew Outputs in State

When a crew completes, you can process its output and store it in your flow state:

```python
@listen(execute_crew)
def process_crew_results(self, _):
    # Parse the raw results (assuming JSON output)
    import json
    try:
        results_dict = json.loads(self.state.raw_results)
        self.state.processed_results = {
            "title": results_dict.get("title", ""),
            "main_points": results_dict.get("main_points", []),
            "conclusion": results_dict.get("conclusion", "")
        }
        return "Results processed successfully"
    except json.JSONDecodeError:
        self.state.error = "Failed to parse crew results as JSON"
        return "Error processing results"
```

## Best Practices for State Management

### 1. Keep State Focused

Design your state to contain only what's necessary:

```python
# Too broad
class BloatedState(BaseModel):
    user_data: Dict = {}
    system_settings: Dict = {}
    temporary_calculations: List = []
    debug_info: Dict = {}
    # ...many more fields

# Better: Focused state
class FocusedState(BaseModel):
    user_id: str
    preferences: Dict[str, str]
    completion_status: Dict[str, bool]
```

### 2. Use Structured State for Complex Flows

As your flows grow in complexity, structured state becomes increasingly valuable:

```python
# Simple flow can use unstructured state
class SimpleGreetingFlow(Flow):
    @start()
    def greet(self):
        self.state["name"] = "World"
        return f"Hello, {self.state['name']}!"

# Complex flow benefits from structured state
class UserRegistrationState(BaseModel):
    username: str
    email: str
    verification_status: bool = False
    registration_date: datetime = Field(default_factory=datetime.now)
    last_login: Optional[datetime] = None

class RegistrationFlow(Flow[UserRegistrationState]):
    # Methods with strongly-typed state access
```

### 3. Document State Transitions

For complex flows, document how state changes throughout the execution:

```python
@start()
def initialize_order(self):
    """
    Initialize order state with empty values.

    State before: {}
    State after: {order_id: str, items: [], status: 'new'}
    """
    self.state.order_id = str(uuid.uuid4())
    self.state.items = []
    self.state.status = "new"
    return "Order initialized"
```

### 4. Handle State Errors Gracefully

Implement error handling for state access:

```python
@listen(previous_step)
def process_data(self, _):
    try:
        # Try to access a value that might not exist
        user_preference = self.state.preferences.get("theme", "default")
    except (AttributeError, KeyError):
        # Handle the error gracefully
        self.state.errors = self.state.get("errors", [])
        self.state.errors.append("Failed to access preferences")
        user_preference = "default"

    return f"Used preference: {user_preference}"
```

### 5. Use State for Progress Tracking

Leverage state to track progress in long-running flows:

```python
class ProgressTrackingFlow(Flow):
    @start()
    def initialize(self):
        self.state["total_steps"] = 3
        self.state["current_step"] = 0
        self.state["progress"] = 0.0
        self.update_progress()
        return "Initialized"

    def update_progress(self):
        """Helper method to calculate and update progress"""
        if self.state.get("total_steps", 0) > 0:
            self.state["progress"] = (self.state.get("current_step", 0) /
                                    self.state["total_steps"]) * 100
            print(f"Progress: {self.state['progress']:.1f}%")

    @listen(initialize)
    def step_one(self, _):
        # Do work...
        self.state["current_step"] = 1
        self.update_progress()
        return "Step 1 complete"

    # Additional steps...
```

### 6. Use Immutable Operations When Possible

Especially with structured state, prefer immutable operations for clarity:

```python
# Instead of modifying lists in place:
self.state.items.append(new_item)  # Mutable operation

# Consider creating new state:
from pydantic import BaseModel
from typing import List

class ItemState(BaseModel):
    items: List[str] = []

class ImmutableFlow(Flow[ItemState]):
    @start()
    def add_item(self):
        # Create new list with the added item
        self.state.items = [*self.state.items, "new item"]
        return "Item added"
```

## Debugging Flow State

### Logging State Changes

When developing, add logging to track state changes:

```python
import logging
logging.basicConfig(level=logging.INFO)

class LoggingFlow(Flow):
    def log_state(self, step_name):
        logging.info(f"State after {step_name}: {self.state}")

    @start()
    def initialize(self):
        self.state["counter"] = 0
        self.log_state("initialize")
        return "Initialized"

    @listen(initialize)
    def increment(self, _):
        self.state["counter"] += 1
        self.log_state("increment")
        return f"Incremented to {self.state['counter']}"
```

### State Visualization

You can add methods to visualize your state for debugging:

```python
def visualize_state(self):
    """Create a simple visualization of the current state"""
    import json
    from rich.console import Console
    from rich.panel import Panel

    console = Console()

    if hasattr(self.state, "model_dump"):
        # Pydantic v2
        state_dict = self.state.model_dump()
    elif hasattr(self.state, "dict"):
        # Pydantic v1
        state_dict = self.state.dict()
    else:
        # Unstructured state
        state_dict = dict(self.state)

    # Remove id for cleaner output
    if "id" in state_dict:
        state_dict.pop("id")

    state_json = json.dumps(state_dict, indent=2, default=str)
    console.print(Panel(state_json, title="Current Flow State"))
```

## Conclusion

Mastering state management in CrewAI Flows gives you the power to build sophisticated, robust AI applications that maintain context, make complex decisions, and deliver consistent results.

Whether you choose unstructured or structured state, implementing proper state management practices will help you create flows that are maintainable, extensible, and effective at solving real-world problems.

As you develop more complex flows, remember that good state management is about finding the right balance between flexibility and structure, making your code both powerful and easy to understand.

<Check>
  You've now mastered the concepts and practices of state management in CrewAI Flows! With this knowledge, you can create robust AI workflows that effectively maintain context, share data between steps, and build sophisticated application logic.
</Check>

## Next Steps

* Experiment with both structured and unstructured state in your flows
* Try implementing state persistence for long-running workflows
* Explore [building your first crew](/en/guides/crews/first-crew) to see how crews and flows can work together
* Check out the [Flow reference documentation](/en/concepts/flows) for more advanced features


# Installation
Source: https://docs.crewai.com/en/installation

Get started with CrewAI - Install, configure, and build your first AI crew

## Video Tutorial

Watch this video tutorial for a step-by-step demonstration of the installation process:

<iframe width="100%" height="400" src="https://www.youtube.com/embed/-kSOTtYzgEw" title="CrewAI Installation Guide" frameborder="0" style={{ borderRadius: '10px' }} allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

## Text Tutorial

<Note>
  **Python Version Requirements**

  CrewAI requires `Python >=3.10 and <3.14`. Here's how to check your version:

  ```bash
  python3 --version
  ```

  If you need to update Python, visit [python.org/downloads](https://python.org/downloads)
</Note>

CrewAI uses the `uv` as its dependency management and package handling tool. It simplifies project setup and execution, offering a seamless experience.

If you haven't installed `uv` yet, follow **step 1** to quickly get it set up on your system, else you can skip to **step 2**.

<Steps>
  <Step title="Install uv">
    * **On macOS/Linux:**

      Use `curl` to download the script and execute it with `sh`:

      ```shell
      curl -LsSf https://astral.sh/uv/install.sh | sh
      ```

      If your system doesn't have `curl`, you can use `wget`:

      ```shell
      wget -qO- https://astral.sh/uv/install.sh | sh
      ```

    * **On Windows:**

      Use `irm` to download the script and `iex` to execute it:

      ```shell
      powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
      ```

      If you run into any issues, refer to [UV's installation guide](https://docs.astral.sh/uv/getting-started/installation/) for more information.
  </Step>

  <Step title="Install CrewAI üöÄ">
    * Run the following command to install `crewai` CLI:

      ```shell
      uv tool install crewai
      ```

      <Warning>
        If you encounter a `PATH` warning, run this command to update your shell:

        ```shell
        uv tool update-shell
        ```
      </Warning>

      <Warning>
        If you encounter the `chroma-hnswlib==0.7.6` build error (`fatal error C1083: Cannot open include file: 'float.h'`) on Windows, install [Visual Studio Build Tools](https://visualstudio.microsoft.com/downloads/) with *Desktop development with C++*.
      </Warning>

    * To verify that `crewai` is installed, run:
      ```shell
      uv tool list
      ```

    * You should see something like:
      ```shell
      crewai v0.102.0
      - crewai
      ```

    * If you need to update `crewai`, run:
      ```shell
      uv tool install crewai --upgrade
      ```

    <Check>Installation successful! You're ready to create your first crew! üéâ</Check>
  </Step>
</Steps>

# Creating a CrewAI Project

We recommend using the `YAML` template scaffolding for a structured approach to defining agents and tasks. Here's how to get started:

<Steps>
  <Step title="Generate Project Scaffolding">
    * Run the `crewai` CLI command:
      ```shell
      crewai create crew <your_project_name>
      ```

    * This creates a new project with the following structure:
      ```
      my_project/
      ‚îú‚îÄ‚îÄ .gitignore
      ‚îú‚îÄ‚îÄ knowledge/
      ‚îú‚îÄ‚îÄ pyproject.toml
      ‚îú‚îÄ‚îÄ README.md
      ‚îú‚îÄ‚îÄ .env
      ‚îî‚îÄ‚îÄ src/
          ‚îî‚îÄ‚îÄ my_project/
              ‚îú‚îÄ‚îÄ __init__.py
              ‚îú‚îÄ‚îÄ main.py
              ‚îú‚îÄ‚îÄ crew.py
              ‚îú‚îÄ‚îÄ tools/
              ‚îÇ   ‚îú‚îÄ‚îÄ custom_tool.py
              ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
              ‚îî‚îÄ‚îÄ config/
                  ‚îú‚îÄ‚îÄ agents.yaml
                  ‚îî‚îÄ‚îÄ tasks.yaml
      ```
  </Step>

  <Step title="Customize Your Project">
    * Your project will contain these essential files:
      | File          | Purpose                                  |
      | ------------- | ---------------------------------------- |
      | `agents.yaml` | Define your AI agents and their roles    |
      | `tasks.yaml`  | Set up agent tasks and workflows         |
      | `.env`        | Store API keys and environment variables |
      | `main.py`     | Project entry point and execution flow   |
      | `crew.py`     | Crew orchestration and coordination      |
      | `tools/`      | Directory for custom agent tools         |
      | `knowledge/`  | Directory for knowledge base             |

    * Start by editing `agents.yaml` and `tasks.yaml` to define your crew's behavior.

    * Keep sensitive information like API keys in `.env`.
  </Step>

  <Step title="Run your Crew">
    * Before you run your crew, make sure to run:
      ```bash
      crewai install
      ```
    * If you need to install additional packages, use:
      ```shell
      uv add <package-name>
      ```
    * To run your crew, execute the following command in the root of your project:
      ```bash
      crewai run
      ```
  </Step>
</Steps>

## Enterprise Installation Options

<Note type="info">
  For teams and organizations, CrewAI offers enterprise deployment options that eliminate setup complexity:

  ### CrewAI Enterprise (SaaS)

  * Zero installation required - just sign up for free at [app.crewai.com](https://app.crewai.com)
  * Automatic updates and maintenance
  * Managed infrastructure and scaling
  * Build Crews with no Code

  ### CrewAI Factory (Self-hosted)

  * Containerized deployment for your infrastructure
  * Supports any hyperscaler including on prem deployments
  * Integration with your existing security systems

  <Card title="Explore Enterprise Options" icon="building" href="https://crewai.com/enterprise">
    Learn about CrewAI's enterprise offerings and schedule a demo
  </Card>
</Note>

## Next Steps

<CardGroup cols={2}>
  <Card title="Build Your First Agent" icon="code" href="/en/quickstart">
    Follow our quickstart guide to create your first CrewAI agent and get hands-on experience.
  </Card>

  <Card title="Join the Community" icon="comments" href="https://community.crewai.com">
    Connect with other developers, get help, and share your CrewAI experiences.
  </Card>
</CardGroup>


# Introduction
Source: https://docs.crewai.com/en/introduction

Build AI agent teams that work together to tackle complex tasks

# What is CrewAI?

**CrewAI is a lean, lightning-fast Python framework built entirely from scratch‚Äîcompletely independent of LangChain or other agent frameworks.**

CrewAI empowers developers with both high-level simplicity and precise low-level control, ideal for creating autonomous AI agents tailored to any scenario:

* **[CrewAI Crews](/en/guides/crews/first-crew)**: Optimize for autonomy and collaborative intelligence, enabling you to create AI teams where each agent has specific roles, tools, and goals.
* **[CrewAI Flows](/en/guides/flows/first-flow)**: Enable granular, event-driven control, single LLM calls for precise task orchestration and supports Crews natively.

With over 100,000 developers certified through our community courses, CrewAI is rapidly becoming the standard for enterprise-ready AI automation.

## How Crews Work

<Note>
  Just like a company has departments (Sales, Engineering, Marketing) working together under leadership to achieve business goals, CrewAI helps you create an organization of AI agents with specialized roles collaborating to accomplish complex tasks.
</Note>

<Frame caption="CrewAI Framework Overview">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crews.png" alt="CrewAI Framework Overview" />
</Frame>

| Component     |         Description        | Key Features                                                                                                                      |
| :------------ | :------------------------: | :-------------------------------------------------------------------------------------------------------------------------------- |
| **Crew**      | The top-level organization | ‚Ä¢ Manages AI agent teams<br />‚Ä¢ Oversees workflows<br />‚Ä¢ Ensures collaboration<br />‚Ä¢ Delivers outcomes                          |
| **AI Agents** |  Specialized team members  | ‚Ä¢ Have specific roles (researcher, writer)<br />‚Ä¢ Use designated tools<br />‚Ä¢ Can delegate tasks<br />‚Ä¢ Make autonomous decisions |
| **Process**   | Workflow management system | ‚Ä¢ Defines collaboration patterns<br />‚Ä¢ Controls task assignments<br />‚Ä¢ Manages interactions<br />‚Ä¢ Ensures efficient execution  |
| **Tasks**     |   Individual assignments   | ‚Ä¢ Have clear objectives<br />‚Ä¢ Use specific tools<br />‚Ä¢ Feed into larger process<br />‚Ä¢ Produce actionable results               |

### How It All Works Together

1. The **Crew** organizes the overall operation
2. **AI Agents** work on their specialized tasks
3. The **Process** ensures smooth collaboration
4. **Tasks** get completed to achieve the goal

## Key Features

<CardGroup cols={2}>
  <Card title="Role-Based Agents" icon="users">
    Create specialized agents with defined roles, expertise, and goals - from researchers to analysts to writers
  </Card>

  <Card title="Flexible Tools" icon="screwdriver-wrench">
    Equip agents with custom tools and APIs to interact with external services and data sources
  </Card>

  <Card title="Intelligent Collaboration" icon="people-arrows">
    Agents work together, sharing insights and coordinating tasks to achieve complex objectives
  </Card>

  <Card title="Task Management" icon="list-check">
    Define sequential or parallel workflows, with agents automatically handling task dependencies
  </Card>
</CardGroup>

## How Flows Work

<Note>
  While Crews excel at autonomous collaboration, Flows provide structured automations, offering granular control over workflow execution. Flows ensure tasks are executed reliably, securely, and efficiently, handling conditional logic, loops, and dynamic state management with precision. Flows integrate seamlessly with Crews, enabling you to balance high autonomy with exacting control.
</Note>

<Frame caption="CrewAI Framework Overview">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/flows.png" alt="CrewAI Framework Overview" />
</Frame>

| Component        |            Description            | Key Features                                                                                                                                                         |
| :--------------- | :-------------------------------: | :------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Flow**         | Structured workflow orchestration | ‚Ä¢ Manages execution paths<br />‚Ä¢ Handles state transitions<br />‚Ä¢ Controls task sequencing<br />‚Ä¢ Ensures reliable execution                                         |
| **Events**       |   Triggers for workflow actions   | ‚Ä¢ Initiate specific processes<br />‚Ä¢ Enable dynamic responses<br />‚Ä¢ Support conditional branching<br />‚Ä¢ Allow for real-time adaptation                             |
| **States**       |    Workflow execution contexts    | ‚Ä¢ Maintain execution data<br />‚Ä¢ Enable persistence<br />‚Ä¢ Support resumability<br />‚Ä¢ Ensure execution integrity                                                    |
| **Crew Support** |    Enhances workflow automation   | ‚Ä¢ Injects pockets of agency when needed<br />‚Ä¢ Complements structured workflows<br />‚Ä¢ Balances automation with intelligence<br />‚Ä¢ Enables adaptive decision-making |

### Key Capabilities

<CardGroup cols={2}>
  <Card title="Event-Driven Orchestration" icon="bolt">
    Define precise execution paths responding dynamically to events
  </Card>

  <Card title="Fine-Grained Control" icon="sliders">
    Manage workflow states and conditional execution securely and efficiently
  </Card>

  <Card title="Native Crew Integration" icon="puzzle-piece">
    Effortlessly combine with Crews for enhanced autonomy and intelligence
  </Card>

  <Card title="Deterministic Execution" icon="route">
    Ensure predictable outcomes with explicit control flow and error handling
  </Card>
</CardGroup>

## When to Use Crews vs. Flows

<Note>
  Understanding when to use [Crews](/en/guides/crews/first-crew) versus [Flows](/en/guides/flows/first-flow) is key to maximizing the potential of CrewAI in your applications.
</Note>

| Use Case                | Recommended Approach                 | Why?                                                                                                                                        |
| :---------------------- | :----------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------ |
| **Open-ended research** | [Crews](/en/guides/crews/first-crew) | When tasks require creative thinking, exploration, and adaptation                                                                           |
| **Content generation**  | [Crews](/en/guides/crews/first-crew) | For collaborative creation of articles, reports, or marketing materials                                                                     |
| **Decision workflows**  | [Flows](/en/guides/flows/first-flow) | When you need predictable, auditable decision paths with precise control                                                                    |
| **API orchestration**   | [Flows](/en/guides/flows/first-flow) | For reliable integration with multiple external services in a specific sequence                                                             |
| **Hybrid applications** | Combined approach                    | Use [Flows](/en/guides/flows/first-flow) to orchestrate overall process with [Crews](/en/guides/crews/first-crew) handling complex subtasks |

### Decision Framework

* **Choose [Crews](/en/guides/crews/first-crew) when:** You need autonomous problem-solving, creative collaboration, or exploratory tasks
* **Choose [Flows](/en/guides/flows/first-flow) when:** You require deterministic outcomes, auditability, or precise control over execution
* **Combine both when:** Your application needs both structured processes and pockets of autonomous intelligence

## Why Choose CrewAI?

* üß† **Autonomous Operation**: Agents make intelligent decisions based on their roles and available tools
* üìù **Natural Interaction**: Agents communicate and collaborate like human team members
* üõ†Ô∏è **Extensible Design**: Easy to add new tools, roles, and capabilities
* üöÄ **Production Ready**: Built for reliability and scalability in real-world applications
* üîí **Security-Focused**: Designed with enterprise security requirements in mind
* üí∞ **Cost-Efficient**: Optimized to minimize token usage and API calls

## Ready to Start Building?

<CardGroup cols={2}>
  <Card title="Build Your First Crew" icon="users-gear" href="/en/guides/crews/first-crew">
    Step-by-step tutorial to create a collaborative AI team that works together to solve complex problems.
  </Card>

  <Card title="Build Your First Flow" icon="diagram-project" href="/en/guides/flows/first-flow">
    Learn how to create structured, event-driven workflows with precise control over execution.
  </Card>
</CardGroup>

<CardGroup cols={3}>
  <Card title="Install CrewAI" icon="wrench" href="/en/installation">
    Get started with CrewAI in your development environment.
  </Card>

  <Card title="Quick Start" icon="bolt" href="en/quickstart">
    Follow our quickstart guide to create your first CrewAI agent and get hands-on experience.
  </Card>

  <Card title="Join the Community" icon="comments" href="https://community.crewai.com">
    Connect with other developers, get help, and share your CrewAI experiences.
  </Card>
</CardGroup>


# Before and After Kickoff Hooks
Source: https://docs.crewai.com/en/learn/before-and-after-kickoff-hooks

Learn how to use before and after kickoff hooks in CrewAI

CrewAI provides hooks that allow you to execute code before and after a crew's kickoff. These hooks are useful for preprocessing inputs or post-processing results.

## Before Kickoff Hook

The before kickoff hook is executed before the crew starts its tasks. It receives the input dictionary and can modify it before passing it to the crew. You can use this hook to set up your environment, load necessary data, or preprocess your inputs. This is useful in scenarios where the input data might need enrichment or validation before being processed by the crew.

Here's an example of defining a before kickoff function in your `crew.py`:

```python
from crewai import CrewBase
from crewai.project import before_kickoff

@CrewBase
class MyCrew:
    @before_kickoff
    def prepare_data(self, inputs):
        # Preprocess or modify inputs
        inputs['processed'] = True
        return inputs

#...
```

In this example, the prepare\_data function modifies the inputs by adding a new key-value pair indicating that the inputs have been processed.

## After Kickoff Hook

The after kickoff hook is executed after the crew has completed its tasks. It receives the result object, which contains the outputs of the crew's execution. This hook is ideal for post-processing results, such as logging, data transformation, or further analysis.

Here's how you can define an after kickoff function in your `crew.py`:

```python
from crewai import CrewBase
from crewai.project import after_kickoff

@CrewBase
class MyCrew:
    @after_kickoff
    def log_results(self, result):
        # Log or modify the results
        print("Crew execution completed with result:", result)
        return result

# ...
```

In the `log_results` function, the results of the crew execution are simply printed out. You can extend this to perform more complex operations such as sending notifications or integrating with other services.

## Utilizing Both Hooks

Both hooks can be used together to provide a comprehensive setup and teardown process for your crew's execution. They are particularly useful in maintaining clean code architecture by separating concerns and enhancing the modularity of your CrewAI implementations.

## Conclusion

Before and after kickoff hooks in CrewAI offer powerful ways to interact with the lifecycle of a crew's execution. By understanding and utilizing these hooks, you can greatly enhance the robustness and flexibility of your AI agents.


# Bring your own agent
Source: https://docs.crewai.com/en/learn/bring-your-own-agent

Learn how to bring your own agents that work within a Crew.

Interoperability is a core concept in CrewAI. This guide will show you how to bring your own agents that work within a Crew.

## Adapter Guide for Bringing your own agents (Langgraph Agents, OpenAI Agents, etc...)

We require 3 adapters to turn any agent from different frameworks to work within crew.

1. BaseAgentAdapter
2. BaseToolAdapter
3. BaseConverter

## BaseAgentAdapter

This abstract class defines the common interface and functionality that all
agent adapters must implement. It extends BaseAgent to maintain compatibility
with the CrewAI framework while adding adapter-specific requirements.

Required Methods:

1. `def configure_tools`
2. `def configure_structured_output`

## Creating your own Adapter

To integrate an agent from a different framework (e.g., LangGraph, Autogen, OpenAI Assistants) into CrewAI, you need to create a custom adapter by inheriting from `BaseAgentAdapter`. This adapter acts as a compatibility layer, translating between the CrewAI interfaces and the specific requirements of your external agent.

Here's how you implement your custom adapter:

1. **Inherit from `BaseAgentAdapter`**:
   ```python
   from crewai.agents.agent_adapters.base_agent_adapter import BaseAgentAdapter
   from crewai.tools import BaseTool
   from typing import List, Optional, Any, Dict

   class MyCustomAgentAdapter(BaseAgentAdapter):
       # ... implementation details ...
   ```

2. **Implement `__init__`**:
   The constructor should call the parent class constructor `super().__init__(**kwargs)` and perform any initialization specific to your external agent. You can use the optional `agent_config` dictionary passed during CrewAI's `Agent` initialization to configure your adapter and the underlying agent.

   ```python
   def __init__(self, agent_config: Optional[Dict[str, Any]] = None, **kwargs: Any):
       super().__init__(agent_config=agent_config, **kwargs)
       # Initialize your external agent here, possibly using agent_config
       # Example: self.external_agent = initialize_my_agent(agent_config)
       print(f"Initializing MyCustomAgentAdapter with config: {agent_config}")
   ```

3. **Implement `configure_tools`**:
   This abstract method is crucial. It receives a list of CrewAI `BaseTool` instances. Your implementation must convert or adapt these tools into the format expected by your external agent framework. This might involve wrapping them, extracting specific attributes, or registering them with the external agent instance.

   ```python
   def configure_tools(self, tools: Optional[List[BaseTool]] = None) -> None:
       if tools:
           adapted_tools = []
           for tool in tools:
               # Adapt CrewAI BaseTool to the format your agent expects
               # Example: adapted_tool = adapt_to_my_framework(tool)
               # adapted_tools.append(adapted_tool)
               pass # Replace with your actual adaptation logic

           # Configure the external agent with the adapted tools
           # Example: self.external_agent.set_tools(adapted_tools)
           print(f"Configuring tools for MyCustomAgentAdapter: {adapted_tools}") # Placeholder
       else:
           # Handle the case where no tools are provided
           # Example: self.external_agent.set_tools([])
           print("No tools provided for MyCustomAgentAdapter.")
   ```

4. **Implement `configure_structured_output`**:
   This method is called when the CrewAI `Agent` is configured with structured output requirements (e.g., `output_json` or `output_pydantic`). Your adapter needs to ensure the external agent is set up to comply with these requirements. This might involve setting specific parameters on the external agent or ensuring its underlying model supports the requested format. If the external agent doesn't support structured output in a way compatible with CrewAI's expectations, you might need to handle the conversion or raise an appropriate error.

   ```python
   def configure_structured_output(self, structured_output: Any) -> None:
       # Configure your external agent to produce output in the specified format
       # Example: self.external_agent.set_output_format(structured_output)
       self.adapted_structured_output = True # Signal that structured output is handled
       print(f"Configuring structured output for MyCustomAgentAdapter: {structured_output}")
   ```

By implementing these methods, your `MyCustomAgentAdapter` will allow your custom agent implementation to function correctly within a CrewAI crew, interacting with tasks and tools seamlessly. Remember to replace the example comments and print statements with your actual adaptation logic specific to the external agent framework you are integrating.

## BaseToolAdapter implementation

The `BaseToolAdapter` class is responsible for converting CrewAI's native `BaseTool` objects into a format that your specific external agent framework can understand and utilize. Different agent frameworks (like LangGraph, OpenAI Assistants, etc.) have their own unique ways of defining and handling tools, and the `BaseToolAdapter` acts as the translator.

Here's how you implement your custom tool adapter:

1. **Inherit from `BaseToolAdapter`**:
   ```python
   from crewai.agents.agent_adapters.base_tool_adapter import BaseToolAdapter
   from crewai.tools import BaseTool
   from typing import List, Any

   class MyCustomToolAdapter(BaseToolAdapter):
       # ... implementation details ...
   ```

2. **Implement `configure_tools`**:
   This is the core abstract method you must implement. It receives a list of CrewAI `BaseTool` instances provided to the agent. Your task is to iterate through this list, adapt each `BaseTool` into the format expected by your external framework, and store the converted tools in the `self.converted_tools` list (which is initialized in the base class constructor).

   ```python
   def configure_tools(self, tools: List[BaseTool]) -> None:
       """Configure and convert CrewAI tools for the specific implementation."""
       self.converted_tools = [] # Reset in case it's called multiple times
       for tool in tools:
           # Sanitize the tool name if required by the target framework
           sanitized_name = self.sanitize_tool_name(tool.name)

           # --- Your Conversion Logic Goes Here ---
           # Example: Convert BaseTool to a dictionary format for LangGraph
           # converted_tool = {
           #     "name": sanitized_name,
           #     "description": tool.description,
           #     "parameters": tool.args_schema.schema() if tool.args_schema else {},
           #     # Add any other framework-specific fields
           # }

           # Example: Convert BaseTool to an OpenAI function definition
           # converted_tool = {
           #     "type": "function",
           #     "function": {
           #         "name": sanitized_name,
           #         "description": tool.description,
           #         "parameters": tool.args_schema.schema() if tool.args_schema else {"type": "object", "properties": {}},
           #     }
           # }

           # --- Replace above examples with your actual adaptation ---
           converted_tool = self.adapt_tool_to_my_framework(tool, sanitized_name) # Placeholder

           self.converted_tools.append(converted_tool)
           print(f"Adapted tool '{tool.name}' to '{sanitized_name}' for MyCustomToolAdapter") # Placeholder

       print(f"MyCustomToolAdapter finished configuring tools: {len(self.converted_tools)} adapted.") # Placeholder

   # --- Helper method for adaptation (Example) ---
   def adapt_tool_to_my_framework(self, tool: BaseTool, sanitized_name: str) -> Any:
       # Replace this with the actual logic to convert a CrewAI BaseTool
       # to the format needed by your specific external agent framework.
       # This will vary greatly depending on the target framework.
       adapted_representation = {
           "framework_specific_name": sanitized_name,
           "framework_specific_description": tool.description,
           "inputs": tool.args_schema.schema() if tool.args_schema else None,
           "implementation_reference": tool.run # Or however the framework needs to call it
       }
       # Also ensure the tool works both sync and async
       async def async_tool_wrapper(*args, **kwargs):
           output = tool.run(*args, **kwargs)
           if inspect.isawaitable(output):
               return await output
           else:
               return output

       adapted_tool = MyFrameworkTool(
           name=sanitized_name,
           description=tool.description,
           inputs=tool.args_schema.schema() if tool.args_schema else None,
           implementation_reference=async_tool_wrapper
       )

       return adapted_representation

   ```

3. **Using the Adapter**:
   Typically, you would instantiate your `MyCustomToolAdapter` within your `MyCustomAgentAdapter`'s `configure_tools` method and use it to process the tools before configuring your external agent.

   ```python
   # Inside MyCustomAgentAdapter.configure_tools
   def configure_tools(self, tools: Optional[List[BaseTool]] = None) -> None:
       if tools:
           tool_adapter = MyCustomToolAdapter() # Instantiate your tool adapter
           tool_adapter.configure_tools(tools)  # Convert the tools
           adapted_tools = tool_adapter.tools() # Get the converted tools

           # Now configure your external agent with the adapted_tools
           # Example: self.external_agent.set_tools(adapted_tools)
           print(f"Configuring external agent with adapted tools: {adapted_tools}") # Placeholder
       else:
           # Handle no tools case
           print("No tools provided for MyCustomAgentAdapter.")
   ```

By creating a `BaseToolAdapter`, you decouple the tool conversion logic from the agent adaptation, making the integration cleaner and more modular. Remember to replace the placeholder examples with the actual conversion logic required by your specific external agent framework.

## BaseConverter

The `BaseConverterAdapter` plays a crucial role when a CrewAI `Task` requires an agent to return its final output in a specific structured format, such as JSON or a Pydantic model. It bridges the gap between CrewAI's structured output requirements and the capabilities of your external agent.

Its primary responsibilities are:

1. **Configuring the Agent for Structured Output:** Based on the `Task`'s requirements (`output_json` or `output_pydantic`), it instructs the associated `BaseAgentAdapter` (and indirectly, the external agent) on what format is expected.
2. **Enhancing the System Prompt:** It modifies the agent's system prompt to include clear instructions on *how* to generate the output in the required structure.
3. **Post-processing the Result:** It takes the raw output from the agent and attempts to parse, validate, and format it according to the required structure, ultimately returning a string representation (e.g., a JSON string).

Here's how you implement your custom converter adapter:

1. **Inherit from `BaseConverterAdapter`**:
   ```python
   from crewai.agents.agent_adapters.base_converter_adapter import BaseConverterAdapter
   # Assuming you have your MyCustomAgentAdapter defined
   # from .my_custom_agent_adapter import MyCustomAgentAdapter
   from crewai.task import Task
   from typing import Any

   class MyCustomConverterAdapter(BaseConverterAdapter):
       # Store the expected output type (e.g., 'json', 'pydantic', 'text')
       _output_type: str = 'text'
       _output_schema: Any = None # Store JSON schema or Pydantic model

       # ... implementation details ...
   ```

2. **Implement `__init__`**:
   The constructor must accept the corresponding `agent_adapter` instance it will work with.

   ```python
   def __init__(self, agent_adapter: Any): # Use your specific AgentAdapter type hint
       self.agent_adapter = agent_adapter
       print(f"Initializing MyCustomConverterAdapter for agent adapter: {type(agent_adapter).__name__}")
   ```

3. **Implement `configure_structured_output`**:
   This method receives the CrewAI `Task` object. You need to check the task's `output_json` and `output_pydantic` attributes to determine the required output structure. Store this information (e.g., in `_output_type` and `_output_schema`) and potentially call configuration methods on your `self.agent_adapter` if the external agent needs specific setup for structured output (which might have been partially handled in the agent adapter's `configure_structured_output` already).

   ```python
   def configure_structured_output(self, task: Task) -> None:
       """Configure the expected structured output based on the task."""
       if task.output_pydantic:
           self._output_type = 'pydantic'
           self._output_schema = task.output_pydantic
           print(f"Converter: Configured for Pydantic output: {self._output_schema.__name__}")
       elif task.output_json:
           self._output_type = 'json'
           self._output_schema = task.output_json
           print(f"Converter: Configured for JSON output with schema: {self._output_schema}")
       else:
           self._output_type = 'text'
           self._output_schema = None
           print("Converter: Configured for standard text output.")

       # Optionally, inform the agent adapter if needed
       # self.agent_adapter.set_output_mode(self._output_type, self._output_schema)
   ```

4. **Implement `enhance_system_prompt`**:
   This method takes the agent's base system prompt string and should append instructions tailored to the currently configured `_output_type` and `_output_schema`. The goal is to guide the LLM powering the agent to produce output in the correct format.

   ````python
   def enhance_system_prompt(self, base_prompt: str) -> str:
       """Enhance the system prompt with structured output instructions."""
       if self._output_type == 'text':
           return base_prompt # No enhancement needed for plain text

       instructions = "\n\nYour final answer MUST be formatted as "
       if self._output_type == 'json':
           schema_str = json.dumps(self._output_schema, indent=2)
           instructions += f"a JSON object conforming to the following schema:\n```json\n{schema_str}\n```"
       elif self._output_type == 'pydantic':
           schema_str = json.dumps(self._output_schema.model_json_schema(), indent=2)
           instructions += f"a JSON object conforming to the Pydantic model '{self._output_schema.__name__}' with the following schema:\n```json\n{schema_str}\n```"

       instructions += "\nEnsure your entire response is ONLY the valid JSON object, without any introductory text, explanations, or concluding remarks."

       print(f"Converter: Enhancing prompt for {self._output_type} output.")
       return base_prompt + instructions
   ````

   *Note: The exact prompt engineering might need tuning based on the agent/LLM being used.*

5. **Implement `post_process_result`**:
   This method receives the raw string output from the agent. If structured output was requested (`json` or `pydantic`), you should attempt to parse the string into the expected format. Handle potential parsing errors (e.g., log them, attempt simple fixes, or raise an exception). Crucially, the method must **always return a string**, even if the intermediate format was a dictionary or Pydantic object (e.g., by serializing it back to a JSON string).

   ```python
   import json
   from pydantic import ValidationError

   def post_process_result(self, result: str) -> str:
       """Post-process the agent's result to ensure it matches the expected format."""
       print(f"Converter: Post-processing result for {self._output_type} output.")
       if self._output_type == 'json':
           try:
               # Attempt to parse and re-serialize to ensure validity and consistent format
               parsed_json = json.loads(result)
               # Optional: Validate against self._output_schema if it's a JSON schema dictionary
               # from jsonschema import validate
               # validate(instance=parsed_json, schema=self._output_schema)
               return json.dumps(parsed_json)
           except json.JSONDecodeError as e:
               print(f"Error: Failed to parse JSON output: {e}\nRaw output:\n{result}")
               # Handle error: return raw, raise exception, or try to fix
               return result # Example: return raw output on failure
           # except Exception as e: # Catch validation errors if using jsonschema
           #     print(f"Error: JSON output failed schema validation: {e}\nRaw output:\n{result}")
           #     return result
       elif self._output_type == 'pydantic':
           try:
               # Attempt to parse into the Pydantic model
               model_instance = self._output_schema.model_validate_json(result)
               # Return the model serialized back to JSON
               return model_instance.model_dump_json()
           except ValidationError as e:
               print(f"Error: Failed to validate Pydantic output: {e}\nRaw output:\n{result}")
               # Handle error
               return result # Example: return raw output on failure
           except json.JSONDecodeError as e:
                print(f"Error: Failed to parse JSON for Pydantic model: {e}\nRaw output:\n{result}")
                return result
       else: # 'text'
           return result # No processing needed for plain text
   ```

By implementing these methods, your `MyCustomConverterAdapter` ensures that structured output requests from CrewAI tasks are correctly handled by your integrated external agent, improving the reliability and usability of your custom agent within the CrewAI framework.

## Out of the Box Adapters

We provide out of the box adapters for the following frameworks:

1. LangGraph
2. OpenAI Agents

## Kicking off a crew with adapted agents:

```python
import json
import os
from typing import List

from crewai_tools import SerperDevTool
from src.crewai import Agent, Crew, Task
from langchain_openai import ChatOpenAI
from pydantic import BaseModel

from crewai.agents.agent_adapters.langgraph.langgraph_adapter import (
    LangGraphAgentAdapter,
)
from crewai.agents.agent_adapters.openai_agents.openai_adapter import OpenAIAgentAdapter

# CrewAI Agent
code_helper_agent = Agent(
    role="Code Helper",
    goal="Help users solve coding problems effectively and provide clear explanations.",
    backstory="You are an experienced programmer with deep knowledge across multiple programming languages and frameworks. You specialize in solving complex coding challenges and explaining solutions clearly.",
    allow_delegation=False,
    verbose=True,
)
# OpenAI Agent Adapter
link_finder_agent = OpenAIAgentAdapter(
    role="Link Finder",
    goal="Find the most relevant and high-quality resources for coding tasks.",
    backstory="You are a research specialist with a talent for finding the most helpful resources. You're skilled at using search tools to discover documentation, tutorials, and examples that directly address the user's coding needs.",
    tools=[SerperDevTool()],
    allow_delegation=False,
    verbose=True,
)

# LangGraph Agent Adapter
reporter_agent = LangGraphAgentAdapter(
    role="Reporter",
    goal="Report the results of the tasks.",
    backstory="You are a reporter who reports the results of the other tasks",
    llm=ChatOpenAI(model="gpt-4o"),
    allow_delegation=True,
    verbose=True,
)


class Code(BaseModel):
    code: str


task = Task(
    description="Give an answer to the coding question: {task}",
    expected_output="A thorough answer to the coding question: {task}",
    agent=code_helper_agent,
    output_json=Code,
)
task2 = Task(
    description="Find links to resources that can help with coding tasks. Use the serper tool to find resources that can help.",
    expected_output="A list of links to resources that can help with coding tasks",
    agent=link_finder_agent,
)


class Report(BaseModel):
    code: str
    links: List[str]


task3 = Task(
    description="Report the results of the tasks.",
    expected_output="A report of the results of the tasks. this is the code produced and then the links to the resources that can help with the coding task.",
    agent=reporter_agent,
    output_json=Report,
)
# Use in CrewAI
crew = Crew(
    agents=[code_helper_agent, link_finder_agent, reporter_agent],
    tasks=[task, task2, task3],
    verbose=True,
)

result = crew.kickoff(
    inputs={"task": "How do you implement an abstract class in python?"}
)

# Print raw result first
print("Raw result:", result)

# Handle result based on its type
if hasattr(result, "json_dict") and result.json_dict:
    json_result = result.json_dict
    print("\nStructured JSON result:")
    print(f"{json.dumps(json_result, indent=2)}")

    # Access fields safely
    if isinstance(json_result, dict):
        if "code" in json_result:
            print("\nCode:")
            print(
                json_result["code"][:200] + "..."
                if len(json_result["code"]) > 200
                else json_result["code"]
            )

        if "links" in json_result:
            print("\nLinks:")
            for link in json_result["links"][:5]:  # Print first 5 links
                print(f"- {link}")
            if len(json_result["links"]) > 5:
                print(f"...and {len(json_result['links']) - 5} more links")
elif hasattr(result, "pydantic") and result.pydantic:
    print("\nPydantic model result:")
    print(result.pydantic.model_dump_json(indent=2))
else:
    # Fallback to raw output
    print("\nNo structured result available, using raw output:")
    print(result.raw[:500] + "..." if len(result.raw) > 500 else result.raw)

```


# Coding Agents
Source: https://docs.crewai.com/en/learn/coding-agents

Learn how to enable your CrewAI Agents to write and execute code, and explore advanced features for enhanced functionality.

## Introduction

CrewAI Agents now have the powerful ability to write and execute code, significantly enhancing their problem-solving capabilities. This feature is particularly useful for tasks that require computational or programmatic solutions.

## Enabling Code Execution

To enable code execution for an agent, set the `allow_code_execution` parameter to `True` when creating the agent.

Here's an example:

```python Code
from crewai import Agent

coding_agent = Agent(
    role="Senior Python Developer",
    goal="Craft well-designed and thought-out code",
    backstory="You are a senior Python developer with extensive experience in software architecture and best practices.",
    allow_code_execution=True
)
```

<Note>
  Note that `allow_code_execution` parameter defaults to `False`.
</Note>

## Important Considerations

1. **Model Selection**: It is strongly recommended to use more capable models like Claude 3.5 Sonnet and GPT-4 when enabling code execution.
   These models have a better understanding of programming concepts and are more likely to generate correct and efficient code.

2. **Error Handling**: The code execution feature includes error handling. If executed code raises an exception, the agent will receive the error message and can attempt to correct the code or
   provide alternative solutions. The `max_retry_limit` parameter, which defaults to 2, controls the maximum number of retries for a task.

3. **Dependencies**: To use the code execution feature, you need to install the `crewai_tools` package. If not installed, the agent will log an info message:
   "Coding tools not available. Install crewai\_tools."

## Code Execution Process

When an agent with code execution enabled encounters a task requiring programming:

<Steps>
  <Step title="Task Analysis">
    The agent analyzes the task and determines that code execution is necessary.
  </Step>

  <Step title="Code Formulation">
    It formulates the Python code needed to solve the problem.
  </Step>

  <Step title="Code Execution">
    The code is sent to the internal code execution tool (`CodeInterpreterTool`).
  </Step>

  <Step title="Result Interpretation">
    The agent interprets the result and incorporates it into its response or uses it for further problem-solving.
  </Step>
</Steps>

## Example Usage

Here's a detailed example of creating an agent with code execution capabilities and using it in a task:

```python Code
from crewai import Agent, Task, Crew

# Create an agent with code execution enabled
coding_agent = Agent(
    role="Python Data Analyst",
    goal="Analyze data and provide insights using Python",
    backstory="You are an experienced data analyst with strong Python skills.",
    allow_code_execution=True
)

# Create a task that requires code execution
data_analysis_task = Task(
    description="Analyze the given dataset and calculate the average age of participants.",
    agent=coding_agent
)

# Create a crew and add the task
analysis_crew = Crew(
    agents=[coding_agent],
    tasks=[data_analysis_task]
)

# Execute the crew
result = analysis_crew.kickoff()

print(result)
```

In this example, the `coding_agent` can write and execute Python code to perform data analysis tasks.


# Conditional Tasks
Source: https://docs.crewai.com/en/learn/conditional-tasks

Learn how to use conditional tasks in a crewAI kickoff

## Introduction

Conditional Tasks in crewAI allow for dynamic workflow adaptation based on the outcomes of previous tasks.
This powerful feature enables crews to make decisions and execute tasks selectively, enhancing the flexibility and efficiency of your AI-driven processes.

## Example Usage

```python Code
from typing import List
from pydantic import BaseModel
from crewai import Agent, Crew
from crewai.tasks.conditional_task import ConditionalTask
from crewai.tasks.task_output import TaskOutput
from crewai.task import Task
from crewai_tools import SerperDevTool

# Define a condition function for the conditional task
# If false, the task will be skipped, if true, then execute the task.
def is_data_missing(output: TaskOutput) -> bool:
    return len(output.pydantic.events) < 10  # this will skip this task

# Define the agents
data_fetcher_agent = Agent(
    role="Data Fetcher",
    goal="Fetch data online using Serper tool",
    backstory="Backstory 1",
    verbose=True,
    tools=[SerperDevTool()]
)

data_processor_agent = Agent(
    role="Data Processor",
    goal="Process fetched data",
    backstory="Backstory 2",
    verbose=True
)

summary_generator_agent = Agent(
    role="Summary Generator",
    goal="Generate summary from fetched data",
    backstory="Backstory 3",
    verbose=True
)

class EventOutput(BaseModel):
    events: List[str]

task1 = Task(
    description="Fetch data about events in San Francisco using Serper tool",
    expected_output="List of 10 things to do in SF this week",
    agent=data_fetcher_agent,
    output_pydantic=EventOutput,
)

conditional_task = ConditionalTask(
    description="""
        Check if data is missing. If we have less than 10 events,
        fetch more events using Serper tool so that
        we have a total of 10 events in SF this week..
        """,
    expected_output="List of 10 Things to do in SF this week",
    condition=is_data_missing,
    agent=data_processor_agent,
)

task3 = Task(
    description="Generate summary of events in San Francisco from fetched data",
    expected_output="A complete report on the customer and their customers and competitors, including their demographics, preferences, market positioning and audience engagement.",
    agent=summary_generator_agent,
)

# Create a crew with the tasks
crew = Crew(
    agents=[data_fetcher_agent, data_processor_agent, summary_generator_agent],
    tasks=[task1, conditional_task, task3],
    verbose=True,
    planning=True
)

# Run the crew
result = crew.kickoff()
print("results", result)
```


# Create Custom Tools
Source: https://docs.crewai.com/en/learn/create-custom-tools

Comprehensive guide on crafting, using, and managing custom tools within the CrewAI framework, including new functionalities and error handling.

## Creating and Utilizing Tools in CrewAI

This guide provides detailed instructions on creating custom tools for the CrewAI framework and how to efficiently manage and utilize these tools,
incorporating the latest functionalities such as tool delegation, error handling, and dynamic tool calling. It also highlights the importance of collaboration tools,
enabling agents to perform a wide range of actions.

### Subclassing `BaseTool`

To create a personalized tool, inherit from `BaseTool` and define the necessary attributes, including the `args_schema` for input validation, and the `_run` method.

```python Code
from typing import Type
from crewai.tools import BaseTool
from pydantic import BaseModel, Field

class MyToolInput(BaseModel):
    """Input schema for MyCustomTool."""
    argument: str = Field(..., description="Description of the argument.")

class MyCustomTool(BaseTool):
    name: str = "Name of my tool"
    description: str = "What this tool does. It's vital for effective utilization."
    args_schema: Type[BaseModel] = MyToolInput

    def _run(self, argument: str) -> str:
        # Your tool's logic here
        return "Tool's result"
```

### Using the `tool` Decorator

Alternatively, you can use the tool decorator `@tool`. This approach allows you to define the tool's attributes and functionality directly within a function,
offering a concise and efficient way to create specialized tools tailored to your needs.

```python Code
from crewai.tools import tool

@tool("Tool Name")
def my_simple_tool(question: str) -> str:
    """Tool description for clarity."""
    # Tool logic here
    return "Tool output"
```

### Defining a Cache Function for the Tool

To optimize tool performance with caching, define custom caching strategies using the `cache_function` attribute.

```python Code
@tool("Tool with Caching")
def cached_tool(argument: str) -> str:
    """Tool functionality description."""
    return "Cacheable result"

def my_cache_strategy(arguments: dict, result: str) -> bool:
    # Define custom caching logic
    return True if some_condition else False

cached_tool.cache_function = my_cache_strategy
```

By adhering to these guidelines and incorporating new functionalities and collaboration tools into your tool creation and management processes,
you can leverage the full capabilities of the CrewAI framework, enhancing both the development experience and the efficiency of your AI agents.


# Custom LLM Implementation
Source: https://docs.crewai.com/en/learn/custom-llm

Learn how to create custom LLM implementations in CrewAI.

## Overview

CrewAI supports custom LLM implementations through the `BaseLLM` abstract base class. This allows you to integrate any LLM provider that doesn't have built-in support in LiteLLM, or implement custom authentication mechanisms.

## Quick Start

Here's a minimal custom LLM implementation:

```python
from crewai import BaseLLM
from typing import Any, Dict, List, Optional, Union
import requests

class CustomLLM(BaseLLM):
    def __init__(self, model: str, api_key: str, endpoint: str, temperature: Optional[float] = None):
        # IMPORTANT: Call super().__init__() with required parameters
        super().__init__(model=model, temperature=temperature)

        self.api_key = api_key
        self.endpoint = endpoint

    def call(
        self,
        messages: Union[str, List[Dict[str, str]]],
        tools: Optional[List[dict]] = None,
        callbacks: Optional[List[Any]] = None,
        available_functions: Optional[Dict[str, Any]] = None,
    ) -> Union[str, Any]:
        """Call the LLM with the given messages."""
        # Convert string to message format if needed
        if isinstance(messages, str):
            messages = [{"role": "user", "content": messages}]

        # Prepare request
        payload = {
            "model": self.model,
            "messages": messages,
            "temperature": self.temperature,
        }

        # Add tools if provided and supported
        if tools and self.supports_function_calling():
            payload["tools"] = tools

        # Make API call
        response = requests.post(
            self.endpoint,
            headers={
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            },
            json=payload,
            timeout=30
        )
        response.raise_for_status()

        result = response.json()
        return result["choices"][0]["message"]["content"]

    def supports_function_calling(self) -> bool:
        """Override if your LLM supports function calling."""
        return True  # Change to False if your LLM doesn't support tools

    def get_context_window_size(self) -> int:
        """Return the context window size of your LLM."""
        return 8192  # Adjust based on your model's actual context window
```

## Using Your Custom LLM

```python
from crewai import Agent, Task, Crew

# Assuming you have the CustomLLM class defined above
# Create your custom LLM
custom_llm = CustomLLM(
    model="my-custom-model",
    api_key="your-api-key",
    endpoint="https://api.example.com/v1/chat/completions",
    temperature=0.7
)

# Use with an agent
agent = Agent(
    role="Research Assistant",
    goal="Find and analyze information",
    backstory="You are a research assistant.",
    llm=custom_llm
)

# Create and execute tasks
task = Task(
    description="Research the latest developments in AI",
    expected_output="A comprehensive summary",
    agent=agent
)

crew = Crew(agents=[agent], tasks=[task])
result = crew.kickoff()
```

## Required Methods

### Constructor: `__init__()`

**Critical**: You must call `super().__init__(model, temperature)` with the required parameters:

```python
def __init__(self, model: str, api_key: str, temperature: Optional[float] = None):
    # REQUIRED: Call parent constructor with model and temperature
    super().__init__(model=model, temperature=temperature)

    # Your custom initialization
    self.api_key = api_key
```

### Abstract Method: `call()`

The `call()` method is the heart of your LLM implementation. It must:

* Accept messages (string or list of dicts with 'role' and 'content')
* Return a string response
* Handle tools and function calling if supported
* Raise appropriate exceptions for errors

### Optional Methods

```python
def supports_function_calling(self) -> bool:
    """Return True if your LLM supports function calling."""
    return True  # Default is True

def supports_stop_words(self) -> bool:
    """Return True if your LLM supports stop sequences."""
    return True  # Default is True

def get_context_window_size(self) -> int:
    """Return the context window size."""
    return 4096  # Default is 4096
```

## Common Patterns

### Error Handling

```python
import requests

def call(self, messages, tools=None, callbacks=None, available_functions=None):
    try:
        response = requests.post(
            self.endpoint,
            headers={"Authorization": f"Bearer {self.api_key}"},
            json=payload,
            timeout=30
        )
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]

    except requests.Timeout:
        raise TimeoutError("LLM request timed out")
    except requests.RequestException as e:
        raise RuntimeError(f"LLM request failed: {str(e)}")
    except (KeyError, IndexError) as e:
        raise ValueError(f"Invalid response format: {str(e)}")
```

### Custom Authentication

```python
from crewai import BaseLLM
from typing import Optional

class CustomAuthLLM(BaseLLM):
    def __init__(self, model: str, auth_token: str, endpoint: str, temperature: Optional[float] = None):
        super().__init__(model=model, temperature=temperature)
        self.auth_token = auth_token
        self.endpoint = endpoint

    def call(self, messages, tools=None, callbacks=None, available_functions=None):
        headers = {
            "Authorization": f"Custom {self.auth_token}",  # Custom auth format
            "Content-Type": "application/json"
        }
        # Rest of implementation...
```

### Stop Words Support

CrewAI automatically adds `"\nObservation:"` as a stop word to control agent behavior. If your LLM supports stop words:

```python
def call(self, messages, tools=None, callbacks=None, available_functions=None):
    payload = {
        "model": self.model,
        "messages": messages,
        "stop": self.stop  # Include stop words in API call
    }
    # Make API call...

def supports_stop_words(self) -> bool:
    return True  # Your LLM supports stop sequences
```

If your LLM doesn't support stop words natively:

```python
def call(self, messages, tools=None, callbacks=None, available_functions=None):
    response = self._make_api_call(messages, tools)
    content = response["choices"][0]["message"]["content"]

    # Manually truncate at stop words
    if self.stop:
        for stop_word in self.stop:
            if stop_word in content:
                content = content.split(stop_word)[0]
                break

    return content

def supports_stop_words(self) -> bool:
    return False  # Tell CrewAI we handle stop words manually
```

## Function Calling

If your LLM supports function calling, implement the complete flow:

```python
import json

def call(self, messages, tools=None, callbacks=None, available_functions=None):
    # Convert string to message format
    if isinstance(messages, str):
        messages = [{"role": "user", "content": messages}]

    # Make API call
    response = self._make_api_call(messages, tools)
    message = response["choices"][0]["message"]

    # Check for function calls
    if "tool_calls" in message and available_functions:
        return self._handle_function_calls(
            message["tool_calls"], messages, tools, available_functions
        )

    return message["content"]

def _handle_function_calls(self, tool_calls, messages, tools, available_functions):
    """Handle function calling with proper message flow."""
    for tool_call in tool_calls:
        function_name = tool_call["function"]["name"]

        if function_name in available_functions:
            # Parse and execute function
            function_args = json.loads(tool_call["function"]["arguments"])
            function_result = available_functions[function_name](**function_args)

            # Add function call and result to message history
            messages.append({
                "role": "assistant",
                "content": None,
                "tool_calls": [tool_call]
            })
            messages.append({
                "role": "tool",
                "tool_call_id": tool_call["id"],
                "name": function_name,
                "content": str(function_result)
            })

            # Call LLM again with updated context
            return self.call(messages, tools, None, available_functions)

    return "Function call failed"
```

## Troubleshooting

### Common Issues

**Constructor Errors**

```python
# ‚ùå Wrong - missing required parameters
def __init__(self, api_key: str):
    super().__init__()

# ‚úÖ Correct
def __init__(self, model: str, api_key: str, temperature: Optional[float] = None):
    super().__init__(model=model, temperature=temperature)
```

**Function Calling Not Working**

* Ensure `supports_function_calling()` returns `True`
* Check that you handle `tool_calls` in the response
* Verify `available_functions` parameter is used correctly

**Authentication Failures**

* Verify API key format and permissions
* Check authentication header format
* Ensure endpoint URLs are correct

**Response Parsing Errors**

* Validate response structure before accessing nested fields
* Handle cases where content might be None
* Add proper error handling for malformed responses

## Testing Your Custom LLM

```python
from crewai import Agent, Task, Crew

def test_custom_llm():
    llm = CustomLLM(
        model="test-model",
        api_key="test-key",
        endpoint="https://api.test.com"
    )

    # Test basic call
    result = llm.call("Hello, world!")
    assert isinstance(result, str)
    assert len(result) > 0

    # Test with CrewAI agent
    agent = Agent(
        role="Test Agent",
        goal="Test custom LLM",
        backstory="A test agent.",
        llm=llm
    )

    task = Task(
        description="Say hello",
        expected_output="A greeting",
        agent=agent
    )

    crew = Crew(agents=[agent], tasks=[task])
    result = crew.kickoff()
    assert "hello" in result.raw.lower()
```

This guide covers the essentials of implementing custom LLMs in CrewAI.


# Custom Manager Agent
Source: https://docs.crewai.com/en/learn/custom-manager-agent

Learn how to set a custom agent as the manager in CrewAI, providing more control over task management and coordination.

# Setting a Specific Agent as Manager in CrewAI

CrewAI allows users to set a specific agent as the manager of the crew, providing more control over the management and coordination of tasks.
This feature enables the customization of the managerial role to better fit your project's requirements.

## Using the `manager_agent` Attribute

### Custom Manager Agent

The `manager_agent` attribute allows you to define a custom agent to manage the crew. This agent will oversee the entire process, ensuring that tasks are completed efficiently and to the highest standard.

### Example

```python Code
import os
from crewai import Agent, Task, Crew, Process

# Define your agents
researcher = Agent(
    role="Researcher",
    goal="Conduct thorough research and analysis on AI and AI agents",
    backstory="You're an expert researcher, specialized in technology, software engineering, AI, and startups. You work as a freelancer and are currently researching for a new client.",
    allow_delegation=False,
)

writer = Agent(
    role="Senior Writer",
    goal="Create compelling content about AI and AI agents",
    backstory="You're a senior writer, specialized in technology, software engineering, AI, and startups. You work as a freelancer and are currently writing content for a new client.",
    allow_delegation=False,
)

# Define your task
task = Task(
    description="Generate a list of 5 interesting ideas for an article, then write one captivating paragraph for each idea that showcases the potential of a full article on this topic. Return the list of ideas with their paragraphs and your notes.",
    expected_output="5 bullet points, each with a paragraph and accompanying notes.",
)

# Define the manager agent
manager = Agent(
    role="Project Manager",
    goal="Efficiently manage the crew and ensure high-quality task completion",
    backstory="You're an experienced project manager, skilled in overseeing complex projects and guiding teams to success. Your role is to coordinate the efforts of the crew members, ensuring that each task is completed on time and to the highest standard.",
    allow_delegation=True,
)

# Instantiate your crew with a custom manager
crew = Crew(
    agents=[researcher, writer],
    tasks=[task],
    manager_agent=manager,
    process=Process.hierarchical,
)

# Start the crew's work
result = crew.kickoff()
```

## Benefits of a Custom Manager Agent

* **Enhanced Control**: Tailor the management approach to fit the specific needs of your project.
* **Improved Coordination**: Ensure efficient task coordination and management by an experienced agent.
* **Customizable Management**: Define managerial roles and responsibilities that align with your project's goals.

## Setting a Manager LLM

If you're using the hierarchical process and don't want to set a custom manager agent, you can specify the language model for the manager:

```python Code
from crewai import LLM

manager_llm = LLM(model="gpt-4o")

crew = Crew(
    agents=[researcher, writer],
    tasks=[task],
    process=Process.hierarchical,
    manager_llm=manager_llm
)
```

<Note>
  Either `manager_agent` or `manager_llm` must be set when using the hierarchical process.
</Note>


# Customize Agents
Source: https://docs.crewai.com/en/learn/customizing-agents

A comprehensive guide to tailoring agents for specific roles, tasks, and advanced customizations within the CrewAI framework.

## Customizable Attributes

Crafting an efficient CrewAI team hinges on the ability to dynamically tailor your AI agents to meet the unique requirements of any project. This section covers the foundational attributes you can customize.

### Key Attributes for Customization

| Attribute                           | Description                                                                                                         |
| :---------------------------------- | :------------------------------------------------------------------------------------------------------------------ |
| **Role**                            | Specifies the agent's job within the crew, such as 'Analyst' or 'Customer Service Rep'.                             |
| **Goal**                            | Defines the agent‚Äôs objectives, aligned with its role and the crew‚Äôs overarching mission.                           |
| **Backstory**                       | Provides depth to the agent's persona, enhancing motivations and engagements within the crew.                       |
| **Tools** *(Optional)*              | Represents the capabilities or methods the agent uses for tasks, from simple functions to complex integrations.     |
| **Cache** *(Optional)*              | Determines if the agent should use a cache for tool usage.                                                          |
| **Max RPM**                         | Sets the maximum requests per minute (`max_rpm`). Can be set to `None` for unlimited requests to external services. |
| **Verbose** *(Optional)*            | Enables detailed logging for debugging and optimization, providing insights into execution processes.               |
| **Allow Delegation** *(Optional)*   | Controls task delegation to other agents, default is `False`.                                                       |
| **Max Iter** *(Optional)*           | Limits the maximum number of iterations (`max_iter`) for a task to prevent infinite loops, with a default of 25.    |
| **Max Execution Time** *(Optional)* | Sets the maximum time allowed for an agent to complete a task.                                                      |
| **System Template** *(Optional)*    | Defines the system format for the agent.                                                                            |
| **Prompt Template** *(Optional)*    | Defines the prompt format for the agent.                                                                            |
| **Response Template** *(Optional)*  | Defines the response format for the agent.                                                                          |
| **Use System Prompt** *(Optional)*  | Controls whether the agent will use a system prompt during task execution.                                          |
| **Respect Context Window**          | Enables a sliding context window by default, maintaining context size.                                              |
| **Max Retry Limit**                 | Sets the maximum number of retries (`max_retry_limit`) for an agent in case of errors.                              |

## Advanced Customization Options

Beyond the basic attributes, CrewAI allows for deeper customization to enhance an agent's behavior and capabilities significantly.

### Language Model Customization

Agents can be customized with specific language models (`llm`) and function-calling language models (`function_calling_llm`), offering advanced control over their processing and decision-making abilities.
It's important to note that setting the `function_calling_llm` allows for overriding the default crew function-calling language model, providing a greater degree of customization.

## Performance and Debugging Settings

Adjusting an agent's performance and monitoring its operations are crucial for efficient task execution.

### Verbose Mode and RPM Limit

* **Verbose Mode**: Enables detailed logging of an agent's actions, useful for debugging and optimization. Specifically, it provides insights into agent execution processes, aiding in the optimization of performance.
* **RPM Limit**: Sets the maximum number of requests per minute (`max_rpm`). This attribute is optional and can be set to `None` for no limit, allowing for unlimited queries to external services if needed.

### Maximum Iterations for Task Execution

The `max_iter` attribute allows users to define the maximum number of iterations an agent can perform for a single task, preventing infinite loops or excessively long executions.
The default value is set to 25, providing a balance between thoroughness and efficiency. Once the agent approaches this number, it will try its best to give a good answer.

## Customizing Agents and Tools

Agents are customized by defining their attributes and tools during initialization. Tools are critical for an agent's functionality, enabling them to perform specialized tasks.
The `tools` attribute should be an array of tools the agent can utilize, and it's initialized as an empty list by default. Tools can be added or modified post-agent initialization to adapt to new requirements.

```shell
pip install 'crewai[tools]'
```

### Example: Assigning Tools to an Agent

```python Code
import os
from crewai import Agent
from crewai_tools import SerperDevTool

# Set API keys for tool initialization
os.environ["OPENAI_API_KEY"] = "Your Key"
os.environ["SERPER_API_KEY"] = "Your Key"

# Initialize a search tool
search_tool = SerperDevTool()

# Initialize the agent with advanced options
agent = Agent(
  role='Research Analyst',
  goal='Provide up-to-date market analysis',
  backstory='An expert analyst with a keen eye for market trends.',
  tools=[search_tool],
  memory=True, # Enable memory
  verbose=True,
  max_rpm=None, # No limit on requests per minute
  max_iter=25, # Default value for maximum iterations
)
```

## Delegation and Autonomy

Controlling an agent's ability to delegate tasks or ask questions is vital for tailoring its autonomy and collaborative dynamics within the CrewAI framework. By default,
the `allow_delegation` attribute is now set to `False`, disabling agents to seek assistance or delegate tasks as needed. This default behavior can be changed to promote collaborative problem-solving and
efficiency within the CrewAI ecosystem. If needed, delegation can be enabled to suit specific operational requirements.

### Example: Disabling Delegation for an Agent

```python Code
agent = Agent(
  role='Content Writer',
  goal='Write engaging content on market trends',
  backstory='A seasoned writer with expertise in market analysis.',
  allow_delegation=True # Enabling delegation
)
```

## Conclusion

Customizing agents in CrewAI by setting their roles, goals, backstories, and tools, alongside advanced options like language model customization, memory, performance settings, and delegation preferences,
equips a nuanced and capable AI team ready for complex challenges.


# Image Generation with DALL-E
Source: https://docs.crewai.com/en/learn/dalle-image-generation

Learn how to use DALL-E for AI-powered image generation in your CrewAI projects

CrewAI supports integration with OpenAI's DALL-E, allowing your AI agents to generate images as part of their tasks. This guide will walk you through how to set up and use the DALL-E tool in your CrewAI projects.

## Prerequisites

* crewAI installed (latest version)
* OpenAI API key with access to DALL-E

## Setting Up the DALL-E Tool

<Steps>
  <Step title="Import the DALL-E tool">
    ```python
    from crewai_tools import DallETool
    ```
  </Step>

  <Step title="Add the DALL-E tool to your agent configuration">
    ```python
    @agent
    def researcher(self) -> Agent:
        return Agent(
            config=self.agents_config['researcher'],
            tools=[SerperDevTool(), DallETool()],  # Add DallETool to the list of tools
            allow_delegation=False,
            verbose=True
        )
    ```
  </Step>
</Steps>

## Using the DALL-E Tool

Once you've added the DALL-E tool to your agent, it can generate images based on text prompts. The tool will return a URL to the generated image, which can be used in the agent's output or passed to other agents for further processing.

### Example Agent Configuration

```yaml
role: >
    LinkedIn Profile Senior Data Researcher
goal: >
    Uncover detailed LinkedIn profiles based on provided name {name} and domain {domain}
    Generate a Dall-e image based on domain {domain}
backstory: >
    You're a seasoned researcher with a knack for uncovering the most relevant LinkedIn profiles.
    Known for your ability to navigate LinkedIn efficiently, you excel at gathering and presenting
    professional information clearly and concisely.
```

### Expected Output

The agent with the DALL-E tool will be able to generate the image and provide a URL in its response. You can then download the image.

<Frame>
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/dall-e-image.png" alt="DALL-E Image" />
</Frame>

## Best Practices

1. **Be specific in your image generation prompts** to get the best results.
2. **Consider generation time** - Image generation can take some time, so factor this into your task planning.
3. **Follow usage policies** - Always comply with OpenAI's usage policies when generating images.

## Troubleshooting

1. **Check API access** - Ensure your OpenAI API key has access to DALL-E.
2. **Version compatibility** - Check that you're using the latest version of crewAI and crewai-tools.
3. **Tool configuration** - Verify that the DALL-E tool is correctly added to the agent's tool list.


# Force Tool Output as Result
Source: https://docs.crewai.com/en/learn/force-tool-output-as-result

Learn how to force tool output as the result in an Agent's task in CrewAI.

## Introduction

In CrewAI, you can force the output of a tool as the result of an agent's task.
This feature is useful when you want to ensure that the tool output is captured and returned as the task result, avoiding any agent modification during the task execution.

## Forcing Tool Output as Result

To force the tool output as the result of an agent's task, you need to set the `result_as_answer` parameter to `True` when adding a tool to the agent.
This parameter ensures that the tool output is captured and returned as the task result, without any modifications by the agent.

Here's an example of how to force the tool output as the result of an agent's task:

```python Code
from crewai.agent import Agent
from my_tool import MyCustomTool

# Create a coding agent with the custom tool
coding_agent = Agent(
        role="Data Scientist",
        goal="Produce amazing reports on AI",
        backstory="You work with data and AI",
        tools=[MyCustomTool(result_as_answer=True)],
    )

# Assuming the tool's execution and result population occurs within the system
task_result = coding_agent.execute_task(task)
```

## Workflow in Action

<Steps>
  <Step title="Task Execution">
    The agent executes the task using the tool provided.
  </Step>

  <Step title="Tool Output">
    The tool generates the output, which is captured as the task result.
  </Step>

  <Step title="Agent Interaction">
    The agent may reflect and take learnings from the tool but the output is not modified.
  </Step>

  <Step title="Result Return">
    The tool output is returned as the task result without any modifications.
  </Step>
</Steps>


# Hierarchical Process
Source: https://docs.crewai.com/en/learn/hierarchical-process

A comprehensive guide to understanding and applying the hierarchical process within your CrewAI projects, updated to reflect the latest coding practices and functionalities.

## Introduction

The hierarchical process in CrewAI introduces a structured approach to task management, simulating traditional organizational hierarchies for efficient task delegation and execution.
This systematic workflow enhances project outcomes by ensuring tasks are handled with optimal efficiency and accuracy.

<Tip>
  The hierarchical process is designed to leverage advanced models like GPT-4, optimizing token usage while handling complex tasks with greater efficiency.
</Tip>

## Hierarchical Process Overview

By default, tasks in CrewAI are managed through a sequential process. However, adopting a hierarchical approach allows for a clear hierarchy in task management,
where a 'manager' agent coordinates the workflow, delegates tasks, and validates outcomes for streamlined and effective execution. This manager agent can now be either
automatically created by CrewAI or explicitly set by the user.

### Key Features

* **Task Delegation**: A manager agent allocates tasks among crew members based on their roles and capabilities.
* **Result Validation**: The manager evaluates outcomes to ensure they meet the required standards.
* **Efficient Workflow**: Emulates corporate structures, providing an organized approach to task management.
* **System Prompt Handling**: Optionally specify whether the system should use predefined prompts.
* **Stop Words Control**: Optionally specify whether stop words should be used, supporting various models including the o1 models.
* **Context Window Respect**: Prioritize important context by enabling respect of the context window, which is now the default behavior.
* **Delegation Control**: Delegation is now disabled by default to give users explicit control.
* **Max Requests Per Minute**: Configurable option to set the maximum number of requests per minute.
* **Max Iterations**: Limit the maximum number of iterations for obtaining a final answer.

## Implementing the Hierarchical Process

To utilize the hierarchical process, it's essential to explicitly set the process attribute to `Process.hierarchical`, as the default behavior is `Process.sequential`.
Define a crew with a designated manager and establish a clear chain of command.

<Tip>
  Assign tools at the agent level to facilitate task delegation and execution by the designated agents under the manager's guidance.
  Tools can also be specified at the task level for precise control over tool availability during task execution.
</Tip>

<Tip>
  Configuring the `manager_llm` parameter is crucial for the hierarchical process.
  The system requires a manager LLM to be set up for proper function, ensuring tailored decision-making.
</Tip>

```python Code
from crewai import Crew, Process, Agent

# Agents are defined with attributes for backstory, cache, and verbose mode
researcher = Agent(
    role='Researcher',
    goal='Conduct in-depth analysis',
    backstory='Experienced data analyst with a knack for uncovering hidden trends.',
)
writer = Agent(
    role='Writer',
    goal='Create engaging content',
    backstory='Creative writer passionate about storytelling in technical domains.',
)

# Establishing the crew with a hierarchical process and additional configurations
project_crew = Crew(
    tasks=[...],  # Tasks to be delegated and executed under the manager's supervision
    agents=[researcher, writer],
    manager_llm="gpt-4o",  # Specify which LLM the manager should use
    process=Process.hierarchical,
    planning=True,
)
```

### Using a Custom Manager Agent

Alternatively, you can create a custom manager agent with specific attributes tailored to your project's management needs. This gives you more control over the manager's behavior and capabilities.

```python
# Define a custom manager agent
manager = Agent(
    role="Project Manager",
    goal="Efficiently manage the crew and ensure high-quality task completion",
    backstory="You're an experienced project manager, skilled in overseeing complex projects and guiding teams to success.",
    allow_delegation=True,
)

# Use the custom manager in your crew
project_crew = Crew(
    tasks=[...],
    agents=[researcher, writer],
    manager_agent=manager,  # Use your custom manager agent
    process=Process.hierarchical,
    planning=True,
)
```

<Tip>
  For more details on creating and customizing a manager agent, check out the [Custom Manager Agent documentation](https://docs.crewai.com/how-to/custom-manager-agent#custom-manager-agent).
</Tip>

### Workflow in Action

1. **Task Assignment**: The manager assigns tasks strategically, considering each agent's capabilities and available tools.
2. **Execution and Review**: Agents complete their tasks with the option for asynchronous execution and callback functions for streamlined workflows.
3. **Sequential Task Progression**: Despite being a hierarchical process, tasks follow a logical order for smooth progression, facilitated by the manager's oversight.

## Conclusion

Adopting the hierarchical process in CrewAI, with the correct configurations and understanding of the system's capabilities, facilitates an organized and efficient approach to project management.
Utilize the advanced features and customizations to tailor the workflow to your specific needs, ensuring optimal task execution and project success.


# Human-in-the-Loop (HITL) Workflows
Source: https://docs.crewai.com/en/learn/human-in-the-loop

Learn how to implement Human-in-the-Loop workflows in CrewAI for enhanced decision-making

Human-in-the-Loop (HITL) is a powerful approach that combines artificial intelligence with human expertise to enhance decision-making and improve task outcomes. This guide shows you how to implement HITL within CrewAI.

## Setting Up HITL Workflows

<Steps>
  <Step title="Configure Your Task">
    Set up your task with human input enabled:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-human-input.png" alt="Crew Human Input" />
    </Frame>
  </Step>

  <Step title="Provide Webhook URL">
    When kicking off your crew, include a webhook URL for human input:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-webhook-url.png" alt="Crew Webhook URL" />
    </Frame>
  </Step>

  <Step title="Receive Webhook Notification">
    Once the crew completes the task requiring human input, you'll receive a webhook notification containing:

    * Execution ID
    * Task ID
    * Task output
  </Step>

  <Step title="Review Task Output">
    The system will pause in the `Pending Human Input` state. Review the task output carefully.
  </Step>

  <Step title="Submit Human Feedback">
    Call the resume endpoint of your crew with the following information:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-resume-endpoint.png" alt="Crew Resume Endpoint" />
    </Frame>

    <Warning>
      **Feedback Impact on Task Execution**:
      It's crucial to exercise care when providing feedback, as the entire feedback content will be incorporated as additional context for further task executions.
    </Warning>

    This means:

    * All information in your feedback becomes part of the task's context.
    * Irrelevant details may negatively influence it.
    * Concise, relevant feedback helps maintain task focus and efficiency.
    * Always review your feedback carefully before submission to ensure it contains only pertinent information that will positively guide the task's execution.
  </Step>

  <Step title="Handle Negative Feedback">
    If you provide negative feedback:

    * The crew will retry the task with added context from your feedback.
    * You'll receive another webhook notification for further review.
    * Repeat steps 4-6 until satisfied.
  </Step>

  <Step title="Execution Continuation">
    When you submit positive feedback, the execution will proceed to the next steps.
  </Step>
</Steps>

## Best Practices

* **Be Specific**: Provide clear, actionable feedback that directly addresses the task at hand
* **Stay Relevant**: Only include information that will help improve the task execution
* **Be Timely**: Respond to HITL prompts promptly to avoid workflow delays
* **Review Carefully**: Double-check your feedback before submitting to ensure accuracy

## Common Use Cases

HITL workflows are particularly valuable for:

* Quality assurance and validation
* Complex decision-making scenarios
* Sensitive or high-stakes operations
* Creative tasks requiring human judgment
* Compliance and regulatory reviews


# Human Input on Execution
Source: https://docs.crewai.com/en/learn/human-input-on-execution

Integrating CrewAI with human input during execution in complex decision-making processes and leveraging the full capabilities of the agent's attributes and tools.

## Human input in agent execution

Human input is critical in several agent execution scenarios, allowing agents to request additional information or clarification when necessary.
This feature is especially useful in complex decision-making processes or when agents require more details to complete a task effectively.

## Using human input with CrewAI

To integrate human input into agent execution, set the `human_input` flag in the task definition. When enabled, the agent prompts the user for input before delivering its final answer.
This input can provide extra context, clarify ambiguities, or validate the agent's output.

### Example:

```shell
pip install crewai
```

```python Code
import os
from crewai import Agent, Task, Crew
from crewai_tools import SerperDevTool

os.environ["SERPER_API_KEY"] = "Your Key"  # serper.dev API key
os.environ["OPENAI_API_KEY"] = "Your Key"

# Loading Tools
search_tool = SerperDevTool()

# Define your agents with roles, goals, tools, and additional attributes
researcher = Agent(
    role='Senior Research Analyst',
    goal='Uncover cutting-edge developments in AI and data science',
    backstory=(
        "You are a Senior Research Analyst at a leading tech think tank. "
        "Your expertise lies in identifying emerging trends and technologies in AI and data science. "
        "You have a knack for dissecting complex data and presenting actionable insights."
    ),
    verbose=True,
    allow_delegation=False,
    tools=[search_tool]
)
writer = Agent(
    role='Tech Content Strategist',
    goal='Craft compelling content on tech advancements',
    backstory=(
        "You are a renowned Tech Content Strategist, known for your insightful and engaging articles on technology and innovation. "
        "With a deep understanding of the tech industry, you transform complex concepts into compelling narratives."
    ),
    verbose=True,
    allow_delegation=True,
    tools=[search_tool],
    cache=False,  # Disable cache for this agent
)

# Create tasks for your agents
task1 = Task(
    description=(
        "Conduct a comprehensive analysis of the latest advancements in AI in 2025. "
        "Identify key trends, breakthrough technologies, and potential industry impacts. "
        "Compile your findings in a detailed report. "
        "Make sure to check with a human if the draft is good before finalizing your answer."
    ),
    expected_output='A comprehensive full report on the latest AI advancements in 2025, leave nothing out',
    agent=researcher,
    human_input=True
)

task2 = Task(
    description=(
        "Using the insights from the researcher\'s report, develop an engaging blog post that highlights the most significant AI advancements. "
        "Your post should be informative yet accessible, catering to a tech-savvy audience. "
        "Aim for a narrative that captures the essence of these breakthroughs and their implications for the future."
    ),
    expected_output='A compelling 3 paragraphs blog post formatted as markdown about the latest AI advancements in 2025',
    agent=writer,
    human_input=True
)

# Instantiate your crew with a sequential process
crew = Crew(
    agents=[researcher, writer],
    tasks=[task1, task2],
    verbose=True,
    memory=True,
    planning=True  # Enable planning feature for the crew
)

# Get your crew to work!
result = crew.kickoff()

print("######################")
print(result)
```


# Kickoff Crew Asynchronously
Source: https://docs.crewai.com/en/learn/kickoff-async

Kickoff a Crew Asynchronously

## Introduction

CrewAI provides the ability to kickoff a crew asynchronously, allowing you to start the crew execution in a non-blocking manner.
This feature is particularly useful when you want to run multiple crews concurrently or when you need to perform other tasks while the crew is executing.

## Asynchronous Crew Execution

To kickoff a crew asynchronously, use the `kickoff_async()` method. This method initiates the crew execution in a separate thread, allowing the main thread to continue executing other tasks.

### Method Signature

```python Code
def kickoff_async(self, inputs: dict) -> CrewOutput:
```

### Parameters

* `inputs` (dict): A dictionary containing the input data required for the tasks.

### Returns

* `CrewOutput`: An object representing the result of the crew execution.

## Potential Use Cases

* **Parallel Content Generation**: Kickoff multiple independent crews asynchronously, each responsible for generating content on different topics. For example, one crew might research and draft an article on AI trends, while another crew generates social media posts about a new product launch. Each crew operates independently, allowing content production to scale efficiently.

* **Concurrent Market Research Tasks**: Launch multiple crews asynchronously to conduct market research in parallel. One crew might analyze industry trends, while another examines competitor strategies, and yet another evaluates consumer sentiment. Each crew independently completes its task, enabling faster and more comprehensive insights.

* **Independent Travel Planning Modules**: Execute separate crews to independently plan different aspects of a trip. One crew might handle flight options, another handles accommodation, and a third plans activities. Each crew works asynchronously, allowing various components of the trip to be planned simultaneously and independently for faster results.

## Example: Single Asynchronous Crew Execution

Here's an example of how to kickoff a crew asynchronously using asyncio and awaiting the result:

```python Code
import asyncio
from crewai import Crew, Agent, Task

# Create an agent with code execution enabled
coding_agent = Agent(
    role="Python Data Analyst",
    goal="Analyze data and provide insights using Python",
    backstory="You are an experienced data analyst with strong Python skills.",
    allow_code_execution=True
)

# Create a task that requires code execution
data_analysis_task = Task(
    description="Analyze the given dataset and calculate the average age of participants. Ages: {ages}",
    agent=coding_agent,
    expected_output="The average age of the participants."
)

# Create a crew and add the task
analysis_crew = Crew(
    agents=[coding_agent],
    tasks=[data_analysis_task]
)

# Async function to kickoff the crew asynchronously
async def async_crew_execution():
    result = await analysis_crew.kickoff_async(inputs={"ages": [25, 30, 35, 40, 45]})
    print("Crew Result:", result)

# Run the async function
asyncio.run(async_crew_execution())
```

## Example: Multiple Asynchronous Crew Executions

In this example, we'll show how to kickoff multiple crews asynchronously and wait for all of them to complete using `asyncio.gather()`:

```python Code
import asyncio
from crewai import Crew, Agent, Task

# Create an agent with code execution enabled
coding_agent = Agent(
    role="Python Data Analyst",
    goal="Analyze data and provide insights using Python",
    backstory="You are an experienced data analyst with strong Python skills.",
    allow_code_execution=True
)

# Create tasks that require code execution
task_1 = Task(
    description="Analyze the first dataset and calculate the average age of participants. Ages: {ages}",
    agent=coding_agent,
    expected_output="The average age of the participants."
)

task_2 = Task(
    description="Analyze the second dataset and calculate the average age of participants. Ages: {ages}",
    agent=coding_agent,
    expected_output="The average age of the participants."
)

# Create two crews and add tasks
crew_1 = Crew(agents=[coding_agent], tasks=[task_1])
crew_2 = Crew(agents=[coding_agent], tasks=[task_2])

# Async function to kickoff multiple crews asynchronously and wait for all to finish
async def async_multiple_crews():
    # Create coroutines for concurrent execution
    result_1 = crew_1.kickoff_async(inputs={"ages": [25, 30, 35, 40, 45]})
    result_2 = crew_2.kickoff_async(inputs={"ages": [20, 22, 24, 28, 30]})

    # Wait for both crews to finish
    results = await asyncio.gather(result_1, result_2)

    for i, result in enumerate(results, 1):
        print(f"Crew {i} Result:", result)

# Run the async function
asyncio.run(async_multiple_crews())
```


# Kickoff Crew for Each
Source: https://docs.crewai.com/en/learn/kickoff-for-each

Kickoff Crew for Each Item in a List

## Introduction

CrewAI provides the ability to kickoff a crew for each item in a list, allowing you to execute the crew for each item in the list.
This feature is particularly useful when you need to perform the same set of tasks for multiple items.

## Kicking Off a Crew for Each Item

To kickoff a crew for each item in a list, use the `kickoff_for_each()` method.
This method executes the crew for each item in the list, allowing you to process multiple items efficiently.

Here's an example of how to kickoff a crew for each item in a list:

```python Code
from crewai import Crew, Agent, Task

# Create an agent with code execution enabled
coding_agent = Agent(
    role="Python Data Analyst",
    goal="Analyze data and provide insights using Python",
    backstory="You are an experienced data analyst with strong Python skills.",
    allow_code_execution=True
)

# Create a task that requires code execution
data_analysis_task = Task(
    description="Analyze the given dataset and calculate the average age of participants. Ages: {ages}",
    agent=coding_agent,
    expected_output="The average age calculated from the dataset"
)

# Create a crew and add the task
analysis_crew = Crew(
    agents=[coding_agent],
    tasks=[data_analysis_task],
    verbose=True,
    memory=False
)

datasets = [
  { "ages": [25, 30, 35, 40, 45] },
  { "ages": [20, 25, 30, 35, 40] },
  { "ages": [30, 35, 40, 45, 50] }
]

# Execute the crew
result = analysis_crew.kickoff_for_each(inputs=datasets)
```


# Connect to any LLM
Source: https://docs.crewai.com/en/learn/llm-connections

Comprehensive guide on integrating CrewAI with various Large Language Models (LLMs) using LiteLLM, including supported providers and configuration options.

## Connect CrewAI to LLMs

CrewAI uses LiteLLM to connect to a wide variety of Language Models (LLMs). This integration provides extensive versatility, allowing you to use models from numerous providers with a simple, unified interface.

<Note>
  By default, CrewAI uses the `gpt-4o-mini` model. This is determined by the `OPENAI_MODEL_NAME` environment variable, which defaults to "gpt-4o-mini" if not set.
  You can easily configure your agents to use a different model or provider as described in this guide.
</Note>

## Supported Providers

LiteLLM supports a wide range of providers, including but not limited to:

* OpenAI
* Anthropic
* Google (Vertex AI, Gemini)
* Azure OpenAI
* AWS (Bedrock, SageMaker)
* Cohere
* VoyageAI
* Hugging Face
* Ollama
* Mistral AI
* Replicate
* Together AI
* AI21
* Cloudflare Workers AI
* DeepInfra
* Groq
* SambaNova
* Nebius AI Studio
* [NVIDIA NIMs](https://docs.api.nvidia.com/nim/reference/models-1)
* And many more!

For a complete and up-to-date list of supported providers, please refer to the [LiteLLM Providers documentation](https://docs.litellm.ai/docs/providers).

## Changing the LLM

To use a different LLM with your CrewAI agents, you have several options:

<Tabs>
  <Tab title="Using a String Identifier">
    Pass the model name as a string when initializing the agent:

    <CodeGroup>
      ```python Code
      from crewai import Agent

      # Using OpenAI's GPT-4
      openai_agent = Agent(
          role='OpenAI Expert',
          goal='Provide insights using GPT-4',
          backstory="An AI assistant powered by OpenAI's latest model.",
          llm='gpt-4'
      )

      # Using Anthropic's Claude
      claude_agent = Agent(
          role='Anthropic Expert',
          goal='Analyze data using Claude',
          backstory="An AI assistant leveraging Anthropic's language model.",
          llm='claude-2'
      )
      ```
    </CodeGroup>
  </Tab>

  <Tab title="Using the LLM Class">
    For more detailed configuration, use the LLM class:

    <CodeGroup>
      ```python Code
      from crewai import Agent, LLM

      llm = LLM(
          model="gpt-4",
          temperature=0.7,
          base_url="https://api.openai.com/v1",
          api_key="your-api-key-here"
      )

      agent = Agent(
          role='Customized LLM Expert',
          goal='Provide tailored responses',
          backstory="An AI assistant with custom LLM settings.",
          llm=llm
      )
      ```
    </CodeGroup>
  </Tab>
</Tabs>

## Configuration Options

When configuring an LLM for your agent, you have access to a wide range of parameters:

| Parameter              |        Type        | Description                                                      |
| :--------------------- | :----------------: | :--------------------------------------------------------------- |
| **model**              |        `str`       | The name of the model to use (e.g., "gpt-4", "claude-2")         |
| **temperature**        |       `float`      | Controls randomness in output (0.0 to 1.0)                       |
| **max\_tokens**        |        `int`       | Maximum number of tokens to generate                             |
| **top\_p**             |       `float`      | Controls diversity of output (0.0 to 1.0)                        |
| **frequency\_penalty** |       `float`      | Penalizes new tokens based on their frequency in the text so far |
| **presence\_penalty**  |       `float`      | Penalizes new tokens based on their presence in the text so far  |
| **stop**               | `str`, `List[str]` | Sequence(s) to stop generation                                   |
| **base\_url**          |        `str`       | The base URL for the API endpoint                                |
| **api\_key**           |        `str`       | Your API key for authentication                                  |

For a complete list of parameters and their descriptions, refer to the LLM class documentation.

## Connecting to OpenAI-Compatible LLMs

You can connect to OpenAI-compatible LLMs using either environment variables or by setting specific attributes on the LLM class:

<Tabs>
  <Tab title="Using Environment Variables">
    <CodeGroup>
      ```python Generic
      import os

      os.environ["OPENAI_API_KEY"] = "your-api-key"
      os.environ["OPENAI_API_BASE"] = "https://api.your-provider.com/v1"
      os.environ["OPENAI_MODEL_NAME"] = "your-model-name"
      ```

      ```python Google
      import os

      # Example using Gemini's OpenAI-compatible API.
      os.environ["OPENAI_API_KEY"] = "your-gemini-key"  # Should start with AIza...
      os.environ["OPENAI_API_BASE"] = "https://generativelanguage.googleapis.com/v1beta/openai/"
      os.environ["OPENAI_MODEL_NAME"] = "openai/gemini-2.0-flash"  # Add your Gemini model here, under openai/
      ```
    </CodeGroup>
  </Tab>

  <Tab title="Using LLM Class Attributes">
    <CodeGroup>
      ```python Generic
      llm = LLM(
          model="custom-model-name",
          api_key="your-api-key",
          base_url="https://api.your-provider.com/v1"
      )
      agent = Agent(llm=llm, ...)
      ```

      ```python Google
      # Example using Gemini's OpenAI-compatible API
      llm = LLM(
          model="openai/gemini-2.0-flash",
          base_url="https://generativelanguage.googleapis.com/v1beta/openai/",
          api_key="your-gemini-key",  # Should start with AIza...
      )
      agent = Agent(llm=llm, ...)
      ```
    </CodeGroup>
  </Tab>
</Tabs>

## Using Local Models with Ollama

For local models like those provided by Ollama:

<Steps>
  <Step title="Download and install Ollama">
    [Click here to download and install Ollama](https://ollama.com/download)
  </Step>

  <Step title="Pull the desired model">
    For example, run `ollama pull llama3.2` to download the model.
  </Step>

  <Step title="Configure your agent">
    <CodeGroup>
      ```python Code
          agent = Agent(
              role='Local AI Expert',
              goal='Process information using a local model',
              backstory="An AI assistant running on local hardware.",
              llm=LLM(model="ollama/llama3.2", base_url="http://localhost:11434")
          )
      ```
    </CodeGroup>
  </Step>
</Steps>

## Changing the Base API URL

You can change the base API URL for any LLM provider by setting the `base_url` parameter:

```python Code
llm = LLM(
    model="custom-model-name",
    base_url="https://api.your-provider.com/v1",
    api_key="your-api-key"
)
agent = Agent(llm=llm, ...)
```

This is particularly useful when working with OpenAI-compatible APIs or when you need to specify a different endpoint for your chosen provider.

## Conclusion

By leveraging LiteLLM, CrewAI offers seamless integration with a vast array of LLMs. This flexibility allows you to choose the most suitable model for your specific needs, whether you prioritize performance, cost-efficiency, or local deployment. Remember to consult the [LiteLLM documentation](https://docs.litellm.ai/docs/) for the most up-to-date information on supported models and configuration options.


# Strategic LLM Selection Guide
Source: https://docs.crewai.com/en/learn/llm-selection-guide

Strategic framework for choosing the right LLM for your CrewAI AI agents and writing effective task and agent definitions

## The CrewAI Approach to LLM Selection

Rather than prescriptive model recommendations, we advocate for a **thinking framework** that helps you make informed decisions based on your specific use case, constraints, and requirements. The LLM landscape evolves rapidly, with new models emerging regularly and existing ones being updated frequently. What matters most is developing a systematic approach to evaluation that remains relevant regardless of which specific models are available.

<Note>
  This guide focuses on strategic thinking rather than specific model recommendations, as the LLM landscape evolves rapidly.
</Note>

## Quick Decision Framework

<Steps>
  <Step title="Analyze Your Tasks">
    Begin by deeply understanding what your tasks actually require. Consider the cognitive complexity involved, the depth of reasoning needed, the format of expected outputs, and the amount of context the model will need to process. This foundational analysis will guide every subsequent decision.
  </Step>

  <Step title="Map Model Capabilities">
    Once you understand your requirements, map them to model strengths. Different model families excel at different types of work; some are optimized for reasoning and analysis, others for creativity and content generation, and others for speed and efficiency.
  </Step>

  <Step title="Consider Constraints">
    Factor in your real-world operational constraints including budget limitations, latency requirements, data privacy needs, and infrastructure capabilities. The theoretically best model may not be the practically best choice for your situation.
  </Step>

  <Step title="Test and Iterate">
    Start with reliable, well-understood models and optimize based on actual performance in your specific use case. Real-world results often differ from theoretical benchmarks, so empirical testing is crucial.
  </Step>
</Steps>

## Core Selection Framework

### a. Task-First Thinking

The most critical step in LLM selection is understanding what your task actually demands. Too often, teams select models based on general reputation or benchmark scores without carefully analyzing their specific requirements. This approach leads to either over-engineering simple tasks with expensive, complex models, or under-powering sophisticated work with models that lack the necessary capabilities.

<Tabs>
  <Tab title="Reasoning Complexity">
    * **Simple Tasks** represent the majority of everyday AI work and include basic instruction following, straightforward data processing, and simple formatting operations. These tasks typically have clear inputs and outputs with minimal ambiguity. The cognitive load is low, and the model primarily needs to follow explicit instructions rather than engage in complex reasoning.

    * **Complex Tasks** require multi-step reasoning, strategic thinking, and the ability to handle ambiguous or incomplete information. These might involve analyzing multiple data sources, developing comprehensive strategies, or solving problems that require breaking down into smaller components. The model needs to maintain context across multiple reasoning steps and often must make inferences that aren't explicitly stated.

    * **Creative Tasks** demand a different type of cognitive capability focused on generating novel, engaging, and contextually appropriate content. This includes storytelling, marketing copy creation, and creative problem-solving. The model needs to understand nuance, tone, and audience while producing content that feels authentic and engaging rather than formulaic.
  </Tab>

  <Tab title="Output Requirements">
    * **Structured Data** tasks require precision and consistency in format adherence. When working with JSON, XML, or database formats, the model must reliably produce syntactically correct output that can be programmatically processed. These tasks often have strict validation requirements and little tolerance for format errors, making reliability more important than creativity.

    * **Creative Content** outputs demand a balance of technical competence and creative flair. The model needs to understand audience, tone, and brand voice while producing content that engages readers and achieves specific communication goals. Quality here is often subjective and requires models that can adapt their writing style to different contexts and purposes.

    * **Technical Content** sits between structured data and creative content, requiring both precision and clarity. Documentation, code generation, and technical analysis need to be accurate and comprehensive while remaining accessible to the intended audience. The model must understand complex technical concepts and communicate them effectively.
  </Tab>

  <Tab title="Context Needs">
    * **Short Context** scenarios involve focused, immediate tasks where the model needs to process limited information quickly. These are often transactional interactions where speed and efficiency matter more than deep understanding. The model doesn't need to maintain extensive conversation history or process large documents.

    * **Long Context** requirements emerge when working with substantial documents, extended conversations, or complex multi-part tasks. The model needs to maintain coherence across thousands of tokens while referencing earlier information accurately. This capability becomes crucial for document analysis, comprehensive research, and sophisticated dialogue systems.

    * **Very Long Context** scenarios push the boundaries of what's currently possible, involving massive document processing, extensive research synthesis, or complex multi-session interactions. These use cases require models specifically designed for extended context handling and often involve trade-offs between context length and processing speed.
  </Tab>
</Tabs>

### b. Model Capability Mapping

Understanding model capabilities requires looking beyond marketing claims and benchmark scores to understand the fundamental strengths and limitations of different model architectures and training approaches.

<AccordionGroup>
  <Accordion title="Reasoning Models" icon="brain">
    Reasoning models represent a specialized category designed specifically for complex, multi-step thinking tasks. These models excel when problems require careful analysis, strategic planning, or systematic problem decomposition. They typically employ techniques like chain-of-thought reasoning or tree-of-thought processing to work through complex problems step by step.

    The strength of reasoning models lies in their ability to maintain logical consistency across extended reasoning chains and to break down complex problems into manageable components. They're particularly valuable for strategic planning, complex analysis, and situations where the quality of reasoning matters more than speed of response.

    However, reasoning models often come with trade-offs in terms of speed and cost. They may also be less suitable for creative tasks or simple operations where their sophisticated reasoning capabilities aren't needed. Consider these models when your tasks involve genuine complexity that benefits from systematic, step-by-step analysis.
  </Accordion>

  <Accordion title="General Purpose Models" icon="microchip">
    General purpose models offer the most balanced approach to LLM selection, providing solid performance across a wide range of tasks without extreme specialization in any particular area. These models are trained on diverse datasets and optimized for versatility rather than peak performance in specific domains.

    The primary advantage of general purpose models is their reliability and predictability across different types of work. They handle most standard business tasks competently, from research and analysis to content creation and data processing. This makes them excellent choices for teams that need consistent performance across varied workflows.

    While general purpose models may not achieve the peak performance of specialized alternatives in specific domains, they offer operational simplicity and reduced complexity in model management. They're often the best starting point for new projects, allowing teams to understand their specific needs before potentially optimizing with more specialized models.
  </Accordion>

  <Accordion title="Fast & Efficient Models" icon="bolt">
    Fast and efficient models prioritize speed, cost-effectiveness, and resource efficiency over sophisticated reasoning capabilities. These models are optimized for high-throughput scenarios where quick responses and low operational costs are more important than nuanced understanding or complex reasoning.

    These models excel in scenarios involving routine operations, simple data processing, function calling, and high-volume tasks where the cognitive requirements are relatively straightforward. They're particularly valuable for applications that need to process many requests quickly or operate within tight budget constraints.

    The key consideration with efficient models is ensuring that their capabilities align with your task requirements. While they can handle many routine operations effectively, they may struggle with tasks requiring nuanced understanding, complex reasoning, or sophisticated content generation. They're best used for well-defined, routine operations where speed and cost matter more than sophistication.
  </Accordion>

  <Accordion title="Creative Models" icon="pen">
    Creative models are specifically optimized for content generation, writing quality, and creative thinking tasks. These models typically excel at understanding nuance, tone, and style while producing engaging, contextually appropriate content that feels natural and authentic.

    The strength of creative models lies in their ability to adapt writing style to different audiences, maintain consistent voice and tone, and generate content that engages readers effectively. They often perform better on tasks involving storytelling, marketing copy, brand communications, and other content where creativity and engagement are primary goals.

    When selecting creative models, consider not just their ability to generate text, but their understanding of audience, context, and purpose. The best creative models can adapt their output to match specific brand voices, target different audience segments, and maintain consistency across extended content pieces.
  </Accordion>

  <Accordion title="Open Source Models" icon="code">
    Open source models offer unique advantages in terms of cost control, customization potential, data privacy, and deployment flexibility. These models can be run locally or on private infrastructure, providing complete control over data handling and model behavior.

    The primary benefits of open source models include elimination of per-token costs, ability to fine-tune for specific use cases, complete data privacy, and independence from external API providers. They're particularly valuable for organizations with strict data privacy requirements, budget constraints, or specific customization needs.

    However, open source models require more technical expertise to deploy and maintain effectively. Teams need to consider infrastructure costs, model management complexity, and the ongoing effort required to keep models updated and optimized. The total cost of ownership may be higher than cloud-based alternatives when factoring in technical overhead.
  </Accordion>
</AccordionGroup>

## Strategic Configuration Patterns

### a. Multi-Model Approach

<Tip>
  Use different models for different purposes within the same crew to optimize both performance and cost.
</Tip>

The most sophisticated CrewAI implementations often employ multiple models strategically, assigning different models to different agents based on their specific roles and requirements. This approach allows teams to optimize for both performance and cost by using the most appropriate model for each type of work.

Planning agents benefit from reasoning models that can handle complex strategic thinking and multi-step analysis. These agents often serve as the "brain" of the operation, developing strategies and coordinating other agents' work. Content agents, on the other hand, perform best with creative models that excel at writing quality and audience engagement. Processing agents handling routine operations can use efficient models that prioritize speed and cost-effectiveness.

**Example: Research and Analysis Crew**

```python
from crewai import Agent, Task, Crew, LLM

# High-capability reasoning model for strategic planning
manager_llm = LLM(model="gemini-2.5-flash-preview-05-20", temperature=0.1)

# Creative model for content generation
content_llm = LLM(model="claude-3-5-sonnet-20241022", temperature=0.7)

# Efficient model for data processing
processing_llm = LLM(model="gpt-4o-mini", temperature=0)

research_manager = Agent(
    role="Research Strategy Manager",
    goal="Develop comprehensive research strategies and coordinate team efforts",
    backstory="Expert research strategist with deep analytical capabilities",
    llm=manager_llm,  # High-capability model for complex reasoning
    verbose=True
)

content_writer = Agent(
    role="Research Content Writer",
    goal="Transform research findings into compelling, well-structured reports",
    backstory="Skilled writer who excels at making complex topics accessible",
    llm=content_llm,  # Creative model for engaging content
    verbose=True
)

data_processor = Agent(
    role="Data Analysis Specialist",
    goal="Extract and organize key data points from research sources",
    backstory="Detail-oriented analyst focused on accuracy and efficiency",
    llm=processing_llm,  # Fast, cost-effective model for routine tasks
    verbose=True
)

crew = Crew(
    agents=[research_manager, content_writer, data_processor],
    tasks=[...],  # Your specific tasks
    manager_llm=manager_llm,  # Manager uses the reasoning model
    verbose=True
)
```

The key to successful multi-model implementation is understanding how different agents interact and ensuring that model capabilities align with agent responsibilities. This requires careful planning but can result in significant improvements in both output quality and operational efficiency.

### b. Component-Specific Selection

<Tabs>
  <Tab title="Manager LLM">
    The manager LLM plays a crucial role in hierarchical CrewAI processes, serving as the coordination point for multiple agents and tasks. This model needs to excel at delegation, task prioritization, and maintaining context across multiple concurrent operations.

    Effective manager LLMs require strong reasoning capabilities to make good delegation decisions, consistent performance to ensure predictable coordination, and excellent context management to track the state of multiple agents simultaneously. The model needs to understand the capabilities and limitations of different agents while optimizing task allocation for efficiency and quality.

    Cost considerations are particularly important for manager LLMs since they're involved in every operation. The model needs to provide sufficient capability for effective coordination while remaining cost-effective for frequent use. This often means finding models that offer good reasoning capabilities without the premium pricing of the most sophisticated options.
  </Tab>

  <Tab title="Function Calling LLM">
    Function calling LLMs handle tool usage across all agents, making them critical for crews that rely heavily on external tools and APIs. These models need to excel at understanding tool capabilities, extracting parameters accurately, and handling tool responses effectively.

    The most important characteristics for function calling LLMs are precision and reliability rather than creativity or sophisticated reasoning. The model needs to consistently extract the correct parameters from natural language requests and handle tool responses appropriately. Speed is also important since tool usage often involves multiple round trips that can impact overall performance.

    Many teams find that specialized function calling models or general purpose models with strong tool support work better than creative or reasoning-focused models for this role. The key is ensuring that the model can reliably bridge the gap between natural language instructions and structured tool calls.
  </Tab>

  <Tab title="Agent-Specific Overrides">
    Individual agents can override crew-level LLM settings when their specific needs differ significantly from the general crew requirements. This capability allows for fine-tuned optimization while maintaining operational simplicity for most agents.

    Consider agent-specific overrides when an agent's role requires capabilities that differ substantially from other crew members. For example, a creative writing agent might benefit from a model optimized for content generation, while a data analysis agent might perform better with a reasoning-focused model.

    The challenge with agent-specific overrides is balancing optimization with operational complexity. Each additional model adds complexity to deployment, monitoring, and cost management. Teams should focus overrides on agents where the performance improvement justifies the additional complexity.
  </Tab>
</Tabs>

## Task Definition Framework

### a. Focus on Clarity Over Complexity

Effective task definition is often more important than model selection in determining the quality of CrewAI outputs. Well-defined tasks provide clear direction and context that enable even modest models to perform well, while poorly defined tasks can cause even sophisticated models to produce unsatisfactory results.

<AccordionGroup>
  <Accordion title="Effective Task Descriptions" icon="list-check">
    The best task descriptions strike a balance between providing sufficient detail and maintaining clarity. They should define the specific objective clearly enough that there's no ambiguity about what success looks like, while explaining the approach or methodology in enough detail that the agent understands how to proceed.

    Effective task descriptions include relevant context and constraints that help the agent understand the broader purpose and any limitations they need to work within. They break complex work into focused steps that can be executed systematically, rather than presenting overwhelming, multi-faceted objectives that are difficult to approach systematically.

    Common mistakes include being too vague about objectives, failing to provide necessary context, setting unclear success criteria, or combining multiple unrelated tasks into a single description. The goal is to provide enough information for the agent to succeed while maintaining focus on a single, clear objective.
  </Accordion>

  <Accordion title="Expected Output Guidelines" icon="bullseye">
    Expected output guidelines serve as a contract between the task definition and the agent, clearly specifying what the deliverable should look like and how it will be evaluated. These guidelines should describe both the format and structure needed, as well as the key elements that must be included for the output to be considered complete.

    The best output guidelines provide concrete examples of quality indicators and define completion criteria clearly enough that both the agent and human reviewers can assess whether the task has been completed successfully. This reduces ambiguity and helps ensure consistent results across multiple task executions.

    Avoid generic output descriptions that could apply to any task, missing format specifications that leave agents guessing about structure, unclear quality standards that make evaluation difficult, or failing to provide examples or templates that help agents understand expectations.
  </Accordion>
</AccordionGroup>

### b. Task Sequencing Strategy

<Tabs>
  <Tab title="Sequential Dependencies">
    Sequential task dependencies are essential when tasks build upon previous outputs, information flows from one task to another, or quality depends on the completion of prerequisite work. This approach ensures that each task has access to the information and context it needs to succeed.

    Implementing sequential dependencies effectively requires using the context parameter to chain related tasks, building complexity gradually through task progression, and ensuring that each task produces outputs that serve as meaningful inputs for subsequent tasks. The goal is to maintain logical flow between dependent tasks while avoiding unnecessary bottlenecks.

    Sequential dependencies work best when there's a clear logical progression from one task to another and when the output of one task genuinely improves the quality or feasibility of subsequent tasks. However, they can create bottlenecks if not managed carefully, so it's important to identify which dependencies are truly necessary versus those that are merely convenient.
  </Tab>

  <Tab title="Parallel Execution">
    Parallel execution becomes valuable when tasks are independent of each other, time efficiency is important, or different expertise areas are involved that don't require coordination. This approach can significantly reduce overall execution time while allowing specialized agents to work on their areas of strength simultaneously.

    Successful parallel execution requires identifying tasks that can truly run independently, grouping related but separate work streams effectively, and planning for result integration when parallel tasks need to be combined into a final deliverable. The key is ensuring that parallel tasks don't create conflicts or redundancies that reduce overall quality.

    Consider parallel execution when you have multiple independent research streams, different types of analysis that don't depend on each other, or content creation tasks that can be developed simultaneously. However, be mindful of resource allocation and ensure that parallel execution doesn't overwhelm your available model capacity or budget.
  </Tab>
</Tabs>

## Optimizing Agent Configuration for LLM Performance

### a. Role-Driven LLM Selection

<Warning>
  Generic agent roles make it impossible to select the right LLM. Specific roles enable targeted model optimization.
</Warning>

The specificity of your agent roles directly determines which LLM capabilities matter most for optimal performance. This creates a strategic opportunity to match precise model strengths with agent responsibilities.

**Generic vs. Specific Role Impact on LLM Choice:**

When defining roles, think about the specific domain knowledge, working style, and decision-making frameworks that would be most valuable for the tasks the agent will handle. The more specific and contextual the role definition, the better the model can embody that role effectively.

```python
# ‚úÖ Specific role - clear LLM requirements
specific_agent = Agent(
    role="SaaS Revenue Operations Analyst",  # Clear domain expertise needed
    goal="Analyze recurring revenue metrics and identify growth opportunities",
    backstory="Specialist in SaaS business models with deep understanding of ARR, churn, and expansion revenue",
    llm=LLM(model="gpt-4o")  # Reasoning model justified for complex analysis
)
```

**Role-to-Model Mapping Strategy:**

* **"Research Analyst"** ‚Üí Reasoning model (GPT-4o, Claude Sonnet) for complex analysis
* **"Content Editor"** ‚Üí Creative model (Claude, GPT-4o) for writing quality
* **"Data Processor"** ‚Üí Efficient model (GPT-4o-mini, Gemini Flash) for structured tasks
* **"API Coordinator"** ‚Üí Function-calling optimized model (GPT-4o, Claude) for tool usage

### b. Backstory as Model Context Amplifier

<Info>
  Strategic backstories multiply your chosen LLM's effectiveness by providing domain-specific context that generic prompting cannot achieve.
</Info>

A well-crafted backstory transforms your LLM choice from generic capability to specialized expertise. This is especially crucial for cost optimization - a well-contextualized efficient model can outperform a premium model without proper context.

**Context-Driven Performance Example:**

```python
# Context amplifies model effectiveness
domain_expert = Agent(
    role="B2B SaaS Marketing Strategist",
    goal="Develop comprehensive go-to-market strategies for enterprise software",
    backstory="""
    You have 10+ years of experience scaling B2B SaaS companies from Series A to IPO.
    You understand the nuances of enterprise sales cycles, the importance of product-market
    fit in different verticals, and how to balance growth metrics with unit economics.
    You've worked with companies like Salesforce, HubSpot, and emerging unicorns, giving
    you perspective on both established and disruptive go-to-market strategies.
    """,
    llm=LLM(model="claude-3-5-sonnet", temperature=0.3)  # Balanced creativity with domain knowledge
)

# This context enables Claude to perform like a domain expert
# Without it, even it would produce generic marketing advice
```

**Backstory Elements That Enhance LLM Performance:**

* **Domain Experience**: "10+ years in enterprise SaaS sales"
* **Specific Expertise**: "Specializes in technical due diligence for Series B+ rounds"
* **Working Style**: "Prefers data-driven decisions with clear documentation"
* **Quality Standards**: "Insists on citing sources and showing analytical work"

### c. Holistic Agent-LLM Optimization

The most effective agent configurations create synergy between role specificity, backstory depth, and LLM selection. Each element reinforces the others to maximize model performance.

**Optimization Framework:**

```python
# Example: Technical Documentation Agent
tech_writer = Agent(
    role="API Documentation Specialist",  # Specific role for clear LLM requirements
    goal="Create comprehensive, developer-friendly API documentation",
    backstory="""
    You're a technical writer with 8+ years documenting REST APIs, GraphQL endpoints,
    and SDK integration guides. You've worked with developer tools companies and
    understand what developers need: clear examples, comprehensive error handling,
    and practical use cases. You prioritize accuracy and usability over marketing fluff.
    """,
    llm=LLM(
        model="claude-3-5-sonnet",  # Excellent for technical writing
        temperature=0.1  # Low temperature for accuracy
    ),
    tools=[code_analyzer_tool, api_scanner_tool],
    verbose=True
)
```

**Alignment Checklist:**

* ‚úÖ **Role Specificity**: Clear domain and responsibilities
* ‚úÖ **LLM Match**: Model strengths align with role requirements
* ‚úÖ **Backstory Depth**: Provides domain context the LLM can leverage
* ‚úÖ **Tool Integration**: Tools support the agent's specialized function
* ‚úÖ **Parameter Tuning**: Temperature and settings optimize for role needs

The key is creating agents where every configuration choice reinforces your LLM selection strategy, maximizing performance while optimizing costs.

## Practical Implementation Checklist

Rather than repeating the strategic framework, here's a tactical checklist for implementing your LLM selection decisions in CrewAI:

<Steps>
  <Step title="Audit Your Current Setup" icon="clipboard-check">
    **What to Review:**

    * Are all agents using the same LLM by default?
    * Which agents handle the most complex reasoning tasks?
    * Which agents primarily do data processing or formatting?
    * Are any agents heavily tool-dependent?

    **Action**: Document current agent roles and identify optimization opportunities.
  </Step>

  <Step title="Implement Crew-Level Strategy" icon="users-gear">
    **Set Your Baseline:**

    ```python
    # Start with a reliable default for the crew
    default_crew_llm = LLM(model="gpt-4o-mini")  # Cost-effective baseline

    crew = Crew(
        agents=[...],
        tasks=[...],
        memory=True
    )
    ```

    **Action**: Establish your crew's default LLM before optimizing individual agents.
  </Step>

  <Step title="Optimize High-Impact Agents" icon="star">
    **Identify and Upgrade Key Agents:**

    ```python
    # Manager or coordination agents
    manager_agent = Agent(
        role="Project Manager",
        llm=LLM(model="gemini-2.5-flash-preview-05-20"),  # Premium for coordination
        # ... rest of config
    )

    # Creative or customer-facing agents
    content_agent = Agent(
        role="Content Creator",
        llm=LLM(model="claude-3-5-sonnet"),  # Best for writing
        # ... rest of config
    )
    ```

    **Action**: Upgrade 20% of your agents that handle 80% of the complexity.
  </Step>

  <Step title="Validate with Enterprise Testing" icon="test-tube">
    **Once you deploy your agents to production:**

    * Use [CrewAI Enterprise platform](https://app.crewai.com) to A/B test your model selections
    * Run multiple iterations with real inputs to measure consistency and performance
    * Compare cost vs. performance across your optimized setup
    * Share results with your team for collaborative decision-making

    **Action**: Replace guesswork with data-driven validation using the testing platform.
  </Step>
</Steps>

### When to Use Different Model Types

<Tabs>
  <Tab title="Reasoning Models">
    Reasoning models become essential when tasks require genuine multi-step logical thinking, strategic planning, or high-level decision making that benefits from systematic analysis. These models excel when problems need to be broken down into components and analyzed systematically rather than handled through pattern matching or simple instruction following.

    Consider reasoning models for business strategy development, complex data analysis that requires drawing insights from multiple sources, multi-step problem solving where each step depends on previous analysis, and strategic planning tasks that require considering multiple variables and their interactions.

    However, reasoning models often come with higher costs and slower response times, so they're best reserved for tasks where their sophisticated capabilities provide genuine value rather than being used for simple operations that don't require complex reasoning.
  </Tab>

  <Tab title="Creative Models">
    Creative models become valuable when content generation is the primary output and the quality, style, and engagement level of that content directly impact success. These models excel when writing quality and style matter significantly, creative ideation or brainstorming is needed, or brand voice and tone are important considerations.

    Use creative models for blog post writing and article creation, marketing copy that needs to engage and persuade, creative storytelling and narrative development, and brand communications where voice and tone are crucial. These models often understand nuance and context better than general purpose alternatives.

    Creative models may be less suitable for technical or analytical tasks where precision and factual accuracy are more important than engagement and style. They're best used when the creative and communicative aspects of the output are primary success factors.
  </Tab>

  <Tab title="Efficient Models">
    Efficient models are ideal for high-frequency, routine operations where speed and cost optimization are priorities. These models work best when tasks have clear, well-defined parameters and don't require sophisticated reasoning or creative capabilities.

    Consider efficient models for data processing and transformation tasks, simple formatting and organization operations, function calling and tool usage where precision matters more than sophistication, and high-volume operations where cost per operation is a significant factor.

    The key with efficient models is ensuring that their capabilities align with task requirements. They can handle many routine operations effectively but may struggle with tasks requiring nuanced understanding, complex reasoning, or sophisticated content generation.
  </Tab>

  <Tab title="Open Source Models">
    Open source models become attractive when budget constraints are significant, data privacy requirements exist, customization needs are important, or local deployment is required for operational or compliance reasons.

    Consider open source models for internal company tools where data privacy is paramount, privacy-sensitive applications that can't use external APIs, cost-optimized deployments where per-token pricing is prohibitive, and situations requiring custom model modifications or fine-tuning.

    However, open source models require more technical expertise to deploy and maintain effectively. Consider the total cost of ownership including infrastructure, technical overhead, and ongoing maintenance when evaluating open source options.
  </Tab>
</Tabs>

## Common CrewAI Model Selection Pitfalls

<AccordionGroup>
  <Accordion title="The 'One Model Fits All' Trap" icon="triangle-exclamation">
    **The Problem**: Using the same LLM for all agents in a crew, regardless of their specific roles and responsibilities. This is often the default approach but rarely optimal.

    **Real Example**: Using GPT-4o for both a strategic planning manager and a data extraction agent. The manager needs reasoning capabilities worth the premium cost, but the data extractor could perform just as well with GPT-4o-mini at a fraction of the price.

    **CrewAI Solution**: Leverage agent-specific LLM configuration to match model capabilities with agent roles:

    ```python
    # Strategic agent gets premium model
    manager = Agent(role="Strategy Manager", llm=LLM(model="gpt-4o"))

    # Processing agent gets efficient model
    processor = Agent(role="Data Processor", llm=LLM(model="gpt-4o-mini"))
    ```
  </Accordion>

  <Accordion title="Ignoring Crew-Level vs Agent-Level LLM Hierarchy" icon="shuffle">
    **The Problem**: Not understanding how CrewAI's LLM hierarchy works - crew LLM, manager LLM, and agent LLM settings can conflict or be poorly coordinated.

    **Real Example**: Setting a crew to use Claude, but having agents configured with GPT models, creating inconsistent behavior and unnecessary model switching overhead.

    **CrewAI Solution**: Plan your LLM hierarchy strategically:

    ```python
    crew = Crew(
        agents=[agent1, agent2],
        tasks=[task1, task2],
        manager_llm=LLM(model="gpt-4o"),  # For crew coordination
        process=Process.hierarchical  # When using manager_llm
    )

    # Agents inherit crew LLM unless specifically overridden
    agent1 = Agent(llm=LLM(model="claude-3-5-sonnet"))  # Override for specific needs
    ```
  </Accordion>

  <Accordion title="Function Calling Model Mismatch" icon="screwdriver-wrench">
    **The Problem**: Choosing models based on general capabilities while ignoring function calling performance for tool-heavy CrewAI workflows.

    **Real Example**: Selecting a creative-focused model for an agent that primarily needs to call APIs, search tools, or process structured data. The agent struggles with tool parameter extraction and reliable function calls.

    **CrewAI Solution**: Prioritize function calling capabilities for tool-heavy agents:

    ```python
    # For agents that use many tools
    tool_agent = Agent(
        role="API Integration Specialist",
        tools=[search_tool, api_tool, data_tool],
        llm=LLM(model="gpt-4o"),  # Excellent function calling
        # OR
        llm=LLM(model="claude-3-5-sonnet")  # Also strong with tools
    )
    ```
  </Accordion>

  <Accordion title="Premature Optimization Without Testing" icon="gear">
    **The Problem**: Making complex model selection decisions based on theoretical performance without validating with actual CrewAI workflows and tasks.

    **Real Example**: Implementing elaborate model switching logic based on task types without testing if the performance gains justify the operational complexity.

    **CrewAI Solution**: Start simple, then optimize based on real performance data:

    ```python
    # Start with this
    crew = Crew(agents=[...], tasks=[...], llm=LLM(model="gpt-4o-mini"))

    # Test performance, then optimize specific agents as needed
    # Use Enterprise platform testing to validate improvements
    ```
  </Accordion>

  <Accordion title="Overlooking Context and Memory Limitations" icon="brain">
    **The Problem**: Not considering how model context windows interact with CrewAI's memory and context sharing between agents.

    **Real Example**: Using a short-context model for agents that need to maintain conversation history across multiple task iterations, or in crews with extensive agent-to-agent communication.

    **CrewAI Solution**: Match context capabilities to crew communication patterns.
  </Accordion>
</AccordionGroup>

## Testing and Iteration Strategy

<Steps>
  <Step title="Start Simple" icon="play">
    Begin with reliable, general-purpose models that are well-understood and widely supported. This provides a stable foundation for understanding your specific requirements and performance expectations before optimizing for specialized needs.
  </Step>

  <Step title="Measure What Matters" icon="chart-line">
    Develop metrics that align with your specific use case and business requirements rather than relying solely on general benchmarks. Focus on measuring outcomes that directly impact your success rather than theoretical performance indicators.
  </Step>

  <Step title="Iterate Based on Results" icon="arrows-rotate">
    Make model changes based on observed performance in your specific context rather than theoretical considerations or general recommendations. Real-world performance often differs significantly from benchmark results or general reputation.
  </Step>

  <Step title="Consider Total Cost" icon="calculator">
    Evaluate the complete cost of ownership including model costs, development time, maintenance overhead, and operational complexity. The cheapest model per token may not be the most cost-effective choice when considering all factors.
  </Step>
</Steps>

<Tip>
  Focus on understanding your requirements first, then select models that best match those needs. The best LLM choice is the one that consistently delivers the results you need within your operational constraints.
</Tip>

### Enterprise-Grade Model Validation

For teams serious about optimizing their LLM selection, the **CrewAI Enterprise platform** provides sophisticated testing capabilities that go far beyond basic CLI testing. The platform enables comprehensive model evaluation that helps you make data-driven decisions about your LLM strategy.

<Frame>
  ![Enterprise Testing Interface](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/enterprise-testing.png)
</Frame>

**Advanced Testing Features:**

* **Multi-Model Comparison**: Test multiple LLMs simultaneously across the same tasks and inputs. Compare performance between GPT-4o, Claude, Llama, Groq, Cerebras, and other leading models in parallel to identify the best fit for your specific use case.

* **Statistical Rigor**: Configure multiple iterations with consistent inputs to measure reliability and performance variance. This helps identify models that not only perform well but do so consistently across runs.

* **Real-World Validation**: Use your actual crew inputs and scenarios rather than synthetic benchmarks. The platform allows you to test with your specific industry context, company information, and real use cases for more accurate evaluation.

* **Comprehensive Analytics**: Access detailed performance metrics, execution times, and cost analysis across all tested models. This enables data-driven decision making rather than relying on general model reputation or theoretical capabilities.

* **Team Collaboration**: Share testing results and model performance data across your team, enabling collaborative decision-making and consistent model selection strategies across projects.

Go to [app.crewai.com](https://app.crewai.com) to get started!

<Info>
  The Enterprise platform transforms model selection from guesswork into a data-driven process, enabling you to validate the principles in this guide with your actual use cases and requirements.
</Info>

## Key Principles Summary

<CardGroup cols={2}>
  <Card title="Task-Driven Selection" icon="bullseye">
    Choose models based on what the task actually requires, not theoretical capabilities or general reputation.
  </Card>

  <Card title="Capability Matching" icon="puzzle-piece">
    Align model strengths with agent roles and responsibilities for optimal performance.
  </Card>

  <Card title="Strategic Consistency" icon="link">
    Maintain coherent model selection strategy across related components and workflows.
  </Card>

  <Card title="Practical Testing" icon="flask">
    Validate choices through real-world usage rather than benchmarks alone.
  </Card>

  <Card title="Iterative Improvement" icon="arrow-up">
    Start simple and optimize based on actual performance and needs.
  </Card>

  <Card title="Operational Balance" icon="scale-balanced">
    Balance performance requirements with cost and complexity constraints.
  </Card>
</CardGroup>

<Check>
  Remember: The best LLM choice is the one that consistently delivers the results you need within your operational constraints. Focus on understanding your requirements first, then select models that best match those needs.
</Check>

## Current Model Landscape (June 2025)

<Warning>
  **Snapshot in Time**: The following model rankings represent current leaderboard standings as of June 2025, compiled from [LMSys Arena](https://arena.lmsys.org/), [Artificial Analysis](https://artificialanalysis.ai/), and other leading benchmarks. LLM performance, availability, and pricing change rapidly. Always conduct your own evaluations with your specific use cases and data.
</Warning>

### Leading Models by Category

The tables below show a representative sample of current top-performing models across different categories, with guidance on their suitability for CrewAI agents:

<Note>
  These tables/metrics showcase selected leading models in each category and are not exhaustive. Many excellent models exist beyond those listed here. The goal is to illustrate the types of capabilities to look for rather than provide a complete catalog.
</Note>

<Tabs>
  <Tab title="Reasoning & Planning">
    **Best for Manager LLMs and Complex Analysis**

    | Model                      | Intelligence Score | Cost (\$/M tokens) | Speed    | Best Use in CrewAI                                  |
    | :------------------------- | :----------------- | :----------------- | :------- | :-------------------------------------------------- |
    | **o3**                     | 70                 | \$17.50            | Fast     | Manager LLM for complex multi-agent coordination    |
    | **Gemini 2.5 Pro**         | 69                 | \$3.44             | Fast     | Strategic planning agents, research coordination    |
    | **DeepSeek R1**            | 68                 | \$0.96             | Moderate | Cost-effective reasoning for budget-conscious crews |
    | **Claude 4 Sonnet**        | 53                 | \$6.00             | Fast     | Analysis agents requiring nuanced understanding     |
    | **Qwen3 235B (Reasoning)** | 62                 | \$2.63             | Moderate | Open-source alternative for reasoning tasks         |

    These models excel at multi-step reasoning and are ideal for agents that need to develop strategies, coordinate other agents, or analyze complex information.
  </Tab>

  <Tab title="Coding & Technical">
    **Best for Development and Tool-Heavy Workflows**

    | Model                 | Coding Performance | Tool Use Score | Cost (\$/M tokens) | Best Use in CrewAI                            |
    | :-------------------- | :----------------- | :------------- | :----------------- | :-------------------------------------------- |
    | **Claude 4 Sonnet**   | Excellent          | 72.7%          | \$6.00             | Primary coding agent, technical documentation |
    | **Claude 4 Opus**     | Excellent          | 72.5%          | \$30.00            | Complex software architecture, code review    |
    | **DeepSeek V3**       | Very Good          | High           | \$0.48             | Cost-effective coding for routine development |
    | **Qwen2.5 Coder 32B** | Very Good          | Medium         | \$0.15             | Budget-friendly coding agent                  |
    | **Llama 3.1 405B**    | Good               | 81.1%          | \$3.50             | Function calling LLM for tool-heavy workflows |

    These models are optimized for code generation, debugging, and technical problem-solving, making them ideal for development-focused crews.
  </Tab>

  <Tab title="Speed & Efficiency">
    **Best for High-Throughput and Real-Time Applications**

    | Model                   | Speed (tokens/s) | Latency (TTFT) | Cost (\$/M tokens) | Best Use in CrewAI                   |
    | :---------------------- | :--------------- | :------------- | :----------------- | :----------------------------------- |
    | **Llama 4 Scout**       | 2,600            | 0.33s          | \$0.27             | High-volume processing agents        |
    | **Gemini 2.5 Flash**    | 376              | 0.30s          | \$0.26             | Real-time response agents            |
    | **DeepSeek R1 Distill** | 383              | Variable       | \$0.04             | Cost-optimized high-speed processing |
    | **Llama 3.3 70B**       | 2,500            | 0.52s          | \$0.60             | Balanced speed and capability        |
    | **Nova Micro**          | High             | 0.30s          | \$0.04             | Simple, fast task execution          |

    These models prioritize speed and efficiency, perfect for agents handling routine operations or requiring quick responses. **Pro tip**: Pairing these models with fast inference providers like Groq can achieve even better performance, especially for open-source models like Llama.
  </Tab>

  <Tab title="Balanced Performance">
    **Best All-Around Models for General Crews**

    | Model                 | Overall Score | Versatility | Cost (\$/M tokens) | Best Use in CrewAI                |
    | :-------------------- | :------------ | :---------- | :----------------- | :-------------------------------- |
    | **GPT-4.1**           | 53            | Excellent   | \$3.50             | General-purpose crew LLM          |
    | **Claude 3.7 Sonnet** | 48            | Very Good   | \$6.00             | Balanced reasoning and creativity |
    | **Gemini 2.0 Flash**  | 48            | Good        | \$0.17             | Cost-effective general use        |
    | **Llama 4 Maverick**  | 51            | Good        | \$0.37             | Open-source general purpose       |
    | **Qwen3 32B**         | 44            | Good        | \$1.23             | Budget-friendly versatility       |

    These models offer good performance across multiple dimensions, suitable for crews with diverse task requirements.
  </Tab>
</Tabs>

### Selection Framework for Current Models

<AccordionGroup>
  <Accordion title="High-Performance Crews" icon="rocket">
    **When performance is the priority**: Use top-tier models like **o3**, **Gemini 2.5 Pro**, or **Claude 4 Sonnet** for manager LLMs and critical agents. These models excel at complex reasoning and coordination but come with higher costs.

    **Strategy**: Implement a multi-model approach where premium models handle strategic thinking while efficient models handle routine operations.
  </Accordion>

  <Accordion title="Cost-Conscious Crews" icon="dollar-sign">
    **When budget is a primary constraint**: Focus on models like **DeepSeek R1**, **Llama 4 Scout**, or **Gemini 2.0 Flash**. These provide strong performance at significantly lower costs.

    **Strategy**: Use cost-effective models for most agents, reserving premium models only for the most critical decision-making roles.
  </Accordion>

  <Accordion title="Specialized Workflows" icon="screwdriver-wrench">
    **For specific domain expertise**: Choose models optimized for your primary use case. **Claude 4** series for coding, **Gemini 2.5 Pro** for research, **Llama 405B** for function calling.

    **Strategy**: Select models based on your crew's primary function, ensuring the core capability aligns with model strengths.
  </Accordion>

  <Accordion title="Enterprise & Privacy" icon="shield">
    **For data-sensitive operations**: Consider open-source models like **Llama 4** series, **DeepSeek V3**, or **Qwen3** that can be deployed locally while maintaining competitive performance.

    **Strategy**: Deploy open-source models on private infrastructure, accepting potential performance trade-offs for data control.
  </Accordion>
</AccordionGroup>

### Key Considerations for Model Selection

* **Performance Trends**: The current landscape shows strong competition between reasoning-focused models (o3, Gemini 2.5 Pro) and balanced models (Claude 4, GPT-4.1). Specialized models like DeepSeek R1 offer excellent cost-performance ratios.

* **Speed vs. Intelligence Trade-offs**: Models like Llama 4 Scout prioritize speed (2,600 tokens/s) while maintaining reasonable intelligence, whereas models like o3 maximize reasoning capability at the cost of speed and price.

* **Open Source Viability**: The gap between open-source and proprietary models continues to narrow, with models like Llama 4 Maverick and DeepSeek V3 offering competitive performance at attractive price points. Fast inference providers particularly shine with open-source models, often delivering better speed-to-cost ratios than proprietary alternatives.

<Info>
  **Testing is Essential**: Leaderboard rankings provide general guidance, but your specific use case, prompting style, and evaluation criteria may produce different results. Always test candidate models with your actual tasks and data before making final decisions.
</Info>

### Practical Implementation Strategy

<Steps>
  <Step title="Start with Proven Models">
    Begin with well-established models like **GPT-4.1**, **Claude 3.7 Sonnet**, or **Gemini 2.0 Flash** that offer good performance across multiple dimensions and have extensive real-world validation.
  </Step>

  <Step title="Identify Specialized Needs">
    Determine if your crew has specific requirements (coding, reasoning, speed) that would benefit from specialized models like **Claude 4 Sonnet** for development or **o3** for complex analysis. For speed-critical applications, consider fast inference providers like **Groq** alongside model selection.
  </Step>

  <Step title="Implement Multi-Model Strategy">
    Use different models for different agents based on their roles. High-capability models for managers and complex tasks, efficient models for routine operations.
  </Step>

  <Step title="Monitor and Optimize">
    Track performance metrics relevant to your use case and be prepared to adjust model selections as new models are released or pricing changes.
  </Step>
</Steps>


# Using Multimodal Agents
Source: https://docs.crewai.com/en/learn/multimodal-agents

Learn how to enable and use multimodal capabilities in your agents for processing images and other non-text content within the CrewAI framework.

## Using Multimodal Agents

CrewAI supports multimodal agents that can process both text and non-text content like images. This guide will show you how to enable and use multimodal capabilities in your agents.

### Enabling Multimodal Capabilities

To create a multimodal agent, simply set the `multimodal` parameter to `True` when initializing your agent:

```python
from crewai import Agent

agent = Agent(
    role="Image Analyst",
    goal="Analyze and extract insights from images",
    backstory="An expert in visual content interpretation with years of experience in image analysis",
    multimodal=True  # This enables multimodal capabilities
)
```

When you set `multimodal=True`, the agent is automatically configured with the necessary tools for handling non-text content, including the `AddImageTool`.

### Working with Images

The multimodal agent comes pre-configured with the `AddImageTool`, which allows it to process images. You don't need to manually add this tool - it's automatically included when you enable multimodal capabilities.

Here's a complete example showing how to use a multimodal agent to analyze an image:

```python
from crewai import Agent, Task, Crew

# Create a multimodal agent
image_analyst = Agent(
    role="Product Analyst",
    goal="Analyze product images and provide detailed descriptions",
    backstory="Expert in visual product analysis with deep knowledge of design and features",
    multimodal=True
)

# Create a task for image analysis
task = Task(
    description="Analyze the product image at https://example.com/product.jpg and provide a detailed description",
    expected_output="A detailed description of the product image",
    agent=image_analyst
)

# Create and run the crew
crew = Crew(
    agents=[image_analyst],
    tasks=[task]
)

result = crew.kickoff()
```

### Advanced Usage with Context

You can provide additional context or specific questions about the image when creating tasks for multimodal agents. The task description can include specific aspects you want the agent to focus on:

```python
from crewai import Agent, Task, Crew

# Create a multimodal agent for detailed analysis
expert_analyst = Agent(
    role="Visual Quality Inspector",
    goal="Perform detailed quality analysis of product images",
    backstory="Senior quality control expert with expertise in visual inspection",
    multimodal=True  # AddImageTool is automatically included
)

# Create a task with specific analysis requirements
inspection_task = Task(
    description="""
    Analyze the product image at https://example.com/product.jpg with focus on:
    1. Quality of materials
    2. Manufacturing defects
    3. Compliance with standards
    Provide a detailed report highlighting any issues found.
    """,
    expected_output="A detailed report highlighting any issues found",
    agent=expert_analyst
)

# Create and run the crew
crew = Crew(
    agents=[expert_analyst],
    tasks=[inspection_task]
)

result = crew.kickoff()
```

### Tool Details

When working with multimodal agents, the `AddImageTool` is automatically configured with the following schema:

```python
class AddImageToolSchema:
    image_url: str  # Required: The URL or path of the image to process
    action: Optional[str] = None  # Optional: Additional context or specific questions about the image
```

The multimodal agent will automatically handle the image processing through its built-in tools, allowing it to:

* Access images via URLs or local file paths
* Process image content with optional context or specific questions
* Provide analysis and insights based on the visual information and task requirements

### Best Practices

When working with multimodal agents, keep these best practices in mind:

1. **Image Access**
   * Ensure your images are accessible via URLs that the agent can reach
   * For local images, consider hosting them temporarily or using absolute file paths
   * Verify that image URLs are valid and accessible before running tasks

2. **Task Description**
   * Be specific about what aspects of the image you want the agent to analyze
   * Include clear questions or requirements in the task description
   * Consider using the optional `action` parameter for focused analysis

3. **Resource Management**
   * Image processing may require more computational resources than text-only tasks
   * Some language models may require base64 encoding for image data
   * Consider batch processing for multiple images to optimize performance

4. **Environment Setup**
   * Verify that your environment has the necessary dependencies for image processing
   * Ensure your language model supports multimodal capabilities
   * Test with small images first to validate your setup

5. **Error Handling**
   * Implement proper error handling for image loading failures
   * Have fallback strategies for when image processing fails
   * Monitor and log image processing operations for debugging


# Overview
Source: https://docs.crewai.com/en/learn/overview

Learn how to build, customize, and optimize your CrewAI applications with comprehensive guides and tutorials

## Learn CrewAI

This section provides comprehensive guides and tutorials to help you master CrewAI, from basic concepts to advanced techniques. Whether you're just getting started or looking to optimize your existing implementations, these resources will guide you through every aspect of building powerful AI agent workflows.

## Getting Started Guides

### Core Concepts

<CardGroup cols={2}>
  <Card title="Sequential Process" icon="list-ol" href="/en/learn/sequential-process">
    Learn how to execute tasks in a sequential order for structured workflows.
  </Card>

  <Card title="Hierarchical Process" icon="sitemap" href="/en/learn/hierarchical-process">
    Implement hierarchical task execution with manager agents overseeing workflows.
  </Card>

  <Card title="Conditional Tasks" icon="code-branch" href="/en/learn/conditional-tasks">
    Create dynamic workflows with conditional task execution based on outcomes.
  </Card>

  <Card title="Async Kickoff" icon="bolt" href="/en/learn/kickoff-async">
    Execute crews asynchronously for improved performance and concurrency.
  </Card>
</CardGroup>

### Agent Development

<CardGroup cols={2}>
  <Card title="Customizing Agents" icon="user-gear" href="/en/learn/customizing-agents">
    Learn how to customize agent behavior, roles, and capabilities.
  </Card>

  <Card title="Coding Agents" icon="code" href="/en/learn/coding-agents">
    Build agents that can write, execute, and debug code automatically.
  </Card>

  <Card title="Multimodal Agents" icon="images" href="/en/learn/multimodal-agents">
    Create agents that can process text, images, and other media types.
  </Card>

  <Card title="Custom Manager Agent" icon="user-tie" href="/en/learn/custom-manager-agent">
    Implement custom manager agents for complex hierarchical workflows.
  </Card>
</CardGroup>

## Advanced Features

### Workflow Control

<CardGroup cols={2}>
  <Card title="Human in the Loop" icon="user-check" href="/en/learn/human-in-the-loop">
    Integrate human oversight and intervention into agent workflows.
  </Card>

  <Card title="Human Input on Execution" icon="hand-paper" href="/en/learn/human-input-on-execution">
    Allow human input during task execution for dynamic decision making.
  </Card>

  <Card title="Replay Tasks" icon="rotate-left" href="/en/learn/replay-tasks-from-latest-crew-kickoff">
    Replay and resume tasks from previous crew executions.
  </Card>

  <Card title="Kickoff for Each" icon="repeat" href="/en/learn/kickoff-for-each">
    Execute crews multiple times with different inputs efficiently.
  </Card>
</CardGroup>

### Customization & Integration

<CardGroup cols={2}>
  <Card title="Custom LLM" icon="brain" href="/en/learn/custom-llm">
    Integrate custom language models and providers with CrewAI.
  </Card>

  <Card title="LLM Connections" icon="link" href="/en/learn/llm-connections">
    Configure and manage connections to various LLM providers.
  </Card>

  <Card title="Create Custom Tools" icon="wrench" href="/en/learn/create-custom-tools">
    Build custom tools to extend agent capabilities.
  </Card>

  <Card title="Using Annotations" icon="at" href="/en/learn/using-annotations">
    Use Python annotations for cleaner, more maintainable code.
  </Card>
</CardGroup>

## Specialized Applications

### Content & Media

<CardGroup cols={2}>
  <Card title="DALL-E Image Generation" icon="image" href="/en/learn/dalle-image-generation">
    Generate images using DALL-E integration with your agents.
  </Card>

  <Card title="Bring Your Own Agent" icon="user-plus" href="/en/learn/bring-your-own-agent">
    Integrate existing agents and models into CrewAI workflows.
  </Card>
</CardGroup>

### Tool Management

<CardGroup cols={2}>
  <Card title="Force Tool Output as Result" icon="hammer" href="/en/learn/force-tool-output-as-result">
    Configure tools to return their output directly as task results.
  </Card>
</CardGroup>

## Learning Path Recommendations

### For Beginners

1. Start with **Sequential Process** to understand basic workflow execution
2. Learn **Customizing Agents** to create effective agent configurations
3. Explore **Create Custom Tools** to extend functionality
4. Try **Human in the Loop** for interactive workflows

### For Intermediate Users

1. Master **Hierarchical Process** for complex multi-agent systems
2. Implement **Conditional Tasks** for dynamic workflows
3. Use **Async Kickoff** for performance optimization
4. Integrate **Custom LLM** for specialized models

### For Advanced Users

1. Build **Multimodal Agents** for complex media processing
2. Create **Custom Manager Agents** for sophisticated orchestration
3. Implement **Bring Your Own Agent** for hybrid systems
4. Use **Replay Tasks** for robust error recovery

## Best Practices

### Development

* **Start Simple**: Begin with basic sequential workflows before adding complexity
* **Test Incrementally**: Test each component before integrating into larger systems
* **Use Annotations**: Leverage Python annotations for cleaner, more maintainable code
* **Custom Tools**: Build reusable tools that can be shared across different agents

### Production

* **Error Handling**: Implement robust error handling and recovery mechanisms
* **Performance**: Use async execution and optimize LLM calls for better performance
* **Monitoring**: Integrate observability tools to track agent performance
* **Human Oversight**: Include human checkpoints for critical decisions

### Optimization

* **Resource Management**: Monitor and optimize token usage and API costs
* **Workflow Design**: Design workflows that minimize unnecessary LLM calls
* **Tool Efficiency**: Create efficient tools that provide maximum value with minimal overhead
* **Iterative Improvement**: Use feedback and metrics to continuously improve agent performance

## Getting Help

* **Documentation**: Each guide includes detailed examples and explanations
* **Community**: Join the [CrewAI Forum](https://community.crewai.com) for discussions and support
* **Examples**: Check the Examples section for complete working implementations
* **Support**: Contact [support@crewai.com](mailto:support@crewai.com) for technical assistance

Start with the guides that match your current needs and gradually explore more advanced topics as you become comfortable with the fundamentals.


# Replay Tasks from Latest Crew Kickoff
Source: https://docs.crewai.com/en/learn/replay-tasks-from-latest-crew-kickoff

Replay tasks from the latest crew.kickoff(...)

## Introduction

CrewAI provides the ability to replay from a task specified from the latest crew kickoff. This feature is particularly useful when you've finished a kickoff and may want to retry certain tasks or don't need to refetch data over and your agents already have the context saved from the kickoff execution so you just need to replay the tasks you want to.

<Note>
  You must run `crew.kickoff()` before you can replay a task.
  Currently, only the latest kickoff is supported, so if you use `kickoff_for_each`, it will only allow you to replay from the most recent crew run.
</Note>

Here's an example of how to replay from a task:

### Replaying from Specific Task Using the CLI

To use the replay feature, follow these steps:

<Steps>
  <Step title="Open your terminal or command prompt." />

  <Step title="Navigate to the directory where your CrewAI project is located." />

  <Step title="Run the following commands:">
    To view the latest kickoff task\_ids use:

    ```shell
    crewai log-tasks-outputs
    ```

    Once you have your `task_id` to replay, use:

    ```shell
    crewai replay -t <task_id>
    ```
  </Step>
</Steps>

<Note>
  Ensure `crewai` is installed and configured correctly in your development environment.
</Note>

### Replaying from a Task Programmatically

To replay from a task programmatically, use the following steps:

<Steps>
  <Step title="Specify the `task_id` and input parameters for the replay process.">
    Specify the `task_id` and input parameters for the replay process.
  </Step>

  <Step title="Execute the replay command within a try-except block to handle potential errors.">
    Execute the replay command within a try-except block to handle potential errors.

    <CodeGroup>
      ```python Code
        def replay():
        """
        Replay the crew execution from a specific task.
        """
        task_id = '<task_id>'
        inputs = {"topic": "CrewAI Training"}  # This is optional; you can pass in the inputs you want to replay; otherwise, it uses the previous kickoff's inputs.
        try:
            YourCrewName_Crew().crew().replay(task_id=task_id, inputs=inputs)

        except subprocess.CalledProcessError as e:
            raise Exception(f"An error occurred while replaying the crew: {e}")

        except Exception as e:
            raise Exception(f"An unexpected error occurred: {e}")
      ```
    </CodeGroup>
  </Step>
</Steps>

## Conclusion

With the above enhancements and detailed functionality, replaying specific tasks in CrewAI has been made more efficient and robust.
Ensure you follow the commands and steps precisely to make the most of these features.


# Sequential Processes
Source: https://docs.crewai.com/en/learn/sequential-process

A comprehensive guide to utilizing the sequential processes for task execution in CrewAI projects.

## Introduction

CrewAI offers a flexible framework for executing tasks in a structured manner, supporting both sequential and hierarchical processes.
This guide outlines how to effectively implement these processes to ensure efficient task execution and project completion.

## Sequential Process Overview

The sequential process ensures tasks are executed one after the other, following a linear progression.
This approach is ideal for projects requiring tasks to be completed in a specific order.

### Key Features

* **Linear Task Flow**: Ensures orderly progression by handling tasks in a predetermined sequence.
* **Simplicity**: Best suited for projects with clear, step-by-step tasks.
* **Easy Monitoring**: Facilitates easy tracking of task completion and project progress.

## Implementing the Sequential Process

To use the sequential process, assemble your crew and define tasks in the order they need to be executed.

```python Code
from crewai import Crew, Process, Agent, Task, TaskOutput, CrewOutput

# Define your agents
researcher = Agent(
  role='Researcher',
  goal='Conduct foundational research',
  backstory='An experienced researcher with a passion for uncovering insights'
)
analyst = Agent(
  role='Data Analyst',
  goal='Analyze research findings',
  backstory='A meticulous analyst with a knack for uncovering patterns'
)
writer = Agent(
  role='Writer',
  goal='Draft the final report',
  backstory='A skilled writer with a talent for crafting compelling narratives'
)

# Define your tasks
research_task = Task(
  description='Gather relevant data...',
  agent=researcher,
  expected_output='Raw Data'
)
analysis_task = Task(
  description='Analyze the data...',
  agent=analyst,
  expected_output='Data Insights'
)
writing_task = Task(
  description='Compose the report...',
  agent=writer,
  expected_output='Final Report'
)

# Form the crew with a sequential process
report_crew = Crew(
  agents=[researcher, analyst, writer],
  tasks=[research_task, analysis_task, writing_task],
  process=Process.sequential
)

# Execute the crew
result = report_crew.kickoff()

# Accessing the type-safe output
task_output: TaskOutput = result.tasks[0].output
crew_output: CrewOutput = result.output
```

### Note:

Each task in a sequential process **must** have an agent assigned. Ensure that every `Task` includes an `agent` parameter.

### Workflow in Action

1. **Initial Task**: In a sequential process, the first agent completes their task and signals completion.
2. **Subsequent Tasks**: Agents pick up their tasks based on the process type, with outcomes of preceding tasks or directives guiding their execution.
3. **Completion**: The process concludes once the final task is executed, leading to project completion.

## Advanced Features

### Task Delegation

In sequential processes, if an agent has `allow_delegation` set to `True`, they can delegate tasks to other agents in the crew.
This feature is automatically set up when there are multiple agents in the crew.

### Asynchronous Execution

Tasks can be executed asynchronously, allowing for parallel processing when appropriate.
To create an asynchronous task, set `async_execution=True` when defining the task.

### Memory and Caching

CrewAI supports both memory and caching features:

* **Memory**: Enable by setting `memory=True` when creating the Crew. This allows agents to retain information across tasks.
* **Caching**: By default, caching is enabled. Set `cache=False` to disable it.

### Callbacks

You can set callbacks at both the task and step level:

* `task_callback`: Executed after each task completion.
* `step_callback`: Executed after each step in an agent's execution.

### Usage Metrics

CrewAI tracks token usage across all tasks and agents. You can access these metrics after execution.

## Best Practices for Sequential Processes

1. **Order Matters**: Arrange tasks in a logical sequence where each task builds upon the previous one.
2. **Clear Task Descriptions**: Provide detailed descriptions for each task to guide the agents effectively.
3. **Appropriate Agent Selection**: Match agents' skills and roles to the requirements of each task.
4. **Use Context**: Leverage the context from previous tasks to inform subsequent ones.

This updated documentation ensures that details accurately reflect the latest changes in the codebase and clearly describes how to leverage new features and configurations.
The content is kept simple and direct to ensure easy understanding.


# Using Annotations in crew.py
Source: https://docs.crewai.com/en/learn/using-annotations

Learn how to use annotations to properly structure agents, tasks, and components in CrewAI

This guide explains how to use annotations to properly reference **agents**, **tasks**, and other components in the `crew.py` file.

## Introduction

Annotations in the CrewAI framework are used to decorate classes and methods, providing metadata and functionality to various components of your crew. These annotations help in organizing and structuring your code, making it more readable and maintainable.

## Available Annotations

The CrewAI framework provides the following annotations:

* `@CrewBase`: Used to decorate the main crew class.
* `@agent`: Decorates methods that define and return Agent objects.
* `@task`: Decorates methods that define and return Task objects.
* `@crew`: Decorates the method that creates and returns the Crew object.
* `@llm`: Decorates methods that initialize and return Language Model objects.
* `@tool`: Decorates methods that initialize and return Tool objects.
* `@callback`: Used for defining callback methods.
* `@output_json`: Used for methods that output JSON data.
* `@output_pydantic`: Used for methods that output Pydantic models.
* `@cache_handler`: Used for defining cache handling methods.

## Usage Examples

Let's go through examples of how to use these annotations:

### 1. Crew Base Class

```python
@CrewBase
class LinkedinProfileCrew():
    """LinkedinProfile crew"""
    agents_config = 'config/agents.yaml'
    tasks_config = 'config/tasks.yaml'
```

The `@CrewBase` annotation is used to decorate the main crew class. This class typically contains configurations and methods for creating agents, tasks, and the crew itself.

### 2. Tool Definition

```python
@tool
def myLinkedInProfileTool(self):
    return LinkedInProfileTool()
```

The `@tool` annotation is used to decorate methods that return tool objects. These tools can be used by agents to perform specific tasks.

### 3. LLM Definition

```python
@llm
def groq_llm(self):
    api_key = os.getenv('api_key')
    return ChatGroq(api_key=api_key, temperature=0, model_name="mixtral-8x7b-32768")
```

The `@llm` annotation is used to decorate methods that initialize and return Language Model objects. These LLMs are used by agents for natural language processing tasks.

### 4. Agent Definition

```python
@agent
def researcher(self) -> Agent:
    return Agent(
        config=self.agents_config['researcher']
    )
```

The `@agent` annotation is used to decorate methods that define and return Agent objects.

### 5. Task Definition

```python
@task
def research_task(self) -> Task:
    return Task(
        config=self.tasks_config['research_linkedin_task'],
        agent=self.researcher()
    )
```

The `@task` annotation is used to decorate methods that define and return Task objects. These methods specify the task configuration and the agent responsible for the task.

### 6. Crew Creation

```python
@crew
def crew(self) -> Crew:
    """Creates the LinkedinProfile crew"""
    return Crew(
        agents=self.agents,
        tasks=self.tasks,
        process=Process.sequential,
        verbose=True
    )
```

The `@crew` annotation is used to decorate the method that creates and returns the `Crew` object. This method assembles all the components (agents and tasks) into a functional crew.

## YAML Configuration

The agent configurations are typically stored in a YAML file. Here's an example of how the `agents.yaml` file might look for the researcher agent:

```yaml
researcher:
    role: >
        LinkedIn Profile Senior Data Researcher
    goal: >
        Uncover detailed LinkedIn profiles based on provided name {name} and domain {domain}
        Generate a Dall-E image based on domain {domain}
    backstory: >
        You're a seasoned researcher with a knack for uncovering the most relevant LinkedIn profiles.
        Known for your ability to navigate LinkedIn efficiently, you excel at gathering and presenting
        professional information clearly and concisely.
    allow_delegation: False
    verbose: True
    llm: groq_llm
    tools:
        - myLinkedInProfileTool
        - mySerperDevTool
        - myDallETool
```

This YAML configuration corresponds to the researcher agent defined in the `LinkedinProfileCrew` class. The configuration specifies the agent's role, goal, backstory, and other properties such as the LLM and tools it uses.

Note how the `llm` and `tools` in the YAML file correspond to the methods decorated with `@llm` and `@tool` in the Python class.

## Best Practices

* **Consistent Naming**: Use clear and consistent naming conventions for your methods. For example, agent methods could be named after their roles (e.g., researcher, reporting\_analyst).
* **Environment Variables**: Use environment variables for sensitive information like API keys.
* **Flexibility**: Design your crew to be flexible by allowing easy addition or removal of agents and tasks.
* **YAML-Code Correspondence**: Ensure that the names and structures in your YAML files correspond correctly to the decorated methods in your Python code.

By following these guidelines and properly using annotations, you can create well-structured and maintainable crews using the CrewAI framework.


# Connecting to Multiple MCP Servers
Source: https://docs.crewai.com/en/mcp/multiple-servers

Learn how to use MCPServerAdapter in CrewAI to connect to multiple MCP servers simultaneously and aggregate their tools.

## Overview

`MCPServerAdapter` in `crewai-tools` allows you to connect to multiple MCP servers concurrently. This is useful when your agents need to access tools distributed across different services or environments. The adapter aggregates tools from all specified servers, making them available to your CrewAI agents.

## Configuration

To connect to multiple servers, you provide a list of server parameter dictionaries to `MCPServerAdapter`. Each dictionary in the list should define the parameters for one MCP server.

Supported transport types for each server in the list include `stdio`, `sse`, and `streamable-http`.

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter
from mcp import StdioServerParameters # Needed for Stdio example

# Define parameters for multiple MCP servers
server_params_list = [
    # Streamable HTTP Server
    {
        "url": "http://localhost:8001/mcp",
        "transport": "streamable-http"
    },
    # SSE Server
    {
        "url": "http://localhost:8000/sse",
        "transport": "sse"
    },
    # StdIO Server
    StdioServerParameters(
        command="python3",
        args=["servers/your_stdio_server.py"],
        env={"UV_PYTHON": "3.12", **os.environ},
    )
]

try:
    with MCPServerAdapter(server_params_list) as aggregated_tools:
        print(f"Available aggregated tools: {[tool.name for tool in aggregated_tools]}")

        multi_server_agent = Agent(
            role="Versatile Assistant",
            goal="Utilize tools from local Stdio, remote SSE, and remote HTTP MCP servers.",
            backstory="An AI agent capable of leveraging a diverse set of tools from multiple sources.",
            tools=aggregated_tools, # All tools are available here
            verbose=True,
        )

        ... # Your other agent, tasks, and crew code here

except Exception as e:
    print(f"Error connecting to or using multiple MCP servers (Managed): {e}")
    print("Ensure all MCP servers are running and accessible with correct configurations.")

```

## Connection Management

When using the context manager (`with` statement), `MCPServerAdapter` handles the lifecycle (start and stop) of all connections to the configured MCP servers. This simplifies resource management and ensures that all connections are properly closed when the context is exited.


# MCP Servers as Tools in CrewAI
Source: https://docs.crewai.com/en/mcp/overview

Learn how to integrate MCP servers as tools in your CrewAI agents using the `crewai-tools` library.

## Overview

The [Model Context Protocol](https://modelcontextprotocol.io/introduction) (MCP) provides a standardized way for AI agents to provide context to LLMs by communicating with external services, known as MCP Servers.
The `crewai-tools` library extends CrewAI's capabilities by allowing you to seamlessly integrate tools from these MCP servers into your agents.
This gives your crews access to a vast ecosystem of functionalities.

We currently support the following transport mechanisms:

* **Stdio**: for local servers (communication via standard input/output between processes on the same machine)
* **Server-Sent Events (SSE)**: for remote servers (unidirectional, real-time data streaming from server to client over HTTP)
* **Streamable HTTP**: for remote servers (flexible, potentially bi-directional communication over HTTP, often utilizing SSE for server-to-client streams)

## Video Tutorial

Watch this video tutorial for a comprehensive guide on MCP integration with CrewAI:

<iframe width="100%" height="400" src="https://www.youtube.com/embed/TpQ45lAZh48" title="CrewAI MCP Integration Guide" frameborder="0" style={{ borderRadius: '10px' }} allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

## Installation

Before you start using MCP with `crewai-tools`, you need to install the `mcp` extra `crewai-tools` dependency with the following command:

```shell
uv pip install 'crewai-tools[mcp]'
```

## Key Concepts & Getting Started

The `MCPServerAdapter` class from `crewai-tools` is the primary way to connect to an MCP server and make its tools available to your CrewAI agents. It supports different transport mechanisms and simplifies connection management.

Using a Python context manager (`with` statement) is the **recommended approach** for `MCPServerAdapter`. It automatically handles starting and stopping the connection to the MCP server.

```python
from crewai import Agent
from crewai_tools import MCPServerAdapter
from mcp import StdioServerParameters # For Stdio Server

# Example server_params (choose one based on your server type):
# 1. Stdio Server:
server_params=StdioServerParameters(
    command="python3",
    args=["servers/your_server.py"],
    env={"UV_PYTHON": "3.12", **os.environ},
)

# 2. SSE Server:
server_params = {
    "url": "http://localhost:8000/sse",
    "transport": "sse"
}

# 3. Streamable HTTP Server:
server_params = {
    "url": "http://localhost:8001/mcp",
    "transport": "streamable-http"
}

# Example usage (uncomment and adapt once server_params is set):
with MCPServerAdapter(server_params) as mcp_tools:
    print(f"Available tools: {[tool.name for tool in mcp_tools]}")

    my_agent = Agent(
        role="MCP Tool User",
        goal="Utilize tools from an MCP server.",
        backstory="I can connect to MCP servers and use their tools.",
        tools=mcp_tools, # Pass the loaded tools to your agent
        reasoning=True,
        verbose=True
    )
    # ... rest of your crew setup ...
```

This general pattern shows how to integrate tools. For specific examples tailored to each transport, refer to the detailed guides below.

## Filtering Tools

There are two ways to filter tools:

1. Accessing a specific tool using dictionary-style indexing.
2. Pass a list of tool names to the `MCPServerAdapter` constructor.

### Accessing a specific tool using dictionary-style indexing.

```python
with MCPServerAdapter(server_params) as mcp_tools:
    print(f"Available tools: {[tool.name for tool in mcp_tools]}")

    my_agent = Agent(
        role="MCP Tool User",
        goal="Utilize tools from an MCP server.",
        backstory="I can connect to MCP servers and use their tools.",
        tools=[mcp_tools["tool_name"]], # Pass the loaded tools to your agent
        reasoning=True,
        verbose=True
    )
    # ... rest of your crew setup ...
```

### Pass a list of tool names to the `MCPServerAdapter` constructor.

```python
with MCPServerAdapter(server_params, "tool_name") as mcp_tools:
    print(f"Available tools: {[tool.name for tool in mcp_tools]}")

    my_agent = Agent(
        role="MCP Tool User",
        goal="Utilize tools from an MCP server.",
        backstory="I can connect to MCP servers and use their tools.",
        tools=mcp_tools, # Pass the loaded tools to your agent
        reasoning=True,
        verbose=True
    )
    # ... rest of your crew setup ...
```

## Using with CrewBase

To use MCPServer tools within a CrewBase class, use the `mcp_tools` method. Server configurations should be provided via the mcp\_server\_params attribute. You can pass either a single configuration or a list of multiple server configurations.

```python
@CrewBase
class CrewWithMCP:
  # ... define your agents and tasks config file ...

  mcp_server_params = [
    # Streamable HTTP Server
    {
        "url": "http://localhost:8001/mcp",
        "transport": "streamable-http"
    },
    # SSE Server
    {
        "url": "http://localhost:8000/sse",
        "transport": "sse"
    },
    # StdIO Server
    StdioServerParameters(
        command="python3",
        args=["servers/your_stdio_server.py"],
        env={"UV_PYTHON": "3.12", **os.environ},
    )
  ]

  @agent
  def your_agent(self):
      return Agent(config=self.agents_config["your_agent"], tools=self.get_mcp_tools()) # get all available tools

    # ... rest of your crew setup ...
```

You can filter which tools are available to your agent by passing a list of tool names to the `get_mcp_tools` method.

```python
@agent
def another_agent(self):
    return Agent(
      config=self.agents_config["your_agent"],
      tools=self.get_mcp_tools("tool_1", "tool_2") # get specific tools
    )
```

## Explore MCP Integrations

<CardGroup cols={2}>
  <Card title="Stdio Transport" icon="server" href="/en/mcp/stdio" color="#3B82F6">
    Connect to local MCP servers via standard input/output. Ideal for scripts and local executables.
  </Card>

  <Card title="SSE Transport" icon="wifi" href="/en/mcp/sse" color="#10B981">
    Integrate with remote MCP servers using Server-Sent Events for real-time data streaming.
  </Card>

  <Card title="Streamable HTTP Transport" icon="globe" href="/en/mcp/streamable-http" color="#F59E0B">
    Utilize flexible Streamable HTTP for robust communication with remote MCP servers.
  </Card>

  <Card title="Connecting to Multiple Servers" icon="layer-group" href="/en/mcp/multiple-servers" color="#8B5CF6">
    Aggregate tools from several MCP servers simultaneously using a single adapter.
  </Card>

  <Card title="Security Considerations" icon="lock" href="/en/mcp/security" color="#EF4444">
    Review important security best practices for MCP integration to keep your agents safe.
  </Card>
</CardGroup>

Checkout this repository for full demos and examples of MCP integration with CrewAI! üëá

<Card title="GitHub Repository" icon="github" href="https://github.com/tonykipkemboi/crewai-mcp-demo" target="_blank">
  CrewAI MCP Demo
</Card>

## Staying Safe with MCP

<Warning>
  Always ensure that you trust an MCP Server before using it.
</Warning>

#### Security Warning: DNS Rebinding Attacks

SSE transports can be vulnerable to DNS rebinding attacks if not properly secured.
To prevent this:

1. **Always validate Origin headers** on incoming SSE connections to ensure they come from expected sources
2. **Avoid binding servers to all network interfaces** (0.0.0.0) when running locally - bind only to localhost (127.0.0.1) instead
3. **Implement proper authentication** for all SSE connections

Without these protections, attackers could use DNS rebinding to interact with local MCP servers from remote websites.

For more details, see the [Anthropic's MCP Transport Security docs](https://modelcontextprotocol.io/docs/concepts/transports#security-considerations).

### Limitations

* **Supported Primitives**: Currently, `MCPServerAdapter` primarily supports adapting MCP `tools`.
  Other MCP primitives like `prompts` or `resources` are not directly integrated as CrewAI components through this adapter at this time.
* **Output Handling**: The adapter typically processes the primary text output from an MCP tool (e.g., `.content[0].text`). Complex or multi-modal outputs might require custom handling if not fitting this pattern.


# MCP Security Considerations
Source: https://docs.crewai.com/en/mcp/security

Learn about important security best practices when integrating MCP servers with your CrewAI agents.

## Overview

<Warning>
  The most critical aspect of MCP security is **trust**. You should **only** connect your CrewAI agents to MCP servers that you fully trust.
</Warning>

When integrating external services like MCP (Model Context Protocol) servers into your CrewAI agents, security is paramount.
MCP servers can execute code, access data, or interact with other systems based on the tools they expose.
It's crucial to understand the implications and follow best practices to protect your applications and data.

### Risks

* Execute arbitrary code on the machine where the agent is running (especially with `Stdio` transport if the server can control the command executed).
* Expose sensitive data from your agent or its environment.
* Manipulate your agent's behavior in unintended ways, including making unauthorized API calls on your behalf.
* Hijack your agent's reasoning process through sophisticated prompt injection techniques (see below).

### 1. Trusting MCP Servers

<Warning>
  **Only connect to MCP servers that you trust.**
</Warning>

Before configuring `MCPServerAdapter` to connect to an MCP server, ensure you know:

* **Who operates the server?** Is it a known, reputable service, or an internal server under your control?
* **What tools does it expose?** Understand the capabilities of the tools. Could they be misused if an attacker gained control or if the server itself is malicious?
* **What data does it access or process?** Be aware of any sensitive information that might be sent to or handled by the MCP server.

Avoid connecting to unknown or unverified MCP servers, especially if your agents handle sensitive tasks or data.

### 2. Secure Prompt Injection via Tool Metadata: The "Model Control Protocol" Risk

A significant and subtle risk is the potential for prompt injection through tool metadata. Here's how it works:

1. When your CrewAI agent connects to an MCP server, it typically requests a list of available tools.
2. The MCP server responds with metadata for each tool, including its name, description, and parameter descriptions.
3. Your agent's underlying Language Model (LLM) uses this metadata to understand how and when to use the tools. This metadata is often incorporated into the LLM's system prompt or context.
4. A malicious MCP server can craft its tool metadata (names, descriptions) to include hidden or overt instructions. These instructions can act as a prompt injection, effectively telling your LLM to behave in a certain way, reveal sensitive information, or perform malicious actions.

**Crucially, this attack can occur simply by connecting to a malicious server and listing its tools, even if your agent never explicitly decides to *use* any of those tools.** The mere exposure to the malicious metadata can be enough to compromise the agent's behavior.

**Mitigation:**

* **Extreme Caution with Untrusted Servers:** Reiterate: *Do not connect to MCP servers you do not fully trust.* The risk of metadata injection makes this paramount.

### Stdio Transport Security

Stdio (Standard Input/Output) transport is typically used for local MCP servers running on the same machine as your CrewAI application.

* **Process Isolation**: While generally safer as it doesn't involve network exposure by default, ensure the script or command run by `StdioServerParameters` is from a trusted source and has appropriate file system permissions. A malicious Stdio server script could still harm your local system.
* **Input Sanitization**: If your Stdio server script takes complex inputs derived from agent interactions, ensure the script itself sanitizes these inputs to prevent command injection or other vulnerabilities within the script's logic.
* **Resource Limits**: Be mindful that a local Stdio server process consumes local resources (CPU, memory). Ensure it's well-behaved and won't exhaust system resources.

### Confused Deputy Attacks

The [Confused Deputy Problem](https://en.wikipedia.org/wiki/Confused_deputy_problem) is a classic security vulnerability that can manifest in MCP integrations, especially when an MCP server acts as a proxy to other third-party services (e.g., Google Calendar, GitHub) that use OAuth 2.0 for authorization.

**Scenario:**

1. An MCP server (let's call it `MCP-Proxy`) allows your agent to interact with `ThirdPartyAPI`.
2. `MCP-Proxy` uses its own single, static `client_id` when talking to `ThirdPartyAPI`'s authorization server.
3. You, as the user, legitimately authorize `MCP-Proxy` to access `ThirdPartyAPI` on your behalf. During this, `ThirdPartyAPI`'s auth server might set a cookie in your browser indicating your consent for `MCP-Proxy`'s `client_id`.
4. An attacker crafts a malicious link. This link initiates an OAuth flow with `MCP-Proxy`, but is designed to trick `ThirdPartyAPI`'s auth server.
5. If you click this link, and `ThirdPartyAPI`'s auth server sees your existing consent cookie for `MCP-Proxy`'s `client_id`, it might *skip* asking for your consent again.
6. `MCP-Proxy` might then be tricked into forwarding an authorization code (for `ThirdPartyAPI`) to the attacker, or an MCP authorization code that the attacker can use to impersonate you to `MCP-Proxy`.

**Mitigation (Primarily for MCP Server Developers):**

* MCP proxy servers using static client IDs for downstream services **must** obtain explicit user consent for *each client application or agent* connecting to them *before* initiating an OAuth flow with the third-party service. This means `MCP-Proxy` itself should show a consent screen.

**CrewAI User Implication:**

* Be cautious if an MCP server redirects you for multiple OAuth authentications, especially if it seems unexpected or if the permissions requested are overly broad.
* Prefer MCP servers that clearly delineate their own identity versus the third-party services they might proxy.

### Remote Transport Security (SSE & Streamable HTTP)

When connecting to remote MCP servers via Server-Sent Events (SSE) or Streamable HTTP, standard web security practices are essential.

### SSE Security Considerations

### a. DNS Rebinding Attacks (Especially for SSE)

<Critical>
  **Protect against DNS Rebinding Attacks.**
</Critical>

DNS rebinding allows an attacker-controlled website to bypass the same-origin policy and make requests to servers on the user's local network (e.g., `localhost`) or intranet. This is particularly risky if you run an MCP server locally (e.g., for development) and an agent in a browser-like environment (though less common for typical CrewAI backend setups) or if the MCP server is on an internal network.

**Mitigation Strategies for MCP Server Implementers:**

* **Validate `Origin` and `Host` Headers**: MCP servers (especially SSE ones) should validate the `Origin` and/or `Host` HTTP headers to ensure requests are coming from expected domains/clients.
* **Bind to `localhost` (127.0.0.1)**: When running MCP servers locally for development, bind them to `127.0.0.1` instead of `0.0.0.0`. This prevents them from being accessible from other machines on the network.
* **Authentication**: Require authentication for all connections to your MCP server if it's not intended for public anonymous access.

### b. Use HTTPS

* **Encrypt Data in Transit**: Always use HTTPS (HTTP Secure) for the URLs of remote MCP servers. This encrypts the communication between your CrewAI application and the MCP server, protecting against eavesdropping and man-in-the-middle attacks. `MCPServerAdapter` will respect the scheme (`http` or `https`) provided in the URL.

### c. Token Passthrough (Anti-Pattern)

This is primarily a concern for MCP server developers but understanding it helps in choosing secure servers.

"Token passthrough" is when an MCP server accepts an access token from your CrewAI agent (which might be a token for a *different* service, say `ServiceA`) and simply passes it through to another downstream API (`ServiceB`) without proper validation. Specifically, `ServiceB` (or the MCP server itself) should only accept tokens that were explicitly issued *for them* (i.e., the 'audience' claim in the token matches the server/service).

**Risks:**

* Bypasses security controls (like rate limiting or fine-grained permissions) on the MCP server or the downstream API.
* Breaks audit trails and accountability.
* Allows misuse of stolen tokens.

**Mitigation (For MCP Server Developers):**

* MCP servers **MUST NOT** accept tokens that were not explicitly issued for them. They must validate the token's audience claim.

**CrewAI User Implication:**

* While not directly controllable by the user, this highlights the importance of connecting to well-designed MCP servers that adhere to security best practices.

#### Authentication and Authorization

* **Verify Identity**: If the MCP server provides sensitive tools or access to private data, it MUST implement strong authentication mechanisms to verify the identity of the client (your CrewAI application). This could involve API keys, OAuth tokens, or other standard methods.
* **Principle of Least Privilege**: Ensure the credentials used by `MCPServerAdapter` (if any) have only the necessary permissions to access the required tools.

### d. Input Validation and Sanitization

* **Input Validation is Critical**: MCP servers **must** rigorously validate all inputs received from agents *before* processing them or passing them to tools. This is a primary defense against many common vulnerabilities:
  * **Command Injection:** If a tool constructs shell commands, SQL queries, or other interpreted language statements based on input, the server must meticulously sanitize this input to prevent malicious commands from being injected and executed.
  * **Path Traversal:** If a tool accesses files based on input parameters, the server must validate and sanitize these paths to prevent access to unauthorized files or directories (e.g., by blocking `../` sequences).
  * **Data Type & Range Checks:** Servers must ensure that input data conforms to the expected data types (e.g., string, number, boolean) and falls within acceptable ranges or adheres to defined formats (e.g., regex for URLs).
  * **JSON Schema Validation:** All tool parameters should be strictly validated against their defined JSON schema. This helps catch malformed requests early.
* **Client-Side Awareness**: While server-side validation is paramount, as a CrewAI user, be mindful of the data your agents are constructed to send to MCP tools, especially if interacting with less-trusted or new MCP servers.

### e. Rate Limiting and Resource Management

* **Prevent Abuse**: MCP servers should implement rate limiting to prevent abuse, whether intentional (Denial of Service attacks) or unintentional (e.g., a misconfigured agent making too many requests).
* **Client-Side Retries**: Implement sensible retry logic in your CrewAI tasks if transient network issues or server rate limits are expected, but avoid aggressive retries that could exacerbate server load.

## 4. Secure MCP Server Implementation Advice (For Developers)

If you are developing an MCP server that CrewAI agents might connect to, consider these best practices in addition to the points above:

* **Follow Secure Coding Practices**: Adhere to standard secure coding principles for your chosen language and framework (e.g., OWASP Top 10).
* **Principle of Least Privilege**: Ensure the process running the MCP server (especially for `Stdio`) has only the minimum necessary permissions. Tools themselves should also operate with the least privilege required to perform their function.
* **Dependency Management**: Keep all server-side dependencies, including operating system packages, language runtimes, and third-party libraries, up-to-date to patch known vulnerabilities. Use tools to scan for vulnerable dependencies.
* **Secure Defaults**: Design your server and its tools to be secure by default. For example, features that could be risky should be off by default or require explicit opt-in with clear warnings.
* **Access Control for Tools**: Implement robust mechanisms to control which authenticated and authorized agents or users can access specific tools, especially those that are powerful, sensitive, or incur costs.
* **Secure Error Handling**: Servers should not expose detailed internal error messages, stack traces, or debugging information to the client, as these can reveal internal workings or potential vulnerabilities. Log errors comprehensively on the server-side for diagnostics.
* **Comprehensive Logging and Monitoring**: Implement detailed logging of security-relevant events (e.g., authentication attempts, tool invocations, errors, authorization changes). Monitor these logs for suspicious activity or abuse patterns.
* **Adherence to MCP Authorization Spec**: If implementing authentication and authorization, strictly follow the [MCP Authorization specification](https://modelcontextprotocol.io/specification/draft/basic/authorization) and relevant [OAuth 2.0 security best practices](https://datatracker.ietf.org/doc/html/rfc9700).
* **Regular Security Audits**: If your MCP server handles sensitive data, performs critical operations, or is publicly exposed, consider periodic security audits by qualified professionals.

## 5. Further Reading

For more detailed information on MCP security, refer to the official documentation:

* **[MCP Transport Security](https://modelcontextprotocol.io/docs/concepts/transports#security-considerations)**

By understanding these security considerations and implementing best practices, you can safely leverage the power of MCP servers in your CrewAI projects.
These are by no means exhaustive, but they cover the most common and critical security concerns.
The threats will continue to evolve, so it's important to stay informed and adapt your security measures accordingly.


# SSE Transport
Source: https://docs.crewai.com/en/mcp/sse

Learn how to connect CrewAI to remote MCP servers using Server-Sent Events (SSE) for real-time communication.

## Overview

Server-Sent Events (SSE) provide a standard way for a web server to send updates to a client over a single, long-lived HTTP connection. In the context of MCP, SSE is used for remote servers to stream data (like tool responses) to your CrewAI application in real-time.

## Key Concepts

* **Remote Servers**: SSE is suitable for MCP servers hosted remotely.
* **Unidirectional Stream**: Typically, SSE is a one-way communication channel from server to client.
* **`MCPServerAdapter` Configuration**: For SSE, you'll provide the server's URL and specify the transport type.

## Connecting via SSE

You can connect to an SSE-based MCP server using two main approaches for managing the connection lifecycle:

### 1. Fully Managed Connection (Recommended)

Using a Python context manager (`with` statement) is the recommended approach. It automatically handles establishing and closing the connection to the SSE MCP server.

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter

server_params = {
    "url": "http://localhost:8000/sse", # Replace with your actual SSE server URL
    "transport": "sse"
}

# Using MCPServerAdapter with a context manager
try:
    with MCPServerAdapter(server_params) as tools:
        print(f"Available tools from SSE MCP server: {[tool.name for tool in tools]}")

        # Example: Using a tool from the SSE MCP server
        sse_agent = Agent(
            role="Remote Service User",
            goal="Utilize a tool provided by a remote SSE MCP server.",
            backstory="An AI agent that connects to external services via SSE.",
            tools=tools,
            reasoning=True,
            verbose=True,
        )

        sse_task = Task(
            description="Fetch real-time stock updates for 'AAPL' using an SSE tool.",
            expected_output="The latest stock price for AAPL.",
            agent=sse_agent,
            markdown=True
        )

        sse_crew = Crew(
            agents=[sse_agent],
            tasks=[sse_task],
            verbose=True,
            process=Process.sequential
        )

        if tools: # Only kickoff if tools were loaded
            result = sse_crew.kickoff() # Add inputs={'stock_symbol': 'AAPL'} if tool requires it
            print("\nCrew Task Result (SSE - Managed):\n", result)
        else:
            print("Skipping crew kickoff as tools were not loaded (check server connection).")

except Exception as e:
    print(f"Error connecting to or using SSE MCP server (Managed): {e}")
    print("Ensure the SSE MCP server is running and accessible at the specified URL.")

```

<Note>
  Replace `"http://localhost:8000/sse"` with the actual URL of your SSE MCP server.
</Note>

### 2. Manual Connection Lifecycle

If you need finer-grained control, you can manage the `MCPServerAdapter` connection lifecycle manually.

<Info>
  You **MUST** call `mcp_server_adapter.stop()` to ensure the connection is closed and resources are released. Using a `try...finally` block is highly recommended.
</Info>

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter

server_params = {
    "url": "http://localhost:8000/sse", # Replace with your actual SSE server URL
    "transport": "sse"
}

mcp_server_adapter = None
try:
    mcp_server_adapter = MCPServerAdapter(server_params)
    mcp_server_adapter.start()
    tools = mcp_server_adapter.tools
    print(f"Available tools (manual SSE): {[tool.name for tool in tools]}")

    manual_sse_agent = Agent(
        role="Remote Data Analyst",
        goal="Analyze data fetched from a remote SSE MCP server using manual connection management.",
        backstory="An AI skilled in handling SSE connections explicitly.",
        tools=tools,
        verbose=True
    )

    analysis_task = Task(
        description="Fetch and analyze the latest user activity trends from the SSE server.",
        expected_output="A summary report of user activity trends.",
        agent=manual_sse_agent
    )

    analysis_crew = Crew(
        agents=[manual_sse_agent],
        tasks=[analysis_task],
        verbose=True,
        process=Process.sequential
    )

    result = analysis_crew.kickoff()
    print("\nCrew Task Result (SSE - Manual):\n", result)

except Exception as e:
    print(f"An error occurred during manual SSE MCP integration: {e}")
    print("Ensure the SSE MCP server is running and accessible.")
finally:
    if mcp_server_adapter and mcp_server_adapter.is_connected:
        print("Stopping SSE MCP server connection (manual)...")
        mcp_server_adapter.stop()  # **Crucial: Ensure stop is called**
    elif mcp_server_adapter:
        print("SSE MCP server adapter was not connected. No stop needed or start failed.")

```

## Security Considerations for SSE

<Warning>
  **DNS Rebinding Attacks**: SSE transports can be vulnerable to DNS rebinding attacks if the MCP server is not properly secured. This could allow malicious websites to interact with local or intranet-based MCP servers.
</Warning>

To mitigate this risk:

* MCP server implementations should **validate `Origin` headers** on incoming SSE connections.
* When running local SSE MCP servers for development, **bind only to `localhost` (`127.0.0.1`)** rather than all network interfaces (`0.0.0.0`).
* Implement **proper authentication** for all SSE connections if they expose sensitive tools or data.

For a comprehensive overview of security best practices, please refer to our [Security Considerations](./security.mdx) page and the official [MCP Transport Security documentation](https://modelcontextprotocol.io/docs/concepts/transports#security-considerations).


# Stdio Transport
Source: https://docs.crewai.com/en/mcp/stdio

Learn how to connect CrewAI to local MCP servers using the Stdio (Standard Input/Output) transport mechanism.

## Overview

The Stdio (Standard Input/Output) transport is designed for connecting `MCPServerAdapter` to local MCP servers that communicate over their standard input and output streams. This is typically used when the MCP server is a script or executable running on the same machine as your CrewAI application.

## Key Concepts

* **Local Execution**: Stdio transport manages a locally running process for the MCP server.
* **`StdioServerParameters`**: This class from the `mcp` library is used to configure the command, arguments, and environment variables for launching the Stdio server.

## Connecting via Stdio

You can connect to an Stdio-based MCP server using two main approaches for managing the connection lifecycle:

### 1. Fully Managed Connection (Recommended)

Using a Python context manager (`with` statement) is the recommended approach. It automatically handles starting the MCP server process and stopping it when the context is exited.

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter
from mcp import StdioServerParameters
import os

# Create a StdioServerParameters object
server_params=StdioServerParameters(
    command="python3",
    args=["servers/your_stdio_server.py"],
    env={"UV_PYTHON": "3.12", **os.environ},
)

with MCPServerAdapter(server_params) as tools:
    print(f"Available tools from Stdio MCP server: {[tool.name for tool in tools]}")

    # Example: Using the tools from the Stdio MCP server in a CrewAI Agent
    research_agent = Agent(
        role="Local Data Processor",
        goal="Process data using a local Stdio-based tool.",
        backstory="An AI that leverages local scripts via MCP for specialized tasks.",
        tools=tools,
        reasoning=True,
        verbose=True,
    )

    processing_task = Task(
        description="Process the input data file 'data.txt' and summarize its contents.",
        expected_output="A summary of the processed data.",
        agent=research_agent,
        markdown=True
    )

    data_crew = Crew(
        agents=[research_agent],
        tasks=[processing_task],
        verbose=True,
        process=Process.sequential
    )

    result = data_crew.kickoff()
    print("\nCrew Task Result (Stdio - Managed):\n", result)

```

### 2. Manual Connection Lifecycle

If you need finer-grained control over when the Stdio MCP server process is started and stopped, you can manage the `MCPServerAdapter` lifecycle manually.

<Info>
  You **MUST** call `mcp_server_adapter.stop()` to ensure the server process is terminated and resources are released. Using a `try...finally` block is highly recommended.
</Info>

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter
from mcp import StdioServerParameters
import os

# Create a StdioServerParameters object
stdio_params=StdioServerParameters(
    command="python3",
    args=["servers/your_stdio_server.py"],
    env={"UV_PYTHON": "3.12", **os.environ},
)

mcp_server_adapter = MCPServerAdapter(server_params=stdio_params)
try:
    mcp_server_adapter.start()  # Manually start the connection and server process
    tools = mcp_server_adapter.tools
    print(f"Available tools (manual Stdio): {[tool.name for tool in tools]}")

    # Example: Using the tools with your Agent, Task, Crew setup
    manual_agent = Agent(
        role="Local Task Executor",
        goal="Execute a specific local task using a manually managed Stdio tool.",
        backstory="An AI proficient in controlling local processes via MCP.",
        tools=tools,
        verbose=True
    )

    manual_task = Task(
        description="Execute the 'perform_analysis' command via the Stdio tool.",
        expected_output="Results of the analysis.",
        agent=manual_agent
    )

    manual_crew = Crew(
        agents=[manual_agent],
        tasks=[manual_task],
        verbose=True,
        process=Process.sequential
    )


    result = manual_crew.kickoff() # Actual inputs depend on your tool
    print("\nCrew Task Result (Stdio - Manual):\n", result)

except Exception as e:
    print(f"An error occurred during manual Stdio MCP integration: {e}")
finally:
    if mcp_server_adapter and mcp_server_adapter.is_connected: # Check if connected before stopping
        print("Stopping Stdio MCP server connection (manual)...")
        mcp_server_adapter.stop()  # **Crucial: Ensure stop is called**
    elif mcp_server_adapter: # If adapter exists but not connected (e.g. start failed)
        print("Stdio MCP server adapter was not connected. No stop needed or start failed.")

```

Remember to replace placeholder paths and commands with your actual Stdio server details. The `env` parameter in `StdioServerParameters` can
be used to set environment variables for the server process, which can be useful for configuring its behavior or providing necessary paths (like `PYTHONPATH`).


# Streamable HTTP Transport
Source: https://docs.crewai.com/en/mcp/streamable-http

Learn how to connect CrewAI to remote MCP servers using the flexible Streamable HTTP transport.

## Overview

Streamable HTTP transport provides a flexible way to connect to remote MCP servers. It's often built upon HTTP and can support various communication patterns, including request-response and streaming, sometimes utilizing Server-Sent Events (SSE) for server-to-client streams within a broader HTTP interaction.

## Key Concepts

* **Remote Servers**: Designed for MCP servers hosted remotely.
* **Flexibility**: Can support more complex interaction patterns than plain SSE, potentially including bi-directional communication if the server implements it.
* **`MCPServerAdapter` Configuration**: You'll need to provide the server's base URL for MCP communication and specify `"streamable-http"` as the transport type.

## Connecting via Streamable HTTP

You have two primary methods for managing the connection lifecycle with a Streamable HTTP MCP server:

### 1. Fully Managed Connection (Recommended)

The recommended approach is to use a Python context manager (`with` statement), which handles the connection's setup and teardown automatically.

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter

server_params = {
    "url": "http://localhost:8001/mcp", # Replace with your actual Streamable HTTP server URL
    "transport": "streamable-http"
}

try:
    with MCPServerAdapter(server_params) as tools:
        print(f"Available tools from Streamable HTTP MCP server: {[tool.name for tool in tools]}")

        http_agent = Agent(
            role="HTTP Service Integrator",
            goal="Utilize tools from a remote MCP server via Streamable HTTP.",
            backstory="An AI agent adept at interacting with complex web services.",
            tools=tools,
            verbose=True,
        )

        http_task = Task(
            description="Perform a complex data query using a tool from the Streamable HTTP server.",
            expected_output="The result of the complex data query.",
            agent=http_agent,
        )

        http_crew = Crew(
            agents=[http_agent],
            tasks=[http_task],
            verbose=True,
            process=Process.sequential
        )

        result = http_crew.kickoff()
        print("\nCrew Task Result (Streamable HTTP - Managed):\n", result)

except Exception as e:
    print(f"Error connecting to or using Streamable HTTP MCP server (Managed): {e}")
    print("Ensure the Streamable HTTP MCP server is running and accessible at the specified URL.")

```

**Note:** Replace `"http://localhost:8001/mcp"` with the actual URL of your Streamable HTTP MCP server.

### 2. Manual Connection Lifecycle

For scenarios requiring more explicit control, you can manage the `MCPServerAdapter` connection manually.

<Info>
  It is **critical** to call `mcp_server_adapter.stop()` when you are done to close the connection and free up resources. A `try...finally` block is the safest way to ensure this.
</Info>

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter

server_params = {
    "url": "http://localhost:8001/mcp", # Replace with your actual Streamable HTTP server URL
    "transport": "streamable-http"
}

mcp_server_adapter = None
try:
    mcp_server_adapter = MCPServerAdapter(server_params)
    mcp_server_adapter.start()
    tools = mcp_server_adapter.tools
    print(f"Available tools (manual Streamable HTTP): {[tool.name for tool in tools]}")

    manual_http_agent = Agent(
        role="Advanced Web Service User",
        goal="Interact with an MCP server using manually managed Streamable HTTP connections.",
        backstory="An AI specialist in fine-tuning HTTP-based service integrations.",
        tools=tools,
        verbose=True
    )

    data_processing_task = Task(
        description="Submit data for processing and retrieve results via Streamable HTTP.",
        expected_output="Processed data or confirmation.",
        agent=manual_http_agent
    )

    data_crew = Crew(
        agents=[manual_http_agent],
        tasks=[data_processing_task],
        verbose=True,
        process=Process.sequential
    )

    result = data_crew.kickoff()
    print("\nCrew Task Result (Streamable HTTP - Manual):\n", result)

except Exception as e:
    print(f"An error occurred during manual Streamable HTTP MCP integration: {e}")
    print("Ensure the Streamable HTTP MCP server is running and accessible.")
finally:
    if mcp_server_adapter and mcp_server_adapter.is_connected:
        print("Stopping Streamable HTTP MCP server connection (manual)...")
        mcp_server_adapter.stop()  # **Crucial: Ensure stop is called**
    elif mcp_server_adapter:
        print("Streamable HTTP MCP server adapter was not connected. No stop needed or start failed.")
```

## Security Considerations

When using Streamable HTTP transport, general web security best practices are paramount:

* **Use HTTPS**: Always prefer HTTPS (HTTP Secure) for your MCP server URLs to encrypt data in transit.
* **Authentication**: Implement robust authentication mechanisms if your MCP server exposes sensitive tools or data.
* **Input Validation**: Ensure your MCP server validates all incoming requests and parameters.

For a comprehensive guide on securing your MCP integrations, please refer to our [Security Considerations](./security.mdx) page and the official [MCP Transport Security documentation](https://modelcontextprotocol.io/docs/concepts/transports#security-considerations).


# AgentOps Integration
Source: https://docs.crewai.com/en/observability/agentops

Understanding and logging your agent performance with AgentOps.

# Introduction

Observability is a key aspect of developing and deploying conversational AI agents. It allows developers to understand how their agents are performing,
how their agents are interacting with users, and how their agents use external tools and APIs.
AgentOps is a product independent of CrewAI that provides a comprehensive observability solution for agents.

## AgentOps

[AgentOps](https://agentops.ai/?=crew) provides session replays, metrics, and monitoring for agents.

At a high level, AgentOps gives you the ability to monitor cost, token usage, latency, agent failures, session-wide statistics, and more.
For more info, check out the [AgentOps Repo](https://github.com/AgentOps-AI/agentops).

### Overview

AgentOps provides monitoring for agents in development and production.
It provides a dashboard for tracking agent performance, session replays, and custom reporting.

Additionally, AgentOps provides session drilldowns for viewing Crew agent interactions, LLM calls, and tool usage in real-time.
This feature is useful for debugging and understanding how agents interact with users as well as other agents.

![Overview of a select series of agent session runs](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/agentops-overview.png)
![Overview of session drilldowns for examining agent runs](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/agentops-session.png)
![Viewing a step-by-step agent replay execution graph](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/agentops-replay.png)

### Features

* **LLM Cost Management and Tracking**: Track spend with foundation model providers.
* **Replay Analytics**: Watch step-by-step agent execution graphs.
* **Recursive Thought Detection**: Identify when agents fall into infinite loops.
* **Custom Reporting**: Create custom analytics on agent performance.
* **Analytics Dashboard**: Monitor high-level statistics about agents in development and production.
* **Public Model Testing**: Test your agents against benchmarks and leaderboards.
* **Custom Tests**: Run your agents against domain-specific tests.
* **Time Travel Debugging**: Restart your sessions from checkpoints.
* **Compliance and Security**: Create audit logs and detect potential threats such as profanity and PII leaks.
* **Prompt Injection Detection**: Identify potential code injection and secret leaks.

### Using AgentOps

<Steps>
  <Step title="Create an API Key">
    Create a user API key here: [Create API Key](https://app.agentops.ai/account)
  </Step>

  <Step title="Configure Your Environment">
    Add your API key to your environment variables:

    ```bash
    AGENTOPS_API_KEY=<YOUR_AGENTOPS_API_KEY>
    ```
  </Step>

  <Step title="Install AgentOps">
    Install AgentOps with:

    ```bash
    pip install 'crewai[agentops]'
    ```

    or

    ```bash
    pip install agentops
    ```
  </Step>

  <Step title="Initialize AgentOps">
    Before using `Crew` in your script, include these lines:

    ```python
    import agentops
    agentops.init()
    ```

    This will initiate an AgentOps session as well as automatically track Crew agents. For further info on how to outfit more complex agentic systems,
    check out the [AgentOps documentation](https://docs.agentops.ai) or join the [Discord](https://discord.gg/j4f3KbeH).
  </Step>
</Steps>

### Crew + AgentOps Examples

<CardGroup cols={3}>
  <Card title="Job Posting" color="#F3A78B" href="https://github.com/joaomdmoura/crewAI-examples/tree/main/job-posting" icon="briefcase" iconType="solid">
    Example of a Crew agent that generates job posts.
  </Card>

  <Card title="Markdown Validator" color="#F3A78B" href="https://github.com/joaomdmoura/crewAI-examples/tree/main/markdown_validator" icon="markdown" iconType="solid">
    Example of a Crew agent that validates Markdown files.
  </Card>

  <Card title="Instagram Post" color="#F3A78B" href="https://github.com/joaomdmoura/crewAI-examples/tree/main/instagram_post" icon="square-instagram" iconType="brands">
    Example of a Crew agent that generates Instagram posts.
  </Card>
</CardGroup>

### Further Information

To get started, create an [AgentOps account](https://agentops.ai/?=crew).

For feature requests or bug reports, please reach out to the AgentOps team on the [AgentOps Repo](https://github.com/AgentOps-AI/agentops).

#### Extra links

<a href="https://twitter.com/agentopsai/">üê¶ Twitter</a>
<span>¬†¬†‚Ä¢¬†¬†</span>
<a href="https://discord.gg/JHPt4C7r">üì¢ Discord</a>
<span>¬†¬†‚Ä¢¬†¬†</span>
<a href="https://app.agentops.ai/?=crew">üñáÔ∏è AgentOps Dashboard</a>
<span>¬†¬†‚Ä¢¬†¬†</span>
<a href="https://docs.agentops.ai/introduction">üìô Documentation</a>


# Arize Phoenix
Source: https://docs.crewai.com/en/observability/arize-phoenix

Arize Phoenix integration for CrewAI with OpenTelemetry and OpenInference

# Arize Phoenix Integration

This guide demonstrates how to integrate **Arize Phoenix** with **CrewAI** using OpenTelemetry via the [OpenInference](https://github.com/openinference/openinference) SDK. By the end of this guide, you will be able to trace your CrewAI agents and easily debug your agents.

> **What is Arize Phoenix?** [Arize Phoenix](https://phoenix.arize.com) is an LLM observability platform that provides tracing and evaluation for AI applications.

[![Watch a Video Demo of Our Integration with Phoenix](https://storage.googleapis.com/arize-assets/fixtures/setup_crewai.png)](https://www.youtube.com/watch?v=Yc5q3l6F7Ww)

## Get Started

We'll walk through a simple example of using CrewAI and integrating it with Arize Phoenix via OpenTelemetry using OpenInference.

You can also access this guide on [Google Colab](https://colab.research.google.com/github/Arize-ai/phoenix/blob/main/tutorials/tracing/crewai_tracing_tutorial.ipynb).

### Step 1: Install Dependencies

```bash
pip install openinference-instrumentation-crewai crewai crewai-tools arize-phoenix-otel
```

### Step 2: Set Up Environment Variables

Setup Phoenix Cloud API keys and configure OpenTelemetry to send traces to Phoenix. Phoenix Cloud is a hosted version of Arize Phoenix, but it is not required to use this integration.

You can get your free Serper API key [here](https://serper.dev/).

```python
import os
from getpass import getpass

# Get your Phoenix Cloud credentials
PHOENIX_API_KEY = getpass("üîë Enter your Phoenix Cloud API Key: ")

# Get API keys for services
OPENAI_API_KEY = getpass("üîë Enter your OpenAI API key: ")
SERPER_API_KEY = getpass("üîë Enter your Serper API key: ")

# Set environment variables
os.environ["PHOENIX_CLIENT_HEADERS"] = f"api_key={PHOENIX_API_KEY}"
os.environ["PHOENIX_COLLECTOR_ENDPOINT"] = "https://app.phoenix.arize.com" # Phoenix Cloud, change this to your own endpoint if you are using a self-hosted instance
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
os.environ["SERPER_API_KEY"] = SERPER_API_KEY
```

### Step 3: Initialize OpenTelemetry with Phoenix

Initialize the OpenInference OpenTelemetry instrumentation SDK to start capturing traces and send them to Phoenix.

```python
from phoenix.otel import register

tracer_provider = register(
    project_name="crewai-tracing-demo",
    auto_instrument=True,
)
```

### Step 4: Create a CrewAI Application

We'll create a CrewAI application where two agents collaborate to research and write a blog post about AI advancements.

```python
from crewai import Agent, Crew, Process, Task
from crewai_tools import SerperDevTool
from openinference.instrumentation.crewai import CrewAIInstrumentor
from phoenix.otel import register

# setup monitoring for your crew
tracer_provider = register(
    endpoint="http://localhost:6006/v1/traces")
CrewAIInstrumentor().instrument(skip_dep_check=True, tracer_provider=tracer_provider)
search_tool = SerperDevTool()

# Define your agents with roles and goals
researcher = Agent(
    role="Senior Research Analyst",
    goal="Uncover cutting-edge developments in AI and data science",
    backstory="""You work at a leading tech think tank.
    Your expertise lies in identifying emerging trends.
    You have a knack for dissecting complex data and presenting actionable insights.""",
    verbose=True,
    allow_delegation=False,
    # You can pass an optional llm attribute specifying what model you wanna use.
    # llm=ChatOpenAI(model_name="gpt-3.5", temperature=0.7),
    tools=[search_tool],
)
writer = Agent(
    role="Tech Content Strategist",
    goal="Craft compelling content on tech advancements",
    backstory="""You are a renowned Content Strategist, known for your insightful and engaging articles.
    You transform complex concepts into compelling narratives.""",
    verbose=True,
    allow_delegation=True,
)

# Create tasks for your agents
task1 = Task(
    description="""Conduct a comprehensive analysis of the latest advancements in AI in 2024.
    Identify key trends, breakthrough technologies, and potential industry impacts.""",
    expected_output="Full analysis report in bullet points",
    agent=researcher,
)

task2 = Task(
    description="""Using the insights provided, develop an engaging blog
    post that highlights the most significant AI advancements.
    Your post should be informative yet accessible, catering to a tech-savvy audience.
    Make it sound cool, avoid complex words so it doesn't sound like AI.""",
    expected_output="Full blog post of at least 4 paragraphs",
    agent=writer,
)

# Instantiate your crew with a sequential process
crew = Crew(
    agents=[researcher, writer], tasks=[task1, task2], verbose=1, process=Process.sequential
)

# Get your crew to work!
result = crew.kickoff()

print("######################")
print(result)
```

### Step 5: View Traces in Phoenix

After running the agent, you can view the traces generated by your CrewAI application in Phoenix. You should see detailed steps of the agent interactions and LLM calls, which can help you debug and optimize your AI agents.

Log into your Phoenix Cloud account and navigate to the project you specified in the `project_name` parameter. You'll see a timeline view of your trace with all the agent interactions, tool usages, and LLM calls.

![Example trace in Phoenix showing agent interactions](https://storage.googleapis.com/arize-assets/fixtures/crewai_traces.png)

### Version Compatibility Information

* Python 3.8+
* CrewAI >= 0.86.0
* Arize Phoenix >= 7.0.1
* OpenTelemetry SDK >= 1.31.0

### References

* [Phoenix Documentation](https://docs.arize.com/phoenix/) - Overview of the Phoenix platform.
* [CrewAI Documentation](https://docs.crewai.com/) - Overview of the CrewAI framework.
* [OpenTelemetry Docs](https://opentelemetry.io/docs/) - OpenTelemetry guide
* [OpenInference GitHub](https://github.com/openinference/openinference) - Source code for OpenInference SDK.


# Langfuse Integration
Source: https://docs.crewai.com/en/observability/langfuse

Learn how to integrate Langfuse with CrewAI via OpenTelemetry using OpenLit

# Integrate Langfuse with CrewAI

This notebook demonstrates how to integrate **Langfuse** with **CrewAI** using OpenTelemetry via the **OpenLit** SDK. By the end of this notebook, you will be able to trace your CrewAI applications with Langfuse for improved observability and debugging.

> **What is Langfuse?** [Langfuse](https://langfuse.com) is an open-source LLM engineering platform. It provides tracing and monitoring capabilities for LLM applications, helping developers debug, analyze, and optimize their AI systems. Langfuse integrates with various tools and frameworks via native integrations, OpenTelemetry, and APIs/SDKs.

[![Langfuse Overview Video](https://github.com/user-attachments/assets/3926b288-ff61-4b95-8aa1-45d041c70866)](https://langfuse.com/watch-demo)

## Get Started

We'll walk through a simple example of using CrewAI and integrating it with Langfuse via OpenTelemetry using OpenLit.

### Step 1: Install Dependencies

```python
%pip install langfuse openlit crewai crewai_tools
```

### Step 2: Set Up Environment Variables

Set your Langfuse API keys and configure OpenTelemetry export settings to send traces to Langfuse. Please refer to the [Langfuse OpenTelemetry Docs](https://langfuse.com/docs/opentelemetry/get-started) for more information on the Langfuse OpenTelemetry endpoint `/api/public/otel` and authentication.

```python
import os

# Get keys for your project from the project settings page: https://cloud.langfuse.com
os.environ["LANGFUSE_PUBLIC_KEY"] = "pk-lf-..."
os.environ["LANGFUSE_SECRET_KEY"] = "sk-lf-..."
os.environ["LANGFUSE_HOST"] = "https://cloud.langfuse.com" # üá™üá∫ EU region
# os.environ["LANGFUSE_HOST"] = "https://us.cloud.langfuse.com" # üá∫üá∏ US region


# Your OpenAI key
os.environ["OPENAI_API_KEY"] = "sk-proj-..."
```

With the environment variables set, we can now initialize the Langfuse client. get\_client() initializes the Langfuse client using the credentials provided in the environment variables.

```python
from langfuse import get_client

langfuse = get_client()

# Verify connection
if langfuse.auth_check():
    print("Langfuse client is authenticated and ready!")
else:
    print("Authentication failed. Please check your credentials and host.")
```

### Step 3: Initialize OpenLit

Initialize the OpenLit OpenTelemetry instrumentation SDK to start capturing OpenTelemetry traces.

```python
import openlit

openlit.init()
```

### Step 4: Create a Simple CrewAI Application

We'll create a simple CrewAI application where multiple agents collaborate to answer a user's question.

```python
from crewai import Agent, Task, Crew

from crewai_tools import (
    WebsiteSearchTool
)

web_rag_tool = WebsiteSearchTool()

writer = Agent(
        role="Writer",
        goal="You make math engaging and understandable for young children through poetry",
        backstory="You're an expert in writing haikus but you know nothing of math.",
        tools=[web_rag_tool],
    )

task = Task(description=("What is {multiplication}?"),
            expected_output=("Compose a haiku that includes the answer."),
            agent=writer)

crew = Crew(
  agents=[writer],
  tasks=[task],
  share_crew=False
)
```

### Step 5: See Traces in Langfuse

After running the agent, you can view the traces generated by your CrewAI application in [Langfuse](https://cloud.langfuse.com). You should see detailed steps of the LLM interactions, which can help you debug and optimize your AI agent.

![CrewAI example trace in Langfuse](https://langfuse.com/images/cookbook/integration_crewai/crewai-example-trace.png)

*[Public example trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/e2cf380ffc8d47d28da98f136140642b?timestamp=2025-02-05T15%3A12%3A02.717Z\&observation=3b32338ee6a5d9af)*

## References

* [Langfuse OpenTelemetry Docs](https://langfuse.com/docs/opentelemetry/get-started)


# Langtrace Integration
Source: https://docs.crewai.com/en/observability/langtrace

How to monitor cost, latency, and performance of CrewAI Agents using Langtrace, an external observability tool.

# Langtrace Overview

Langtrace is an open-source, external tool that helps you set up observability and evaluations for Large Language Models (LLMs), LLM frameworks, and Vector Databases.
While not built directly into CrewAI, Langtrace can be used alongside CrewAI to gain deep visibility into the cost, latency, and performance of your CrewAI Agents.
This integration allows you to log hyperparameters, monitor performance regressions, and establish a process for continuous improvement of your Agents.

![Overview of a select series of agent session runs](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/langtrace1.png)
![Overview of agent traces](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/langtrace2.png)
![Overview of llm traces in details](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/langtrace3.png)

## Setup Instructions

<Steps>
  <Step title="Sign up for Langtrace">
    Sign up by visiting [https://langtrace.ai/signup](https://langtrace.ai/signup).
  </Step>

  <Step title="Create a project">
    Set the project type to `CrewAI` and generate an API key.
  </Step>

  <Step title="Install Langtrace in your CrewAI project">
    Use the following command:

    ```bash
    pip install langtrace-python-sdk
    ```
  </Step>

  <Step title="Import Langtrace">
    Import and initialize Langtrace at the beginning of your script, before any CrewAI imports:

    ```python
    from langtrace_python_sdk import langtrace
    langtrace.init(api_key='<LANGTRACE_API_KEY>')

    # Now import CrewAI modules
    from crewai import Agent, Task, Crew
    ```
  </Step>
</Steps>

### Features and Their Application to CrewAI

1. **LLM Token and Cost Tracking**

   * Monitor the token usage and associated costs for each CrewAI agent interaction.

2. **Trace Graph for Execution Steps**

   * Visualize the execution flow of your CrewAI tasks, including latency and logs.
   * Useful for identifying bottlenecks in your agent workflows.

3. **Dataset Curation with Manual Annotation**

   * Create datasets from your CrewAI task outputs for future training or evaluation.

4. **Prompt Versioning and Management**

   * Keep track of different versions of prompts used in your CrewAI agents.
   * Useful for A/B testing and optimizing agent performance.

5. **Prompt Playground with Model Comparisons**

   * Test and compare different prompts and models for your CrewAI agents before deployment.

6. **Testing and Evaluations**

   * Set up automated tests for your CrewAI agents and tasks.


# Maxim Integration
Source: https://docs.crewai.com/en/observability/maxim

Start Agent monitoring, evaluation, and observability

# Maxim Overview

Maxim AI provides comprehensive agent monitoring, evaluation, and observability for your CrewAI applications. With Maxim's one-line integration, you can easily trace and analyse agent interactions, performance metrics, and more.

## Features

### Prompt Management

Maxim's Prompt Management capabilities enable you to create, organize, and optimize prompts for your CrewAI agents. Rather than hardcoding instructions, leverage Maxim‚Äôs SDK to dynamically retrieve and apply version-controlled prompts.

<Tabs>
  <Tab title="Prompt Playground">
    Create, refine, experiment and deploy your prompts via the playground. Organize of your prompts using folders and versions, experimenting with the real world cases by linking tools and context, and deploying based on custom logic.

    Easily experiment across models by [**configuring models**](https://www.getmaxim.ai/docs/introduction/quickstart/setting-up-workspace#add-model-api-keys) and selecting the relevant model from the dropdown at the top of the prompt playground.

    <img src="https://raw.githubusercontent.com/akmadan/crewAI/docs_maxim_observability/docs/images/maxim_playground.png" />
  </Tab>

  <Tab title="Prompt Versions">
    As teams build their AI applications, a big part of experimentation is iterating on the prompt structure. In order to collaborate effectively and organize your changes clearly, Maxim allows prompt versioning and comparison runs across versions.

    <img src="https://raw.githubusercontent.com/akmadan/crewAI/docs_maxim_observability/docs/images/maxim_versions.png" />
  </Tab>

  <Tab title="Prompt Comparisons">
    Iterating on Prompts as you evolve your AI application would need experiments across models, prompt structures, etc. In order to compare versions and make informed decisions about changes, the comparison playground allows a side by side view of results.

    ## **Why use Prompt comparison?**

    Prompt comparison combines multiple single Prompts into one view, enabling a streamlined approach for various workflows:

    1. **Model comparison**: Evaluate the performance of different models on the same Prompt.
    2. **Prompt optimization**: Compare different versions of a Prompt to identify the most effective formulation.
    3. **Cross-Model consistency**: Ensure consistent outputs across various models for the same Prompt.
    4. **Performance benchmarking**: Analyze metrics like latency, cost, and token count across different models and Prompts.
  </Tab>
</Tabs>

### Observability & Evals

Maxim AI provides comprehensive observability & evaluation for your CrewAI agents, helping you understand exactly what's happening during each execution.

<Tabs>
  <Tab title="Agent Tracing">
    Track your agent‚Äôs complete lifecycle, including tool calls, agent trajectories, and decision flows effortlessly.

    <img src="https://raw.githubusercontent.com/akmadan/crewAI/docs_maxim_observability/docs/images/maxim_agent_tracking.png" />
  </Tab>

  <Tab title="Analytics + Evals">
    Run detailed evaluations on full traces or individual nodes with support for:

    * Multi-step interactions and granular trace analysis
    * Session Level Evaluations
    * Simulations for real-world testing

    <img src="https://raw.githubusercontent.com/akmadan/crewAI/docs_maxim_observability/docs/images/maxim_trace_eval.png" />

    <CardGroup cols={3}>
      <Card title="Auto Evals on Logs" icon="e" href="https://www.getmaxim.ai/docs/observe/how-to/evaluate-logs/auto-evaluation">
        <p>
          Evaluate captured logs automatically from the UI based on filters and sampling
        </p>
      </Card>

      <Card title="Human Evals on Logs" icon="hand" href="https://www.getmaxim.ai/docs/observe/how-to/evaluate-logs/human-evaluation">
        <p>
          Use human evaluation or rating to assess the quality of your logs and evaluate them.
        </p>
      </Card>

      <Card title="Node Level Evals" icon="road" href="https://www.getmaxim.ai/docs/observe/how-to/evaluate-logs/node-level-evaluation">
        <p>
          Evaluate any component of your trace or log to gain insights into your agent‚Äôs behavior.
        </p>
      </Card>
    </CardGroup>

    ***
  </Tab>

  <Tab title="Alerting">
    Set thresholds on **error**, **cost, token usage, user feedback, latency** and get real-time alerts via Slack or PagerDuty.

    <img src="https://raw.githubusercontent.com/akmadan/crewAI/docs_maxim_observability/docs/images/maxim_alerts_1.png" />
  </Tab>

  <Tab title="Dashboards">
    Visualize Traces over time, usage metrics, latency & error rates with ease.

    <img src="https://raw.githubusercontent.com/akmadan/crewAI/docs_maxim_observability/docs/images/maxim_dashboard_1.png" />
  </Tab>
</Tabs>

## Getting Started

### Prerequisites

* Python version >=3.10
* A Maxim account ([sign up here](https://getmaxim.ai/))
* Generate Maxim API Key
* A CrewAI project

### Installation

Install the Maxim SDK via pip:

```python
pip install maxim-py
```

Or add it to your `requirements.txt`:

```
maxim-py
```

### Basic Setup

### 1. Set up environment variables

```python
### Environment Variables Setup

# Create a `.env` file in your project root:

# Maxim API Configuration
MAXIM_API_KEY=your_api_key_here
MAXIM_LOG_REPO_ID=your_repo_id_here
```

### 2. Import the required packages

```python
from crewai import Agent, Task, Crew, Process
from maxim import Maxim
from maxim.logger.crewai import instrument_crewai
```

### 3. Initialise Maxim with your API key

```python {8}
# Instrument CrewAI with just one line
instrument_crewai(Maxim().logger())
```

### 4. Create and run your CrewAI application as usual

```python
# Create your agent
researcher = Agent(
    role='Senior Research Analyst',
    goal='Uncover cutting-edge developments in AI',
    backstory="You are an expert researcher at a tech think tank...",
    verbose=True,
    llm=llm
)

# Define the task
research_task = Task(
    description="Research the latest AI advancements...",
    expected_output="",
    agent=researcher
)

# Configure and run the crew
crew = Crew(
    agents=[researcher],
    tasks=[research_task],
    verbose=True
)

try:
    result = crew.kickoff()
finally:
    maxim.cleanup()  # Ensure cleanup happens even if errors occur
```

That's it! All your CrewAI agent interactions will now be logged and available in your Maxim dashboard.

Check this Google Colab Notebook for a quick reference - [Notebook](https://colab.research.google.com/drive/1ZKIZWsmgQQ46n8TH9zLsT1negKkJA6K8?usp=sharing)

## Viewing Your Traces

After running your CrewAI application:

1. Log in to your [Maxim Dashboard](https://app.getmaxim.ai/login)
2. Navigate to your repository
3. View detailed agent traces, including:

   * Agent conversations
   * Tool usage patterns
   * Performance metrics
   * Cost analytics

   <img src="https://raw.githubusercontent.com/akmadan/crewAI/docs_maxim_observability/docs/images/crewai_traces.gif" />

## Troubleshooting

### Common Issues

* **No traces appearing**: Ensure your API key and repository ID are correct
* Ensure you've **`called instrument_crewai()`** ***before*** running your crew. This initializes logging hooks correctly.
* Set `debug=True` in your `instrument_crewai()` call to surface any internal errors:

  ```python
  instrument_crewai(logger, debug=True)
  ```
* Configure your agents with `verbose=True` to capture detailed logs:

  ```python
  agent = CrewAgent(..., verbose=True)
  ```
* Double-check that `instrument_crewai()` is called **before** creating or executing agents. This might be obvious, but it's a common oversight.

## Resources

<CardGroup cols="3">
  <Card title="CrewAI Docs" icon="book" href="https://docs.crewai.com/">
    Official CrewAI documentation
  </Card>

  <Card title="Maxim Docs" icon="book" href="https://getmaxim.ai/docs">
    Official Maxim documentation
  </Card>

  <Card title="Maxim Github" icon="github" href="https://github.com/maximhq">
    Maxim Github
  </Card>
</CardGroup>


# MLflow Integration
Source: https://docs.crewai.com/en/observability/mlflow

Quickly start monitoring your Agents with MLflow.

# MLflow Overview

[MLflow](https://mlflow.org/) is an open-source platform to assist machine learning practitioners and teams in handling the complexities of the machine learning process.

It provides a tracing feature that enhances LLM observability in your Generative AI applications by capturing detailed information about the execution of your application‚Äôs services.
Tracing provides a way to record the inputs, outputs, and metadata associated with each intermediate step of a request, enabling you to easily pinpoint the source of bugs and unexpected behaviors.

![Overview of MLflow crewAI tracing usage](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/mlflow-tracing.gif)

### Features

* **Tracing Dashboard**: Monitor activities of your crewAI agents with detailed dashboards that include inputs, outputs and metadata of spans.
* **Automated Tracing**: A fully automated integration with crewAI, which can be enabled by running `mlflow.crewai.autolog()`.
* **Manual Trace Instrumentation with minor efforts**: Customize trace instrumentation through MLflow's high-level fluent APIs such as decorators, function wrappers and context managers.
* **OpenTelemetry Compatibility**: MLflow Tracing supports exporting traces to an OpenTelemetry Collector, which can then be used to export traces to various backends such as Jaeger, Zipkin, and AWS X-Ray.
* **Package and Deploy Agents**: Package and deploy your crewAI agents to an inference server with a variety of deployment targets.
* **Securely Host LLMs**: Host multiple LLM from various providers in one unified endpoint through MFflow gateway.
* **Evaluation**: Evaluate your crewAI agents with a wide range of metrics using a convenient API `mlflow.evaluate()`.

## Setup Instructions

<Steps>
  <Step title="Install MLflow package">
    ```shell
    # The crewAI integration is available in mlflow>=2.19.0
    pip install mlflow
    ```
  </Step>

  <Step title="Start MFflow tracking server">
    ```shell
    # This process is optional, but it is recommended to use MLflow tracking server for better visualization and broader features.
    mlflow server
    ```
  </Step>

  <Step title="Initialize MLflow in Your Application">
    Add the following two lines to your application code:

    ```python
    import mlflow

    mlflow.crewai.autolog()

    # Optional: Set a tracking URI and an experiment name if you have a tracking server
    mlflow.set_tracking_uri("http://localhost:5000")
    mlflow.set_experiment("CrewAI")
    ```

    Example Usage for tracing CrewAI Agents:

    ```python
    from crewai import Agent, Crew, Task
    from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource
    from crewai_tools import SerperDevTool, WebsiteSearchTool

    from textwrap import dedent

    content = "Users name is John. He is 30 years old and lives in San Francisco."
    string_source = StringKnowledgeSource(
        content=content, metadata={"preference": "personal"}
    )

    search_tool = WebsiteSearchTool()


    class TripAgents:
        def city_selection_agent(self):
            return Agent(
                role="City Selection Expert",
                goal="Select the best city based on weather, season, and prices",
                backstory="An expert in analyzing travel data to pick ideal destinations",
                tools=[
                    search_tool,
                ],
                verbose=True,
            )

        def local_expert(self):
            return Agent(
                role="Local Expert at this city",
                goal="Provide the BEST insights about the selected city",
                backstory="""A knowledgeable local guide with extensive information
            about the city, it's attractions and customs""",
                tools=[search_tool],
                verbose=True,
            )


    class TripTasks:
        def identify_task(self, agent, origin, cities, interests, range):
            return Task(
                description=dedent(
                    f"""
                    Analyze and select the best city for the trip based
                    on specific criteria such as weather patterns, seasonal
                    events, and travel costs. This task involves comparing
                    multiple cities, considering factors like current weather
                    conditions, upcoming cultural or seasonal events, and
                    overall travel expenses.
                    Your final answer must be a detailed
                    report on the chosen city, and everything you found out
                    about it, including the actual flight costs, weather
                    forecast and attractions.

                    Traveling from: {origin}
                    City Options: {cities}
                    Trip Date: {range}
                    Traveler Interests: {interests}
                """
                ),
                agent=agent,
                expected_output="Detailed report on the chosen city including flight costs, weather forecast, and attractions",
            )

        def gather_task(self, agent, origin, interests, range):
            return Task(
                description=dedent(
                    f"""
                    As a local expert on this city you must compile an
                    in-depth guide for someone traveling there and wanting
                    to have THE BEST trip ever!
                    Gather information about key attractions, local customs,
                    special events, and daily activity recommendations.
                    Find the best spots to go to, the kind of place only a
                    local would know.
                    This guide should provide a thorough overview of what
                    the city has to offer, including hidden gems, cultural
                    hotspots, must-visit landmarks, weather forecasts, and
                    high level costs.
                    The final answer must be a comprehensive city guide,
                    rich in cultural insights and practical tips,
                    tailored to enhance the travel experience.

                    Trip Date: {range}
                    Traveling from: {origin}
                    Traveler Interests: {interests}
                """
                ),
                agent=agent,
                expected_output="Comprehensive city guide including hidden gems, cultural hotspots, and practical travel tips",
            )


    class TripCrew:
        def __init__(self, origin, cities, date_range, interests):
            self.cities = cities
            self.origin = origin
            self.interests = interests
            self.date_range = date_range

        def run(self):
            agents = TripAgents()
            tasks = TripTasks()

            city_selector_agent = agents.city_selection_agent()
            local_expert_agent = agents.local_expert()

            identify_task = tasks.identify_task(
                city_selector_agent,
                self.origin,
                self.cities,
                self.interests,
                self.date_range,
            )
            gather_task = tasks.gather_task(
                local_expert_agent, self.origin, self.interests, self.date_range
            )

            crew = Crew(
                agents=[city_selector_agent, local_expert_agent],
                tasks=[identify_task, gather_task],
                verbose=True,
                memory=True,
                knowledge={
                    "sources": [string_source],
                    "metadata": {"preference": "personal"},
                },
            )

            result = crew.kickoff()
            return result


    trip_crew = TripCrew("California", "Tokyo", "Dec 12 - Dec 20", "sports")
    result = trip_crew.run()

    print(result)
    ```

    Refer to [MLflow Tracing Documentation](https://mlflow.org/docs/latest/llms/tracing/index.html) for more configurations and use cases.
  </Step>

  <Step title="Visualize Activities of Agents">
    Now traces for your crewAI agents are captured by MLflow.
    Let's visit MLflow tracking server to view the traces and get insights into your Agents.

    Open `127.0.0.1:5000` on your browser to visit MLflow tracking server.

    <Frame caption="MLflow Tracing Dashboard">
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/mlflow1.png" alt="MLflow tracing example with crewai" />
    </Frame>
  </Step>
</Steps>


# OpenLIT Integration
Source: https://docs.crewai.com/en/observability/openlit

Quickly start monitoring your Agents in just a single line of code with OpenTelemetry.

# OpenLIT Overview

[OpenLIT](https://github.com/openlit/openlit?src=crewai-docs) is an open-source tool that makes it simple to monitor the performance of AI agents, LLMs, VectorDBs, and GPUs with just **one** line of code.

It provides OpenTelemetry-native tracing and metrics to track important parameters like cost, latency, interactions and task sequences.
This setup enables you to track hyperparameters and monitor for performance issues, helping you find ways to enhance and fine-tune your agents over time.

<Frame caption="OpenLIT Dashboard">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/openlit1.png" alt="Overview Agent usage including cost and tokens" />

  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/openlit2.png" alt="Overview of agent otel traces and metrics" />

  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/openlit3.png" alt="Overview of agent traces in details" />
</Frame>

### Features

* **Analytics Dashboard**: Monitor your Agents health and performance with detailed dashboards that track metrics, costs, and user interactions.
* **OpenTelemetry-native Observability SDK**: Vendor-neutral SDKs to send traces and metrics to your existing observability tools like Grafana, DataDog and more.
* **Cost Tracking for Custom and Fine-Tuned Models**: Tailor cost estimations for specific models using custom pricing files for precise budgeting.
* **Exceptions Monitoring Dashboard**: Quickly spot and resolve issues by tracking common exceptions and errors with a monitoring dashboard.
* **Compliance and Security**: Detect potential threats such as profanity and PII leaks.
* **Prompt Injection Detection**: Identify potential code injection and secret leaks.
* **API Keys and Secrets Management**: Securely handle your LLM API keys and secrets centrally, avoiding insecure practices.
* **Prompt Management**: Manage and version Agent prompts using PromptHub for consistent and easy access across Agents.
* **Model Playground** Test and compare different models for your CrewAI agents before deployment.

## Setup Instructions

<Steps>
  <Step title="Deploy OpenLIT">
    <Steps>
      <Step title="Git Clone OpenLIT Repository">
        ```shell
        git clone git@github.com:openlit/openlit.git
        ```
      </Step>

      <Step title="Start Docker Compose">
        From the root directory of the [OpenLIT Repo](https://github.com/openlit/openlit), Run the below command:

        ```shell
        docker compose up -d
        ```
      </Step>
    </Steps>
  </Step>

  <Step title="Install OpenLIT SDK">
    ```shell
    pip install openlit
    ```
  </Step>

  <Step title="Initialize OpenLIT in Your Application">
    Add the following two lines to your application code:

    <Tabs>
      <Tab title="Setup using function arguments">
        ```python
        import openlit
        openlit.init(otlp_endpoint="http://127.0.0.1:4318")
        ```

        Example Usage for monitoring a CrewAI Agent:

        ```python
        from crewai import Agent, Task, Crew, Process
        import openlit

        openlit.init(disable_metrics=True)
        # Define your agents
        researcher = Agent(
            role="Researcher",
            goal="Conduct thorough research and analysis on AI and AI agents",
            backstory="You're an expert researcher, specialized in technology, software engineering, AI, and startups. You work as a freelancer and are currently researching for a new client.",
            allow_delegation=False,
            llm='command-r'
        )


        # Define your task
        task = Task(
            description="Generate a list of 5 interesting ideas for an article, then write one captivating paragraph for each idea that showcases the potential of a full article on this topic. Return the list of ideas with their paragraphs and your notes.",
            expected_output="5 bullet points, each with a paragraph and accompanying notes.",
        )

        # Define the manager agent
        manager = Agent(
            role="Project Manager",
            goal="Efficiently manage the crew and ensure high-quality task completion",
            backstory="You're an experienced project manager, skilled in overseeing complex projects and guiding teams to success. Your role is to coordinate the efforts of the crew members, ensuring that each task is completed on time and to the highest standard.",
            allow_delegation=True,
            llm='command-r'
        )

        # Instantiate your crew with a custom manager
        crew = Crew(
            agents=[researcher],
            tasks=[task],
            manager_agent=manager,
            process=Process.hierarchical,
        )

        # Start the crew's work
        result = crew.kickoff()

        print(result)
        ```
      </Tab>

      <Tab title="Setup using Environment Variables">
        Add the following two lines to your application code:

        ```python
        import openlit

        openlit.init()
        ```

        Run the following command to configure the OTEL export endpoint:

        ```shell
        export OTEL_EXPORTER_OTLP_ENDPOINT = "http://127.0.0.1:4318"
        ```

        Example Usage for monitoring a CrewAI Async Agent:

        ```python
        import asyncio
        from crewai import Crew, Agent, Task
        import openlit

        openlit.init(otlp_endpoint="http://127.0.0.1:4318")

        # Create an agent with code execution enabled
        coding_agent = Agent(
          role="Python Data Analyst",
          goal="Analyze data and provide insights using Python",
          backstory="You are an experienced data analyst with strong Python skills.",
          allow_code_execution=True,
          llm="command-r"
        )

        # Create a task that requires code execution
        data_analysis_task = Task(
          description="Analyze the given dataset and calculate the average age of participants. Ages: {ages}",
          agent=coding_agent,
          expected_output="5 bullet points, each with a paragraph and accompanying notes.",
        )

        # Create a crew and add the task
        analysis_crew = Crew(
          agents=[coding_agent],
          tasks=[data_analysis_task]
        )

        # Async function to kickoff the crew asynchronously
        async def async_crew_execution():
            result = await analysis_crew.kickoff_async(inputs={"ages": [25, 30, 35, 40, 45]})
            print("Crew Result:", result)

        # Run the async function
        asyncio.run(async_crew_execution())
        ```
      </Tab>
    </Tabs>

    Refer to OpenLIT [Python SDK repository](https://github.com/openlit/openlit/tree/main/sdk/python) for more advanced configurations and use cases.
  </Step>

  <Step title="Visualize and Analyze">
    With the Agent Observability data now being collected and sent to OpenLIT, the next step is to visualize and analyze this data to get insights into your Agent's performance, behavior, and identify areas of improvement.

    Just head over to OpenLIT at `127.0.0.1:3000` on your browser to start exploring. You can login using the default credentials

    * **Email**: `user@openlit.io`
    * **Password**: `openlituser`

    <Frame caption="OpenLIT Dashboard">
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/openlit1.png" alt="Overview Agent usage including cost and tokens" />

      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/openlit2.png" alt="Overview of agent otel traces and metrics" />
    </Frame>
  </Step>
</Steps>


# Opik Integration
Source: https://docs.crewai.com/en/observability/opik

Learn how to use Comet Opik to debug, evaluate, and monitor your CrewAI applications with comprehensive tracing, automated evaluations, and production-ready dashboards.

# Opik Overview

With [Comet Opik](https://www.comet.com/docs/opik/), debug, evaluate, and monitor your LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards.

<Frame caption="Opik Agent Dashboard">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/opik-crewai-dashboard.png" alt="Opik agent monitoring example with CrewAI" />
</Frame>

Opik provides comprehensive support for every stage of your CrewAI application development:

* **Log Traces and Spans**: Automatically track LLM calls and application logic to debug and analyze development and production systems. Manually or programmatically annotate, view, and compare responses across projects.
* **Evaluate Your LLM Application's Performance**: Evaluate against a custom test set and run built-in evaluation metrics or define your own metrics in the SDK or UI.
* **Test Within Your CI/CD Pipeline**: Establish reliable performance baselines with Opik's LLM unit tests, built on PyTest. Run online evaluations for continuous monitoring in production.
* **Monitor & Analyze Production Data**: Understand your models' performance on unseen data in production and generate datasets for new dev iterations.

## Setup

Comet provides a hosted version of the Opik platform, or you can run the platform locally.

To use the hosted version, simply [create a free Comet account](https://www.comet.com/signup?utm_medium=github\&utm_source=crewai_docs) and grab you API Key.

To run the Opik platform locally, see our [installation guide](https://www.comet.com/docs/opik/self-host/overview/) for more information.

For this guide we will use CrewAI‚Äôs quickstart example.

<Steps>
  <Step title="Install required packages">
    ```shell
    pip install crewai crewai-tools opik --upgrade
    ```
  </Step>

  <Step title="Configure Opik">
    ```python
    import opik
    opik.configure(use_local=False)
    ```
  </Step>

  <Step title="Prepare environment">
    First, we set up our API keys for our LLM-provider as environment variables:

    ```python
    import os
    import getpass

    if "OPENAI_API_KEY" not in os.environ:
    os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter your OpenAI API key: ")
    ```
  </Step>

  <Step title="Using CrewAI">
    The first step is to create our project. We will use an example from CrewAI‚Äôs documentation:

    ```python
    from crewai import Agent, Crew, Task, Process


    class YourCrewName:
        def agent_one(self) -> Agent:
            return Agent(
                role="Data Analyst",
                goal="Analyze data trends in the market",
                backstory="An experienced data analyst with a background in economics",
                verbose=True,
            )

        def agent_two(self) -> Agent:
            return Agent(
                role="Market Researcher",
                goal="Gather information on market dynamics",
                backstory="A diligent researcher with a keen eye for detail",
                verbose=True,
            )

        def task_one(self) -> Task:
            return Task(
                name="Collect Data Task",
                description="Collect recent market data and identify trends.",
                expected_output="A report summarizing key trends in the market.",
                agent=self.agent_one(),
            )

        def task_two(self) -> Task:
            return Task(
                name="Market Research Task",
                description="Research factors affecting market dynamics.",
                expected_output="An analysis of factors influencing the market.",
                agent=self.agent_two(),
            )

        def crew(self) -> Crew:
            return Crew(
                agents=[self.agent_one(), self.agent_two()],
                tasks=[self.task_one(), self.task_two()],
                process=Process.sequential,
                verbose=True,
            )

    ```

    Now we can import Opik‚Äôs tracker and run our crew:

    ```python
    from opik.integrations.crewai import track_crewai

    track_crewai(project_name="crewai-integration-demo")

    my_crew = YourCrewName().crew()
    result = my_crew.kickoff()

    print(result)
    ```

    After running your CrewAI application, visit the Opik app to view:

    * LLM traces, spans, and their metadata
    * Agent interactions and task execution flow
    * Performance metrics like latency and token usage
    * Evaluation metrics (built-in or custom)
  </Step>
</Steps>

## Resources

* [ü¶â Opik Documentation](https://www.comet.com/docs/opik/)
* [üëâ Opik + CrewAI Colab](https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/crewai.ipynb)
* [üê¶ X](https://x.com/cometml)
* [üí¨ Slack](https://slack.comet.com/)


# Overview
Source: https://docs.crewai.com/en/observability/overview

Monitor, evaluate, and optimize your CrewAI agents with comprehensive observability tools

## Observability for CrewAI

Observability is crucial for understanding how your CrewAI agents perform, identifying bottlenecks, and ensuring reliable operation in production environments. This section covers various tools and platforms that provide monitoring, evaluation, and optimization capabilities for your agent workflows.

## Why Observability Matters

* **Performance Monitoring**: Track agent execution times, token usage, and resource consumption
* **Quality Assurance**: Evaluate output quality and consistency across different scenarios
* **Debugging**: Identify and resolve issues in agent behavior and task execution
* **Cost Management**: Monitor LLM API usage and associated costs
* **Continuous Improvement**: Gather insights to optimize agent performance over time

## Available Observability Tools

### Monitoring & Tracing Platforms

<CardGroup cols={2}>
  <Card title="AgentOps" icon="paperclip" href="/en/observability/agentops">
    Session replays, metrics, and monitoring for agent development and production.
  </Card>

  <Card title="OpenLIT" icon="magnifying-glass-chart" href="/en/observability/openlit">
    OpenTelemetry-native monitoring with cost tracking and performance analytics.
  </Card>

  <Card title="MLflow" icon="bars-staggered" href="/en/observability/mlflow">
    Machine learning lifecycle management with tracing and evaluation capabilities.
  </Card>

  <Card title="Langfuse" icon="link" href="/en/observability/langfuse">
    LLM engineering platform with detailed tracing and analytics.
  </Card>

  <Card title="Langtrace" icon="chart-line" href="/en/observability/langtrace">
    Open-source observability for LLMs and agent frameworks.
  </Card>

  <Card title="Arize Phoenix" icon="meteor" href="/en/observability/arize-phoenix">
    AI observability platform for monitoring and troubleshooting.
  </Card>

  <Card title="Portkey" icon="key" href="/en/observability/portkey">
    AI gateway with comprehensive monitoring and reliability features.
  </Card>

  <Card title="Opik" icon="meteor" href="/en/observability/opik">
    Debug, evaluate, and monitor LLM applications with comprehensive tracing.
  </Card>

  <Card title="Weave" icon="network-wired" href="/en/observability/weave">
    Weights & Biases platform for tracking and evaluating AI applications.
  </Card>
</CardGroup>

### Evaluation & Quality Assurance

<CardGroup cols={2}>
  <Card title="Patronus AI" icon="shield-check" href="/en/observability/patronus-evaluation">
    Comprehensive evaluation platform for LLM outputs and agent behaviors.
  </Card>
</CardGroup>

## Key Observability Metrics

### Performance Metrics

* **Execution Time**: How long agents take to complete tasks
* **Token Usage**: Input/output tokens consumed by LLM calls
* **API Latency**: Response times from external services
* **Success Rate**: Percentage of successfully completed tasks

### Quality Metrics

* **Output Accuracy**: Correctness of agent responses
* **Consistency**: Reliability across similar inputs
* **Relevance**: How well outputs match expected results
* **Safety**: Compliance with content policies and guidelines

### Cost Metrics

* **API Costs**: Expenses from LLM provider usage
* **Resource Utilization**: Compute and memory consumption
* **Cost per Task**: Economic efficiency of agent operations
* **Budget Tracking**: Monitoring against spending limits

## Getting Started

1. **Choose Your Tools**: Select observability platforms that match your needs
2. **Instrument Your Code**: Add monitoring to your CrewAI applications
3. **Set Up Dashboards**: Configure visualizations for key metrics
4. **Define Alerts**: Create notifications for important events
5. **Establish Baselines**: Measure initial performance for comparison
6. **Iterate and Improve**: Use insights to optimize your agents

## Best Practices

### Development Phase

* Use detailed tracing to understand agent behavior
* Implement evaluation metrics early in development
* Monitor resource usage during testing
* Set up automated quality checks

### Production Phase

* Implement comprehensive monitoring and alerting
* Track performance trends over time
* Monitor for anomalies and degradation
* Maintain cost visibility and control

### Continuous Improvement

* Regular performance reviews and optimization
* A/B testing of different agent configurations
* Feedback loops for quality improvement
* Documentation of lessons learned

Choose the observability tools that best fit your use case, infrastructure, and monitoring requirements to ensure your CrewAI agents perform reliably and efficiently.


# Patronus AI Evaluation
Source: https://docs.crewai.com/en/observability/patronus-evaluation

Monitor and evaluate CrewAI agent performance using Patronus AI's comprehensive evaluation platform for LLM outputs and agent behaviors.

# Patronus AI Evaluation

## Overview

[Patronus AI](https://patronus.ai) provides comprehensive evaluation and monitoring capabilities for CrewAI agents, enabling you to assess model outputs, agent behaviors, and overall system performance. This integration allows you to implement continuous evaluation workflows that help maintain quality and reliability in production environments.

## Key Features

* **Automated Evaluation**: Real-time assessment of agent outputs and behaviors
* **Custom Criteria**: Define specific evaluation criteria tailored to your use cases
* **Performance Monitoring**: Track agent performance metrics over time
* **Quality Assurance**: Ensure consistent output quality across different scenarios
* **Safety & Compliance**: Monitor for potential issues and policy violations

## Evaluation Tools

Patronus provides three main evaluation tools for different use cases:

1. **PatronusEvalTool**: Allows agents to select the most appropriate evaluator and criteria for the evaluation task.
2. **PatronusPredefinedCriteriaEvalTool**: Uses predefined evaluator and criteria specified by the user.
3. **PatronusLocalEvaluatorTool**: Uses custom function evaluators defined by the user.

## Installation

To use these tools, you need to install the Patronus package:

```shell
uv add patronus
```

You'll also need to set up your Patronus API key as an environment variable:

```shell
export PATRONUS_API_KEY="your_patronus_api_key"
```

## Steps to Get Started

To effectively use the Patronus evaluation tools, follow these steps:

1. **Install Patronus**: Install the Patronus package using the command above.
2. **Set Up API Key**: Set your Patronus API key as an environment variable.
3. **Choose the Right Tool**: Select the appropriate Patronus evaluation tool based on your needs.
4. **Configure the Tool**: Configure the tool with the necessary parameters.

## Examples

### Using PatronusEvalTool

The following example demonstrates how to use the `PatronusEvalTool`, which allows agents to select the most appropriate evaluator and criteria:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import PatronusEvalTool

# Initialize the tool
patronus_eval_tool = PatronusEvalTool()

# Define an agent that uses the tool
coding_agent = Agent(
    role="Coding Agent",
    goal="Generate high quality code and verify that the output is code",
    backstory="An experienced coder who can generate high quality python code.",
    tools=[patronus_eval_tool],
    verbose=True,
)

# Example task to generate and evaluate code
generate_code_task = Task(
    description="Create a simple program to generate the first N numbers in the Fibonacci sequence. Select the most appropriate evaluator and criteria for evaluating your output.",
    expected_output="Program that generates the first N numbers in the Fibonacci sequence.",
    agent=coding_agent,
)

# Create and run the crew
crew = Crew(agents=[coding_agent], tasks=[generate_code_task])
result = crew.kickoff()
```

### Using PatronusPredefinedCriteriaEvalTool

The following example demonstrates how to use the `PatronusPredefinedCriteriaEvalTool`, which uses predefined evaluator and criteria:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import PatronusPredefinedCriteriaEvalTool

# Initialize the tool with predefined criteria
patronus_eval_tool = PatronusPredefinedCriteriaEvalTool(
    evaluators=[{"evaluator": "judge", "criteria": "contains-code"}]
)

# Define an agent that uses the tool
coding_agent = Agent(
    role="Coding Agent",
    goal="Generate high quality code",
    backstory="An experienced coder who can generate high quality python code.",
    tools=[patronus_eval_tool],
    verbose=True,
)

# Example task to generate code
generate_code_task = Task(
    description="Create a simple program to generate the first N numbers in the Fibonacci sequence.",
    expected_output="Program that generates the first N numbers in the Fibonacci sequence.",
    agent=coding_agent,
)

# Create and run the crew
crew = Crew(agents=[coding_agent], tasks=[generate_code_task])
result = crew.kickoff()
```

### Using PatronusLocalEvaluatorTool

The following example demonstrates how to use the `PatronusLocalEvaluatorTool`, which uses custom function evaluators:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import PatronusLocalEvaluatorTool
from patronus import Client, EvaluationResult
import random

# Initialize the Patronus client
client = Client()

# Register a custom evaluator
@client.register_local_evaluator("random_evaluator")
def random_evaluator(**kwargs):
    score = random.random()
    return EvaluationResult(
        score_raw=score,
        pass_=score >= 0.5,
        explanation="example explanation",
    )

# Initialize the tool with the custom evaluator
patronus_eval_tool = PatronusLocalEvaluatorTool(
    patronus_client=client,
    evaluator="random_evaluator",
    evaluated_model_gold_answer="example label",
)

# Define an agent that uses the tool
coding_agent = Agent(
    role="Coding Agent",
    goal="Generate high quality code",
    backstory="An experienced coder who can generate high quality python code.",
    tools=[patronus_eval_tool],
    verbose=True,
)

# Example task to generate code
generate_code_task = Task(
    description="Create a simple program to generate the first N numbers in the Fibonacci sequence.",
    expected_output="Program that generates the first N numbers in the Fibonacci sequence.",
    agent=coding_agent,
)

# Create and run the crew
crew = Crew(agents=[coding_agent], tasks=[generate_code_task])
result = crew.kickoff()
```

## Parameters

### PatronusEvalTool

The `PatronusEvalTool` does not require any parameters during initialization. It automatically fetches available evaluators and criteria from the Patronus API.

### PatronusPredefinedCriteriaEvalTool

The `PatronusPredefinedCriteriaEvalTool` accepts the following parameters during initialization:

* **evaluators**: Required. A list of dictionaries containing the evaluator and criteria to use. For example: `[{"evaluator": "judge", "criteria": "contains-code"}]`.

### PatronusLocalEvaluatorTool

The `PatronusLocalEvaluatorTool` accepts the following parameters during initialization:

* **patronus\_client**: Required. The Patronus client instance.
* **evaluator**: Optional. The name of the registered local evaluator to use. Default is an empty string.
* **evaluated\_model\_gold\_answer**: Optional. The gold answer to use for evaluation. Default is an empty string.

## Usage

When using the Patronus evaluation tools, you provide the model input, output, and context, and the tool returns the evaluation results from the Patronus API.

For the `PatronusEvalTool` and `PatronusPredefinedCriteriaEvalTool`, the following parameters are required when calling the tool:

* **evaluated\_model\_input**: The agent's task description in simple text.
* **evaluated\_model\_output**: The agent's output of the task.
* **evaluated\_model\_retrieved\_context**: The agent's context.

For the `PatronusLocalEvaluatorTool`, the same parameters are required, but the evaluator and gold answer are specified during initialization.

## Conclusion

The Patronus evaluation tools provide a powerful way to evaluate and score model inputs and outputs using the Patronus AI platform. By enabling agents to evaluate their own outputs or the outputs of other agents, these tools can help improve the quality and reliability of CrewAI workflows.


# Portkey Integration
Source: https://docs.crewai.com/en/observability/portkey

How to use Portkey with CrewAI

<img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/main/Portkey-CrewAI.png" alt="Portkey CrewAI Header Image" width="70%" />

## Introduction

Portkey enhances CrewAI with production-readiness features, turning your experimental agent crews into robust systems by providing:

* **Complete observability** of every agent step, tool use, and interaction
* **Built-in reliability** with fallbacks, retries, and load balancing
* **Cost tracking and optimization** to manage your AI spend
* **Access to 200+ LLMs** through a single integration
* **Guardrails** to keep agent behavior safe and compliant
* **Version-controlled prompts** for consistent agent performance

### Installation & Setup

<Steps>
  <Step title="Install the required packages">
    ```bash
    pip install -U crewai portkey-ai
    ```
  </Step>

  <Step title="Generate API Key" icon="lock">
    Create a Portkey API key with optional budget/rate limits from the [Portkey dashboard](https://app.portkey.ai/). You can also attach configurations for reliability, caching, and more to this key. More on this later.
  </Step>

  <Step title="Configure CrewAI with Portkey">
    The integration is simple - you just need to update the LLM configuration in your CrewAI setup:

    ```python
    from crewai import LLM
    from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

    # Create an LLM instance with Portkey integration
    gpt_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",  # We are using a Virtual key, so this is a placeholder
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_LLM_VIRTUAL_KEY",
            trace_id="unique-trace-id",               # Optional, for request tracing
        )
    )

    #Use them in your Crew Agents like this:

    	@agent
    	def lead_market_analyst(self) -> Agent:
    		return Agent(
    			config=self.agents_config['lead_market_analyst'],
    			verbose=True,
    			memory=False,
    			llm=gpt_llm
    		)

    ```

    <Info>
      **What are Virtual Keys?** Virtual keys in Portkey securely store your LLM provider API keys (OpenAI, Anthropic, etc.) in an encrypted vault. They allow for easier key rotation and budget management. [Learn more about virtual keys here](https://portkey.ai/docs/product/ai-gateway/virtual-keys).
    </Info>
  </Step>
</Steps>

## Production Features

### 1. Enhanced Observability

Portkey provides comprehensive observability for your CrewAI agents, helping you understand exactly what's happening during each execution.

<Tabs>
  <Tab title="Traces">
    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20Product%2011.1.webp" />
    </Frame>

    Traces provide a hierarchical view of your crew's execution, showing the sequence of LLM calls, tool invocations, and state transitions.

    ```python
    # Add trace_id to enable hierarchical tracing in Portkey
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
            trace_id="unique-session-id"  # Add unique trace ID
        )
    )
    ```
  </Tab>

  <Tab title="Logs">
    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20Portkey%20Docs%20Metadata.png" />
    </Frame>

    Portkey logs every interaction with LLMs, including:

    * Complete request and response payloads
    * Latency and token usage metrics
    * Cost calculations
    * Tool calls and function executions

    All logs can be filtered by metadata, trace IDs, models, and more, making it easy to debug specific crew runs.
  </Tab>

  <Tab title="Metrics & Dashboards">
    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20Dashboard.png" />
    </Frame>

    Portkey provides built-in dashboards that help you:

    * Track cost and token usage across all crew runs
    * Analyze performance metrics like latency and success rates
    * Identify bottlenecks in your agent workflows
    * Compare different crew configurations and LLMs

    You can filter and segment all metrics by custom metadata to analyze specific crew types, user groups, or use cases.
  </Tab>

  <Tab title="Metadata Filtering">
    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/Metadata%20Filters%20from%20CrewAI.png" alt="Analytics with metadata filters" />
    </Frame>

    Add custom metadata to your CrewAI LLM configuration to enable powerful filtering and segmentation:

    ```python
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
            metadata={
                "crew_type": "research_crew",
                "environment": "production",
                "_user": "user_123",   # Special _user field for user analytics
                "request_source": "mobile_app"
            }
        )
    )
    ```

    This metadata can be used to filter logs, traces, and metrics on the Portkey dashboard, allowing you to analyze specific crew runs, users, or environments.
  </Tab>
</Tabs>

### 2. Reliability - Keep Your Crews Running Smoothly

When running crews in production, things can go wrong - API rate limits, network issues, or provider outages. Portkey's reliability features ensure your agents keep running smoothly even when problems occur.

It's simple to enable fallback in your CrewAI setup by using a Portkey Config:

```python
from crewai import LLM
from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

# Create LLM with fallback configuration
portkey_llm = LLM(
    model="gpt-4o",
    max_tokens=1000,
    base_url=PORTKEY_GATEWAY_URL,
    api_key="dummy",
    extra_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        config={
            "strategy": {
                "mode": "fallback"
            },
            "targets": [
                {
                    "provider": "openai",
                    "api_key": "YOUR_OPENAI_API_KEY",
                    "override_params": {"model": "gpt-4o"}
                },
                {
                    "provider": "anthropic",
                    "api_key": "YOUR_ANTHROPIC_API_KEY",
                    "override_params": {"model": "claude-3-opus-20240229"}
                }
            ]
        }
    )
)

# Use this LLM configuration with your agents
```

This configuration will automatically try Claude if the GPT-4o request fails, ensuring your crew can continue operating.

<CardGroup cols="2">
  <Card title="Automatic Retries" icon="rotate" href="https://portkey.ai/docs/product/ai-gateway/automatic-retries">
    Handles temporary failures automatically. If an LLM call fails, Portkey will retry the same request for the specified number of times - perfect for rate limits or network blips.
  </Card>

  <Card title="Request Timeouts" icon="clock" href="https://portkey.ai/docs/product/ai-gateway/request-timeouts">
    Prevent your agents from hanging. Set timeouts to ensure you get responses (or can fail gracefully) within your required timeframes.
  </Card>

  <Card title="Conditional Routing" icon="route" href="https://portkey.ai/docs/product/ai-gateway/conditional-routing">
    Send different requests to different providers. Route complex reasoning to GPT-4, creative tasks to Claude, and quick responses to Gemini based on your needs.
  </Card>

  <Card title="Fallbacks" icon="shield" href="https://portkey.ai/docs/product/ai-gateway/fallbacks">
    Keep running even if your primary provider fails. Automatically switch to backup providers to maintain availability.
  </Card>

  <Card title="Load Balancing" icon="scale-balanced" href="https://portkey.ai/docs/product/ai-gateway/load-balancing">
    Spread requests across multiple API keys or providers. Great for high-volume crew operations and staying within rate limits.
  </Card>
</CardGroup>

### 3. Prompting in CrewAI

Portkey's Prompt Engineering Studio helps you create, manage, and optimize the prompts used in your CrewAI agents. Instead of hardcoding prompts or instructions, use Portkey's prompt rendering API to dynamically fetch and apply your versioned prompts.

<Frame caption="Manage prompts in Portkey's Prompt Library">
  ![Prompt Playground Interface](https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20Portkey%20Docs.webp)
</Frame>

<Tabs>
  <Tab title="Prompt Playground">
    Prompt Playground is a place to compare, test and deploy perfect prompts for your AI application. It's where you experiment with different models, test variables, compare outputs, and refine your prompt engineering strategy before deploying to production. It allows you to:

    1. Iteratively develop prompts before using them in your agents
    2. Test prompts with different variables and models
    3. Compare outputs between different prompt versions
    4. Collaborate with team members on prompt development

    This visual environment makes it easier to craft effective prompts for each step in your CrewAI agents' workflow.
  </Tab>

  <Tab title="Using Prompt Templates">
    The Prompt Render API retrieves your prompt templates with all parameters configured:

    ```python
    from crewai import Agent, LLM
    from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL, Portkey

    # Initialize Portkey admin client
    portkey_admin = Portkey(api_key="YOUR_PORTKEY_API_KEY")

    # Retrieve prompt using the render API
    prompt_data = portkey_client.prompts.render(
        prompt_id="YOUR_PROMPT_ID",
        variables={
            "agent_role": "Senior Research Scientist",
        }
    )

    backstory_agent_prompt=prompt_data.data.messages[0]["content"]


    # Set up LLM with Portkey integration
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_OPENAI_VIRTUAL_KEY"
        )
    )

    # Create agent using the rendered prompt
    researcher = Agent(
        role="Senior Research Scientist",
        goal="Discover groundbreaking insights about the assigned topic",
        backstory=backstory_agent,  # Use the rendered prompt
        verbose=True,
        llm=portkey_llm
    )
    ```
  </Tab>

  <Tab title="Prompt Versioning">
    You can:

    * Create multiple versions of the same prompt
    * Compare performance between versions
    * Roll back to previous versions if needed
    * Specify which version to use in your code:

    ```python
    # Use a specific prompt version
    prompt_data = portkey_admin.prompts.render(
        prompt_id="YOUR_PROMPT_ID@version_number",
        variables={
            "agent_role": "Senior Research Scientist",
            "agent_goal": "Discover groundbreaking insights"
        }
    )
    ```
  </Tab>

  <Tab title="Mustache Templating for variables">
    Portkey prompts use Mustache-style templating for easy variable substitution:

    ```
    You are a {{agent_role}} with expertise in {{domain}}.

    Your mission is to {{agent_goal}} by leveraging your knowledge
    and experience in the field.

    Always maintain a {{tone}} tone and focus on providing {{focus_area}}.
    ```

    When rendering, simply pass the variables:

    ```python
    prompt_data = portkey_admin.prompts.render(
        prompt_id="YOUR_PROMPT_ID",
        variables={
            "agent_role": "Senior Research Scientist",
            "domain": "artificial intelligence",
            "agent_goal": "discover groundbreaking insights",
            "tone": "professional",
            "focus_area": "practical applications"
        }
    )
    ```
  </Tab>
</Tabs>

<Card title="Prompt Engineering Studio" icon="wand-magic-sparkles" href="https://portkey.ai/docs/product/prompt-library">
  Learn more about Portkey's prompt management features
</Card>

### 4. Guardrails for Safe Crews

Guardrails ensure your CrewAI agents operate safely and respond appropriately in all situations.

**Why Use Guardrails?**

CrewAI agents can experience various failure modes:

* Generating harmful or inappropriate content
* Leaking sensitive information like PII
* Hallucinating incorrect information
* Generating outputs in incorrect formats

Portkey's guardrails add protections for both inputs and outputs.

**Implementing Guardrails**

```python
from crewai import Agent, LLM
from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

# Create LLM with guardrails
portkey_llm = LLM(
    model="gpt-4o",
    base_url=PORTKEY_GATEWAY_URL,
    api_key="dummy",
    extra_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
        config={
            "input_guardrails": ["guardrails-id-xxx", "guardrails-id-yyy"],
            "output_guardrails": ["guardrails-id-zzz"]
        }
    )
)

# Create agent with guardrailed LLM
researcher = Agent(
    role="Senior Research Scientist",
    goal="Discover groundbreaking insights about the assigned topic",
    backstory="You are an expert researcher with deep domain knowledge.",
    verbose=True,
    llm=portkey_llm
)
```

Portkey's guardrails can:

* Detect and redact PII in both inputs and outputs
* Filter harmful or inappropriate content
* Validate response formats against schemas
* Check for hallucinations against ground truth
* Apply custom business logic and rules

<Card title="Learn More About Guardrails" icon="shield-check" href="https://portkey.ai/docs/product/guardrails">
  Explore Portkey's guardrail features to enhance agent safety
</Card>

### 5. User Tracking with Metadata

Track individual users through your CrewAI agents using Portkey's metadata system.

**What is Metadata in Portkey?**

Metadata allows you to associate custom data with each request, enabling filtering, segmentation, and analytics. The special `_user` field is specifically designed for user tracking.

```python
from crewai import Agent, LLM
from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

# Configure LLM with user tracking
portkey_llm = LLM(
    model="gpt-4o",
    base_url=PORTKEY_GATEWAY_URL,
    api_key="dummy",
    extra_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
        metadata={
            "_user": "user_123",  # Special _user field for user analytics
            "user_tier": "premium",
            "user_company": "Acme Corp",
            "session_id": "abc-123"
        }
    )
)

# Create agent with tracked LLM
researcher = Agent(
    role="Senior Research Scientist",
    goal="Discover groundbreaking insights about the assigned topic",
    backstory="You are an expert researcher with deep domain knowledge.",
    verbose=True,
    llm=portkey_llm
)
```

**Filter Analytics by User**

With metadata in place, you can filter analytics by user and analyze performance metrics on a per-user basis:

<Frame caption="Filter analytics by user">
  <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/Metadata%20Filters%20from%20CrewAI.png" />
</Frame>

This enables:

* Per-user cost tracking and budgeting
* Personalized user analytics
* Team or organization-level metrics
* Environment-specific monitoring (staging vs. production)

<Card title="Learn More About Metadata" icon="tags" href="https://portkey.ai/docs/product/observability/metadata">
  Explore how to use custom metadata to enhance your analytics
</Card>

### 6. Caching for Efficient Crews

Implement caching to make your CrewAI agents more efficient and cost-effective:

<Tabs>
  <Tab title="Simple Caching">
    ```python
    from crewai import Agent, LLM
    from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

    # Configure LLM with simple caching
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
            config={
                "cache": {
                    "mode": "simple"
                }
            }
        )
    )

    # Create agent with cached LLM
    researcher = Agent(
        role="Senior Research Scientist",
        goal="Discover groundbreaking insights about the assigned topic",
        backstory="You are an expert researcher with deep domain knowledge.",
        verbose=True,
        llm=portkey_llm
    )
    ```

    Simple caching performs exact matches on input prompts, caching identical requests to avoid redundant model executions.
  </Tab>

  <Tab title="Semantic Caching">
    ```python
    from crewai import Agent, LLM
    from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

    # Configure LLM with semantic caching
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
            config={
                "cache": {
                    "mode": "semantic"
                }
            }
        )
    )

    # Create agent with semantically cached LLM
    researcher = Agent(
        role="Senior Research Scientist",
        goal="Discover groundbreaking insights about the assigned topic",
        backstory="You are an expert researcher with deep domain knowledge.",
        verbose=True,
        llm=portkey_llm
    )
    ```

    Semantic caching considers the contextual similarity between input requests, caching responses for semantically similar inputs.
  </Tab>
</Tabs>

### 7. Model Interoperability

CrewAI supports multiple LLM providers, and Portkey extends this capability by providing access to over 200 LLMs through a unified interface. You can easily switch between different models without changing your core agent logic:

```python
from crewai import Agent, LLM
from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

# Set up LLMs with different providers
openai_llm = LLM(
    model="gpt-4o",
    base_url=PORTKEY_GATEWAY_URL,
    api_key="dummy",
    extra_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        virtual_key="YOUR_OPENAI_VIRTUAL_KEY"
    )
)

anthropic_llm = LLM(
    model="claude-3-5-sonnet-latest",
    max_tokens=1000,
    base_url=PORTKEY_GATEWAY_URL,
    api_key="dummy",
    extra_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        virtual_key="YOUR_ANTHROPIC_VIRTUAL_KEY"
    )
)

# Choose which LLM to use for each agent based on your needs
researcher = Agent(
    role="Senior Research Scientist",
    goal="Discover groundbreaking insights about the assigned topic",
    backstory="You are an expert researcher with deep domain knowledge.",
    verbose=True,
    llm=openai_llm  # Use anthropic_llm for Anthropic
)
```

Portkey provides access to LLMs from providers including:

* OpenAI (GPT-4o, GPT-4 Turbo, etc.)
* Anthropic (Claude 3.5 Sonnet, Claude 3 Opus, etc.)
* Mistral AI (Mistral Large, Mistral Medium, etc.)
* Google Vertex AI (Gemini 1.5 Pro, etc.)
* Cohere (Command, Command-R, etc.)
* AWS Bedrock (Claude, Titan, etc.)
* Local/Private Models

<Card title="Supported Providers" icon="server" href="https://portkey.ai/docs/integrations/llms">
  See the full list of LLM providers supported by Portkey
</Card>

## Set Up Enterprise Governance for CrewAI

**Why Enterprise Governance?**
If you are using CrewAI inside your organization, you need to consider several governance aspects:

* **Cost Management**: Controlling and tracking AI spending across teams
* **Access Control**: Managing which teams can use specific models
* **Usage Analytics**: Understanding how AI is being used across the organization
* **Security & Compliance**: Maintaining enterprise security standards
* **Reliability**: Ensuring consistent service across all users

Portkey adds a comprehensive governance layer to address these enterprise needs. Let's implement these controls step by step.

<Steps>
  <Step title="Create Virtual Key">
    Virtual Keys are Portkey's secure way to manage your LLM provider API keys. They provide essential controls like:

    * Budget limits for API usage
    * Rate limiting capabilities
    * Secure API key storage

    To create a virtual key:
    Go to [Virtual Keys](https://app.portkey.ai/virtual-keys) in the Portkey App. Save and copy the virtual key ID

    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/Virtual%20Key%20from%20Portkey%20Docs.png" width="500" />
    </Frame>

    <Note>
      Save your virtual key ID - you'll need it for the next step.
    </Note>
  </Step>

  <Step title="Create Default Config">
    Configs in Portkey define how your requests are routed, with features like advanced routing, fallbacks, and retries.

    To create your config:

    1. Go to [Configs](https://app.portkey.ai/configs) in Portkey dashboard
    2. Create new config with:
       ```json
       {
           "virtual_key": "YOUR_VIRTUAL_KEY_FROM_STEP1",
          	"override_params": {
             "model": "gpt-4o" // Your preferred model name
           }
       }
       ```
    3. Save and note the Config name for the next step

    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20Portkey%20Docs%20Config.png" width="500" />
    </Frame>
  </Step>

  <Step title="Configure Portkey API Key">
    Now create a Portkey API key and attach the config you created in Step 2:

    1. Go to [API Keys](https://app.portkey.ai/api-keys) in Portkey and Create new API key
    2. Select your config from `Step 2`
    3. Generate and save your API key

    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20API%20Key.png" width="500" />
    </Frame>
  </Step>

  <Step title="Connect to CrewAI">
    After setting up your Portkey API key with the attached config, connect it to your CrewAI agents:

    ```python
    from crewai import Agent, LLM
    from portkey_ai import PORTKEY_GATEWAY_URL

    # Configure LLM with your API key
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="YOUR_PORTKEY_API_KEY"
    )

    # Create agent with Portkey-enabled LLM
    researcher = Agent(
        role="Senior Research Scientist",
        goal="Discover groundbreaking insights about the assigned topic",
        backstory="You are an expert researcher with deep domain knowledge.",
        verbose=True,
        llm=portkey_llm
    )
    ```
  </Step>
</Steps>

<AccordionGroup>
  <Accordion title="Step 1: Implement Budget Controls & Rate Limits">
    ### Step 1: Implement Budget Controls & Rate Limits

    Virtual Keys enable granular control over LLM access at the team/department level. This helps you:

    * Set up [budget limits](https://portkey.ai/docs/product/ai-gateway/virtual-keys/budget-limits)
    * Prevent unexpected usage spikes using Rate limits
    * Track departmental spending

    #### Setting Up Department-Specific Controls:

    1. Navigate to [Virtual Keys](https://app.portkey.ai/virtual-keys) in Portkey dashboard
    2. Create new Virtual Key for each department with budget limits and rate limits
    3. Configure department-specific limits

    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/Virtual%20Key%20from%20Portkey%20Docs.png" width="500" />
    </Frame>
  </Accordion>

  <Accordion title="Step 2: Define Model Access Rules">
    ### Step 2: Define Model Access Rules

    As your AI usage scales, controlling which teams can access specific models becomes crucial. Portkey Configs provide this control layer with features like:

    #### Access Control Features:

    * **Model Restrictions**: Limit access to specific models
    * **Data Protection**: Implement guardrails for sensitive data
    * **Reliability Controls**: Add fallbacks and retry logic

    #### Example Configuration:

    Here's a basic configuration to route requests to OpenAI, specifically using GPT-4o:

    ```json
    {
    	"strategy": {
    		"mode": "single"
    	},
    	"targets": [
    		{
    			"virtual_key": "YOUR_OPENAI_VIRTUAL_KEY",
    			"override_params": {
    				"model": "gpt-4o"
    			}
    		}
    	]
    }
    ```

    Create your config on the [Configs page](https://app.portkey.ai/configs) in your Portkey dashboard.

    <Note>
      Configs can be updated anytime to adjust controls without affecting running applications.
    </Note>
  </Accordion>

  <Accordion title="Step 3: Implement Access Controls">
    ### Step 3: Implement Access Controls

    Create User-specific API keys that automatically:

    * Track usage per user/team with the help of virtual keys
    * Apply appropriate configs to route requests
    * Collect relevant metadata to filter logs
    * Enforce access permissions

    Create API keys through:

    * [Portkey App](https://app.portkey.ai/)
    * [API Key Management API](/en/api-reference/admin-api/control-plane/api-keys/create-api-key)

    Example using Python SDK:

    ```python
    from portkey_ai import Portkey

    portkey = Portkey(api_key="YOUR_ADMIN_API_KEY")

    api_key = portkey.api_keys.create(
        name="engineering-team",
        type="organisation",
        workspace_id="YOUR_WORKSPACE_ID",
        defaults={
            "config_id": "your-config-id",
            "metadata": {
                "environment": "production",
                "department": "engineering"
            }
        },
        scopes=["logs.view", "configs.read"]
    )
    ```

    For detailed key management instructions, see our [API Keys documentation](/en/api-reference/admin-api/control-plane/api-keys/create-api-key).
  </Accordion>

  <Accordion title="Step 4: Deploy & Monitor">
    ### Step 4: Deploy & Monitor

    After distributing API keys to your team members, your enterprise-ready CrewAI setup is ready to go. Each team member can now use their designated API keys with appropriate access levels and budget controls.

    Monitor usage in Portkey dashboard:

    * Cost tracking by department
    * Model usage patterns
    * Request volumes
    * Error rates
  </Accordion>
</AccordionGroup>

<Note>
  ### Enterprise Features Now Available

  **Your CrewAI integration now has:**

  * Departmental budget controls
  * Model access governance
  * Usage tracking & attribution
  * Security guardrails
  * Reliability features
</Note>

## Frequently Asked Questions

<AccordionGroup>
  <Accordion title="How does Portkey enhance CrewAI?">
    Portkey adds production-readiness to CrewAI through comprehensive observability (traces, logs, metrics), reliability features (fallbacks, retries, caching), and access to 200+ LLMs through a unified interface. This makes it easier to debug, optimize, and scale your agent applications.
  </Accordion>

  <Accordion title="Can I use Portkey with existing CrewAI applications?">
    Yes! Portkey integrates seamlessly with existing CrewAI applications. You just need to update your LLM configuration code with the Portkey-enabled version. The rest of your agent and crew code remains unchanged.
  </Accordion>

  <Accordion title="Does Portkey work with all CrewAI features?">
    Portkey supports all CrewAI features, including agents, tools, human-in-the-loop workflows, and all task process types (sequential, hierarchical, etc.). It adds observability and reliability without limiting any of the framework's functionality.
  </Accordion>

  <Accordion title="Can I track usage across multiple agents in a crew?">
    Yes, Portkey allows you to use a consistent `trace_id` across multiple agents in a crew to track the entire workflow. This is especially useful for complex crews where you want to understand the full execution path across multiple agents.
  </Accordion>

  <Accordion title="How do I filter logs and traces for specific crew runs?">
    Portkey allows you to add custom metadata to your LLM configuration, which you can then use for filtering. Add fields like `crew_name`, `crew_type`, or `session_id` to easily find and analyze specific crew executions.
  </Accordion>

  <Accordion title="Can I use my own API keys with Portkey?">
    Yes! Portkey uses your own API keys for the various LLM providers. It securely stores them as virtual keys, allowing you to easily manage and rotate keys without changing your code.
  </Accordion>
</AccordionGroup>

## Resources

<CardGroup cols="3">
  <Card title="CrewAI Docs" icon="book" href="https://docs.crewai.com/">
    <p>Official CrewAI documentation</p>
  </Card>

  <Card title="Book a Demo" icon="calendar" href="https://calendly.com/portkey-ai">
    <p>Get personalized guidance on implementing this integration</p>
  </Card>
</CardGroup>


# Weave Integration
Source: https://docs.crewai.com/en/observability/weave

Learn how to use Weights & Biases (W&B) Weave to track, experiment with, evaluate, and improve your CrewAI applications.

# Weave Overview

[Weights & Biases (W\&B) Weave](https://weave-docs.wandb.ai/) is a framework for tracking, experimenting with, evaluating, deploying, and improving LLM-based applications.

![Overview of W\&B Weave CrewAI tracing usage](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/weave-tracing.gif)

Weave provides comprehensive support for every stage of your CrewAI application development:

* **Tracing & Monitoring**: Automatically track LLM calls and application logic to debug and analyze production systems
* **Systematic Iteration**: Refine and iterate on prompts, datasets, and models
* **Evaluation**: Use custom or pre-built scorers to systematically assess and enhance agent performance
* **Guardrails**: Protect your agents with pre- and post-safeguards for content moderation and prompt safety

Weave automatically captures traces for your CrewAI applications, enabling you to monitor and analyze your agents' performance, interactions, and execution flow. This helps you build better evaluation datasets and optimize your agent workflows.

## Setup Instructions

<Steps>
  <Step title="Install required packages">
    ```shell
    pip install crewai weave
    ```
  </Step>

  <Step title="Set up W&B Account">
    Sign up for a [Weights & Biases account](https://wandb.ai) if you haven't already. You'll need this to view your traces and metrics.
  </Step>

  <Step title="Initialize Weave in Your Application">
    Add the following code to your application:

    ```python
    import weave

    # Initialize Weave with your project name
    weave.init(project_name="crewai_demo")
    ```

    After initialization, Weave will provide a URL where you can view your traces and metrics.
  </Step>

  <Step title="Create your Crews/Flows">
    ```python
    from crewai import Agent, Task, Crew, LLM, Process

    # Create an LLM with a temperature of 0 to ensure deterministic outputs
    llm = LLM(model="gpt-4o", temperature=0)

    # Create agents
    researcher = Agent(
        role='Research Analyst',
        goal='Find and analyze the best investment opportunities',
        backstory='Expert in financial analysis and market research',
        llm=llm,
        verbose=True,
        allow_delegation=False,
    )

    writer = Agent(
        role='Report Writer',
        goal='Write clear and concise investment reports',
        backstory='Experienced in creating detailed financial reports',
        llm=llm,
        verbose=True,
        allow_delegation=False,
    )

    # Create tasks
    research_task = Task(
        description='Deep research on the {topic}',
        expected_output='Comprehensive market data including key players, market size, and growth trends.',
        agent=researcher
    )

    writing_task = Task(
        description='Write a detailed report based on the research',
        expected_output='The report should be easy to read and understand. Use bullet points where applicable.',
        agent=writer
    )

    # Create a crew
    crew = Crew(
        agents=[researcher, writer],
        tasks=[research_task, writing_task],
        verbose=True,
        process=Process.sequential,
    )

    # Run the crew
    result = crew.kickoff(inputs={"topic": "AI in material science"})
    print(result)
    ```
  </Step>

  <Step title="View Traces in Weave">
    After running your CrewAI application, visit the Weave URL provided during initialization to view:

    * LLM calls and their metadata
    * Agent interactions and task execution flow
    * Performance metrics like latency and token usage
    * Any errors or issues that occurred during execution

    <Frame caption="Weave Tracing Dashboard">
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/weave-tracing.png" alt="Weave tracing example with CrewAI" />
    </Frame>
  </Step>
</Steps>

## Features

* Weave automatically captures all CrewAI operations: agent interactions and task executions; LLM calls with metadata and token usage; tool usage and results.
* The integration supports all CrewAI execution methods: `kickoff()`, `kickoff_for_each()`, `kickoff_async()`, and `kickoff_for_each_async()`.
* Automatic tracing of all [crewAI-tools](https://github.com/crewAIInc/crewAI-tools).
* Flow feature support with decorator patching (`@start`, `@listen`, `@router`, `@or_`, `@and_`).
* Track custom guardrails passed to CrewAI `Task` with `@weave.op()`.

For detailed information on what's supported, visit the [Weave CrewAI documentation](https://weave-docs.wandb.ai/guides/integrations/crewai/#getting-started-with-flow).

## Resources

* [üìò Weave Documentation](https://weave-docs.wandb.ai)
* [üìä Example Weave x CrewAI dashboard](https://wandb.ai/ayut/crewai_demo/weave/traces?cols=%7B%22wb_run_id%22%3Afalse%2C%22attributes.weave.client_version%22%3Afalse%2C%22attributes.weave.os_name%22%3Afalse%2C%22attributes.weave.os_release%22%3Afalse%2C%22attributes.weave.os_version%22%3Afalse%2C%22attributes.weave.source%22%3Afalse%2C%22attributes.weave.sys_version%22%3Afalse%7D\&peekPath=%2Fayut%2Fcrewai_demo%2Fcalls%2F0195c838-38cb-71a2-8a15-651ecddf9d89)
* [üê¶ X](https://x.com/weave_wb)


# Quickstart
Source: https://docs.crewai.com/en/quickstart

Build your first AI agent with CrewAI in under 5 minutes.

## Build your first CrewAI Agent

Let's create a simple crew that will help us `research` and `report` on the `latest AI developments` for a given topic or subject.

Before we proceed, make sure you have finished installing CrewAI.
If you haven't installed them yet, you can do so by following the [installation guide](/en/installation).

Follow the steps below to get Crewing! üö£‚Äç‚ôÇÔ∏è

<Steps>
  <Step title="Create your crew">
    Create a new crew project by running the following command in your terminal.
    This will create a new directory called `latest-ai-development` with the basic structure for your crew.

    <CodeGroup>
      ```shell Terminal
      crewai create crew latest-ai-development
      ```
    </CodeGroup>
  </Step>

  <Step title="Navigate to your new crew project">
    <CodeGroup>
      ```shell Terminal
      cd latest-ai-development
      ```
    </CodeGroup>
  </Step>

  <Step title="Modify your `agents.yaml` file">
    <Tip>
      You can also modify the agents as needed to fit your use case or copy and paste as is to your project.
      Any variable interpolated in your `agents.yaml` and `tasks.yaml` files like `{topic}` will be replaced by the value of the variable in the `main.py` file.
    </Tip>

    ```yaml agents.yaml
    # src/latest_ai_development/config/agents.yaml
    researcher:
      role: >
        {topic} Senior Data Researcher
      goal: >
        Uncover cutting-edge developments in {topic}
      backstory: >
        You're a seasoned researcher with a knack for uncovering the latest
        developments in {topic}. Known for your ability to find the most relevant
        information and present it in a clear and concise manner.

    reporting_analyst:
      role: >
        {topic} Reporting Analyst
      goal: >
        Create detailed reports based on {topic} data analysis and research findings
      backstory: >
        You're a meticulous analyst with a keen eye for detail. You're known for
        your ability to turn complex data into clear and concise reports, making
        it easy for others to understand and act on the information you provide.
    ```
  </Step>

  <Step title="Modify your `tasks.yaml` file">
    ````yaml tasks.yaml
    # src/latest_ai_development/config/tasks.yaml
    research_task:
      description: >
        Conduct a thorough research about {topic}
        Make sure you find any interesting and relevant information given
        the current year is 2025.
      expected_output: >
        A list with 10 bullet points of the most relevant information about {topic}
      agent: researcher

    reporting_task:
      description: >
        Review the context you got and expand each topic into a full section for a report.
        Make sure the report is detailed and contains any and all relevant information.
      expected_output: >
        A fully fledge reports with the mains topics, each with a full section of information.
        Formatted as markdown without '```'
      agent: reporting_analyst
      output_file: report.md
    ````
  </Step>

  <Step title="Modify your `crew.py` file">
    ```python crew.py
    # src/latest_ai_development/crew.py
    from crewai import Agent, Crew, Process, Task
    from crewai.project import CrewBase, agent, crew, task
    from crewai_tools import SerperDevTool
    from crewai.agents.agent_builder.base_agent import BaseAgent
    from typing import List

    @CrewBase
    class LatestAiDevelopmentCrew():
      """LatestAiDevelopment crew"""

      agents: List[BaseAgent]
      tasks: List[Task]

      @agent
      def researcher(self) -> Agent:
        return Agent(
          config=self.agents_config['researcher'], # type: ignore[index]
          verbose=True,
          tools=[SerperDevTool()]
        )

      @agent
      def reporting_analyst(self) -> Agent:
        return Agent(
          config=self.agents_config['reporting_analyst'], # type: ignore[index]
          verbose=True
        )

      @task
      def research_task(self) -> Task:
        return Task(
          config=self.tasks_config['research_task'], # type: ignore[index]
        )

      @task
      def reporting_task(self) -> Task:
        return Task(
          config=self.tasks_config['reporting_task'], # type: ignore[index]
          output_file='output/report.md' # This is the file that will be contain the final report.
        )

      @crew
      def crew(self) -> Crew:
        """Creates the LatestAiDevelopment crew"""
        return Crew(
          agents=self.agents, # Automatically created by the @agent decorator
          tasks=self.tasks, # Automatically created by the @task decorator
          process=Process.sequential,
          verbose=True,
        )
    ```
  </Step>

  <Step title="[Optional] Add before and after crew functions">
    ```python crew.py
    # src/latest_ai_development/crew.py
    from crewai import Agent, Crew, Process, Task
    from crewai.project import CrewBase, agent, crew, task, before_kickoff, after_kickoff
    from crewai_tools import SerperDevTool

    @CrewBase
    class LatestAiDevelopmentCrew():
      """LatestAiDevelopment crew"""

      @before_kickoff
      def before_kickoff_function(self, inputs):
        print(f"Before kickoff function with inputs: {inputs}")
        return inputs # You can return the inputs or modify them as needed

      @after_kickoff
      def after_kickoff_function(self, result):
        print(f"After kickoff function with result: {result}")
        return result # You can return the result or modify it as needed

      # ... remaining code
    ```
  </Step>

  <Step title="Feel free to pass custom inputs to your crew">
    For example, you can pass the `topic` input to your crew to customize the research and reporting.

    ```python main.py
    #!/usr/bin/env python
    # src/latest_ai_development/main.py
    import sys
    from latest_ai_development.crew import LatestAiDevelopmentCrew

    def run():
      """
      Run the crew.
      """
      inputs = {
        'topic': 'AI Agents'
      }
      LatestAiDevelopmentCrew().crew().kickoff(inputs=inputs)
    ```
  </Step>

  <Step title="Set your environment variables">
    Before running your crew, make sure you have the following keys set as environment variables in your `.env` file:

    * A [Serper.dev](https://serper.dev/) API key: `SERPER_API_KEY=YOUR_KEY_HERE`
    * The configuration for your choice of model, such as an API key. See the
      [LLM setup guide](/en/concepts/llms#setting-up-your-llm) to learn how to configure models from any provider.
  </Step>

  <Step title="Lock and install the dependencies">
    * Lock the dependencies and install them by using the CLI command:
      <CodeGroup>
        ```shell Terminal
        crewai install
        ```
      </CodeGroup>
    * If you have additional packages that you want to install, you can do so by running:
      <CodeGroup>
        ```shell Terminal
        uv add <package-name>
        ```
      </CodeGroup>
  </Step>

  <Step title="Run your crew">
    * To run your crew, execute the following command in the root of your project:
      <CodeGroup>
        ```bash Terminal
        crewai run
        ```
      </CodeGroup>
  </Step>

  <Step title="Enterprise Alternative: Create in Crew Studio">
    For CrewAI Enterprise users, you can create the same crew without writing code:

    1. Log in to your CrewAI Enterprise account (create a free account at [app.crewai.com](https://app.crewai.com))
    2. Open Crew Studio
    3. Type what is the automation you're trying to build
    4. Create your tasks visually and connect them in sequence
    5. Configure your inputs and click "Download Code" or "Deploy"

    ![Crew Studio Quickstart](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-studio-interface.png)

    <Card title="Try CrewAI Enterprise" icon="rocket" href="https://app.crewai.com">
      Start your free account at CrewAI Enterprise
    </Card>
  </Step>

  <Step title="View your final report">
    You should see the output in the console and the `report.md` file should be created in the root of your project with the final report.

    Here's an example of what the report should look like:

    <CodeGroup>
      ```markdown output/report.md
      # Comprehensive Report on the Rise and Impact of AI Agents in 2025

      ## 1. Introduction to AI Agents
      In 2025, Artificial Intelligence (AI) agents are at the forefront of innovation across various industries. As intelligent systems that can perform tasks typically requiring human cognition, AI agents are paving the way for significant advancements in operational efficiency, decision-making, and overall productivity within sectors like Human Resources (HR) and Finance. This report aims to detail the rise of AI agents, their frameworks, applications, and potential implications on the workforce.

      ## 2. Benefits of AI Agents
      AI agents bring numerous advantages that are transforming traditional work environments. Key benefits include:

      - **Task Automation**: AI agents can carry out repetitive tasks such as data entry, scheduling, and payroll processing without human intervention, greatly reducing the time and resources spent on these activities.
      - **Improved Efficiency**: By quickly processing large datasets and performing analyses that would take humans significantly longer, AI agents enhance operational efficiency. This allows teams to focus on strategic tasks that require higher-level thinking.
      - **Enhanced Decision-Making**: AI agents can analyze trends and patterns in data, provide insights, and even suggest actions, helping stakeholders make informed decisions based on factual data rather than intuition alone.

      ## 3. Popular AI Agent Frameworks
      Several frameworks have emerged to facilitate the development of AI agents, each with its own unique features and capabilities. Some of the most popular frameworks include:

      - **Autogen**: A framework designed to streamline the development of AI agents through automation of code generation.
      - **Semantic Kernel**: Focuses on natural language processing and understanding, enabling agents to comprehend user intentions better.
      - **Promptflow**: Provides tools for developers to create conversational agents that can navigate complex interactions seamlessly.
      - **Langchain**: Specializes in leveraging various APIs to ensure agents can access and utilize external data effectively.
      - **CrewAI**: Aimed at collaborative environments, CrewAI strengthens teamwork by facilitating communication through AI-driven insights.
      - **MemGPT**: Combines memory-optimized architectures with generative capabilities, allowing for more personalized interactions with users.

      These frameworks empower developers to build versatile and intelligent agents that can engage users, perform advanced analytics, and execute various tasks aligned with organizational goals.

      ## 4. AI Agents in Human Resources
      AI agents are revolutionizing HR practices by automating and optimizing key functions:

      - **Recruiting**: AI agents can screen resumes, schedule interviews, and even conduct initial assessments, thus accelerating the hiring process while minimizing biases.
      - **Succession Planning**: AI systems analyze employee performance data and potential, helping organizations identify future leaders and plan appropriate training.
      - **Employee Engagement**: Chatbots powered by AI can facilitate feedback loops between employees and management, promoting an open culture and addressing concerns promptly.

      As AI continues to evolve, HR departments leveraging these agents can realize substantial improvements in both efficiency and employee satisfaction.

      ## 5. AI Agents in Finance
      The finance sector is seeing extensive integration of AI agents that enhance financial practices:

      - **Expense Tracking**: Automated systems manage and monitor expenses, flagging anomalies and offering recommendations based on spending patterns.
      - **Risk Assessment**: AI models assess credit risk and uncover potential fraud by analyzing transaction data and behavioral patterns.
      - **Investment Decisions**: AI agents provide stock predictions and analytics based on historical data and current market conditions, empowering investors with informative insights.

      The incorporation of AI agents into finance is fostering a more responsive and risk-aware financial landscape.

      ## 6. Market Trends and Investments
      The growth of AI agents has attracted significant investment, especially amidst the rising popularity of chatbots and generative AI technologies. Companies and entrepreneurs are eager to explore the potential of these systems, recognizing their ability to streamline operations and improve customer engagement.

      Conversely, corporations like Microsoft are taking strides to integrate AI agents into their product offerings, with enhancements to their Copilot 365 applications. This strategic move emphasizes the importance of AI literacy in the modern workplace and indicates the stabilizing of AI agents as essential business tools.

      ## 7. Future Predictions and Implications
      Experts predict that AI agents will transform essential aspects of work life. As we look toward the future, several anticipated changes include:

      - Enhanced integration of AI agents across all business functions, creating interconnected systems that leverage data from various departmental silos for comprehensive decision-making.
      - Continued advancement of AI technologies, resulting in smarter, more adaptable agents capable of learning and evolving from user interactions.
      - Increased regulatory scrutiny to ensure ethical use, especially concerning data privacy and employee surveillance as AI agents become more prevalent.

      To stay competitive and harness the full potential of AI agents, organizations must remain vigilant about latest developments in AI technology and consider continuous learning and adaptation in their strategic planning.

      ## 8. Conclusion
      The emergence of AI agents is undeniably reshaping the workplace landscape in 5. With their ability to automate tasks, enhance efficiency, and improve decision-making, AI agents are critical in driving operational success. Organizations must embrace and adapt to AI developments to thrive in an increasingly digital business environment.
      ```
    </CodeGroup>
  </Step>
</Steps>

<Check>
  Congratulations!

  You have successfully set up your crew project and are ready to start building your own agentic workflows!
</Check>

### Note on Consistency in Naming

The names you use in your YAML files (`agents.yaml` and `tasks.yaml`) should match the method names in your Python code.
For example, you can reference the agent for specific tasks from `tasks.yaml` file.
This naming consistency allows CrewAI to automatically link your configurations with your code; otherwise, your task won't recognize the reference properly.

#### Example References

<Tip>
  Note how we use the same name for the agent in the `agents.yaml` (`email_summarizer`) file as the method name in the `crew.py` (`email_summarizer`) file.
</Tip>

```yaml agents.yaml
email_summarizer:
    role: >
      Email Summarizer
    goal: >
      Summarize emails into a concise and clear summary
    backstory: >
      You will create a 5 bullet point summary of the report
    llm: provider/model-id  # Add your choice of model here
```

<Tip>
  Note how we use the same name for the task in the `tasks.yaml` (`email_summarizer_task`) file as the method name in the `crew.py` (`email_summarizer_task`) file.
</Tip>

```yaml tasks.yaml
email_summarizer_task:
    description: >
      Summarize the email into a 5 bullet point summary
    expected_output: >
      A 5 bullet point summary of the email
    agent: email_summarizer
    context:
      - reporting_task
      - research_task
```

## Deploying Your Crew

The easiest way to deploy your crew to production is through [CrewAI Enterprise](http://app.crewai.com).

Watch this video tutorial for a step-by-step demonstration of deploying your crew to [CrewAI Enterprise](http://app.crewai.com) using the CLI.

<iframe width="100%" height="400" src="https://www.youtube.com/embed/3EqSV-CYDZA" title="CrewAI Deployment Guide" frameborder="0" style={{ borderRadius: '10px' }} allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

<CardGroup cols={2}>
  <Card title="Deploy on Enterprise" icon="rocket" href="http://app.crewai.com">
    Get started with CrewAI Enterprise and deploy your crew in a production environment with just a few clicks.
  </Card>

  <Card title="Join the Community" icon="comments" href="https://community.crewai.com">
    Join our open source community to discuss ideas, share your projects, and connect with other CrewAI developers.
  </Card>
</CardGroup>


# null
Source: https://docs.crewai.com/en/snippets/snippet-intro



One of the core principles of software development is DRY (Don't Repeat
Yourself). This is a principle that apply to documentation as
well. If you find yourself repeating the same content in multiple places, you
should consider creating a custom snippet to keep your content in sync.


# Telemetry
Source: https://docs.crewai.com/en/telemetry

Understanding the telemetry data collected by CrewAI and how it contributes to the enhancement of the library.

## Telemetry

<Note>
  By default, we collect no data that would be considered personal information under GDPR and other privacy regulations.
  We do collect Tool's names and Agent's roles, so be advised not to include any personal information in the tool's names or the Agent's roles.
  Because no personal information is collected, it's not necessary to worry about data residency.
  When `share_crew` is enabled, additional data is collected which may contain personal information if included by the user.
  Users should exercise caution when enabling this feature to ensure compliance with privacy regulations.
</Note>

CrewAI utilizes anonymous telemetry to gather usage statistics with the primary goal of enhancing the library.
Our focus is on improving and developing the features, integrations, and tools most utilized by our users.

It's pivotal to understand that by default, **NO personal data is collected** concerning prompts, task descriptions, agents' backstories or goals,
usage of tools, API calls, responses, any data processed by the agents, or secrets and environment variables.
When the `share_crew` feature is enabled, detailed data including task descriptions, agents' backstories or goals, and other specific attributes are collected
to provide deeper insights. This expanded data collection may include personal information if users have incorporated it into their crews or tasks.
Users should carefully consider the content of their crews and tasks before enabling `share_crew`.
Users can disable telemetry by setting the environment variable `CREWAI_DISABLE_TELEMETRY` to `true` or by setting `OTEL_SDK_DISABLED` to `true` (note that the latter disables all OpenTelemetry instrumentation globally).

### Examples:

```python
# Disable CrewAI telemetry only
os.environ['CREWAI_DISABLE_TELEMETRY'] = 'true'

# Disable all OpenTelemetry (including CrewAI)
os.environ['OTEL_SDK_DISABLED'] = 'true'
```

### Data Explanation:

| Defaulted | Data                                     | Reason and Specifics                                                                                                                                                                                                                                                                                             |
| --------- | ---------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Yes       | CrewAI and Python Version                | Tracks software versions. Example: CrewAI v1.2.3, Python 3.8.10. No personal data.                                                                                                                                                                                                                               |
| Yes       | Crew Metadata                            | Includes: randomly generated key and ID, process type (e.g., 'sequential', 'parallel'), boolean flag for memory usage (true/false), count of tasks, count of agents. All non-personal.                                                                                                                           |
| Yes       | Agent Data                               | Includes: randomly generated key and ID, role name (should not include personal info), boolean settings (verbose, delegation enabled, code execution allowed), max iterations, max RPM, max retry limit, LLM info (see LLM Attributes), list of tool names (should not include personal info). No personal data. |
| Yes       | Task Metadata                            | Includes: randomly generated key and ID, boolean execution settings (async\_execution, human\_input), associated agent's role and key, list of tool names. All non-personal.                                                                                                                                     |
| Yes       | Tool Usage Statistics                    | Includes: tool name (should not include personal info), number of usage attempts (integer), LLM attributes used. No personal data.                                                                                                                                                                               |
| Yes       | Test Execution Data                      | Includes: crew's randomly generated key and ID, number of iterations, model name used, quality score (float), execution time (in seconds). All non-personal.                                                                                                                                                     |
| Yes       | Task Lifecycle Data                      | Includes: creation and execution start/end times, crew and task identifiers. Stored as spans with timestamps. No personal data.                                                                                                                                                                                  |
| Yes       | LLM Attributes                           | Includes: name, model\_name, model, top\_k, temperature, and class name of the LLM. All technical, non-personal data.                                                                                                                                                                                            |
| Yes       | Crew Deployment attempt using crewAI CLI | Includes: The fact a deploy is being made and crew id, and if it's trying to pull logs, no other data.                                                                                                                                                                                                           |
| No        | Agent's Expanded Data                    | Includes: goal description, backstory text, i18n prompt file identifier. Users should ensure no personal info is included in text fields.                                                                                                                                                                        |
| No        | Detailed Task Information                | Includes: task description, expected output description, context references. Users should ensure no personal info is included in these fields.                                                                                                                                                                   |
| No        | Environment Information                  | Includes: platform, release, system, version, and CPU count. Example: 'Windows 10', 'x86\_64'. No personal data.                                                                                                                                                                                                 |
| No        | Crew and Task Inputs and Outputs         | Includes: input parameters and output results as non-identifiable data. Users should ensure no personal info is included.                                                                                                                                                                                        |
| No        | Comprehensive Crew Execution Data        | Includes: detailed logs of crew operations, all agents and tasks data, final output. All non-personal and technical in nature.                                                                                                                                                                                   |

<Note>
  "No" in the "Defaulted" column indicates that this data is only collected when `share_crew` is set to `true`.
</Note>

### Opt-In Further Telemetry Sharing

Users can choose to share their complete telemetry data by enabling the `share_crew` attribute to `True` in their crew configurations.
Enabling `share_crew` results in the collection of detailed crew and task execution data, including `goal`, `backstory`, `context`, and `output` of tasks.
This enables a deeper insight into usage patterns.

<Warning>
  If you enable `share_crew`, the collected data may include personal information if it has been incorporated into crew configurations, task descriptions, or outputs.
  Users should carefully review their data and ensure compliance with GDPR and other applicable privacy regulations before enabling this feature.
</Warning>


# AI Mind Tool
Source: https://docs.crewai.com/en/tools/ai-ml/aimindtool

The `AIMindTool` is designed to query data sources in natural language.

# `AIMindTool`

## Description

The `AIMindTool` is a wrapper around [AI-Minds](https://mindsdb.com/minds) provided by [MindsDB](https://mindsdb.com/). It allows you to query data sources in natural language by simply configuring their connection parameters. This tool is useful when you need answers to questions from your data stored in various data sources including PostgreSQL, MySQL, MariaDB, ClickHouse, Snowflake, and Google BigQuery.

Minds are AI systems that work similarly to large language models (LLMs) but go beyond by answering any question from any data. This is accomplished by:

* Selecting the most relevant data for an answer using parametric search
* Understanding the meaning and providing responses within the correct context through semantic search
* Delivering precise answers by analyzing data and using machine learning (ML) models

## Installation

To incorporate this tool into your project, you need to install the Minds SDK:

```shell
uv add minds-sdk
```

## Steps to Get Started

To effectively use the `AIMindTool`, follow these steps:

1. **Package Installation**: Confirm that the `crewai[tools]` and `minds-sdk` packages are installed in your Python environment.
2. **API Key Acquisition**: Sign up for a Minds account [here](https://mdb.ai/register), and obtain an API key.
3. **Environment Configuration**: Store your obtained API key in an environment variable named `MINDS_API_KEY` to facilitate its use by the tool.

## Example

The following example demonstrates how to initialize the tool and execute a query:

```python Code
from crewai_tools import AIMindTool

# Initialize the AIMindTool
aimind_tool = AIMindTool(
    datasources=[
        {
            "description": "house sales data",
            "engine": "postgres",
            "connection_data": {
                "user": "demo_user",
                "password": "demo_password",
                "host": "samples.mindsdb.com",
                "port": 5432,
                "database": "demo",
                "schema": "demo_data"
            },
            "tables": ["house_sales"]
        }
    ]
)

# Run a natural language query
result = aimind_tool.run("How many 3 bedroom houses were sold in 2008?")
print(result)
```

## Parameters

The `AIMindTool` accepts the following parameters:

* **api\_key**: Optional. Your Minds API key. If not provided, it will be read from the `MINDS_API_KEY` environment variable.
* **datasources**: A list of dictionaries, each containing the following keys:
  * **description**: A description of the data contained in the datasource.
  * **engine**: The engine (or type) of the datasource.
  * **connection\_data**: A dictionary containing the connection parameters for the datasource.
  * **tables**: A list of tables that the data source will use. This is optional and can be omitted if all tables in the data source are to be used.

A list of supported data sources and their connection parameters can be found [here](https://docs.mdb.ai/docs/data_sources).

## Agent Integration Example

Here's how to integrate the `AIMindTool` with a CrewAI agent:

```python Code
from crewai import Agent
from crewai.project import agent
from crewai_tools import AIMindTool

# Initialize the tool
aimind_tool = AIMindTool(
    datasources=[
        {
            "description": "sales data",
            "engine": "postgres",
            "connection_data": {
                "user": "your_user",
                "password": "your_password",
                "host": "your_host",
                "port": 5432,
                "database": "your_db",
                "schema": "your_schema"
            },
            "tables": ["sales"]
        }
    ]
)

# Define an agent with the AIMindTool
@agent
def data_analyst(self) -> Agent:
    return Agent(
        config=self.agents_config["data_analyst"],
        allow_delegation=False,
        tools=[aimind_tool]
    )
```

## Conclusion

The `AIMindTool` provides a powerful way to query your data sources using natural language, making it easier to extract insights without writing complex SQL queries. By connecting to various data sources and leveraging AI-Minds technology, this tool enables agents to access and analyze data efficiently.


# Code Interpreter
Source: https://docs.crewai.com/en/tools/ai-ml/codeinterpretertool

The `CodeInterpreterTool` is a powerful tool designed for executing Python 3 code within a secure, isolated environment.

# `CodeInterpreterTool`

## Description

The `CodeInterpreterTool` enables CrewAI agents to execute Python 3 code that they generate autonomously. This functionality is particularly valuable as it allows agents to create code, execute it, obtain the results, and utilize that information to inform subsequent decisions and actions.

There are several ways to use this tool:

### Docker Container (Recommended)

This is the primary option. The code runs in a secure, isolated Docker container, ensuring safety regardless of its content.
Make sure Docker is installed and running on your system. If you don‚Äôt have it, you can install it from [here](https://docs.docker.com/get-docker/).

### Sandbox environment

If Docker is unavailable ‚Äî either not installed or not accessible for any reason ‚Äî the code will be executed in a restricted Python environment - called sandbox.
This environment is very limited, with strict restrictions on many modules and built-in functions.

### Unsafe Execution

**NOT RECOMMENDED FOR PRODUCTION**
This mode allows execution of any Python code, including dangerous calls to `sys, os..` and similar modules. [Check out](/en/tools/ai-ml/codeinterpretertool#enabling-unsafe-mode) how to enable this mode

## Logging

The `CodeInterpreterTool` logs the selected execution strategy to STDOUT

## Installation

To use this tool, you need to install the CrewAI tools package:

```shell
pip install 'crewai[tools]'
```

## Example

The following example demonstrates how to use the `CodeInterpreterTool` with a CrewAI agent:

```python Code
from crewai import Agent, Task, Crew, Process
from crewai_tools import CodeInterpreterTool

# Initialize the tool
code_interpreter = CodeInterpreterTool()

# Define an agent that uses the tool
programmer_agent = Agent(
    role="Python Programmer",
    goal="Write and execute Python code to solve problems",
    backstory="An expert Python programmer who can write efficient code to solve complex problems.",
    tools=[code_interpreter],
    verbose=True,
)

# Example task to generate and execute code
coding_task = Task(
    description="Write a Python function to calculate the Fibonacci sequence up to the 10th number and print the result.",
    expected_output="The Fibonacci sequence up to the 10th number.",
    agent=programmer_agent,
)

# Create and run the crew
crew = Crew(
    agents=[programmer_agent],
    tasks=[coding_task],
    verbose=True,
    process=Process.sequential,
)
result = crew.kickoff()
```

You can also enable code execution directly when creating an agent:

```python Code
from crewai import Agent

# Create an agent with code execution enabled
programmer_agent = Agent(
    role="Python Programmer",
    goal="Write and execute Python code to solve problems",
    backstory="An expert Python programmer who can write efficient code to solve complex problems.",
    allow_code_execution=True,  # This automatically adds the CodeInterpreterTool
    verbose=True,
)
```

### Enabling `unsafe_mode`

```python Code
from crewai_tools import CodeInterpreterTool

code = """
import os
os.system("ls -la")
"""

CodeInterpreterTool(unsafe_mode=True).run(code=code)
```

## Parameters

The `CodeInterpreterTool` accepts the following parameters during initialization:

* **user\_dockerfile\_path**: Optional. Path to a custom Dockerfile to use for the code interpreter container.
* **user\_docker\_base\_url**: Optional. URL to the Docker daemon to use for running the container.
* **unsafe\_mode**: Optional. Whether to run code directly on the host machine instead of in a Docker container or sandbox. Default is `False`. Use with caution!
* **default\_image\_tag**: Optional. Default Docker image tag. Default is `code-interpreter:latest`

When using the tool with an agent, the agent will need to provide:

* **code**: Required. The Python 3 code to execute.
* **libraries\_used**: Optional. A list of libraries used in the code that need to be installed. Default is `[]`

## Agent Integration Example

Here's a more detailed example of how to integrate the `CodeInterpreterTool` with a CrewAI agent:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import CodeInterpreterTool

# Initialize the tool
code_interpreter = CodeInterpreterTool()

# Define an agent that uses the tool
data_analyst = Agent(
    role="Data Analyst",
    goal="Analyze data using Python code",
    backstory="""You are an expert data analyst who specializes in using Python
    to analyze and visualize data. You can write efficient code to process
    large datasets and extract meaningful insights.""",
    tools=[code_interpreter],
    verbose=True,
)

# Create a task for the agent
analysis_task = Task(
    description="""
    Write Python code to:
    1. Generate a random dataset of 100 points with x and y coordinates
    2. Calculate the correlation coefficient between x and y
    3. Create a scatter plot of the data
    4. Print the correlation coefficient and save the plot as 'scatter.png'

    Make sure to handle any necessary imports and print the results.
    """,
    expected_output="The correlation coefficient and confirmation that the scatter plot has been saved.",
    agent=data_analyst,
)

# Run the task
crew = Crew(
    agents=[data_analyst],
    tasks=[analysis_task],
    verbose=True,
    process=Process.sequential,
)
result = crew.kickoff()
```

## Implementation Details

The `CodeInterpreterTool` uses Docker to create a secure environment for code execution:

```python Code
class CodeInterpreterTool(BaseTool):
    name: str = "Code Interpreter"
    description: str = "Interprets Python3 code strings with a final print statement."
    args_schema: Type[BaseModel] = CodeInterpreterSchema
    default_image_tag: str = "code-interpreter:latest"

    def _run(self, **kwargs) -> str:
        code = kwargs.get("code", self.code)
        libraries_used = kwargs.get("libraries_used", [])

        if self.unsafe_mode:
            return self.run_code_unsafe(code, libraries_used)
        else:
            return self.run_code_safety(code, libraries_used)
```

The tool performs the following steps:

1. Verifies that the Docker image exists or builds it if necessary
2. Creates a Docker container with the current working directory mounted
3. Installs any required libraries specified by the agent
4. Executes the Python code in the container
5. Returns the output of the code execution
6. Cleans up by stopping and removing the container

## Security Considerations

By default, the `CodeInterpreterTool` runs code in an isolated Docker container, which provides a layer of security. However, there are still some security considerations to keep in mind:

1. The Docker container has access to the current working directory, so sensitive files could potentially be accessed.
2. If the Docker container is unavailable and the code needs to run safely, it will be executed in a sandbox environment. For security reasons, installing arbitrary libraries is not allowed
3. The `unsafe_mode` parameter allows code to be executed directly on the host machine, which should only be used in trusted environments.
4. Be cautious when allowing agents to install arbitrary libraries, as they could potentially include malicious code.

## Conclusion

The `CodeInterpreterTool` provides a powerful way for CrewAI agents to execute Python code in a relatively secure environment. By enabling agents to write and run code, it significantly expands their problem-solving capabilities, especially for tasks involving data analysis, calculations, or other computational work. This tool is particularly useful for agents that need to perform complex operations that are more efficiently expressed in code than in natural language.


# DALL-E Tool
Source: https://docs.crewai.com/en/tools/ai-ml/dalletool

The `DallETool` is a powerful tool designed for generating images from textual descriptions.

# `DallETool`

## Description

This tool is used to give the Agent the ability to generate images using the DALL-E model. It is a transformer-based model that generates images from textual descriptions.
This tool allows the Agent to generate images based on the text input provided by the user.

## Installation

Install the crewai\_tools package

```shell
pip install 'crewai[tools]'
```

## Example

Remember that when using this tool, the text must be generated by the Agent itself. The text must be a description of the image you want to generate.

```python Code
from crewai_tools import DallETool

Agent(
    ...
    tools=[DallETool()],
)
```

If needed you can also tweak the parameters of the DALL-E model by passing them as arguments to the `DallETool` class. For example:

```python Code
from crewai_tools import DallETool

dalle_tool = DallETool(model="dall-e-3",
                       size="1024x1024",
                       quality="standard",
                       n=1)

Agent(
    ...
    tools=[dalle_tool]
)
```

The parameters are based on the `client.images.generate` method from the OpenAI API. For more information on the parameters,
please refer to the [OpenAI API documentation](https://platform.openai.com/docs/guides/images/introduction?lang=python).


# LangChain Tool
Source: https://docs.crewai.com/en/tools/ai-ml/langchaintool

The `LangChainTool` is a wrapper for LangChain tools and query engines.

## `LangChainTool`

<Info>
  CrewAI seamlessly integrates with LangChain's comprehensive [list of tools](https://python.langchain.com/docs/integrations/tools/), all of which can be used with CrewAI.
</Info>

```python Code
import os
from dotenv import load_dotenv
from crewai import Agent, Task, Crew
from crewai.tools import BaseTool
from pydantic import Field
from langchain_community.utilities import GoogleSerperAPIWrapper

# Set up your SERPER_API_KEY key in an .env file, eg:
# SERPER_API_KEY=<your api key>
load_dotenv()

search = GoogleSerperAPIWrapper()

class SearchTool(BaseTool):
    name: str = "Search"
    description: str = "Useful for search-based queries. Use this to find current information about markets, companies, and trends."
    search: GoogleSerperAPIWrapper = Field(default_factory=GoogleSerperAPIWrapper)

    def _run(self, query: str) -> str:
        """Execute the search query and return results"""
        try:
            return self.search.run(query)
        except Exception as e:
            return f"Error performing search: {str(e)}"

# Create Agents
researcher = Agent(
    role='Research Analyst',
    goal='Gather current market data and trends',
    backstory="""You are an expert research analyst with years of experience in
    gathering market intelligence. You're known for your ability to find
    relevant and up-to-date market information and present it in a clear,
    actionable format.""",
    tools=[SearchTool()],
    verbose=True
)

# rest of the code ...
```

## Conclusion

Tools are pivotal in extending the capabilities of CrewAI agents, enabling them to undertake a broad spectrum of tasks and collaborate effectively.
When building solutions with CrewAI, leverage both custom and existing tools to empower your agents and enhance the AI ecosystem. Consider utilizing error handling, caching mechanisms,
and the flexibility of tool arguments to optimize your agents' performance and capabilities.


# LlamaIndex Tool
Source: https://docs.crewai.com/en/tools/ai-ml/llamaindextool

The `LlamaIndexTool` is a wrapper for LlamaIndex tools and query engines.

# `LlamaIndexTool`

## Description

The `LlamaIndexTool` is designed to be a general wrapper around LlamaIndex tools and query engines, enabling you to leverage LlamaIndex resources in terms of RAG/agentic pipelines as tools to plug into CrewAI agents. This tool allows you to seamlessly integrate LlamaIndex's powerful data processing and retrieval capabilities into your CrewAI workflows.

## Installation

To use this tool, you need to install LlamaIndex:

```shell
uv add llama-index
```

## Steps to Get Started

To effectively use the `LlamaIndexTool`, follow these steps:

1. **Install LlamaIndex**: Install the LlamaIndex package using the command above.
2. **Set Up LlamaIndex**: Follow the [LlamaIndex documentation](https://docs.llamaindex.ai/) to set up a RAG/agent pipeline.
3. **Create a Tool or Query Engine**: Create a LlamaIndex tool or query engine that you want to use with CrewAI.

## Example

The following examples demonstrate how to initialize the tool from different LlamaIndex components:

### From a LlamaIndex Tool

```python Code
from crewai_tools import LlamaIndexTool
from crewai import Agent
from llama_index.core.tools import FunctionTool

# Example 1: Initialize from FunctionTool
def search_data(query: str) -> str:
    """Search for information in the data."""
    # Your implementation here
    return f"Results for: {query}"

# Create a LlamaIndex FunctionTool
og_tool = FunctionTool.from_defaults(
    search_data,
    name="DataSearchTool",
    description="Search for information in the data"
)

# Wrap it with LlamaIndexTool
tool = LlamaIndexTool.from_tool(og_tool)

# Define an agent that uses the tool
@agent
def researcher(self) -> Agent:
    '''
    This agent uses the LlamaIndexTool to search for information.
    '''
    return Agent(
        config=self.agents_config["researcher"],
        tools=[tool]
    )
```

### From LlamaHub Tools

```python Code
from crewai_tools import LlamaIndexTool
from llama_index.tools.wolfram_alpha import WolframAlphaToolSpec

# Initialize from LlamaHub Tools
wolfram_spec = WolframAlphaToolSpec(app_id="your_app_id")
wolfram_tools = wolfram_spec.to_tool_list()
tools = [LlamaIndexTool.from_tool(t) for t in wolfram_tools]
```

### From a LlamaIndex Query Engine

```python Code
from crewai_tools import LlamaIndexTool
from llama_index.core import VectorStoreIndex
from llama_index.core.readers import SimpleDirectoryReader

# Load documents
documents = SimpleDirectoryReader("./data").load_data()

# Create an index
index = VectorStoreIndex.from_documents(documents)

# Create a query engine
query_engine = index.as_query_engine()

# Create a LlamaIndexTool from the query engine
query_tool = LlamaIndexTool.from_query_engine(
    query_engine,
    name="Company Data Query Tool",
    description="Use this tool to lookup information in company documents"
)
```

## Class Methods

The `LlamaIndexTool` provides two main class methods for creating instances:

### from\_tool

Creates a `LlamaIndexTool` from a LlamaIndex tool.

```python Code
@classmethod
def from_tool(cls, tool: Any, **kwargs: Any) -> "LlamaIndexTool":
    # Implementation details
```

### from\_query\_engine

Creates a `LlamaIndexTool` from a LlamaIndex query engine.

```python Code
@classmethod
def from_query_engine(
    cls,
    query_engine: Any,
    name: Optional[str] = None,
    description: Optional[str] = None,
    return_direct: bool = False,
    **kwargs: Any,
) -> "LlamaIndexTool":
    # Implementation details
```

## Parameters

The `from_query_engine` method accepts the following parameters:

* **query\_engine**: Required. The LlamaIndex query engine to wrap.
* **name**: Optional. The name of the tool.
* **description**: Optional. The description of the tool.
* **return\_direct**: Optional. Whether to return the response directly. Default is `False`.

## Conclusion

The `LlamaIndexTool` provides a powerful way to integrate LlamaIndex's capabilities into CrewAI agents. By wrapping LlamaIndex tools and query engines, it enables agents to leverage sophisticated data retrieval and processing functionalities, enhancing their ability to work with complex information sources.


# Overview
Source: https://docs.crewai.com/en/tools/ai-ml/overview

Leverage AI services, generate images, process vision, and build intelligent systems

These tools integrate with AI and machine learning services to enhance your agents with advanced capabilities like image generation, vision processing, and intelligent code execution.

## **Available Tools**

<CardGroup cols={2}>
  <Card title="DALL-E Tool" icon="image" href="/en/tools/ai-ml/dalletool">
    Generate AI images using OpenAI's DALL-E model.
  </Card>

  <Card title="Vision Tool" icon="eye" href="/en/tools/ai-ml/visiontool">
    Process and analyze images with computer vision capabilities.
  </Card>

  <Card title="AI Mind Tool" icon="brain" href="/en/tools/ai-ml/aimindtool">
    Advanced AI reasoning and decision-making capabilities.
  </Card>

  <Card title="LlamaIndex Tool" icon="llama" href="/en/tools/ai-ml/llamaindextool">
    Build knowledge bases and retrieval systems with LlamaIndex.
  </Card>

  <Card title="LangChain Tool" icon="link" href="/en/tools/ai-ml/langchaintool">
    Integrate with LangChain for complex AI workflows.
  </Card>

  <Card title="RAG Tool" icon="database" href="/en/tools/ai-ml/ragtool">
    Implement Retrieval-Augmented Generation systems.
  </Card>

  <Card title="Code Interpreter Tool" icon="code" href="/en/tools/ai-ml/codeinterpretertool">
    Execute Python code and perform data analysis.
  </Card>
</CardGroup>

## **Common Use Cases**

* **Content Generation**: Create images, text, and multimedia content
* **Data Analysis**: Execute code and analyze complex datasets
* **Knowledge Systems**: Build RAG systems and intelligent databases
* **Computer Vision**: Process and understand visual content
* **AI Safety**: Implement content moderation and safety checks

```python
from crewai_tools import DallETool, VisionTool, CodeInterpreterTool

# Create AI tools
image_generator = DallETool()
vision_processor = VisionTool()
code_executor = CodeInterpreterTool()

# Add to your agent
agent = Agent(
    role="AI Specialist",
    tools=[image_generator, vision_processor, code_executor],
    goal="Create and analyze content using AI capabilities"
)
```


# RAG Tool
Source: https://docs.crewai.com/en/tools/ai-ml/ragtool

The `RagTool` is a dynamic knowledge base tool for answering questions using Retrieval-Augmented Generation.

# `RagTool`

## Description

The `RagTool` is designed to answer questions by leveraging the power of Retrieval-Augmented Generation (RAG) through EmbedChain.
It provides a dynamic knowledge base that can be queried to retrieve relevant information from various data sources.
This tool is particularly useful for applications that require access to a vast array of information and need to provide contextually relevant answers.

## Example

The following example demonstrates how to initialize the tool and use it with different data sources:

```python Code
from crewai_tools import RagTool

# Create a RAG tool with default settings
rag_tool = RagTool()

# Add content from a file
rag_tool.add(data_type="file", path="path/to/your/document.pdf")

# Add content from a web page
rag_tool.add(data_type="web_page", url="https://example.com")

# Define an agent with the RagTool
@agent
def knowledge_expert(self) -> Agent:
    '''
    This agent uses the RagTool to answer questions about the knowledge base.
    '''
    return Agent(
        config=self.agents_config["knowledge_expert"],
        allow_delegation=False,
        tools=[rag_tool]
    )
```

## Supported Data Sources

The `RagTool` can be used with a wide variety of data sources, including:

* üì∞ PDF files
* üìä CSV files
* üìÉ JSON files
* üìù Text
* üìÅ Directories/Folders
* üåê HTML Web pages
* üìΩÔ∏è YouTube Channels
* üì∫ YouTube Videos
* üìö Documentation websites
* üìù MDX files
* üìÑ DOCX files
* üßæ XML files
* üì¨ Gmail
* üìù GitHub repositories
* üêò PostgreSQL databases
* üê¨ MySQL databases
* ü§ñ Slack conversations
* üí¨ Discord messages
* üó®Ô∏è Discourse forums
* üìù Substack newsletters
* üêù Beehiiv content
* üíæ Dropbox files
* üñºÔ∏è Images
* ‚öôÔ∏è Custom data sources

## Parameters

The `RagTool` accepts the following parameters:

* **summarize**: Optional. Whether to summarize the retrieved content. Default is `False`.
* **adapter**: Optional. A custom adapter for the knowledge base. If not provided, an EmbedchainAdapter will be used.
* **config**: Optional. Configuration for the underlying EmbedChain App.

## Adding Content

You can add content to the knowledge base using the `add` method:

```python Code
# Add a PDF file
rag_tool.add(data_type="file", path="path/to/your/document.pdf")

# Add a web page
rag_tool.add(data_type="web_page", url="https://example.com")

# Add a YouTube video
rag_tool.add(data_type="youtube_video", url="https://www.youtube.com/watch?v=VIDEO_ID")

# Add a directory of files
rag_tool.add(data_type="directory", path="path/to/your/directory")
```

## Agent Integration Example

Here's how to integrate the `RagTool` with a CrewAI agent:

```python Code
from crewai import Agent
from crewai.project import agent
from crewai_tools import RagTool

# Initialize the tool and add content
rag_tool = RagTool()
rag_tool.add(data_type="web_page", url="https://docs.crewai.com")
rag_tool.add(data_type="file", path="company_data.pdf")

# Define an agent with the RagTool
@agent
def knowledge_expert(self) -> Agent:
    return Agent(
        config=self.agents_config["knowledge_expert"],
        allow_delegation=False,
        tools=[rag_tool]
    )
```

## Advanced Configuration

You can customize the behavior of the `RagTool` by providing a configuration dictionary:

```python Code
from crewai_tools import RagTool

# Create a RAG tool with custom configuration
config = {
    "app": {
        "name": "custom_app",
    },
    "llm": {
        "provider": "openai",
        "config": {
            "model": "gpt-4",
        }
    },
    "embedding_model": {
        "provider": "openai",
        "config": {
            "model": "text-embedding-ada-002"
        }
    },
    "vectordb": {
        "provider": "elasticsearch",
        "config": {
            "collection_name": "my-collection",
            "cloud_id": "deployment-name:xxxx",
            "api_key": "your-key",
            "verify_certs": False
        }
    },
    "chunker": {
        "chunk_size": 400,
        "chunk_overlap": 100,
        "length_function": "len",
        "min_chunk_size": 0
    }
}

rag_tool = RagTool(config=config, summarize=True)
```

The internal RAG tool utilizes the Embedchain adapter, allowing you to pass any configuration options that are supported by Embedchain.
You can refer to the [Embedchain documentation](https://docs.embedchain.ai/components/introduction) for details.
Make sure to review the configuration options available in the .yaml file.

## Conclusion

The `RagTool` provides a powerful way to create and query knowledge bases from various data sources. By leveraging Retrieval-Augmented Generation, it enables agents to access and retrieve relevant information efficiently, enhancing their ability to provide accurate and contextually appropriate responses.


# Vision Tool
Source: https://docs.crewai.com/en/tools/ai-ml/visiontool

The `VisionTool` is designed to extract text from images.

# `VisionTool`

## Description

This tool is used to extract text from images. When passed to the agent it will extract the text from the image and then use it to generate a response, report or any other output.
The URL or the PATH of the image should be passed to the Agent.

## Installation

Install the crewai\_tools package

```shell
pip install 'crewai[tools]'
```

## Usage

In order to use the VisionTool, the OpenAI API key should be set in the environment variable `OPENAI_API_KEY`.

```python Code
from crewai_tools import VisionTool

vision_tool = VisionTool()

@agent
def researcher(self) -> Agent:
    '''
    This agent uses the VisionTool to extract text from images.
    '''
    return Agent(
        config=self.agents_config["researcher"],
        allow_delegation=False,
        tools=[vision_tool]
    )
```

## Arguments

The VisionTool requires the following arguments:

| Argument             | Type     | Description                                                                      |
| :------------------- | :------- | :------------------------------------------------------------------------------- |
| **image\_path\_url** | `string` | **Mandatory**. The path to the image file from which text needs to be extracted. |


# Apify Actors
Source: https://docs.crewai.com/en/tools/automation/apifyactorstool

`ApifyActorsTool` lets you call Apify Actors to provide your CrewAI workflows with web scraping, crawling, data extraction, and web automation capabilities.

# `ApifyActorsTool`

Integrate [Apify Actors](https://apify.com/actors) into your CrewAI workflows.

## Description

The `ApifyActorsTool` connects [Apify Actors](https://apify.com/actors), cloud-based programs for web scraping and automation, to your CrewAI workflows.
Use any of the 4,000+ Actors on [Apify Store](https://apify.com/store) for use cases such as extracting data from social media, search engines, online maps, e-commerce sites, travel portals, or general websites.

For details, see the [Apify CrewAI integration](https://docs.apify.com/platform/integrations/crewai) in Apify documentation.

## Steps to get started

<Steps>
  <Step title="Install dependencies">
    Install `crewai[tools]` and `langchain-apify` using pip: `pip install 'crewai[tools]' langchain-apify`.
  </Step>

  <Step title="Obtain an Apify API token">
    Sign up to [Apify Console](https://console.apify.com/) and get your [Apify API token](https://console.apify.com/settings/integrations)..
  </Step>

  <Step title="Configure environment">
    Set your Apify API token as the `APIFY_API_TOKEN` environment variable to enable the tool's functionality.
  </Step>
</Steps>

## Usage example

Use the `ApifyActorsTool` manually to run the [RAG Web Browser Actor](https://apify.com/apify/rag-web-browser) to perform a web search:

```python
from crewai_tools import ApifyActorsTool

# Initialize the tool with an Apify Actor
tool = ApifyActorsTool(actor_name="apify/rag-web-browser")

# Run the tool with input parameters
results = tool.run(run_input={"query": "What is CrewAI?", "maxResults": 5})

# Process the results
for result in results:
    print(f"URL: {result['metadata']['url']}")
    print(f"Content: {result.get('markdown', 'N/A')[:100]}...")
```

### Expected output

Here is the output from running the code above:

```text
URL: https://www.example.com/crewai-intro
Content: CrewAI is a framework for building AI-powered workflows...
URL: https://docs.crewai.com/
Content: Official documentation for CrewAI...
```

The `ApifyActorsTool` automatically fetches the Actor definition and input schema from Apify using the provided `actor_name` and then constructs the tool description and argument schema. This means you need to specify only a valid `actor_name`, and the tool handles the rest when used with agents‚Äîno need to specify the `run_input`. Here's how it works:

```python
from crewai import Agent
from crewai_tools import ApifyActorsTool

rag_browser = ApifyActorsTool(actor_name="apify/rag-web-browser")

agent = Agent(
    role="Research Analyst",
    goal="Find and summarize information about specific topics",
    backstory="You are an experienced researcher with attention to detail",
    tools=[rag_browser],
)
```

You can run other Actors from [Apify Store](https://apify.com/store) simply by changing the `actor_name` and, when using it manually, adjusting the `run_input` based on the Actor input schema.

For an example of usage with agents, see the [CrewAI Actor template](https://apify.com/templates/python-crewai).

## Configuration

The `ApifyActorsTool` requires these inputs to work:

* **`actor_name`**
  The ID of the Apify Actor to run, e.g., `"apify/rag-web-browser"`. Browse all Actors on [Apify Store](https://apify.com/store).
* **`run_input`**
  A dictionary of input parameters for the Actor when running the tool manually.
  * For example, for the `apify/rag-web-browser` Actor: `{"query": "search term", "maxResults": 5}`
  * See the Actor's [input schema](https://apify.com/apify/rag-web-browser/input-schema) for the list of input parameters.

## Resources

* **[Apify](https://apify.com/)**: Explore the Apify platform.
* **[How to build an AI agent on Apify](https://blog.apify.com/how-to-build-an-ai-agent/)** - A complete step-by-step guide to creating, publishing, and monetizing AI agents on the Apify platform.
* **[RAG Web Browser Actor](https://apify.com/apify/rag-web-browser)**: A popular Actor for web search for LLMs.
* **[CrewAI Integration Guide](https://docs.apify.com/platform/integrations/crewai)**: Follow the official guide for integrating Apify and CrewAI.


# Composio Tool
Source: https://docs.crewai.com/en/tools/automation/composiotool

Composio provides 250+ production-ready tools for AI agents with flexible authentication management.

# `ComposioToolSet`

## Description

Composio is an integration platform that allows you to connect your AI agents to 250+ tools. Key features include:

* **Enterprise-Grade Authentication**: Built-in support for OAuth, API Keys, JWT with automatic token refresh
* **Full Observability**: Detailed tool usage logs, execution timestamps, and more

## Installation

To incorporate Composio tools into your project, follow the instructions below:

```shell
pip install composio-crewai
pip install crewai
```

After the installation is complete, either run `composio login` or export your composio API key as `COMPOSIO_API_KEY`. Get your Composio API key from [here](https://app.composio.dev)

## Example

The following example demonstrates how to initialize the tool and execute a github action:

1. Initialize Composio toolset

```python Code
from composio_crewai import ComposioToolSet, App, Action
from crewai import Agent, Task, Crew

toolset = ComposioToolSet()
```

2. Connect your GitHub account

<CodeGroup>
  ```shell CLI
  composio add github
  ```

  ```python Code
  request = toolset.initiate_connection(app=App.GITHUB)
  print(f"Open this URL to authenticate: {request.redirectUrl}")
  ```
</CodeGroup>

3. Get Tools

* Retrieving all the tools from an app (not recommended for production):

```python Code
tools = toolset.get_tools(apps=[App.GITHUB])
```

* Filtering tools based on tags:

```python Code
tag = "users"

filtered_action_enums = toolset.find_actions_by_tags(
    App.GITHUB,
    tags=[tag],
)

tools = toolset.get_tools(actions=filtered_action_enums)
```

* Filtering tools based on use case:

```python Code
use_case = "Star a repository on GitHub"

filtered_action_enums = toolset.find_actions_by_use_case(
    App.GITHUB, use_case=use_case, advanced=False
)

tools = toolset.get_tools(actions=filtered_action_enums)
```

<Tip>Set `advanced` to True to get actions for complex use cases</Tip>

* Using specific tools:

In this demo, we will use the `GITHUB_STAR_A_REPOSITORY_FOR_THE_AUTHENTICATED_USER` action from the GitHub app.

```python Code
tools = toolset.get_tools(
    actions=[Action.GITHUB_STAR_A_REPOSITORY_FOR_THE_AUTHENTICATED_USER]
)
```

Learn more about filtering actions [here](https://docs.composio.dev/patterns/tools/use-tools/use-specific-actions)

4. Define agent

```python Code
crewai_agent = Agent(
    role="GitHub Agent",
    goal="You take action on GitHub using GitHub APIs",
    backstory="You are AI agent that is responsible for taking actions on GitHub on behalf of users using GitHub APIs",
    verbose=True,
    tools=tools,
    llm= # pass an llm
)
```

5. Execute task

```python Code
task = Task(
    description="Star a repo composiohq/composio on GitHub",
    agent=crewai_agent,
    expected_output="Status of the operation",
)

crew = Crew(agents=[crewai_agent], tasks=[task])

crew.kickoff()
```

* More detailed list of tools can be found [here](https://app.composio.dev)


# MultiOn Tool
Source: https://docs.crewai.com/en/tools/automation/multiontool

The `MultiOnTool` empowers CrewAI agents with the capability to navigate and interact with the web through natural language instructions.

## Overview

The `MultiOnTool` is designed to wrap [MultiOn's](https://docs.multion.ai/welcome) web browsing capabilities, enabling CrewAI agents to control web browsers using natural language instructions. This tool facilitates seamless web browsing, making it an essential asset for projects requiring dynamic web data interaction and automation of web-based tasks.

## Installation

To use this tool, you need to install the MultiOn package:

```shell
uv add multion
```

You'll also need to install the MultiOn browser extension and enable API usage.

## Steps to Get Started

To effectively use the `MultiOnTool`, follow these steps:

1. **Install CrewAI**: Ensure that the `crewai[tools]` package is installed in your Python environment.
2. **Install and use MultiOn**: Follow [MultiOn documentation](https://docs.multion.ai/learn/browser-extension) for installing the MultiOn Browser Extension.
3. **Enable API Usage**: Click on the MultiOn extension in the extensions folder of your browser (not the hovering MultiOn icon on the web page) to open the extension configurations. Click the API Enabled toggle to enable the API.

## Example

The following example demonstrates how to initialize the tool and execute a web browsing task:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import MultiOnTool

# Initialize the tool
multion_tool = MultiOnTool(api_key="YOUR_MULTION_API_KEY", local=False)

# Define an agent that uses the tool
browser_agent = Agent(
    role="Browser Agent",
    goal="Control web browsers using natural language",
    backstory="An expert browsing agent.",
    tools=[multion_tool],
    verbose=True,
)

# Example task to search and summarize news
browse_task = Task(
    description="Summarize the top 3 trending AI News headlines",
    expected_output="A summary of the top 3 trending AI News headlines",
    agent=browser_agent,
)

# Create and run the crew
crew = Crew(agents=[browser_agent], tasks=[browse_task])
result = crew.kickoff()
```

## Parameters

The `MultiOnTool` accepts the following parameters during initialization:

* **api\_key**: Optional. Specifies the MultiOn API key. If not provided, it will look for the `MULTION_API_KEY` environment variable.
* **local**: Optional. Set to `True` to run the agent locally on your browser. Make sure the MultiOn browser extension is installed and API Enabled is checked. Default is `False`.
* **max\_steps**: Optional. Sets the maximum number of steps the MultiOn agent can take for a command. Default is `3`.

## Usage

When using the `MultiOnTool`, the agent will provide natural language instructions that the tool translates into web browsing actions. The tool returns the results of the browsing session along with a status.

```python Code
# Example of using the tool with an agent
browser_agent = Agent(
    role="Web Browser Agent",
    goal="Search for and summarize information from the web",
    backstory="An expert at finding and extracting information from websites.",
    tools=[multion_tool],
    verbose=True,
)

# Create a task for the agent
search_task = Task(
    description="Search for the latest AI news on TechCrunch and summarize the top 3 headlines",
    expected_output="A summary of the top 3 AI news headlines from TechCrunch",
    agent=browser_agent,
)

# Run the task
crew = Crew(agents=[browser_agent], tasks=[search_task])
result = crew.kickoff()
```

If the status returned is `CONTINUE`, the agent should be instructed to reissue the same instruction to continue execution.

## Implementation Details

The `MultiOnTool` is implemented as a subclass of `BaseTool` from CrewAI. It wraps the MultiOn client to provide web browsing capabilities:

```python Code
class MultiOnTool(BaseTool):
    """Tool to wrap MultiOn Browse Capabilities."""

    name: str = "Multion Browse Tool"
    description: str = """Multion gives the ability for LLMs to control web browsers using natural language instructions.
            If the status is 'CONTINUE', reissue the same instruction to continue execution
        """

    # Implementation details...

    def _run(self, cmd: str, *args: Any, **kwargs: Any) -> str:
        """
        Run the Multion client with the given command.

        Args:
            cmd (str): The detailed and specific natural language instruction for web browsing
            *args (Any): Additional arguments to pass to the Multion client
            **kwargs (Any): Additional keyword arguments to pass to the Multion client
        """
        # Implementation details...
```

## Conclusion

The `MultiOnTool` provides a powerful way to integrate web browsing capabilities into CrewAI agents. By enabling agents to interact with websites through natural language instructions, it opens up a wide range of possibilities for web-based tasks, from data collection and research to automated interactions with web services.


# Overview
Source: https://docs.crewai.com/en/tools/automation/overview

Automate workflows and integrate with external platforms and services

These tools enable your agents to automate workflows, integrate with external platforms, and connect with various third-party services for enhanced functionality.

## **Available Tools**

<CardGroup cols={2}>
  <Card title="Apify Actor Tool" icon="spider" href="/en/tools/automation/apifyactorstool">
    Run Apify actors for web scraping and automation tasks.
  </Card>

  <Card title="Composio Tool" icon="puzzle-piece" href="/en/tools/automation/composiotool">
    Integrate with hundreds of apps and services through Composio.
  </Card>

  <Card title="Multion Tool" icon="window-restore" href="/en/tools/automation/multiontool">
    Automate browser interactions and web-based workflows.
  </Card>
</CardGroup>

## **Common Use Cases**

* **Workflow Automation**: Automate repetitive tasks and processes
* **API Integration**: Connect with external APIs and services
* **Data Synchronization**: Sync data between different platforms
* **Process Orchestration**: Coordinate complex multi-step workflows
* **Third-party Services**: Leverage external tools and platforms

```python
from crewai_tools import ApifyActorTool, ComposioTool, MultiOnTool

# Create automation tools
apify_automation = ApifyActorTool()
platform_integration = ComposioTool()
browser_automation = MultiOnTool()

# Add to your agent
agent = Agent(
    role="Automation Specialist",
    tools=[apify_automation, platform_integration, browser_automation],
    goal="Automate workflows and integrate systems"
)
```

## **Integration Benefits**

* **Efficiency**: Reduce manual work through automation
* **Scalability**: Handle increased workloads automatically
* **Reliability**: Consistent execution of workflows
* **Connectivity**: Bridge different systems and platforms
* **Productivity**: Focus on high-value tasks while automation handles routine work


# Bedrock Invoke Agent Tool
Source: https://docs.crewai.com/en/tools/cloud-storage/bedrockinvokeagenttool

Enables CrewAI agents to invoke Amazon Bedrock Agents and leverage their capabilities within your workflows

# `BedrockInvokeAgentTool`

The `BedrockInvokeAgentTool` enables CrewAI agents to invoke Amazon Bedrock Agents and leverage their capabilities within your workflows.

## Installation

```bash
uv pip install 'crewai[tools]'
```

## Requirements

* AWS credentials configured (either through environment variables or AWS CLI)
* `boto3` and `python-dotenv` packages
* Access to Amazon Bedrock Agents

## Usage

Here's how to use the tool with a CrewAI agent:

```python {2, 4-8}
from crewai import Agent, Task, Crew
from crewai_tools.aws.bedrock.agents.invoke_agent_tool import BedrockInvokeAgentTool

# Initialize the tool
agent_tool = BedrockInvokeAgentTool(
    agent_id="your-agent-id",
    agent_alias_id="your-agent-alias-id"
)

# Create a CrewAI agent that uses the tool
aws_expert = Agent(
    role='AWS Service Expert',
    goal='Help users understand AWS services and quotas',
    backstory='I am an expert in AWS services and can provide detailed information about them.',
    tools=[agent_tool],
    verbose=True
)

# Create a task for the agent
quota_task = Task(
    description="Find out the current service quotas for EC2 in us-west-2 and explain any recent changes.",
    agent=aws_expert
)

# Create a crew with the agent
crew = Crew(
    agents=[aws_expert],
    tasks=[quota_task],
    verbose=2
)

# Run the crew
result = crew.kickoff()
print(result)
```

## Tool Arguments

| Argument             | Type   | Required | Default   | Description                                 |
| :------------------- | :----- | :------- | :-------- | :------------------------------------------ |
| **agent\_id**        | `str`  | Yes      | None      | The unique identifier of the Bedrock agent  |
| **agent\_alias\_id** | `str`  | Yes      | None      | The unique identifier of the agent alias    |
| **session\_id**      | `str`  | No       | timestamp | The unique identifier of the session        |
| **enable\_trace**    | `bool` | No       | False     | Whether to enable trace for debugging       |
| **end\_session**     | `bool` | No       | False     | Whether to end the session after invocation |
| **description**      | `str`  | No       | None      | Custom description for the tool             |

## Environment Variables

```bash
BEDROCK_AGENT_ID=your-agent-id           # Alternative to passing agent_id
BEDROCK_AGENT_ALIAS_ID=your-agent-alias-id # Alternative to passing agent_alias_id
AWS_REGION=your-aws-region               # Defaults to us-west-2
AWS_ACCESS_KEY_ID=your-access-key        # Required for AWS authentication
AWS_SECRET_ACCESS_KEY=your-secret-key    # Required for AWS authentication
```

## Advanced Usage

### Multi-Agent Workflow with Session Management

```python {2, 4-22}
from crewai import Agent, Task, Crew, Process
from crewai_tools.aws.bedrock.agents.invoke_agent_tool import BedrockInvokeAgentTool

# Initialize tools with session management
initial_tool = BedrockInvokeAgentTool(
    agent_id="your-agent-id",
    agent_alias_id="your-agent-alias-id",
    session_id="custom-session-id"
)

followup_tool = BedrockInvokeAgentTool(
    agent_id="your-agent-id",
    agent_alias_id="your-agent-alias-id",
    session_id="custom-session-id"
)

final_tool = BedrockInvokeAgentTool(
    agent_id="your-agent-id",
    agent_alias_id="your-agent-alias-id",
    session_id="custom-session-id",
    end_session=True
)

# Create agents for different stages
researcher = Agent(
    role='AWS Service Researcher',
    goal='Gather information about AWS services',
    backstory='I am specialized in finding detailed AWS service information.',
    tools=[initial_tool]
)

analyst = Agent(
    role='Service Compatibility Analyst',
    goal='Analyze service compatibility and requirements',
    backstory='I analyze AWS services for compatibility and integration possibilities.',
    tools=[followup_tool]
)

summarizer = Agent(
    role='Technical Documentation Writer',
    goal='Create clear technical summaries',
    backstory='I specialize in creating clear, concise technical documentation.',
    tools=[final_tool]
)

# Create tasks
research_task = Task(
    description="Find all available AWS services in us-west-2 region.",
    agent=researcher
)

analysis_task = Task(
    description="Analyze which services support IPv6 and their implementation requirements.",
    agent=analyst
)

summary_task = Task(
    description="Create a summary of IPv6-compatible services and their key features.",
    agent=summarizer
)

# Create a crew with the agents and tasks
crew = Crew(
    agents=[researcher, analyst, summarizer],
    tasks=[research_task, analysis_task, summary_task],
    process=Process.sequential,
    verbose=2
)

# Run the crew
result = crew.kickoff()
```

## Use Cases

### Hybrid Multi-Agent Collaborations

* Create workflows where CrewAI agents collaborate with managed Bedrock agents running as services in AWS
* Enable scenarios where sensitive data processing happens within your AWS environment while other agents operate externally
* Bridge on-premises CrewAI agents with cloud-based Bedrock agents for distributed intelligence workflows

### Data Sovereignty and Compliance

* Keep data-sensitive agentic workflows within your AWS environment while allowing external CrewAI agents to orchestrate tasks
* Maintain compliance with data residency requirements by processing sensitive information only within your AWS account
* Enable secure multi-agent collaborations where some agents cannot access your organization's private data

### Seamless AWS Service Integration

* Access any AWS service through Amazon Bedrock Actions without writing complex integration code
* Enable CrewAI agents to interact with AWS services through natural language requests
* Leverage pre-built Bedrock agent capabilities to interact with AWS services like Bedrock Knowledge Bases, Lambda, and more

### Scalable Hybrid Agent Architectures

* Offload computationally intensive tasks to managed Bedrock agents while lightweight tasks run in CrewAI
* Scale agent processing by distributing workloads between local CrewAI agents and cloud-based Bedrock agents

### Cross-Organizational Agent Collaboration

* Enable secure collaboration between your organization's CrewAI agents and partner organizations' Bedrock agents
* Create workflows where external expertise from Bedrock agents can be incorporated without exposing sensitive data
* Build agent ecosystems that span organizational boundaries while maintaining security and data control


# Bedrock Knowledge Base Retriever
Source: https://docs.crewai.com/en/tools/cloud-storage/bedrockkbretriever

Retrieve information from Amazon Bedrock Knowledge Bases using natural language queries

# `BedrockKBRetrieverTool`

The `BedrockKBRetrieverTool` enables CrewAI agents to retrieve information from Amazon Bedrock Knowledge Bases using natural language queries.

## Installation

```bash
uv pip install 'crewai[tools]'
```

## Requirements

* AWS credentials configured (either through environment variables or AWS CLI)
* `boto3` and `python-dotenv` packages
* Access to Amazon Bedrock Knowledge Base

## Usage

Here's how to use the tool with a CrewAI agent:

```python {2, 4-17}
from crewai import Agent, Task, Crew
from crewai_tools.aws.bedrock.knowledge_base.retriever_tool import BedrockKBRetrieverTool

# Initialize the tool
kb_tool = BedrockKBRetrieverTool(
    knowledge_base_id="your-kb-id",
    number_of_results=5
)

# Create a CrewAI agent that uses the tool
researcher = Agent(
    role='Knowledge Base Researcher',
    goal='Find information about company policies',
    backstory='I am a researcher specialized in retrieving and analyzing company documentation.',
    tools=[kb_tool],
    verbose=True
)

# Create a task for the agent
research_task = Task(
    description="Find our company's remote work policy and summarize the key points.",
    agent=researcher
)

# Create a crew with the agent
crew = Crew(
    agents=[researcher],
    tasks=[research_task],
    verbose=2
)

# Run the crew
result = crew.kickoff()
print(result)
```

## Tool Arguments

| Argument                     | Type   | Required | Default | Description                                                                |
| :--------------------------- | :----- | :------- | :------ | :------------------------------------------------------------------------- |
| **knowledge\_base\_id**      | `str`  | Yes      | None    | The unique identifier of the knowledge base (0-10 alphanumeric characters) |
| **number\_of\_results**      | `int`  | No       | 5       | Maximum number of results to return                                        |
| **retrieval\_configuration** | `dict` | No       | None    | Custom configurations for the knowledge base query                         |
| **guardrail\_configuration** | `dict` | No       | None    | Content filtering settings                                                 |
| **next\_token**              | `str`  | No       | None    | Token for pagination                                                       |

## Environment Variables

```bash
BEDROCK_KB_ID=your-knowledge-base-id  # Alternative to passing knowledge_base_id
AWS_REGION=your-aws-region            # Defaults to us-east-1
AWS_ACCESS_KEY_ID=your-access-key     # Required for AWS authentication
AWS_SECRET_ACCESS_KEY=your-secret-key # Required for AWS authentication
```

## Response Format

The tool returns results in JSON format:

```json
{
  "results": [
    {
      "content": "Retrieved text content",
      "content_type": "text",
      "source_type": "S3",
      "source_uri": "s3://bucket/document.pdf",
      "score": 0.95,
      "metadata": {
        "additional": "metadata"
      }
    }
  ],
  "nextToken": "pagination-token",
  "guardrailAction": "NONE"
}
```

## Advanced Usage

### Custom Retrieval Configuration

```python
kb_tool = BedrockKBRetrieverTool(
    knowledge_base_id="your-kb-id",
    retrieval_configuration={
        "vectorSearchConfiguration": {
            "numberOfResults": 10,
            "overrideSearchType": "HYBRID"
        }
    }
)

policy_expert = Agent(
    role='Policy Expert',
    goal='Analyze company policies in detail',
    backstory='I am an expert in corporate policy analysis with deep knowledge of regulatory requirements.',
    tools=[kb_tool]
)
```

## Supported Data Sources

* Amazon S3
* Confluence
* Salesforce
* SharePoint
* Web pages
* Custom document locations
* Amazon Kendra
* SQL databases

## Use Cases

### Enterprise Knowledge Integration

* Enable CrewAI agents to access your organization's proprietary knowledge without exposing sensitive data
* Allow agents to make decisions based on your company's specific policies, procedures, and documentation
* Create agents that can answer questions based on your internal documentation while maintaining data security

### Specialized Domain Knowledge

* Connect CrewAI agents to domain-specific knowledge bases (legal, medical, technical) without retraining models
* Leverage existing knowledge repositories that are already maintained in your AWS environment
* Combine CrewAI's reasoning with domain-specific information from your knowledge bases

### Data-Driven Decision Making

* Ground CrewAI agent responses in your actual company data rather than general knowledge
* Ensure agents provide recommendations based on your specific business context and documentation
* Reduce hallucinations by retrieving factual information from your knowledge bases

### Scalable Information Access

* Access terabytes of organizational knowledge without embedding it all into your models
* Dynamically query only the relevant information needed for specific tasks
* Leverage AWS's scalable infrastructure to handle large knowledge bases efficiently

### Compliance and Governance

* Ensure CrewAI agents provide responses that align with your company's approved documentation
* Create auditable trails of information sources used by your agents
* Maintain control over what information sources your agents can access


# Overview
Source: https://docs.crewai.com/en/tools/cloud-storage/overview

Interact with cloud services, storage systems, and cloud-based AI platforms

These tools enable your agents to interact with cloud services, access cloud storage, and leverage cloud-based AI platforms for scalable operations.

## **Available Tools**

<CardGroup cols={2}>
  <Card title="S3 Reader Tool" icon="cloud" href="/en/tools/cloud-storage/s3readertool">
    Read files and data from Amazon S3 buckets.
  </Card>

  <Card title="S3 Writer Tool" icon="cloud-arrow-up" href="/en/tools/cloud-storage/s3writertool">
    Write and upload files to Amazon S3 storage.
  </Card>

  <Card title="Bedrock Invoke Agent" icon="aws" href="/en/tools/cloud-storage/bedrockinvokeagenttool">
    Invoke Amazon Bedrock agents for AI-powered tasks.
  </Card>

  <Card title="Bedrock KB Retriever" icon="database" href="/en/tools/cloud-storage/bedrockkbretriever">
    Retrieve information from Amazon Bedrock knowledge bases.
  </Card>
</CardGroup>

## **Common Use Cases**

* **File Storage**: Store and retrieve files from cloud storage systems
* **Data Backup**: Backup important data to cloud storage
* **AI Services**: Access cloud-based AI models and services
* **Knowledge Retrieval**: Query cloud-hosted knowledge bases
* **Scalable Operations**: Leverage cloud infrastructure for processing

```python
from crewai_tools import S3ReaderTool, S3WriterTool, BedrockInvokeAgentTool

# Create cloud tools
s3_reader = S3ReaderTool()
s3_writer = S3WriterTool()
bedrock_agent = BedrockInvokeAgentTool()

# Add to your agent
agent = Agent(
    role="Cloud Operations Specialist",
    tools=[s3_reader, s3_writer, bedrock_agent],
    goal="Manage cloud resources and AI services"
)
```


# S3 Reader Tool
Source: https://docs.crewai.com/en/tools/cloud-storage/s3readertool

The `S3ReaderTool` enables CrewAI agents to read files from Amazon S3 buckets.

# `S3ReaderTool`

## Description

The `S3ReaderTool` is designed to read files from Amazon S3 buckets. This tool allows CrewAI agents to access and retrieve content stored in S3, making it ideal for workflows that require reading data, configuration files, or any other content stored in AWS S3 storage.

## Installation

To use this tool, you need to install the required dependencies:

```shell
uv add boto3
```

## Steps to Get Started

To effectively use the `S3ReaderTool`, follow these steps:

1. **Install Dependencies**: Install the required packages using the command above.
2. **Configure AWS Credentials**: Set up your AWS credentials as environment variables.
3. **Initialize the Tool**: Create an instance of the tool.
4. **Specify S3 Path**: Provide the S3 path to the file you want to read.

## Example

The following example demonstrates how to use the `S3ReaderTool` to read a file from an S3 bucket:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools.aws.s3 import S3ReaderTool

# Initialize the tool
s3_reader_tool = S3ReaderTool()

# Define an agent that uses the tool
file_reader_agent = Agent(
    role="File Reader",
    goal="Read files from S3 buckets",
    backstory="An expert in retrieving and processing files from cloud storage.",
    tools=[s3_reader_tool],
    verbose=True,
)

# Example task to read a configuration file
read_task = Task(
    description="Read the configuration file from {my_bucket} and summarize its contents.",
    expected_output="A summary of the configuration file contents.",
    agent=file_reader_agent,
)

# Create and run the crew
crew = Crew(agents=[file_reader_agent], tasks=[read_task])
result = crew.kickoff(inputs={"my_bucket": "s3://my-bucket/config/app-config.json"})
```

## Parameters

The `S3ReaderTool` accepts the following parameter when used by an agent:

* **file\_path**: Required. The S3 file path in the format `s3://bucket-name/file-name`.

## AWS Credentials

The tool requires AWS credentials to access S3 buckets. You can configure these credentials using environment variables:

* **CREW\_AWS\_REGION**: The AWS region where your S3 bucket is located. Default is `us-east-1`.
* **CREW\_AWS\_ACCESS\_KEY\_ID**: Your AWS access key ID.
* **CREW\_AWS\_SEC\_ACCESS\_KEY**: Your AWS secret access key.

## Usage

When using the `S3ReaderTool` with an agent, the agent will need to provide the S3 file path:

```python Code
# Example of using the tool with an agent
file_reader_agent = Agent(
    role="File Reader",
    goal="Read files from S3 buckets",
    backstory="An expert in retrieving and processing files from cloud storage.",
    tools=[s3_reader_tool],
    verbose=True,
)

# Create a task for the agent to read a specific file
read_config_task = Task(
    description="Read the application configuration file from {my_bucket} and extract the database connection settings.",
    expected_output="The database connection settings from the configuration file.",
    agent=file_reader_agent,
)

# Run the task
crew = Crew(agents=[file_reader_agent], tasks=[read_config_task])
result = crew.kickoff(inputs={"my_bucket": "s3://my-bucket/config/app-config.json"})
```

## Error Handling

The `S3ReaderTool` includes error handling for common S3 issues:

* Invalid S3 path format
* Missing or inaccessible files
* Permission issues
* AWS credential problems

When an error occurs, the tool will return an error message that includes details about the issue.

## Implementation Details

The `S3ReaderTool` uses the AWS SDK for Python (boto3) to interact with S3:

```python Code
class S3ReaderTool(BaseTool):
    name: str = "S3 Reader Tool"
    description: str = "Reads a file from Amazon S3 given an S3 file path"

    def _run(self, file_path: str) -> str:
        try:
            bucket_name, object_key = self._parse_s3_path(file_path)

            s3 = boto3.client(
                's3',
                region_name=os.getenv('CREW_AWS_REGION', 'us-east-1'),
                aws_access_key_id=os.getenv('CREW_AWS_ACCESS_KEY_ID'),
                aws_secret_access_key=os.getenv('CREW_AWS_SEC_ACCESS_KEY')
            )

            # Read file content from S3
            response = s3.get_object(Bucket=bucket_name, Key=object_key)
            file_content = response['Body'].read().decode('utf-8')

            return file_content
        except ClientError as e:
            return f"Error reading file from S3: {str(e)}"
```

## Conclusion

The `S3ReaderTool` provides a straightforward way to read files from Amazon S3 buckets. By enabling agents to access content stored in S3, it facilitates workflows that require cloud-based file access. This tool is particularly useful for data processing, configuration management, and any task that involves retrieving information from AWS S3 storage.


# S3 Writer Tool
Source: https://docs.crewai.com/en/tools/cloud-storage/s3writertool

The `S3WriterTool` enables CrewAI agents to write content to files in Amazon S3 buckets.

# `S3WriterTool`

## Description

The `S3WriterTool` is designed to write content to files in Amazon S3 buckets. This tool allows CrewAI agents to create or update files in S3, making it ideal for workflows that require storing data, saving configuration files, or persisting any other content to AWS S3 storage.

## Installation

To use this tool, you need to install the required dependencies:

```shell
uv add boto3
```

## Steps to Get Started

To effectively use the `S3WriterTool`, follow these steps:

1. **Install Dependencies**: Install the required packages using the command above.
2. **Configure AWS Credentials**: Set up your AWS credentials as environment variables.
3. **Initialize the Tool**: Create an instance of the tool.
4. **Specify S3 Path and Content**: Provide the S3 path where you want to write the file and the content to be written.

## Example

The following example demonstrates how to use the `S3WriterTool` to write content to a file in an S3 bucket:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools.aws.s3 import S3WriterTool

# Initialize the tool
s3_writer_tool = S3WriterTool()

# Define an agent that uses the tool
file_writer_agent = Agent(
    role="File Writer",
    goal="Write content to files in S3 buckets",
    backstory="An expert in storing and managing files in cloud storage.",
    tools=[s3_writer_tool],
    verbose=True,
)

# Example task to write a report
write_task = Task(
    description="Generate a summary report of the quarterly sales data and save it to {my_bucket}.",
    expected_output="Confirmation that the report was successfully saved to S3.",
    agent=file_writer_agent,
)

# Create and run the crew
crew = Crew(agents=[file_writer_agent], tasks=[write_task])
result = crew.kickoff(inputs={"my_bucket": "s3://my-bucket/reports/quarterly-summary.txt"})
```

## Parameters

The `S3WriterTool` accepts the following parameters when used by an agent:

* **file\_path**: Required. The S3 file path in the format `s3://bucket-name/file-name`.
* **content**: Required. The content to write to the file.

## AWS Credentials

The tool requires AWS credentials to access S3 buckets. You can configure these credentials using environment variables:

* **CREW\_AWS\_REGION**: The AWS region where your S3 bucket is located. Default is `us-east-1`.
* **CREW\_AWS\_ACCESS\_KEY\_ID**: Your AWS access key ID.
* **CREW\_AWS\_SEC\_ACCESS\_KEY**: Your AWS secret access key.

## Usage

When using the `S3WriterTool` with an agent, the agent will need to provide both the S3 file path and the content to write:

```python Code
# Example of using the tool with an agent
file_writer_agent = Agent(
    role="File Writer",
    goal="Write content to files in S3 buckets",
    backstory="An expert in storing and managing files in cloud storage.",
    tools=[s3_writer_tool],
    verbose=True,
)

# Create a task for the agent to write a specific file
write_config_task = Task(
    description="""
    Create a configuration file with the following database settings:
    - host: db.example.com
    - port: 5432
    - username: app_user
    - password: secure_password

    Save this configuration as JSON to {my_bucket}.
    """,
    expected_output="Confirmation that the configuration file was successfully saved to S3.",
    agent=file_writer_agent,
)

# Run the task
crew = Crew(agents=[file_writer_agent], tasks=[write_config_task])
result = crew.kickoff(inputs={"my_bucket": "s3://my-bucket/config/db-config.json"})
```

## Error Handling

The `S3WriterTool` includes error handling for common S3 issues:

* Invalid S3 path format
* Permission issues (e.g., no write access to the bucket)
* AWS credential problems
* Bucket does not exist

When an error occurs, the tool will return an error message that includes details about the issue.

## Implementation Details

The `S3WriterTool` uses the AWS SDK for Python (boto3) to interact with S3:

```python Code
class S3WriterTool(BaseTool):
    name: str = "S3 Writer Tool"
    description: str = "Writes content to a file in Amazon S3 given an S3 file path"

    def _run(self, file_path: str, content: str) -> str:
        try:
            bucket_name, object_key = self._parse_s3_path(file_path)

            s3 = boto3.client(
                's3',
                region_name=os.getenv('CREW_AWS_REGION', 'us-east-1'),
                aws_access_key_id=os.getenv('CREW_AWS_ACCESS_KEY_ID'),
                aws_secret_access_key=os.getenv('CREW_AWS_SEC_ACCESS_KEY')
            )

            s3.put_object(Bucket=bucket_name, Key=object_key, Body=content.encode('utf-8'))
            return f"Successfully wrote content to {file_path}"
        except ClientError as e:
            return f"Error writing file to S3: {str(e)}"
```

## Conclusion

The `S3WriterTool` provides a straightforward way to write content to files in Amazon S3 buckets. By enabling agents to create and update files in S3, it facilitates workflows that require cloud-based file storage. This tool is particularly useful for data persistence, configuration management, report generation, and any task that involves storing information in AWS S3 storage.


# MySQL RAG Search
Source: https://docs.crewai.com/en/tools/database-data/mysqltool

The `MySQLSearchTool` is designed to search MySQL databases and return the most relevant results.

## Overview

This tool is designed to facilitate semantic searches within MySQL database tables. Leveraging the RAG (Retrieve and Generate) technology,
the MySQLSearchTool provides users with an efficient means of querying database table content, specifically tailored for MySQL databases.
It simplifies the process of finding relevant data through semantic search queries, making it an invaluable resource for users needing
to perform advanced queries on extensive datasets within a MySQL database.

## Installation

To install the `crewai_tools` package and utilize the MySQLSearchTool, execute the following command in your terminal:

```shell
pip install 'crewai[tools]'
```

## Example

Below is an example showcasing how to use the MySQLSearchTool to conduct a semantic search on a table within a MySQL database:

```python Code
from crewai_tools import MySQLSearchTool

# Initialize the tool with the database URI and the target table name
tool = MySQLSearchTool(
    db_uri='mysql://user:password@localhost:3306/mydatabase',
    table_name='employees'
)
```

## Arguments

The MySQLSearchTool requires the following arguments for its operation:

* `db_uri`: A string representing the URI of the MySQL database to be queried. This argument is mandatory and must include the necessary authentication details and the location of the database.
* `table_name`: A string specifying the name of the table within the database on which the semantic search will be performed. This argument is mandatory.

## Custom model and embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python Code
tool = MySQLSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google",
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# NL2SQL Tool
Source: https://docs.crewai.com/en/tools/database-data/nl2sqltool

The `NL2SQLTool` is designed to convert natural language to SQL queries.

## Overview

This tool is used to convert natural language to SQL queries. When passed to the agent it will generate queries and then use them to interact with the database.

This enables multiple workflows like having an Agent to access the database fetch information based on the goal and then use the information to generate a response, report or any other output.
Along with that provides the ability for the Agent to update the database based on its goal.

**Attention**: Make sure that the Agent has access to a Read-Replica or that is okay for the Agent to run insert/update queries on the database.

## Requirements

* SqlAlchemy
* Any DB compatible library (e.g. psycopg2, mysql-connector-python)

## Installation

Install the crewai\_tools package

```shell
pip install 'crewai[tools]'
```

## Usage

In order to use the NL2SQLTool, you need to pass the database URI to the tool. The URI should be in the format `dialect+driver://username:password@host:port/database`.

```python Code
from crewai_tools import NL2SQLTool

# psycopg2 was installed to run this example with PostgreSQL
nl2sql = NL2SQLTool(db_uri="postgresql://example@localhost:5432/test_db")

@agent
def researcher(self) -> Agent:
    return Agent(
        config=self.agents_config["researcher"],
        allow_delegation=False,
        tools=[nl2sql]
    )
```

## Example

The primary task goal was:

"Retrieve the average, maximum, and minimum monthly revenue for each city, but only include cities that have more than one user. Also, count the number of user in each city and
sort the results by the average monthly revenue in descending order"

So the Agent tried to get information from the DB, the first one is wrong so the Agent tries again and gets the correct information and passes to the next agent.

![alt text](https://github.com/crewAIInc/crewAI-tools/blob/main/crewai_tools/tools/nl2sql/images/image-2.png?raw=true)
![alt text](https://github.com/crewAIInc/crewAI-tools/raw/main/crewai_tools/tools/nl2sql/images/image-3.png)

The second task goal was:

"Review the data and create a detailed report, and then create the table on the database with the fields based on the data provided.
Include information on the average, maximum, and minimum monthly revenue for each city, but only include cities that have more than one user. Also, count the number of users in each city and sort the results by the average monthly revenue in descending order."

Now things start to get interesting, the Agent generates the SQL query to not only create the table but also insert the data into the table. And in the end the Agent still returns the final report which is exactly what was in the database.

![alt text](https://github.com/crewAIInc/crewAI-tools/raw/main/crewai_tools/tools/nl2sql/images/image-4.png)
![alt text](https://github.com/crewAIInc/crewAI-tools/raw/main/crewai_tools/tools/nl2sql/images/image-5.png)

![alt text](https://github.com/crewAIInc/crewAI-tools/raw/main/crewai_tools/tools/nl2sql/images/image-9.png)
![alt text](https://github.com/crewAIInc/crewAI-tools/raw/main/crewai_tools/tools/nl2sql/images/image-7.png)

This is a simple example of how the NL2SQLTool can be used to interact with the database and generate reports based on the data in the database.

The Tool provides endless possibilities on the logic of the Agent and how it can interact with the database.

```md
 DB -> Agent -> ... -> Agent -> DB
```


# Overview
Source: https://docs.crewai.com/en/tools/database-data/overview

Connect to databases, vector stores, and data warehouses for comprehensive data access

These tools enable your agents to interact with various database systems, from traditional SQL databases to modern vector stores and data warehouses.

## **Available Tools**

<CardGroup cols={2}>
  <Card title="MySQL Tool" icon="database" href="/en/tools/database-data/mysqltool">
    Connect to and query MySQL databases with SQL operations.
  </Card>

  <Card title="PostgreSQL Search" icon="elephant" href="/en/tools/database-data/pgsearchtool">
    Search and query PostgreSQL databases efficiently.
  </Card>

  <Card title="Snowflake Search" icon="snowflake" href="/en/tools/database-data/snowflakesearchtool">
    Access Snowflake data warehouse for analytics and reporting.
  </Card>

  <Card title="NL2SQL Tool" icon="language" href="/en/tools/database-data/nl2sqltool">
    Convert natural language queries to SQL statements automatically.
  </Card>

  <Card title="Qdrant Vector Search" icon="vector-square" href="/en/tools/database-data/qdrantvectorsearchtool">
    Search vector embeddings using Qdrant vector database.
  </Card>

  <Card title="Weaviate Vector Search" icon="network-wired" href="/en/tools/database-data/weaviatevectorsearchtool">
    Perform semantic search with Weaviate vector database.
  </Card>
</CardGroup>

## **Common Use Cases**

* **Data Analysis**: Query databases for business intelligence and reporting
* **Vector Search**: Find similar content using semantic embeddings
* **ETL Operations**: Extract, transform, and load data between systems
* **Real-time Analytics**: Access live data for decision making

```python
from crewai_tools import MySQLTool, QdrantVectorSearchTool, NL2SQLTool

# Create database tools
mysql_db = MySQLTool()
vector_search = QdrantVectorSearchTool()
nl_to_sql = NL2SQLTool()

# Add to your agent
agent = Agent(
    role="Data Analyst",
    tools=[mysql_db, vector_search, nl_to_sql],
    goal="Extract insights from various data sources"
)
```


# PG RAG Search
Source: https://docs.crewai.com/en/tools/database-data/pgsearchtool

The `PGSearchTool` is designed to search PostgreSQL databases and return the most relevant results.

## Overview

<Note>
  The PGSearchTool is currently under development. This document outlines the intended functionality and interface.
  As development progresses, please be aware that some features may not be available or could change.
</Note>

## Description

The PGSearchTool is envisioned as a powerful tool for facilitating semantic searches within PostgreSQL database tables. By leveraging advanced Retrieve and Generate (RAG) technology,
it aims to provide an efficient means for querying database table content, specifically tailored for PostgreSQL databases.
The tool's goal is to simplify the process of finding relevant data through semantic search queries, offering a valuable resource for users needing to conduct advanced queries on
extensive datasets within a PostgreSQL environment.

## Installation

The `crewai_tools` package, which will include the PGSearchTool upon its release, can be installed using the following command:

```shell
pip install 'crewai[tools]'
```

<Note>
  The PGSearchTool is not yet available in the current version of the `crewai_tools` package. This installation command will be updated once the tool is released.
</Note>

## Example Usage

Below is a proposed example showcasing how to use the PGSearchTool for conducting a semantic search on a table within a PostgreSQL database:

```python Code
from crewai_tools import PGSearchTool

# Initialize the tool with the database URI and the target table name
tool = PGSearchTool(
    db_uri='postgresql://user:password@localhost:5432/mydatabase',
    table_name='employees'
)
```

## Arguments

The PGSearchTool is designed to require the following arguments for its operation:

| Argument        | Type     | Description                                                                                                                                                                                                    |
| :-------------- | :------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **db\_uri**     | `string` | **Mandatory**. A string representing the URI of the PostgreSQL database to be queried. This argument will be mandatory and must include the necessary authentication details and the location of the database. |
| **table\_name** | `string` | **Mandatory**. A string specifying the name of the table within the database on which the semantic search will be performed. This argument will also be mandatory.                                             |

## Custom Model and Embeddings

The tool intends to use OpenAI for both embeddings and summarization by default. Users will have the option to customize the model using a config dictionary as follows:

```python Code
tool = PGSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Qdrant Vector Search Tool
Source: https://docs.crewai.com/en/tools/database-data/qdrantvectorsearchtool

Semantic search capabilities for CrewAI agents using Qdrant vector database

## Overview

The Qdrant Vector Search Tool enables semantic search capabilities in your CrewAI agents by leveraging [Qdrant](https://qdrant.tech/), a vector similarity search engine. This tool allows your agents to search through documents stored in a Qdrant collection using semantic similarity.

## Installation

Install the required packages:

```bash
uv add qdrant-client
```

## Basic Usage

Here's a minimal example of how to use the tool:

```python
from crewai import Agent
from crewai_tools import QdrantVectorSearchTool

# Initialize the tool
qdrant_tool = QdrantVectorSearchTool(
    qdrant_url="your_qdrant_url",
    qdrant_api_key="your_qdrant_api_key",
    collection_name="your_collection"
)

# Create an agent that uses the tool
agent = Agent(
    role="Research Assistant",
    goal="Find relevant information in documents",
    tools=[qdrant_tool]
)

# The tool will automatically use OpenAI embeddings
# and return the 3 most relevant results with scores > 0.35
```

## Complete Working Example

Here's a complete example showing how to:

1. Extract text from a PDF
2. Generate embeddings using OpenAI
3. Store in Qdrant
4. Create a CrewAI agentic RAG workflow for semantic search

```python
import os
import uuid
import pdfplumber
from openai import OpenAI
from dotenv import load_dotenv
from crewai import Agent, Task, Crew, Process, LLM
from crewai_tools import QdrantVectorSearchTool
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct, Distance, VectorParams

# Load environment variables
load_dotenv()

# Initialize OpenAI client
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Extract text from PDF
def extract_text_from_pdf(pdf_path):
    text = []
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text.append(page_text.strip())
    return text

# Generate OpenAI embeddings
def get_openai_embedding(text):
    response = client.embeddings.create(
        input=text,
        model="text-embedding-3-small"
    )
    return response.data[0].embedding

# Store text and embeddings in Qdrant
def load_pdf_to_qdrant(pdf_path, qdrant, collection_name):
    # Extract text from PDF
    text_chunks = extract_text_from_pdf(pdf_path)

    # Create Qdrant collection
    if qdrant.collection_exists(collection_name):
        qdrant.delete_collection(collection_name)
    qdrant.create_collection(
        collection_name=collection_name,
        vectors_config=VectorParams(size=1536, distance=Distance.COSINE)
    )

    # Store embeddings
    points = []
    for chunk in text_chunks:
        embedding = get_openai_embedding(chunk)
        points.append(PointStruct(
            id=str(uuid.uuid4()),
            vector=embedding,
            payload={"text": chunk}
        ))
    qdrant.upsert(collection_name=collection_name, points=points)

# Initialize Qdrant client and load data
qdrant = QdrantClient(
    url=os.getenv("QDRANT_URL"),
    api_key=os.getenv("QDRANT_API_KEY")
)
collection_name = "example_collection"
pdf_path = "path/to/your/document.pdf"
load_pdf_to_qdrant(pdf_path, qdrant, collection_name)

# Initialize Qdrant search tool
qdrant_tool = QdrantVectorSearchTool(
    qdrant_url=os.getenv("QDRANT_URL"),
    qdrant_api_key=os.getenv("QDRANT_API_KEY"),
    collection_name=collection_name,
    limit=3,
    score_threshold=0.35
)

# Create CrewAI agents
search_agent = Agent(
    role="Senior Semantic Search Agent",
    goal="Find and analyze documents based on semantic search",
    backstory="""You are an expert research assistant who can find relevant
    information using semantic search in a Qdrant database.""",
    tools=[qdrant_tool],
    verbose=True
)

answer_agent = Agent(
    role="Senior Answer Assistant",
    goal="Generate answers to questions based on the context provided",
    backstory="""You are an expert answer assistant who can generate
    answers to questions based on the context provided.""",
    tools=[qdrant_tool],
    verbose=True
)

# Define tasks
search_task = Task(
    description="""Search for relevant documents about the {query}.
    Your final answer should include:
    - The relevant information found
    - The similarity scores of the results
    - The metadata of the relevant documents""",
    agent=search_agent
)

answer_task = Task(
    description="""Given the context and metadata of relevant documents,
    generate a final answer based on the context.""",
    agent=answer_agent
)

# Run CrewAI workflow
crew = Crew(
    agents=[search_agent, answer_agent],
    tasks=[search_task, answer_task],
    process=Process.sequential,
    verbose=True
)

result = crew.kickoff(
    inputs={"query": "What is the role of X in the document?"}
)
print(result)
```

## Tool Parameters

### Required Parameters

* `qdrant_url` (str): The URL of your Qdrant server
* `qdrant_api_key` (str): API key for authentication with Qdrant
* `collection_name` (str): Name of the Qdrant collection to search

### Optional Parameters

* `limit` (int): Maximum number of results to return (default: 3)
* `score_threshold` (float): Minimum similarity score threshold (default: 0.35)
* `custom_embedding_fn` (Callable\[\[str], list\[float]]): Custom function for text vectorization

## Search Parameters

The tool accepts these parameters in its schema:

* `query` (str): The search query to find similar documents
* `filter_by` (str, optional): Metadata field to filter on
* `filter_value` (str, optional): Value to filter by

## Return Format

The tool returns results in JSON format:

```json
[
  {
    "metadata": {
      // Any metadata stored with the document
    },
    "context": "The actual text content of the document",
    "distance": 0.95  // Similarity score
  }
]
```

## Default Embedding

By default, the tool uses OpenAI's `text-embedding-3-small` model for vectorization. This requires:

* OpenAI API key set in environment: `OPENAI_API_KEY`

## Custom Embeddings

Instead of using the default embedding model, you might want to use your own embedding function in cases where you:

1. Want to use a different embedding model (e.g., Cohere, HuggingFace, Ollama models)
2. Need to reduce costs by using open-source embedding models
3. Have specific requirements for vector dimensions or embedding quality
4. Want to use domain-specific embeddings (e.g., for medical or legal text)

Here's an example using a HuggingFace model:

```python
from transformers import AutoTokenizer, AutoModel
import torch

# Load model and tokenizer
tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')
model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')

def custom_embeddings(text: str) -> list[float]:
    # Tokenize and get model outputs
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True)
    outputs = model(**inputs)

    # Use mean pooling to get text embedding
    embeddings = outputs.last_hidden_state.mean(dim=1)

    # Convert to list of floats and return
    return embeddings[0].tolist()

# Use custom embeddings with the tool
tool = QdrantVectorSearchTool(
    qdrant_url="your_url",
    qdrant_api_key="your_key",
    collection_name="your_collection",
    custom_embedding_fn=custom_embeddings  # Pass your custom function
)
```

## Error Handling

The tool handles these specific errors:

* Raises ImportError if `qdrant-client` is not installed (with option to auto-install)
* Raises ValueError if `QDRANT_URL` is not set
* Prompts to install `qdrant-client` if missing using `uv add qdrant-client`

## Environment Variables

Required environment variables:

```bash
export QDRANT_URL="your_qdrant_url"  # If not provided in constructor
export QDRANT_API_KEY="your_api_key"  # If not provided in constructor
export OPENAI_API_KEY="your_openai_key"  # If using default embeddings
```


# Snowflake Search Tool
Source: https://docs.crewai.com/en/tools/database-data/snowflakesearchtool

The `SnowflakeSearchTool` enables CrewAI agents to execute SQL queries and perform semantic search on Snowflake data warehouses.

# `SnowflakeSearchTool`

## Description

The `SnowflakeSearchTool` is designed to connect to Snowflake data warehouses and execute SQL queries with advanced features like connection pooling, retry logic, and asynchronous execution. This tool allows CrewAI agents to interact with Snowflake databases, making it ideal for data analysis, reporting, and business intelligence tasks that require access to enterprise data stored in Snowflake.

## Installation

To use this tool, you need to install the required dependencies:

```shell
uv add cryptography snowflake-connector-python snowflake-sqlalchemy
```

Or alternatively:

```shell
uv sync --extra snowflake
```

## Steps to Get Started

To effectively use the `SnowflakeSearchTool`, follow these steps:

1. **Install Dependencies**: Install the required packages using one of the commands above.
2. **Configure Snowflake Connection**: Create a `SnowflakeConfig` object with your Snowflake credentials.
3. **Initialize the Tool**: Create an instance of the tool with the necessary configuration.
4. **Execute Queries**: Use the tool to run SQL queries against your Snowflake database.

## Example

The following example demonstrates how to use the `SnowflakeSearchTool` to query data from a Snowflake database:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import SnowflakeSearchTool, SnowflakeConfig

# Create Snowflake configuration
config = SnowflakeConfig(
    account="your_account",
    user="your_username",
    password="your_password",
    warehouse="COMPUTE_WH",
    database="your_database",
    snowflake_schema="your_schema"
)

# Initialize the tool
snowflake_tool = SnowflakeSearchTool(config=config)

# Define an agent that uses the tool
data_analyst_agent = Agent(
    role="Data Analyst",
    goal="Analyze data from Snowflake database",
    backstory="An expert data analyst who can extract insights from enterprise data.",
    tools=[snowflake_tool],
    verbose=True,
)

# Example task to query sales data
query_task = Task(
    description="Query the sales data for the last quarter and summarize the top 5 products by revenue.",
    expected_output="A summary of the top 5 products by revenue for the last quarter.",
    agent=data_analyst_agent,
)

# Create and run the crew
crew = Crew(agents=[data_analyst_agent],
            tasks=[query_task])
result = crew.kickoff()
```

You can also customize the tool with additional parameters:

```python Code
# Initialize the tool with custom parameters
snowflake_tool = SnowflakeSearchTool(
    config=config,
    pool_size=10,
    max_retries=5,
    retry_delay=2.0,
    enable_caching=True
)
```

## Parameters

### SnowflakeConfig Parameters

The `SnowflakeConfig` class accepts the following parameters:

* **account**: Required. Snowflake account identifier.
* **user**: Required. Snowflake username.
* **password**: Optional\*. Snowflake password.
* **private\_key\_path**: Optional\*. Path to private key file (alternative to password).
* **warehouse**: Required. Snowflake warehouse name.
* **database**: Required. Default database.
* **snowflake\_schema**: Required. Default schema.
* **role**: Optional. Snowflake role.
* **session\_parameters**: Optional. Custom session parameters as a dictionary.

\*Either `password` or `private_key_path` must be provided.

### SnowflakeSearchTool Parameters

The `SnowflakeSearchTool` accepts the following parameters during initialization:

* **config**: Required. A `SnowflakeConfig` object containing connection details.
* **pool\_size**: Optional. Number of connections in the pool. Default is 5.
* **max\_retries**: Optional. Maximum retry attempts for failed queries. Default is 3.
* **retry\_delay**: Optional. Delay between retries in seconds. Default is 1.0.
* **enable\_caching**: Optional. Whether to enable query result caching. Default is True.

## Usage

When using the `SnowflakeSearchTool`, you need to provide the following parameters:

* **query**: Required. The SQL query to execute.
* **database**: Optional. Override the default database specified in the config.
* **snowflake\_schema**: Optional. Override the default schema specified in the config.
* **timeout**: Optional. Query timeout in seconds. Default is 300.

The tool will return the query results as a list of dictionaries, where each dictionary represents a row with column names as keys.

```python Code
# Example of using the tool with an agent
data_analyst = Agent(
    role="Data Analyst",
    goal="Analyze sales data from Snowflake",
    backstory="An expert data analyst with experience in SQL and data visualization.",
    tools=[snowflake_tool],
    verbose=True
)

# The agent will use the tool with parameters like:
# query="SELECT product_name, SUM(revenue) as total_revenue FROM sales GROUP BY product_name ORDER BY total_revenue DESC LIMIT 5"
# timeout=600

# Create a task for the agent
analysis_task = Task(
    description="Query the sales database and identify the top 5 products by revenue for the last quarter.",
    expected_output="A detailed analysis of the top 5 products by revenue.",
    agent=data_analyst
)

# Run the task
crew = Crew(
    agents=[data_analyst],
    tasks=[analysis_task]
)
result = crew.kickoff()
```

## Advanced Features

### Connection Pooling

The `SnowflakeSearchTool` implements connection pooling to improve performance by reusing database connections. You can control the pool size with the `pool_size` parameter.

### Automatic Retries

The tool automatically retries failed queries with exponential backoff. You can configure the retry behavior with the `max_retries` and `retry_delay` parameters.

### Query Result Caching

To improve performance for repeated queries, the tool can cache query results. This feature is enabled by default but can be disabled by setting `enable_caching=False`.

### Key-Pair Authentication

In addition to password authentication, the tool supports key-pair authentication for enhanced security:

```python Code
config = SnowflakeConfig(
    account="your_account",
    user="your_username",
    private_key_path="/path/to/your/private/key.p8",
    warehouse="COMPUTE_WH",
    database="your_database",
    snowflake_schema="your_schema"
)
```

## Error Handling

The `SnowflakeSearchTool` includes comprehensive error handling for common Snowflake issues:

* Connection failures
* Query timeouts
* Authentication errors
* Database and schema errors

When an error occurs, the tool will attempt to retry the operation (if configured) and provide detailed error information.

## Conclusion

The `SnowflakeSearchTool` provides a powerful way to integrate Snowflake data warehouses with CrewAI agents. With features like connection pooling, automatic retries, and query caching, it enables efficient and reliable access to enterprise data. This tool is particularly useful for data analysis, reporting, and business intelligence tasks that require access to structured data stored in Snowflake.


# Weaviate Vector Search
Source: https://docs.crewai.com/en/tools/database-data/weaviatevectorsearchtool

The `WeaviateVectorSearchTool` is designed to search a Weaviate vector database for semantically similar documents.

## Overview

The `WeaviateVectorSearchTool` is specifically crafted for conducting semantic searches within documents stored in a Weaviate vector database. This tool allows you to find semantically similar documents to a given query, leveraging the power of vector embeddings for more accurate and contextually relevant search results.

[Weaviate](https://weaviate.io/) is a vector database that stores and queries vector embeddings, enabling semantic search capabilities.

## Installation

To incorporate this tool into your project, you need to install the Weaviate client:

```shell
uv add weaviate-client
```

## Steps to Get Started

To effectively use the `WeaviateVectorSearchTool`, follow these steps:

1. **Package Installation**: Confirm that the `crewai[tools]` and `weaviate-client` packages are installed in your Python environment.
2. **Weaviate Setup**: Set up a Weaviate cluster. You can follow the [Weaviate documentation](https://weaviate.io/developers/wcs/manage-clusters/connect) for instructions.
3. **API Keys**: Obtain your Weaviate cluster URL and API key.
4. **OpenAI API Key**: Ensure you have an OpenAI API key set in your environment variables as `OPENAI_API_KEY`.

## Example

The following example demonstrates how to initialize the tool and execute a search:

```python Code
from crewai_tools import WeaviateVectorSearchTool

# Initialize the tool
tool = WeaviateVectorSearchTool(
    collection_name='example_collections',
    limit=3,
    weaviate_cluster_url="https://your-weaviate-cluster-url.com",
    weaviate_api_key="your-weaviate-api-key",
)

@agent
def search_agent(self) -> Agent:
    '''
    This agent uses the WeaviateVectorSearchTool to search for
    semantically similar documents in a Weaviate vector database.
    '''
    return Agent(
        config=self.agents_config["search_agent"],
        tools=[tool]
    )
```

## Parameters

The `WeaviateVectorSearchTool` accepts the following parameters:

* **collection\_name**: Required. The name of the collection to search within.
* **weaviate\_cluster\_url**: Required. The URL of the Weaviate cluster.
* **weaviate\_api\_key**: Required. The API key for the Weaviate cluster.
* **limit**: Optional. The number of results to return. Default is `3`.
* **vectorizer**: Optional. The vectorizer to use. If not provided, it will use `text2vec_openai` with the `nomic-embed-text` model.
* **generative\_model**: Optional. The generative model to use. If not provided, it will use OpenAI's `gpt-4o`.

## Advanced Configuration

You can customize the vectorizer and generative model used by the tool:

```python Code
from crewai_tools import WeaviateVectorSearchTool
from weaviate.classes.config import Configure

# Setup custom model for vectorizer and generative model
tool = WeaviateVectorSearchTool(
    collection_name='example_collections',
    limit=3,
    vectorizer=Configure.Vectorizer.text2vec_openai(model="nomic-embed-text"),
    generative_model=Configure.Generative.openai(model="gpt-4o-mini"),
    weaviate_cluster_url="https://your-weaviate-cluster-url.com",
    weaviate_api_key="your-weaviate-api-key",
)
```

## Preloading Documents

You can preload your Weaviate database with documents before using the tool:

```python Code
import os
from crewai_tools import WeaviateVectorSearchTool
import weaviate
from weaviate.classes.init import Auth

# Connect to Weaviate
client = weaviate.connect_to_weaviate_cloud(
    cluster_url="https://your-weaviate-cluster-url.com",
    auth_credentials=Auth.api_key("your-weaviate-api-key"),
    headers={"X-OpenAI-Api-Key": "your-openai-api-key"}
)

# Get or create collection
test_docs = client.collections.get("example_collections")
if not test_docs:
    test_docs = client.collections.create(
        name="example_collections",
        vectorizer_config=Configure.Vectorizer.text2vec_openai(model="nomic-embed-text"),
        generative_config=Configure.Generative.openai(model="gpt-4o"),
    )

# Load documents
docs_to_load = os.listdir("knowledge")
with test_docs.batch.dynamic() as batch:
    for d in docs_to_load:
        with open(os.path.join("knowledge", d), "r") as f:
            content = f.read()
        batch.add_object(
            {
                "content": content,
                "year": d.split("_")[0],
            }
        )

# Initialize the tool
tool = WeaviateVectorSearchTool(
    collection_name='example_collections',
    limit=3,
    weaviate_cluster_url="https://your-weaviate-cluster-url.com",
    weaviate_api_key="your-weaviate-api-key",
)
```

## Agent Integration Example

Here's how to integrate the `WeaviateVectorSearchTool` with a CrewAI agent:

```python Code
from crewai import Agent
from crewai_tools import WeaviateVectorSearchTool

# Initialize the tool
weaviate_tool = WeaviateVectorSearchTool(
    collection_name='example_collections',
    limit=3,
    weaviate_cluster_url="https://your-weaviate-cluster-url.com",
    weaviate_api_key="your-weaviate-api-key",
)

# Create an agent with the tool
rag_agent = Agent(
    name="rag_agent",
    role="You are a helpful assistant that can answer questions with the help of the WeaviateVectorSearchTool.",
    llm="gpt-4o-mini",
    tools=[weaviate_tool],
)
```

## Conclusion

The `WeaviateVectorSearchTool` provides a powerful way to search for semantically similar documents in a Weaviate vector database. By leveraging vector embeddings, it enables more accurate and contextually relevant search results compared to traditional keyword-based searches. This tool is particularly useful for applications that require finding information based on meaning rather than exact matches.


# CSV RAG Search
Source: https://docs.crewai.com/en/tools/file-document/csvsearchtool

The `CSVSearchTool` is a powerful RAG (Retrieval-Augmented Generation) tool designed for semantic searches within a CSV file's content.

# `CSVSearchTool`

<Note>
  **Experimental**: We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

This tool is used to perform a RAG (Retrieval-Augmented Generation) search within a CSV file's content. It allows users to semantically search for queries in the content of a specified CSV file.
This feature is particularly useful for extracting information from large CSV datasets where traditional search methods might be inefficient. All tools with "Search" in their name, including CSVSearchTool,
are RAG tools designed for searching different sources of data.

## Installation

Install the crewai\_tools package

```shell
pip install 'crewai[tools]'
```

## Example

```python Code
from crewai_tools import CSVSearchTool

# Initialize the tool with a specific CSV file.
# This setup allows the agent to only search the given CSV file.
tool = CSVSearchTool(csv='path/to/your/csvfile.csv')

# OR

# Initialize the tool without a specific CSV file.
# Agent will need to provide the CSV path at runtime.
tool = CSVSearchTool()
```

## Arguments

The following parameters can be used to customize the `CSVSearchTool`'s behavior:

| Argument | Type     | Description                                                                                                                                                               |
| :------- | :------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **csv**  | `string` | *Optional*. The path to the CSV file you want to search. This is a mandatory argument if the tool was initialized without a specific CSV file; otherwise, it is optional. |

## Custom model and embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python Code
tool = CSVSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Directory Read
Source: https://docs.crewai.com/en/tools/file-document/directoryreadtool

The `DirectoryReadTool` is a powerful utility designed to provide a comprehensive listing of directory contents.

# `DirectoryReadTool`

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

The DirectoryReadTool is a powerful utility designed to provide a comprehensive listing of directory contents.
It can recursively navigate through the specified directory, offering users a detailed enumeration of all files, including those within subdirectories.
This tool is crucial for tasks that require a thorough inventory of directory structures or for validating the organization of files within directories.

## Installation

To utilize the DirectoryReadTool in your project, install the `crewai_tools` package. If this package is not yet part of your environment, you can install it using pip with the command below:

```shell
pip install 'crewai[tools]'
```

This command installs the latest version of the `crewai_tools` package, granting access to the DirectoryReadTool among other utilities.

## Example

Employing the DirectoryReadTool is straightforward. The following code snippet demonstrates how to set it up and use the tool to list the contents of a specified directory:

```python Code
from crewai_tools import DirectoryReadTool

# Initialize the tool so the agent can read any directory's content
# it learns about during execution
tool = DirectoryReadTool()

# OR

# Initialize the tool with a specific directory,
# so the agent can only read the content of the specified directory
tool = DirectoryReadTool(directory='/path/to/your/directory')
```

## Arguments

The following parameters can be used to customize the `DirectoryReadTool`'s behavior:

| Argument      | Type     | Description                                                                                                                                                                                                   |
| :------------ | :------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **directory** | `string` | *Optional*. An argument that specifies the path to the directory whose contents you wish to list. It accepts both absolute and relative paths, guiding the tool to the desired directory for content listing. |


# Directory RAG Search
Source: https://docs.crewai.com/en/tools/file-document/directorysearchtool

The `DirectorySearchTool` is a powerful RAG (Retrieval-Augmented Generation) tool designed for semantic searches within a directory's content.

# `DirectorySearchTool`

<Note>
  **Experimental**: The DirectorySearchTool is under continuous development. Features and functionalities might evolve, and unexpected behavior may occur as we refine the tool.
</Note>

## Description

The DirectorySearchTool enables semantic search within the content of specified directories, leveraging the Retrieval-Augmented Generation (RAG) methodology for efficient navigation through files. Designed for flexibility, it allows users to dynamically specify search directories at runtime or set a fixed directory during initial setup.

## Installation

To use the DirectorySearchTool, begin by installing the crewai\_tools package. Execute the following command in your terminal:

```shell
pip install 'crewai[tools]'
```

## Initialization and Usage

Import the DirectorySearchTool from the `crewai_tools` package to start. You can initialize the tool without specifying a directory, enabling the setting of the search directory at runtime. Alternatively, the tool can be initialized with a predefined directory.

```python Code
from crewai_tools import DirectorySearchTool

# For dynamic directory specification at runtime
tool = DirectorySearchTool()

# For fixed directory searches
tool = DirectorySearchTool(directory='/path/to/directory')
```

## Arguments

* `directory`: A string argument that specifies the search directory. This is optional during initialization but required for searches if not set initially.

## Custom Model and Embeddings

The DirectorySearchTool uses OpenAI for embeddings and summarization by default. Customization options for these settings include changing the model provider and configuration, enhancing flexibility for advanced users.

```python Code
tool = DirectorySearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # Options include ollama, google, anthropic, llama2, and more
            config=dict(
                model="llama2",
                # Additional configurations here
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# DOCX RAG Search
Source: https://docs.crewai.com/en/tools/file-document/docxsearchtool

The `DOCXSearchTool` is a RAG tool designed for semantic searching within DOCX documents.

# `DOCXSearchTool`

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

The `DOCXSearchTool` is a RAG tool designed for semantic searching within DOCX documents.
It enables users to effectively search and extract relevant information from DOCX files using query-based searches.
This tool is invaluable for data analysis, information management, and research tasks,
streamlining the process of finding specific information within large document collections.

## Installation

Install the crewai\_tools package by running the following command in your terminal:

```shell
uv pip install docx2txt 'crewai[tools]'
```

## Example

The following example demonstrates initializing the DOCXSearchTool to search within any DOCX file's content or with a specific DOCX file path.

```python Code
from crewai_tools import DOCXSearchTool

# Initialize the tool to search within any DOCX file's content
tool = DOCXSearchTool()

# OR

# Initialize the tool with a specific DOCX file,
# so the agent can only search the content of the specified DOCX file
tool = DOCXSearchTool(docx='path/to/your/document.docx')
```

## Arguments

The following parameters can be used to customize the `DOCXSearchTool`'s behavior:

| Argument | Type     | Description                                                                                                                                                                                                        |
| :------- | :------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **docx** | `string` | *Optional*. An argument that specifies the path to the DOCX file you want to search. If not provided during initialization, the tool allows for later specification of any DOCX file's content path for searching. |

## Custom model and embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python Code
tool = DOCXSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# File Read
Source: https://docs.crewai.com/en/tools/file-document/filereadtool

The `FileReadTool` is designed to read files from the local file system.

## Overview

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

The FileReadTool conceptually represents a suite of functionalities within the crewai\_tools package aimed at facilitating file reading and content retrieval.
This suite includes tools for processing batch text files, reading runtime configuration files, and importing data for analytics.
It supports a variety of text-based file formats such as `.txt`, `.csv`, `.json`, and more. Depending on the file type, the suite offers specialized functionality,
such as converting JSON content into a Python dictionary for ease of use.

## Installation

To utilize the functionalities previously attributed to the FileReadTool, install the crewai\_tools package:

```shell
pip install 'crewai[tools]'
```

## Usage Example

To get started with the FileReadTool:

```python Code
from crewai_tools import FileReadTool

# Initialize the tool to read any files the agents knows or lean the path for
file_read_tool = FileReadTool()

# OR

# Initialize the tool with a specific file path, so the agent can only read the content of the specified file
file_read_tool = FileReadTool(file_path='path/to/your/file.txt')
```

## Arguments

* `file_path`: The path to the file you want to read. It accepts both absolute and relative paths. Ensure the file exists and you have the necessary permissions to access it.


# File Write
Source: https://docs.crewai.com/en/tools/file-document/filewritetool

The `FileWriterTool` is designed to write content to files.

# `FileWriterTool`

## Description

The `FileWriterTool` is a component of the crewai\_tools package, designed to simplify the process of writing content to files with cross-platform compatibility (Windows, Linux, macOS).
It is particularly useful in scenarios such as generating reports, saving logs, creating configuration files, and more.
This tool handles path differences across operating systems, supports UTF-8 encoding, and automatically creates directories if they don't exist, making it easier to organize your output reliably across different platforms.

## Installation

Install the crewai\_tools package to use the `FileWriterTool` in your projects:

```shell
pip install 'crewai[tools]'
```

## Example

To get started with the `FileWriterTool`:

```python Code
from crewai_tools import FileWriterTool

# Initialize the tool
file_writer_tool = FileWriterTool()

# Write content to a file in a specified directory
result = file_writer_tool._run('example.txt', 'This is a test content.', 'test_directory')
print(result)
```

## Arguments

* `filename`: The name of the file you want to create or overwrite.
* `content`: The content to write into the file.
* `directory` (optional): The path to the directory where the file will be created. Defaults to the current directory (`.`). If the directory does not exist, it will be created.

## Conclusion

By integrating the `FileWriterTool` into your crews, the agents can reliably write content to files across different operating systems.
This tool is essential for tasks that require saving output data, creating structured file systems, and handling cross-platform file operations.
It's particularly recommended for Windows users who may encounter file writing issues with standard Python file operations.

By adhering to the setup and usage guidelines provided, incorporating this tool into projects is straightforward and ensures consistent file writing behavior across all platforms.


# JSON RAG Search
Source: https://docs.crewai.com/en/tools/file-document/jsonsearchtool

The `JSONSearchTool` is designed to search JSON files and return the most relevant results.

# `JSONSearchTool`

<Note>
  The JSONSearchTool is currently in an experimental phase. This means the tool
  is under active development, and users might encounter unexpected behavior or
  changes. We highly encourage feedback on any issues or suggestions for
  improvements.
</Note>

## Description

The JSONSearchTool is designed to facilitate efficient and precise searches within JSON file contents. It utilizes a RAG (Retrieve and Generate) search mechanism, allowing users to specify a JSON path for targeted searches within a particular JSON file. This capability significantly improves the accuracy and relevance of search results.

## Installation

To install the JSONSearchTool, use the following pip command:

```shell
pip install 'crewai[tools]'
```

## Usage Examples

Here are updated examples on how to utilize the JSONSearchTool effectively for searching within JSON files. These examples take into account the current implementation and usage patterns identified in the codebase.

```python Code
from crewai_tools import JSONSearchTool

# General JSON content search
# This approach is suitable when the JSON path is either known beforehand or can be dynamically identified.
tool = JSONSearchTool()

# Restricting search to a specific JSON file
# Use this initialization method when you want to limit the search scope to a specific JSON file.
tool = JSONSearchTool(json_path='./path/to/your/file.json')
```

## Arguments

* `json_path` (str, optional): Specifies the path to the JSON file to be searched. This argument is not required if the tool is initialized for a general search. When provided, it confines the search to the specified JSON file.

## Configuration Options

The JSONSearchTool supports extensive customization through a configuration dictionary. This allows users to select different models for embeddings and summarization based on their requirements.

```python Code
tool = JSONSearchTool(
    config={
        "llm": {
            "provider": "ollama",  # Other options include google, openai, anthropic, llama2, etc.
            "config": {
                "model": "llama2",
                # Additional optional configurations can be specified here.
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            },
        },
        "embedding_model": {
            "provider": "google", # or openai, ollama, ...
            "config": {
                "model": "models/embedding-001",
                "task_type": "retrieval_document",
                # Further customization options can be added here.
            },
        },
    }
)
```


# MDX RAG Search
Source: https://docs.crewai.com/en/tools/file-document/mdxsearchtool

The `MDXSearchTool` is designed to search MDX files and return the most relevant results.

# `MDXSearchTool`

<Note>
  The MDXSearchTool is in continuous development. Features may be added or removed, and functionality could change unpredictably as we refine the tool.
</Note>

## Description

The MDX Search Tool is a component of the `crewai_tools` package aimed at facilitating advanced markdown language extraction. It enables users to effectively search and extract relevant information from MD files using query-based searches. This tool is invaluable for data analysis, information management, and research tasks, streamlining the process of finding specific information within large document collections.

## Installation

Before using the MDX Search Tool, ensure the `crewai_tools` package is installed. If it is not, you can install it with the following command:

```shell
pip install 'crewai[tools]'
```

## Usage Example

To use the MDX Search Tool, you must first set up the necessary environment variables. Then, integrate the tool into your crewAI project to begin your market research. Below is a basic example of how to do this:

```python Code
from crewai_tools import MDXSearchTool

# Initialize the tool to search any MDX content it learns about during execution
tool = MDXSearchTool()

# OR

# Initialize the tool with a specific MDX file path for an exclusive search within that document
tool = MDXSearchTool(mdx='path/to/your/document.mdx')
```

## Parameters

* mdx: **Optional**. Specifies the MDX file path for the search. It can be provided during initialization.

## Customization of Model and Embeddings

The tool defaults to using OpenAI for embeddings and summarization. For customization, utilize a configuration dictionary as shown below:

```python Code
tool = MDXSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # Options include google, openai, anthropic, llama2, etc.
            config=dict(
                model="llama2",
                # Optional parameters can be included here.
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # Optional title for the embeddings can be added here.
                # title="Embeddings",
            ),
        ),
    )
)
```


# Overview
Source: https://docs.crewai.com/en/tools/file-document/overview

Read, write, and search through various file formats with CrewAI's document processing tools

These tools enable your agents to work with various file formats and document types. From reading PDFs to processing JSON data, these tools handle all your document processing needs.

## **Available Tools**

<CardGroup cols={2}>
  <Card title="File Read Tool" icon="folders" href="/en/tools/file-document/filereadtool">
    Read content from any file type including text, markdown, and more.
  </Card>

  <Card title="File Write Tool" icon="file-pen" href="/en/tools/file-document/filewritetool">
    Write content to files, create new documents, and save processed data.
  </Card>

  <Card title="PDF Search Tool" icon="file-pdf" href="/en/tools/file-document/pdfsearchtool">
    Search and extract text content from PDF documents efficiently.
  </Card>

  <Card title="DOCX Search Tool" icon="file-word" href="/en/tools/file-document/docxsearchtool">
    Search through Microsoft Word documents and extract relevant content.
  </Card>

  <Card title="JSON Search Tool" icon="brackets-curly" href="/en/tools/file-document/jsonsearchtool">
    Parse and search through JSON files with advanced query capabilities.
  </Card>

  <Card title="CSV Search Tool" icon="table" href="/en/tools/file-document/csvsearchtool">
    Process and search through CSV files, extract specific rows and columns.
  </Card>

  <Card title="XML Search Tool" icon="code" href="/en/tools/file-document/xmlsearchtool">
    Parse XML files and search for specific elements and attributes.
  </Card>

  <Card title="MDX Search Tool" icon="markdown" href="/en/tools/file-document/mdxsearchtool">
    Search through MDX files and extract content from documentation.
  </Card>

  <Card title="TXT Search Tool" icon="file-lines" href="/en/tools/file-document/txtsearchtool">
    Search through plain text files with pattern matching capabilities.
  </Card>

  <Card title="Directory Search Tool" icon="folder-open" href="/en/tools/file-document/directorysearchtool">
    Search for files and folders within directory structures.
  </Card>

  <Card title="Directory Read Tool" icon="folder" href="/en/tools/file-document/directoryreadtool">
    Read and list directory contents, file structures, and metadata.
  </Card>
</CardGroup>

## **Common Use Cases**

* **Document Processing**: Extract and analyze content from various file formats
* **Data Import**: Read structured data from CSV, JSON, and XML files
* **Content Search**: Find specific information within large document collections
* **File Management**: Organize and manipulate files and directories
* **Data Export**: Save processed results to various file formats

## **Quick Start Example**

```python
from crewai_tools import FileReadTool, PDFSearchTool, JSONSearchTool

# Create tools
file_reader = FileReadTool()
pdf_searcher = PDFSearchTool()
json_processor = JSONSearchTool()

# Add to your agent
agent = Agent(
    role="Document Analyst",
    tools=[file_reader, pdf_searcher, json_processor],
    goal="Process and analyze various document types"
)
```

## **Tips for Document Processing**

* **File Permissions**: Ensure your agent has proper read/write permissions
* **Large Files**: Consider chunking for very large documents
* **Format Support**: Check tool documentation for supported file formats
* **Error Handling**: Implement proper error handling for corrupted or inaccessible files


# PDF RAG Search
Source: https://docs.crewai.com/en/tools/file-document/pdfsearchtool

The `PDFSearchTool` is designed to search PDF files and return the most relevant results.

# `PDFSearchTool`

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

The PDFSearchTool is a RAG tool designed for semantic searches within PDF content. It allows for inputting a search query and a PDF document, leveraging advanced search techniques to find relevant content efficiently.
This capability makes it especially useful for extracting specific information from large PDF files quickly.

## Installation

To get started with the PDFSearchTool, first, ensure the crewai\_tools package is installed with the following command:

```shell
pip install 'crewai[tools]'
```

## Example

Here's how to use the PDFSearchTool to search within a PDF document:

```python Code
from crewai_tools import PDFSearchTool

# Initialize the tool allowing for any PDF content search if the path is provided during execution
tool = PDFSearchTool()

# OR

# Initialize the tool with a specific PDF path for exclusive search within that document
tool = PDFSearchTool(pdf='path/to/your/document.pdf')
```

## Arguments

* `pdf`: **Optional** The PDF path for the search. Can be provided at initialization or within the `run` method's arguments. If provided at initialization, the tool confines its search to the specified document.

## Custom model and embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python Code
tool = PDFSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# TXT RAG Search
Source: https://docs.crewai.com/en/tools/file-document/txtsearchtool

The `TXTSearchTool` is designed to perform a RAG (Retrieval-Augmented Generation) search within the content of a text file.

## Overview

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

This tool is used to perform a RAG (Retrieval-Augmented Generation) search within the content of a text file.
It allows for semantic searching of a query within a specified text file's content,
making it an invaluable resource for quickly extracting information or finding specific sections of text based on the query provided.

## Installation

To use the `TXTSearchTool`, you first need to install the `crewai_tools` package.
This can be done using pip, a package manager for Python.
Open your terminal or command prompt and enter the following command:

```shell
pip install 'crewai[tools]'
```

This command will download and install the TXTSearchTool along with any necessary dependencies.

## Example

The following example demonstrates how to use the TXTSearchTool to search within a text file.
This example shows both the initialization of the tool with a specific text file and the subsequent search within that file's content.

```python Code
from crewai_tools import TXTSearchTool

# Initialize the tool to search within any text file's content
# the agent learns about during its execution
tool = TXTSearchTool()

# OR

# Initialize the tool with a specific text file,
# so the agent can search within the given text file's content
tool = TXTSearchTool(txt='path/to/text/file.txt')
```

## Arguments

* `txt` (str): **Optional**. The path to the text file you want to search.
  This argument is only required if the tool was not initialized with a specific text file;
  otherwise, the search will be conducted within the initially provided text file.

## Custom model and embeddings

By default, the tool uses OpenAI for both embeddings and summarization.
To customize the model, you can use a config dictionary as follows:

```python Code
tool = TXTSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# XML RAG Search
Source: https://docs.crewai.com/en/tools/file-document/xmlsearchtool

The `XMLSearchTool` is designed to perform a RAG (Retrieval-Augmented Generation) search within the content of a XML file.

# `XMLSearchTool`

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

The XMLSearchTool is a cutting-edge RAG tool engineered for conducting semantic searches within XML files.
Ideal for users needing to parse and extract information from XML content efficiently, this tool supports inputting a search query and an optional XML file path.
By specifying an XML path, users can target their search more precisely to the content of that file, thereby obtaining more relevant search outcomes.

## Installation

To start using the XMLSearchTool, you must first install the crewai\_tools package. This can be easily done with the following command:

```shell
pip install 'crewai[tools]'
```

## Example

Here are two examples demonstrating how to use the XMLSearchTool.
The first example shows searching within a specific XML file, while the second example illustrates initiating a search without predefining an XML path, providing flexibility in search scope.

```python Code
from crewai_tools import XMLSearchTool

# Allow agents to search within any XML file's content
#as it learns about their paths during execution
tool = XMLSearchTool()

# OR

# Initialize the tool with a specific XML file path
#for exclusive search within that document
tool = XMLSearchTool(xml='path/to/your/xmlfile.xml')
```

## Arguments

* `xml`: This is the path to the XML file you wish to search.
  It is an optional parameter during the tool's initialization but must be provided either at initialization or as part of the `run` method's arguments to execute a search.

## Custom model and embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python Code
tool = XMLSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Tools Overview
Source: https://docs.crewai.com/en/tools/overview

Discover CrewAI's extensive library of 40+ tools to supercharge your AI agents

CrewAI provides an extensive library of pre-built tools to enhance your agents' capabilities. From file processing to web scraping, database queries to AI services - we've got you covered.

## **Tool Categories**

<CardGroup cols={2}>
  <Card title="File & Document" icon="file-check" href="/en/tools/file-document/overview" color="#3B82F6">
    Read, write, and search through various file formats including PDF, DOCX, JSON, CSV, and more. Perfect for document processing workflows.
  </Card>

  <Card title="Web Scraping & Browsing" icon="globe" href="/en/tools/web-scraping/overview" color="#10B981">
    Extract data from websites, automate browser interactions, and scrape content at scale with tools like Firecrawl, Selenium, and more.
  </Card>

  <Card title="Search & Research" icon="magnifying-glass" href="/en/tools/search-research/overview" color="#F59E0B">
    Perform web searches, find code repositories, research YouTube content, and discover information across the internet.
  </Card>

  <Card title="Database & Data" icon="database" href="/en/tools/database-data/overview" color="#8B5CF6">
    Connect to SQL databases, vector stores, and data warehouses. Query MySQL, PostgreSQL, Snowflake, Qdrant, and Weaviate.
  </Card>

  <Card title="AI & Machine Learning" icon="brain" href="/en/tools/ai-ml/overview" color="#EF4444">
    Generate images with DALL-E, process vision tasks, integrate with LangChain, build RAG systems, and leverage code interpreters.
  </Card>

  <Card title="Cloud & Storage" icon="cloud" href="/en/tools/cloud-storage/overview" color="#06B6D4">
    Interact with cloud services including AWS S3, Amazon Bedrock, and other cloud storage and AI services.
  </Card>

  <Card title="Automation & Integration" icon="bolt" href="/en/tools/automation/overview" color="#84CC16">
    Automate workflows with Apify, Composio, and other integration platforms to connect your agents with external services.
  </Card>
</CardGroup>

## **Quick Access**

Need a specific tool? Here are some popular choices:

<CardGroup cols={3}>
  <Card title="RAG Tool" icon="image" href="/en/tools/ai-ml/ragtool">
    Implement Retrieval-Augmented Generation
  </Card>

  <Card title="Serper Dev" icon="book-atlas" href="/en/tools/search-research/serperdevtool">
    Google search API
  </Card>

  <Card title="File Read" icon="file" href="/en/tools/file-document/filereadtool">
    Read any file type
  </Card>

  <Card title="Scrape Website" icon="globe" href="/en/tools/web-scraping/scrapewebsitetool">
    Extract web content
  </Card>

  <Card title="Code Interpreter" icon="code" href="/en/tools/ai-ml/codeinterpretertool">
    Execute Python code
  </Card>

  <Card title="S3 Reader" icon="cloud" href="/en/tools/cloud-storage/s3readertool">
    Access AWS S3 files
  </Card>
</CardGroup>

## **Getting Started**

To use any tool in your CrewAI project:

1. **Import** the tool in your crew configuration
2. **Add** it to your agent's tools list
3. **Configure** any required API keys or settings

```python
from crewai_tools import FileReadTool, SerperDevTool

# Add tools to your agent
agent = Agent(
    role="Research Analyst",
    tools=[FileReadTool(), SerperDevTool()],
    # ... other configuration
)
```

Ready to explore? Pick a category above to discover tools that fit your use case!


# Brave Search
Source: https://docs.crewai.com/en/tools/search-research/bravesearchtool

The `BraveSearchTool` is designed to search the internet using the Brave Search API.

# `BraveSearchTool`

## Description

This tool is designed to perform web searches using the Brave Search API. It allows you to search the internet with a specified query and retrieve relevant results. The tool supports customizable result counts and country-specific searches.

## Installation

To incorporate this tool into your project, follow the installation instructions below:

```shell
pip install 'crewai[tools]'
```

## Steps to Get Started

To effectively use the `BraveSearchTool`, follow these steps:

1. **Package Installation**: Confirm that the `crewai[tools]` package is installed in your Python environment.
2. **API Key Acquisition**: Acquire a Brave Search API key by registering at [Brave Search API](https://api.search.brave.com/app/keys).
3. **Environment Configuration**: Store your obtained API key in an environment variable named `BRAVE_API_KEY` to facilitate its use by the tool.

## Example

The following example demonstrates how to initialize the tool and execute a search with a given query:

```python Code
from crewai_tools import BraveSearchTool

# Initialize the tool for internet searching capabilities
tool = BraveSearchTool()

# Execute a search
results = tool.run(search_query="CrewAI agent framework")
print(results)
```

## Parameters

The `BraveSearchTool` accepts the following parameters:

* **search\_query**: Mandatory. The search query you want to use to search the internet.
* **country**: Optional. Specify the country for the search results. Default is empty string.
* **n\_results**: Optional. Number of search results to return. Default is `10`.
* **save\_file**: Optional. Whether to save the search results to a file. Default is `False`.

## Example with Parameters

Here is an example demonstrating how to use the tool with additional parameters:

```python Code
from crewai_tools import BraveSearchTool

# Initialize the tool with custom parameters
tool = BraveSearchTool(
    country="US",
    n_results=5,
    save_file=True
)

# Execute a search
results = tool.run(search_query="Latest AI developments")
print(results)
```

## Agent Integration Example

Here's how to integrate the `BraveSearchTool` with a CrewAI agent:

```python Code
from crewai import Agent
from crewai.project import agent
from crewai_tools import BraveSearchTool

# Initialize the tool
brave_search_tool = BraveSearchTool()

# Define an agent with the BraveSearchTool
@agent
def researcher(self) -> Agent:
    return Agent(
        config=self.agents_config["researcher"],
        allow_delegation=False,
        tools=[brave_search_tool]
    )
```

## Conclusion

By integrating the `BraveSearchTool` into Python projects, users gain the ability to conduct real-time, relevant searches across the internet directly from their applications. The tool provides a simple interface to the powerful Brave Search API, making it easy to retrieve and process search results programmatically. By adhering to the setup and usage guidelines provided, incorporating this tool into projects is streamlined and straightforward.


# Code Docs RAG Search
Source: https://docs.crewai.com/en/tools/search-research/codedocssearchtool

The `CodeDocsSearchTool` is a powerful RAG (Retrieval-Augmented Generation) tool designed for semantic searches within code documentation.

# `CodeDocsSearchTool`

<Note>
  **Experimental**: We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

The CodeDocsSearchTool is a powerful RAG (Retrieval-Augmented Generation) tool designed for semantic searches within code documentation.
It enables users to efficiently find specific information or topics within code documentation. By providing a `docs_url` during initialization,
the tool narrows down the search to that particular documentation site. Alternatively, without a specific `docs_url`,
it searches across a wide array of code documentation known or discovered throughout its execution, making it versatile for various documentation search needs.

## Installation

To start using the CodeDocsSearchTool, first, install the crewai\_tools package via pip:

```shell
pip install 'crewai[tools]'
```

## Example

Utilize the CodeDocsSearchTool as follows to conduct searches within code documentation:

```python Code
from crewai_tools import CodeDocsSearchTool

# To search any code documentation content
# if the URL is known or discovered during its execution:
tool = CodeDocsSearchTool()

# OR

# To specifically focus your search on a given documentation site
# by providing its URL:
tool = CodeDocsSearchTool(docs_url='https://docs.example.com/reference')
```

<Note>
  Substitute '[https://docs.example.com/reference](https://docs.example.com/reference)' with your target documentation URL
  and 'How to use search tool' with the search query relevant to your needs.
</Note>

## Arguments

The following parameters can be used to customize the `CodeDocsSearchTool`'s behavior:

| Argument      | Type     | Description                                                             |
| :------------ | :------- | :---------------------------------------------------------------------- |
| **docs\_url** | `string` | *Optional*. Specifies the URL of the code documentation to be searched. |

## Custom model and embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python Code
tool = CodeDocsSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# EXA Search Web Loader
Source: https://docs.crewai.com/en/tools/search-research/exasearchtool

The `EXASearchTool` is designed to perform a semantic search for a specified query from a text's content across the internet.

# `EXASearchTool`

## Description

The EXASearchTool is designed to perform a semantic search for a specified query from a text's content across the internet.
It utilizes the [exa.ai](https://exa.ai/) API to fetch and display the most relevant search results based on the query provided by the user.

## Installation

To incorporate this tool into your project, follow the installation instructions below:

```shell
pip install 'crewai[tools]'
```

## Example

The following example demonstrates how to initialize the tool and execute a search with a given query:

```python Code
from crewai_tools import EXASearchTool

# Initialize the tool for internet searching capabilities
tool = EXASearchTool()
```

## Steps to Get Started

To effectively use the EXASearchTool, follow these steps:

<Steps>
  <Step title="Package Installation">
    Confirm that the `crewai[tools]` package is installed in your Python environment.
  </Step>

  <Step title="API Key Acquisition">
    Acquire a [exa.ai](https://exa.ai/) API key by registering for a free account at [exa.ai](https://exa.ai/).
  </Step>

  <Step title="Environment Configuration">
    Store your obtained API key in an environment variable named `EXA_API_KEY` to facilitate its use by the tool.
  </Step>
</Steps>

## Conclusion

By integrating the `EXASearchTool` into Python projects, users gain the ability to conduct real-time, relevant searches across the internet directly from their applications.
By adhering to the setup and usage guidelines provided, incorporating this tool into projects is streamlined and straightforward.


# Github Search
Source: https://docs.crewai.com/en/tools/search-research/githubsearchtool

The `GithubSearchTool` is designed to search websites and convert them into clean markdown or structured data.

# `GithubSearchTool`

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

The GithubSearchTool is a Retrieval-Augmented Generation (RAG) tool specifically designed for conducting semantic searches within GitHub repositories. Utilizing advanced semantic search capabilities, it sifts through code, pull requests, issues, and repositories, making it an essential tool for developers, researchers, or anyone in need of precise information from GitHub.

## Installation

To use the GithubSearchTool, first ensure the crewai\_tools package is installed in your Python environment:

```shell
pip install 'crewai[tools]'
```

This command installs the necessary package to run the GithubSearchTool along with any other tools included in the crewai\_tools package.

## Example

Here‚Äôs how you can use the GithubSearchTool to perform semantic searches within a GitHub repository:

```python Code
from crewai_tools import GithubSearchTool

# Initialize the tool for semantic searches within a specific GitHub repository
tool = GithubSearchTool(
	github_repo='https://github.com/example/repo',
	gh_token='your_github_personal_access_token',
	content_types=['code', 'issue'] # Options: code, repo, pr, issue
)

# OR

# Initialize the tool for semantic searches within a specific GitHub repository, so the agent can search any repository if it learns about during its execution
tool = GithubSearchTool(
	gh_token='your_github_personal_access_token',
	content_types=['code', 'issue'] # Options: code, repo, pr, issue
)
```

## Arguments

* `github_repo` : The URL of the GitHub repository where the search will be conducted. This is a mandatory field and specifies the target repository for your search.
* `gh_token` : Your GitHub Personal Access Token (PAT) required for authentication. You can create one in your GitHub account settings under Developer Settings > Personal Access Tokens.
* `content_types` : Specifies the types of content to include in your search. You must provide a list of content types from the following options: `code` for searching within the code,
  `repo` for searching within the repository's general information, `pr` for searching within pull requests, and `issue` for searching within issues.
  This field is mandatory and allows tailoring the search to specific content types within the GitHub repository.

## Custom model and embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python Code
tool = GithubSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Linkup Search Tool
Source: https://docs.crewai.com/en/tools/search-research/linkupsearchtool

The `LinkupSearchTool` enables querying the Linkup API for contextual information.

# `LinkupSearchTool`

## Description

The `LinkupSearchTool` provides the ability to query the Linkup API for contextual information and retrieve structured results. This tool is ideal for enriching workflows with up-to-date and reliable information from Linkup, allowing agents to access relevant data during their tasks.

## Installation

To use this tool, you need to install the Linkup SDK:

```shell
uv add linkup-sdk
```

## Steps to Get Started

To effectively use the `LinkupSearchTool`, follow these steps:

1. **API Key**: Obtain a Linkup API key.
2. **Environment Setup**: Set up your environment with the API key.
3. **Install SDK**: Install the Linkup SDK using the command above.

## Example

The following example demonstrates how to initialize the tool and use it in an agent:

```python Code
from crewai_tools import LinkupSearchTool
from crewai import Agent
import os

# Initialize the tool with your API key
linkup_tool = LinkupSearchTool(api_key=os.getenv("LINKUP_API_KEY"))

# Define an agent that uses the tool
@agent
def researcher(self) -> Agent:
    '''
    This agent uses the LinkupSearchTool to retrieve contextual information
    from the Linkup API.
    '''
    return Agent(
        config=self.agents_config["researcher"],
        tools=[linkup_tool]
    )
```

## Parameters

The `LinkupSearchTool` accepts the following parameters:

### Constructor Parameters

* **api\_key**: Required. Your Linkup API key.

### Run Parameters

* **query**: Required. The search term or phrase.
* **depth**: Optional. The search depth. Default is "standard".
* **output\_type**: Optional. The type of output. Default is "searchResults".

## Advanced Usage

You can customize the search parameters for more specific results:

```python Code
# Perform a search with custom parameters
results = linkup_tool.run(
    query="Women Nobel Prize Physics",
    depth="deep",
    output_type="searchResults"
)
```

## Return Format

The tool returns results in the following format:

```json
{
  "success": true,
  "results": [
    {
      "name": "Result Title",
      "url": "https://example.com/result",
      "content": "Content of the result..."
    },
    // Additional results...
  ]
}
```

If an error occurs, the response will be:

```json
{
  "success": false,
  "error": "Error message"
}
```

## Error Handling

The tool gracefully handles API errors and provides structured feedback. If the API request fails, the tool will return a dictionary with `success: false` and an error message.

## Conclusion

The `LinkupSearchTool` provides a seamless way to integrate Linkup's contextual information retrieval capabilities into your CrewAI agents. By leveraging this tool, agents can access relevant and up-to-date information to enhance their decision-making and task execution.


# Overview
Source: https://docs.crewai.com/en/tools/search-research/overview

Perform web searches, find repositories, and research information across the internet

These tools enable your agents to search the web, research topics, and find information across various platforms including search engines, GitHub, and YouTube.

## **Available Tools**

<CardGroup cols={2}>
  <Card title="Serper Dev Tool" icon="google" href="/en/tools/search-research/serperdevtool">
    Google search API integration for comprehensive web search capabilities.
  </Card>

  <Card title="Brave Search Tool" icon="shield" href="/en/tools/search-research/bravesearchtool">
    Privacy-focused search with Brave's independent search index.
  </Card>

  <Card title="Exa Search Tool" icon="magnifying-glass" href="/en/tools/search-research/exasearchtool">
    AI-powered search for finding specific and relevant content.
  </Card>

  <Card title="LinkUp Search Tool" icon="link" href="/en/tools/search-research/linkupsearchtool">
    Real-time web search with fresh content indexing.
  </Card>

  <Card title="GitHub Search Tool" icon="github" href="/en/tools/search-research/githubsearchtool">
    Search GitHub repositories, code, issues, and documentation.
  </Card>

  <Card title="Website Search Tool" icon="globe" href="/en/tools/search-research/websitesearchtool">
    Search within specific websites and domains.
  </Card>

  <Card title="Code Docs Search Tool" icon="code" href="/en/tools/search-research/codedocssearchtool">
    Search through code documentation and technical resources.
  </Card>

  <Card title="YouTube Channel Search" icon="youtube" href="/en/tools/search-research/youtubechannelsearchtool">
    Search YouTube channels for specific content and creators.
  </Card>

  <Card title="YouTube Video Search" icon="play" href="/en/tools/search-research/youtubevideosearchtool">
    Find and analyze YouTube videos by topic, keyword, or criteria.
  </Card>
</CardGroup>

## **Common Use Cases**

* **Market Research**: Search for industry trends and competitor analysis
* **Content Discovery**: Find relevant articles, videos, and resources
* **Code Research**: Search repositories and documentation for solutions
* **Lead Generation**: Research companies and individuals
* **Academic Research**: Find scholarly articles and technical papers

```python
from crewai_tools import SerperDevTool, GitHubSearchTool, YoutubeVideoSearchTool

# Create research tools
web_search = SerperDevTool()
code_search = GitHubSearchTool()
video_research = YoutubeVideoSearchTool()

# Add to your agent
agent = Agent(
    role="Research Analyst",
    tools=[web_search, code_search, video_research],
    goal="Gather comprehensive information on any topic"
)
```


# Google Serper Search
Source: https://docs.crewai.com/en/tools/search-research/serperdevtool

The `SerperDevTool` is designed to search the internet and return the most relevant results.

# `SerperDevTool`

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

This tool is designed to perform a semantic search for a specified query from a text's content across the internet. It utilizes the [serper.dev](https://serper.dev) API
to fetch and display the most relevant search results based on the query provided by the user.

## Installation

To incorporate this tool into your project, follow the installation instructions below:

```shell
pip install 'crewai[tools]'
```

## Example

The following example demonstrates how to initialize the tool and execute a search with a given query:

```python Code
from crewai_tools import SerperDevTool

# Initialize the tool for internet searching capabilities
tool = SerperDevTool()
```

## Steps to Get Started

To effectively use the `SerperDevTool`, follow these steps:

1. **Package Installation**: Confirm that the `crewai[tools]` package is installed in your Python environment.
2. **API Key Acquisition**: Acquire a `serper.dev` API key by registering for a free account at `serper.dev`.
3. **Environment Configuration**: Store your obtained API key in an environment variable named `SERPER_API_KEY` to facilitate its use by the tool.

## Parameters

The `SerperDevTool` comes with several parameters that will be passed to the API :

* **search\_url**: The URL endpoint for the search API. (Default is `https://google.serper.dev/search`)

* **country**: Optional. Specify the country for the search results.

* **location**: Optional. Specify the location for the search results.

* **locale**: Optional. Specify the locale for the search results.

* **n\_results**: Number of search results to return. Default is `10`.

The values for `country`, `location`, `locale` and `search_url` can be found on the [Serper Playground](https://serper.dev/playground).

## Example with Parameters

Here is an example demonstrating how to use the tool with additional parameters:

```python Code
from crewai_tools import SerperDevTool

tool = SerperDevTool(
    search_url="https://google.serper.dev/scholar",
    n_results=2,
)

print(tool.run(search_query="ChatGPT"))

# Using Tool: Search the internet

# Search results: Title: Role of chat gpt in public health
# Link: https://link.springer.com/article/10.1007/s10439-023-03172-7
# Snippet: ‚Ä¶ ChatGPT in public health. In this overview, we will examine the potential uses of ChatGPT in
# ---
# Title: Potential use of chat gpt in global warming
# Link: https://link.springer.com/article/10.1007/s10439-023-03171-8
# Snippet: ‚Ä¶ as ChatGPT, have the potential to play a critical role in advancing our understanding of climate
# ---

```

```python Code
from crewai_tools import SerperDevTool

tool = SerperDevTool(
    country="fr",
    locale="fr",
    location="Paris, Paris, Ile-de-France, France",
    n_results=2,
)

print(tool.run(search_query="Jeux Olympiques"))

# Using Tool: Search the internet

# Search results: Title: Jeux Olympiques de Paris 2024 - Actualit√©s, calendriers, r√©sultats
# Link: https://olympics.com/fr/paris-2024
# Snippet: Quels sont les sports pr√©sents aux Jeux Olympiques de Paris 2024 ? ¬∑ Athl√©tisme ¬∑ Aviron ¬∑ Badminton ¬∑ Basketball ¬∑ Basketball 3x3 ¬∑ Boxe ¬∑ Breaking ¬∑ Cano√´ ...
# ---
# Title: Billetterie Officielle de Paris 2024 - Jeux Olympiques et Paralympiques
# Link: https://tickets.paris2024.org/
# Snippet: Achetez vos billets exclusivement sur le site officiel de la billetterie de Paris 2024 pour participer au plus grand √©v√©nement sportif au monde.
# ---
```

## Conclusion

By integrating the `SerperDevTool` into Python projects, users gain the ability to conduct real-time, relevant searches across the internet directly from their applications.
The updated parameters allow for more customized and localized search results. By adhering to the setup and usage guidelines provided, incorporating this tool into projects is streamlined and straightforward.


# Website RAG Search
Source: https://docs.crewai.com/en/tools/search-research/websitesearchtool

The `WebsiteSearchTool` is designed to perform a RAG (Retrieval-Augmented Generation) search within the content of a website.

# `WebsiteSearchTool`

<Note>
  The WebsiteSearchTool is currently in an experimental phase. We are actively working on incorporating this tool into our suite of offerings and will update the documentation accordingly.
</Note>

## Description

The WebsiteSearchTool is designed as a concept for conducting semantic searches within the content of websites.
It aims to leverage advanced machine learning models like Retrieval-Augmented Generation (RAG) to navigate and extract information from specified URLs efficiently.
This tool intends to offer flexibility, allowing users to perform searches across any website or focus on specific websites of interest.
Please note, the current implementation details of the WebsiteSearchTool are under development, and its functionalities as described may not yet be accessible.

## Installation

To prepare your environment for when the WebsiteSearchTool becomes available, you can install the foundational package with:

```shell
pip install 'crewai[tools]'
```

This command installs the necessary dependencies to ensure that once the tool is fully integrated, users can start using it immediately.

## Example Usage

Below are examples of how the WebsiteSearchTool could be utilized in different scenarios. Please note, these examples are illustrative and represent planned functionality:

```python Code
from crewai_tools import WebsiteSearchTool

# Example of initiating tool that agents can use
# to search across any discovered websites
tool = WebsiteSearchTool()

# Example of limiting the search to the content of a specific website,
# so now agents can only search within that website
tool = WebsiteSearchTool(website='https://example.com')
```

## Arguments

* `website`: An optional argument intended to specify the website URL for focused searches. This argument is designed to enhance the tool's flexibility by allowing targeted searches when necessary.

## Customization Options

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python Code
tool = WebsiteSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# YouTube Channel RAG Search
Source: https://docs.crewai.com/en/tools/search-research/youtubechannelsearchtool

The `YoutubeChannelSearchTool` is designed to perform a RAG (Retrieval-Augmented Generation) search within the content of a Youtube channel.

# `YoutubeChannelSearchTool`

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

This tool is designed to perform semantic searches within a specific Youtube channel's content.
Leveraging the RAG (Retrieval-Augmented Generation) methodology, it provides relevant search results,
making it invaluable for extracting information or finding specific content without the need to manually sift through videos.
It streamlines the search process within Youtube channels, catering to researchers, content creators, and viewers seeking specific information or topics.

## Installation

To utilize the YoutubeChannelSearchTool, the `crewai_tools` package must be installed. Execute the following command in your shell to install:

```shell
pip install 'crewai[tools]'
```

## Example

The following example demonstrates how to use the `YoutubeChannelSearchTool` with a CrewAI agent:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import YoutubeChannelSearchTool

# Initialize the tool for general YouTube channel searches
youtube_channel_tool = YoutubeChannelSearchTool()

# Define an agent that uses the tool
channel_researcher = Agent(
    role="Channel Researcher",
    goal="Extract relevant information from YouTube channels",
    backstory="An expert researcher who specializes in analyzing YouTube channel content.",
    tools=[youtube_channel_tool],
    verbose=True,
)

# Example task to search for information in a specific channel
research_task = Task(
    description="Search for information about machine learning tutorials in the YouTube channel {youtube_channel_handle}",
    expected_output="A summary of the key machine learning tutorials available on the channel.",
    agent=channel_researcher,
)

# Create and run the crew
crew = Crew(agents=[channel_researcher], tasks=[research_task])
result = crew.kickoff(inputs={"youtube_channel_handle": "@exampleChannel"})
```

You can also initialize the tool with a specific YouTube channel handle:

```python Code
# Initialize the tool with a specific YouTube channel handle
youtube_channel_tool = YoutubeChannelSearchTool(
    youtube_channel_handle='@exampleChannel'
)

# Define an agent that uses the tool
channel_researcher = Agent(
    role="Channel Researcher",
    goal="Extract relevant information from a specific YouTube channel",
    backstory="An expert researcher who specializes in analyzing YouTube channel content.",
    tools=[youtube_channel_tool],
    verbose=True,
)
```

## Parameters

The `YoutubeChannelSearchTool` accepts the following parameters:

* **youtube\_channel\_handle**: Optional. The handle of the YouTube channel to search within. If provided during initialization, the agent won't need to specify it when using the tool. If the handle doesn't start with '@', it will be automatically added.
* **config**: Optional. Configuration for the underlying RAG system, including LLM and embedder settings.
* **summarize**: Optional. Whether to summarize the retrieved content. Default is `False`.

When using the tool with an agent, the agent will need to provide:

* **search\_query**: Required. The search query to find relevant information in the channel content.
* **youtube\_channel\_handle**: Required only if not provided during initialization. The handle of the YouTube channel to search within.

## Custom Model and Embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python Code
youtube_channel_tool = YoutubeChannelSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```

## Agent Integration Example

Here's a more detailed example of how to integrate the `YoutubeChannelSearchTool` with a CrewAI agent:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import YoutubeChannelSearchTool

# Initialize the tool
youtube_channel_tool = YoutubeChannelSearchTool()

# Define an agent that uses the tool
channel_researcher = Agent(
    role="Channel Researcher",
    goal="Extract and analyze information from YouTube channels",
    backstory="""You are an expert channel researcher who specializes in extracting
    and analyzing information from YouTube channels. You have a keen eye for detail
    and can quickly identify key points and insights from video content across an entire channel.""",
    tools=[youtube_channel_tool],
    verbose=True,
)

# Create a task for the agent
research_task = Task(
    description="""
    Search for information about data science projects and tutorials
    in the YouTube channel {youtube_channel_handle}.

    Focus on:
    1. Key data science techniques covered
    2. Popular tutorial series
    3. Most viewed or recommended videos

    Provide a comprehensive summary of these points.
    """,
    expected_output="A detailed summary of data science content available on the channel.",
    agent=channel_researcher,
)

# Run the task
crew = Crew(agents=[channel_researcher], tasks=[research_task])
result = crew.kickoff(inputs={"youtube_channel_handle": "@exampleDataScienceChannel"})
```

## Implementation Details

The `YoutubeChannelSearchTool` is implemented as a subclass of `RagTool`, which provides the base functionality for Retrieval-Augmented Generation:

```python Code
class YoutubeChannelSearchTool(RagTool):
    name: str = "Search a Youtube Channels content"
    description: str = "A tool that can be used to semantic search a query from a Youtube Channels content."
    args_schema: Type[BaseModel] = YoutubeChannelSearchToolSchema

    def __init__(self, youtube_channel_handle: Optional[str] = None, **kwargs):
        super().__init__(**kwargs)
        if youtube_channel_handle is not None:
            kwargs["data_type"] = DataType.YOUTUBE_CHANNEL
            self.add(youtube_channel_handle)
            self.description = f"A tool that can be used to semantic search a query the {youtube_channel_handle} Youtube Channels content."
            self.args_schema = FixedYoutubeChannelSearchToolSchema
            self._generate_description()

    def add(
        self,
        youtube_channel_handle: str,
        **kwargs: Any,
    ) -> None:
        if not youtube_channel_handle.startswith("@"):
            youtube_channel_handle = f"@{youtube_channel_handle}"
        super().add(youtube_channel_handle, **kwargs)
```

## Conclusion

The `YoutubeChannelSearchTool` provides a powerful way to search and extract information from YouTube channel content using RAG techniques. By enabling agents to search across an entire channel's videos, it facilitates information extraction and analysis tasks that would otherwise be difficult to perform. This tool is particularly useful for research, content analysis, and knowledge extraction from YouTube channels.


# YouTube Video RAG Search
Source: https://docs.crewai.com/en/tools/search-research/youtubevideosearchtool

The `YoutubeVideoSearchTool` is designed to perform a RAG (Retrieval-Augmented Generation) search within the content of a Youtube video.

# `YoutubeVideoSearchTool`

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

This tool is part of the `crewai_tools` package and is designed to perform semantic searches within Youtube video content, utilizing Retrieval-Augmented Generation (RAG) techniques.
It is one of several "Search" tools in the package that leverage RAG for different sources.
The YoutubeVideoSearchTool allows for flexibility in searches; users can search across any Youtube video content without specifying a video URL,
or they can target their search to a specific Youtube video by providing its URL.

## Installation

To utilize the `YoutubeVideoSearchTool`, you must first install the `crewai_tools` package.
This package contains the `YoutubeVideoSearchTool` among other utilities designed to enhance your data analysis and processing tasks.
Install the package by executing the following command in your terminal:

```shell
pip install 'crewai[tools]'
```

## Example

The following example demonstrates how to use the `YoutubeVideoSearchTool` with a CrewAI agent:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import YoutubeVideoSearchTool

# Initialize the tool for general YouTube video searches
youtube_search_tool = YoutubeVideoSearchTool()

# Define an agent that uses the tool
video_researcher = Agent(
    role="Video Researcher",
    goal="Extract relevant information from YouTube videos",
    backstory="An expert researcher who specializes in analyzing video content.",
    tools=[youtube_search_tool],
    verbose=True,
)

# Example task to search for information in a specific video
research_task = Task(
    description="Search for information about machine learning frameworks in the YouTube video at {youtube_video_url}",
    expected_output="A summary of the key machine learning frameworks mentioned in the video.",
    agent=video_researcher,
)

# Create and run the crew
crew = Crew(agents=[video_researcher], tasks=[research_task])
result = crew.kickoff(inputs={"youtube_video_url": "https://youtube.com/watch?v=example"})
```

You can also initialize the tool with a specific YouTube video URL:

```python Code
# Initialize the tool with a specific YouTube video URL
youtube_search_tool = YoutubeVideoSearchTool(
    youtube_video_url='https://youtube.com/watch?v=example'
)

# Define an agent that uses the tool
video_researcher = Agent(
    role="Video Researcher",
    goal="Extract relevant information from a specific YouTube video",
    backstory="An expert researcher who specializes in analyzing video content.",
    tools=[youtube_search_tool],
    verbose=True,
)
```

## Parameters

The `YoutubeVideoSearchTool` accepts the following parameters:

* **youtube\_video\_url**: Optional. The URL of the YouTube video to search within. If provided during initialization, the agent won't need to specify it when using the tool.
* **config**: Optional. Configuration for the underlying RAG system, including LLM and embedder settings.
* **summarize**: Optional. Whether to summarize the retrieved content. Default is `False`.

When using the tool with an agent, the agent will need to provide:

* **search\_query**: Required. The search query to find relevant information in the video content.
* **youtube\_video\_url**: Required only if not provided during initialization. The URL of the YouTube video to search within.

## Custom Model and Embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python Code
youtube_search_tool = YoutubeVideoSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # or openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```

## Agent Integration Example

Here's a more detailed example of how to integrate the `YoutubeVideoSearchTool` with a CrewAI agent:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import YoutubeVideoSearchTool

# Initialize the tool
youtube_search_tool = YoutubeVideoSearchTool()

# Define an agent that uses the tool
video_researcher = Agent(
    role="Video Researcher",
    goal="Extract and analyze information from YouTube videos",
    backstory="""You are an expert video researcher who specializes in extracting
    and analyzing information from YouTube videos. You have a keen eye for detail
    and can quickly identify key points and insights from video content.""",
    tools=[youtube_search_tool],
    verbose=True,
)

# Create a task for the agent
research_task = Task(
    description="""
    Search for information about recent advancements in artificial intelligence
    in the YouTube video at {youtube_video_url}.

    Focus on:
    1. Key AI technologies mentioned
    2. Real-world applications discussed
    3. Future predictions made by the speaker

    Provide a comprehensive summary of these points.
    """,
    expected_output="A detailed summary of AI advancements, applications, and future predictions from the video.",
    agent=video_researcher,
)

# Run the task
crew = Crew(agents=[video_researcher], tasks=[research_task])
result = crew.kickoff(inputs={"youtube_video_url": "https://youtube.com/watch?v=example"})
```

## Implementation Details

The `YoutubeVideoSearchTool` is implemented as a subclass of `RagTool`, which provides the base functionality for Retrieval-Augmented Generation:

```python Code
class YoutubeVideoSearchTool(RagTool):
    name: str = "Search a Youtube Video content"
    description: str = "A tool that can be used to semantic search a query from a Youtube Video content."
    args_schema: Type[BaseModel] = YoutubeVideoSearchToolSchema

    def __init__(self, youtube_video_url: Optional[str] = None, **kwargs):
        super().__init__(**kwargs)
        if youtube_video_url is not None:
            kwargs["data_type"] = DataType.YOUTUBE_VIDEO
            self.add(youtube_video_url)
            self.description = f"A tool that can be used to semantic search a query the {youtube_video_url} Youtube Video content."
            self.args_schema = FixedYoutubeVideoSearchToolSchema
            self._generate_description()
```

## Conclusion

The `YoutubeVideoSearchTool` provides a powerful way to search and extract information from YouTube video content using RAG techniques. By enabling agents to search within video content, it facilitates information extraction and analysis tasks that would otherwise be difficult to perform. This tool is particularly useful for research, content analysis, and knowledge extraction from video sources.


# Browserbase Web Loader
Source: https://docs.crewai.com/en/tools/web-scraping/browserbaseloadtool

Browserbase is a developer platform to reliably run, manage, and monitor headless browsers.

# `BrowserbaseLoadTool`

## Description

[Browserbase](https://browserbase.com) is a developer platform to reliably run, manage, and monitor headless browsers.

Power your AI data retrievals with:

* [Serverless Infrastructure](https://docs.browserbase.com/under-the-hood) providing reliable browsers to extract data from complex UIs
* [Stealth Mode](https://docs.browserbase.com/features/stealth-mode) with included fingerprinting tactics and automatic captcha solving
* [Session Debugger](https://docs.browserbase.com/features/sessions) to inspect your Browser Session with networks timeline and logs
* [Live Debug](https://docs.browserbase.com/guides/session-debug-connection/browser-remote-control) to quickly debug your automation

## Installation

* Get an API key and Project ID from [browserbase.com](https://browserbase.com) and set it in environment variables (`BROWSERBASE_API_KEY`, `BROWSERBASE_PROJECT_ID`).
* Install the [Browserbase SDK](http://github.com/browserbase/python-sdk) along with `crewai[tools]` package:

```shell
pip install browserbase 'crewai[tools]'
```

## Example

Utilize the BrowserbaseLoadTool as follows to allow your agent to load websites:

```python Code
from crewai_tools import BrowserbaseLoadTool

# Initialize the tool with the Browserbase API key and Project ID
tool = BrowserbaseLoadTool()
```

## Arguments

The following parameters can be used to customize the `BrowserbaseLoadTool`'s behavior:

| Argument          | Type     | Description                                                                           |
| :---------------- | :------- | :------------------------------------------------------------------------------------ |
| **api\_key**      | `string` | *Optional*. Browserbase API key. Default is `BROWSERBASE_API_KEY` env variable.       |
| **project\_id**   | `string` | *Optional*. Browserbase Project ID. Default is `BROWSERBASE_PROJECT_ID` env variable. |
| **text\_content** | `bool`   | *Optional*. Retrieve only text content. Default is `False`.                           |
| **session\_id**   | `string` | *Optional*. Provide an existing Session ID.                                           |
| **proxy**         | `bool`   | *Optional*. Enable/Disable Proxies. Default is `False`.                               |


# Firecrawl Crawl Website
Source: https://docs.crewai.com/en/tools/web-scraping/firecrawlcrawlwebsitetool

The `FirecrawlCrawlWebsiteTool` is designed to crawl and convert websites into clean markdown or structured data.

# `FirecrawlCrawlWebsiteTool`

## Description

[Firecrawl](https://firecrawl.dev) is a platform for crawling and convert any website into clean markdown or structured data.

## Installation

* Get an API key from [firecrawl.dev](https://firecrawl.dev) and set it in environment variables (`FIRECRAWL_API_KEY`).
* Install the [Firecrawl SDK](https://github.com/mendableai/firecrawl) along with `crewai[tools]` package:

```shell
pip install firecrawl-py 'crewai[tools]'
```

## Example

Utilize the FirecrawlScrapeFromWebsiteTool as follows to allow your agent to load websites:

```python Code
from crewai_tools import FirecrawlCrawlWebsiteTool

tool = FirecrawlCrawlWebsiteTool(url='firecrawl.dev')
```

## Arguments

* `api_key`: Optional. Specifies Firecrawl API key. Defaults is the `FIRECRAWL_API_KEY` environment variable.
* `url`: The base URL to start crawling from.
* `page_options`: Optional.
  * `onlyMainContent`: Optional. Only return the main content of the page excluding headers, navs, footers, etc.
  * `includeHtml`: Optional. Include the raw HTML content of the page. Will output a html key in the response.
* `crawler_options`: Optional. Options for controlling the crawling behavior.
  * `includes`: Optional. URL patterns to include in the crawl.
  * `exclude`: Optional. URL patterns to exclude from the crawl.
  * `generateImgAltText`: Optional. Generate alt text for images using LLMs (requires a paid plan).
  * `returnOnlyUrls`: Optional. If true, returns only the URLs as a list in the crawl status. Note: the response will be a list of URLs inside the data, not a list of documents.
  * `maxDepth`: Optional. Maximum depth to crawl. Depth 1 is the base URL, depth 2 includes the base URL and its direct children, and so on.
  * `mode`: Optional. The crawling mode to use. Fast mode crawls 4x faster on websites without a sitemap but may not be as accurate and shouldn't be used on heavily JavaScript-rendered websites.
  * `limit`: Optional. Maximum number of pages to crawl.
  * `timeout`: Optional. Timeout in milliseconds for the crawling operation.


# Firecrawl Scrape Website
Source: https://docs.crewai.com/en/tools/web-scraping/firecrawlscrapewebsitetool

The `FirecrawlScrapeWebsiteTool` is designed to scrape websites and convert them into clean markdown or structured data.

# `FirecrawlScrapeWebsiteTool`

## Description

[Firecrawl](https://firecrawl.dev) is a platform for crawling and convert any website into clean markdown or structured data.

## Installation

* Get an API key from [firecrawl.dev](https://firecrawl.dev) and set it in environment variables (`FIRECRAWL_API_KEY`).
* Install the [Firecrawl SDK](https://github.com/mendableai/firecrawl) along with `crewai[tools]` package:

```shell
pip install firecrawl-py 'crewai[tools]'
```

## Example

Utilize the FirecrawlScrapeWebsiteTool as follows to allow your agent to load websites:

```python Code
from crewai_tools import FirecrawlScrapeWebsiteTool

tool = FirecrawlScrapeWebsiteTool(url='firecrawl.dev')
```

## Arguments

* `api_key`: Optional. Specifies Firecrawl API key. Defaults is the `FIRECRAWL_API_KEY` environment variable.
* `url`: The URL to scrape.
* `page_options`: Optional.
  * `onlyMainContent`: Optional. Only return the main content of the page excluding headers, navs, footers, etc.
  * `includeHtml`: Optional. Include the raw HTML content of the page. Will output a html key in the response.
* `extractor_options`: Optional. Options for LLM-based extraction of structured information from the page content
  * `mode`: The extraction mode to use, currently supports 'llm-extraction'
  * `extractionPrompt`: Optional. A prompt describing what information to extract from the page
  * `extractionSchema`: Optional. The schema for the data to be extracted
* `timeout`: Optional. Timeout in milliseconds for the request


# Firecrawl Search
Source: https://docs.crewai.com/en/tools/web-scraping/firecrawlsearchtool

The `FirecrawlSearchTool` is designed to search websites and convert them into clean markdown or structured data.

# `FirecrawlSearchTool`

## Description

[Firecrawl](https://firecrawl.dev) is a platform for crawling and convert any website into clean markdown or structured data.

## Installation

* Get an API key from [firecrawl.dev](https://firecrawl.dev) and set it in environment variables (`FIRECRAWL_API_KEY`).
* Install the [Firecrawl SDK](https://github.com/mendableai/firecrawl) along with `crewai[tools]` package:

```shell
pip install firecrawl-py 'crewai[tools]'
```

## Example

Utilize the FirecrawlSearchTool as follows to allow your agent to load websites:

```python Code
from crewai_tools import FirecrawlSearchTool

tool = FirecrawlSearchTool(query='what is firecrawl?')
```

## Arguments

* `api_key`: Optional. Specifies Firecrawl API key. Defaults is the `FIRECRAWL_API_KEY` environment variable.
* `query`: The search query string to be used for searching.
* `page_options`: Optional. Options for result formatting.
  * `onlyMainContent`: Optional. Only return the main content of the page excluding headers, navs, footers, etc.
  * `includeHtml`: Optional. Include the raw HTML content of the page. Will output a html key in the response.
  * `fetchPageContent`: Optional. Fetch the full content of the page.
* `search_options`: Optional. Options for controlling the crawling behavior.
  * `limit`: Optional. Maximum number of pages to crawl.


# Hyperbrowser Load Tool
Source: https://docs.crewai.com/en/tools/web-scraping/hyperbrowserloadtool

The `HyperbrowserLoadTool` enables web scraping and crawling using Hyperbrowser.

# `HyperbrowserLoadTool`

## Description

The `HyperbrowserLoadTool` enables web scraping and crawling using [Hyperbrowser](https://hyperbrowser.ai), a platform for running and scaling headless browsers. This tool allows you to scrape a single page or crawl an entire site, returning the content in properly formatted markdown or HTML.

Key Features:

* Instant Scalability - Spin up hundreds of browser sessions in seconds without infrastructure headaches
* Simple Integration - Works seamlessly with popular tools like Puppeteer and Playwright
* Powerful APIs - Easy to use APIs for scraping/crawling any site
* Bypass Anti-Bot Measures - Built-in stealth mode, ad blocking, automatic CAPTCHA solving, and rotating proxies

## Installation

To use this tool, you need to install the Hyperbrowser SDK:

```shell
uv add hyperbrowser
```

## Steps to Get Started

To effectively use the `HyperbrowserLoadTool`, follow these steps:

1. **Sign Up**: Head to [Hyperbrowser](https://app.hyperbrowser.ai/) to sign up and generate an API key.
2. **API Key**: Set the `HYPERBROWSER_API_KEY` environment variable or pass it directly to the tool constructor.
3. **Install SDK**: Install the Hyperbrowser SDK using the command above.

## Example

The following example demonstrates how to initialize the tool and use it to scrape a website:

```python Code
from crewai_tools import HyperbrowserLoadTool
from crewai import Agent

# Initialize the tool with your API key
tool = HyperbrowserLoadTool(api_key="your_api_key")  # Or use environment variable

# Define an agent that uses the tool
@agent
def web_researcher(self) -> Agent:
    '''
    This agent uses the HyperbrowserLoadTool to scrape websites
    and extract information.
    '''
    return Agent(
        config=self.agents_config["web_researcher"],
        tools=[tool]
    )
```

## Parameters

The `HyperbrowserLoadTool` accepts the following parameters:

### Constructor Parameters

* **api\_key**: Optional. Your Hyperbrowser API key. If not provided, it will be read from the `HYPERBROWSER_API_KEY` environment variable.

### Run Parameters

* **url**: Required. The website URL to scrape or crawl.
* **operation**: Optional. The operation to perform on the website. Either 'scrape' or 'crawl'. Default is 'scrape'.
* **params**: Optional. Additional parameters for the scrape or crawl operation.

## Supported Parameters

For detailed information on all supported parameters, visit:

* [Scrape Parameters](https://docs.hyperbrowser.ai/reference/sdks/python/scrape#start-scrape-job-and-wait)
* [Crawl Parameters](https://docs.hyperbrowser.ai/reference/sdks/python/crawl#start-crawl-job-and-wait)

## Return Format

The tool returns content in the following format:

* For **scrape** operations: The content of the page in markdown or HTML format.
* For **crawl** operations: The content of each page separated by dividers, including the URL of each page.

## Conclusion

The `HyperbrowserLoadTool` provides a powerful way to scrape and crawl websites, handling complex scenarios like anti-bot measures, CAPTCHAs, and more. By leveraging Hyperbrowser's platform, this tool enables agents to access and extract web content efficiently.


# Overview
Source: https://docs.crewai.com/en/tools/web-scraping/overview

Extract data from websites and automate browser interactions with powerful scraping tools

These tools enable your agents to interact with the web, extract data from websites, and automate browser-based tasks. From simple web scraping to complex browser automation, these tools cover all your web interaction needs.

## **Available Tools**

<CardGroup cols={2}>
  <Card title="Scrape Website Tool" icon="globe" href="/en/tools/web-scraping/scrapewebsitetool">
    General-purpose web scraping tool for extracting content from any website.
  </Card>

  <Card title="Scrape Element Tool" icon="crosshairs" href="/en/tools/web-scraping/scrapeelementfromwebsitetool">
    Target specific elements on web pages with precision scraping capabilities.
  </Card>

  <Card title="Firecrawl Crawl Tool" icon="spider" href="/en/tools/web-scraping/firecrawlcrawlwebsitetool">
    Crawl entire websites systematically with Firecrawl's powerful engine.
  </Card>

  <Card title="Firecrawl Scrape Tool" icon="fire" href="/en/tools/web-scraping/firecrawlscrapewebsitetool">
    High-performance web scraping with Firecrawl's advanced capabilities.
  </Card>

  <Card title="Firecrawl Search Tool" icon="magnifying-glass" href="/en/tools/web-scraping/firecrawlsearchtool">
    Search and extract specific content using Firecrawl's search features.
  </Card>

  <Card title="Selenium Scraping Tool" icon="robot" href="/en/tools/web-scraping/seleniumscrapingtool">
    Browser automation and scraping with Selenium WebDriver capabilities.
  </Card>

  <Card title="ScrapFly Tool" icon="plane" href="/en/tools/web-scraping/scrapflyscrapetool">
    Professional web scraping with ScrapFly's premium scraping service.
  </Card>

  <Card title="ScrapGraph Tool" icon="network-wired" href="/en/tools/web-scraping/scrapegraphscrapetool">
    Graph-based web scraping for complex data relationships.
  </Card>

  <Card title="Spider Tool" icon="spider" href="/en/tools/web-scraping/spidertool">
    Comprehensive web crawling and data extraction capabilities.
  </Card>

  <Card title="BrowserBase Tool" icon="browser" href="/en/tools/web-scraping/browserbaseloadtool">
    Cloud-based browser automation with BrowserBase infrastructure.
  </Card>

  <Card title="HyperBrowser Tool" icon="window-maximize" href="/en/tools/web-scraping/hyperbrowserloadtool">
    Fast browser interactions with HyperBrowser's optimized engine.
  </Card>

  <Card title="Stagehand Tool" icon="hand" href="/en/tools/web-scraping/stagehandtool">
    Intelligent browser automation with natural language commands.
  </Card>

  <Card title="Oxylabs Scraper Tool" icon="globe" href="/en/tools/web-scraping/oxylabsscraperstool">
    Access web data at scale with Oxylabs.
  </Card>
</CardGroup>

## **Common Use Cases**

* **Data Extraction**: Scrape product information, prices, and reviews
* **Content Monitoring**: Track changes on websites and news sources
* **Lead Generation**: Extract contact information and business data
* **Market Research**: Gather competitive intelligence and market data
* **Testing & QA**: Automate browser testing and validation workflows
* **Social Media**: Extract posts, comments, and social media analytics

## **Quick Start Example**

```python
from crewai_tools import ScrapeWebsiteTool, FirecrawlScrapeWebsiteTool, SeleniumScrapingTool

# Create scraping tools
simple_scraper = ScrapeWebsiteTool()
advanced_scraper = FirecrawlScrapeWebsiteTool()
browser_automation = SeleniumScrapingTool()

# Add to your agent
agent = Agent(
    role="Web Research Specialist",
    tools=[simple_scraper, advanced_scraper, browser_automation],
    goal="Extract and analyze web data efficiently"
)
```

## **Scraping Best Practices**

* **Respect robots.txt**: Always check and follow website scraping policies
* **Rate Limiting**: Implement delays between requests to avoid overwhelming servers
* **User Agents**: Use appropriate user agent strings to identify your bot
* **Legal Compliance**: Ensure your scraping activities comply with terms of service
* **Error Handling**: Implement robust error handling for network issues and blocked requests
* **Data Quality**: Validate and clean extracted data before processing

## **Tool Selection Guide**

* **Simple Tasks**: Use `ScrapeWebsiteTool` for basic content extraction
* **JavaScript-Heavy Sites**: Use `SeleniumScrapingTool` for dynamic content
* **Scale & Performance**: Use `FirecrawlScrapeWebsiteTool` for high-volume scraping
* **Cloud Infrastructure**: Use `BrowserBaseLoadTool` for scalable browser automation
* **Complex Workflows**: Use `StagehandTool` for intelligent browser interactions


# Oxylabs Scrapers
Source: https://docs.crewai.com/en/tools/web-scraping/oxylabsscraperstool

Oxylabs Scrapers allow to easily access the information from the respective sources. Please see the list of available sources below:
  - `Amazon Product`
  - `Amazon Search`
  - `Google Seach`
  - `Universal`


## Installation

Get the credentials by creating an Oxylabs Account [here](https://oxylabs.io).

```shell
pip install 'crewai[tools]' oxylabs
```

Check [Oxylabs Documentation](https://developers.oxylabs.io/scraping-solutions/web-scraper-api/targets) to get more information about API parameters.

# `OxylabsAmazonProductScraperTool`

### Example

```python
from crewai_tools import OxylabsAmazonProductScraperTool

# make sure OXYLABS_USERNAME and OXYLABS_PASSWORD variables are set
tool = OxylabsAmazonProductScraperTool()

result = tool.run(query="AAAAABBBBCC")

print(result)
```

### Parameters

* `query` - 10-symbol ASIN code.
* `domain` - domain localization for Amazon.
* `geo_location` - the *Deliver to* location.
* `user_agent_type` - device type and browser.
* `render` - enables JavaScript rendering when set to `html`.
* `callback_url` - URL to your callback endpoint.
* `context` - Additional advanced settings and controls for specialized requirements.
* `parse` - returns parsed data when set to true.
* `parsing_instructions` - define your own parsing and data transformation logic that will be executed on an HTML scraping result.

### Advanced example

```python
from crewai_tools import OxylabsAmazonProductScraperTool

# make sure OXYLABS_USERNAME and OXYLABS_PASSWORD variables are set
tool = OxylabsAmazonProductScraperTool(
    config={
        "domain": "com",
        "parse": True,
        "context": [
            {
                "key": "autoselect_variant",
                "value": True
            }
        ]
    }
)

result = tool.run(query="AAAAABBBBCC")

print(result)
```

# `OxylabsAmazonSearchScraperTool`

### Example

```python
from crewai_tools import OxylabsAmazonSearchScraperTool

# make sure OXYLABS_USERNAME and OXYLABS_PASSWORD variables are set
tool = OxylabsAmazonSearchScraperTool()

result = tool.run(query="headsets")

print(result)
```

### Parameters

* `query` - Amazon search term.
* `domain` - Domain localization for Bestbuy.
* `start_page` - starting page number.
* `pages` - number of pages to retrieve.
* `geo_location` - the *Deliver to* location.
* `user_agent_type` - device type and browser.
* `render` - enables JavaScript rendering when set to `html`.
* `callback_url` - URL to your callback endpoint.
* `context` - Additional advanced settings and controls for specialized requirements.
* `parse` - returns parsed data when set to true.
* `parsing_instructions` - define your own parsing and data transformation logic that will be executed on an HTML scraping result.

### Advanced example

```python
from crewai_tools import OxylabsAmazonSearchScraperTool

# make sure OXYLABS_USERNAME and OXYLABS_PASSWORD variables are set
tool = OxylabsAmazonSearchScraperTool(
    config={
        "domain": 'nl',
        "start_page": 2,
        "pages": 2,
        "parse": True,
        "context": [
            {'key': 'category_id', 'value': 16391693031}
        ],
    }
)

result = tool.run(query='nirvana tshirt')

print(result)
```

# `OxylabsGoogleSearchScraperTool`

### Example

```python
from crewai_tools import OxylabsGoogleSearchScraperTool

# make sure OXYLABS_USERNAME and OXYLABS_PASSWORD variables are set
tool = OxylabsGoogleSearchScraperTool()

result = tool.run(query="iPhone 16")

print(result)
```

### Parameters

* `query` - search keyword.
* `domain` - domain localization for Google.
* `start_page` - starting page number.
* `pages` - number of pages to retrieve.
* `limit` - number of results to retrieve in each page.
* `locale` - `Accept-Language` header value which changes your Google search page web interface language.
* `geo_location` - the geographical location that the result should be adapted for. Using this parameter correctly is extremely important to get the right data.
* `user_agent_type` - device type and browser.
* `render` - enables JavaScript rendering when set to `html`.
* `callback_url` - URL to your callback endpoint.
* `context` - Additional advanced settings and controls for specialized requirements.
* `parse` - returns parsed data when set to true.
* `parsing_instructions` - define your own parsing and data transformation logic that will be executed on an HTML scraping result.

### Advanced example

```python
from crewai_tools import OxylabsGoogleSearchScraperTool

# make sure OXYLABS_USERNAME and OXYLABS_PASSWORD variables are set
tool = OxylabsGoogleSearchScraperTool(
    config={
        "parse": True,
        "geo_location": "Paris, France",
        "user_agent_type": "tablet",
    }
)

result = tool.run(query="iPhone 16")

print(result)
```

# `OxylabsUniversalScraperTool`

### Example

```python
from crewai_tools import OxylabsUniversalScraperTool

# make sure OXYLABS_USERNAME and OXYLABS_PASSWORD variables are set
tool = OxylabsUniversalScraperTool()

result = tool.run(url="https://ip.oxylabs.io")

print(result)
```

### Parameters

* `url` - website url to scrape.
* `user_agent_type` - device type and browser.
* `geo_location` - sets the proxy's geolocation to retrieve data.
* `render` - enables JavaScript rendering when set to `html`.
* `callback_url` - URL to your callback endpoint.
* `context` - Additional advanced settings and controls for specialized requirements.
* `parse` - returns parsed data when set to `true`, as long as a dedicated parser exists for the submitted URL's page type.
* `parsing_instructions` - define your own parsing and data transformation logic that will be executed on an HTML scraping result.

### Advanced example

```python
from crewai_tools import OxylabsUniversalScraperTool

# make sure OXYLABS_USERNAME and OXYLABS_PASSWORD variables are set
tool = OxylabsUniversalScraperTool(
    config={
        "render": "html",
        "user_agent_type": "mobile",
        "context": [
            {"key": "force_headers", "value": True},
            {"key": "force_cookies", "value": True},
            {
                "key": "headers",
                "value": {
                    "Custom-Header-Name": "custom header content",
                },
            },
            {
                "key": "cookies",
                "value": [
                    {"key": "NID", "value": "1234567890"},
                    {"key": "1P JAR", "value": "0987654321"},
                ],
            },
            {"key": "http_method", "value": "get"},
            {"key": "follow_redirects", "value": True},
            {"key": "successful_status_codes", "value": [808, 909]},
        ],
    }
)

result = tool.run(url="https://ip.oxylabs.io")

print(result)
```


# Scrape Element From Website Tool
Source: https://docs.crewai.com/en/tools/web-scraping/scrapeelementfromwebsitetool

The `ScrapeElementFromWebsiteTool` enables CrewAI agents to extract specific elements from websites using CSS selectors.

# `ScrapeElementFromWebsiteTool`

## Description

The `ScrapeElementFromWebsiteTool` is designed to extract specific elements from websites using CSS selectors. This tool allows CrewAI agents to scrape targeted content from web pages, making it useful for data extraction tasks where only specific parts of a webpage are needed.

## Installation

To use this tool, you need to install the required dependencies:

```shell
uv add requests beautifulsoup4
```

## Steps to Get Started

To effectively use the `ScrapeElementFromWebsiteTool`, follow these steps:

1. **Install Dependencies**: Install the required packages using the command above.
2. **Identify CSS Selectors**: Determine the CSS selectors for the elements you want to extract from the website.
3. **Initialize the Tool**: Create an instance of the tool with the necessary parameters.

## Example

The following example demonstrates how to use the `ScrapeElementFromWebsiteTool` to extract specific elements from a website:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import ScrapeElementFromWebsiteTool

# Initialize the tool
scrape_tool = ScrapeElementFromWebsiteTool()

# Define an agent that uses the tool
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract specific information from websites",
    backstory="An expert in web scraping who can extract targeted content from web pages.",
    tools=[scrape_tool],
    verbose=True,
)

# Example task to extract headlines from a news website
scrape_task = Task(
    description="Extract the main headlines from the CNN homepage. Use the CSS selector '.headline' to target the headline elements.",
    expected_output="A list of the main headlines from CNN.",
    agent=web_scraper_agent,
)

# Create and run the crew
crew = Crew(agents=[web_scraper_agent], tasks=[scrape_task])
result = crew.kickoff()
```

You can also initialize the tool with predefined parameters:

```python Code
# Initialize the tool with predefined parameters
scrape_tool = ScrapeElementFromWebsiteTool(
    website_url="https://www.example.com",
    css_element=".main-content"
)
```

## Parameters

The `ScrapeElementFromWebsiteTool` accepts the following parameters during initialization:

* **website\_url**: Optional. The URL of the website to scrape. If provided during initialization, the agent won't need to specify it when using the tool.
* **css\_element**: Optional. The CSS selector for the elements to extract. If provided during initialization, the agent won't need to specify it when using the tool.
* **cookies**: Optional. A dictionary containing cookies to be sent with the request. This can be useful for websites that require authentication.

## Usage

When using the `ScrapeElementFromWebsiteTool` with an agent, the agent will need to provide the following parameters (unless they were specified during initialization):

* **website\_url**: The URL of the website to scrape.
* **css\_element**: The CSS selector for the elements to extract.

The tool will return the text content of all elements matching the CSS selector, joined by newlines.

```python Code
# Example of using the tool with an agent
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract specific elements from websites",
    backstory="An expert in web scraping who can extract targeted content using CSS selectors.",
    tools=[scrape_tool],
    verbose=True,
)

# Create a task for the agent to extract specific elements
extract_task = Task(
    description="""
    Extract all product titles from the featured products section on example.com.
    Use the CSS selector '.product-title' to target the title elements.
    """,
    expected_output="A list of product titles from the website",
    agent=web_scraper_agent,
)

# Run the task through a crew
crew = Crew(agents=[web_scraper_agent], tasks=[extract_task])
result = crew.kickoff()
```

## Implementation Details

The `ScrapeElementFromWebsiteTool` uses the `requests` library to fetch the web page and `BeautifulSoup` to parse the HTML and extract the specified elements:

```python Code
class ScrapeElementFromWebsiteTool(BaseTool):
    name: str = "Read a website content"
    description: str = "A tool that can be used to read a website content."

    # Implementation details...

    def _run(self, **kwargs: Any) -> Any:
        website_url = kwargs.get("website_url", self.website_url)
        css_element = kwargs.get("css_element", self.css_element)
        page = requests.get(
            website_url,
            headers=self.headers,
            cookies=self.cookies if self.cookies else {},
        )
        parsed = BeautifulSoup(page.content, "html.parser")
        elements = parsed.select(css_element)
        return "\n".join([element.get_text() for element in elements])
```

## Conclusion

The `ScrapeElementFromWebsiteTool` provides a powerful way to extract specific elements from websites using CSS selectors. By enabling agents to target only the content they need, it makes web scraping tasks more efficient and focused. This tool is particularly useful for data extraction, content monitoring, and research tasks where specific information needs to be extracted from web pages.


# Scrapegraph Scrape Tool
Source: https://docs.crewai.com/en/tools/web-scraping/scrapegraphscrapetool

The `ScrapegraphScrapeTool` leverages Scrapegraph AI's SmartScraper API to intelligently extract content from websites.

# `ScrapegraphScrapeTool`

## Description

The `ScrapegraphScrapeTool` is designed to leverage Scrapegraph AI's SmartScraper API to intelligently extract content from websites. This tool provides advanced web scraping capabilities with AI-powered content extraction, making it ideal for targeted data collection and content analysis tasks. Unlike traditional web scrapers, it can understand the context and structure of web pages to extract the most relevant information based on natural language prompts.

## Installation

To use this tool, you need to install the Scrapegraph Python client:

```shell
uv add scrapegraph-py
```

You'll also need to set up your Scrapegraph API key as an environment variable:

```shell
export SCRAPEGRAPH_API_KEY="your_api_key"
```

You can obtain an API key from [Scrapegraph AI](https://scrapegraphai.com).

## Steps to Get Started

To effectively use the `ScrapegraphScrapeTool`, follow these steps:

1. **Install Dependencies**: Install the required package using the command above.
2. **Set Up API Key**: Set your Scrapegraph API key as an environment variable or provide it during initialization.
3. **Initialize the Tool**: Create an instance of the tool with the necessary parameters.
4. **Define Extraction Prompts**: Create natural language prompts to guide the extraction of specific content.

## Example

The following example demonstrates how to use the `ScrapegraphScrapeTool` to extract content from a website:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import ScrapegraphScrapeTool

# Initialize the tool
scrape_tool = ScrapegraphScrapeTool(api_key="your_api_key")

# Define an agent that uses the tool
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract specific information from websites",
    backstory="An expert in web scraping who can extract targeted content from web pages.",
    tools=[scrape_tool],
    verbose=True,
)

# Example task to extract product information from an e-commerce site
scrape_task = Task(
    description="Extract product names, prices, and descriptions from the featured products section of example.com.",
    expected_output="A structured list of product information including names, prices, and descriptions.",
    agent=web_scraper_agent,
)

# Create and run the crew
crew = Crew(agents=[web_scraper_agent], tasks=[scrape_task])
result = crew.kickoff()
```

You can also initialize the tool with predefined parameters:

```python Code
# Initialize the tool with predefined parameters
scrape_tool = ScrapegraphScrapeTool(
    website_url="https://www.example.com",
    user_prompt="Extract all product prices and descriptions",
    api_key="your_api_key"
)
```

## Parameters

The `ScrapegraphScrapeTool` accepts the following parameters during initialization:

* **api\_key**: Optional. Your Scrapegraph API key. If not provided, it will look for the `SCRAPEGRAPH_API_KEY` environment variable.
* **website\_url**: Optional. The URL of the website to scrape. If provided during initialization, the agent won't need to specify it when using the tool.
* **user\_prompt**: Optional. Custom instructions for content extraction. If provided during initialization, the agent won't need to specify it when using the tool.
* **enable\_logging**: Optional. Whether to enable logging for the Scrapegraph client. Default is `False`.

## Usage

When using the `ScrapegraphScrapeTool` with an agent, the agent will need to provide the following parameters (unless they were specified during initialization):

* **website\_url**: The URL of the website to scrape.
* **user\_prompt**: Optional. Custom instructions for content extraction. Default is "Extract the main content of the webpage".

The tool will return the extracted content based on the provided prompt.

```python Code
# Example of using the tool with an agent
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract specific information from websites",
    backstory="An expert in web scraping who can extract targeted content from web pages.",
    tools=[scrape_tool],
    verbose=True,
)

# Create a task for the agent to extract specific content
extract_task = Task(
    description="Extract the main heading and summary from example.com",
    expected_output="The main heading and summary from the website",
    agent=web_scraper_agent,
)

# Run the task
crew = Crew(agents=[web_scraper_agent], tasks=[extract_task])
result = crew.kickoff()
```

## Error Handling

The `ScrapegraphScrapeTool` may raise the following exceptions:

* **ValueError**: When API key is missing or URL format is invalid.
* **RateLimitError**: When API rate limits are exceeded.
* **RuntimeError**: When scraping operation fails (network issues, API errors).

It's recommended to instruct agents to handle potential errors gracefully:

```python Code
# Create a task that includes error handling instructions
robust_extract_task = Task(
    description="""
    Extract the main heading from example.com.
    Be aware that you might encounter errors such as:
    - Invalid URL format
    - Missing API key
    - Rate limit exceeded
    - Network or API errors

    If you encounter any errors, provide a clear explanation of what went wrong
    and suggest possible solutions.
    """,
    expected_output="Either the extracted heading or a clear error explanation",
    agent=web_scraper_agent,
)
```

## Rate Limiting

The Scrapegraph API has rate limits that vary based on your subscription plan. Consider the following best practices:

* Implement appropriate delays between requests when processing multiple URLs.
* Handle rate limit errors gracefully in your application.
* Check your API plan limits on the Scrapegraph dashboard.

## Implementation Details

The `ScrapegraphScrapeTool` uses the Scrapegraph Python client to interact with the SmartScraper API:

```python Code
class ScrapegraphScrapeTool(BaseTool):
    """
    A tool that uses Scrapegraph AI to intelligently scrape website content.
    """

    # Implementation details...

    def _run(self, **kwargs: Any) -> Any:
        website_url = kwargs.get("website_url", self.website_url)
        user_prompt = (
            kwargs.get("user_prompt", self.user_prompt)
            or "Extract the main content of the webpage"
        )

        if not website_url:
            raise ValueError("website_url is required")

        # Validate URL format
        self._validate_url(website_url)

        try:
            # Make the SmartScraper request
            response = self._client.smartscraper(
                website_url=website_url,
                user_prompt=user_prompt,
            )

            return response
        # Error handling...
```

## Conclusion

The `ScrapegraphScrapeTool` provides a powerful way to extract content from websites using AI-powered understanding of web page structure. By enabling agents to target specific information using natural language prompts, it makes web scraping tasks more efficient and focused. This tool is particularly useful for data extraction, content monitoring, and research tasks where specific information needs to be extracted from web pages.


# Scrape Website
Source: https://docs.crewai.com/en/tools/web-scraping/scrapewebsitetool

The `ScrapeWebsiteTool` is designed to extract and read the content of a specified website.

# `ScrapeWebsiteTool`

<Note>
  We are still working on improving tools, so there might be unexpected behavior or changes in the future.
</Note>

## Description

A tool designed to extract and read the content of a specified website. It is capable of handling various types of web pages by making HTTP requests and parsing the received HTML content.
This tool can be particularly useful for web scraping tasks, data collection, or extracting specific information from websites.

## Installation

Install the crewai\_tools package

```shell
pip install 'crewai[tools]'
```

## Example

```python
from crewai_tools import ScrapeWebsiteTool

# To enable scrapping any website it finds during it's execution
tool = ScrapeWebsiteTool()

# Initialize the tool with the website URL,
# so the agent can only scrap the content of the specified website
tool = ScrapeWebsiteTool(website_url='https://www.example.com')

# Extract the text from the site
text = tool.run()
print(text)
```

## Arguments

| Argument         | Type     | Description                                                                                                                                        |
| :--------------- | :------- | :------------------------------------------------------------------------------------------------------------------------------------------------- |
| **website\_url** | `string` | **Mandatory** website URL to read the file. This is the primary input for the tool, specifying which website's content should be scraped and read. |


# Scrapfly Scrape Website Tool
Source: https://docs.crewai.com/en/tools/web-scraping/scrapflyscrapetool

The `ScrapflyScrapeWebsiteTool` leverages Scrapfly's web scraping API to extract content from websites in various formats.

# `ScrapflyScrapeWebsiteTool`

## Description

The `ScrapflyScrapeWebsiteTool` is designed to leverage [Scrapfly](https://scrapfly.io/)'s web scraping API to extract content from websites. This tool provides advanced web scraping capabilities with headless browser support, proxies, and anti-bot bypass features. It allows for extracting web page data in various formats, including raw HTML, markdown, and plain text, making it ideal for a wide range of web scraping tasks.

## Installation

To use this tool, you need to install the Scrapfly SDK:

```shell
uv add scrapfly-sdk
```

You'll also need to obtain a Scrapfly API key by registering at [scrapfly.io/register](https://www.scrapfly.io/register/).

## Steps to Get Started

To effectively use the `ScrapflyScrapeWebsiteTool`, follow these steps:

1. **Install Dependencies**: Install the Scrapfly SDK using the command above.
2. **Obtain API Key**: Register at Scrapfly to get your API key.
3. **Initialize the Tool**: Create an instance of the tool with your API key.
4. **Configure Scraping Parameters**: Customize the scraping parameters based on your needs.

## Example

The following example demonstrates how to use the `ScrapflyScrapeWebsiteTool` to extract content from a website:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import ScrapflyScrapeWebsiteTool

# Initialize the tool
scrape_tool = ScrapflyScrapeWebsiteTool(api_key="your_scrapfly_api_key")

# Define an agent that uses the tool
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract information from websites",
    backstory="An expert in web scraping who can extract content from any website.",
    tools=[scrape_tool],
    verbose=True,
)

# Example task to extract content from a website
scrape_task = Task(
    description="Extract the main content from the product page at https://web-scraping.dev/products and summarize the available products.",
    expected_output="A summary of the products available on the website.",
    agent=web_scraper_agent,
)

# Create and run the crew
crew = Crew(agents=[web_scraper_agent], tasks=[scrape_task])
result = crew.kickoff()
```

You can also customize the scraping parameters:

```python Code
# Example with custom scraping parameters
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract information from websites with custom parameters",
    backstory="An expert in web scraping who can extract content from any website.",
    tools=[scrape_tool],
    verbose=True,
)

# The agent will use the tool with parameters like:
# url="https://web-scraping.dev/products"
# scrape_format="markdown"
# ignore_scrape_failures=True
# scrape_config={
#     "asp": True,  # Bypass scraping blocking solutions, like Cloudflare
#     "render_js": True,  # Enable JavaScript rendering with a cloud headless browser
#     "proxy_pool": "public_residential_pool",  # Select a proxy pool
#     "country": "us",  # Select a proxy location
#     "auto_scroll": True,  # Auto scroll the page
# }

scrape_task = Task(
    description="Extract the main content from the product page at https://web-scraping.dev/products using advanced scraping options including JavaScript rendering and proxy settings.",
    expected_output="A detailed summary of the products with all available information.",
    agent=web_scraper_agent,
)
```

## Parameters

The `ScrapflyScrapeWebsiteTool` accepts the following parameters:

### Initialization Parameters

* **api\_key**: Required. Your Scrapfly API key.

### Run Parameters

* **url**: Required. The URL of the website to scrape.
* **scrape\_format**: Optional. The format in which to extract the web page content. Options are "raw" (HTML), "markdown", or "text". Default is "markdown".
* **scrape\_config**: Optional. A dictionary containing additional Scrapfly scraping configuration options.
* **ignore\_scrape\_failures**: Optional. Whether to ignore failures during scraping. If set to `True`, the tool will return `None` instead of raising an exception when scraping fails.

## Scrapfly Configuration Options

The `scrape_config` parameter allows you to customize the scraping behavior with the following options:

* **asp**: Enable anti-scraping protection bypass.
* **render\_js**: Enable JavaScript rendering with a cloud headless browser.
* **proxy\_pool**: Select a proxy pool (e.g., "public\_residential\_pool", "datacenter").
* **country**: Select a proxy location (e.g., "us", "uk").
* **auto\_scroll**: Automatically scroll the page to load lazy-loaded content.
* **js**: Execute custom JavaScript code by the headless browser.

For a complete list of configuration options, refer to the [Scrapfly API documentation](https://scrapfly.io/docs/scrape-api/getting-started).

## Usage

When using the `ScrapflyScrapeWebsiteTool` with an agent, the agent will need to provide the URL of the website to scrape and can optionally specify the format and additional configuration options:

```python Code
# Example of using the tool with an agent
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract information from websites",
    backstory="An expert in web scraping who can extract content from any website.",
    tools=[scrape_tool],
    verbose=True,
)

# Create a task for the agent
scrape_task = Task(
    description="Extract the main content from example.com in markdown format.",
    expected_output="The main content of example.com in markdown format.",
    agent=web_scraper_agent,
)

# Run the task
crew = Crew(agents=[web_scraper_agent], tasks=[scrape_task])
result = crew.kickoff()
```

For more advanced usage with custom configuration:

```python Code
# Create a task with more specific instructions
advanced_scrape_task = Task(
    description="""
    Extract content from example.com with the following requirements:
    - Convert the content to plain text format
    - Enable JavaScript rendering
    - Use a US-based proxy
    - Handle any scraping failures gracefully
    """,
    expected_output="The extracted content from example.com",
    agent=web_scraper_agent,
)
```

## Error Handling

By default, the `ScrapflyScrapeWebsiteTool` will raise an exception if scraping fails. Agents can be instructed to handle failures gracefully by specifying the `ignore_scrape_failures` parameter:

```python Code
# Create a task that instructs the agent to handle errors
error_handling_task = Task(
    description="""
    Extract content from a potentially problematic website and make sure to handle any
    scraping failures gracefully by setting ignore_scrape_failures to True.
    """,
    expected_output="Either the extracted content or a graceful error message",
    agent=web_scraper_agent,
)
```

## Implementation Details

The `ScrapflyScrapeWebsiteTool` uses the Scrapfly SDK to interact with the Scrapfly API:

```python Code
class ScrapflyScrapeWebsiteTool(BaseTool):
    name: str = "Scrapfly web scraping API tool"
    description: str = (
        "Scrape a webpage url using Scrapfly and return its content as markdown or text"
    )

    # Implementation details...

    def _run(
        self,
        url: str,
        scrape_format: str = "markdown",
        scrape_config: Optional[Dict[str, Any]] = None,
        ignore_scrape_failures: Optional[bool] = None,
    ):
        from scrapfly import ScrapeApiResponse, ScrapeConfig

        scrape_config = scrape_config if scrape_config is not None else {}
        try:
            response: ScrapeApiResponse = self.scrapfly.scrape(
                ScrapeConfig(url, format=scrape_format, **scrape_config)
            )
            return response.scrape_result["content"]
        except Exception as e:
            if ignore_scrape_failures:
                logger.error(f"Error fetching data from {url}, exception: {e}")
                return None
            else:
                raise e
```

## Conclusion

The `ScrapflyScrapeWebsiteTool` provides a powerful way to extract content from websites using Scrapfly's advanced web scraping capabilities. With features like headless browser support, proxies, and anti-bot bypass, it can handle complex websites and extract content in various formats. This tool is particularly useful for data extraction, content monitoring, and research tasks where reliable web scraping is required.


# Selenium Scraper
Source: https://docs.crewai.com/en/tools/web-scraping/seleniumscrapingtool

The `SeleniumScrapingTool` is designed to extract and read the content of a specified website using Selenium.

# `SeleniumScrapingTool`

<Note>
  This tool is currently in development. As we refine its capabilities, users may encounter unexpected behavior.
  Your feedback is invaluable to us for making improvements.
</Note>

## Description

The `SeleniumScrapingTool` is crafted for high-efficiency web scraping tasks.
It allows for precise extraction of content from web pages by using CSS selectors to target specific elements.
Its design caters to a wide range of scraping needs, offering flexibility to work with any provided website URL.

## Installation

To use this tool, you need to install the CrewAI tools package and Selenium:

```shell
pip install 'crewai[tools]'
uv add selenium webdriver-manager
```

You'll also need to have Chrome installed on your system, as the tool uses Chrome WebDriver for browser automation.

## Example

The following example demonstrates how to use the `SeleniumScrapingTool` with a CrewAI agent:

```python Code
from crewai import Agent, Task, Crew, Process
from crewai_tools import SeleniumScrapingTool

# Initialize the tool
selenium_tool = SeleniumScrapingTool()

# Define an agent that uses the tool
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract information from websites using Selenium",
    backstory="An expert web scraper who can extract content from dynamic websites.",
    tools=[selenium_tool],
    verbose=True,
)

# Example task to scrape content from a website
scrape_task = Task(
    description="Extract the main content from the homepage of example.com. Use the CSS selector 'main' to target the main content area.",
    expected_output="The main content from example.com's homepage.",
    agent=web_scraper_agent,
)

# Create and run the crew
crew = Crew(
    agents=[web_scraper_agent],
    tasks=[scrape_task],
    verbose=True,
    process=Process.sequential,
)
result = crew.kickoff()
```

You can also initialize the tool with predefined parameters:

```python Code
# Initialize the tool with predefined parameters
selenium_tool = SeleniumScrapingTool(
    website_url='https://example.com',
    css_element='.main-content',
    wait_time=5
)

# Define an agent that uses the tool
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract information from websites using Selenium",
    backstory="An expert web scraper who can extract content from dynamic websites.",
    tools=[selenium_tool],
    verbose=True,
)
```

## Parameters

The `SeleniumScrapingTool` accepts the following parameters during initialization:

* **website\_url**: Optional. The URL of the website to scrape. If provided during initialization, the agent won't need to specify it when using the tool.
* **css\_element**: Optional. The CSS selector for the elements to extract. If provided during initialization, the agent won't need to specify it when using the tool.
* **cookie**: Optional. A dictionary containing cookie information, useful for simulating a logged-in session to access restricted content.
* **wait\_time**: Optional. Specifies the delay (in seconds) before scraping, allowing the website and any dynamic content to fully load. Default is `3` seconds.
* **return\_html**: Optional. Whether to return the HTML content instead of just the text. Default is `False`.

When using the tool with an agent, the agent will need to provide the following parameters (unless they were specified during initialization):

* **website\_url**: Required. The URL of the website to scrape.
* **css\_element**: Required. The CSS selector for the elements to extract.

## Agent Integration Example

Here's a more detailed example of how to integrate the `SeleniumScrapingTool` with a CrewAI agent:

```python Code
from crewai import Agent, Task, Crew, Process
from crewai_tools import SeleniumScrapingTool

# Initialize the tool
selenium_tool = SeleniumScrapingTool()

# Define an agent that uses the tool
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract and analyze information from dynamic websites",
    backstory="""You are an expert web scraper who specializes in extracting
    content from dynamic websites that require browser automation. You have
    extensive knowledge of CSS selectors and can identify the right selectors
    to target specific content on any website.""",
    tools=[selenium_tool],
    verbose=True,
)

# Create a task for the agent
scrape_task = Task(
    description="""
    Extract the following information from the news website at {website_url}:

    1. The headlines of all featured articles (CSS selector: '.headline')
    2. The publication dates of these articles (CSS selector: '.pub-date')
    3. The author names where available (CSS selector: '.author')

    Compile this information into a structured format with each article's details grouped together.
    """,
    expected_output="A structured list of articles with their headlines, publication dates, and authors.",
    agent=web_scraper_agent,
)

# Run the task
crew = Crew(
    agents=[web_scraper_agent],
    tasks=[scrape_task],
    verbose=True,
    process=Process.sequential,
)
result = crew.kickoff(inputs={"website_url": "https://news-example.com"})
```

## Implementation Details

The `SeleniumScrapingTool` uses Selenium WebDriver to automate browser interactions:

```python Code
class SeleniumScrapingTool(BaseTool):
    name: str = "Read a website content"
    description: str = "A tool that can be used to read a website content."
    args_schema: Type[BaseModel] = SeleniumScrapingToolSchema

    def _run(self, **kwargs: Any) -> Any:
        website_url = kwargs.get("website_url", self.website_url)
        css_element = kwargs.get("css_element", self.css_element)
        return_html = kwargs.get("return_html", self.return_html)
        driver = self._create_driver(website_url, self.cookie, self.wait_time)

        content = self._get_content(driver, css_element, return_html)
        driver.close()

        return "\n".join(content)
```

The tool performs the following steps:

1. Creates a headless Chrome browser instance
2. Navigates to the specified URL
3. Waits for the specified time to allow the page to load
4. Adds any cookies if provided
5. Extracts content based on the CSS selector
6. Returns the extracted content as text or HTML
7. Closes the browser instance

## Handling Dynamic Content

The `SeleniumScrapingTool` is particularly useful for scraping websites with dynamic content that is loaded via JavaScript. By using a real browser instance, it can:

1. Execute JavaScript on the page
2. Wait for dynamic content to load
3. Interact with elements if needed
4. Extract content that would not be available with simple HTTP requests

You can adjust the `wait_time` parameter to ensure that all dynamic content has loaded before extraction.

## Conclusion

The `SeleniumScrapingTool` provides a powerful way to extract content from websites using browser automation. By enabling agents to interact with websites as a real user would, it facilitates scraping of dynamic content that would be difficult or impossible to extract using simpler methods. This tool is particularly useful for research, data collection, and monitoring tasks that involve modern web applications with JavaScript-rendered content.


# Spider Scraper
Source: https://docs.crewai.com/en/tools/web-scraping/spidertool

The `SpiderTool` is designed to extract and read the content of a specified website using Spider.

# `SpiderTool`

## Description

[Spider](https://spider.cloud/?ref=crewai) is the [fastest](https://github.com/spider-rs/spider/blob/main/benches/BENCHMARKS.md#benchmark-results)
open source scraper and crawler that returns LLM-ready data.
It converts any website into pure HTML, markdown, metadata or text while enabling you to crawl with custom actions using AI.

## Installation

To use the `SpiderTool` you need to download the [Spider SDK](https://pypi.org/project/spider-client/)
and the `crewai[tools]` SDK too:

```shell
pip install spider-client 'crewai[tools]'
```

## Example

This example shows you how you can use the `SpiderTool` to enable your agent to scrape and crawl websites.
The data returned from the Spider API is already LLM-ready, so no need to do any cleaning there.

```python Code
from crewai_tools import SpiderTool

def main():
    spider_tool = SpiderTool()

    searcher = Agent(
        role="Web Research Expert",
        goal="Find related information from specific URL's",
        backstory="An expert web researcher that uses the web extremely well",
        tools=[spider_tool],
        verbose=True,
    )

    return_metadata = Task(
        description="Scrape https://spider.cloud with a limit of 1 and enable metadata",
        expected_output="Metadata and 10 word summary of spider.cloud",
        agent=searcher
    )

    crew = Crew(
        agents=[searcher],
        tasks=[
            return_metadata,
        ],
        verbose=2
    )

    crew.kickoff()

if __name__ == "__main__":
    main()
```

## Arguments

| Argument                | Type     | Description                                                                                                                       |
| :---------------------- | :------- | :-------------------------------------------------------------------------------------------------------------------------------- |
| **api\_key**            | `string` | Specifies Spider API key. If not specified, it looks for `SPIDER_API_KEY` in environment variables.                               |
| **params**              | `object` | Optional parameters for the request. Defaults to `{"return_format": "markdown"}` to optimize content for LLMs.                    |
| **request**             | `string` | Type of request to perform (`http`, `chrome`, `smart`). `smart` defaults to HTTP, switching to JavaScript rendering if needed.    |
| **limit**               | `int`    | Max pages to crawl per website. Set to `0` or omit for unlimited.                                                                 |
| **depth**               | `int`    | Max crawl depth. Set to `0` for no limit.                                                                                         |
| **cache**               | `bool`   | Enables HTTP caching to speed up repeated runs. Default is `true`.                                                                |
| **budget**              | `object` | Sets path-based limits for crawled pages, e.g., `{"*":1}` for root page only.                                                     |
| **locale**              | `string` | Locale for the request, e.g., `en-US`.                                                                                            |
| **cookies**             | `string` | HTTP cookies for the request.                                                                                                     |
| **stealth**             | `bool`   | Enables stealth mode for Chrome requests to avoid detection. Default is `true`.                                                   |
| **headers**             | `object` | HTTP headers as a map of key-value pairs for all requests.                                                                        |
| **metadata**            | `bool`   | Stores metadata about pages and content, aiding AI interoperability. Defaults to `false`.                                         |
| **viewport**            | `object` | Sets Chrome viewport dimensions. Default is `800x600`.                                                                            |
| **encoding**            | `string` | Specifies encoding type, e.g., `UTF-8`, `SHIFT_JIS`.                                                                              |
| **subdomains**          | `bool`   | Includes subdomains in the crawl. Default is `false`.                                                                             |
| **user\_agent**         | `string` | Custom HTTP user agent. Defaults to a random agent.                                                                               |
| **store\_data**         | `bool`   | Enables data storage for the request. Overrides `storageless` when set. Default is `false`.                                       |
| **gpt\_config**         | `object` | Allows AI to generate crawl actions, with optional chaining steps via an array for `"prompt"`.                                    |
| **fingerprint**         | `bool`   | Enables advanced fingerprinting for Chrome.                                                                                       |
| **storageless**         | `bool`   | Prevents all data storage, including AI embeddings. Default is `false`.                                                           |
| **readability**         | `bool`   | Pre-processes content for reading via [Mozilla‚Äôs readability](https://github.com/mozilla/readability). Improves content for LLMs. |
| **return\_format**      | `string` | Format to return data: `markdown`, `raw`, `text`, `html2text`. Use `raw` for default page format.                                 |
| **proxy\_enabled**      | `bool`   | Enables high-performance proxies to avoid network-level blocking.                                                                 |
| **query\_selector**     | `string` | CSS query selector for content extraction from markup.                                                                            |
| **full\_resources**     | `bool`   | Downloads all resources linked to the website.                                                                                    |
| **request\_timeout**    | `int`    | Timeout in seconds for requests (5-60). Default is `30`.                                                                          |
| **run\_in\_background** | `bool`   | Runs the request in the background, useful for data storage and triggering dashboard crawls. No effect if `storageless` is set.   |


# Stagehand Tool
Source: https://docs.crewai.com/en/tools/web-scraping/stagehandtool

Web automation tool that integrates Stagehand with CrewAI for browser interaction and automation

# Overview

The `StagehandTool` integrates the [Stagehand](https://docs.stagehand.dev/get_started/introduction) framework with CrewAI, enabling agents to interact with websites and automate browser tasks using natural language instructions.

## Overview

Stagehand is a powerful browser automation framework built by Browserbase that allows AI agents to:

* Navigate to websites
* Click buttons, links, and other elements
* Fill in forms
* Extract data from web pages
* Observe and identify elements
* Perform complex workflows

The StagehandTool wraps the Stagehand Python SDK to provide CrewAI agents with browser control capabilities through three core primitives:

1. **Act**: Perform actions like clicking, typing, or navigating
2. **Extract**: Extract structured data from web pages
3. **Observe**: Identify and analyze elements on the page

## Prerequisites

Before using this tool, ensure you have:

1. A [Browserbase](https://www.browserbase.com/) account with API key and project ID
2. An API key for an LLM (OpenAI or Anthropic Claude)
3. The Stagehand Python SDK installed

Install the required dependency:

```bash
pip install stagehand-py
```

## Usage

### Basic Implementation

The StagehandTool can be implemented in two ways:

#### 1. Using Context Manager (Recommended)

<Tip>
  The context manager approach is recommended as it ensures proper cleanup of resources even if exceptions occur.
</Tip>

```python
from crewai import Agent, Task, Crew
from crewai_tools import StagehandTool
from stagehand.schemas import AvailableModel

# Initialize the tool with your API keys using a context manager
with StagehandTool(
    api_key="your-browserbase-api-key",
    project_id="your-browserbase-project-id",
    model_api_key="your-llm-api-key",  # OpenAI or Anthropic API key
    model_name=AvailableModel.CLAUDE_3_7_SONNET_LATEST,  # Optional: specify which model to use
) as stagehand_tool:
    # Create an agent with the tool
    researcher = Agent(
        role="Web Researcher",
        goal="Find and summarize information from websites",
        backstory="I'm an expert at finding information online.",
        verbose=True,
        tools=[stagehand_tool],
    )

    # Create a task that uses the tool
    research_task = Task(
        description="Go to https://www.example.com and tell me what you see on the homepage.",
        agent=researcher,
    )

    # Run the crew
    crew = Crew(
        agents=[researcher],
        tasks=[research_task],
        verbose=True,
    )

    result = crew.kickoff()
    print(result)
```

#### 2. Manual Resource Management

```python
from crewai import Agent, Task, Crew
from crewai_tools import StagehandTool
from stagehand.schemas import AvailableModel

# Initialize the tool with your API keys
stagehand_tool = StagehandTool(
    api_key="your-browserbase-api-key",
    project_id="your-browserbase-project-id",
    model_api_key="your-llm-api-key",
    model_name=AvailableModel.CLAUDE_3_7_SONNET_LATEST,
)

try:
    # Create an agent with the tool
    researcher = Agent(
        role="Web Researcher",
        goal="Find and summarize information from websites",
        backstory="I'm an expert at finding information online.",
        verbose=True,
        tools=[stagehand_tool],
    )

    # Create a task that uses the tool
    research_task = Task(
        description="Go to https://www.example.com and tell me what you see on the homepage.",
        agent=researcher,
    )

    # Run the crew
    crew = Crew(
        agents=[researcher],
        tasks=[research_task],
        verbose=True,
    )

    result = crew.kickoff()
    print(result)
finally:
    # Explicitly clean up resources
    stagehand_tool.close()
```

## Command Types

The StagehandTool supports three different command types for specific web automation tasks:

### 1. Act Command

The `act` command type (default) enables webpage interactions like clicking buttons, filling forms, and navigation.

```python
# Perform an action (default behavior)
result = stagehand_tool.run(
    instruction="Click the login button",
    url="https://example.com",
    command_type="act"  # Default, so can be omitted
)

# Fill out a form
result = stagehand_tool.run(
    instruction="Fill the contact form with name 'John Doe', email 'john@example.com', and message 'Hello world'",
    url="https://example.com/contact"
)
```

### 2. Extract Command

The `extract` command type retrieves structured data from webpages.

```python
# Extract all product information
result = stagehand_tool.run(
    instruction="Extract all product names, prices, and descriptions",
    url="https://example.com/products",
    command_type="extract"
)

# Extract specific information with a selector
result = stagehand_tool.run(
    instruction="Extract the main article title and content",
    url="https://example.com/blog/article",
    command_type="extract",
    selector=".article-container"  # Optional CSS selector
)
```

### 3. Observe Command

The `observe` command type identifies and analyzes webpage elements.

```python
# Find interactive elements
result = stagehand_tool.run(
    instruction="Find all interactive elements in the navigation menu",
    url="https://example.com",
    command_type="observe"
)

# Identify form fields
result = stagehand_tool.run(
    instruction="Identify all the input fields in the registration form",
    url="https://example.com/register",
    command_type="observe",
    selector="#registration-form"
)
```

## Configuration Options

Customize the StagehandTool behavior with these parameters:

```python
stagehand_tool = StagehandTool(
    api_key="your-browserbase-api-key",
    project_id="your-browserbase-project-id",
    model_api_key="your-llm-api-key",
    model_name=AvailableModel.CLAUDE_3_7_SONNET_LATEST,
    dom_settle_timeout_ms=5000,  # Wait longer for DOM to settle
    headless=True,  # Run browser in headless mode
    self_heal=True,  # Attempt to recover from errors
    wait_for_captcha_solves=True,  # Wait for CAPTCHA solving
    verbose=1,  # Control logging verbosity (0-3)
)
```

## Best Practices

1. **Be Specific**: Provide detailed instructions for better results
2. **Choose Appropriate Command Type**: Select the right command type for your task
3. **Use Selectors**: Leverage CSS selectors to improve accuracy
4. **Break Down Complex Tasks**: Split complex workflows into multiple tool calls
5. **Implement Error Handling**: Add error handling for potential issues

## Troubleshooting

Common issues and solutions:

* **Session Issues**: Verify API keys for both Browserbase and LLM provider
* **Element Not Found**: Increase `dom_settle_timeout_ms` for slower pages
* **Action Failures**: Use `observe` to identify correct elements first
* **Incomplete Data**: Refine instructions or provide specific selectors

## Additional Resources

For questions about the CrewAI integration:

* Join Stagehand's [Slack community](https://stagehand.dev/slack)
* Open an issue in the [Stagehand repository](https://github.com/browserbase/stagehand)
* Visit [Stagehand documentation](https://docs.stagehand.dev/)


# Introdu√ß√£o
Source: https://docs.crewai.com/pt-BR/api-reference/introduction

Refer√™ncia completa para a API REST do CrewAI Enterprise

# CrewAI Enterprise API

Bem-vindo √† refer√™ncia da API do CrewAI Enterprise. Esta API permite que voc√™ interaja programaticamente com seus crews implantados, possibilitando a integra√ß√£o com seus aplicativos, fluxos de trabalho e servi√ßos.

## In√≠cio R√°pido

<Steps>
  <Step title="Obtenha suas credenciais de API">
    Navegue at√© a p√°gina de detalhes do seu crew no painel do CrewAI Enterprise e copie seu Bearer Token na aba Status.
  </Step>

  <Step title="Descubra os Inputs Necess√°rios">
    Use o endpoint `GET /inputs` para ver quais par√¢metros seu crew espera.
  </Step>

  <Step title="Inicie uma Execu√ß√£o de Crew">
    Chame `POST /kickoff` com seus inputs para iniciar a execu√ß√£o do crew e receber um `kickoff_id`.
  </Step>

  <Step title="Monitore o Progresso">
    Use `GET /status/{kickoff_id}` para checar o status da execu√ß√£o e recuperar os resultados.
  </Step>
</Steps>

## Autentica√ß√£o

Todas as requisi√ß√µes √† API exigem autentica√ß√£o usando um Bearer token. Inclua seu token no header `Authorization`:

```bash
curl -H "Authorization: Bearer YOUR_CREW_TOKEN" \
  https://your-crew-url.crewai.com/inputs
```

### Tipos de Token

| Tipo de Token         | Escopo                         | Caso de Uso                                                          |
| :-------------------- | :----------------------------- | :------------------------------------------------------------------- |
| **Bearer Token**      | Acesso em n√≠vel de organiza√ß√£o | Opera√ß√µes completas de crew, ideal para integra√ß√£o server-to-server  |
| **User Bearer Token** | Acesso com escopo de usu√°rio   | Permiss√µes limitadas, adequado para opera√ß√µes espec√≠ficas de usu√°rio |

<Tip>
  Voc√™ pode encontrar ambos os tipos de token na aba Status da p√°gina de detalhes do seu crew no painel do CrewAI Enterprise.
</Tip>

## URL Base

Cada crew implantado possui um endpoint de API √∫nico:

```
https://your-crew-name.crewai.com
```

Substitua `your-crew-name` pela URL real do seu crew no painel.

## Fluxo T√≠pico

1. **Descoberta**: Chame `GET /inputs` para entender o que seu crew precisa
2. **Execu√ß√£o**: Envie os inputs via `POST /kickoff` para iniciar o processamento
3. **Monitoramento**: Fa√ßa polling em `GET /status/{kickoff_id}` at√© a conclus√£o
4. **Resultados**: Extraia o output final da resposta conclu√≠da

## Tratamento de Erros

A API utiliza c√≥digos de status HTTP padr√£o:

| C√≥digo | Significado                                      |
| ------ | :----------------------------------------------- |
| `200`  | Sucesso                                          |
| `400`  | Requisi√ß√£o Inv√°lida - Formato de input inv√°lido  |
| `401`  | N√£o Autorizado - Bearer token inv√°lido           |
| `404`  | N√£o Encontrado - Recurso n√£o existe              |
| `422`  | Erro de Valida√ß√£o - Inputs obrigat√≥rios ausentes |
| `500`  | Erro no Servidor - Contate o suporte             |

## Testes Interativos

<Info>
  **Por que n√£o h√° bot√£o "Enviar"?** Como cada usu√°rio do CrewAI Enterprise possui sua pr√≥pria URL de crew, utilizamos o **modo refer√™ncia** em vez de um playground interativo para evitar confus√£o. Isso mostra exatamente como as requisi√ß√µes devem ser feitas, sem bot√µes de envio n√£o funcionais.
</Info>

Cada p√°gina de endpoint mostra para voc√™:

* ‚úÖ **Formato exato da requisi√ß√£o** com todos os par√¢metros
* ‚úÖ **Exemplos de resposta** para casos de sucesso e erro
* ‚úÖ **Exemplos de c√≥digo** em v√°rias linguagens (cURL, Python, JavaScript, etc.)
* ‚úÖ **Exemplos de autentica√ß√£o** com o formato adequado de Bearer token

### **Para testar sua API de verdade:**

<CardGroup cols={2}>
  <Card title="Copie Exemplos cURL" icon="terminal">
    Copie os exemplos cURL e substitua a URL + token por seus valores reais
  </Card>

  <Card title="Use Postman/Insomnia" icon="play">
    Importe os exemplos na sua ferramenta de testes de API preferida
  </Card>
</CardGroup>

**Exemplo de fluxo:**

1. **Copie este exemplo cURL** de qualquer p√°gina de endpoint
2. **Substitua `your-actual-crew-name.crewai.com`** pela URL real do seu crew
3. **Substitua o Bearer token** pelo seu token real do painel
4. **Execute a requisi√ß√£o** no seu terminal ou cliente de API

## Precisa de Ajuda?

<CardGroup cols={2}>
  <Card title="Suporte Enterprise" icon="headset" href="mailto:support@crewai.com">
    Obtenha ajuda com integra√ß√£o da API e resolu√ß√£o de problemas
  </Card>

  <Card title="Painel Enterprise" icon="chart-line" href="https://app.crewai.com">
    Gerencie seus crews e visualize logs de execu√ß√£o
  </Card>
</CardGroup>


# Agentes
Source: https://docs.crewai.com/pt-BR/concepts/agents

Guia detalhado sobre como criar e gerenciar agentes no framework CrewAI.

## Vis√£o Geral de um Agente

No framework CrewAI, um `Agent` √© uma unidade aut√¥noma que pode:

* Executar tarefas espec√≠ficas
* Tomar decis√µes com base em seu papel e objetivo
* Utilizar ferramentas para alcan√ßar objetivos
* Comunicar e colaborar com outros agentes
* Manter a mem√≥ria de intera√ß√µes
* Delegar tarefas, quando permitido

<Tip>
  Pense em um agente como um membro especializado da equipe com habilidades, compet√™ncias e responsabilidades espec√≠ficas. Por exemplo, um agente `Researcher` pode ser excelente em coletar e analisar informa√ß√µes, enquanto um agente `Writer` pode ser melhor na cria√ß√£o de conte√∫do.
</Tip>

<Note type="info" title="Aprimoramento Empresarial: Construtor Visual de Agentes">
  O CrewAI Enterprise inclui um Construtor Visual de Agentes, que simplifica a cria√ß√£o e configura√ß√£o de agentes sem escrever c√≥digo. Projete seus agentes visualmente e teste-os em tempo real.

  ![Visual Agent Builder Screenshot](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-studio-interface.png)

  O Construtor Visual de Agentes permite:

  * Configura√ß√£o intuitiva de agentes com interfaces baseadas em formul√°rios
  * Testes e valida√ß√£o em tempo real
  * Biblioteca de modelos com tipos de agentes pr√©-configurados
  * F√°cil personaliza√ß√£o de atributos e comportamentos do agente
</Note>

## Atributos do Agente

| Atributo                                | Par√¢metro                | Tipo                                  | Descri√ß√£o                                                                                                 |
| :-------------------------------------- | :----------------------- | :------------------------------------ | :-------------------------------------------------------------------------------------------------------- |
| **Role (Fun√ß√£o)**                       | `role`                   | `str`                                 | Define a fun√ß√£o e a √°rea de especializa√ß√£o do agente dentro da equipe.                                    |
| **Goal (Objetivo)**                     | `goal`                   | `str`                                 | O objetivo individual que guia a tomada de decis√£o do agente.                                             |
| **Backstory (Hist√≥ria de fundo)**       | `backstory`              | `str`                                 | Fornece contexto e personalidade ao agente, enriquecendo as intera√ß√µes.                                   |
| **LLM** *(opcional)*                    | `llm`                    | `Union[str, LLM, Any]`                | Modelo de linguagem que alimenta o agente. Padr√£o: modelo especificado em `OPENAI_MODEL_NAME` ou "gpt-4". |
| **Tools (Ferramentas)** *(opcional)*    | `tools`                  | `List[BaseTool]`                      | Capacidades ou fun√ß√µes dispon√≠veis para o agente. Padr√£o: lista vazia.                                    |
| **Function Calling LLM** *(opcional)*   | `function_calling_llm`   | `Optional[Any]`                       | Modelo de linguagem usado para chamada de ferramentas, sobrescreve LLM principal se especificado.         |
| **Max Iterations** *(opcional)*         | `max_iter`               | `int`                                 | N√∫mero m√°ximo de itera√ß√µes antes do agente fornecer sua melhor resposta. Padr√£o: 20.                      |
| **Max RPM** *(opcional)*                | `max_rpm`                | `Optional[int]`                       | Quantidade m√°xima de requisi√ß√µes por minuto para evitar limites de taxa.                                  |
| **Max Execution Time** *(opcional)*     | `max_execution_time`     | `Optional[int]`                       | Tempo m√°ximo (em segundos) de execu√ß√£o da tarefa.                                                         |
| **Verbose** *(opcional)*                | `verbose`                | `bool`                                | Habilita logs detalhados de execu√ß√£o para depura√ß√£o. Padr√£o: False.                                       |
| **Allow Delegation** *(opcional)*       | `allow_delegation`       | `bool`                                | Permite que o agente delegue tarefas para outros agentes. Padr√£o: False.                                  |
| **Step Callback** *(opcional)*          | `step_callback`          | `Optional[Any]`                       | Fun√ß√£o chamada ap√≥s cada passo do agente, sobrescreve callback da equipe.                                 |
| **Cache** *(opcional)*                  | `cache`                  | `bool`                                | Ativa cache para o uso de ferramentas. Padr√£o: True.                                                      |
| **System Template** *(opcional)*        | `system_template`        | `Optional[str]`                       | Template personalizado de prompt de sistema para o agente.                                                |
| **Prompt Template** *(opcional)*        | `prompt_template`        | `Optional[str]`                       | Template de prompt personalizado para o agente.                                                           |
| **Response Template** *(opcional)*      | `response_template`      | `Optional[str]`                       | Template de resposta personalizado para o agente.                                                         |
| **Allow Code Execution** *(opcional)*   | `allow_code_execution`   | `Optional[bool]`                      | Ativa execu√ß√£o de c√≥digo pelo agente. Padr√£o: False.                                                      |
| **Max Retry Limit** *(opcional)*        | `max_retry_limit`        | `int`                                 | N√∫mero m√°ximo de tentativas (retries) em caso de erro. Padr√£o: 2.                                         |
| **Respect Context Window** *(opcional)* | `respect_context_window` | `bool`                                | Mant√©m as mensagens dentro do tamanho da janela de contexto, resumindo quando necess√°rio. Padr√£o: True.   |
| **Code Execution Mode** *(opcional)*    | `code_execution_mode`    | `Literal["safe", "unsafe"]`           | Modo de execu√ß√£o de c√≥digo: 'safe' (usando Docker) ou 'unsafe' (direto). Padr√£o: 'safe'.                  |
| **Multimodal** *(opcional)*             | `multimodal`             | `bool`                                | Se o agente suporta capacidades multimodais. Padr√£o: False.                                               |
| **Inject Date** *(opcional)*            | `inject_date`            | `bool`                                | Se deve injetar automaticamente a data atual nas tarefas. Padr√£o: False.                                  |
| **Date Format** *(opcional)*            | `date_format`            | `str`                                 | Formato de data utilizado quando `inject_date` est√° ativo. Padr√£o: "%Y-%m-%d" (formato ISO).              |
| **Reasoning** *(opcional)*              | `reasoning`              | `bool`                                | Se o agente deve refletir e criar um plano antes de executar uma tarefa. Padr√£o: False.                   |
| **Max Reasoning Attempts** *(opcional)* | `max_reasoning_attempts` | `Optional[int]`                       | N√∫mero m√°ximo de tentativas de racioc√≠nio antes de executar a tarefa. Se None, tentar√° at√© estar pronto.  |
| **Embedder** *(opcional)*               | `embedder`               | `Optional[Dict[str, Any]]`            | Configura√ß√£o do embedder utilizado pelo agente.                                                           |
| **Knowledge Sources** *(opcional)*      | `knowledge_sources`      | `Optional[List[BaseKnowledgeSource]]` | Fontes de conhecimento dispon√≠veis para o agente.                                                         |
| **Use System Prompt** *(opcional)*      | `use_system_prompt`      | `Optional[bool]`                      | Se deve usar o system prompt (suporte para modelo o1). Padr√£o: True.                                      |

## Criando Agentes

Existem duas maneiras de criar agentes no CrewAI: usando **configura√ß√£o YAML (recomendado)** ou definindo-os **diretamente em c√≥digo**.

### Configura√ß√£o em YAML (Recomendado)

Usar configura√ß√£o em YAML proporciona uma maneira mais limpa e f√°cil de manter para definir agentes. Recomendamos fortemente esse m√©todo em seus projetos CrewAI.

Depois de criar seu projeto CrewAI conforme descrito na se√ß√£o de [Instala√ß√£o](/pt-BR/installation), navegue at√© o arquivo `src/latest_ai_development/config/agents.yaml` e edite o template para atender aos seus requisitos.

<Note>
  Vari√°veis em seus arquivos YAML (como `{topic}`) ser√£o substitu√≠das pelos valores fornecidos em seus inputs ao executar o crew:

  ```python Code
  crew.kickoff(inputs={'topic': 'AI Agents'})
  ```
</Note>

Veja um exemplo de como configurar agentes usando YAML:

```yaml agents.yaml
# src/latest_ai_development/config/agents.yaml
researcher:
  role: >
    {topic} Senior Data Researcher
  goal: >
    Uncover cutting-edge developments in {topic}
  backstory: >
    You're a seasoned researcher with a knack for uncovering the latest
    developments in {topic}. Known for your ability to find the most relevant
    information and present it in a clear and concise manner.

reporting_analyst:
  role: >
    {topic} Reporting Analyst
  goal: >
    Create detailed reports based on {topic} data analysis and research findings
  backstory: >
    You're a meticulous analyst with a keen eye for detail. You're known for
    your ability to turn complex data into clear and concise reports, making
    it easy for others to understand and act on the information you provide.
```

Para usar essa configura√ß√£o YAML no seu c√≥digo, crie uma classe de crew que herda de `CrewBase`:

```python Code
# src/latest_ai_development/crew.py
from crewai import Agent, Crew, Process
from crewai.project import CrewBase, agent, crew
from crewai_tools import SerperDevTool

@CrewBase
class LatestAiDevelopmentCrew():
  """LatestAiDevelopment crew"""

  agents_config = "config/agents.yaml"

  @agent
  def researcher(self) -> Agent:
    return Agent(
      config=self.agents_config['researcher'], # type: ignore[index]
      verbose=True,
      tools=[SerperDevTool()]
    )

  @agent
  def reporting_analyst(self) -> Agent:
    return Agent(
      config=self.agents_config['reporting_analyst'], # type: ignore[index]
      verbose=True
    )
```

<Note>
  Os nomes utilizados em seus arquivos YAML (`agents.yaml`) devem ser iguais aos nomes dos m√©todos no seu c√≥digo Python.
</Note>

### Defini√ß√£o Direta em C√≥digo

Voc√™ pode criar agentes diretamente em c√≥digo instanciando a classe `Agent`. Veja um exemplo abrangente mostrando todos os par√¢metros dispon√≠veis:

```python Code
from crewai import Agent
from crewai_tools import SerperDevTool

# Crie um agente com todos os par√¢metros dispon√≠veis
agent = Agent(
    role="Cientista de Dados S√™nior",
    goal="Analisar e interpretar conjuntos de dados complexos para fornecer insights acion√°veis",
    backstory="Com mais de 10 anos de experi√™ncia em ci√™ncia de dados e aprendizado de m√°quina, voc√™ √© especialista em encontrar padr√µes em grandes volumes de dados.",
    llm="gpt-4",  # Padr√£o: OPENAI_MODEL_NAME ou "gpt-4"
    function_calling_llm=None,  # Opcional: LLM separado para chamadas de ferramentas
    verbose=False,  # Padr√£o: False
    allow_delegation=False,  # Padr√£o: False
    max_iter=20,  # Padr√£o: 20 itera√ß√µes
    max_rpm=None,  # Opcional: Limite de requisi√ß√µes por minuto
    max_execution_time=None,  # Opcional: Tempo m√°ximo de execu√ß√£o em segundos
    max_retry_limit=2,  # Padr√£o: 2 tentativas em caso de erro
    allow_code_execution=False,  # Padr√£o: False
    code_execution_mode="safe",  # Padr√£o: "safe" (op√ß√µes: "safe", "unsafe")
    respect_context_window=True,  # Padr√£o: True
    use_system_prompt=True,  # Padr√£o: True
    multimodal=False,  # Padr√£o: False
    inject_date=False,  # Padr√£o: False
    date_format="%Y-%m-%d",  # Padr√£o: formato ISO
    reasoning=False,  # Padr√£o: False
    max_reasoning_attempts=None,  # Padr√£o: None
    tools=[SerperDevTool()],  # Opcional: Lista de ferramentas
    knowledge_sources=None,  # Opcional: Lista de fontes de conhecimento
    embedder=None,  # Opcional: Configura√ß√£o de embedder customizado
    system_template=None,  # Opcional: Template de prompt de sistema
    prompt_template=None,  # Opcional: Template de prompt customizado
    response_template=None,  # Opcional: Template de resposta customizado
    step_callback=None,  # Opcional: Fun√ß√£o de callback para monitoramento
)
```

Vamos detalhar algumas combina√ß√µes de par√¢metros-chave para casos de uso comuns:

#### Agente de Pesquisa B√°sico

```python Code
research_agent = Agent(
    role="Analista de Pesquisa",
    goal="Encontrar e resumir informa√ß√µes sobre t√≥picos espec√≠ficos",
    backstory="Voc√™ √© um pesquisador experiente com aten√ß√£o aos detalhes",
    tools=[SerperDevTool()],
    verbose=True  # Ativa logs para depura√ß√£o
)
```

#### Agente de Desenvolvimento de C√≥digo

```python Code
dev_agent = Agent(
    role="Desenvolvedor Python S√™nior",
    goal="Escrever e depurar c√≥digos Python",
    backstory="Desenvolvedor Python especialista com 10 anos de experi√™ncia",
    allow_code_execution=True,
    code_execution_mode="safe",  # Usa Docker para seguran√ßa
    max_execution_time=300,  # Limite de 5 minutos
    max_retry_limit=3  # Mais tentativas para tarefas complexas
)
```

#### Agente de An√°lise de Longa Dura√ß√£o

```python Code
analysis_agent = Agent(
    role="Analista de Dados",
    goal="Realizar an√°lise aprofundada de grandes conjuntos de dados",
    backstory="Especialista em an√°lise de big data e reconhecimento de padr√µes",
    memory=True,
    respect_context_window=True,
    max_rpm=10,  # Limite de requisi√ß√µes por minuto
    function_calling_llm="gpt-4o-mini"  # Modelo mais econ√¥mico para chamadas de ferramentas
)
```

#### Agente com Template Personalizado

```python Code
custom_agent = Agent(
    role="Atendente de Suporte ao Cliente",
    goal="Auxiliar clientes com suas d√∫vidas e solicita√ß√µes",
    backstory="Experiente em atendimento ao cliente com foco em satisfa√ß√£o",
    system_template="""<|start_header_id|>system<|end_header_id|>\n                        {{ .System }}<|eot_id|>""",
    prompt_template="""<|start_header_id|>user<|end_header_id|>\n                        {{ .Prompt }}<|eot_id|>""",
    response_template="""<|start_header_id|>assistant<|end_header_id|>\n                        {{ .Response }}<|eot_id|>""",
)
```

#### Agente Ciente de Data, com Racioc√≠nio

```python Code
strategic_agent = Agent(
    role="Analista de Mercado",
    goal="Acompanhar movimentos do mercado com refer√™ncias de datas precisas e planejamento estrat√©gico",
    backstory="Especialista em an√°lise financeira sens√≠vel ao tempo e relat√≥rios estrat√©gicos",
    inject_date=True,  # Injeta automaticamente a data atual nas tarefas
    date_format="%d de %B de %Y",  # Exemplo: "21 de maio de 2025"
    reasoning=True,  # Ativa planejamento estrat√©gico
    max_reasoning_attempts=2,  # Limite de itera√ß√µes de planejamento
    verbose=True
)
```

#### Agente de Racioc√≠nio

```python Code
reasoning_agent = Agent(
    role="Planejador Estrat√©gico",
    goal="Analisar problemas complexos e criar planos de execu√ß√£o detalhados",
    backstory="Especialista em planejamento estrat√©gico que desmembra desafios complexos metodicamente",
    reasoning=True,  # Ativa racioc√≠nio e planejamento
    max_reasoning_attempts=3,  # Limite de tentativas de racioc√≠nio
    max_iter=30,  # Permite mais itera√ß√µes para planejamento complexo
    verbose=True
)
```

#### Agente Multimodal

```python Code
multimodal_agent = Agent(
    role="Analista de Conte√∫do Visual",
    goal="Analisar e processar tanto conte√∫do textual quanto visual",
    backstory="Especialista em an√°lise multimodal combinando compreens√£o de texto e imagem",
    multimodal=True,  # Ativa capacidades multimodais
    verbose=True
)
```

### Detalhes dos Par√¢metros

#### Par√¢metros Cr√≠ticos

* `role`, `goal` e `backstory` s√£o obrigat√≥rios e definem o comportamento do agente
* `llm` determina o modelo de linguagem utilizado (padr√£o: GPT-4 da OpenAI)

#### Mem√≥ria e Contexto

* `memory`: Ative para manter o hist√≥rico de conversas
* `respect_context_window`: Evita problemas com limites de tokens
* `knowledge_sources`: Adicione bases de conhecimento espec√≠ficas do dom√≠nio

#### Controle de Execu√ß√£o

* `max_iter`: N√∫mero m√°ximo de tentativas antes da melhor resposta
* `max_execution_time`: Tempo limite em segundos
* `max_rpm`: Limite de requisi√ß√µes por minuto
* `max_retry_limit`: Tentativas de corre√ß√£o em erros

#### Execu√ß√£o de C√≥digo

* `allow_code_execution`: Deve ser True para permitir execu√ß√£o de c√≥digo
* `code_execution_mode`:
  * `"safe"`: Usa Docker (recomendado para produ√ß√£o)
  * `"unsafe"`: Execu√ß√£o direta (apenas em ambientes confi√°veis)

<Note>
  Isso executa uma imagem Docker padr√£o. Se voc√™ deseja configurar a imagem Docker, veja a ferramenta Code Interpreter na se√ß√£o de ferramentas.
  Adicione a ferramenta de interpreta√ß√£o de c√≥digo como um par√¢metro em ferramentas no agente.
</Note>

#### Funcionalidades Avan√ßadas

* `multimodal`: Habilita capacidades multimodais para processar texto e conte√∫do visual
* `reasoning`: Permite que o agente reflita e crie planos antes de executar tarefas
* `inject_date`: Injeta a data atual automaticamente nas descri√ß√µes das tarefas

#### Templates

* `system_template`: Define o comportamento central do agente
* `prompt_template`: Estrutura o formato da entrada
* `response_template`: Formata as respostas do agente

<Note>
  Ao usar templates personalizados, assegure-se de definir tanto `system_template` quanto `prompt_template`. O `response_template` √© opcional, mas recomendado para formata√ß√£o consistente de sa√≠da.
</Note>

<Note>
  Ao usar templates personalizados, voc√™ pode usar vari√°veis como `{role}`, `{goal}` e `{backstory}` em seus templates. Elas ser√£o automaticamente preenchidas durante a execu√ß√£o.
</Note>

## Ferramentas do Agente

Agentes podem ser equipados com diversas ferramentas para ampliar suas capacidades. O CrewAI suporta ferramentas do:

* [CrewAI Toolkit](https://github.com/joaomdmoura/crewai-tools)
* [LangChain Tools](https://python.langchain.com/docs/integrations/tools)

Veja como adicionar ferramentas a um agente:

```python Code
from crewai import Agent
from crewai_tools import SerperDevTool, WikipediaTools

# Criar ferramentas
search_tool = SerperDevTool()
wiki_tool = WikipediaTools()

# Adicionar ferramentas ao agente
researcher = Agent(
    role="Pesquisador de Tecnologia em IA",
    goal="Pesquisar os √∫ltimos avan√ßos em IA",
    tools=[search_tool, wiki_tool],
    verbose=True
)
```

## Mem√≥ria e Contexto do Agente

Agentes podem manter a mem√≥ria de suas intera√ß√µes e usar contexto de tarefas anteriores. Isto √© especialmente √∫til para fluxos de trabalho complexos onde √© necess√°rio reter informa√ß√µes ao longo de v√°rias tarefas.

```python Code
from crewai import Agent

analyst = Agent(
    role="Analista de Dados",
    goal="Analisar e memorizar padr√µes complexos de dados",
    memory=True,  # Ativa mem√≥ria
    verbose=True
)
```

<Note>
  Quando `memory` est√° ativo, o agente manter√° o contexto ao longo de m√∫ltiplas intera√ß√µes, melhorando a capacidade de lidar com tarefas complexas, em m√∫ltiplos passos.
</Note>

## Gerenciamento da Janela de Contexto

O CrewAI inclui um gerenciamento autom√°tico sofisticado de janela de contexto para lidar com situa√ß√µes onde as conversas excedem o limite de tokens do modelo de linguagem. Esse poderoso recurso √© controlado pelo par√¢metro `respect_context_window`.

### Como Funciona o Gerenciamento de Janela de Contexto

Quando o hist√≥rico de conversas de um agente se torna muito grande para a janela de contexto do LLM, o CrewAI detecta essa situa√ß√£o automaticamente e pode:

1. **Resumir o conte√∫do automaticamente** (com `respect_context_window=True`)
2. **Parar a execu√ß√£o com erro** (com `respect_context_window=False`)

### Manipula√ß√£o Autom√°tica de Contexto (`respect_context_window=True`)

Esta √© a **configura√ß√£o padr√£o e recomendada** para a maioria dos casos. Quando ativada, CrewAI ir√°:

```python Code
# Agente com gerenciamento autom√°tico de contexto (padr√£o)
smart_agent = Agent(
    role="Analista de Pesquisa",
    goal="Analisar grandes documentos e conjuntos de dados",
    backstory="Especialista em processar informa√ß√µes extensas",
    respect_context_window=True,  # üîë Padr√£o: gerencia limites de contexto automaticamente
    verbose=True
)
```

**O que acontece quando os limites de contexto s√£o excedidos:**

* ‚ö†Ô∏è **Mensagem de aviso**: `"Context length exceeded. Summarizing content to fit the model context window."`
* üîÑ **Resumir automaticamente**: O CrewAI resume o hist√≥rico da conversa de forma inteligente
* ‚úÖ **Execu√ß√£o cont√≠nua**: A execu√ß√£o da tarefa prossegue normalmente com o contexto resumido
* üìù **Informa√ß√£o preservada**: Informa√ß√µes-chave s√£o mantidas enquanto reduz a contagem de tokens

### Limites Estritos de Contexto (`respect_context_window=False`)

Quando voc√™ precisa de controle total e prefere que a execu√ß√£o pare a perder qualquer informa√ß√£o:

```python Code
# Agente com limites estritos de contexto
strict_agent = Agent(
    role="Legal Document Reviewer",
    goal="Provide precise legal analysis without information loss",
    backstory="Legal expert requiring complete context for accurate analysis",
    respect_context_window=False,  # ‚ùå Stop execution on context limit
    verbose=True
)
```

**O que acontece quando os limites de contexto s√£o excedidos:**

* ‚ùå **Mensagem de erro**: `"Context length exceeded. Consider using smaller text or RAG tools from crewai_tools."`
* üõë **Execu√ß√£o interrompida**: A execu√ß√£o da tarefa √© parada imediatamente
* üîß **Interven√ß√£o manual necess√°ria**: Voc√™ precisar√° modificar sua abordagem

### Como Escolher a Melhor Configura√ß√£o

#### Use `respect_context_window=True` (padr√£o) quando:

* **Processar documentos grandes** que podem ultrapassar os limites de contexto
* **Conversas longas** onde certo grau de resumo √© aceit√°vel
* **Tarefas de pesquisa** onde o contexto geral √© mais importante que detalhes exatos
* **Prototipagem e desenvolvimento** quando se deseja execu√ß√£o robusta

```python Code
# Ideal para processamento de documentos
document_processor = Agent(
    role="Document Analyst",
    goal="Extract insights from large research papers",
    backstory="Expert at analyzing extensive documentation",
    respect_context_window=True,  # Lida com documentos grandes sem problemas
    max_iter=50,  # Permite mais itera√ß√µes para an√°lises complexas
    verbose=True
)
```

#### Use `respect_context_window=False` quando:

* **Precis√£o √© cr√≠tica** e perda de informa√ß√£o √© inaceit√°vel
* **Tarefas jur√≠dicas ou m√©dicas** que requerem contexto completo
* **Revis√£o de c√≥digo** onde detalhes perdidos podem causar bugs
* **An√°lise financeira** onde precis√£o √© fundamental

```python Code
# Ideal para tarefas de precis√£o
precision_agent = Agent(
    role="Code Security Auditor",
    goal="Identify security vulnerabilities in code",
    backstory="Security expert requiring complete code context",
    respect_context_window=False,  # Prefere falhar do que an√°lise incompleta
    max_retry_limit=1,  # Falha r√°pida em caso de problemas de contexto
    verbose=True
)
```

### Abordagens Alternativas para Grandes Volumes de Dados

Ao lidar com conjuntos de dados muito grandes, considere as seguintes estrat√©gias:

#### 1. Use Ferramentas RAG

```python Code
from crewai_tools import RagTool

# Crie uma ferramenta RAG para processamento de documentos grandes
rag_tool = RagTool()

rag_agent = Agent(
    role="Research Assistant",
    goal="Query large knowledge bases efficiently",
    backstory="Expert at using RAG tools for information retrieval",
    tools=[rag_tool],  # Usar RAG ao inv√©s de grandes janelas de contexto
    respect_context_window=True,
    verbose=True
)
```

#### 2. Use Fontes de Conhecimento

```python Code
# Use fontes de conhecimento ao inv√©s de prompts grandes
knowledge_agent = Agent(
    role="Knowledge Expert",
    goal="Answer questions using curated knowledge",
    backstory="Expert at leveraging structured knowledge sources",
    knowledge_sources=[your_knowledge_sources],  # Conhecimento pr√©-processado
    respect_context_window=True,
    verbose=True
)
```

### Boas Pr√°ticas para Janela de Contexto

1. **Monitore o uso de contexto**: Ative `verbose=True` para visualizar o gerenciamento de contexto em a√ß√£o
2. **Otimize para efici√™ncia**: Estruture tarefas para minimizar o ac√∫mulo de contexto
3. **Use modelos apropriados**: Escolha LLMs com janelas de contexto adequadas √† sua tarefa
4. **Teste ambos os modos**: Experimente `True` e `False` para descobrir o que funciona melhor para seu caso
5. **Combine com RAG**: Utilize ferramentas RAG para grandes conjuntos de dados ao inv√©s de depender apenas da janela de contexto

### Solucionando Problemas de Contexto

**Se voc√™ receber erros de limite de contexto:**

```python Code
# Solu√ß√£o r√°pida: Habilite manipula√ß√£o autom√°tica
agent.respect_context_window = True

# Solu√ß√£o melhor: Use ferramentas RAG para dados volumosos
from crewai_tools import RagTool
agent.tools = [RagTool()]

# Alternativa: Divida as tarefas em partes menores
# Ou use fontes de conhecimento no lugar de prompts extensos
```

**Se o resumo autom√°tico perder informa√ß√µes importantes:**

```python Code
# Desative o resumo autom√°tico e use RAG
agent = Agent(
    role="Detailed Analyst",
    goal="Maintain complete information accuracy",
    backstory="Expert requiring full context",
    respect_context_window=False,  # Sem resumo autom√°tico
    tools=[RagTool()],  # Use RAG para grandes volumes de dados
    verbose=True
)
```

<Note>
  O recurso de gerenciamento da janela de contexto funciona automaticamente em segundo plano. Voc√™ n√£o precisa chamar fun√ß√µes especiais ‚Äì basta definir `respect_context_window` conforme deseja e o CrewAI cuida do resto!
</Note>

## Considera√ß√µes e Boas Pr√°ticas Importantes

### Seguran√ßa e Execu√ß√£o de C√≥digo

* Ao usar `allow_code_execution`, seja cauteloso com entradas do usu√°rio e sempre as valide
* Use `code_execution_mode: "safe"` (Docker) em ambientes de produ√ß√£o
* Considere definir limites adequados de `max_execution_time` para evitar loops infinitos

### Otimiza√ß√£o de Performance

* Use `respect_context_window: true` para evitar problemas com limite de tokens
* Ajuste `max_rpm` para evitar rate limiting
* Ative `cache: true` para melhorar performance em tarefas repetitivas
* Ajuste `max_iter` e `max_retry_limit` conforme a complexidade da tarefa

### Gerenciamento de Mem√≥ria e Contexto

* Considere `knowledge_sources` para informa√ß√µes espec√≠ficas de dom√≠nio
* Configure `embedder` ao usar modelos de embedding personalizados
* Use templates personalizados (`system_template`, `prompt_template`, `response_template`) para controle fino do comportamento do agente

### Funcionalidades Avan√ßadas

* Ative `reasoning: true` para agentes que precisam planejar e refletir antes de tarefas complexas
* Defina `max_reasoning_attempts` para controlar as itera√ß√µes de planejamento (`None` para ilimitadas)
* Use `inject_date: true` para dar consci√™ncia temporal a agentes em tarefas que dependem de datas
* Personalize o formato de data com `date_format` usando c√≥digos padr√µes do Python datetime
* Ative `multimodal: true` para agentes que precisam processar texto e imagem

### Colabora√ß√£o entre Agentes

* Ative `allow_delegation: true` quando agentes precisarem trabalhar juntos
* Use `step_callback` para monitorar e registrar intera√ß√µes dos agentes
* Considere usar LLMs diferentes para prop√≥sitos distintos:
  * `llm` principal para racioc√≠nio complexo
  * `function_calling_llm` para uso eficiente de ferramentas

### Consci√™ncia de Data e Racioc√≠nio

* Use `inject_date: true` para fornecer consci√™ncia temporal aos agentes em tarefas sens√≠veis ao tempo
* Customize o formato de data com `date_format` usando c√≥digos standards de datetime do Python
* C√≥digos v√°lidos incluem: %Y (ano), %m (m√™s), %d (dia), %B (nome completo do m√™s), etc.
* Formatos de data inv√°lidos ser√£o registrados como avisos e n√£o modificar√£o a descri√ß√£o da tarefa
* Ative `reasoning: true` para tarefas complexas que se beneficiam de planejamento e reflex√£o antecipados

### Compatibilidade de Modelos

* Defina `use_system_prompt: false` para modelos antigos que n√£o suportam mensagens de sistema
* Certifique-se que o `llm` escolhido suporta as funcionalidades necess√°rias (como function calling)

## Solu√ß√£o de Problemas Comuns

1. **Limite de Taxa (Rate Limiting)**: Se atingir limites de API:
   * Implemente o `max_rpm` adequado
   * Use cache para opera√ß√µes repetitivas
   * Considere agrupar requisi√ß√µes em lote

2. **Erros de Janela de Contexto**: Se exceder limites de contexto:
   * Habilite `respect_context_window`
   * Otimize seus prompts
   * Limpe periodicamente a mem√≥ria do agente

3. **Problemas de Execu√ß√£o de C√≥digo**: Se a execu√ß√£o de c√≥digo falhar:
   * Verifique se o Docker est√° instalado para o modo seguro
   * Cheque permiss√µes de execu√ß√£o
   * Revise as configura√ß√µes do sandbox de c√≥digo

4. **Problemas de Mem√≥ria**: Se as respostas do agente parecerem inconsistentes:
   * Cheque a configura√ß√£o das fontes de conhecimento
   * Analise o gerenciamento do hist√≥rico de conversas

Lembre-se de que agentes s√£o mais eficientes quando configurados de acordo com o caso de uso espec√≠fico. Reserve um tempo para entender seus requisitos e ajustar esses par√¢metros conforme necess√°rio.


# CLI
Source: https://docs.crewai.com/pt-BR/concepts/cli

Aprenda a usar o CLI do CrewAI para interagir com o CrewAI.

## Vis√£o Geral

O CLI do CrewAI fornece um conjunto de comandos para interagir com o CrewAI, permitindo que voc√™ crie, treine, execute e gerencie crews & flows.

## Instala√ß√£o

Para usar o CLI do CrewAI, certifique-se de que o CrewAI est√° instalado:

```shell Terminal
pip install crewai
```

## Uso B√°sico

A estrutura b√°sica de um comando CLI do CrewAI √©:

```shell Terminal
crewai [COMMAND] [OPTIONS] [ARGUMENTS]
```

## Comandos Dispon√≠veis

### 1. Create

Crie um novo crew ou flow.

```shell Terminal
crewai create [OPTIONS] TYPE NAME
```

* `TYPE`: Escolha entre "crew" ou "flow"
* `NAME`: Nome do crew ou flow

Exemplo:

```shell Terminal
crewai create crew my_new_crew
crewai create flow my_new_flow
```

### 2. Version

Mostre a vers√£o instalada do CrewAI.

```shell Terminal
crewai version [OPTIONS]
```

* `--tools`: (Opcional) Mostra a vers√£o instalada das ferramentas do CrewAI

Exemplo:

```shell Terminal
crewai version
crewai version --tools
```

### 3. Train

Treine o crew por um n√∫mero espec√≠fico de itera√ß√µes.

```shell Terminal
crewai train [OPTIONS]
```

* `-n, --n_iterations INTEGER`: N√∫mero de itera√ß√µes para treinar o crew (padr√£o: 5)
* `-f, --filename TEXT`: Caminho para um arquivo customizado para treinamento (padr√£o: "trained\_agents\_data.pkl")

Exemplo:

```shell Terminal
crewai train -n 10 -f my_training_data.pkl
```

### 4. Replay

Reexecute a execu√ß√£o do crew a partir de uma tarefa espec√≠fica.

```shell Terminal
crewai replay [OPTIONS]
```

* `-t, --task_id TEXT`: Reexecuta o crew a partir deste task ID, incluindo todas as tarefas subsequentes

Exemplo:

```shell Terminal
crewai replay -t task_123456
```

### 5. Log-tasks-outputs

Recupere as sa√≠das mais recentes das tarefas crew\.kickoff() do seu crew.

```shell Terminal
crewai log-tasks-outputs
```

### 6. Reset-memories

Redefine as mem√≥rias do crew (longa, curta, de entidades, latest\_crew\_kickoff\_outputs).

```shell Terminal
crewai reset-memories [OPTIONS]
```

* `-l, --long`: Redefine a mem√≥ria de LONGO PRAZO
* `-s, --short`: Redefine a mem√≥ria de CURTO PRAZO
* `-e, --entities`: Redefine a mem√≥ria de ENTIDADES
* `-k, --kickoff-outputs`: Redefine as OUTPUTS DA TAREFA KICKOFF MAIS RECENTE
* `-kn, --knowledge`: Redefine o armazenamento de CONHECIMENTO
* `-akn, --agent-knowledge`: Redefine o armazenamento de CONHECIMENTO DOS AGENTES
* `-a, --all`: Redefine TODAS as mem√≥rias

Exemplo:

```shell Terminal
crewai reset-memories --long --short
crewai reset-memories --all
```

### 7. Test

Teste o crew e avalie os resultados.

```shell Terminal
crewai test [OPTIONS]
```

* `-n, --n_iterations INTEGER`: N√∫mero de itera√ß√µes para testar o crew (padr√£o: 3)
* `-m, --model TEXT`: Modelo LLM para executar os testes no Crew (padr√£o: "gpt-4o-mini")

Exemplo:

```shell Terminal
crewai test -n 5 -m gpt-3.5-turbo
```

### 8. Run

Execute o crew ou flow.

```shell Terminal
crewai run
```

<Note>
  A partir da vers√£o 0.103.0, o comando `crewai run` pode ser usado para executar tanto crews padr√£o quanto flows. Para flows, ele detecta automaticamente o tipo a partir do pyproject.toml e executa o comando apropriado. Este √© agora o modo recomendado de executar tanto crews quanto flows.
</Note>

<Note>
  Certifique-se de executar estes comandos a partir do diret√≥rio onde seu projeto CrewAI est√° configurado.
  Alguns comandos podem exigir configura√ß√£o ou ajustes adicionais dentro da estrutura do seu projeto.
</Note>

### 9. Chat

A partir da vers√£o `0.98.0`, ao rodar o comando `crewai chat`, voc√™ inicia uma sess√£o interativa com seu crew. O assistente de IA ir√° gui√°-lo solicitando as entradas necess√°rias para executar o crew. Uma vez que todas as entradas s√£o fornecidas, o crew executar√° suas tarefas.

Depois de receber os resultados, voc√™ pode continuar interagindo com o assistente para instru√ß√µes ou perguntas adicionais.

```shell Terminal
crewai chat
```

<Note>
  Garanta que voc√™ execute estes comandos a partir do diret√≥rio raiz do seu projeto CrewAI.
</Note>

<Note>
  IMPORTANTE: Defina a propriedade `chat_llm` no seu arquivo `crew.py` para habilitar este comando.

  ```python
  @crew
  def crew(self) -> Crew:
      return Crew(
          agents=self.agents,
          tasks=self.tasks,
          process=Process.sequential,
          verbose=True,
          chat_llm="gpt-4o",  # LLM para orquestra√ß√£o de chat
      )
  ```
</Note>

### 10. Deploy

Implemente o crew ou flow no [CrewAI Enterprise](https://app.crewai.com).

* **Autentica√ß√£o**: Voc√™ precisa estar autenticado para implementar no CrewAI Enterprise.
  ```shell Terminal
  crewai signup
  ```
  Caso j√° tenha uma conta, voc√™ pode fazer login com:
  ```shell Terminal
  crewai login
  ```

* **Criar um deployment**: Depois de autenticado, voc√™ pode criar um deployment para seu crew ou flow a partir da raiz do seu projeto local.
  ```shell Terminal
  crewai deploy create
  ```
  * L√™ a configura√ß√£o do seu projeto local.
  * Solicita a confirma√ß√£o das vari√°veis de ambiente (como `OPENAI_API_KEY`, `SERPER_API_KEY`) encontradas localmente. Elas ser√£o armazenadas de forma segura junto ao deployment na plataforma Enterprise. Verifique se suas chaves sens√≠veis est√£o corretamente configuradas localmente (por exemplo, em um arquivo `.env`) antes de executar este comando.

### 11. Gerenciamento de Organiza√ß√£o

Gerencie suas organiza√ß√µes no CrewAI Enterprise.

```shell Terminal
crewai org [COMMAND] [OPTIONS]
```

#### Comandos:

* `list`: Liste todas as organiza√ß√µes das quais voc√™ faz parte

```shell Terminal
crewai org list
```

* `current`: Exibe sua organiza√ß√£o ativa atualmente

```shell Terminal
crewai org current
```

* `switch`: Mude para uma organiza√ß√£o espec√≠fica

```shell Terminal
crewai org switch <organization_id>
```

<Note>
  Voc√™ deve estar autenticado no CrewAI Enterprise para usar estes comandos de gerenciamento de organiza√ß√£o.
</Note>

* **Criar um deployment** (continua√ß√£o):
  * Vincula o deployment ao respectivo reposit√≥rio remoto do GitHub (normalmente detectado automaticamente).

* **Implantar o Crew**: Depois de autenticado, voc√™ pode implantar seu crew ou flow no CrewAI Enterprise.
  ```shell Terminal
  crewai deploy push
  ```
  * Inicia o processo de deployment na plataforma CrewAI Enterprise.
  * Ap√≥s a inicia√ß√£o bem-sucedida, ser√° exibida a mensagem Deployment created successfully! juntamente com o Nome do Deployment e um Deployment ID (UUID) √∫nico.

* **Status do Deployment**: Voc√™ pode verificar o status do seu deployment com:
  ```shell Terminal
  crewai deploy status
  ```
  Isso retorna o status mais recente do √∫ltimo deployment iniciado (por exemplo, `Building Images for Crew`, `Deploy Enqueued`, `Online`).

* **Logs do Deployment**: Voc√™ pode checar os logs do seu deployment com:
  ```shell Terminal
  crewai deploy logs
  ```
  Isso faz o streaming dos logs do deployment para seu terminal.

* **Listar deployments**: Voc√™ pode listar todos os seus deployments com:
  ```shell Terminal
  crewai deploy list
  ```
  Isto lista todos os seus deployments.

* **Deletar um deployment**: Voc√™ pode deletar um deployment com:
  ```shell Terminal
  crewai deploy remove
  ```
  Isto exclui o deployment da plataforma CrewAI Enterprise.

* **Comando de Ajuda**: Voc√™ pode obter ajuda sobre o CLI com:
  ```shell Terminal
  crewai deploy --help
  ```
  Isto exibe a mensagem de ajuda para o CLI CrewAI Deploy.

Assista ao v√≠deo tutorial para uma demonstra√ß√£o passo-a-passo de implanta√ß√£o do seu crew no [CrewAI Enterprise](http://app.crewai.com) usando o CLI.

<iframe width="100%" height="400" src="https://www.youtube.com/embed/3EqSV-CYDZA" title="CrewAI Deployment Guide" frameborder="0" style={{ borderRadius: '10px' }} allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

### 11. Chaves de API

Ao executar o comando `crewai create crew`, o CLI primeiro mostrar√° os 5 provedores de LLM mais comuns e pedir√° para voc√™ selecionar um.

Ap√≥s selecionar um provedor de LLM, ser√° solicitado que voc√™ informe as chaves de API.

#### Provedores iniciais de chave de API

Inicialmente, o CLI solicitar√° as chaves de API para os seguintes servi√ßos:

* OpenAI
* Groq
* Anthropic
* Google Gemini
* SambaNova

Ao selecionar um provedor, o CLI solicitar√° que voc√™ insira sua chave de API.

#### Outras op√ß√µes

Se voc√™ selecionar a op√ß√£o 6, ser√° poss√≠vel escolher de uma lista de provedores suportados pelo LiteLLM.

Ao escolher um provedor, o CLI solicitar√° que voc√™ informe o nome da chave e a chave de API.

Veja o seguinte link para o nome de chave de cada provedor:

* [LiteLLM Providers](https://docs.litellm.ai/docs/providers)


# Colabora√ß√£o
Source: https://docs.crewai.com/pt-BR/concepts/collaboration

Como permitir que agentes trabalhem juntos, deleguem tarefas e se comuniquem de forma eficaz em equipes CrewAI.

## Vis√£o Geral

A colabora√ß√£o no CrewAI permite que agentes trabalhem juntos como uma equipe, delegando tarefas e fazendo perguntas para aproveitar a expertise uns dos outros. Quando `allow_delegation=True`, os agentes automaticamente t√™m acesso a poderosas ferramentas de colabora√ß√£o.

## Guia R√°pido: Habilite a Colabora√ß√£o

```python
from crewai import Agent, Crew, Task

# Enable collaboration for agents
researcher = Agent(
    role="Especialista em Pesquisa",
    goal="Realizar pesquisas aprofundadas sobre qualquer tema",
    backstory="Pesquisador especialista com acesso a diversas fontes",
    allow_delegation=True,  # üîë Configura√ß√£o chave para colabora√ß√£o
    verbose=True
)

writer = Agent(
    role="Redator de Conte√∫do",
    goal="Criar conte√∫do envolvente com base em pesquisas",
    backstory="Redator habilidoso que transforma pesquisas em conte√∫do atraente",
    allow_delegation=True,  # üîë Permite fazer perguntas a outros agentes
    verbose=True
)

# Agents can now collaborate automatically
crew = Crew(
    agents=[researcher, writer],
    tasks=[...],
    verbose=True
)
```

## Como Funciona a Colabora√ß√£o entre Agentes

Quando `allow_delegation=True`, o CrewAI automaticamente fornece aos agentes duas ferramentas poderosas:

### 1. **Ferramenta de Delega√ß√£o de Trabalho**

Permite que agentes designem tarefas para colegas com expertise espec√≠fica.

```python
# Agent automatically gets this tool:
# Delegate work to coworker(task: str, context: str, coworker: str)
```

### 2. **Ferramenta de Fazer Pergunta**

Permite que agentes fa√ßam perguntas espec√≠ficas para obter informa√ß√µes de colegas.

```python
# Agent automatically gets this tool:
# Ask question to coworker(question: str, context: str, coworker: str)
```

## Colabora√ß√£o em A√ß√£o

Veja um exemplo completo onde agentes colaboram em uma tarefa de cria√ß√£o de conte√∫do:

```python
from crewai import Agent, Crew, Task, Process

# Create collaborative agents
researcher = Agent(
    role="Especialista em Pesquisa",
    goal="Realizar pesquisas aprofundadas sobre qualquer tema",
    backstory="Pesquisador especialista com acesso a diversas fontes",
    allow_delegation=True,
    verbose=True
)

writer = Agent(
    role="Redator de Conte√∫do",
    goal="Criar conte√∫do envolvente com base em pesquisas",
    backstory="Redator habilidoso que transforma pesquisas em conte√∫do atraente",
    allow_delegation=True,
    verbose=True
)

editor = Agent(
    role="Content Editor",
    goal="Ensure content quality and consistency",
    backstory="""You're an experienced editor with an eye for detail,
    ensuring content meets high standards for clarity and accuracy.""",
    allow_delegation=True,
    verbose=True
)

# Create a task that encourages collaboration
article_task = Task(
    description="""Escreva um artigo abrangente de 1000 palavras sobre 'O Futuro da IA na Sa√∫de'.

O artigo deve incluir:
- Aplica√ß√µes atuais de IA na sa√∫de
- Tend√™ncias e tecnologias emergentes
- Desafios potenciais e considera√ß√µes √©ticas
- Previs√µes de especialistas para os pr√≥ximos 5 anos

Colabore com seus colegas para garantir precis√£o e qualidade.""",
    expected_output="Um artigo bem pesquisado, envolvente, com 1000 palavras, estrutura adequada e cita√ß√µes",
    agent=writer  # O redator lidera, mas pode delegar pesquisa ao pesquisador
)

# Create collaborative crew
crew = Crew(
    agents=[researcher, writer, editor],
    tasks=[article_task],
    process=Process.sequential,
    verbose=True
)

result = crew.kickoff()
```

## Padr√µes de Colabora√ß√£o

### Padr√£o 1: Pesquisa ‚Üí Reda√ß√£o ‚Üí Edi√ß√£o

```python
research_task = Task(
    description="Pesquise os √∫ltimos avan√ßos em computa√ß√£o qu√¢ntica",
    expected_output="Resumo abrangente da pesquisa com principais descobertas e fontes",
    agent=researcher
)

writing_task = Task(
    description="Escreva um artigo com base nos achados da pesquisa",
    expected_output="Artigo envolvente de 800 palavras sobre computa√ß√£o qu√¢ntica",
    agent=writer,
    context=[research_task]  # Recebe a sa√≠da da pesquisa como contexto
)

editing_task = Task(
    description="Edite e revise o artigo para publica√ß√£o",
    expected_output="Artigo pronto para publica√ß√£o, com clareza e fluidez aprimoradas",
    agent=editor,
    context=[writing_task]  # Recebe o rascunho do artigo como contexto
)
```

### Padr√£o 2: Tarefa √önica Colaborativa

```python
collaborative_task = Task(
    description="""Crie uma estrat√©gia de marketing para um novo produto de IA.

Redator: Foque em mensagens e estrat√©gia de conte√∫do
Pesquisador: Forne√ßa an√°lise de mercado e insights de concorrentes

Trabalhem juntos para criar uma estrat√©gia abrangente.""",
    expected_output="Estrat√©gia de marketing completa com embasamento em pesquisa",
    agent=writer  # Agente l√≠der, mas pode delegar ao pesquisador
)
```

## Colabora√ß√£o Hier√°rquica

Para projetos complexos, utilize um processo hier√°rquico com um agente gerente:

```python
from crewai import Agent, Crew, Task, Process

# Manager agent coordinates the team
manager = Agent(
    role="Gerente de Projetos",
    goal="Coordenar esfor√ßos da equipe e garantir o sucesso do projeto",
    backstory="Gerente de projetos experiente, habilidoso em delega√ß√£o e controle de qualidade",
    allow_delegation=True,
    verbose=True
)

# Specialist agents
researcher = Agent(
    role="Pesquisador",
    goal="Fornecer pesquisa e an√°lise precisas",
    backstory="Pesquisador especialista com habilidades anal√≠ticas profundas",
    allow_delegation=False,  # Especialistas focam em sua expertise
    verbose=True
)

writer = Agent(
    role="Redator",
    goal="Criar conte√∫do envolvente",
    backstory="Redator habilidoso que cria conte√∫do atraente",
    allow_delegation=False,
    verbose=True
)

# Manager-led task
project_task = Task(
    description="Crie um relat√≥rio de an√°lise de mercado completo com recomenda√ß√µes",
    expected_output="Resumo executivo, an√°lise detalhada e recomenda√ß√µes estrat√©gicas",
    agent=manager  # O gerente delega para especialistas
)

# Hierarchical crew
crew = Crew(
    agents=[manager, researcher, writer],
    tasks=[project_task],
    process=Process.hierarchical,  # Manager coordinates everything
    manager_llm="gpt-4o",  # Specify LLM for manager
    verbose=True
)
```

## Melhores Pr√°ticas para Colabora√ß√£o

### 1. **Defini√ß√£o Clara de Pap√©is**

```python
# ‚úÖ Bom: pap√©is espec√≠ficos e complementares
researcher = Agent(role="Market Research Analyst", ...)
writer = Agent(role="Technical Content Writer", ...)

# ‚ùå Evite: Pap√©is sobrepostos ou vagos
agent1 = Agent(role="General Assistant", ...)
agent2 = Agent(role="Helper", ...)
```

### 2. **Delega√ß√£o Estrat√©gica Habilitada**

```python
# ‚úÖ Habilite delega√ß√£o para coordenadores e generalistas
lead_agent = Agent(
    role="Content Lead",
    allow_delegation=True,  # Can delegate to specialists
    ...
)

# ‚úÖ Desative para especialistas focados (opcional)
specialist_agent = Agent(
    role="Data Analyst",
    allow_delegation=False,  # Focuses on core expertise
    ...
)
```

### 3. **Compartilhamento de Contexto**

```python
# ‚úÖ Use o par√¢metro context para depend√™ncias entre tarefas
writing_task = Task(
    description="Write article based on research",
    agent=writer,
    context=[research_task],  # Shares research results
    ...
)
```

### 4. **Descri√ß√µes Claras de Tarefas**

```python
# ‚úÖ Descri√ß√µes espec√≠ficas e acion√°veis
Task(
    description="""Research competitors in the AI chatbot space.
    Focus on: pricing models, key features, target markets.
    Provide data in a structured format.""",
    ...
)

# ‚ùå Descri√ß√µes vagas que n√£o orientam a colabora√ß√£o
Task(description="Do some research about chatbots", ...)
```

## Solu√ß√£o de Problemas em Colabora√ß√£o

### Problema: Agentes N√£o Colaboram

**Sintomas:** Agentes trabalham isoladamente, sem ocorrer delega√ß√£o

```python
# ‚úÖ Solu√ß√£o: Certifique-se que a delega√ß√£o est√° habilitada
agent = Agent(
    role="...",
    allow_delegation=True,  # This is required!
    ...
)
```

### Problema: Troca Excessiva de Perguntas

**Sintomas:** Agentes fazem perguntas em excesso, progresso lento

```python
# ‚úÖ Solu√ß√£o: Forne√ßa melhor contexto e pap√©is espec√≠ficos
Task(
    description="""Write a technical blog post about machine learning.

    Context: Target audience is software developers with basic ML knowledge.
    Length: 1200 words
    Include: code examples, practical applications, best practices

    If you need specific technical details, delegate research to the researcher.""",
    ...
)
```

### Problema: Loops de Delega√ß√£o

**Sintomas:** Agentes delegam tarefas repetidamente uns para os outros indefinidamente

```python
# ‚úÖ Solu√ß√£o: Hierarquia e responsabilidades bem definidas
manager = Agent(role="Manager", allow_delegation=True)
specialist1 = Agent(role="Specialist A", allow_delegation=False)  # No re-delegation
specialist2 = Agent(role="Specialist B", allow_delegation=False)
```

## Recursos Avan√ßados de Colabora√ß√£o

### Regras Personalizadas de Colabora√ß√£o

```python
# Set specific collaboration guidelines in agent backstory
agent = Agent(
    role="Senior Developer",
    backstory="""You lead development projects and coordinate with team members.

    Collaboration guidelines:
    - Delegate research tasks to the Research Analyst
    - Ask the Designer for UI/UX guidance
    - Consult the QA Engineer for testing strategies
    - Only escalate blocking issues to the Project Manager""",
    allow_delegation=True
)
```

### Monitoramento da Colabora√ß√£o

```python
def track_collaboration(output):
    """Track collaboration patterns"""
    if "Delegate work to coworker" in output.raw:
        print("ü§ù Delegation occurred")
    if "Ask question to coworker" in output.raw:
        print("‚ùì Question asked")

crew = Crew(
    agents=[...],
    tasks=[...],
    step_callback=track_collaboration,  # Monitor collaboration
    verbose=True
)
```

## Mem√≥ria e Aprendizado

Permita que agentes se lembrem de colabora√ß√µes passadas:

```python
agent = Agent(
    role="Content Lead",
    memory=True,  # Remembers past interactions
    allow_delegation=True,
    verbose=True
)
```

Com a mem√≥ria ativada, os agentes aprendem com colabora√ß√µes anteriores e aprimoram suas decis√µes de delega√ß√£o ao longo do tempo.

## Pr√≥ximos Passos

* **Teste os exemplos**: Comece pelo exemplo b√°sico de colabora√ß√£o
* **Experimente diferentes pap√©is**: Teste combina√ß√µes variadas de pap√©is de agentes
* **Monitore as intera√ß√µes**: Use `verbose=True` para ver a colabora√ß√£o em a√ß√£o
* **Otimize descri√ß√µes de tarefas**: Tarefas claras geram melhor colabora√ß√£o
* **Escale**: Experimente processos hier√°rquicos para projetos complexos

A colabora√ß√£o transforma agentes de IA individuais em equipes poderosas capazes de enfrentar desafios complexos e multifacetados juntos.


# Crews
Source: https://docs.crewai.com/pt-BR/concepts/crews

Compreendendo e utilizando crews no framework crewAI com atributos e funcionalidades abrangentes.

## Vis√£o Geral

Uma crew no crewAI representa um grupo colaborativo de agentes trabalhando em conjunto para alcan√ßar um conjunto de tarefas. Cada crew define a estrat√©gia de execu√ß√£o de tarefas, colabora√ß√£o entre agentes e o fluxo de trabalho geral.

## Atributos de Crew

| Atributo                              | Par√¢metros             | Descri√ß√£o                                                                                                                                                                                                               |
| :------------------------------------ | :--------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Tasks**                             | `tasks`                | Uma lista de tasks atribu√≠das √† crew.                                                                                                                                                                                   |
| **Agents**                            | `agents`               | Uma lista de agentes que fazem parte da crew.                                                                                                                                                                           |
| **Process** *(opcional)*              | `process`              | O fluxo de processo (por exemplo, sequencial, hier√°rquico) seguido pela crew. O padr√£o √© `sequential`.                                                                                                                  |
| **Verbose** *(opcional)*              | `verbose`              | O n√≠vel de verbosidade para logging durante a execu√ß√£o. O padr√£o √© `False`.                                                                                                                                             |
| **Manager LLM** *(opcional)*          | `manager_llm`          | O modelo de linguagem utilizado pelo agente gerenciador em um processo hier√°rquico. **Obrigat√≥rio ao usar um processo hier√°rquico.**                                                                                    |
| **Function Calling LLM** *(opcional)* | `function_calling_llm` | Se definido, a crew utilizar√° este LLM para invocar fun√ß√µes das ferramentas para todos os agentes da crew. Cada agente pode ter seu pr√≥prio LLM, que substitui o LLM da crew para chamadas de fun√ß√£o.                   |
| **Config** *(opcional)*               | `config`               | Configura√ß√µes opcionais para a crew, no formato `Json` ou `Dict[str, Any]`.                                                                                                                                             |
| **Max RPM** *(opcional)*              | `max_rpm`              | N√∫mero m√°ximo de requisi√ß√µes por minuto que a crew respeita durante a execu√ß√£o. O padr√£o √© `None`.                                                                                                                      |
| **Memory** *(opcional)*               | `memory`               | Utilizada para armazenar mem√≥rias de execu√ß√£o (curto prazo, longo prazo, mem√≥ria de entidade).                                                                                                                          |
| **Memory Config** *(opcional)*        | `memory_config`        | Configura√ß√£o para o provedor de mem√≥ria a ser utilizada pela crew.                                                                                                                                                      |
| **Cache** *(opcional)*                | `cache`                | Especifica se deve usar cache para armazenar os resultados da execu√ß√£o de ferramentas. O padr√£o √© `True`.                                                                                                               |
| **Embedder** *(opcional)*             | `embedder`             | Configura√ß√£o do embedder a ser utilizado pela crew. Atualmente mais usado por memory. O padr√£o √© `{"provider": "openai"}`.                                                                                              |
| **Step Callback** *(opcional)*        | `step_callback`        | Uma fun√ß√£o chamada ap√≥s cada etapa de cada agente. Pode ser usada para registrar as a√ß√µes do agente ou executar outras opera√ß√µes; n√£o sobrescreve o `step_callback` espec√≠fico do agente.                               |
| **Task Callback** *(opcional)*        | `task_callback`        | Uma fun√ß√£o chamada ap√≥s a conclus√£o de cada tarefa. √ötil para monitoramento ou para opera√ß√µes adicionais p√≥s-execu√ß√£o da task.                                                                                          |
| **Share Crew** *(opcional)*           | `share_crew`           | Se deseja compartilhar as informa√ß√µes completas da crew e execu√ß√£o com a equipe do crewAI para melhorar a biblioteca e nos permitir treinar modelos.                                                                    |
| **Output Log File** *(opcional)*      | `output_log_file`      | Defina como True para salvar logs como logs.txt no diret√≥rio atual ou forne√ßa um caminho de arquivo. Os logs estar√£o em formato JSON se o nome terminar com .json, caso contr√°rio .txt. O padr√£o √© `None`.              |
| **Manager Agent** *(opcional)*        | `manager_agent`        | `manager` define um agente customizado que ser√° utilizado como gerente.                                                                                                                                                 |
| **Prompt File** *(opcional)*          | `prompt_file`          | Caminho para o arquivo JSON de prompt a ser utilizado pela crew.                                                                                                                                                        |
| **Planning** *(opcional)*             | `planning`             | Adiciona habilidade de planejamento √† Crew. Quando ativado, antes de cada itera√ß√£o, todos os dados da Crew s√£o enviados a um AgentPlanner que planejar√° as tasks e este plano ser√° adicionado √† descri√ß√£o de cada task. |
| **Planning LLM** *(opcional)*         | `planning_llm`         | O modelo de linguagem usado pelo AgentPlanner em um processo de planejamento.                                                                                                                                           |

<Tip>
  **Crew Max RPM**: O atributo `max_rpm` define o n√∫mero m√°ximo de requisi√ß√µes por minuto que a crew pode executar para evitar limites de taxa e ir√° sobrescrever as configura√ß√µes de `max_rpm` dos agentes individuais se voc√™ o definir.
</Tip>

## Criando Crews

Existem duas maneiras de criar crews no CrewAI: utilizando **configura√ß√£o YAML (recomendado)** ou definindo diretamente **em c√≥digo**.

### Configura√ß√£o YAML (Recomendado)

O uso da configura√ß√£o YAML proporciona uma forma mais limpa e f√°cil de manter para definir crews, sendo consistente com a defini√ß√£o de agentes e tasks em projetos CrewAI.

Ap√≥s criar seu projeto CrewAI conforme descrito na se√ß√£o [Instala√ß√£o](/pt-BR/installation), voc√™ pode definir sua crew em uma classe que herda de `CrewBase` e utiliza decorators para definir agentes, tarefas e a pr√≥pria crew.

#### Exemplo de Classe Crew com Decorators

```python code
from crewai import Agent, Crew, Task, Process
from crewai.project import CrewBase, agent, task, crew, before_kickoff, after_kickoff
from crewai.agents.agent_builder.base_agent import BaseAgent
from typing import List

@CrewBase
class YourCrewName:
    """Descri√ß√£o da sua crew"""

    agents: List[BaseAgent]
    tasks: List[Task]

    # Caminhos para seus arquivos de configura√ß√£o YAML
    # Para um exemplo de agente e tarefa definidos em YAML, confira:
    # - Task: https://docs.crewai.com/concepts/tasks#yaml-configuration-recommended
    # - Agents: https://docs.crewai.com/concepts/agents#yaml-configuration-recommended
    agents_config = 'config/agents.yaml'
    tasks_config = 'config/tasks.yaml'

    @before_kickoff
    def prepare_inputs(self, inputs):
        # Modifique inputs antes da crew iniciar
        inputs['additional_data'] = "Alguma informa√ß√£o extra"
        return inputs

    @after_kickoff
    def process_output(self, output):
        # Modifique a sa√≠da ap√≥s a crew finalizar
        output.raw += "\nProcessado ap√≥s kickoff."
        return output

    @agent
    def agent_one(self) -> Agent:
        return Agent(
            config=self.agents_config['agent_one'], # type: ignore[index]
            verbose=True
        )

    @agent
    def agent_two(self) -> Agent:
        return Agent(
            config=self.agents_config['agent_two'], # type: ignore[index]
            verbose=True
        )

    @task
    def task_one(self) -> Task:
        return Task(
            config=self.tasks_config['task_one'] # type: ignore[index]
        )

    @task
    def task_two(self) -> Task:
        return Task(
            config=self.tasks_config['task_two'] # type: ignore[index]
        )

    @crew
    def crew(self) -> Crew:
        return Crew(
            agents=self.agents,  # Coletado automaticamente pelo decorator @agent
            tasks=self.tasks,    # Coletado automaticamente pelo decorator @task
            process=Process.sequential,
            verbose=True,
        )
```

Como executar o c√≥digo acima:

```python code
YourCrewName().crew().kickoff(inputs={"any": "input here"})
```

<Note>
  As tarefas ser√£o executadas na ordem em que forem definidas.
</Note>

A classe `CrewBase`, junto com esses decorators, automatiza a coleta de agentes e tarefas, reduzindo a necessidade de gerenciamento manual.

#### Vis√£o geral dos Decorators de `annotations.py`

O CrewAI fornece v√°rios decorators no arquivo `annotations.py` que s√£o usados para marcar m√©todos dentro de sua classe crew para tratamento especial:

* `@CrewBase`: Marca a classe como classe base de crew.
* `@agent`: Denota um m√©todo que retorna um objeto `Agent`.
* `@task`: Denota um m√©todo que retorna um objeto `Task`.
* `@crew`: Denota o m√©todo que retorna o objeto `Crew`.
* `@before_kickoff`: (Opcional) Marca um m√©todo a ser executado antes da crew iniciar.
* `@after_kickoff`: (Opcional) Marca um m√©todo a ser executado ap√≥s a crew finalizar.

Esses decorators ajudam na organiza√ß√£o da estrutura da sua crew e coletam automaticamente agentes e tasks sem precisar list√°-los manualmente.

### Defini√ß√£o Direta em C√≥digo (Alternativa)

Como alternativa, voc√™ pode definir a crew diretamente em c√≥digo sem utilizar arquivos de configura√ß√£o YAML.

```python code
from crewai import Agent, Crew, Task, Process
from crewai_tools import YourCustomTool

class YourCrewName:
    def agent_one(self) -> Agent:
        return Agent(
            role="Analista de Dados",
            goal="Analisar tend√™ncias de dados no mercado brasileiro",
            backstory="Analista experiente com forma√ß√£o em economia",
            verbose=True,
            tools=[YourCustomTool()]
        )

    def agent_two(self) -> Agent:
        return Agent(
            role="Pesquisador de Mercado",
            goal="Coletar informa√ß√µes sobre a din√¢mica do mercado nacional",
            backstory="Pesquisador dedicado com olhar atento aos detalhes",
            verbose=True
        )

    def task_one(self) -> Task:
        return Task(
            description="Coletar dados recentes do mercado brasileiro e identificar tend√™ncias.",
            expected_output="Um relat√≥rio resumido com as principais tend√™ncias do mercado.",
            agent=self.agent_one()
        )

    def task_two(self) -> Task:
        return Task(
            description="Pesquisar fatores que afetam a din√¢mica do mercado nacional.",
            expected_output="Uma an√°lise dos fatores que influenciam o mercado.",
            agent=self.agent_two()
        )

    def crew(self) -> Crew:
        return Crew(
            agents=[self.agent_one(), self.agent_two()],
            tasks=[self.task_one(), self.task_two()],
            process=Process.sequential,
            verbose=True
        )
```

Como executar o c√≥digo acima:

```python code
YourCrewName().crew().kickoff(inputs={})
```

Neste exemplo:

* Agentes e tarefas s√£o definidos diretamente dentro da classe, sem decorators.
* Criamos e gerenciamos manualmente a lista de agentes e tasks.
* Essa abordagem fornece mais controle, mas pode ser menos sustent√°vel para projetos maiores.

## Sa√≠da da Crew

A sa√≠da de uma crew no framework CrewAI √© encapsulada na classe `CrewOutput`.
Essa classe fornece uma forma estruturada de acessar os resultados da execu√ß√£o da crew, incluindo v√°rios formatos como string bruta, JSON e modelos Pydantic.
O `CrewOutput` inclui os resultados da tarefa final, uso de tokens e as sa√≠das das tasks individuais.

### Atributos do Crew Output

| Atributo         | Par√¢metros     | Tipo                       | Descri√ß√£o                                                                                      |
| :--------------- | :------------- | :------------------------- | :--------------------------------------------------------------------------------------------- |
| **Raw**          | `raw`          | `str`                      | A sa√≠da bruta da crew. Este √© o formato padr√£o da sa√≠da.                                       |
| **Pydantic**     | `pydantic`     | `Optional[BaseModel]`      | Um objeto modelo Pydantic representando a sa√≠da estruturada da crew.                           |
| **JSON Dict**    | `json_dict`    | `Optional[Dict[str, Any]]` | Um dicion√°rio representando a sa√≠da da crew em formato JSON.                                   |
| **Tasks Output** | `tasks_output` | `List[TaskOutput]`         | Uma lista de objetos `TaskOutput`, cada um representando a sa√≠da de uma task na crew.          |
| **Token Usage**  | `token_usage`  | `Dict[str, Any]`           | Um resumo do uso de tokens, oferecendo informa√ß√µes sobre a performance do modelo de linguagem. |

### M√©todos e Propriedades do Crew Output

| M√©todo/Propriedade | Descri√ß√£o                                                                                              |
| :----------------- | :----------------------------------------------------------------------------------------------------- |
| **json**           | Retorna a representa√ß√£o em string JSON da sa√≠da da crew caso o formato seja JSON.                      |
| **to\_dict**       | Converte as sa√≠das JSON e Pydantic em um dicion√°rio.                                                   |
| ****str****        | Retorna a representa√ß√£o em string do resultado da crew, priorizando Pydantic, depois JSON, depois raw. |

### Acessando a Sa√≠da da Crew

Ap√≥s executar uma crew, sua sa√≠da pode ser acessada pelo atributo `output` do objeto `Crew`. A classe `CrewOutput` oferece v√°rias formas de interagir com esta sa√≠da.

#### Exemplo

```python Code
# Execu√ß√£o de exemplo da crew
crew = Crew(
    agents=[research_agent, writer_agent],
    tasks=[research_task, write_article_task],
    verbose=True
)

crew_output = crew.kickoff()

# Acessando a sa√≠da da crew
print(f"Raw Output: {crew_output.raw}")
if crew_output.json_dict:
    print(f"JSON Output: {json.dumps(crew_output.json_dict, indent=2)}")
if crew_output.pydantic:
    print(f"Pydantic Output: {crew_output.pydantic}")
print(f"Tasks Output: {crew_output.tasks_output}")
print(f"Token Usage: {crew_output.token_usage}")
```

## Acessando Logs da Crew

Voc√™ pode visualizar o log em tempo real da execu√ß√£o da crew, definindo `output_log_file` como `True(Boolean)` ou um `file_name(str)`. Suporta logging de eventos como tanto `file_name.txt` quanto `file_name.json`.
Se for `True(Boolean)`, salvar√° como `logs.txt`.

Caso `output_log_file` seja `False(Boolean)` ou `None`, os logs n√£o ser√£o gerados.

```python Code
# Salvar logs da crew
crew = Crew(output_log_file = True)  # Logs ser√£o salvos como logs.txt
crew = Crew(output_log_file = file_name)  # Logs ser√£o salvos como file_name.txt
crew = Crew(output_log_file = file_name.txt)  # Logs ser√£o salvos como file_name.txt
crew = Crew(output_log_file = file_name.json)  # Logs ser√£o salvos como file_name.json
```

## Utiliza√ß√£o de Mem√≥ria

As crews podem utilizar mem√≥ria (curto prazo, longo prazo e mem√≥ria de entidade) para potencializar sua execu√ß√£o e aprendizado ao longo do tempo. Este recurso permite que as crews armazenem e recuperem mem√≥rias de execu√ß√£o, auxiliando na tomada de decis√£o e nas estrat√©gias de execu√ß√£o de tasks.

## Utiliza√ß√£o de Cache

Caches podem ser utilizados para armazenar resultados de execu√ß√µes de ferramentas, tornando o processo mais eficiente ao evitar a reexecu√ß√£o de tasks id√™nticas.

## M√©tricas de Uso da Crew

Ap√≥s a execu√ß√£o da crew, voc√™ pode acessar o atributo `usage_metrics` para visualizar as m√©tricas de uso do modelo de linguagem (LLM) para todas as tasks executadas pela crew. Isso fornece insights sobre efici√™ncia operacional e oportunidades de melhoria.

```python Code
# Acessar as m√©tricas de uso da crew
crew = Crew(agents=[agent1, agent2], tasks=[task1, task2])
crew.kickoff()
print(crew.usage_metrics)
```

## Processo de Execu√ß√£o da Crew

* **Sequential Process**: As tasks s√£o executadas uma ap√≥s a outra, permitindo um fluxo de trabalho linear.
* **Hierarchical Process**: Um agente gerente coordena a crew, delegando tarefas e validando resultados antes de prosseguir. **Nota**: Um `manager_llm` ou `manager_agent` √© necess√°rio para este processo e √© essencial para validar o fluxo.

### Iniciando uma Crew

Uma vez que sua crew esteja montada, inicie o workflow com o m√©todo `kickoff()`. Isso inicia a execu√ß√£o conforme o fluxo de processo definido.

```python Code
# Iniciar execu√ß√£o das tasks da crew
result = my_crew.kickoff()
print(result)
```

### Diferentes Formas de Iniciar uma Crew

Assim que sua crew estiver definida, inicie o fluxo de trabalho com o m√©todo kickoff apropriado. O CrewAI oferece v√°rios m√©todos para melhor controle do processo: `kickoff()`, `kickoff_for_each()`, `kickoff_async()` e `kickoff_for_each_async()`.

* `kickoff()`: Inicia o processo de execu√ß√£o seguindo o fluxo definido.
* `kickoff_for_each()`: Executa tasks sequencialmente para cada evento de entrada ou item da cole√ß√£o fornecida.
* `kickoff_async()`: Inicia o workflow de forma ass√≠ncrona.
* `kickoff_for_each_async()`: Executa as tasks concorrentemente para cada entrada, aproveitando o processamento ass√≠ncrono.

```python Code
# Iniciar execu√ß√£o das tasks da crew
result = my_crew.kickoff()
print(result)

# Exemplo com kickoff_for_each
inputs_array = [{'topic': 'AI in healthcare'}, {'topic': 'AI in finance'}]
results = my_crew.kickoff_for_each(inputs=inputs_array)
for result in results:
    print(result)

# Exemplo com kickoff_async
inputs = {'topic': 'AI in healthcare'}
async_result = await my_crew.kickoff_async(inputs=inputs)
print(async_result)

# Exemplo com kickoff_for_each_async
inputs_array = [{'topic': 'AI in healthcare'}, {'topic': 'AI in finance'}]
async_results = await my_crew.kickoff_for_each_async(inputs=inputs_array)
for async_result in async_results:
    print(async_result)
```

Esses m√©todos fornecem flexibilidade para gerenciar e executar tasks dentro de sua crew, permitindo fluxos de trabalho s√≠ncronos e ass√≠ncronos de acordo com sua necessidade.

### Repetindo Execu√ß√£o a partir de uma Task Espec√≠fica

Agora √© poss√≠vel reiniciar a execu√ß√£o a partir de uma task espec√≠fica usando o comando CLI `replay`.

O recurso de replay no CrewAI permite reexecutar a partir de uma task espec√≠fica atrav√©s da interface de linha de comando (CLI). Rodando o comando `crewai replay -t <task_id>`, voc√™ pode especificar o `task_id` para o processo de replay.

Kickoffs agora salvam localmente as sa√≠das das tasks dos kickoffs recentes para permitir replay posteriormente.

### Repetindo a Partir de uma Task Espec√≠fica Usando o CLI

Para usar o recurso de replay, siga estes passos:

1. Abra seu terminal ou prompt de comando.
2. Navegue at√© o diret√≥rio do seu projeto CrewAI.
3. Execute o seguinte comando:

Para visualizar os IDs das √∫ltimas tasks do kickoff, utilize:

```shell
crewai log-tasks-outputs
```

Depois, para repetir a partir de uma task espec√≠fica, utilize:

```shell
crewai replay -t <task_id>
```

Esses comandos permitem repetir tasks dos seus √∫ltimos kickoffs, mantendo o contexto das tasks j√° executadas anteriormente.


# Listeners de Evento
Source: https://docs.crewai.com/pt-BR/concepts/event-listener

Acesse eventos do CrewAI para criar integra√ß√µes e monitoramento personalizados

## Vis√£o Geral

O CrewAI oferece um sistema de eventos poderoso que permite escutar e reagir a diversos eventos que ocorrem durante a execu√ß√£o do seu Crew. Esse recurso possibilita a cria√ß√£o de integra√ß√µes personalizadas, solu√ß√µes de monitoramento, sistemas de log ou qualquer outra funcionalidade que precise ser acionada com base nos eventos internos do CrewAI.

## Como Funciona

O CrewAI utiliza uma arquitetura de event bus para emitir eventos ao longo do ciclo de vida da execu√ß√£o. O sistema de eventos √© constru√≠do a partir dos seguintes componentes:

1. **CrewAIEventsBus**: Um event bus singleton que gerencia o registro e emiss√£o de eventos
2. **BaseEvent**: Classe base para todos os eventos do sistema
3. **BaseEventListener**: Classe base abstrata para criar listeners de evento personalizados

Quando a√ß√µes espec√≠ficas ocorrem no CrewAI (como a inicializa√ß√£o de um Crew, um Agent concluindo uma tarefa ou o uso de uma ferramenta), o sistema emite os eventos correspondentes. Voc√™ pode registrar handlers para esses eventos para executar c√≥digo personalizado quando eles acontecerem.

<Note type="info" title="Aprimoramento Enterprise: Prompt Tracing">
  O CrewAI Enterprise fornece o recurso Prompt Tracing, que aproveita o sistema de eventos para rastrear, armazenar e visualizar todos os prompts, respostas e metadados associados. Isso proporciona poderosas capacidades de depura√ß√£o e transpar√™ncia nas opera√ß√µes dos seus agentes.

  ![Prompt Tracing Dashboard](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/traces-overview.png)

  Com o Prompt Tracing voc√™ pode:

  * Visualizar o hist√≥rico completo de todos os prompts enviados ao seu LLM
  * Monitorar o uso de tokens e custos
  * Depurar falhas de racioc√≠nio dos agentes
  * Compartilhar sequ√™ncias de prompts com sua equipe
  * Comparar diferentes estrat√©gias de prompts
  * Exportar rastreamentos para compliance e auditoria
</Note>

## Criando um Listener de Evento Personalizado

Para criar um listener de evento personalizado, voc√™ precisa:

1. Criar uma classe que herde de `BaseEventListener`
2. Implementar o m√©todo `setup_listeners`
3. Registrar handles para os eventos de seu interesse
4. Instanciar seu listener no arquivo apropriado

Veja um exemplo simples de uma classe de listener de evento personalizado:

```python
from crewai.utilities.events import (
    CrewKickoffStartedEvent,
    CrewKickoffCompletedEvent,
    AgentExecutionCompletedEvent,
)
from crewai.utilities.events.base_event_listener import BaseEventListener

class MeuListenerPersonalizado(BaseEventListener):
    def __init__(self):
        super().__init__()

    def setup_listeners(self, crewai_event_bus):
        @crewai_event_bus.on(CrewKickoffStartedEvent)
        def ao_iniciar_crew(source, event):
            print(f"Crew '{event.crew_name}' iniciou a execu√ß√£o!")

        @crewai_event_bus.on(CrewKickoffCompletedEvent)
        def ao_finalizar_crew(source, event):
            print(f"Crew '{event.crew_name}' finalizou a execu√ß√£o!")
            print(f"Sa√≠da: {event.output}")

        @crewai_event_bus.on(AgentExecutionCompletedEvent)
        def ao_finalizar_execucao_agente(source, event):
            print(f"Agente '{event.agent.role}' concluiu a tarefa")
            print(f"Sa√≠da: {event.output}")
```

## Registrando Corretamente Seu Listener

Apenas definir sua classe de listener n√£o √© suficiente. √â necess√°rio criar uma inst√¢ncia dela e garantir que ela seja importada na sua aplica√ß√£o. Isso garante que:

1. Os event handlers estejam registrados no event bus
2. A inst√¢ncia do listener permane√ßa em mem√≥ria (n√£o seja coletada pelo garbage collector)
3. O listener esteja ativo quando os eventos forem emitidos

### Op√ß√£o 1: Importar e Instanciar no Seu Crew ou Implementa√ß√£o de Flow

O mais importante √© criar uma inst√¢ncia do seu listener no arquivo onde seu Crew ou Flow est√° definido e executado:

#### Para Aplica√ß√µes Baseadas em Crew

Crie e importe seu listener no in√≠cio do arquivo de implementa√ß√£o do seu Crew:

```python
# No seu arquivo crew.py
from crewai import Agent, Crew, Task
from my_listeners import MyCustomListener

# Crie uma inst√¢ncia do seu listener
my_listener = MyCustomListener()

class MyCustomCrew:
    # Sua implementa√ß√£o do crew...

    def crew(self):
        return Crew(
            agents=[...],
            tasks=[...],
            # ...
        )
```

#### Para Aplica√ß√µes Baseadas em Flow

Crie e importe seu listener no in√≠cio do arquivo de implementa√ß√£o do seu Flow:

```python
# Em seu arquivo main.py ou flow.py
from crewai.flow import Flow, listen, start
from my_listeners import MyCustomListener

# Crie uma inst√¢ncia do seu listener
my_listener = MyCustomListener()

class MyCustomFlow(Flow):
    # Sua implementa√ß√£o do flow...

    @start()
    def first_step(self):
        # ...
```

Isso assegura que seu listener ser√° carregado e estar√° ativo quando seu Crew ou Flow for executado.

### Op√ß√£o 2: Criar um Pacote para Seus Listeners

Para uma abordagem mais estruturada, especialmente se houver m√∫ltiplos listeners:

1. Crie um pacote para seus listeners:

```
my_project/
  ‚îú‚îÄ‚îÄ listeners/
  ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
  ‚îÇ   ‚îú‚îÄ‚îÄ my_custom_listener.py
  ‚îÇ   ‚îî‚îÄ‚îÄ another_listener.py
```

2. Em `my_custom_listener.py`, defina sua classe de listener e crie uma inst√¢ncia:

```python
# my_custom_listener.py
from crewai.utilities.events.base_event_listener import BaseEventListener
# ... importe events ...

class MyCustomListener(BaseEventListener):
    # ... implementa√ß√£o ...

# Crie uma inst√¢ncia do seu listener
my_custom_listener = MyCustomListener()
```

3. Em `__init__.py`, importe as inst√¢ncias dos listeners para garantir seu carregamento:

```python
# __init__.py
from .my_custom_listener import my_custom_listener
from .another_listener import another_listener

# Opcionalmente exporte-os se precisar acess√°-los em outros lugares
__all__ = ['my_custom_listener', 'another_listener']
```

4. Importe seu pacote de listeners no arquivo do seu Crew ou Flow:

```python
# No seu arquivo crew.py ou flow.py
import my_project.listeners  # Isso carrega todos os seus listeners

class MyCustomCrew:
    # Sua implementa√ß√£o do crew...
```

√â exatamente assim que o `agentops_listener` integrado do CrewAI √© registrado. No c√≥digo-fonte do CrewAI, voc√™ encontrar√°:

```python
# src/crewai/utilities/events/third_party/__init__.py
from .agentops_listener import agentops_listener
```

Isso garante que o `agentops_listener` seja carregado quando o pacote `crewai.utilities.events` for importado.

## Tipos de Eventos Dispon√≠veis

O CrewAI fornece uma ampla variedade de eventos para escuta:

### Eventos de Crew

* **CrewKickoffStartedEvent**: Emitido quando um Crew inicia a execu√ß√£o
* **CrewKickoffCompletedEvent**: Emitido quando um Crew conclui a execu√ß√£o
* **CrewKickoffFailedEvent**: Emitido quando um Crew falha ao concluir a execu√ß√£o
* **CrewTestStartedEvent**: Emitido ao iniciar o teste de um Crew
* **CrewTestCompletedEvent**: Emitido ao concluir o teste de um Crew
* **CrewTestFailedEvent**: Emitido ao falhar no teste de um Crew
* **CrewTrainStartedEvent**: Emitido ao iniciar o treinamento de um Crew
* **CrewTrainCompletedEvent**: Emitido ao concluir o treinamento de um Crew
* **CrewTrainFailedEvent**: Emitido ao falhar no treinamento de um Crew

### Eventos de Agent

* **AgentExecutionStartedEvent**: Emitido quando um Agent inicia a execu√ß√£o de uma tarefa
* **AgentExecutionCompletedEvent**: Emitido quando um Agent conclui a execu√ß√£o de uma tarefa
* **AgentExecutionErrorEvent**: Emitido quando um Agent encontra um erro durante a execu√ß√£o

### Eventos de Task

* **TaskStartedEvent**: Emitido ao iniciar a execu√ß√£o de uma Task
* **TaskCompletedEvent**: Emitido ao concluir a execu√ß√£o de uma Task
* **TaskFailedEvent**: Emitido ao falhar na execu√ß√£o de uma Task
* **TaskEvaluationEvent**: Emitido quando uma Task √© avaliada

### Eventos de Uso de Ferramentas

* **ToolUsageStartedEvent**: Emitido ao iniciar a execu√ß√£o de uma ferramenta
* **ToolUsageFinishedEvent**: Emitido ao concluir a execu√ß√£o de uma ferramenta
* **ToolUsageErrorEvent**: Emitido quando ocorre erro na execu√ß√£o de uma ferramenta
* **ToolValidateInputErrorEvent**: Emitido ao ocorrer erro de valida√ß√£o de entrada na ferramenta
* **ToolExecutionErrorEvent**: Emitido quando ocorre erro na execu√ß√£o de uma ferramenta
* **ToolSelectionErrorEvent**: Emitido ao ocorrer erro na sele√ß√£o de uma ferramenta

### Eventos de Knowledge

* **KnowledgeRetrievalStartedEvent**: Emitido ao iniciar recupera√ß√£o de conhecimento
* **KnowledgeRetrievalCompletedEvent**: Emitido ao concluir recupera√ß√£o de conhecimento
* **KnowledgeQueryStartedEvent**: Emitido ao iniciar consulta de conhecimento
* **KnowledgeQueryCompletedEvent**: Emitido ao concluir consulta de conhecimento
* **KnowledgeQueryFailedEvent**: Emitido ao falhar consulta de conhecimento
* **KnowledgeSearchQueryFailedEvent**: Emitido ao falhar consulta de busca de conhecimento

### Eventos de Guardrail do LLM

* **LLMGuardrailStartedEvent**: Emitido ao iniciar valida√ß√£o dos guardrails. Cont√©m detalhes do guardrail aplicado e tentativas.
* **LLMGuardrailCompletedEvent**: Emitido ao concluir valida√ß√£o dos guardrails. Cont√©m detalhes sobre sucesso/falha na valida√ß√£o, resultados e mensagens de erro, se houver.

### Eventos de Flow

* **FlowCreatedEvent**: Emitido ao criar um Flow
* **FlowStartedEvent**: Emitido ao iniciar a execu√ß√£o de um Flow
* **FlowFinishedEvent**: Emitido ao concluir a execu√ß√£o de um Flow
* **FlowPlotEvent**: Emitido ao plotar um Flow
* **MethodExecutionStartedEvent**: Emitido ao iniciar a execu√ß√£o de um m√©todo do Flow
* **MethodExecutionFinishedEvent**: Emitido ao concluir a execu√ß√£o de um m√©todo do Flow
* **MethodExecutionFailedEvent**: Emitido ao falhar na execu√ß√£o de um m√©todo do Flow

### Eventos de LLM

* **LLMCallStartedEvent**: Emitido ao iniciar uma chamada LLM
* **LLMCallCompletedEvent**: Emitido ao concluir uma chamada LLM
* **LLMCallFailedEvent**: Emitido ao falhar uma chamada LLM
* **LLMStreamChunkEvent**: Emitido para cada chunk recebido durante respostas em streaming do LLM

## Estrutura dos Handlers de Evento

Cada handler de evento recebe dois par√¢metros:

1. **source**: O objeto que emitiu o evento
2. **event**: A inst√¢ncia do evento, contendo dados espec√≠ficos do evento

A estrutura do objeto de evento depende do tipo do evento, mas todos herdam de `BaseEvent` e incluem:

* **timestamp**: O hor√°rio em que o evento foi emitido
* **type**: Identificador do tipo do evento

Campos adicionais variam pelo tipo de evento. Por exemplo, `CrewKickoffCompletedEvent` inclui os campos `crew_name` e `output`.

## Exemplo Real: Integra√ß√£o com AgentOps

O CrewAI inclui um exemplo de integra√ß√£o com [AgentOps](https://github.com/AgentOps-AI/agentops), uma plataforma de monitoramento e observabilidade para agentes de IA. Veja como √© implementado:

```python
from typing import Optional

from crewai.utilities.events import (
    CrewKickoffCompletedEvent,
    ToolUsageErrorEvent,
    ToolUsageStartedEvent,
)
from crewai.utilities.events.base_event_listener import BaseEventListener
from crewai.utilities.events.crew_events import CrewKickoffStartedEvent
from crewai.utilities.events.task_events import TaskEvaluationEvent

try:
    import agentops
    AGENTOPS_INSTALLED = True
except ImportError:
    AGENTOPS_INSTALLED = False

class AgentOpsListener(BaseEventListener):
    tool_event: Optional["agentops.ToolEvent"] = None
    session: Optional["agentops.Session"] = None

    def __init__(self):
        super().__init__()

    def setup_listeners(self, crewai_event_bus):
        if not AGENTOPS_INSTALLED:
            return

        @crewai_event_bus.on(CrewKickoffStartedEvent)
        def on_crew_kickoff_started(source, event: CrewKickoffStartedEvent):
            self.session = agentops.init()
            for agent in source.agents:
                if self.session:
                    self.session.create_agent(
                        name=agent.role,
                        agent_id=str(agent.id),
                    )

        @crewai_event_bus.on(CrewKickoffCompletedEvent)
        def on_crew_kickoff_completed(source, event: CrewKickoffCompletedEvent):
            if self.session:
                self.session.end_session(
                    end_state="Success",
                    end_state_reason="Finished Execution",
                )

        @crewai_event_bus.on(ToolUsageStartedEvent)
        def on_tool_usage_started(source, event: ToolUsageStartedEvent):
            self.tool_event = agentops.ToolEvent(name=event.tool_name)
            if self.session:
                self.session.record(self.tool_event)

        @crewai_event_bus.on(ToolUsageErrorEvent)
        def on_tool_usage_error(source, event: ToolUsageErrorEvent):
            agentops.ErrorEvent(exception=event.error, trigger_event=self.tool_event)
```

Esse listener inicializa uma sess√£o do AgentOps quando um Crew inicia, cadastra agentes no AgentOps, rastreia o uso de ferramentas e finaliza a sess√£o quando o Crew √© conclu√≠do.

O listener AgentOps √© registrado no sistema de eventos do CrewAI via importa√ß√£o em `src/crewai/utilities/events/third_party/__init__.py`:

```python
from .agentops_listener import agentops_listener
```

Isso garante que o `agentops_listener` seja carregado quando o pacote `crewai.utilities.events` for importado.

## Uso Avan√ßado: Handlers Escopados

Para lidar temporariamente com eventos (√∫til para testes ou opera√ß√µes espec√≠ficas), voc√™ pode usar o context manager `scoped_handlers`:

```python
from crewai.utilities.events import crewai_event_bus, CrewKickoffStartedEvent

with crewai_event_bus.scoped_handlers():
    @crewai_event_bus.on(CrewKickoffStartedEvent)
    def temp_handler(source, event):
        print("Este handler s√≥ existe neste contexto")

    # Fa√ßa algo que emita eventos

# Fora do contexto, o handler tempor√°rio √© removido
```

## Casos de Uso

Listeners de evento podem ser usados para v√°rias finalidades:

1. **Log e Monitoramento**: Monitore a execu√ß√£o do seu Crew e registre eventos importantes
2. **Analytics**: Colete dados sobre o desempenho e comportamento do seu Crew
3. **Depura√ß√£o**: Configure listeners tempor√°rios para debugar problemas espec√≠ficos
4. **Integra√ß√£o**: Conecte o CrewAI a sistemas externos como plataformas de monitoramento, bancos de dados ou servi√ßos de notifica√ß√£o
5. **Comportamento Personalizado**: Dispare a√ß√µes personalizadas com base em eventos espec√≠ficos

## Boas Pr√°ticas

1. **Mantenha Handlers Leves**: Handlers de eventos devem ser leves e evitar opera√ß√µes bloqueantes
2. **Tratamento de Erros**: Implemente tratamento de erros adequado nos event handlers para evitar que exce√ß√µes afetem a execu√ß√£o principal
3. **Limpeza**: Se seu listener alocar recursos, garanta o devido fechamento/libera√ß√£o
4. **Escuta Seletiva**: Escute apenas eventos que realmente precisa tratar
5. **Testes**: Teste seus listeners de evento isoladamente para garantir que se comportam conforme esperado

Aproveitando o sistema de eventos do CrewAI, √© poss√≠vel estender a funcionalidade e integr√°-lo facilmente √† sua infraestrutura existente.


# Flows
Source: https://docs.crewai.com/pt-BR/concepts/flows

Saiba como criar e gerenciar fluxos de trabalho de IA usando CrewAI Flows.

## Vis√£o Geral

O CrewAI Flows √© um recurso poderoso projetado para simplificar a cria√ß√£o e o gerenciamento de fluxos de trabalho de IA. Os flows permitem que desenvolvedores combinem e coordenem tarefas de codifica√ß√£o e crews de forma eficiente, proporcionando uma estrutura robusta para a constru√ß√£o de automa√ß√µes de IA sofisticadas.

Os flows permitem que voc√™ crie fluxos de trabalho estruturados e orientados por eventos. Eles oferecem uma forma integrada de conectar m√∫ltiplas tarefas, gerenciar estado e controlar o fluxo de execu√ß√£o nas suas aplica√ß√µes de IA. Com flows, voc√™ pode facilmente projetar e implementar processos de m√∫ltiplas etapas que exploram todo o potencial das capacidades do CrewAI.

1. **Cria√ß√£o Simplificada de Fluxos de Trabalho**: Conecte facilmente m√∫ltiplas crews e tarefas para criar workflows de IA complexos.

2. **Gerenciamento de Estado**: Flows facilitam muito o gerenciamento e o compartilhamento de estados entre diferentes tarefas do seu fluxo de trabalho.

3. **Arquitetura Orientada a Eventos**: Constru√≠do sobre um modelo orientado a eventos, permitindo fluxos din√¢micos e responsivos.

4. **Controle de Fluxo Flex√≠vel**: Implemente l√≥gica condicional, loops e ramifica√ß√µes dentro dos seus fluxos.

## Primeiros Passos

Vamos criar um Flow simples no qual voc√™ usar√° a OpenAI para gerar uma cidade aleat√≥ria em uma tarefa e, em seguida, usar√° essa cidade para gerar uma curiosidade em outra tarefa.

```python Code
# (O c√≥digo n√£o √© traduzido)
```

Na ilustra√ß√£o acima, criamos um Flow simples que gera uma cidade aleat√≥ria usando a OpenAI e depois cria uma curiosidade sobre essa cidade. O Flow consiste em duas tarefas: `generate_city` e `generate_fun_fact`. A tarefa `generate_city` √© o ponto de in√≠cio do Flow, enquanto a tarefa `generate_fun_fact` fica escutando o resultado da tarefa `generate_city`.

Cada inst√¢ncia de Flow recebe automaticamente um identificador √∫nico (UUID) em seu estado, que auxilia no rastreamento e gerenciamento das execu√ß√µes. O estado tamb√©m pode armazenar dados adicionais (como a cidade gerada e a curiosidade) que permanecem durante toda a execu√ß√£o do flow.

Ao executar o Flow, ele ir√°:

1. Gerar um ID √∫nico para o estado do flow
2. Gerar uma cidade aleat√≥ria e armazen√°-la no estado
3. Gerar uma curiosidade sobre essa cidade e armazen√°-la no estado
4. Imprimir os resultados no console

O ID √∫nico do estado e os dados armazenados podem ser √∫teis para rastrear execu√ß√µes do flow e manter contexto entre as tarefas.

**Nota:** Certifique-se de configurar seu arquivo `.env` para armazenar sua `OPENAI_API_KEY`. Essa chave √© necess√°ria para autenticar as requisi√ß√µes √† API da OpenAI.

### @start()

O decorador `@start()` √© utilizado para marcar um m√©todo como ponto inicial de um Flow. Quando um Flow √© iniciado, todos os m√©todos decorados com `@start()` s√£o executados em paralelo. √â poss√≠vel ter m√∫ltiplos m√©todos start em um Flow, e todos eles ser√£o executados quando o Flow iniciar.

### @listen()

O decorador `@listen()` √© utilizado para marcar um m√©todo como ouvinte da sa√≠da de outra tarefa do Flow. O m√©todo decorado com `@listen()` ser√° executado quando a tarefa especificada emitir uma sa√≠da. O m√©todo pode acessar a sa√≠da da tarefa √† qual est√° escutando como argumento.

#### Utiliza√ß√£o

O decorador `@listen()` pode ser usado de v√°rias formas:

1. **Escutando um M√©todo pelo Nome**: Voc√™ pode passar o nome do m√©todo ao qual deseja escutar como string. Quando esse m√©todo concluir, o m√©todo ouvinte ser√° chamado.

   ```python Code
   # (O c√≥digo n√£o √© traduzido)
   ```

2. **Escutando um M√©todo Diretamente**: Voc√™ pode passar o pr√≥prio m√©todo. Quando esse m√©todo concluir, o m√©todo ouvinte ser√° chamado.
   ```python Code
   # (O c√≥digo n√£o √© traduzido)
   ```

### Sa√≠da de um Flow

Acessar e manipular a sa√≠da de um Flow √© essencial para integrar seus workflows de IA a aplica√ß√µes ou sistemas maiores. O CrewAI Flows fornece mecanismos f√°ceis para recuperar a sa√≠da final, acessar resultados intermedi√°rios e gerenciar o estado geral do seu Flow.

#### Recuperando a Sa√≠da Final

Ao executar um Flow, a sa√≠da final √© determinada pelo √∫ltimo m√©todo conclu√≠do. O m√©todo `kickoff()` retorna a sa√≠da desse m√©todo final.

Veja como acessar a sa√≠da final:

<CodeGroup>
  ```python Code
  # (O c√≥digo n√£o √© traduzido)
  ```

  ```text Output
  ---- Final Output ----
  Second method received: Output from first_method
  ```
</CodeGroup>

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-2.png)

Neste exemplo, o `second_method` √© o √∫ltimo m√©todo a ser conclu√≠do, logo sua sa√≠da ser√° a sa√≠da final do Flow.
O m√©todo `kickoff()` retorna essa sa√≠da, que √© impressa no console. O m√©todo `plot()` ir√° gerar o arquivo HTML para visualizar o fluxo.

#### Acessando e Atualizando o Estado

Al√©m de recuperar a sa√≠da final, voc√™ pode acessar e atualizar o estado dentro do seu Flow. O estado pode ser usado para armazenar e compartilhar dados entre diferentes m√©todos do Flow. Ap√≥s a execu√ß√£o do Flow, voc√™ pode acessar o estado para recuperar informa√ß√µes adicionadas ou alteradas durante o processo.

Veja um exemplo de como atualizar e acessar o estado:

<CodeGroup>
  ```python Code
  # (O c√≥digo n√£o √© traduzido)
  ```

  ```text Output
  Final Output: Hello from first_method - updated by second_method
  Final State:
  counter=2 message='Hello from first_method - updated by second_method'
  ```
</CodeGroup>

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-2.png)

Neste exemplo, o estado √© atualizado tanto por `first_method` quanto por `second_method`.
Ap√≥s o t√©rmino da execu√ß√£o, √© poss√≠vel acessar o estado final e observar as atualiza√ß√µes realizadas por esses m√©todos.

Ao garantir que a sa√≠da do m√©todo final seja retornada e oferecer acesso ao estado, o CrewAI Flows facilita a integra√ß√£o dos resultados dos seus workflows de IA em aplica√ß√µes maiores,
al√©m de permitir o gerenciamento e o acesso ao estado durante toda a execu√ß√£o do Flow.

## Gerenciamento de Estado em Flows

Gerenciar o estado de forma eficaz √© fundamental para construir fluxos de trabalho de IA confi√°veis e de f√°cil manuten√ß√£o. O CrewAI Flows oferece mecanismos robustos para o gerenciamento de estado tanto n√£o estruturado quanto estruturado,
permitindo que o desenvolvedor escolha a abordagem que melhor se adapta √† sua aplica√ß√£o.

### Gerenciamento de Estado N√£o Estruturado

No gerenciamento de estado n√£o estruturado, todo o estado √© armazenado no atributo `state` da classe `Flow`.
Essa abordagem oferece flexibilidade, permitindo que o desenvolvedor adicione ou modifique atributos do estado conforme necess√°rio sem precisar definir um esquema r√≠gido.
Mesmo com estados n√£o estruturados, os flows do CrewAI geram e mant√™m automaticamente um identificador √∫nico (UUID) para cada inst√¢ncia de estado.

```python Code
# (O c√≥digo n√£o √© traduzido)
```

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-3.png)

**Nota:** O campo `id` √© gerado e preservado automaticamente durante toda a execu√ß√£o do flow. N√£o √© necess√°rio gerenci√°-lo ou defini-lo manualmente, e ele permanecer√° mesmo ao atualizar o estado com novos dados.

**Pontos-Chave:**

* **Flexibilidade:** √â poss√≠vel adicionar atributos dinamicamente ao `self.state` sem restri√ß√µes pr√©-definidas.
* **Simplicidade:** Ideal para fluxos de trabalho diretos em que a estrutura do estado √© m√≠nima ou varia bastante.

### Gerenciamento de Estado Estruturado

No gerenciamento de estado estruturado, utilizam-se esquemas pr√©-definidos para garantir consist√™ncia e seguran√ßa de tipos em todo o workflow.
Ao usar modelos como o `BaseModel` da Pydantic, os desenvolvedores podem definir a forma exata do estado, melhorando a valida√ß√£o e fornecendo auto-complete nos ambientes de desenvolvimento.

Cada estado nos flows do CrewAI recebe automaticamente um identificador √∫nico (UUID) para ajudar no rastreamento e gerenciamento. Esse ID √© gerado e mantido automaticamente pelo sistema de flows.

```python Code
# (O c√≥digo n√£o √© traduzido)
```

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-3.png)

**Pontos-Chave:**

* **Esquema Definido:** `ExampleState` deixa claro a estrutura do estado, aumentando a legibilidade e a manuten√ß√£o do c√≥digo.
* **Seguran√ßa de Tipos:** O uso da Pydantic garante que os atributos do estado tenham os tipos certos, reduzindo os erros em tempo de execu√ß√£o.
* **Auto-Completar:** IDEs conseguem oferecer auto-completar e checagem de erros, gra√ßas ao modelo definido do estado.

### Escolhendo entre Estado N√£o Estruturado e Estruturado

* **Use Estado N√£o Estruturado quando:**
  * O estado do fluxo √© simples ou altamente din√¢mico.
  * Flexibilidade √© mais importante do que uma defini√ß√£o r√≠gida do estado.
  * Prototipagem r√°pida √© necess√°ria sem a sobrecarga de defini√ß√£o de esquemas.

* **Use Estado Estruturado quando:**
  * O flow exige uma estrutura de estado bem definida e consistente.
  * Seguran√ßa de tipos e valida√ß√£o s√£o importantes para a confiabilidade da aplica√ß√£o.
  * √â desejado usar recursos da IDE como auto-completar e checagem de tipos para uma melhor experi√™ncia de desenvolvimento.

Ao oferecer as duas op√ß√µes de gerenciamento de estado, o CrewAI Flows permite que desenvolvedores criem fluxos de IA que sejam ao mesmo tempo flex√≠veis e robustos, atendendo a uma ampla variedade de requisitos de aplica√ß√£o.

## Persist√™ncia de Flow

O decorador @persist permite a persist√™ncia autom√°tica do estado nos flows do CrewAI, garantindo que voc√™ mantenha o estado do flow entre reinicializa√ß√µes ou execu√ß√µes diferentes do workflow. Esse decorador pode ser aplicado tanto ao n√≠vel de classe, quanto ao n√≠vel de m√©todo, oferecendo flexibilidade sobre como gerenciar a persist√™ncia do estado.

### Persist√™ncia no N√≠vel de Classe

Quando aplicado no n√≠vel da classe, o decorador @persist garante a persist√™ncia autom√°tica de todos os estados dos m√©todos do flow:

```python
# (O c√≥digo n√£o √© traduzido)
```

### Persist√™ncia no N√≠vel de M√©todo

Para um controle mais granular, voc√™ pode aplicar @persist em m√©todos espec√≠ficos:

```python
# (O c√≥digo n√£o √© traduzido)
```

### Como Funciona

1. **Identifica√ß√£o √önica do Estado**
   * Cada estado do flow recebe automaticamente um UUID √∫nico
   * O ID √© preservado entre atualiza√ß√µes do estado e chamadas de m√©todos
   * Suporta tanto estados estruturados (Pydantic BaseModel) quanto n√£o estruturados (dicion√°rio)

2. **Backend SQLite Padr√£o**
   * O SQLiteFlowPersistence √© o backend de armazenamento padr√£o
   * Os estados s√£o salvos automaticamente em um banco de dados SQLite local
   * O tratamento de erros √© robusto, oferecendo mensagens claras caso ocorram falhas nas opera√ß√µes de banco de dados

3. **Tratamento de Erros**
   * Mensagens de erro abrangentes para opera√ß√µes de banco de dados
   * Valida√ß√£o autom√°tica do estado ao salvar e carregar
   * Feedback claro quando houver problemas de persist√™ncia

### Considera√ß√µes Importantes

* **Tipos de Estado**: S√£o suportados tanto estados estruturados (Pydantic BaseModel) quanto n√£o estruturados (dicion√°rio)
* **ID Autom√°tico**: O campo `id` √© adicionado automaticamente se n√£o estiver presente
* **Recupera√ß√£o de Estado**: Flows que falharem ou forem reiniciados podem recarregar automaticamente seu estado anterior
* **Implementa√ß√£o Personalizada**: Voc√™ pode fornecer sua pr√≥pria implementa√ß√£o de FlowPersistence para necessidades de armazenamento especializadas

### Vantagens T√©cnicas

1. **Controle Preciso Atrav√©s de Acesso de Baixo N√≠vel**
   * Acesso direto √†s opera√ß√µes de persist√™ncia para casos avan√ßados
   * Controle detalhado via decoradores de persist√™ncia no n√≠vel do m√©todo
   * Inspe√ß√£o de estado e recursos de depura√ß√£o embutidos
   * Visibilidade total das mudan√ßas e opera√ß√µes de persist√™ncia do estado

2. **Maior Confiabilidade**
   * Recupera√ß√£o autom√°tica do estado ap√≥s falhas no sistema ou reinicializa√ß√µes
   * Atualiza√ß√µes de estado baseadas em transa√ß√µes para garantir integridade dos dados
   * Mensagens de erro abrangentes e claras
   * Valida√ß√£o robusta durante opera√ß√µes de salvar e carregar estado

3. **Arquitetura Extens√≠vel**
   * Backend de persist√™ncia personaliz√°vel atrav√©s da interface FlowPersistence
   * Suporte para solu√ß√µes de armazenamento especializadas al√©m do SQLite
   * Compatibilidade tanto com estados estruturados (Pydantic) quanto n√£o estruturados (dict)
   * Integra√ß√£o perfeita com os padr√µes de flow existentes no CrewAI

A arquitetura de persist√™ncia enfatiza precis√£o t√©cnica e op√ß√µes de personaliza√ß√£o, permitindo que desenvolvedores mantenham controle total sobre o gerenciamento de estado enquanto se beneficiam dos recursos de confiabilidade integrados.

## Controle de Flow

### L√≥gica Condicional: `or`

A fun√ß√£o `or_` nos flows permite escutar m√∫ltiplos m√©todos e acionar o m√©todo ouvinte quando qualquer um dos m√©todos especificados gerar uma sa√≠da.

<CodeGroup>
  ```python Code
  # (O c√≥digo n√£o √© traduzido)
  ```

  ```text Output
  Logger: Hello from the start method
  Logger: Hello from the second method
  ```
</CodeGroup>

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-4.png)

Ao executar esse Flow, o m√©todo `logger` ser√° acionado pela sa√≠da tanto do `start_method` quanto do `second_method`.
A fun√ß√£o `or_` serve para escutar v√°rios m√©todos e disparar o m√©todo ouvinte quando qualquer um emitir um resultado.

### L√≥gica Condicional: `and`

A fun√ß√£o `and_` nos flows permite escutar m√∫ltiplos m√©todos e acionar o m√©todo ouvinte apenas quando todos os m√©todos especificados emitirem uma sa√≠da.

<CodeGroup>
  ```python Code
  # (O c√≥digo n√£o √© traduzido)
  ```

  ```text Output
  ---- Logger ----
  {'greeting': 'Hello from the start method', 'joke': 'What do computers eat? Microchips.'}
  ```
</CodeGroup>

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-5.png)

Ao executar esse Flow, o m√©todo `logger` s√≥ ser√° disparado quando ambos `start_method` e `second_method` emitirem uma sa√≠da.
A fun√ß√£o `and_` √© usada para escutar v√°rios m√©todos e acionar o m√©todo ouvinte apenas quando todas as condi√ß√µes forem atendidas.

### Router

O decorador `@router()` nos flows permite definir l√≥gica de roteamento condicional baseada na sa√≠da de um m√©todo.
Voc√™ pode especificar diferentes rotas conforme a sa√≠da do m√©todo, permitindo controlar o fluxo de execu√ß√£o de forma din√¢mica.

<CodeGroup>
  ```python Code
  # (O c√≥digo n√£o √© traduzido)
  ```

  ```text Output
  Starting the structured flow
  Third method running
  Fourth method running
  ```
</CodeGroup>

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-6.png)

No exemplo, o `start_method` gera um valor booleano aleat√≥rio e armazena no estado.
O `second_method` usa o decorador `@router()` para decidir o roteamento conforme o valor booleano.
Se o valor for `True`, retorna `"success"`, sen√£o retorna `"failed"`.
Os m√©todos `third_method` e `fourth_method` escutam a sa√≠da do `second_method` e executam com base no valor retornado.

Ao executar esse Flow, a sa√≠da ser√° diferente dependendo do valor booleano aleat√≥rio gerado pelo `start_method`.

## Adicionando Agentes aos Flows

Os agentes podem ser integrados facilmente aos seus flows, oferecendo uma alternativa leve √†s crews completas quando voc√™ precisar executar tarefas simples e focadas. Veja um exemplo de como utilizar um agente em um flow para realizar uma pesquisa de mercado:

```python
# (O c√≥digo n√£o √© traduzido)
```

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-7.png)

Esse exemplo demonstra diversos recursos fundamentais do uso de agentes em flows:

1. **Sa√≠da Estruturada**: O uso de modelos Pydantic para definir o formato esperado da sa√≠da (`MarketAnalysis`) garante seguran√ßa de tipos e dados estruturados em todo o flow.

2. **Gerenciamento de Estado**: O estado do flow (`MarketResearchState`) mant√©m o contexto entre as etapas e armazena entradas e sa√≠das.

3. **Integra√ß√£o de Ferramentas**: Os agentes podem usar ferramentas (como `WebsiteSearchTool`) para potencializar suas habilidades.

## Adicionando Crews aos Flows

Criar um flow com m√∫ltiplas crews no CrewAI √© simples.

Voc√™ pode gerar um novo projeto CrewAI que j√° inclui toda a estrutura para criar um flow com v√°rias crews executando o seguinte comando:

```bash
crewai create flow name_of_flow
```

Esse comando ir√° gerar um novo projeto CrewAI com a estrutura de pastas necess√°ria. O projeto gerado inclui uma crew pr√©-criada chamada `poem_crew`, j√° funcional. Voc√™ pode usar essa crew como modelo, copiando, colando e editando para criar outras crews.

### Estrutura de Pastas

Ap√≥s rodar o comando `crewai create flow name_of_flow`, voc√™ ver√° uma estrutura parecida com:

| Diret√≥rio/Arquivo      | Descri√ß√£o                                                  |
| :--------------------- | :--------------------------------------------------------- |
| `name_of_flow/`        | Diret√≥rio raiz do flow.                                    |
| ‚îú‚îÄ‚îÄ `crews/`           | Cont√©m diret√≥rios para crews espec√≠ficas.                  |
| ‚îÇ ‚îî‚îÄ‚îÄ `poem_crew/`     | Diret√≥rio da "poem\_crew" com configura√ß√µes e scripts.     |
| ‚îÇ ‚îú‚îÄ‚îÄ `config/`        | Arquivos de configura√ß√£o da "poem\_crew".                  |
| ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ `agents.yaml`  | YAML que define os agentes da "poem\_crew".                |
| ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ `tasks.yaml`   | YAML que define as tarefas da "poem\_crew".                |
| ‚îÇ ‚îú‚îÄ‚îÄ `poem_crew.py`   | Script da funcionalidade da "poem\_crew".                  |
| ‚îú‚îÄ‚îÄ `tools/`           | Ferramentas adicionais usadas no flow.                     |
| ‚îÇ ‚îî‚îÄ‚îÄ `custom_tool.py` | Implementa√ß√£o de ferramenta customizada.                   |
| ‚îú‚îÄ‚îÄ `main.py`          | Script principal do flow.                                  |
| ‚îú‚îÄ‚îÄ `README.md`        | Descri√ß√£o do projeto e instru√ß√µes.                         |
| ‚îú‚îÄ‚îÄ `pyproject.toml`   | Arquivo de configura√ß√µes e depend√™ncias do projeto.        |
| ‚îî‚îÄ‚îÄ `.gitignore`       | Arquivos e pastas a serem ignorados no controle de vers√£o. |

### Construindo suas Crews

Na pasta `crews`, voc√™ pode definir m√∫ltiplas crews. Cada crew tem sua pr√≥pria pasta, com arquivos de configura√ß√£o e o arquivo de defini√ß√£o da crew. Por exemplo, a pasta `poem_crew` cont√©m:

* `config/agents.yaml`: Define os agentes da crew.
* `config/tasks.yaml`: Define as tarefas da crew.
* `poem_crew.py`: Cont√©m a defini√ß√£o da crew, incluindo agentes, tarefas, etc.

Voc√™ pode copiar, colar e editar a `poem_crew` para criar outras crews.

### Conectando Crews no `main.py`

No arquivo `main.py`, voc√™ cria seu flow e conecta as crews. √â poss√≠vel definir o fluxo usando a classe `Flow` e os decoradores `@start` e `@listen` para definir a ordem de execu√ß√£o.

Veja um exemplo de como conectar a `poem_crew` no arquivo `main.py`:

```python Code
# (O c√≥digo n√£o √© traduzido)
```

Neste exemplo, a classe `PoemFlow` define um fluxo que gera a quantidade de frases, usa a `PoemCrew` para gerar um poema e, depois, salva o poema em um arquivo. O flow inicia com o m√©todo `kickoff()`, e o gr√°fico √© gerado pelo m√©todo `plot()`.

![Flow Visual image](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crewai-flow-8.png)

### Executando o Flow

(Opcional) Antes de rodar o flow, instale as depend√™ncias executando:

```bash
crewai install
```

Ap√≥s instalar as depend√™ncias, ative o ambiente virtual com:

```bash
source .venv/bin/activate
```

Com o ambiente ativado, execute o flow usando um dos comandos:

```bash
crewai flow kickoff
```

ou

```bash
uv run kickoff
```

O flow ser√° executado, e voc√™ ver√° a sa√≠da no console.

## Plotando Flows

Visualizar seus fluxos de trabalho de IA proporciona insights valiosos sobre a estrutura e os caminhos de execu√ß√£o dos flows. O CrewAI oferece uma ferramenta de visualiza√ß√£o poderosa que permite gerar plots interativos dos flows, facilitando o entendimento e a otimiza√ß√£o dos workflows de IA.

### O que s√£o Plots?

No CrewAI, plots s√£o representa√ß√µes gr√°ficas dos fluxos de trabalho de IA. Eles mostram as tarefas, suas conex√µes e o fluxo de dados entre elas. Essa visualiza√ß√£o ajuda a compreender a sequ√™ncia de opera√ß√µes, identificar gargalos e garantir que a l√≥gica do workflow est√° alinhada com o esperado.

### Como Gerar um Plot

O CrewAI oferece duas formas pr√°ticas de gerar plots dos seus flows:

#### Op√ß√£o 1: Usando o m√©todo `plot()`

Se estiver trabalhando diretamente com uma inst√¢ncia do flow, basta chamar o m√©todo `plot()` do objeto. Isso criar√° um arquivo HTML com o plot interativo do seu flow.

```python Code
# (O c√≥digo n√£o √© traduzido)
```

Esse comando gera um arquivo chamado `my_flow_plot.html` no diret√≥rio atual. Abra esse arquivo em um navegador para visualizar o plot interativo.

#### Op√ß√£o 2: Usando a Linha de Comando

Em projetos CrewAI estruturados, √© poss√≠vel gerar um plot pela linha de comando. Isso √© √∫til para projetos maiores, onde voc√™ deseja visualizar toda a configura√ß√£o do flow.

```bash
crewai flow plot
```

O comando gera um arquivo HTML com o plot do flow, semelhante ao m√©todo `plot()`. Basta abrir o arquivo no navegador para explorar o workflow.

### Entendendo o Plot

O plot gerado mostra n√≥s representando as tarefas do seu flow, com setas indicando o fluxo de execu√ß√£o. A visualiza√ß√£o √© interativa, permitindo zoom, navega√ß√£o e detalhes ao passar o mouse nos n√≥s.

Ao visualizar seus flows, voc√™ tem clareza do formato do workflow, facilitando debug, otimiza√ß√£o e comunica√ß√£o dos seus processos de IA para outras pessoas.

### Conclus√£o

A plotagem dos flows √© um recurso poderoso do CrewAI para aprimorar o design e o gerenciamento de fluxos de IA complexos. Usando o m√©todo `plot()` ou a linha de comando, voc√™ obt√©m uma vis√£o visual dos workflows, benef√≠cio tanto para desenvolvimento quanto para apresenta√ß√£o.

## Pr√≥ximos Passos

Se voc√™ deseja explorar exemplos adicionais de flows, acompanhe alguns exemplos em nosso reposit√≥rio de exemplos. Aqui est√£o quatro sugest√µes espec√≠ficas de flows, cada uma demonstrando casos de uso distintos para voc√™ escolher conforme seu problema:

1. **Email Auto Responder Flow**: Este exemplo demonstra um loop infinito, onde um job de background roda continuamente automatizando respostas de email. √â ideal para tarefas rotineiras sem interven√ß√£o manual. [Ver Exemplo](https://github.com/crewAIInc/crewAI-examples/tree/main/email_auto_responder_flow)

2. **Lead Score Flow**: Destaca como adicionar feedback humano e manipular diferentes ramos condicionais usando router. Um √≥timo aprendizado para workflows com decis√£o din√¢mica e supervis√£o humana. [Ver Exemplo](https://github.com/crewAIInc/crewAI-examples/tree/main/lead-score-flow)

3. **Write a Book Flow**: Exemplo ideal para encadear m√∫ltiplas crews, onde a sa√≠da de uma √© usada por outra. Uma crew faz um sum√°rio do livro inteiro, outra gera cap√≠tulos... Tudo conectado para entregar um livro completo. Perfeito para processos longos e coordenados. [Ver Exemplo](https://github.com/crewAIInc/crewAI-examples/tree/main/write_a_book_with_flows)

4. **Meeting Assistant Flow**: Demonstra como transmitir um evento para desencadear m√∫ltiplas a√ß√µes posteriores. Exemplo: ao finalizar uma reuni√£o, atualizar um Trello, enviar mensagem no Slack e salvar resultados ao mesmo tempo. Indicado para gerenciamento completo de tarefas e notifica√ß√µes. [Ver Exemplo](https://github.com/crewAIInc/crewAI-examples/tree/main/meeting_assistant_flow)

Explore esses exemplos para descobrir como aproveitar CrewAI Flows em diferentes contextos ‚Äì desde automa√ß√£o de tarefas repetitivas at√© o gerenciamento de processos din√¢micos com decis√µes e feedback humano.

Al√©m disso, confira nosso v√≠deo no YouTube sobre como utilizar flows no CrewAI abaixo!

<iframe width="560" height="315" src="https://www.youtube.com/embed/MTb5my6VOT8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen />

## Executando Flows

Existem duas formas de executar um flow:

### Usando a API do Flow

Voc√™ pode executar um flow programaticamente criando uma inst√¢ncia da sua classe de flow e chamando o m√©todo `kickoff()`:

```python
# Exemplo de execu√ß√£o de flow em portugu√™s
flow = ExemploFlow()
resultado = flow.kickoff()
```

### Usando a CLI

A partir da vers√£o 0.103.0, √© poss√≠vel executar flows usando o comando `crewai run`:

```shell
crewai run
```

O comando detecta automaticamente se seu projeto √© um flow (com base na configura√ß√£o `type = "flow"` no pyproject.toml) e executa conforme o esperado. Esse √© o m√©todo recomendado para executar flows pelo terminal.

Por compatibilidade retroativa, tamb√©m √© poss√≠vel usar:

```shell
crewai flow kickoff
```

No entanto, o comando `crewai run` √© agora o preferido, pois funciona tanto para crews quanto para flows.


# Knowledge
Source: https://docs.crewai.com/pt-BR/concepts/knowledge

O que √© knowledge em CrewAI e como us√°-lo.

## Vis√£o Geral

Knowledge no CrewAI √© um sistema poderoso que permite que agentes de IA acessem e utilizem fontes de informa√ß√£o externas durante suas tarefas.
Pense nisso como dar aos seus agentes uma biblioteca de refer√™ncia que eles podem consultar enquanto trabalham.

<Info>
  Principais benef√≠cios de usar Knowledge:

  * Aprimorar agentes com informa√ß√µes espec√≠ficas do dom√≠nio
  * Apoiar decis√µes com dados do mundo real
  * Manter contexto entre conversas
  * Fundamentar respostas em informa√ß√µes factuais
</Info>

## Exemplos de In√≠cio R√°pido

<Tip>
  Para Fontes de Knowledge baseadas em arquivos, certifique-se de colocar seus arquivos em um diret√≥rio `knowledge` na raiz do seu projeto.
  Al√©m disso, use caminhos relativos do diret√≥rio `knowledge` ao criar a fonte.
</Tip>

### Exemplo B√°sico de Knowledge com String

```python Code
from crewai import Agent, Task, Crew, Process, LLM
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# Create a knowledge source
content = "Users name is John. He is 30 years old and lives in San Francisco."
string_source = StringKnowledgeSource(content=content)

# Create an LLM with a temperature of 0 to ensure deterministic outputs
llm = LLM(model="gpt-4o-mini", temperature=0)

# Create an agent with the knowledge store
agent = Agent(
    role="Sobre o Usu√°rio",
    goal="Voc√™ sabe tudo sobre o usu√°rio.",
    backstory="Voc√™ √© mestre em entender pessoas e suas prefer√™ncias.",
    verbose=True,
    allow_delegation=False,
    llm=llm,
)

task = Task(
    description="Responda √†s seguintes perguntas sobre o usu√°rio: {question}",
    expected_output="Uma resposta para a pergunta.",
    agent=agent,
)

crew = Crew(
    agents=[agent],
    tasks=[task],
    verbose=True,
    process=Process.sequential,
    knowledge_sources=[string_source], # Enable knowledge by adding the sources here
)

result = crew.kickoff(inputs={"question": "What city does John live in and how old is he?"})
```

### Exemplo de Knowledge com Conte√∫do Web

<Note>
  Voc√™ precisa instalar `docling` para o seguinte exemplo funcionar: `uv add docling`
</Note>

```python Code
from crewai import LLM, Agent, Crew, Process, Task
from crewai.knowledge.source.crew_docling_source import CrewDoclingSource

# Create a knowledge source from web content
content_source = CrewDoclingSource(
    file_paths=[
        "https://lilianweng.github.io/posts/2024-11-28-reward-hacking",
        "https://lilianweng.github.io/posts/2024-07-07-hallucination",
    ],
)

# Create an LLM with a temperature of 0 to ensure deterministic outputs
llm = LLM(model="gpt-4o-mini", temperature=0)

# Create an agent with the knowledge store
agent = Agent(
    role="Sobre artigos",
    goal="Voc√™ sabe tudo sobre os artigos.",
    backstory="Voc√™ √© mestre em entender artigos e seus conte√∫dos.",
    verbose=True,
    allow_delegation=False,
    llm=llm,
)

task = Task(
    description="Responda √†s seguintes perguntas sobre os artigos: {question}",
    expected_output="Uma resposta para a pergunta.",
    agent=agent,
)

crew = Crew(
    agents=[agent],
    tasks=[task],
    verbose=True,
    process=Process.sequential,
    knowledge_sources=[content_source],
)

result = crew.kickoff(
    inputs={"question": "What is the reward hacking paper about? Be sure to provide sources."}
)
```

## Fontes de Knowledge Suportadas

O CrewAI suporta v√°rios tipos de fontes de knowledge prontas para uso:

<CardGroup cols={2}>
  <Card title="Fontes de Texto" icon="text">
    * Strings brutas
    * Arquivos de texto (.txt)
    * Documentos PDF
  </Card>

  <Card title="Dados Estruturados" icon="table">
    * Arquivos CSV
    * Planilhas Excel
    * Documentos JSON
  </Card>
</CardGroup>

### Fonte de Knowledge de Arquivo de Texto

```python
from crewai.knowledge.source.text_file_knowledge_source import TextFileKnowledgeSource

text_source = TextFileKnowledgeSource(
    file_paths=["document.txt", "another.txt"]
)
```

### Fonte de Knowledge PDF

```python
from crewai.knowledge.source.pdf_knowledge_source import PDFKnowledgeSource

pdf_source = PDFKnowledgeSource(
    file_paths=["document.pdf", "another.pdf"]
)
```

### Fonte de Knowledge CSV

```python
from crewai.knowledge.source.csv_knowledge_source import CSVKnowledgeSource

csv_source = CSVKnowledgeSource(
    file_paths=["data.csv"]
)
```

### Fonte de Knowledge Excel

```python
from crewai.knowledge.source.excel_knowledge_source import ExcelKnowledgeSource

excel_source = ExcelKnowledgeSource(
    file_paths=["spreadsheet.xlsx"]
)
```

### Fonte de Knowledge JSON

```python
from crewai.knowledge.source.json_knowledge_source import JSONKnowledgeSource

json_source = JSONKnowledgeSource(
    file_paths=["data.json"]
)
```

<Note>
  Certifique-se de criar a pasta ./knowledge. Todos os arquivos de origem (ex: .txt, .pdf, .xlsx, .json) devem ser colocados nesta pasta para gerenciamento centralizado.
</Note>

## Knowledge de Agente vs Crew: Guia Completo

<Info>
  **Entendendo os N√≠veis de Knowledge**: O CrewAI suporta knowledge tanto no n√≠vel de agente quanto de crew. Esta se√ß√£o esclarece exatamente como cada um funciona, quando s√£o inicializados, e aborda equ√≠vocos comuns sobre depend√™ncias.
</Info>

### Como a Inicializa√ß√£o de Knowledge Realmente Funciona

Aqui est√° exatamente o que acontece quando voc√™ usa knowledge:

#### Knowledge no N√≠vel do Agente (Independente)

```python
from crewai import Agent, Task, Crew
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# Agent with its own knowledge - NO crew knowledge needed
specialist_knowledge = StringKnowledgeSource(
    content="Specialized technical information for this agent only"
)

specialist_agent = Agent(
    role="Especialista T√©cnico",
    goal="Fornecer expertise t√©cnica",
    backstory="Especialista em dom√≠nios t√©cnicos especializados",
    knowledge_sources=[specialist_knowledge]  # Conhecimento espec√≠fico do agente
)

task = Task(
    description="Responda perguntas t√©cnicas",
    agent=specialist_agent,
    expected_output="Resposta t√©cnica"
)

# No crew-level knowledge required
crew = Crew(
    agents=[specialist_agent],
    tasks=[task]
)

result = crew.kickoff()  # Agent knowledge works independently
```

#### O Que Acontece Durante `crew.kickoff()`

Quando voc√™ chama `crew.kickoff()`, aqui est√° a sequ√™ncia exata:

```python
# During kickoff
for agent in self.agents:
    agent.crew = self  # Agent gets reference to crew
    agent.set_knowledge(crew_embedder=self.embedder)  # Agent knowledge initialized
    agent.create_agent_executor()
```

#### Independ√™ncia de Armazenamento

Cada n√≠vel de knowledge usa cole√ß√µes de armazenamento independentes:

```python
# Agent knowledge storage
agent_collection_name = agent.role  # e.g., "Especialista T√©cnico"

# Crew knowledge storage
crew_collection_name = "crew"

# Both stored in same ChromaDB instance but different collections
# Path: ~/.local/share/CrewAI/{project}/knowledge/
#   ‚îú‚îÄ‚îÄ crew/                    # Crew knowledge collection
#   ‚îú‚îÄ‚îÄ Especialista T√©cnico/    # Agent knowledge collection
#   ‚îî‚îÄ‚îÄ Another Agent Role/      # Another agent's collection
```

### Exemplos Completos Funcionais

#### Exemplo 1: Knowledge Apenas do Agente

```python
from crewai import Agent, Task, Crew
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# Agent-specific knowledge
agent_knowledge = StringKnowledgeSource(
    content="Agent-specific information that only this agent needs"
)

agent = Agent(
    role="Especialista",
    goal="Use specialized knowledge",
    backstory="Expert with specific knowledge",
    knowledge_sources=[agent_knowledge],
    embedder={  # Agent can have its own embedder
        "provider": "openai",
        "config": {"model": "text-embedding-3-small"}
    }
)

task = Task(
    description="Answer using your specialized knowledge",
    agent=agent,
    expected_output="Answer based on agent knowledge"
)

# No crew knowledge needed
crew = Crew(agents=[agent], tasks=[task])
result = crew.kickoff()  # Works perfectly
```

#### Exemplo 2: Knowledge Tanto do Agente Quanto da Crew

```python
# Crew-wide knowledge (shared by all agents)
crew_knowledge = StringKnowledgeSource(
    content="Company policies and general information for all agents"
)

# Agent-specific knowledge
specialist_knowledge = StringKnowledgeSource(
    content="Technical specifications only the specialist needs"
)

specialist = Agent(
    role="Especialista T√©cnico",
    goal="Fornecer expertise t√©cnica",
    backstory="Especialista em dom√≠nios t√©cnicos especializados",
    knowledge_sources=[specialist_knowledge]  # Conhecimento espec√≠fico do agente
)

generalist = Agent(
    role="General Assistant",
    goal="Provide general assistance",
    backstory="General helper"
    # No agent-specific knowledge
)

crew = Crew(
    agents=[specialist, generalist],
    tasks=[...],
    knowledge_sources=[crew_knowledge]  # Crew-wide knowledge
)

# Result:
# - specialist gets: crew_knowledge + specialist_knowledge
# - generalist gets: crew_knowledge only
```

#### Exemplo 3: M√∫ltiplos Agentes com Knowledge Diferente

```python
# Different knowledge for different agents
sales_knowledge = StringKnowledgeSource(content="Sales procedures and pricing")
tech_knowledge = StringKnowledgeSource(content="Technical documentation")
support_knowledge = StringKnowledgeSource(content="Support procedures")

sales_agent = Agent(
    role="Sales Representative",
    knowledge_sources=[sales_knowledge],
    embedder={"provider": "openai", "config": {"model": "text-embedding-3-small"}}
)

tech_agent = Agent(
    role="Technical Expert",
    knowledge_sources=[tech_knowledge],
    embedder={"provider": "ollama", "config": {"model": "mxbai-embed-large"}}
)

support_agent = Agent(
    role="Support Specialist",
    knowledge_sources=[support_knowledge]
    # Will use crew embedder as fallback
)

crew = Crew(
    agents=[sales_agent, tech_agent, support_agent],
    tasks=[...],
    embedder={  # Fallback embedder for agents without their own
        "provider": "google",
        "config": {"model": "text-embedding-004"}
    }
)

# Each agent gets only their specific knowledge
# Each can use different embedding providers
```

<Tip>
  Diferente da recupera√ß√£o de um banco de dados vetorial usando uma ferramenta, agentes pr√©-carregados com knowledge n√£o precisar√£o de uma persona de recupera√ß√£o ou tarefa.
  Simplesmente adicione as fontes de knowledge relevantes que seu agente ou crew precisa para funcionar.

  As fontes de knowledge podem ser adicionadas no n√≠vel do agente ou da crew.
  As fontes de knowledge no n√≠vel da crew ser√£o usadas por **todos os agentes** na crew.
  As fontes de knowledge no n√≠vel do agente ser√£o usadas pelo **agente espec√≠fico** que √© pr√©-carregado com o knowledge.
</Tip>

## Configura√ß√£o de Knowledge

Voc√™ pode configurar a configura√ß√£o de knowledge para a crew ou agente.

```python Code
from crewai.knowledge.knowledge_config import KnowledgeConfig

knowledge_config = KnowledgeConfig(results_limit=10, score_threshold=0.5)

agent = Agent(
    ...
    knowledge_config=knowledge_config
)
```

<Tip>
  `results_limit`: √© o n√∫mero de documentos relevantes a retornar. Padr√£o √© 3.
  `score_threshold`: √© a pontua√ß√£o m√≠nima para um documento ser considerado relevante. Padr√£o √© 0.35.
</Tip>

## Par√¢metros de Knowledge Suportados

<ParamField body="sources" type="List[BaseKnowledgeSource]" required="Yes">
  Lista de fontes de knowledge que fornecem conte√∫do para ser armazenado e consultado. Pode incluir PDF, CSV, Excel, JSON, arquivos de texto ou conte√∫do de string.
</ParamField>

<ParamField body="collection_name" type="str">
  Nome da cole√ß√£o onde o knowledge ser√° armazenado. Usado para identificar diferentes conjuntos de knowledge. Padr√£o √© "knowledge" se n√£o fornecido.
</ParamField>

<ParamField body="storage" type="Optional[KnowledgeStorage]">
  Configura√ß√£o de armazenamento personalizada para gerenciar como o knowledge √© armazenado e recuperado. Se n√£o fornecido, um armazenamento padr√£o ser√° criado.
</ParamField>

## Transpar√™ncia do Armazenamento de Knowledge

<Info>
  **Entendendo o Armazenamento de Knowledge**: O CrewAI armazena automaticamente as fontes de knowledge em diret√≥rios espec√≠ficos da plataforma usando ChromaDB para armazenamento vetorial. Entender essas localiza√ß√µes e padr√µes ajuda com implanta√ß√µes de produ√ß√£o, depura√ß√£o e gerenciamento de armazenamento.
</Info>

### Onde o CrewAI Armazena Arquivos de Knowledge

Por padr√£o, o CrewAI usa o mesmo sistema de armazenamento que a mem√≥ria, armazenando knowledge em diret√≥rios espec√≠ficos da plataforma:

#### Localiza√ß√µes de Armazenamento Padr√£o por Plataforma

**macOS:**

```
~/Library/Application Support/CrewAI/{project_name}/
‚îî‚îÄ‚îÄ knowledge/                    # Knowledge ChromaDB files
    ‚îú‚îÄ‚îÄ chroma.sqlite3           # ChromaDB metadata
    ‚îú‚îÄ‚îÄ {collection_id}/         # Vector embeddings
    ‚îî‚îÄ‚îÄ knowledge_{collection}/  # Named collections
```

**Linux:**

```
~/.local/share/CrewAI/{project_name}/
‚îî‚îÄ‚îÄ knowledge/
    ‚îú‚îÄ‚îÄ chroma.sqlite3
    ‚îú‚îÄ‚îÄ {collection_id}/
    ‚îî‚îÄ‚îÄ knowledge_{collection}/
```

**Windows:**

```
C:\Users\{username}\AppData\Local\CrewAI\{project_name}\
‚îî‚îÄ‚îÄ knowledge\
    ‚îú‚îÄ‚îÄ chroma.sqlite3
    ‚îú‚îÄ‚îÄ {collection_id}\
    ‚îî‚îÄ‚îÄ knowledge_{collection}\
```

### Encontrando Sua Localiza√ß√£o de Armazenamento de Knowledge

Para ver exatamente onde o CrewAI est√° armazenando seus arquivos de knowledge:

```python
from crewai.utilities.paths import db_storage_path
import os

# Get the knowledge storage path
knowledge_path = os.path.join(db_storage_path(), "knowledge")
print(f"Knowledge storage location: {knowledge_path}")

# List knowledge collections and files
if os.path.exists(knowledge_path):
    print("\nKnowledge storage contents:")
    for item in os.listdir(knowledge_path):
        item_path = os.path.join(knowledge_path, item)
        if os.path.isdir(item_path):
            print(f"üìÅ Collection: {item}/")
            # Show collection contents
            try:
                for subitem in os.listdir(item_path):
                    print(f"   ‚îî‚îÄ‚îÄ {subitem}")
            except PermissionError:
                print(f"   ‚îî‚îÄ‚îÄ (permission denied)")
        else:
            print(f"üìÑ {item}")
else:
    print("No knowledge storage found yet.")
```

### Controlando Localiza√ß√µes de Armazenamento de Knowledge

#### Op√ß√£o 1: Vari√°vel de Ambiente (Recomendado)

```python
import os
from crewai import Crew

# Set custom storage location for all CrewAI data
os.environ["CREWAI_STORAGE_DIR"] = "./my_project_storage"

# All knowledge will now be stored in ./my_project_storage/knowledge/
crew = Crew(
    agents=[...],
    tasks=[...],
    knowledge_sources=[...]
)
```

#### Op√ß√£o 2: Armazenamento de Knowledge Personalizado

```python
from crewai.knowledge.storage.knowledge_storage import KnowledgeStorage
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# Create custom storage with specific embedder
custom_storage = KnowledgeStorage(
    embedder={
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    },
    collection_name="my_custom_knowledge"
)

# Use with knowledge sources
knowledge_source = StringKnowledgeSource(
    content="Your knowledge content here"
)
knowledge_source.storage = custom_storage
```

#### Op√ß√£o 3: Armazenamento de Knowledge Espec√≠fico do Projeto

```python
import os
from pathlib import Path

# Store knowledge in project directory
project_root = Path(__file__).parent
knowledge_dir = project_root / "knowledge_storage"

os.environ["CREWAI_STORAGE_DIR"] = str(knowledge_dir)

# Now all knowledge will be stored in your project directory
```

### Comportamento Padr√£o do Provedor de Embedding

<Info>
  **Provedor de Embedding Padr√£o**: O CrewAI usa por padr√£o embeddings da OpenAI (`text-embedding-3-small`) para armazenamento de knowledge, mesmo quando usa diferentes provedores de LLM. Voc√™ pode facilmente personalizar isso para corresponder √† sua configura√ß√£o.
</Info>

#### Entendendo o Comportamento Padr√£o

```python
from crewai import Agent, Crew, LLM
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# When using Claude as your LLM...
agent = Agent(
    role="Researcher",
    goal="Research topics",
    backstory="Expert researcher",
    llm=LLM(provider="anthropic", model="claude-3-sonnet")  # Using Claude
)

# CrewAI will still use OpenAI embeddings by default for knowledge
# This ensures consistency but may not match your LLM provider preference
knowledge_source = StringKnowledgeSource(content="Research data...")

crew = Crew(
    agents=[agent],
    tasks=[...],
    knowledge_sources=[knowledge_source]
    # Default: Uses OpenAI embeddings even with Claude LLM
)
```

#### Personalizando Provedores de Embedding de Knowledge

```python
# Option 1: Use Voyage AI (recommended by Anthropic for Claude users)
crew = Crew(
    agents=[agent],
    tasks=[...],
    knowledge_sources=[knowledge_source],
    embedder={
        "provider": "voyageai",  # Recommended for Claude users
        "config": {
            "api_key": "your-voyage-api-key",
            "model": "voyage-3"  # or "voyage-3-large" for best quality
        }
    }
)

# Option 2: Use local embeddings (no external API calls)
crew = Crew(
    agents=[agent],
    tasks=[...],
    knowledge_sources=[knowledge_source],
    embedder={
        "provider": "ollama",
        "config": {
            "model": "mxbai-embed-large",
            "url": "http://localhost:11434/api/embeddings"
        }
    }
)

# Option 3: Agent-level embedding customization
agent = Agent(
    role="Researcher",
    goal="Research topics",
    backstory="Expert researcher",
    knowledge_sources=[knowledge_source],
    embedder={
        "provider": "google",
        "config": {
            "model": "models/text-embedding-004",
            "api_key": "your-google-key"
        }
    }
)
```

#### Configurando Embeddings do Azure OpenAI

Ao usar embeddings do Azure OpenAI:

1. Certifique-se de implantar o modelo de embedding na plataforma Azure primeiro
2. Ent√£o voc√™ precisa usar a seguinte configura√ß√£o:

```python
agent = Agent(
    role="Researcher",
    goal="Research topics",
    backstory="Expert researcher",
    knowledge_sources=[knowledge_source],
    embedder={
        "provider": "azure",
        "config": {
            "api_key": "your-azure-api-key",
            "model": "text-embedding-ada-002", # change to the model you are using and is deployed in Azure
            "api_base": "https://your-azure-endpoint.openai.azure.com/",
            "api_version": "2024-02-01"
        }
    }
)
```

## Recursos Avan√ßados

### Reescrita de Consulta

O CrewAI implementa um mecanismo inteligente de reescrita de consulta para otimizar a recupera√ß√£o de knowledge. Quando um agente precisa pesquisar nas fontes de knowledge, o prompt da tarefa bruto √© automaticamente transformado em uma consulta de pesquisa mais eficaz.

#### Como a Reescrita de Consulta Funciona

1. Quando um agente executa uma tarefa com fontes de knowledge dispon√≠veis, o m√©todo `_get_knowledge_search_query` √© acionado
2. O LLM do agente √© usado para transformar o prompt original da tarefa em uma consulta de pesquisa otimizada
3. Esta consulta otimizada √© ent√£o usada para recuperar informa√ß√µes relevantes das fontes de knowledge

#### Benef√≠cios da Reescrita de Consulta

<CardGroup cols={2}>
  <Card title="Precis√£o de Recupera√ß√£o Melhorada" icon="bullseye-arrow">
    Ao focar em conceitos-chave e remover conte√∫do irrelevante, a reescrita de consulta ajuda a recuperar informa√ß√µes mais relevantes.
  </Card>

  <Card title="Consci√™ncia de Contexto" icon="brain">
    As consultas reescritas s√£o projetadas para ser mais espec√≠ficas e conscientes do contexto para recupera√ß√£o de banco de dados vetorial.
  </Card>
</CardGroup>

#### Exemplo

```python
# Original task prompt
task_prompt = "Answer the following questions about the user's favorite movies: What movie did John watch last week? Format your answer in JSON."

# Behind the scenes, this might be rewritten as:
rewritten_query = "What movies did John watch last week?"
```

A consulta reescrita √© mais focada na necessidade de informa√ß√£o principal e remove instru√ß√µes irrelevantes sobre formata√ß√£o de sa√≠da.

<Tip>
  Este mecanismo √© totalmente autom√°tico e n√£o requer configura√ß√£o dos usu√°rios. O LLM do agente √© usado para realizar a reescrita da consulta, ent√£o usar um LLM mais capaz pode melhorar a qualidade das consultas reescritas.
</Tip>

### Eventos de Knowledge

O CrewAI emite eventos durante o processo de recupera√ß√£o de knowledge que voc√™ pode escutar usando o sistema de eventos. Esses eventos permitem que voc√™ monitore, depure e analise como o knowledge est√° sendo recuperado e usado pelos seus agentes.

#### Eventos de Knowledge Dispon√≠veis

* **KnowledgeRetrievalStartedEvent**: Emitido quando um agente come√ßa a recuperar knowledge das fontes
* **KnowledgeRetrievalCompletedEvent**: Emitido quando a recupera√ß√£o de knowledge √© conclu√≠da, incluindo a consulta usada e o conte√∫do recuperado
* **KnowledgeQueryStartedEvent**: Emitido quando uma consulta √†s fontes de knowledge come√ßa
* **KnowledgeQueryCompletedEvent**: Emitido quando uma consulta √© conclu√≠da com sucesso
* **KnowledgeQueryFailedEvent**: Emitido quando uma consulta √†s fontes de knowledge falha
* **KnowledgeSearchQueryFailedEvent**: Emitido quando uma consulta de pesquisa falha

#### Exemplo: Monitorando Recupera√ß√£o de Knowledge

```python
from crewai.utilities.events import (
    KnowledgeRetrievalStartedEvent,
    KnowledgeRetrievalCompletedEvent,
)
from crewai.utilities.events.base_event_listener import BaseEventListener

class KnowledgeMonitorListener(BaseEventListener):
    def setup_listeners(self, crewai_event_bus):
        @crewai_event_bus.on(KnowledgeRetrievalStartedEvent)
        def on_knowledge_retrieval_started(source, event):
            print(f"Agent '{event.agent.role}' started retrieving knowledge")

        @crewai_event_bus.on(KnowledgeRetrievalCompletedEvent)
        def on_knowledge_retrieval_completed(source, event):
            print(f"Agent '{event.agent.role}' completed knowledge retrieval")
            print(f"Query: {event.query}")
            print(f"Retrieved {len(event.retrieved_knowledge)} knowledge chunks")

# Create an instance of your listener
knowledge_monitor = KnowledgeMonitorListener()
```

Para mais informa√ß√µes sobre como usar eventos, consulte a documenta√ß√£o [Event Listeners](https://docs.crewai.com/concepts/event-listener).

### Fontes de Knowledge Personalizadas

O CrewAI permite que voc√™ crie fontes de knowledge personalizadas para qualquer tipo de dados estendendo a classe `BaseKnowledgeSource`. Vamos criar um exemplo pr√°tico que busca e processa artigos de not√≠cias espaciais.

#### Exemplo de Fonte de Knowledge de Not√≠cias Espaciais

<CodeGroup>
  ```python Code
  from crewai import Agent, Task, Crew, Process, LLM
  from crewai.knowledge.source.base_knowledge_source import BaseKnowledgeSource
  import requests
  from datetime import datetime
  from typing import Dict, Any
  from pydantic import BaseModel, Field

  class SpaceNewsKnowledgeSource(BaseKnowledgeSource):
      """Knowledge source that fetches data from Space News API."""

      api_endpoint: str = Field(description="API endpoint URL")
      limit: int = Field(default=10, description="Number of articles to fetch")

      def load_content(self) -> Dict[Any, str]:
          """Fetch and format space news articles."""
          try:
              response = requests.get(
                  f"{self.api_endpoint}?limit={self.limit}"
              )
              response.raise_for_status()

              data = response.json()
              articles = data.get('results', [])

              formatted_data = self.validate_content(articles)
              return {self.api_endpoint: formatted_data}
          except Exception as e:
              raise ValueError(f"Failed to fetch space news: {str(e)}")

      def validate_content(self, articles: list) -> str:
          """Format articles into readable text."""
          formatted = "Space News Articles:\n\n"
          for article in articles:
              formatted += f"""
                  Title: {article['title']}
                  Published: {article['published_at']}
                  Summary: {article['summary']}
                  News Site: {article['news_site']}
                  URL: {article['url']}
                  -------------------"""
          return formatted

      def add(self) -> None:
          """Process and store the articles."""
          content = self.load_content()
          for _, text in content.items():
              chunks = self._chunk_text(text)
              self.chunks.extend(chunks)

          self._save_documents()

  # Create knowledge source
  recent_news = SpaceNewsKnowledgeSource(
      api_endpoint="https://api.spaceflightnewsapi.net/v4/articles",
      limit=10,
  )

  # Create specialized agent
  space_analyst = Agent(
      role="Space News Analyst",
      goal="Answer questions about space news accurately and comprehensively",
      backstory="""You are a space industry analyst with expertise in space exploration,
      satellite technology, and space industry trends. You excel at answering questions
      about space news and providing detailed, accurate information.""",
      knowledge_sources=[recent_news],
      llm=LLM(model="gpt-4", temperature=0.0)
  )

  # Create task that handles user questions
  analysis_task = Task(
      description="Answer this question about space news: {user_question}",
      expected_output="A detailed answer based on the recent space news articles",
      agent=space_analyst
  )

  # Create and run the crew
  crew = Crew(
      agents=[space_analyst],
      tasks=[analysis_task],
      verbose=True,
      process=Process.sequential
  )

  # Example usage
  result = crew.kickoff(
      inputs={"user_question": "What are the latest developments in space exploration?"}
  )
  ```

  ```output Output
  # Agent: Space News Analyst
  ## Task: Answer this question about space news: What are the latest developments in space exploration?


  # Agent: Space News Analyst
  ## Final Answer:
  The latest developments in space exploration, based on recent space news articles, include the following:

  1. SpaceX has received the final regulatory approvals to proceed with the second integrated Starship/Super Heavy launch, scheduled for as soon as the morning of Nov. 17, 2023. This is a significant step in SpaceX's ambitious plans for space exploration and colonization. [Source: SpaceNews](https://spacenews.com/starship-cleared-for-nov-17-launch/)

  2. SpaceX has also informed the US Federal Communications Commission (FCC) that it plans to begin launching its first next-generation Starlink Gen2 satellites. This represents a major upgrade to the Starlink satellite internet service, which aims to provide high-speed internet access worldwide. [Source: Teslarati](https://www.teslarati.com/spacex-first-starlink-gen2-satellite-launch-2022/)

  3. AI startup Synthetaic has raised $15 million in Series B funding. The company uses artificial intelligence to analyze data from space and air sensors, which could have significant applications in space exploration and satellite technology. [Source: SpaceNews](https://spacenews.com/ai-startup-synthetaic-raises-15-million-in-series-b-funding/)

  4. The Space Force has formally established a unit within the U.S. Indo-Pacific Command, marking a permanent presence in the Indo-Pacific region. This could have significant implications for space security and geopolitics. [Source: SpaceNews](https://spacenews.com/space-force-establishes-permanent-presence-in-indo-pacific-region/)

  5. Slingshot Aerospace, a space tracking and data analytics company, is expanding its network of ground-based optical telescopes to increase coverage of low Earth orbit. This could improve our ability to track and analyze objects in low Earth orbit, including satellites and space debris. [Source: SpaceNews](https://spacenews.com/slingshots-space-tracking-network-to-extend-coverage-of-low-earth-orbit/)

  6. The National Natural Science Foundation of China has outlined a five-year project for researchers to study the assembly of ultra-large spacecraft. This could lead to significant advancements in spacecraft technology and space exploration capabilities. [Source: SpaceNews](https://spacenews.com/china-researching-challenges-of-kilometer-scale-ultra-large-spacecraft/)

  7. The Center for AEroSpace Autonomy Research (CAESAR) at Stanford University is focusing on spacecraft autonomy. The center held a kickoff event on May 22, 2024, to highlight the industry, academia, and government collaboration it seeks to foster. This could lead to significant advancements in autonomous spacecraft technology. [Source: SpaceNews](https://spacenews.com/stanford-center-focuses-on-spacecraft-autonomy/)
  ```
</CodeGroup>

## Depura√ß√£o e Solu√ß√£o de Problemas

### Depurando Problemas de Knowledge

#### Verificar Inicializa√ß√£o de Knowledge do Agente

```python
from crewai import Agent, Crew, Task
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

knowledge_source = StringKnowledgeSource(content="Test knowledge")

agent = Agent(
    role="Test Agent",
    goal="Test knowledge",
    backstory="Testing",
    knowledge_sources=[knowledge_source]
)

crew = Crew(agents=[agent], tasks=[Task(...)])

# Before kickoff - knowledge not initialized
print(f"Before kickoff - Agent knowledge: {getattr(agent, 'knowledge', None)}")

crew.kickoff()

# After kickoff - knowledge initialized
print(f"After kickoff - Agent knowledge: {agent.knowledge}")
print(f"Agent knowledge collection: {agent.knowledge.storage.collection_name}")
print(f"Number of sources: {len(agent.knowledge.sources)}")
```

#### Verificar Localiza√ß√µes de Armazenamento de Knowledge

```python
import os
from crewai.utilities.paths import db_storage_path

# Check storage structure
storage_path = db_storage_path()
knowledge_path = os.path.join(storage_path, "knowledge")

if os.path.exists(knowledge_path):
    print("Knowledge collections found:")
    for collection in os.listdir(knowledge_path):
        collection_path = os.path.join(knowledge_path, collection)
        if os.path.isdir(collection_path):
            print(f"  - {collection}/")
            # Show collection contents
            for item in os.listdir(collection_path):
                print(f"    ‚îî‚îÄ‚îÄ {item}")
```

#### Testar Recupera√ß√£o de Knowledge

```python
# Test agent knowledge retrieval
if hasattr(agent, 'knowledge') and agent.knowledge:
    test_query = ["test query"]
    results = agent.knowledge.query(test_query)
    print(f"Agent knowledge results: {len(results)} documents found")

    # Test crew knowledge retrieval (if exists)
    if hasattr(crew, 'knowledge') and crew.knowledge:
        crew_results = crew.query_knowledge(test_query)
        print(f"Crew knowledge results: {len(crew_results)} documents found")
```

#### Inspecionar Cole√ß√µes de Knowledge

```python
import chromadb
from crewai.utilities.paths import db_storage_path
import os

# Connect to CrewAI's knowledge ChromaDB
knowledge_path = os.path.join(db_storage_path(), "knowledge")

if os.path.exists(knowledge_path):
    client = chromadb.PersistentClient(path=knowledge_path)
    collections = client.list_collections()

    print("Knowledge Collections:")
    for collection in collections:
        print(f"  - {collection.name}: {collection.count()} documents")

        # Sample a few documents to verify content
        if collection.count() > 0:
            sample = collection.peek(limit=2)
            print(f"    Sample content: {sample['documents'][0][:100]}...")
else:
    print("No knowledge storage found")
```

#### Verificar Processamento de Knowledge

```python
from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

# Create a test knowledge source
test_source = StringKnowledgeSource(
    content="Test knowledge content for debugging",
    chunk_size=100,  # Small chunks for testing
    chunk_overlap=20
)

# Check chunking behavior
print(f"Original content length: {len(test_source.content)}")
print(f"Chunk size: {test_source.chunk_size}")
print(f"Chunk overlap: {test_source.chunk_overlap}")

# Process and inspect chunks
test_source.add()
print(f"Number of chunks created: {len(test_source.chunks)}")
for i, chunk in enumerate(test_source.chunks[:3]):  # Show first 3 chunks
    print(f"Chunk {i+1}: {chunk[:50]}...")
```

### Problemas Comuns de Armazenamento de Knowledge

**Erros "Arquivo n√£o encontrado":**

```python
# Ensure files are in the correct location
from crewai.utilities.constants import KNOWLEDGE_DIRECTORY
import os

knowledge_dir = KNOWLEDGE_DIRECTORY  # Usually "knowledge"
file_path = os.path.join(knowledge_dir, "your_file.pdf")

if not os.path.exists(file_path):
    print(f"File not found: {file_path}")
    print(f"Current working directory: {os.getcwd()}")
    print(f"Expected knowledge directory: {os.path.abspath(knowledge_dir)}")
```

**Erros "Incompatibilidade de dimens√£o de embedding":**

```python
# This happens when switching embedding providers
# Reset knowledge storage to clear old embeddings
crew.reset_memories(command_type='knowledge')

# Or use consistent embedding providers
crew = Crew(
    agents=[...],
    tasks=[...],
    knowledge_sources=[...],
    embedder={"provider": "openai", "config": {"model": "text-embedding-3-small"}}
)
```

**Erros "ChromaDB permiss√£o negada":**

```bash
# Fix storage permissions
chmod -R 755 ~/.local/share/CrewAI/
```

**Knowledge n√£o persistindo entre execu√ß√µes:**

```python
# Verify storage location consistency
import os
from crewai.utilities.paths import db_storage_path

print("CREWAI_STORAGE_DIR:", os.getenv("CREWAI_STORAGE_DIR"))
print("Computed storage path:", db_storage_path())
print("Knowledge path:", os.path.join(db_storage_path(), "knowledge"))
```

### Comandos de Reset de Knowledge

```python
# Reset only agent-specific knowledge
crew.reset_memories(command_type='agent_knowledge')

# Reset both crew and agent knowledge
crew.reset_memories(command_type='knowledge')

# CLI commands
# crewai reset-memories --agent-knowledge  # Agent knowledge only
# crewai reset-memories --knowledge        # All knowledge
```

### Limpando Knowledge

Se voc√™ precisar limpar o knowledge armazenado no CrewAI, voc√™ pode usar o comando `crewai reset-memories` com a op√ß√£o `--knowledge`.

```bash Command
crewai reset-memories --knowledge
```

Isso √© √∫til quando voc√™ atualizou suas fontes de knowledge e quer garantir que os agentes estejam usando as informa√ß√µes mais recentes.

## Melhores Pr√°ticas

<AccordionGroup>
  <Accordion title="Organiza√ß√£o de Conte√∫do">
    * Mantenha tamanhos de chunk apropriados para seu tipo de conte√∫do
    * Considere sobreposi√ß√£o de conte√∫do para preserva√ß√£o de contexto
    * Organize informa√ß√µes relacionadas em fontes de knowledge separadas
  </Accordion>

  <Accordion title="Dicas de Performance">
    * Ajuste tamanhos de chunk baseado na complexidade do conte√∫do
    * Configure modelos de embedding apropriados
    * Considere usar provedores de embedding locais para processamento mais r√°pido
  </Accordion>

  <Accordion title="Knowledge de Uma Vez">
    * Com a estrutura de arquivo t√≠pica fornecida pelo CrewAI, as fontes de knowledge s√£o incorporadas toda vez que o kickoff √© acionado.
    * Se as fontes de knowledge s√£o grandes, isso leva √† inefici√™ncia e lat√™ncia aumentada, pois os mesmos dados s√£o incorporados cada vez.
    * Para resolver isso, inicialize diretamente o par√¢metro knowledge em vez do par√¢metro knowledge\_sources.
    * Link para a issue para ter a ideia completa [Github Issue](https://github.com/crewAIInc/crewAI/issues/2755)
  </Accordion>

  <Accordion title="Gerenciamento de Knowledge">
    * Use knowledge no n√≠vel do agente para informa√ß√µes espec√≠ficas do papel
    * Use knowledge no n√≠vel da crew para informa√ß√µes compartilhadas que todos os agentes precisam
    * Configure embedders no n√≠vel do agente se voc√™ precisar de estrat√©gias de embedding diferentes
    * Use nomenclatura consistente de cole√ß√£o mantendo pap√©is de agente descritivos
    * Teste a inicializa√ß√£o de knowledge verificando agent.knowledge ap√≥s o kickoff
    * Monitore localiza√ß√µes de armazenamento para entender onde o knowledge est√° armazenado
    * Reset knowledge apropriadamente usando os tipos de comando corretos
  </Accordion>

  <Accordion title="Melhores Pr√°ticas de Produ√ß√£o">
    * Configure `CREWAI_STORAGE_DIR` para uma localiza√ß√£o conhecida em produ√ß√£o
    * Escolha provedores de embedding expl√≠citos para corresponder √† sua configura√ß√£o de LLM e evitar conflitos de chave de API
    * Monitore o tamanho do armazenamento de knowledge conforme ele cresce com adi√ß√µes de documentos
    * Organize fontes de knowledge por dom√≠nio ou prop√≥sito usando nomes de cole√ß√£o
    * Inclua diret√≥rios de knowledge em suas estrat√©gias de backup e implanta√ß√£o
    * Configure permiss√µes de arquivo apropriadas para arquivos de knowledge e diret√≥rios de armazenamento
    * Use vari√°veis de ambiente para chaves de API e configura√ß√£o sens√≠vel
  </Accordion>
</AccordionGroup>


# LLMs
Source: https://docs.crewai.com/pt-BR/concepts/llms

Um guia abrangente para configurar e usar Modelos de Linguagem de Grande Escala (LLMs) em seus projetos CrewAI

## Vis√£o Geral

O CrewAI integra-se com m√∫ltiplos provedores de LLM atrav√©s do LiteLLM, oferecendo flexibilidade para voc√™ escolher o modelo certo para o seu caso de uso espec√≠fico. Este guia ir√° ajud√°-lo a entender como configurar e usar diferentes provedores de LLM em seus projetos CrewAI.

## O que s√£o LLMs?

Modelos de Linguagem de Grande Escala (LLMs) s√£o a intelig√™ncia central por tr√°s dos agentes CrewAI. Eles permitem que os agentes compreendam o contexto, tomem decis√µes e gerem respostas semelhantes √†s humanas. Veja o que voc√™ precisa saber:

<CardGroup cols={2}>
  <Card title="No√ß√µes B√°sicas de LLM" icon="brain">
    Modelos de Linguagem de Grande Escala s√£o sistemas de IA treinados em grandes volumes de dados textuais. Eles potencializam a intelig√™ncia dos agentes CrewAI, permitindo compreender e gerar textos de voz humana.
  </Card>

  <Card title="Janela de Contexto" icon="window">
    A janela de contexto determina quanto texto um LLM pode processar de uma s√≥ vez. Janelas maiores (por exemplo, 128K tokens) permitem mais contexto, por√©m podem ser mais caras e lentas.
  </Card>

  <Card title="Temperatura" icon="temperature-three-quarters">
    A temperatura (0.0 a 1.0) controla a aleatoriedade das respostas. Valores mais baixos (ex.: 0.2) produzem respostas mais focadas e determin√≠sticas, enquanto valores mais altos (ex.: 0.8) aumentam criatividade e variabilidade.
  </Card>

  <Card title="Sele√ß√£o de Provedor" icon="server">
    Cada provedor de LLM (ex.: OpenAI, Anthropic, Google) oferece modelos diferentes, com capacidades, pre√ßos e recursos variados. Escolha conforme suas necessidades de precis√£o, velocidade e custo.
  </Card>
</CardGroup>

## Configurando seu LLM

Existem diferentes locais no c√≥digo do CrewAI onde voc√™ pode especificar o modelo a ser utilizado. Ap√≥s definir o modelo usado, ser√° necess√°rio fornecer a configura√ß√£o (como uma chave de API) para cada provedor de modelo. Veja a se√ß√£o de [exemplos de configura√ß√£o de provedores](#provider-configuration-examples) para seu provedor.

<Tabs>
  <Tab title="1. Vari√°veis de Ambiente">
    A maneira mais simples de come√ßar. Defina o modelo diretamente em seu ambiente, usando um arquivo `.env` ou no c√≥digo do seu aplicativo. Se voc√™ utilizou `crewai create` para iniciar seu projeto, j√° estar√° configurado.

    ```bash .env
    MODEL=model-id  # e.g. gpt-4o, gemini-2.0-flash, claude-3-sonnet-...

    # Lembre-se de definir suas chaves de API aqui tamb√©m. Veja a se√ß√£o
    # do Provedor abaixo.
    ```

    <Warning>
      Nunca envie chaves de API para controle de vers√£o. Use arquivos de ambiente (.env) ou o gerenciamento de segredos do seu sistema.
    </Warning>
  </Tab>

  <Tab title="2. Configura√ß√£o YAML">
    Crie um arquivo YAML para definir as configura√ß√µes dos seus agentes. Este m√©todo √© √≥timo para controle de vers√£o e colabora√ß√£o em equipe:

    ```yaml agents.yaml {6}
    researcher:
        role: Research Specialist
        goal: Conduct comprehensive research and analysis
        backstory: A dedicated research professional with years of experience
        verbose: true
        llm: provider/model-id  # e.g. openai/gpt-4o, google/gemini-2.0-flash, anthropic/claude...
        # (veja exemplos de configura√ß√£o de provedores abaixo para mais)
    ```

    <Info>
      A configura√ß√£o YAML permite:

      * Controlar vers√µes das configura√ß√µes dos agentes
      * Trocar facilmente entre diferentes modelos
      * Compartilhar configura√ß√µes entre membros da equipe
      * Documentar escolhas de modelos e seus prop√≥sitos
    </Info>
  </Tab>

  <Tab title="3. C√≥digo Direto">
    Para m√°xima flexibilidade, configure os LLMs diretamente no seu c√≥digo Python:

    ```python {4,8}
    from crewai import LLM

    # Configura√ß√£o b√°sica
    llm = LLM(model="model-id-here")  # gpt-4o, gemini-2.0-flash, anthropic/claude...

    # Configura√ß√£o avan√ßada com par√¢metros detalhados
    llm = LLM(
        model="openai/gpt-4",
        temperature=0.8,
        max_tokens=150,
        top_p=0.9,
        frequency_penalty=0.1,
        presence_penalty=0.1,
        response_format={"type":"json"},
        stop=["FIM"],
        seed=42
    )
    ```

    <Info>
      Explica√ß√µes dos par√¢metros:

      * `temperature`: Controla a aleatoriedade (0.0-1.0)
      * `timeout`: Tempo m√°ximo de espera pela resposta
      * `max_tokens`: Limita o comprimento da resposta
      * `top_p`: Alternativa √† temperatura para amostragem
      * `frequency_penalty`: Reduz repeti√ß√£o de palavras
      * `presence_penalty`: Incentiva novos t√≥picos
      * `response_format`: Especifica formato de sa√≠da
      * `seed`: Garante resultados consistentes
    </Info>
  </Tab>
</Tabs>

## Exemplos de Configura√ß√£o de Provedores

O CrewAI suporta uma grande variedade de provedores de LLM, cada um com recursos, m√©todos de autentica√ß√£o e capacidades de modelo √∫nicos.
Nesta se√ß√£o, voc√™ encontrar√° exemplos detalhados que ajudam a selecionar, configurar e otimizar o LLM que melhor atende √†s necessidades do seu projeto.

<AccordionGroup>
  <Accordion title="OpenAI">
    Defina as seguintes vari√°veis de ambiente no seu arquivo `.env`:

    ```toml Code
    # Obrigat√≥rio
    OPENAI_API_KEY=sk-...

    # Opcional
    OPENAI_API_BASE=<custom-base-url>
    OPENAI_ORGANIZATION=<your-org-id>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    from crewai import LLM

    llm = LLM(
        model="openai/gpt-4",
        temperature=0.8,
        max_tokens=150,
        top_p=0.9,
        frequency_penalty=0.1,
        presence_penalty=0.1,
        stop=["FIM"],
        seed=42
    )
    ```

    OpenAI √© um dos l√≠deres em modelos LLM com uma ampla gama de modelos e recursos.

    | Modelo               | Janela de Contexto | Melhor Para                                             |
    | -------------------- | ------------------ | ------------------------------------------------------- |
    | GPT-4                | 8.192 tokens       | Tarefas de alta precis√£o, racioc√≠nio complexo           |
    | GPT-4 Turbo          | 128.000 tokens     | Conte√∫do longo, an√°lise de documentos                   |
    | GPT-4o & GPT-4o-mini | 128.000 tokens     | Processamento de contexto amplo com bom custo-benef√≠cio |
    | o3-mini              | 200.000 tokens     | Racioc√≠nio r√°pido, tarefas complexas                    |
    | o1-mini              | 128.000 tokens     | Racioc√≠nio r√°pido, tarefas complexas                    |
    | o1-preview           | 128.000 tokens     | Racioc√≠nio r√°pido, tarefas complexas                    |
    | o1                   | 200.000 tokens     | Racioc√≠nio r√°pido, tarefas complexas                    |
  </Accordion>

  <Accordion title="Meta-Llama">
    A API Llama da Meta fornece acesso √† fam√≠lia de modelos de linguagem de grande escala da Meta.
    A API est√° dispon√≠vel atrav√©s da [Meta Llama API](https://llama.developer.meta.com?utm_source=partner-crewai\&utm_medium=website).
    Defina as seguintes vari√°veis de ambiente no seu arquivo `.env`:

    ```toml Code
    # Configura√ß√£o chave da API Meta Llama
    LLAMA_API_KEY=LLM|your_api_key_here
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    from crewai import LLM

    # Inicializar Meta Llama LLM
    llm = LLM(
        model="meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8",
        temperature=0.8,
        stop=["FIM"],
        seed=42
    )
    ```

    Todos os modelos listados em [https://llama.developer.meta.com/docs/models/](https://llama.developer.meta.com/docs/models/) s√£o suportados.

    | ID do Modelo                                        | Comprimento contexto entrada | Comprimento contexto sa√≠da | Modalidades de entrada | Modalidades de sa√≠da |
    | --------------------------------------------------- | ---------------------------- | -------------------------- | ---------------------- | -------------------- |
    | `meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8`     | 128k                         | 4028                       | Texto, Imagem          | Texto                |
    | `meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8` | 128k                         | 4028                       | Texto, Imagem          | Texto                |
    | `meta_llama/Llama-3.3-70B-Instruct`                 | 128k                         | 4028                       | Texto                  | Texto                |
    | `meta_llama/Llama-3.3-8B-Instruct`                  | 128k                         | 4028                       | Texto                  | Texto                |
  </Accordion>

  <Accordion title="Anthropic">
    ```toml Code
    # Obrigat√≥rio
    ANTHROPIC_API_KEY=sk-ant-...

    # Opcional
    ANTHROPIC_API_BASE=<custom-base-url>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="anthropic/claude-3-sonnet-20240229-v1:0",
        temperature=0.7
    )
    ```
  </Accordion>

  <Accordion title="Google (Gemini API)">
    Defina sua chave de API no seu arquivo `.env`. Se precisar de uma chave, ou encontrar uma existente, verifique o [AI Studio](https://aistudio.google.com/apikey).

    ```toml .env
    # https://ai.google.dev/gemini-api/docs/api-key
    GEMINI_API_KEY=<your-api-key>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    from crewai import LLM

    llm = LLM(
        model="gemini/gemini-2.0-flash",
        temperature=0.7,
    )
    ```

    ### Modelos Gemini

    O Google oferece uma variedade de modelos poderosos otimizados para diferentes casos de uso.

    | Modelo                         | Janela de Contexto | Melhor Para                                                                                                               |
    | ------------------------------ | ------------------ | ------------------------------------------------------------------------------------------------------------------------- |
    | gemini-2.5-flash-preview-04-17 | 1M tokens          | Pensamento adaptativo, efici√™ncia de custo                                                                                |
    | gemini-2.5-pro-preview-05-06   | 1M tokens          | Pensamento e racioc√≠nio avan√ßados, compreens√£o multimodal, codifica√ß√£o avan√ßada, etc.                                     |
    | gemini-2.0-flash               | 1M tokens          | Pr√≥xima gera√ß√£o de recursos, velocidade, racioc√≠nio e streaming em tempo real                                             |
    | gemini-2.0-flash-lite          | 1M tokens          | Efici√™ncia de custo e baixa lat√™ncia                                                                                      |
    | gemini-1.5-flash               | 1M tokens          | Modelo multimodal equilibrado, bom para maioria das tarefas                                                               |
    | gemini-1.5-flash-8B            | 1M tokens          | Mais r√°pido, mais eficiente em custo, adequado para tarefas de alta frequ√™ncia                                            |
    | gemini-1.5-pro                 | 2M tokens          | Melhor desempenho para uma ampla variedade de tarefas de racioc√≠nio, incluindo l√≥gica, codifica√ß√£o e colabora√ß√£o criativa |

    A lista completa de modelos est√° dispon√≠vel na [documenta√ß√£o dos modelos Gemini](https://ai.google.dev/gemini-api/docs/models).

    ### Gemma

    A API Gemini tamb√©m permite uso de sua chave de API para acessar [modelos Gemma](https://ai.google.dev/gemma/docs) hospedados na infraestrutura Google.

    | Modelo         | Janela de Contexto |
    | -------------- | ------------------ |
    | gemma-3-1b-it  | 32k tokens         |
    | gemma-3-4b-it  | 32k tokens         |
    | gemma-3-12b-it | 32k tokens         |
    | gemma-3-27b-it | 128k tokens        |
  </Accordion>

  <Accordion title="Google (Vertex AI)">
    Obtenha as credenciais pelo Google Cloud Console, salve em um arquivo JSON e carregue com o c√≥digo a seguir:

    ```python Code
    import json

    file_path = 'path/to/vertex_ai_service_account.json'

    # Carregar o arquivo JSON
    with open(file_path, 'r') as file:
        vertex_credentials = json.load(file)

    # Converter credenciais em string JSON
    vertex_credentials_json = json.dumps(vertex_credentials)
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    from crewai import LLM

    llm = LLM(
        model="gemini/gemini-1.5-pro-latest",
        temperature=0.7,
        vertex_credentials=vertex_credentials_json
    )
    ```

    O Google oferece uma variedade de modelos poderosos otimizados para diferentes casos de uso:

    | Modelo                         | Janela de Contexto | Melhor Para                                                                                                               |
    | ------------------------------ | ------------------ | ------------------------------------------------------------------------------------------------------------------------- |
    | gemini-2.5-flash-preview-04-17 | 1M tokens          | Pensamento adaptativo, efici√™ncia de custo                                                                                |
    | gemini-2.5-pro-preview-05-06   | 1M tokens          | Pensamento e racioc√≠nio avan√ßados, compreens√£o multimodal, codifica√ß√£o avan√ßada, etc.                                     |
    | gemini-2.0-flash               | 1M tokens          | Pr√≥xima gera√ß√£o de recursos, velocidade, racioc√≠nio e streaming em tempo real                                             |
    | gemini-2.0-flash-lite          | 1M tokens          | Efici√™ncia de custo e baixa lat√™ncia                                                                                      |
    | gemini-1.5-flash               | 1M tokens          | Modelo multimodal equilibrado, bom para maioria das tarefas                                                               |
    | gemini-1.5-flash-8B            | 1M tokens          | Mais r√°pido, mais eficiente em custo, adequado para tarefas de alta frequ√™ncia                                            |
    | gemini-1.5-pro                 | 2M tokens          | Melhor desempenho para uma ampla variedade de tarefas de racioc√≠nio, incluindo l√≥gica, codifica√ß√£o e colabora√ß√£o criativa |
  </Accordion>

  <Accordion title="Azure">
    ```toml Code
    # Obrigat√≥rio
    AZURE_API_KEY=<your-api-key>
    AZURE_API_BASE=<your-resource-url>
    AZURE_API_VERSION=<api-version>

    # Opcional
    AZURE_AD_TOKEN=<your-azure-ad-token>
    AZURE_API_TYPE=<your-azure-api-type>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="azure/gpt-4",
        api_version="2023-05-15"
    )
    ```
  </Accordion>

  <Accordion title="AWS Bedrock">
    ```toml Code
    AWS_ACCESS_KEY_ID=<your-access-key>
    AWS_SECRET_ACCESS_KEY=<your-secret-key>
    AWS_DEFAULT_REGION=<your-region>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="bedrock/anthropic.claude-3-sonnet-20240229-v1:0"
    )
    ```

    Antes de usar o Amazon Bedrock, certifique-se de ter o boto3 instalado em seu ambiente

    [Amazon Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/models-regions.html) √© um servi√ßo gerenciado que fornece acesso a m√∫ltiplos modelos fundamentais dos principais provedores de IA atrav√©s de uma API unificada, permitindo o desenvolvimento seguro e respons√°vel de aplica√ß√µes de IA.

    | Modelo                  | Janela de Contexto | Melhor Para                                                                                                                       |
    | ----------------------- | ------------------ | --------------------------------------------------------------------------------------------------------------------------------- |
    | Amazon Nova Pro         | At√© 300k tokens    | Alto desempenho, equil√≠brio entre precis√£o, velocidade e custo em tarefas diversas.                                               |
    | Amazon Nova Micro       | At√© 128k tokens    | Modelo texto-only de alta performance, custo-benef√≠cio, otimizado para baixa lat√™ncia.                                            |
    | Amazon Nova Lite        | At√© 300k tokens    | Alto desempenho, processamento multimodal acess√≠vel para texto, imagem, v√≠deo em tempo real.                                      |
    | Claude 3.7 Sonnet       | At√© 128k tokens    | Alto desempenho para racioc√≠nio complexo, programa√ß√£o & agentes de IA                                                             |
    | Claude 3.5 Sonnet v2    | At√© 200k tokens    | Modelo avan√ßado especializado em engenharia de software, capacidades agenticas e intera√ß√£o computacional com custo otimizado.     |
    | Claude 3.5 Sonnet       | At√© 200k tokens    | Alto desempenho com intelig√™ncia e racioc√≠nio excepcionais, equil√≠brio entre velocidade-custo.                                    |
    | Claude 3.5 Haiku        | At√© 200k tokens    | Modelo multimodal r√°pido e compacto, otimizado para respostas r√°pidas e intera√ß√µes humanas naturais                               |
    | Claude 3 Sonnet         | At√© 200k tokens    | Modelo multimodal equilibrando intelig√™ncia e velocidade para grandes volumes de uso.                                             |
    | Claude 3 Haiku          | At√© 200k tokens    | Compacto, multimodal, otimizado para respostas r√°pidas e di√°logo natural                                                          |
    | Claude 3 Opus           | At√© 200k tokens    | Modelo multimodal mais avan√ßado para tarefas complexas com racioc√≠nio humano e entendimento contextual superior.                  |
    | Claude 2.1              | At√© 200k tokens    | Vers√£o aprimorada com janela de contexto aumentada, maior confiabilidade, menos alucina√ß√µes para aplica√ß√µes longas e RAG          |
    | Claude                  | At√© 100k tokens    | Modelo vers√°til para di√°logos sofisticados, conte√∫do criativo e instru√ß√µes precisas.                                              |
    | Claude Instant          | At√© 100k tokens    | Modelo r√°pido e de baixo custo para tarefas di√°rias, como di√°logos, an√°lise, sumariza√ß√£o e Q\&A em documentos                     |
    | Llama 3.1 405B Instruct | At√© 128k tokens    | LLM avan√ßado para gera√ß√£o de dados sint√©ticos, distila√ß√£o e infer√™ncia para chatbots, programa√ß√£o, tarefas de dom√≠nio espec√≠fico. |
    | Llama 3.1 70B Instruct  | At√© 128k tokens    | Potencializa conversas complexas com entendimento contextual superior, racioc√≠nio e gera√ß√£o de texto.                             |
    | Llama 3.1 8B Instruct   | At√© 128k tokens    | Modelo de √∫ltima gera√ß√£o, entendimento de linguagem, racioc√≠nio e gera√ß√£o de texto.                                               |
    | Llama 3 70B Instruct    | At√© 8k tokens      | Potencializa conversas complexas com entendimento contextual superior, racioc√≠nio e gera√ß√£o de texto.                             |
    | Llama 3 8B Instruct     | At√© 8k tokens      | LLM de √∫ltima gera√ß√£o com excelente desempenho em linguagem e gera√ß√£o de texto.                                                   |
    | Titan Text G1 - Lite    | At√© 4k tokens      | Modelo leve e econ√¥mico para tarefas em ingl√™s e ajuste fino, focado em sumariza√ß√£o e gera√ß√£o de conte√∫do.                        |
    | Titan Text G1 - Express | At√© 8k tokens      | Modelo vers√°til para tarefas gerais de linguagem, chat e aplica√ß√µes RAG com suporte a ingl√™s e 100+ l√≠nguas.                      |
    | Cohere Command          | At√© 4k tokens      | Modelo especializado em seguir comandos do usu√°rio e entregar solu√ß√µes empresariais pr√°ticas.                                     |
    | Jurassic-2 Mid          | At√© 8.191 tokens   | Modelo econ√¥mico equilibrando qualidade e custo para tarefas como Q\&A, sumariza√ß√£o e gera√ß√£o de conte√∫do.                        |
    | Jurassic-2 Ultra        | At√© 8.191 tokens   | Gera√ß√£o avan√ßada de texto e compreens√£o, excelente em an√°lise e cria√ß√£o de conte√∫do complexo.                                     |
    | Jamba-Instruct          | At√© 256k tokens    | Modelo com janela de contexto extendida para gera√ß√£o de texto, sumariza√ß√£o e Q\&A de baixo custo.                                 |
    | Mistral 7B Instruct     | At√© 32k tokens     | LLM atende instru√ß√µes, solicita√ß√µes e gera texto criativo.                                                                        |
    | Mistral 8x7B Instruct   | At√© 32k tokens     | MOE LLM que atende instru√ß√µes, solicita√ß√µes e gera texto criativo.                                                                |
  </Accordion>

  <Accordion title="Amazon SageMaker">
    ```toml Code
    AWS_ACCESS_KEY_ID=<your-access-key>
    AWS_SECRET_ACCESS_KEY=<your-secret-key>
    AWS_DEFAULT_REGION=<your-region>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="sagemaker/<my-endpoint>"
    )
    ```
  </Accordion>

  <Accordion title="Mistral">
    Defina as seguintes vari√°veis de ambiente no seu arquivo `.env`:

    ```toml Code
    MISTRAL_API_KEY=<your-api-key>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="mistral/mistral-large-latest",
        temperature=0.7
    )
    ```
  </Accordion>

  <Accordion title="Nvidia NIM">
    Defina as seguintes vari√°veis de ambiente no seu arquivo `.env`:

    ```toml Code
    NVIDIA_API_KEY=<your-api-key>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="nvidia_nim/meta/llama3-70b-instruct",
        temperature=0.7
    )
    ```

    O Nvidia NIM oferece uma su√≠te abrangente de modelos para diversos usos, desde tarefas gerais at√© aplica√ß√µes especializadas.

    | Modelo                                      | Janela de Contexto | Melhor Para                                                                                                                 |
    | ------------------------------------------- | ------------------ | --------------------------------------------------------------------------------------------------------------------------- |
    | nvidia/mistral-nemo-minitron-8b-8k-instruct | 8.192 tokens       | Modelo pequeno de linguagem topo de linha para chatbots, assistentes virtuais e gera√ß√£o de conte√∫do.                        |
    | nvidia/nemotron-4-mini-hindi-4b-instruct    | 4.096 tokens       | SLM bil√≠ngue Hindi-Ingl√™s para infer√™ncia no dispositivo, espec√≠fico para l√≠ngua hindi.                                     |
    | nvidia/llama-3.1-nemotron-70b-instruct      | 128k tokens        | Personalizado para respostas mais √∫teis                                                                                     |
    | nvidia/llama3-chatqa-1.5-8b                 | 128k tokens        | LLM avan√ßado para respostas contextuais de alta qualidade em chatbots e mecanismos de busca.                                |
    | nvidia/llama3-chatqa-1.5-70b                | 128k tokens        | LLM avan√ßado para respostas contextuais de alta qualidade para chatbots e mecanismos de busca.                              |
    | nvidia/vila                                 | 128k tokens        | Modelo multmodal vis√£o-linguagem para compreens√£o de texto/img/v√≠deo com respostas informativas                             |
    | nvidia/neva-22                              | 4.096 tokens       | Modelo de vis√£o-linguagem multimodal para compreens√£o textos/imagens e respostas informativas                               |
    | nvidia/nemotron-mini-4b-instruct            | 8.192 tokens       | Tarefas gerais                                                                                                              |
    | nvidia/usdcode-llama3-70b-instruct          | 128k tokens        | LLM de ponta para queries OpenUSD e gera√ß√£o de c√≥digo USD-Python.                                                           |
    | nvidia/nemotron-4-340b-instruct             | 4.096 tokens       | Gera dados sint√©ticos diversos simulando caracter√≠sticas reais.                                                             |
    | meta/codellama-70b                          | 100k tokens        | LLM capaz de gerar c√≥digo a partir de linguagem natural e vice-versa.                                                       |
    | meta/llama2-70b                             | 4.096 tokens       | Modelo de IA avan√ßado para gera√ß√£o de textos e c√≥digos.                                                                     |
    | meta/llama3-8b-instruct                     | 8.192 tokens       | LLM de √∫ltima gera√ß√£o, entendimento de linguagem, racioc√≠nio e gera√ß√£o de texto.                                            |
    | meta/llama3-70b-instruct                    | 8.192 tokens       | Potencializa conversas complexas com entendimento contextual superior, racioc√≠nio e gera√ß√£o de texto.                       |
    | meta/llama-3.1-8b-instruct                  | 128k tokens        | Modelo compacto de √∫ltima gera√ß√£o, com compreens√£o, racioc√≠nio e gera√ß√£o de texto superior.                                 |
    | meta/llama-3.1-70b-instruct                 | 128k tokens        | Potencializa conversas complexas com entendimento contextual superior, racioc√≠nio e gera√ß√£o de texto.                       |
    | meta/llama-3.1-405b-instruct                | 128k tokens        | LLM avan√ßado para gera√ß√£o sint√©tica de dados, destila√ß√£o e infer√™ncia para chatbots, c√≥digo, tarefas de dom√≠nio espec√≠fico. |
    | meta/llama-3.2-1b-instruct                  | 128k tokens        | Pequeno modelo de linguagem de √∫ltima gera√ß√£o, entendimento, racioc√≠nio e gera√ß√£o textual.                                  |
    | meta/llama-3.2-3b-instruct                  | 128k tokens        | Pequeno modelo de linguagem de √∫ltima gera√ß√£o, entendimento, racioc√≠nio e gera√ß√£o textual.                                  |
    | meta/llama-3.2-11b-vision-instruct          | 128k tokens        | Pequeno modelo de linguagem de √∫ltima gera√ß√£o, entendimento, racioc√≠nio e gera√ß√£o textual multimodal.                       |
    | meta/llama-3.2-90b-vision-instruct          | 128k tokens        | Pequeno modelo de linguagem de √∫ltima gera√ß√£o, entendimento, racioc√≠nio e gera√ß√£o textual multimodal.                       |
    | google/gemma-7b                             | 8.192 tokens       | Modelo avan√ßado de gera√ß√£o de texto, compreens√£o, transforma√ß√£o e programa√ß√£o.                                              |
    | google/gemma-2b                             | 8.192 tokens       | Modelo avan√ßado de gera√ß√£o de texto, compreens√£o, transforma√ß√£o e programa√ß√£o.                                              |
    | google/codegemma-7b                         | 8.192 tokens       | Modelo avan√ßado baseado no Gemma-7B do Google, especializado em gera√ß√£o de c√≥digos e autocomplete.                          |
    | google/codegemma-1.1-7b                     | 8.192 tokens       | Modelo avan√ßado para gera√ß√£o, complemento, racioc√≠nio e instru√ß√£o em c√≥digo.                                                |
    | google/recurrentgemma-2b                    | 8.192 tokens       | Modelo baseado em arquitetura recorrente para infer√™ncia mais r√°pida em sequ√™ncias longas.                                  |
    | google/gemma-2-9b-it                        | 8.192 tokens       | Modelo avan√ßado de gera√ß√£o de texto, compreens√£o, transforma√ß√£o e programa√ß√£o.                                              |
    | google/gemma-2-27b-it                       | 8.192 tokens       | Modelo avan√ßado de gera√ß√£o de texto, compreens√£o, transforma√ß√£o e programa√ß√£o.                                              |
    | google/gemma-2-2b-it                        | 8.192 tokens       | Modelo avan√ßado de gera√ß√£o de texto, compreens√£o, transforma√ß√£o e programa√ß√£o.                                              |
    | google/deplot                               | 512 tokens         | Modelo visual por linguagem para entender gr√°ficos e converter em tabelas.                                                  |
    | google/paligemma                            | 8.192 tokens       | Modelo vis√£o-linguagem experto em compreender texto e visual, gerando respostas informativas.                               |
    | mistralai/mistral-7b-instruct-v0.2          | 32k tokens         | LLM que segue instru√ß√µes, completa pedidos e gera texto criativo.                                                           |
    | mistralai/mixtral-8x7b-instruct-v0.1        | 8.192 tokens       | MOE LLM para seguir instru√ß√µes e gerar vers√µes criativas de texto.                                                          |
    | mistralai/mistral-large                     | 4.096 tokens       | Gera√ß√£o de dados sint√©ticos.                                                                                                |
    | mistralai/mixtral-8x22b-instruct-v0.1       | 8.192 tokens       | Gera√ß√£o de dados sint√©ticos.                                                                                                |
    | mistralai/mistral-7b-instruct-v0.3          | 32k tokens         | LLM que segue instru√ß√µes, completa pedidos e gera texto criativo.                                                           |
    | nv-mistralai/mistral-nemo-12b-instruct      | 128k tokens        | Modelo de linguagem avan√ßado para racioc√≠nio, c√≥digo, tarefas multil√≠ngues; roda em uma √∫nica GPU.                          |
    | mistralai/mamba-codestral-7b-v0.1           | 256k tokens        | Modelo para escrita e intera√ß√£o com c√≥digo em m√∫ltiplas linguagens e tarefas.                                               |
    | microsoft/phi-3-mini-128k-instruct          | 128K tokens        | LLM leve, de √∫ltima gera√ß√£o, com habilidades de l√≥gica e matem√°tica.                                                        |
    | microsoft/phi-3-mini-4k-instruct            | 4.096 tokens       | LLM leve, de √∫ltima gera√ß√£o, com habilidades de l√≥gica e matem√°tica.                                                        |
    | microsoft/phi-3-small-8k-instruct           | 8.192 tokens       | LLM leve, de √∫ltima gera√ß√£o, com habilidades de l√≥gica e matem√°tica.                                                        |
    | microsoft/phi-3-small-128k-instruct         | 128K tokens        | LLM leve, de √∫ltima gera√ß√£o, com habilidades de l√≥gica e matem√°tica.                                                        |
    | microsoft/phi-3-medium-4k-instruct          | 4.096 tokens       | LLM leve, de √∫ltima gera√ß√£o, com habilidades de l√≥gica e matem√°tica.                                                        |
    | microsoft/phi-3-medium-128k-instruct        | 128K tokens        | LLM leve, de √∫ltima gera√ß√£o, com habilidades de l√≥gica e matem√°tica.                                                        |
    | microsoft/phi-3.5-mini-instruct             | 128K tokens        | LLM multil√≠ngue leve para aplica√ß√µes de IA restritas em mem√≥ria e tempo.                                                    |
    | microsoft/phi-3.5-moe-instruct              | 128K tokens        | LLM avan√ßada baseada em Mixture of Experts para gera√ß√£o eficiente de conte√∫do.                                              |
    | microsoft/kosmos-2                          | 1.024 tokens       | Modelo multimodal revolucion√°rio para compreender e raciocinar elementos visuais em imagens.                                |
    | microsoft/phi-3-vision-128k-instruct        | 128k tokens        | Modelo multimodal aberto de ponta para racioc√≠nio de alta qualidade a partir de imagens.                                    |
    | microsoft/phi-3.5-vision-instruct           | 128k tokens        | Modelo multimodal aberto de ponta para racioc√≠nio de alta qualidade a partir de imagens.                                    |
    | databricks/dbrx-instruct                    | 12k tokens         | LLM de uso geral com desempenho no estado da arte para linguagem, programa√ß√£o e RAG.                                        |
    | snowflake/arctic                            | 1.024 tokens       | Infer√™ncia eficiente para aplica√ß√µes empresariais focadas em SQL e programa√ß√£o.                                             |
    | aisingapore/sea-lion-7b-instruct            | 4.096 tokens       | LLM para representa√ß√£o e diversidade lingu√≠stica e cultural do sudeste asi√°tico.                                            |
    | ibm/granite-8b-code-instruct                | 4.096 tokens       | LLM para programa√ß√£o: gera√ß√£o, explica√ß√£o e di√°logo multi-turn de c√≥digo.                                                   |
    | ibm/granite-34b-code-instruct               | 8.192 tokens       | LLM para programa√ß√£o: gera√ß√£o, explica√ß√£o e di√°logo multi-turn de c√≥digo.                                                   |
    | ibm/granite-3.0-8b-instruct                 | 4.096 tokens       | Pequeno modelo avan√ßado, com suporte a RAG, sum√°rio, classifica√ß√£o, c√≥digo e IA agentica.                                   |
    | ibm/granite-3.0-3b-a800m-instruct           | 4.096 tokens       | Modelo Mixture of Experts eficiente para RAG, sum√°rio, extra√ß√£o de entidades, classifica√ß√£o.                                |
    | mediatek/breeze-7b-instruct                 | 4.096 tokens       | Gera dados sint√©ticos diversos.                                                                                             |
    | upstage/solar-10.7b-instruct                | 4.096 tokens       | Excelente em tarefas de PLN, especialmente seguir instru√ß√µes, racioc√≠nio e matem√°tica.                                      |
    | writer/palmyra-med-70b-32k                  | 32k tokens         | LLM l√≠der para respostas m√©dicas precisas e contextuais.                                                                    |
    | writer/palmyra-med-70b                      | 32k tokens         | LLM l√≠der para respostas m√©dicas precisas e contextuais.                                                                    |
    | writer/palmyra-fin-70b-32k                  | 32k tokens         | LLM especializada em an√°lise financeira, relat√≥rios e processamento de dados.                                               |
    | 01-ai/yi-large                              | 32k tokens         | Poderoso para ingl√™s e chin√™s, incluindo chatbot e escrita criativa.                                                        |
    | deepseek-ai/deepseek-coder-6.7b-instruct    | 2k tokens          | Modelo avan√ßado para gera√ß√£o de c√≥digo, autocomplete, infilling.                                                            |
    | rakuten/rakutenai-7b-instruct               | 1.024 tokens       | LLM topo de linha, compreens√£o, racioc√≠nio e gera√ß√£o textual.                                                               |
    | rakuten/rakutenai-7b-chat                   | 1.024 tokens       | LLM topo de linha, compreens√£o, racioc√≠nio e gera√ß√£o textual.                                                               |
    | baichuan-inc/baichuan2-13b-chat             | 4.096 tokens       | Suporte a chat em chin√™s/ingl√™s, programa√ß√£o, matem√°tica, seguir instru√ß√µes, resolver quizzes.                              |
  </Accordion>

  <Accordion title="Local NVIDIA NIM Deployed using WSL2">
    O NVIDIA NIM permite rodar LLMs potentes localmente em m√°quinas Windows usando WSL2 (Windows Subsystem for Linux).
    Este m√©todo aproveita o GPU NVIDIA para infer√™ncia privativa, segura e econ√¥mica, sem depender de servi√ßos em nuvem.
    Perfeito para desenvolvimento, testes ou produ√ß√£o onde privacidade ou funcionalidades offline s√£o necess√°rias.

    Aqui est√° um guia passo a passo para configurar um modelo local NVIDIA NIM:

    1. Siga as instru√ß√µes de instala√ß√£o no [site da NVIDIA](https://docs.nvidia.com/nim/wsl2/latest/getting-started.html)

    2. Instale o modelo local. Para Llama 3.1-8b siga as [instru√ß√µes](https://build.nvidia.com/meta/llama-3_1-8b-instruct/deploy)

    3. Configure seus modelos locais crewai:

    ```python Code
    from crewai.llm import LLM

    local_nvidia_nim_llm = LLM(
        model="openai/meta/llama-3.1-8b-instruct", # √© compat√≠vel com openai-api
        base_url="http://localhost:8000/v1",
        api_key="<your_api_key|any text if you have not configured it>", # api_key obrigat√≥rio, pode usar qualquer texto
    )

    # Ent√£o pode us√°-lo no seu crew:

    @CrewBase
    class MyCrew():
        # ...

        @agent
        def researcher(self) -> Agent:
            return Agent(
                config=self.agents_config['researcher'], # type: ignore[index]
                llm=local_nvidia_nim_llm
            )

        # ...
    ```
  </Accordion>

  <Accordion title="Groq">
    Defina as seguintes vari√°veis de ambiente no seu arquivo `.env`:

    ```toml Code
    GROQ_API_KEY=<your-api-key>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="groq/llama-3.2-90b-text-preview",
        temperature=0.7
    )
    ```

    | Modelo           | Janela de Contexto | Melhor Para                                   |
    | ---------------- | ------------------ | --------------------------------------------- |
    | Llama 3.1 70B/8B | 131.072 tokens     | Alta performance e tarefas de contexto grande |
    | Llama 3.2 S√©rie  | 8.192 tokens       | Tarefas gerais                                |
    | Mixtral 8x7B     | 32.768 tokens      | Equil√≠brio entre performance e contexto       |
  </Accordion>

  <Accordion title="IBM watsonx.ai">
    Defina as seguintes vari√°veis de ambiente no seu arquivo `.env`:

    ```toml Code
    # Obrigat√≥rio
    WATSONX_URL=<your-url>
    WATSONX_APIKEY=<your-apikey>
    WATSONX_PROJECT_ID=<your-project-id>

    # Opcional
    WATSONX_TOKEN=<your-token>
    WATSONX_DEPLOYMENT_SPACE_ID=<your-space-id>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="watsonx/meta-llama/llama-3-1-70b-instruct",
        base_url="https://api.watsonx.ai/v1"
    )
    ```
  </Accordion>

  <Accordion title="Ollama (LLMs Locais)">
    1. Instale o Ollama: [ollama.ai](https://ollama.ai/)
    2. Rode um modelo: `ollama run llama3`
    3. Configure:

    ```python Code
    llm = LLM(
        model="ollama/llama3:70b",
        base_url="http://localhost:11434"
    )
    ```
  </Accordion>

  <Accordion title="Fireworks AI">
    Defina as seguintes vari√°veis de ambiente no seu arquivo `.env`:

    ```toml Code
    FIREWORKS_API_KEY=<your-api-key>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="fireworks_ai/accounts/fireworks/models/llama-v3-70b-instruct",
        temperature=0.7
    )
    ```
  </Accordion>

  <Accordion title="Perplexity AI">
    Defina as seguintes vari√°veis de ambiente no seu arquivo `.env`:

    ```toml Code
    PERPLEXITY_API_KEY=<your-api-key>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="llama-3.1-sonar-large-128k-online",
        base_url="https://api.perplexity.ai/"
    )
    ```
  </Accordion>

  <Accordion title="Hugging Face">
    Defina as seguintes vari√°veis de ambiente no seu arquivo `.env`:

    ```toml Code
    HF_TOKEN=<your-api-key>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="huggingface/meta-llama/Meta-Llama-3.1-8B-Instruct"
    )
    ```
  </Accordion>

  <Accordion title="SambaNova">
    Defina as seguintes vari√°veis de ambiente no seu arquivo `.env`:

    ```toml Code
    SAMBANOVA_API_KEY=<your-api-key>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="sambanova/Meta-Llama-3.1-8B-Instruct",
        temperature=0.7
    )
    ```

    | Modelo           | Janela de Contexto | Melhor Para                                  |
    | ---------------- | ------------------ | -------------------------------------------- |
    | Llama 3.1 70B/8B | At√© 131.072 tokens | Alto desempenho, tarefas com grande contexto |
    | Llama 3.1 405B   | 8.192 tokens       | Desempenho e qualidade de sa√≠da elevada      |
    | Llama 3.2 S√©rie  | 8.192 tokens       | Tarefas gerais e multimodais                 |
    | Llama 3.3 70B    | At√© 131.072 tokens | Desempenho e qualidade de sa√≠da elevada      |
    | Fam√≠lia Qwen2    | 8.192 tokens       | Desempenho e qualidade de sa√≠da elevada      |
  </Accordion>

  <Accordion title="Cerebras">
    Defina as seguintes vari√°veis de ambiente no seu arquivo `.env`:

    ```toml Code
    # Obrigat√≥rio
    CEREBRAS_API_KEY=<your-api-key>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="cerebras/llama3.1-70b",
        temperature=0.7,
        max_tokens=8192
    )
    ```

    <Info>
      Recursos do Cerebras:

      * Altas velocidades de infer√™ncia
      * Pre√ßos competitivos
      * Equil√≠brio entre velocidade e qualidade
      * Suporte a longas janelas de contexto
    </Info>
  </Accordion>

  <Accordion title="Open Router">
    Defina as seguintes vari√°veis de ambiente no seu arquivo `.env`:

    ```toml Code
    OPENROUTER_API_KEY=<your-api-key>
    ```

    Exemplo de uso em seu projeto CrewAI:

    ```python Code
    llm = LLM(
        model="openrouter/deepseek/deepseek-r1",
        base_url="https://openrouter.ai/api/v1",
        api_key=OPENROUTER_API_KEY
    )
    ```

    <Info>
      Modelos do Open Router:

      * openrouter/deepseek/deepseek-r1
      * openrouter/deepseek/deepseek-chat
    </Info>
  </Accordion>
</AccordionGroup>

## Respostas em streaming

O CrewAI suporta respostas em streaming de LLMs, permitindo que sua aplica√ß√£o receba e processe sa√≠das em tempo real assim que s√£o geradas.

<Tabs>
  <Tab title="Configura√ß√£o B√°sica">
    Ative o streaming definindo o par√¢metro `stream` como `True` ao inicializar seu LLM:

    ```python
    from crewai import LLM

    # Crie um LLM com streaming ativado
    llm = LLM(
        model="openai/gpt-4o",
        stream=True  # Ativar streaming
    )
    ```

    Quando o streaming est√° ativado, as respostas s√£o entregues em partes √† medida que v√£o sendo geradas, criando uma experi√™ncia mais responsiva para o usu√°rio.
  </Tab>

  <Tab title="Manipula√ß√£o de Eventos">
    O CrewAI emite eventos para cada chunk recebido durante o streaming:

    ```python
    from crewai.utilities.events import (
      LLMStreamChunkEvent
    )
    from crewai.utilities.events.base_event_listener import BaseEventListener

    class MyCustomListener(BaseEventListener):
        def setup_listeners(self, crewai_event_bus):
            @crewai_event_bus.on(LLMStreamChunkEvent)
            def on_llm_stream_chunk(self, event: LLMStreamChunkEvent):
              # Clique para cada chunk assim que chegar
              print(f"Received chunk: {event.chunk}")

    my_listener = MyCustomListener()
    ```

    <Tip>
      [Clique aqui](https://docs.crewai.com/concepts/event-listener#event-listeners) para mais detalhes
    </Tip>
  </Tab>
</Tabs>

## Chamada Estruturada de LLM

O CrewAI suporta respostas estruturadas de LLMs permitindo que voc√™ defina um `response_format` usando um modelo Pydantic. Isso permite que o framework automaticamente fa√ßa o parsing e valide a sa√≠da, facilitando a integra√ß√£o da resposta em sua aplica√ß√£o sem p√≥s-processamento manual.

Por exemplo, √© poss√≠vel definir um modelo Pydantic para representar a resposta esperada e pass√°-lo como `response_format` ao instanciar o LLM. O modelo ser√° utilizado para converter a resposta do LLM em um objeto Python estruturado.

```python Code
from crewai import LLM

class Dog(BaseModel):
    name: str
    age: int
    breed: str


llm = LLM(model="gpt-4o", response_format=Dog)

response = llm.call(
    "Analyze the following messages and return the name, age, and breed. "
    "Meet Kona! She is 3 years old and is a black german shepherd."
)
print(response)

# Output:
# Dog(name='Kona', age=3, breed='black german shepherd')
```

## Recursos Avan√ßados e Otimiza√ß√£o

Saiba como obter o m√°ximo da configura√ß√£o do seu LLM:

<AccordionGroup>
  <Accordion title="Gest√£o da Janela de Contexto">
    O CrewAI inclui recursos inteligentes para gerenciamento de contexto:

    ```python
    from crewai import LLM

    # O CrewAI automaticamente gerencia:
    # 1. Contagem e acompanhamento de tokens
    # 2. Resumo de conte√∫do quando necess√°rio
    # 3. Divis√£o de tarefas para grandes contextos

    llm = LLM(
        model="gpt-4",
        max_tokens=4000,  # Limitar tamanho da resposta
    )
    ```

    <Info>
      Boas pr√°ticas para o gerenciamento de contexto:

      1. Prefira modelos com janelas apropriadas
      2. Pr√©-processe entradas muito longas
      3. Utilize divis√£o para documentos grandes
      4. Monitore tokens para otimizar custos
    </Info>
  </Accordion>

  <Accordion title="Otimiza√ß√£o de Performance">
    <Steps>
      <Step title="Otimiza√ß√£o do Uso de Tokens">
        Escolha a janela de contexto certa para sua tarefa:

        * Tarefas pequenas (at√© 4K tokens): Modelos padr√£o
        * Tarefas m√©dias (entre 4K-32K): Modelos aprimorados
        * Tarefas grandes (acima de 32K): Modelos com contexto expandido

        ```python
        # Configure o modelo com as op√ß√µes certas
        llm = LLM(
            model="openai/gpt-4-turbo-preview",
            temperature=0.7,    # Ajuste conforme a tarefa
            max_tokens=4096,    # Defina conforme a necessidade da sa√≠da
            timeout=300        # Timeout maior para tarefas complexas
        )
        ```

        <Tip>
          * Temperaturas baixas (0.1 a 0.3) para respostas factuais
          * Temperaturas altas (0.7 a 0.9) para tarefas criativas
        </Tip>
      </Step>

      <Step title="Boas Pr√°ticas">
        1. Monitore o uso de tokens
        2. Implemente limites de taxa (rate limiting)
        3. Use cache quando poss√≠vel
        4. Defina limites apropriados para max\_tokens
      </Step>
    </Steps>

    <Info>
      Lembre-se de monitorar regularmente o uso de tokens e ajustar suas configura√ß√µes para otimizar custos e desempenho.
    </Info>
  </Accordion>

  <Accordion title="Descartar Par√¢metros Adicionais">
    O CrewAI usa Litellm internamente para chamadas LLM, permitindo descartar par√¢metros adicionais desnecess√°rios para seu caso de uso. Isso pode simplificar seu c√≥digo e reduzir a complexidade da configura√ß√£o do LLM.
    Por exemplo, se n√£o precisar enviar o par√¢metro <code>stop</code>, basta omiti-lo na chamada do LLM:

    ```python
    from crewai import LLM
    import os

    os.environ["OPENAI_API_KEY"] = "<api-key>"

    o3_llm = LLM(
        model="o3",
        drop_params=True,
        additional_drop_params=["stop"]
    )
    ```
  </Accordion>
</AccordionGroup>

## Problemas Comuns e Solu√ß√µes

<Tabs>
  <Tab title="Autentica√ß√£o">
    <Warning>
      A maioria dos problemas de autentica√ß√£o pode ser resolvida verificando o formato da chave da API e os nomes das vari√°veis de ambiente.
    </Warning>

    ```bash
    # OpenAI
    OPENAI_API_KEY=sk-...

    # Anthropic
    ANTHROPIC_API_KEY=sk-ant-...
    ```
  </Tab>

  <Tab title="Nomes dos Modelos">
    <Check>
      Sempre inclua o prefixo do provedor nos nomes dos modelos
    </Check>

    ```python
    # Correto
    llm = LLM(model="openai/gpt-4")

    # Incorreto
    llm = LLM(model="gpt-4")
    ```
  </Tab>

  <Tab title="Comprimento do Contexto">
    <Tip>
      Use modelos de contexto expandido para tarefas extensas
    </Tip>

    ```python
    # Modelo com contexto expandido
    llm = LLM(model="openai/gpt-4o")  # 128K tokens
    ```
  </Tab>
</Tabs>


# Mem√≥ria
Source: https://docs.crewai.com/pt-BR/concepts/memory

Aproveitando sistemas de mem√≥ria no framework CrewAI para aprimorar as capacidades dos agentes.

## Vis√£o Geral

O framework CrewAI oferece um sistema de mem√≥ria sofisticado projetado para aprimorar significativamente as capacidades dos agentes de IA. O CrewAI disponibiliza **tr√™s abordagens distintas de mem√≥ria** que atendem a diferentes casos de uso:

1. **Sistema B√°sico de Mem√≥ria** - Mem√≥ria de curto prazo, longo prazo e de entidades integradas
2. **Mem√≥ria de Usu√°rio** - Mem√≥ria espec√≠fica do usu√°rio com integra√ß√£o ao Mem0 (abordagem legada)
3. **Mem√≥ria Externa** - Provedores de mem√≥ria externos aut√¥nomos (nova abordagem)

## Componentes do Sistema de Mem√≥ria

| Componente                 | Descri√ß√£o                                                                                                                                                                                                                                     |
| :------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Mem√≥ria de Curto Prazo** | Armazena temporariamente intera√ß√µes e resultados recentes usando `RAG`, permitindo que os agentes recordem e utilizem informa√ß√µes relevantes ao contexto atual durante as execu√ß√µes.                                                          |
| **Mem√≥ria de Longo Prazo** | Preserva informa√ß√µes valiosas e aprendizados de execu√ß√µes passadas, permitindo que os agentes construam e refinem seu conhecimento ao longo do tempo.                                                                                         |
| **Mem√≥ria de Entidades**   | Captura e organiza informa√ß√µes sobre entidades (pessoas, lugares, conceitos) encontradas durante tarefas, facilitando um entendimento mais profundo e o mapeamento de relacionamentos. Utiliza `RAG` para armazenar informa√ß√µes de entidades. |
| **Mem√≥ria Contextual**     | Mant√©m o contexto das intera√ß√µes combinando `ShortTermMemory`, `LongTermMemory` e `EntityMemory`, auxiliando na coer√™ncia e relev√¢ncia das respostas dos agentes ao longo de uma sequ√™ncia de tarefas ou conversas.                           |

## 1. Sistema B√°sico de Mem√≥ria (Recomendado)

A abordagem mais simples e comum de uso. Ative a mem√≥ria para sua crew com um √∫nico par√¢metro:

### In√≠cio R√°pido

```python
from crewai import Crew, Agent, Task, Process

# Habilitar o sistema b√°sico de mem√≥ria
crew = Crew(
    agents=[...],
    tasks=[...],
    process=Process.sequential,
    memory=True,  # Ativa mem√≥ria de curto prazo, longo prazo e de entidades
    verbose=True
)
```

### Como Funciona

* **Mem√≥ria de Curto Prazo**: Usa ChromaDB com RAG para o contexto atual
* **Mem√≥ria de Longo Prazo**: Usa SQLite3 para armazenar resultados de tarefas entre sess√µes
* **Mem√≥ria de Entidades**: Usa RAG para rastrear entidades (pessoas, lugares, conceitos)
* **Local de Armazenamento**: Localidade espec√≠fica da plataforma via pacote `appdirs`
* **Diret√≥rio de Armazenamento Personalizado**: Defina a vari√°vel de ambiente `CREWAI_STORAGE_DIR`

## Transpar√™ncia no Local de Armazenamento

<Info>
  **Compreendendo os Locais de Armazenamento**: CrewAI utiliza diret√≥rios espec√≠ficos da plataforma para guardar arquivos de mem√≥ria e conhecimento seguindo as conven√ß√µes do sistema operacional. Conhecer esses locais ajuda na implanta√ß√£o em produ√ß√£o, backups e depura√ß√£o.
</Info>

### Onde o CrewAI Armazena os Arquivos

Por padr√£o, o CrewAI usa a biblioteca `appdirs` para determinar os locais de armazenamento conforme a conven√ß√£o da plataforma. Veja exatamente onde seus arquivos s√£o armazenados:

#### Locais de Armazenamento Padr√£o por Plataforma

**macOS:**

```
~/Library/Application Support/CrewAI/{project_name}/
‚îú‚îÄ‚îÄ knowledge/           # Arquivos base de conhecimento ChromaDB
‚îú‚îÄ‚îÄ short_term_memory/   # Arquivos de mem√≥ria de curto prazo ChromaDB
‚îú‚îÄ‚îÄ long_term_memory/    # Arquivos de mem√≥ria de longo prazo ChromaDB
‚îú‚îÄ‚îÄ entities/            # Arquivos de mem√≥ria de entidades ChromaDB
‚îî‚îÄ‚îÄ long_term_memory_storage.db  # Banco de dados SQLite
```

**Linux:**

```
~/.local/share/CrewAI/{project_name}/
‚îú‚îÄ‚îÄ knowledge/
‚îú‚îÄ‚îÄ short_term_memory/
‚îú‚îÄ‚îÄ long_term_memory/
‚îú‚îÄ‚îÄ entities/
‚îî‚îÄ‚îÄ long_term_memory_storage.db
```

**Windows:**

```
C:\Users\{username}\AppData\Local\CrewAI\{project_name}\
‚îú‚îÄ‚îÄ knowledge\
‚îú‚îÄ‚îÄ short_term_memory\
‚îú‚îÄ‚îÄ long_term_memory\
‚îú‚îÄ‚îÄ entities\
‚îî‚îÄ‚îÄ long_term_memory_storage.db
```

### Encontrando Seu Local de Armazenamento

Para ver exatamente onde o CrewAI est√° armazenando arquivos em seu sistema:

```python
from crewai.utilities.paths import db_storage_path
import os

# Obter o caminho base de armazenamento
storage_path = db_storage_path()
print(f"CrewAI storage location: {storage_path}")

# Listar todos os diret√≥rios e arquivos do CrewAI
if os.path.exists(storage_path):
    print("\nStored files and directories:")
    for item in os.listdir(storage_path):
        item_path = os.path.join(storage_path, item)
        if os.path.isdir(item_path):
            print(f"üìÅ {item}/")
            # Exibir cole√ß√µes ChromaDB
            if os.path.exists(item_path):
                for subitem in os.listdir(item_path):
                    print(f"   ‚îî‚îÄ‚îÄ {subitem}")
        else:
            print(f"üìÑ {item}")
else:
    print("No CrewAI storage directory found yet.")
```

### Controlando Locais de Armazenamento

#### Op√ß√£o 1: Vari√°vel de Ambiente (Recomendado)

```python
import os
from crewai import Crew

# Definir local de armazenamento personalizado
os.environ["CREWAI_STORAGE_DIR"] = "./my_project_storage"

# Toda a mem√≥ria e conhecimento ser√£o salvos em ./my_project_storage/
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True
)
```

#### Op√ß√£o 2: Caminho de Armazenamento Personalizado

```python
import os
from crewai import Crew
from crewai.memory import LongTermMemory
from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage

# Configurar local de armazenamento personalizado
custom_storage_path = "./storage"
os.makedirs(custom_storage_path, exist_ok=True)

crew = Crew(
    memory=True,
    long_term_memory=LongTermMemory(
        storage=LTMSQLiteStorage(
            db_path=f"{custom_storage_path}/memory.db"
        )
    )
)
```

#### Op√ß√£o 3: Armazenamento Espec√≠fico de Projeto

```python
import os
from pathlib import Path

# Armazenar no diret√≥rio do projeto
project_root = Path(__file__).parent
storage_dir = project_root / "crewai_storage"

os.environ["CREWAI_STORAGE_DIR"] = str(storage_dir)

# Todo o armazenamento ficar√° agora na pasta do projeto
```

### Padr√£o do Provedor de Embedding

<Info>
  **Provedor de Embedding Padr√£o**: O CrewAI utiliza embeddings do OpenAI por padr√£o para garantir consist√™ncia e confiabilidade. Voc√™ pode facilmente customizar para combinar com seu provedor LLM ou utilizar embeddings locais.
</Info>

#### Compreendendo o Comportamento Padr√£o

```python
# Ao utilizar Claude como seu LLM...
from crewai import Agent, LLM

agent = Agent(
    role="Analyst",
    goal="Analyze data",
    backstory="Expert analyst",
    llm=LLM(provider="anthropic", model="claude-3-sonnet")  # Usando Claude
)

# O CrewAI usar√° embeddings OpenAI por padr√£o para garantir consist√™ncia
# Voc√™ pode customizar facilmente para combinar com seu provedor preferido
```

#### Personalizando Provedores de Embedding

```python
from crewai import Crew

# Op√ß√£o 1: Combinar com seu provedor de LLM
crew = Crew(
    agents=[agent],
    tasks=[task],
    memory=True,
    embedder={
        "provider": "anthropic",  # Combine com seu provedor de LLM
        "config": {
            "api_key": "your-anthropic-key",
            "model": "text-embedding-3-small"
        }
    }
)

# Op√ß√£o 2: Use embeddings locais (sem chamadas para API externa)
crew = Crew(
    agents=[agent],
    tasks=[task],
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    }
)
```

### Depura√ß√£o de Problemas de Armazenamento

#### Verifique Permiss√µes do Armazenamento

```python
import os
from crewai.utilities.paths import db_storage_path

storage_path = db_storage_path()
print(f"Storage path: {storage_path}")
print(f"Path exists: {os.path.exists(storage_path)}")
print(f"Is writable: {os.access(storage_path, os.W_OK) if os.path.exists(storage_path) else 'Path does not exist'}")

# Crie com permiss√µes apropriadas
if not os.path.exists(storage_path):
    os.makedirs(storage_path, mode=0o755, exist_ok=True)
    print(f"Created storage directory: {storage_path}")
```

#### Inspecione Cole√ß√µes do ChromaDB

```python
import chromadb
from crewai.utilities.paths import db_storage_path

# Conecte-se ao ChromaDB do CrewAI
storage_path = db_storage_path()
chroma_path = os.path.join(storage_path, "knowledge")

if os.path.exists(chroma_path):
    client = chromadb.PersistentClient(path=chroma_path)
    collections = client.list_collections()

    print("ChromaDB Collections:")
    for collection in collections:
        print(f"  - {collection.name}: {collection.count()} documentos")
else:
    print("No ChromaDB storage found")
```

#### Resetar Armazenamento (Depura√ß√£o)

```python
from crewai import Crew

# Limpar todo o armazenamento de mem√≥ria
crew = Crew(agents=[...], tasks=[...], memory=True)

# Limpar tipos espec√≠ficos de mem√≥ria
crew.reset_memories(command_type='short')     # Mem√≥ria de curto prazo
crew.reset_memories(command_type='long')      # Mem√≥ria de longo prazo
crew.reset_memories(command_type='entity')    # Mem√≥ria de entidades
crew.reset_memories(command_type='knowledge') # Armazenamento de conhecimento
```

### Melhores Pr√°ticas para Produ√ß√£o

1. **Defina o `CREWAI_STORAGE_DIR`** para um local conhecido em produ√ß√£o para maior controle
2. **Escolha explicitamente provedores de embeddings** para coincidir com seu setup de LLM
3. **Monitore o tamanho do diret√≥rio de armazenamento** em casos de grande escala
4. **Inclua diret√≥rios de armazenamento** em sua pol√≠tica de backup
5. **Defina permiss√µes apropriadas de arquivo** (0o755 para diret√≥rios, 0o644 para arquivos)
6. **Use caminhos relativos ao projeto** para implanta√ß√µes containerizadas

### Problemas Comuns de Armazenamento

**Erros "ChromaDB permission denied":**

```bash
# Corrija permiss√µes
chmod -R 755 ~/.local/share/CrewAI/
```

**Erros "Database is locked":**

```python
# Certifique-se que apenas uma inst√¢ncia CrewAI acesse o armazenamento
import fcntl
import os

storage_path = db_storage_path()
lock_file = os.path.join(storage_path, ".crewai.lock")

with open(lock_file, 'w') as f:
    fcntl.flock(f.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
    # Seu c√≥digo CrewAI aqui
```

**Armazenamento n√£o persiste entre execu√ß√µes:**

```python
# Verifique se o local do armazenamento √© consistente
import os
print("CREWAI_STORAGE_DIR:", os.getenv("CREWAI_STORAGE_DIR"))
print("Current working directory:", os.getcwd())
print("Computed storage path:", db_storage_path())
```

## Configura√ß√£o Personalizada de Embedders

O CrewAI suporta m√∫ltiplos provedores de embeddings para oferecer flexibilidade na escolha da melhor op√ß√£o para seu caso de uso. Aqui est√° um guia completo para configura√ß√£o de diferentes provedores de embeddings para seu sistema de mem√≥ria.

### Por que Escolher Diferentes Provedores de Embeddings?

* **Otimiza√ß√£o de Custos**: Embeddings locais (Ollama) s√£o gratuitos ap√≥s configura√ß√£o inicial
* **Privacidade**: Mantenha seus dados locais com Ollama ou use seu provedor preferido na nuvem
* **Desempenho**: Alguns modelos t√™m melhor desempenho para dom√≠nios ou idiomas espec√≠ficos
* **Consist√™ncia**: Combine seu provedor de embedding com o de LLM
* **Conformidade**: Atenda a requisitos regulat√≥rios ou organizacionais

### OpenAI Embeddings (Padr√£o)

A OpenAI oferece embeddings confi√°veis e de alta qualidade para a maioria dos cen√°rios.

```python
from crewai import Crew

# Configura√ß√£o b√°sica OpenAI (usa a vari√°vel de ambiente OPENAI_API_KEY)
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "model": "text-embedding-3-small"  # ou "text-embedding-3-large"
        }
    }
)

# Configura√ß√£o avan√ßada OpenAI
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "api_key": "your-openai-api-key",  # Opcional: sobrescreve vari√°vel de ambiente
            "model": "text-embedding-3-large",
            "dimensions": 1536,  # Opcional: reduz as dimens√µes para armazenamento menor
            "organization_id": "your-org-id"  # Opcional: para contas organizacionais
        }
    }
)
```

### Azure OpenAI Embeddings

Para empresas que utilizam deploys Azure OpenAI.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",  # Use openai como provider para Azure
        "config": {
            "api_key": "your-azure-api-key",
            "api_base": "https://your-resource.openai.azure.com/",
            "api_type": "azure",
            "api_version": "2023-05-15",
            "model": "text-embedding-3-small",
            "deployment_id": "your-deployment-name"  # Nome do deploy Azure
        }
    }
)
```

### Google AI Embeddings

Use modelos de embeddings de texto do Google para integra√ß√£o com servi√ßos do Google Cloud.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "google",
        "config": {
            "api_key": "your-google-api-key",
            "model": "text-embedding-004"  # ou "text-embedding-preview-0409"
        }
    }
)
```

### Vertex AI Embeddings

Para usu√°rios do Google Cloud com acesso ao Vertex AI.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "vertexai",
        "config": {
            "project_id": "your-gcp-project-id",
            "region": "us-central1",  # ou sua regi√£o preferencial
            "api_key": "your-service-account-key",
            "model_name": "textembedding-gecko"
        }
    }
)
```

### Ollama Embeddings (Local)

Execute embeddings localmente para privacidade e economia.

```python
# Primeiro, instale e rode Ollama localmente, depois baixe um modelo de embedding:
# ollama pull mxbai-embed-large

crew = Crew(
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {
            "model": "mxbai-embed-large",  # ou "nomic-embed-text"
            "url": "http://localhost:11434/api/embeddings"  # URL padr√£o do Ollama
        }
    }
)

# Para instala√ß√µes personalizadas do Ollama
crew = Crew(
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {
            "model": "mxbai-embed-large",
            "url": "http://your-ollama-server:11434/api/embeddings"
        }
    }
)
```

### Cohere Embeddings

Utilize os modelos de embedding da Cohere para suporte multil√≠ngue.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "cohere",
        "config": {
            "api_key": "your-cohere-api-key",
            "model": "embed-english-v3.0"  # ou "embed-multilingual-v3.0"
        }
    }
)
```

### VoyageAI Embeddings

Embeddings de alto desempenho otimizados para tarefas de recupera√ß√£o.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "voyageai",
        "config": {
            "api_key": "your-voyage-api-key",
            "model": "voyage-large-2",  # ou "voyage-code-2" para c√≥digo
            "input_type": "document"  # ou "query"
        }
    }
)
```

### AWS Bedrock Embeddings

Para usu√°rios AWS com acesso ao Bedrock.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "bedrock",
        "config": {
            "aws_access_key_id": "your-access-key",
            "aws_secret_access_key": "your-secret-key",
            "region_name": "us-east-1",
            "model": "amazon.titan-embed-text-v1"
        }
    }
)
```

### Hugging Face Embeddings

Utilize modelos open-source do Hugging Face.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "huggingface",
        "config": {
            "api_key": "your-hf-token",  # Opcional para modelos p√∫blicos
            "model": "sentence-transformers/all-MiniLM-L6-v2",
            "api_url": "https://api-inference.huggingface.co"  # ou seu endpoint customizado
        }
    }
)
```

### IBM Watson Embeddings

Para usu√°rios do IBM Cloud.

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "watson",
        "config": {
            "api_key": "your-watson-api-key",
            "url": "your-watson-instance-url",
            "model": "ibm/slate-125m-english-rtrvr"
        }
    }
)
```

### Como Escolher o Provedor de Embedding Certo

| Provedor         | Melhor Para                    | Pr√≥s                        | Contras                    |
| :--------------- | :----------------------------- | :-------------------------- | :------------------------- |
| **OpenAI**       | Uso geral, confiabilidade      | Alta qualidade, bem testado | Custo, requer chave de API |
| **Ollama**       | Privacidade, economia          | Gratuito, local, privado    | Requer configura√ß√£o local  |
| **Google AI**    | Ecossistema Google             | Bom desempenho              | Requer conta Google        |
| **Azure OpenAI** | Empresas, conformidade         | Recursos corporativos       | Configura√ß√£o mais complexa |
| **Cohere**       | Conte√∫do multil√≠ngue           | Excelente suporte a idiomas | Uso especializado          |
| **VoyageAI**     | Tarefas de busca e recupera√ß√£o | Otimizado para pesquisa     | Provedor mais novo         |

### Configura√ß√£o via Vari√°vel de Ambiente

Para seguran√ßa, armazene chaves de API em vari√°veis de ambiente:

```python
import os

# Configurar vari√°veis de ambiente
os.environ["OPENAI_API_KEY"] = "your-openai-key"
os.environ["GOOGLE_API_KEY"] = "your-google-key"
os.environ["COHERE_API_KEY"] = "your-cohere-key"

# Use sem expor as chaves no c√≥digo
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "model": "text-embedding-3-small"
            # A chave de API ser√° carregada automaticamente da vari√°vel de ambiente
        }
    }
)
```

### Testando Diferentes Provedores de Embedding

Compare provedores de embedding para o seu caso de uso espec√≠fico:

```python
from crewai import Crew
from crewai.utilities.paths import db_storage_path

# Testar diferentes provedores com os mesmos dados
providers_to_test = [
    {
        "name": "OpenAI",
        "config": {
            "provider": "openai",
            "config": {"model": "text-embedding-3-small"}
        }
    },
    {
        "name": "Ollama",
        "config": {
            "provider": "ollama",
            "config": {"model": "mxbai-embed-large"}
        }
    }
]

for provider in providers_to_test:
    print(f"\nTesting {provider['name']} embeddings...")

    # Criar crew com embedder espec√≠fico
    crew = Crew(
        agents=[...],
        tasks=[...],
        memory=True,
        embedder=provider['config']
    )

    # Execute o teste e me√ßa o desempenho
    result = crew.kickoff()
    print(f"{provider['name']} completed successfully")
```

### Solu√ß√£o de Problemas de Embeddings

**Erros de modelo n√£o encontrado:**

```python
# Verifique disponibilidade do modelo
from crewai.utilities.embedding_configurator import EmbeddingConfigurator

configurator = EmbeddingConfigurator()
try:
    embedder = configurator.configure_embedder({
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    })
    print("Embedder configured successfully")
except Exception as e:
    print(f"Configuration error: {e}")
```

**Problemas com chave de API:**

```python
import os

# Verifique se as chaves de API est√£o configuradas
required_keys = ["OPENAI_API_KEY", "GOOGLE_API_KEY", "COHERE_API_KEY"]
for key in required_keys:
    if os.getenv(key):
        print(f"‚úÖ {key} is set")
    else:
        print(f"‚ùå {key} is not set")
```

**Compara√ß√£o de desempenho:**

```python
import time

def test_embedding_performance(embedder_config, test_text="This is a test document"):
    start_time = time.time()

    crew = Crew(
        agents=[...],
        tasks=[...],
        memory=True,
        embedder=embedder_config
    )

    # Simula opera√ß√£o de mem√≥ria
    crew.kickoff()

    end_time = time.time()
    return end_time - start_time

# Comparar desempenho
openai_time = test_embedding_performance({
    "provider": "openai",
    "config": {"model": "text-embedding-3-small"}
})

ollama_time = test_embedding_performance({
    "provider": "ollama",
    "config": {"model": "mxbai-embed-large"}
})

print(f"OpenAI: {openai_time:.2f}s")
print(f"Ollama: {ollama_time:.2f}s")
```

## 2. Mem√≥ria de Usu√°rio com Mem0 (Legado)

<Warning>
  **Abordagem Legada**: Embora totalmente funcional, esta abordagem √© considerada legada. Para novos projetos que exijam mem√≥ria espec√≠fica do usu√°rio, considere usar Mem√≥ria Externa.
</Warning>

A Mem√≥ria de Usu√°rio se integra com o [Mem0](https://mem0.ai/) para fornecer mem√≥ria espec√≠fica do usu√°rio que persiste entre sess√µes e se integra ao sistema de mem√≥ria contextual da crew.

### Pr√©-requisitos

```bash
pip install mem0ai
```

### Configura√ß√£o Mem0 na Nuvem

```python
import os
from crewai import Crew, Process

# Defina sua chave de API do Mem0
os.environ["MEM0_API_KEY"] = "m0-your-api-key"

crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,  # Necess√°rio para integra√ß√£o com a mem√≥ria contextual
    memory_config={
        "provider": "mem0",
        "config": {"user_id": "john"},
        "user_memory": {}  # Obrigat√≥rio - inicializa a mem√≥ria de usu√°rio
    },
    process=Process.sequential,
    verbose=True
)
```

### Configura√ß√£o Avan√ßada Mem0

```python
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,
    memory_config={
        "provider": "mem0",
        "config": {
            "user_id": "john",
            "org_id": "my_org_id",        # Opcional
            "project_id": "my_project_id", # Opcional
            "api_key": "custom-api-key"    # Opcional - sobrescreve vari√°vel de ambiente
        },
        "user_memory": {}
    }
)
```

### Configura√ß√£o Mem0 Local

```python
crew = Crew(
    agents=[...],
    tasks=[...],
    memory=True,
    memory_config={
        "provider": "mem0",
        "config": {
            "user_id": "john",
            "local_mem0_config": {
                "vector_store": {
                    "provider": "qdrant",
                    "config": {"host": "localhost", "port": 6333}
                },
                "llm": {
                    "provider": "openai",
                    "config": {"api_key": "your-api-key", "model": "gpt-4"}
                },
                "embedder": {
                    "provider": "openai",
                    "config": {"api_key": "your-api-key", "model": "text-embedding-3-small"}
                }
            }
        },
        "user_memory": {}
    }
)
```

## 3. Mem√≥ria Externa (Nova Abordagem)

A Mem√≥ria Externa fornece um sistema de mem√≥ria aut√¥nomo que opera independentemente da mem√≥ria interna da crew. Isso √© ideal para provedores de mem√≥ria especializados ou compartilhamento de mem√≥ria entre aplica√ß√µes.

### Mem√≥ria Externa B√°sica com Mem0

```python
import os
from crewai import Agent, Crew, Process, Task
from crewai.memory.external.external_memory import ExternalMemory

os.environ["MEM0_API_KEY"] = "your-api-key"

# Criar inst√¢ncia de mem√≥ria externa
external_memory = ExternalMemory(
    embedder_config={
        "provider": "mem0",
        "config": {"user_id": "U-123"}
    }
)

crew = Crew(
    agents=[...],
    tasks=[...],
    external_memory=external_memory,  # Independente da mem√≥ria b√°sica
    process=Process.sequential,
    verbose=True
)
```

### Implementa√ß√£o Personalizada de Armazenamento

```python
from crewai.memory.external.external_memory import ExternalMemory
from crewai.memory.storage.interface import Storage

class CustomStorage(Storage):
    def __init__(self):
        self.memories = []

    def save(self, value, metadata=None, agent=None):
        self.memories.append({
            "value": value,
            "metadata": metadata,
            "agent": agent
        })

    def search(self, query, limit=10, score_threshold=0.5):
        # Implemente sua l√≥gica de busca aqui
        return [m for m in self.memories if query.lower() in str(m["value"]).lower()]

    def reset(self):
        self.memories = []

# Usando armazenamento customizado
external_memory = ExternalMemory(storage=CustomStorage())

crew = Crew(
    agents=[...],
    tasks=[...],
    external_memory=external_memory
)
```

## Compara√ß√£o dos Sistemas de Mem√≥ria

| Recurso                       | Mem√≥ria B√°sica       | Mem√≥ria de Usu√°rio (Legado)        | Mem√≥ria Externa             |
| ----------------------------- | -------------------- | ---------------------------------- | --------------------------- |
| **Complexidade de Setup**     | Simples              | M√©dia                              | M√©dia                       |
| **Integra√ß√£o**                | Contextual integrada | Contextual + espec√≠fica do usu√°rio | Aut√¥noma                    |
| **Armazenamento**             | Arquivos locais      | Mem0 Cloud/Local                   | Customizada/Mem0            |
| **Multi-sess√£o**              | ‚úÖ                    | ‚úÖ                                  | ‚úÖ                           |
| **Especificidade do Usu√°rio** | ‚ùå                    | ‚úÖ                                  | ‚úÖ                           |
| **Provedores Customizados**   | Limitado             | Apenas Mem0                        | Qualquer provedor           |
| **Recomendado para**          | Maioria dos casos    | Projetos legados                   | Necessidades especializadas |

## Provedores de Embedding Suportados

### OpenAI (Padr√£o)

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {"model": "text-embedding-3-small"}
    }
)
```

### Ollama

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "ollama",
        "config": {"model": "mxbai-embed-large"}
    }
)
```

### Google AI

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "google",
        "config": {
            "api_key": "your-api-key",
            "model": "text-embedding-004"
        }
    }
)
```

### Azure OpenAI

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "api_key": "your-api-key",
            "api_base": "https://your-resource.openai.azure.com/",
            "api_version": "2023-05-15",
            "model_name": "text-embedding-3-small"
        }
    }
)
```

### Vertex AI

```python
crew = Crew(
    memory=True,
    embedder={
        "provider": "vertexai",
        "config": {
            "project_id": "your-project-id",
            "region": "your-region",
            "api_key": "your-api-key",
            "model_name": "textembedding-gecko"
        }
    }
)
```

## Melhores Pr√°ticas de Seguran√ßa

### Vari√°veis de Ambiente

```python
import os
from crewai import Crew

# Armazene dados sens√≠veis em vari√°veis de ambiente
crew = Crew(
    memory=True,
    embedder={
        "provider": "openai",
        "config": {
            "api_key": os.getenv("OPENAI_API_KEY"),
            "model": "text-embedding-3-small"
        }
    }
)
```

### Seguran√ßa no Armazenamento

```python
import os
from crewai import Crew
from crewai.memory import LongTermMemory
from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage

# Use caminhos seguros para armazenamento
storage_path = os.getenv("CREWAI_STORAGE_DIR", "./storage")
os.makedirs(storage_path, mode=0o700, exist_ok=True)  # Permiss√µes restritas

crew = Crew(
    memory=True,
    long_term_memory=LongTermMemory(
        storage=LTMSQLiteStorage(
            db_path=f"{storage_path}/memory.db"
        )
    )
)
```

## Solu√ß√£o de Problemas

### Problemas Comuns

**A mem√≥ria n√£o est√° persistindo entre sess√µes?**

* Verifique a vari√°vel de ambiente `CREWAI_STORAGE_DIR`
* Garanta permiss√µes de escrita no diret√≥rio de armazenamento
* Certifique-se que a mem√≥ria est√° ativada com `memory=True`

**Erros de autentica√ß√£o no Mem0?**

* Verifique se a vari√°vel de ambiente `MEM0_API_KEY` est√° definida
* Confira permiss√µes da chave de API no painel do Mem0
* Certifique-se de que o pacote `mem0ai` est√° instalado

**Alto uso de mem√≥ria com grandes volumes de dados?**

* Considere usar Mem√≥ria Externa com armazenamento personalizado
* Implemente pagina√ß√£o nos m√©todos de busca do armazenamento customizado
* Utilize modelos de embedding menores para menor consumo de mem√≥ria

### Dicas de Desempenho

* Use `memory=True` para a maioria dos casos (mais simples e r√°pido)
* S√≥ utilize Mem√≥ria de Usu√°rio se precisar de persist√™ncia espec√≠fica por usu√°rio
* Considere Mem√≥ria Externa para necessidades de grande escala ou especializadas
* Prefira modelos de embedding menores para maior rapidez
* Defina limites apropriados de busca para controlar o tamanho da recupera√ß√£o

## Benef√≠cios do Sistema de Mem√≥ria do CrewAI

* ü¶æ **Aprendizado Adaptativo:** As crews tornam-se mais eficientes ao longo do tempo, adaptando-se a novas informa√ß√µes e refinando sua abordagem para tarefas.
* ü´° **Personaliza√ß√£o Avan√ßada:** A mem√≥ria permite que agentes lembrem prefer√™ncias do usu√°rio e intera√ß√µes passadas, proporcionando experi√™ncias personalizadas.
* üß† **Melhoria na Resolu√ß√£o de Problemas:** O acesso a um rico acervo de mem√≥ria auxilia os agentes a tomar decis√µes mais informadas, recorrendo a aprendizados pr√©vios e contextuais.

## Conclus√£o

Integrar o sistema de mem√≥ria do CrewAI em seus projetos √© simples. Ao aproveitar os componentes e configura√ß√µes oferecidos,
voc√™ rapidamente capacita seus agentes a lembrar, raciocinar e aprender com suas intera√ß√µes, desbloqueando novos n√≠veis de intelig√™ncia e capacidade.


# Planejamento
Source: https://docs.crewai.com/pt-BR/concepts/planning

Aprenda como adicionar planejamento √† sua CrewAI Crew e melhorar sua performance.

## Vis√£o geral

O recurso de planejamento no CrewAI permite que voc√™ adicione capacidade de planejamento √† sua crew. Quando ativado, antes de cada itera√ß√£o da Crew, todas as informa√ß√µes da Crew s√£o enviadas para um AgentPlanner que ir√° planejar as tarefas passo a passo, e este plano ser√° adicionado √† descri√ß√£o de cada tarefa.

### Usando o recurso de Planejamento

Come√ßar a usar o recurso de planejamento √© muito simples, o √∫nico passo necess√°rio √© adicionar `planning=True` √† sua Crew:

<CodeGroup>
  ```python Code
  from crewai import Crew, Agent, Task, Process

  # Monte sua crew com capacidades de planejamento
  minha_crew = Crew(
      agents=self.agents,
      tasks=self.tasks,
      process=Process.sequential,
      planning=True,
  )
  ```
</CodeGroup>

A partir deste ponto, sua crew ter√° o planejamento ativado, e as tarefas ser√£o planejadas antes de cada itera√ß√£o.

<Warning>
  Quando o planejamento est√° ativado, o crewAI ir√° usar `gpt-4o-mini` como o LLM padr√£o para planejamento, o que requer uma chave de API v√°lida da OpenAI. Como seus agentes podem estar usando LLMs diferentes, isso pode causar confus√£o se voc√™ n√£o tiver uma chave de API da OpenAI configurada ou se estiver experimentando um comportamento inesperado relacionado a chamadas de API de LLM.
</Warning>

#### LLM de Planejamento

Agora voc√™ pode definir qual LLM ser√° usado para planejar as tarefas.

Ao executar o exemplo b√°sico, voc√™ ver√° algo semelhante ao resultado abaixo, que representa a sa√≠da do `AgentPlanner` respons√°vel por criar a l√≥gica passo a passo a ser adicionada √†s tarefas dos Agents.

<CodeGroup>
  ```python Code
  from crewai import Crew, Agent, Task, Process

  # Monte sua crew com capacidades de planejamento e LLM personalizado
  my_crew = Crew(
      agents=self.agents,
      tasks=self.tasks,
      process=Process.sequential,
      planning=True,
      planning_llm="gpt-4o"
  )

  # Execute a crew
  my_crew.kickoff()
  ```

  ````markdown Result
  [2024-07-15 16:49:11][INFO]: Planejando a execu√ß√£o da crew
  **Plano Passo a Passo para Execu√ß√£o das Tarefas**

  **Tarefa N√∫mero 1: Realizar uma pesquisa aprofundada sobre LLMs de IA**

  **Agente:** Pesquisador S√™nior de Dados de LLMs de IA

  **Objetivo do Agente:** Descobrir avan√ßos de ponta em LLMs de IA

  **Resultado Esperado da Tarefa:** Uma lista com 10 t√≥picos dos dados mais relevantes sobre LLMs de IA

  **Ferramentas da Tarefa:** Nenhuma especificada

  **Ferramentas do Agente:** Nenhuma especificada

  **Plano Passo a Passo:**

  1. **Definir o Escopo da Pesquisa:**

     - Determine as √°reas espec√≠ficas de LLMs de IA a focar, como avan√ßos em arquitetura, casos de uso, considera√ß√µes √©ticas e m√©tricas de performance.

  2. **Identificar Fontes Confi√°veis:**

     - Liste fontes confi√°veis para pesquisa em IA, incluindo peri√≥dicos acad√™micos, relat√≥rios da ind√∫stria, confer√™ncias (ex: NeurIPS, ACL), laborat√≥rios de pesquisa em IA (ex: OpenAI, Google AI) e bancos de dados online (ex: IEEE Xplore, arXiv).

  3. **Coletar Dados:**

     - Procure pelos artigos, publica√ß√µes e relat√≥rios mais recentes publicados em 2024 e in√≠cio de 2025.
     - Use palavras-chave como "Large Language Models 2025", "Avan√ßos em LLM de IA", "√âtica em IA 2025", etc.

  4. **Analisar Resultados:**

     - Leia e resuma os principais pontos de cada fonte.
     - Destaque novas t√©cnicas, modelos e aplica√ß√µes introduzidos no √∫ltimo ano.

  5. **Organizar as Informa√ß√µes:**

     - Categorize as informa√ß√µes em t√≥picos relevantes (ex: novas arquiteturas, implica√ß√µes √©ticas, aplica√ß√µes no mundo real).
     - Garanta que cada t√≥pico seja conciso, mas informativo.

  6. **Criar a Lista:**

     - Compile os 10 dados mais relevantes em itens de uma lista.
     - Revise a lista para garantir clareza e relev√¢ncia.

  **Sa√≠da Esperada:**

  Uma lista com 10 t√≥picos dos dados mais relevantes sobre LLMs de IA.

  ---

  **Tarefa N√∫mero 2: Revise o contexto obtido e expanda cada t√≥pico em uma se√ß√£o completa para um relat√≥rio**

  **Agente:** Analista de Relat√≥rios de LLMs de IA

  **Objetivo do Agente:** Criar relat√≥rios detalhados baseados na an√°lise de dados e pesquisa sobre LLMs de IA

  **Resultado Esperado da Tarefa:** Um relat√≥rio completo com os principais t√≥picos, cada um com uma se√ß√£o completa de informa√ß√µes. Formatado em markdown sem '```'

  **Ferramentas da Tarefa:** Nenhuma especificada

  **Ferramentas do Agente:** Nenhuma especificada

  **Plano Passo a Passo:**

  1. **Revisar os T√≥picos:**
     - Leia atentamente a lista dos 10 t√≥picos fornecida pelo Pesquisador S√™nior de Dados de LLMs de IA.

  2. **Esbo√ßar o Relat√≥rio:**
     - Crie um esbo√ßo com cada t√≥pico como t√≠tulo principal da se√ß√£o.
     - Planeje subse√ß√µes sob cada t√≠tulo para abordar diferentes aspectos do tema.

  3. **Pesquisar Detalhes Adicionais:**
     - Para cada t√≥pico, conduza pesquisa adicional, se necess√°rio, para reunir informa√ß√µes mais detalhadas.
     - Busque estudos de caso, exemplos e dados estat√≠sticos para embasar cada se√ß√£o.

  4. **Redigir Se√ß√µes Detalhadas:**
     - Expanda cada t√≥pico em uma se√ß√£o abrangente.
     - Certifique-se de que cada se√ß√£o inclua introdu√ß√£o, explica√ß√£o detalhada, exemplos e conclus√£o.
     - Utilize formata√ß√£o markdown para t√≠tulos, subt√≠tulos, listas e √™nfase.

  5. **Revisar e Editar:**
     - Revise o relat√≥rio para garantir clareza, coer√™ncia e corre√ß√£o.
     - Garanta uma sequ√™ncia l√≥gica de uma se√ß√£o para a outra.
     - Formate o relat√≥rio conforme os padr√µes markdown.

  6. **Finalizar o Relat√≥rio:**
     - Certifique-se de que o relat√≥rio est√° completo, com todas as se√ß√µes expandidas e detalhadas.
     - Fa√ßa uma √∫ltima verifica√ß√£o de formata√ß√£o e ajustes necess√°rios.

  **Sa√≠da Esperada:**
  Um relat√≥rio completo com os principais t√≥picos, cada um com uma se√ß√£o cheia de informa√ß√µes. Formatado em markdown sem '```'.
  ````
</CodeGroup>


# Processos
Source: https://docs.crewai.com/pt-BR/concepts/processes

Guia detalhado sobre o gerenciamento de fluxos de trabalho atrav√©s de processos no CrewAI, com detalhes de implementa√ß√£o atualizados.

## Vis√£o Geral

<Tip>
  Processos orquestram a execu√ß√£o de tarefas por agentes, de maneira semelhante √† gest√£o de projetos em equipes humanas.
  Esses processos garantem que as tarefas sejam distribu√≠das e executadas de forma eficiente, alinhadas a uma estrat√©gia predefinida.
</Tip>

## Implementa√ß√µes de Processos

* **Sequencial**: Executa tarefas de forma sequencial, garantindo que as tarefas sejam conclu√≠das em uma progress√£o ordenada.
* **Hier√°rquico**: Organiza tarefas em uma hierarquia gerencial, onde as tarefas s√£o delegadas e executadas com base numa cadeia de comando estruturada. Um modelo de linguagem de gerente (`manager_llm`) ou um agente gerente personalizado (`manager_agent`) deve ser especificado na crew para habilitar o processo hier√°rquico, facilitando a cria√ß√£o e o gerenciamento de tarefas pelo gerente.
* **Processo Consensual (Planejado)**: Visando a tomada de decis√£o colaborativa entre agentes para execu√ß√£o de tarefas, esse tipo de processo introduz uma abordagem democr√°tica ao gerenciamento de tarefas dentro do CrewAI. Est√° planejado para desenvolvimento futuro e ainda n√£o est√° implementado no c√≥digo-fonte.

## O Papel dos Processos no Trabalho em Equipe

Os processos permitem que agentes individuais atuem como uma unidade coesa, otimizando seus esfor√ßos para atingir objetivos comuns com efici√™ncia e coer√™ncia.

## Atribuindo Processos a uma Crew

Para atribuir um processo a uma crew, especifique o tipo de processo ao criar a crew para definir a estrat√©gia de execu√ß√£o. Para um processo hier√°rquico, garanta a defini√ß√£o de `manager_llm` ou `manager_agent` para o agente gerente.

```python
from crewai import Crew, Process

# Exemplo: Criando uma crew com processo sequencial
crew = Crew(
    agents=meus_agentes,
    tasks=minhas_tarefas,
    process=Process.sequential
)

# Exemplo: Criando uma crew com processo hier√°rquico
# Certifique-se de fornecer um manager_llm ou manager_agent
crew = Crew(
    agents=meus_agentes,
    tasks=minhas_tarefas,
    process=Process.hierarchical,
    manager_llm="gpt-4o"
    # ou
    # manager_agent=meu_agente_gerente
)
```

**Nota:** Certifique-se de que `meus_agentes` e `minhas_tarefas` estejam definidos antes de criar o objeto `Crew`, e para o processo hier√°rquico, √© necess√°rio tamb√©m fornecer o `manager_llm` ou `manager_agent`.

## Processo Sequencial

Este m√©todo reflete fluxos de trabalho din√¢micos de equipes, progredindo nas tarefas de maneira cuidadosa e sistem√°tica. A execu√ß√£o das tarefas segue a ordem preestabelecida na lista de tarefas, com a sa√≠da de uma tarefa servindo de contexto para a pr√≥xima.

Para personalizar o contexto das tarefas, utilize o par√¢metro `context` na classe `Task` para especificar as sa√≠das que devem ser usadas como contexto para as tarefas subsequentes.

## Processo Hier√°rquico

Emulando uma hierarquia corporativa, o CrewAI permite especificar um agente gerente personalizado ou criar um automaticamente, exigindo a especifica√ß√£o de um modelo de linguagem de gerente (`manager_llm`). Esse agente supervisiona a execu√ß√£o das tarefas, incluindo planejamento, delega√ß√£o e valida√ß√£o. As tarefas n√£o s√£o pr√©-atribu√≠das; o gerente aloca tarefas aos agentes com base em suas capacidades, revisa as sa√≠das e avalia a conclus√£o das tarefas.

## Classe Process: Vis√£o Detalhada

A classe `Process` √© implementada como uma enumera√ß√£o (`Enum`), garantindo seguran√ßa de tipo e restringindo os valores de processos aos tipos definidos (`sequential`, `hierarchical`). O processo consensual est√° planejado para inclus√£o futura, refor√ßando nosso compromisso com o desenvolvimento cont√≠nuo e a inova√ß√£o.

## Conclus√£o

A colabora√ß√£o estruturada possibilitada pelos processos dentro do CrewAI √© fundamental para permitir o trabalho em equipe sistem√°tico entre agentes.
Esta documenta√ß√£o foi atualizada para refletir os mais recentes recursos, melhorias e a planejada integra√ß√£o do Processo Consensual, garantindo que os usu√°rios tenham acesso √†s informa√ß√µes mais atuais e abrangentes.


# Reasoning
Source: https://docs.crewai.com/pt-BR/concepts/reasoning

Aprenda como habilitar e usar o reasoning do agente para aprimorar a execu√ß√£o de tarefas.

## Vis√£o Geral

O reasoning do agente √© um recurso que permite que agentes reflitam sobre uma tarefa e criem um plano antes da execu√ß√£o. Isso ajuda os agentes a abordarem tarefas de forma mais met√≥dica e garante que estejam preparados para realizar o trabalho atribu√≠do.

## Uso

Para habilitar o reasoning para um agente, basta definir `reasoning=True` ao criar o agente:

```python
from crewai import Agent

analista = Agent(
    role="Analista de Dados",
    goal="Analisar dados e fornecer insights",
    backstory="Voc√™ √© um analista de dados especialista.",
    reasoning=True,
    max_reasoning_attempts=3  # Opcional: Defina um limite de tentativas de reasoning
)
```

## Como Funciona

Quando o reasoning est√° habilitado, antes de executar uma tarefa, o agente ir√°:

1. Refletir sobre a tarefa e criar um plano detalhado
2. Avaliar se est√° pronto para executar a tarefa
3. Refinar o plano conforme necess√°rio at√© estar pronto ou at√© o limite de max\_reasoning\_attempts ser atingido
4. Inserir o plano de reasoning na descri√ß√£o da tarefa antes da execu√ß√£o

Esse processo ajuda o agente a dividir tarefas complexas em etapas gerenci√°veis e identificar potenciais desafios antes de come√ßar.

## Op√ß√µes de Configura√ß√£o

<ParamField body="reasoning" type="bool" default="False">
  Ativa ou desativa o reasoning
</ParamField>

<ParamField body="max_reasoning_attempts" type="int" default="None">
  N√∫mero m√°ximo de tentativas para refinar o plano antes de prosseguir com a execu√ß√£o. Se None (padr√£o), o agente continuar√° refinando at√© que esteja pronto.
</ParamField>

## Exemplo

Aqui est√° um exemplo completo:

```python
from crewai import Agent, Task, Crew

# Create an agent with reasoning enabled
analista = Agent(
    role="Analista de Dados",
    goal="Analisar dados e fornecer insights",
    backstory="Voc√™ √© um analista de dados especialista.",
    reasoning=True,
    max_reasoning_attempts=3  # Opcional: Defina um limite de tentativas de reasoning
)

# Create a task
analysis_task = Task(
    description="Analise os dados de vendas fornecidos e identifique as principais tend√™ncias.",
    expected_output="Um relat√≥rio destacando as 3 principais tend√™ncias de vendas.",
    agent=analista
)

# Create a crew and run the task
crew = Crew(agents=[analista], tasks=[analysis_task])
result = crew.kickoff()

print(result)
```

## Tratamento de Erros

O processo de reasoning foi projetado para ser robusto, com tratamento de erros integrado. Se ocorrer um erro durante o reasoning, o agente prosseguir√° com a execu√ß√£o da tarefa sem o plano de reasoning. Isso garante que as tarefas ainda possam ser executadas mesmo que o processo de reasoning falhe.

Veja como lidar com poss√≠veis erros no seu c√≥digo:

```python
from crewai import Agent, Task
import logging

# Set up logging to capture any reasoning errors
logging.basicConfig(level=logging.INFO)

# Create an agent with reasoning enabled
agent = Agent(
    role="Analista de Dados",
    goal="Analisar dados e fornecer insights",
    reasoning=True,
    max_reasoning_attempts=3
)

# Create a task
task = Task(
    description="Analise os dados de vendas fornecidos e identifique as principais tend√™ncias.",
    expected_output="Um relat√≥rio destacando as 3 principais tend√™ncias de vendas.",
    agent=agent
)

# Execute the task
# If an error occurs during reasoning, it will be logged and execution will continue
result = agent.execute_task(task)
```

## Exemplo de Sa√≠da de reasoning

Veja um exemplo de como pode ser um plano de reasoning para uma tarefa de an√°lise de dados:

```
Task: Analise os dados de vendas fornecidos e identifique as principais tend√™ncias.

Reasoning Plan:
I'll analyze the sales data to identify the top 3 trends.

1. Understanding of the task:
   I need to analyze sales data to identify key trends that would be valuable for business decision-making.

2. Key steps I'll take:
   - First, I'll examine the data structure to understand what fields are available
   - Then I'll perform exploratory data analysis to identify patterns
   - Next, I'll analyze sales by time periods to identify temporal trends
   - I'll also analyze sales by product categories and customer segments
   - Finally, I'll identify the top 3 most significant trends

3. Approach to challenges:
   - If the data has missing values, I'll decide whether to fill or filter them
   - If the data has outliers, I'll investigate whether they're valid data points or errors
   - If trends aren't immediately obvious, I'll apply statistical methods to uncover patterns

4. Use of available tools:
   - I'll use data analysis tools to explore and visualize the data
   - I'll use statistical tools to identify significant patterns
   - I'll use knowledge retrieval to access relevant information about sales analysis

5. Expected outcome:
   A concise report highlighting the top 3 sales trends with supporting evidence from the data.

READY: I am ready to execute the task.
```

Esse plano de reasoning ajuda o agente a organizar sua abordagem para a tarefa, considerar poss√≠veis desafios e garantir que entregar√° o resultado esperado.


# Tarefas
Source: https://docs.crewai.com/pt-BR/concepts/tasks

Guia detalhado sobre como gerenciar e criar tarefas dentro do framework CrewAI.

## Vis√£o Geral

No framework CrewAI, uma `Task` (Tarefa) √© uma atribui√ß√£o espec√≠fica executada por um `Agent` (Agente).

As tarefas fornecem todos os detalhes necess√°rios para sua execu√ß√£o, como descri√ß√£o, agente respons√°vel, ferramentas exigidas e mais, facilitando uma ampla gama de complexidades de a√ß√£o.

As tarefas dentro do CrewAI podem ser colaborativas, exigindo que m√∫ltiplos agentes trabalhem juntos. Isso √© gerenciado por meio das propriedades da tarefa e orquestrado pelo processo do Crew, potencializando o trabalho em equipe e a efici√™ncia.

<Note type="info" title="Aprimoramento Empresarial: Construtor Visual de Tarefas">
  O CrewAI Enterprise inclui um Construtor Visual de Tarefas no Crew Studio, que simplifica a cria√ß√£o e o encadeamento de tarefas complexas. Projete seus fluxos de tarefas visualmente e teste-os em tempo real sem necessidade de escrever c√≥digo.

  ![Task Builder Screenshot](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-studio-interface.png)

  O Construtor Visual de Tarefas permite:

  * Cria√ß√£o de tarefas via arrastar-e-soltar
  * Visualiza√ß√£o de depend√™ncias e fluxo de tarefas
  * Testes e valida√ß√µes em tempo real
  * F√°cil compartilhamento e colabora√ß√£o
</Note>

### Fluxo de Execu√ß√£o de Tarefas

As tarefas podem ser executadas de duas maneiras:

* **Sequencial**: As tarefas s√£o executadas na ordem em que s√£o definidas
* **Hier√°rquica**: As tarefas s√£o atribu√≠das aos agentes com base em seus pap√©is e especialidades

O fluxo de execu√ß√£o √© definido ao criar o crew:

```python Code
crew = Crew(
    agents=[agent1, agent2],
    tasks=[task1, task2],
    process=Process.sequential  # ou Process.hierarchical
)
```

## Atributos da Tarefa

| Atributo                          | Par√¢metros        | Tipo                        | Descri√ß√£o                                                                                               |
| :-------------------------------- | :---------------- | :-------------------------- | :------------------------------------------------------------------------------------------------------ |
| **Descri√ß√£o**                     | `description`     | `str`                       | Uma declara√ß√£o clara e concisa do que a tarefa envolve.                                                 |
| **Sa√≠da Esperada**                | `expected_output` | `str`                       | Uma descri√ß√£o detalhada de como deve ser o resultado da tarefa conclu√≠da.                               |
| **Nome** *(opcional)*             | `name`            | `Optional[str]`             | Um identificador de nome para a tarefa.                                                                 |
| **Agente** *(opcional)*           | `agent`           | `Optional[BaseAgent]`       | O agente respons√°vel por executar a tarefa.                                                             |
| **Ferramentas** *(opcional)*      | `tools`           | `List[BaseTool]`            | As ferramentas/recursos que o agente pode usar para esta tarefa.                                        |
| **Contexto** *(opcional)*         | `context`         | `Optional[List["Task"]]`    | Outras tarefas cujas sa√≠das ser√£o usadas como contexto para esta tarefa.                                |
| **Execu√ß√£o Ass√≠ncrona** *(opc.)*  | `async_execution` | `Optional[bool]`            | Se a tarefa deve ser executada de forma ass√≠ncrona. O padr√£o √© False.                                   |
| **Input Humano** *(opcional)*     | `human_input`     | `Optional[bool]`            | Se a tarefa deve ter uma revis√£o humana da resposta final do agente. O padr√£o √© False.                  |
| **Markdown** *(opcional)*         | `markdown`        | `Optional[bool]`            | Se a tarefa deve instruir o agente a retornar a resposta final formatada em Markdown. O padr√£o √© False. |
| **Config** *(opcional)*           | `config`          | `Optional[Dict[str, Any]]`  | Par√¢metros de configura√ß√£o espec√≠ficos da tarefa.                                                       |
| **Arquivo de Sa√≠da** *(opcional)* | `output_file`     | `Optional[str]`             | Caminho do arquivo para armazenar a sa√≠da da tarefa.                                                    |
| **Sa√≠da JSON** *(opcional)*       | `output_json`     | `Optional[Type[BaseModel]]` | Um modelo Pydantic para estruturar a sa√≠da em JSON.                                                     |
| **Output Pydantic** *(opcional)*  | `output_pydantic` | `Optional[Type[BaseModel]]` | Um modelo Pydantic para a sa√≠da da tarefa.                                                              |
| **Callback** *(opcional)*         | `callback`        | `Optional[Any]`             | Fun√ß√£o/objeto a ser executado ap√≥s a conclus√£o da tarefa.                                               |

## Criando Tarefas

Existem duas maneiras de criar tarefas no CrewAI: utilizando **configura√ß√£o YAML (recomendado)** ou definindo-as **diretamente no c√≥digo**.

### Configura√ß√£o YAML (Recomendado)

Utilizar configura√ß√£o YAML oferece uma forma mais limpa e de f√°cil manuten√ß√£o para definir tarefas. Recomendamos fortemente esse m√©todo em seus projetos CrewAI.

Ap√≥s criar seu projeto CrewAI conforme indicado na se√ß√£o [Instala√ß√£o](/pt-BR/installation), navegue at√© o arquivo `src/latest_ai_development/config/tasks.yaml` e modifique o template para refletir os requisitos espec√≠ficos das tarefas.

<Note>
  Vari√°veis em seus arquivos YAML (como `{topic}`) ser√£o substitu√≠das por valores vindos dos seus inputs ao executar o crew:

  ```python Code
  crew.kickoff(inputs={'topic': 'AI Agents'})
  ```
</Note>

Veja um exemplo de configura√ß√£o de tarefas usando YAML:

````yaml tasks.yaml
research_task:
  description: >
    Realize uma pesquisa detalhada sobre {topic}
    Certifique-se de encontrar informa√ß√µes interessantes e relevantes considerando
    que o ano atual √© 2025.
  expected_output: >
    Uma lista com 10 t√≥picos em bullet points das informa√ß√µes mais relevantes sobre {topic}
  agent: researcher

reporting_task:
  description: >
    Revise o contexto recebido e expanda cada t√≥pico em uma se√ß√£o completa de um relat√≥rio.
    Certifique-se de que o relat√≥rio seja detalhado e contenha todas as informa√ß√µes relevantes.
  expected_output: >
    Um relat√≥rio completo com os principais t√≥picos, cada um com uma se√ß√£o cheia de informa√ß√µes.
    Formatado em markdown sem '```'
  agent: reporting_analyst
  markdown: true
  output_file: report.md
````

Para usar essa configura√ß√£o YAML em seu c√≥digo, crie uma classe crew que herda de `CrewBase`:

```python crew.py
# src/latest_ai_development/crew.py

from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task
from crewai_tools import SerperDevTool

@CrewBase
class LatestAiDevelopmentCrew():
  """LatestAiDevelopment crew"""

  @agent
  def researcher(self) -> Agent:
    return Agent(
      config=self.agents_config['researcher'], # type: ignore[index]
      verbose=True,
      tools=[SerperDevTool()]
    )

  @agent
  def reporting_analyst(self) -> Agent:
    return Agent(
      config=self.agents_config['reporting_analyst'], # type: ignore[index]
      verbose=True
    )

  @task
  def research_task(self) -> Task:
    return Task(
      config=self.tasks_config['research_task'] # type: ignore[index]
    )

  @task
  def reporting_task(self) -> Task:
    return Task(
      config=self.tasks_config['reporting_task'] # type: ignore[index]
    )

  @crew
  def crew(self) -> Crew:
    return Crew(
      agents=[
        self.researcher(),
        self.reporting_analyst()
      ],
      tasks=[
        self.research_task(),
        self.reporting_task()
      ],
      process=Process.sequential
    )
```

<Note>
  Os nomes usados em seus arquivos YAML (`agents.yaml` e `tasks.yaml`) devem corresponder aos nomes dos m√©todos no seu c√≥digo Python.
</Note>

### Defini√ß√£o Direta no C√≥digo (Alternativa)

Alternativamente, voc√™ pode definir tarefas diretamente no seu c√≥digo sem usar configura√ß√£o YAML:

```python task.py
from crewai import Task

research_task = Task(
    description="""
        Realize uma pesquisa detalhada sobre AI Agents.
        Certifique-se de encontrar informa√ß√µes interessantes e relevantes considerando
        que o ano atual √© 2025.
    """,
    expected_output="""
        Uma lista com 10 t√≥picos em bullet points das informa√ß√µes mais relevantes sobre AI Agents
    """,
    agent=researcher
)

reporting_task = Task(
    description="""
        Revise o contexto recebido e expanda cada t√≥pico em uma se√ß√£o completa de um relat√≥rio.
        Certifique-se de que o relat√≥rio seja detalhado e contenha todas as informa√ß√µes relevantes.
    """,
    expected_output="""
        Um relat√≥rio completo com os principais t√≥picos, cada um com uma se√ß√£o cheia de informa√ß√µes.
    """,
    agent=reporting_analyst,
    markdown=True,  # Ativa formata√ß√£o markdown para a sa√≠da final
    output_file="report.md"
)
```

<Tip>
  Especifique diretamente um `agent` para a tarefa ou permita que o processo `hierarchical` do CrewAI decida com base em pap√©is, disponibilidade, etc.
</Tip>

## Sa√≠da da Tarefa

Compreender as sa√≠das das tarefas √© crucial para construir fluxos de trabalho de IA eficazes. O CrewAI oferece uma maneira estruturada de lidar com resultados usando a classe `TaskOutput`, que suporta m√∫ltiplos formatos de sa√≠da e pode ser facilmente passada entre tarefas.

A sa√≠da de uma tarefa no framework CrewAI √© encapsulada na classe `TaskOutput`. Essa classe fornece uma maneira estruturada de acessar os resultados da tarefa, incluindo v√°rios formatos como sa√≠da bruta, JSON e modelos Pydantic.

Por padr√£o, o `TaskOutput` incluir√° apenas a sa√≠da `raw`. Um `TaskOutput` s√≥ ter√° as sa√≠das `pydantic` ou `json_dict` se o objeto original da `Task` estiver configurado com `output_pydantic` ou `output_json`, respectivamente.

### Atributos do Task Output

| Atributo          | Par√¢metros      | Tipo                       | Descri√ß√£o                                                                                 |
| :---------------- | :-------------- | :------------------------- | :---------------------------------------------------------------------------------------- |
| **Description**   | `description`   | `str`                      | Descri√ß√£o da tarefa.                                                                      |
| **Summary**       | `summary`       | `Optional[str]`            | Resumo da tarefa, gerado automaticamente a partir das primeiras 10 palavras da descri√ß√£o. |
| **Raw**           | `raw`           | `str`                      | Sa√≠da bruta da tarefa. Este √© o formato padr√£o da sa√≠da.                                  |
| **Pydantic**      | `pydantic`      | `Optional[BaseModel]`      | Objeto modelo Pydantic representando a sa√≠da da tarefa de forma estruturada.              |
| **JSON Dict**     | `json_dict`     | `Optional[Dict[str, Any]]` | Dicion√°rio representando a sa√≠da da tarefa em JSON.                                       |
| **Agent**         | `agent`         | `str`                      | O agente que executou a tarefa.                                                           |
| **Output Format** | `output_format` | `OutputFormat`             | O formato da sa√≠da da tarefa, podendo ser RAW, JSON e Pydantic. O padr√£o √© RAW.           |

### M√©todos e Propriedades da Tarefa

| M√©todo/Propriedade | Descri√ß√£o                                                                                            |
| :----------------- | :--------------------------------------------------------------------------------------------------- |
| **json**           | Retorna a representa√ß√£o da sa√≠da da tarefa em JSON como string, se o formato de sa√≠da for JSON.      |
| **to\_dict**       | Converte as sa√≠das JSON e Pydantic para um dicion√°rio.                                               |
| **str**            | Retorna a representa√ß√£o em string da sa√≠da da tarefa, priorizando Pydantic, depois JSON, depois raw. |

### Acessando Sa√≠das das Tarefas

Uma vez que a tarefa √© executada, sua sa√≠da pode ser acessada pelo atributo `output` do objeto `Task`. A classe `TaskOutput` oferece v√°rias formas de interagir e apresentar esse resultado.

#### Exemplo

```python Code
# Exemplo de tarefa
task = Task(
    description='Encontre e resuma as √∫ltimas not√≠cias de IA',
    expected_output='Uma lista em bullet points com o resumo das 5 not√≠cias mais importantes de IA',
    agent=research_agent,
    tools=[search_tool]
)

# Executando o crew
crew = Crew(
    agents=[research_agent],
    tasks=[task],
    verbose=True
)

result = crew.kickoff()

# Acessando a sa√≠da da tarefa
task_output = task.output

print(f"Descri√ß√£o da Tarefa: {task_output.description}")
print(f"Resumo da Tarefa: {task_output.summary}")
print(f"Sa√≠da Bruta: {task_output.raw}")
if task_output.json_dict:
    print(f"Sa√≠da em JSON: {json.dumps(task_output.json_dict, indent=2)}")
if task_output.pydantic:
    print(f"Sa√≠da Pydantic: {task_output.pydantic}")
```

## Formata√ß√£o Markdown na Sa√≠da

O par√¢metro `markdown` ativa a formata√ß√£o autom√°tica em markdown na sa√≠da das tarefas. Quando configurado como `True`, a tarefa ir√° instruir o agente a formatar a resposta final utilizando a sintaxe Markdown correta.

### Usando Formata√ß√£o Markdown

```python Code
# Exemplo de tarefa com formata√ß√£o markdown ativada
formatted_task = Task(
    description="Crie um relat√≥rio abrangente sobre tend√™ncias em IA",
    expected_output="Um relat√≥rio bem estruturado com t√≠tulos, se√ß√µes e bullet points",
    agent=reporter_agent,
    markdown=True  # Habilita a formata√ß√£o autom√°tica em markdown
)
```

Quando `markdown=True`, o agente recebe instru√ß√µes extras para formatar a sa√≠da usando:

* `#` para t√≠tulos
* `**texto**` para negrito
* `*texto*` para it√°lico
* `-` ou `*` para bullet points
* `` `c√≥digo` `` para c√≥digo inline
* ` `linguagem \`\`\` para blocos de c√≥digo

### Configura√ß√£o YAML com Markdown

```yaml tasks.yaml
analysis_task:
  description: >
    Analise os dados de mercado e crie um relat√≥rio detalhado
  expected_output: >
    Uma an√°lise completa com gr√°ficos e descobertas-chave
  agent: analyst
  markdown: true  # Habilita formata√ß√£o em markdown
  output_file: analysis.md
```

### Benef√≠cios da Sa√≠da Markdown

* **Formata√ß√£o Consistente**: Garante que todas as sa√≠das sigam as conven√ß√µes de markdown
* **Maior Legibilidade**: Conte√∫do estruturado com t√≠tulos, listas e √™nfase
* **Pronto para Documenta√ß√£o**: A sa√≠da pode ser usada diretamente em sistemas de documenta√ß√£o
* **Compatibilidade Multi-plataforma**: Markdown √© universalmente suportado

<Note>
  As instru√ß√µes de formata√ß√£o em markdown s√£o adicionadas automaticamente ao prompt da tarefa quando `markdown=True`, ent√£o n√£o √© necess√°rio detalhar os requisitos de formata√ß√£o na descri√ß√£o da tarefa.
</Note>

## Depend√™ncias de Tarefas e Contexto

As tarefas podem depender da sa√≠da de outras tarefas utilizando o atributo `context`. Por exemplo:

```python Code
research_task = Task(
    description="Pesquise os √∫ltimos avan√ßos em IA",
    expected_output="Uma lista de avan√ßos recentes em IA",
    agent=researcher
)

analysis_task = Task(
    description="Analise os achados da pesquisa e identifique as tend√™ncias principais",
    expected_output="Relat√≥rio de an√°lise das tend√™ncias em IA",
    agent=analyst,
    context=[research_task]  # Esta tarefa aguardar√° a conclus√£o da research_task
)
```

## Guardrails em Tarefas

Guardrails (trilhas de prote√ß√£o) de tarefas fornecem uma maneira de validar e transformar as sa√≠das das tarefas antes que elas sejam passadas para a pr√≥xima tarefa. Esse recurso assegura a qualidade dos dados e oferece feedback aos agentes quando sua sa√≠da n√£o atende a crit√©rios espec√≠ficos.

### Usando Guardrails em Tarefas

Para adicionar um guardrail a uma tarefa, forne√ßa uma fun√ß√£o de valida√ß√£o por meio do par√¢metro `guardrail`:

```python Code
from typing import Tuple, Union, Dict, Any
from crewai import TaskOutput

def validate_blog_content(result: TaskOutput) -> Tuple[bool, Any]:
    """Valida se o conte√∫do do blog atende aos requisitos."""
    try:
        # Verifica a contagem de palavras
        word_count = len(result.split())
        if word_count > 200:
            return (False, "O conte√∫do do blog excede 200 palavras")

        # L√≥gica adicional de valida√ß√£o aqui
        return (True, result.strip())
    except Exception as e:
        return (False, "Erro inesperado durante a valida√ß√£o")

blog_task = Task(
    description="Escreva um post de blog sobre IA",
    expected_output="Um post de blog com menos de 200 palavras",
    agent=blog_agent,
    guardrail=validate_blog_content  # Adiciona a fun√ß√£o guardrail
)
```

### Requisitos da Fun√ß√£o Guardrail

1. **Assinatura da Fun√ß√£o**:
   * Deve aceitar exatamente um par√¢metro (a sa√≠da da tarefa)
   * Deve retornar uma tupla `(bool, Any)`
   * Type hints s√£o recomendados, mas opcionais

2. **Valores de Retorno**:
   * Em caso de sucesso: retorna uma tupla `(True, resultado_validado)`
   * Em caso de falha: retorna uma tupla `(False, "mensagem de erro explicando a falha")`

### LLMGuardrail

A classe `LLMGuardrail` oferece um mecanismo robusto para valida√ß√£o das sa√≠das das tarefas.

### Melhores Pr√°ticas de Tratamento de Erros

1. **Respostas de Erro Estruturadas**:

```python Code
from crewai import TaskOutput, LLMGuardrail

def validate_with_context(result: TaskOutput) -> Tuple[bool, Any]:
    try:
        # L√≥gica principal de valida√ß√£o
        validated_data = perform_validation(result)
        return (True, validated_data)
    except ValidationError as e:
        return (False, f"ERRO_DE_VALIDACAO: {str(e)}")
    except Exception as e:
        return (False, str(e))
```

2. **Categorias de Erro**:
   * Use c√≥digos de erro espec√≠ficos
   * Inclua contexto relevante
   * Forne√ßa feedback acion√°vel

3. **Cadeia de Valida√ß√£o**:

```python Code
from typing import Any, Dict, List, Tuple, Union
from crewai import TaskOutput

def complex_validation(result: TaskOutput) -> Tuple[bool, Any]:
    """Encadeia m√∫ltiplas etapas de valida√ß√£o."""
    # Passo 1: Valida√ß√£o b√°sica
    if not result:
        return (False, "Resultado vazio")

    # Passo 2: Valida√ß√£o de conte√∫do
    try:
        validated = validate_content(result)
        if not validated:
            return (False, "Conte√∫do inv√°lido")

        # Passo 3: Valida√ß√£o de formato
        formatted = format_output(validated)
        return (True, formatted)
    except Exception as e:
        return (False, str(e))
```

### Tratamento dos Resultados do Guardrail

Quando um guardrail retorna `(False, erro)`:

1. O erro √© enviado de volta para o agente
2. O agente tenta corrigir o problema
3. O processo se repete at√©:
   * O guardrail retornar `(True, resultado)`
   * O n√∫mero m√°ximo de tentativas ser atingido

Exemplo com manipula√ß√£o de tentativas:

```python Code
from typing import Optional, Tuple, Union
from crewai import TaskOutput, Task

def validate_json_output(result: TaskOutput) -> Tuple[bool, Any]:
    """Valida e faz o parsing da sa√≠da como JSON."""
    try:
        # Tenta realizar o parsing como JSON
        data = json.loads(result)
        return (True, data)
    except json.JSONDecodeError as e:
        return (False, "Formato JSON inv√°lido")

task = Task(
    description="Gere um relat√≥rio em JSON",
    expected_output="Um objeto JSON v√°lido",
    agent=analyst,
    guardrail=validate_json_output,
    max_retries=3  # Limite de tentativas
)
```

## Obtendo Sa√≠das Estruturadas e Consistentes das Tarefas

<Note>
  √â importante tamb√©m observar que a sa√≠da da √∫ltima tarefa de um crew se torna a sa√≠da final do pr√≥prio crew.
</Note>

### Usando `output_pydantic`

A propriedade `output_pydantic` permite que voc√™ defina um modelo Pydantic que a sa√≠da da tarefa deve seguir. Isso garante que a sa√≠da seja n√£o apenas estruturada, mas tamb√©m validada de acordo com o modelo.

Veja um exemplo de uso do output\_pydantic:

```python Code
import json

from crewai import Agent, Crew, Process, Task
from pydantic import BaseModel


class Blog(BaseModel):
    title: str
    content: str


blog_agent = Agent(
    role="Blog Content Generator Agent",
    goal="Gerar um t√≠tulo e conte√∫do para blog",
    backstory="""Voc√™ √© um especialista em cria√ß√£o de conte√∫do, habilidoso em escrever posts de blogs engajadores e informativos.""",
    verbose=False,
    allow_delegation=False,
    llm="gpt-4o",
)

task1 = Task(
    description="""Crie um t√≠tulo e conte√∫do para blog sobre um t√≥pico. Certifique-se de que o conte√∫do tenha menos de 200 palavras.""",
    expected_output="Um t√≠tulo atraente e um conte√∫do bem escrito para blog.",
    agent=blog_agent,
    output_pydantic=Blog,
)

# Instanciando o crew com processo sequencial
crew = Crew(
    agents=[blog_agent],
    tasks=[task1],
    verbose=True,
    process=Process.sequential,
)

result = crew.kickoff()

# Op√ß√£o 1: Acessando propriedades via indexa√ß√£o de dicion√°rio
print("Acessando propriedades - Op√ß√£o 1")
title = result["title"]
content = result["content"]
print("T√≠tulo:", title)
print("Conte√∫do:", content)

# Op√ß√£o 2: Acessando diretamente do modelo Pydantic
print("Acessando propriedades - Op√ß√£o 2")
title = result.pydantic.title
content = result.pydantic.content
print("T√≠tulo:", title)
print("Conte√∫do:", content)

# Op√ß√£o 3: Usando o m√©todo to_dict()
print("Acessando propriedades - Op√ß√£o 3")
output_dict = result.to_dict()
title = output_dict["title"]
content = output_dict["content"]
print("T√≠tulo:", title)
print("Conte√∫do:", content)

# Op√ß√£o 4: Imprimindo o objeto Blog inteiro
print("Acessando propriedades - Op√ß√£o 5")
print("Blog:", result)

```

Neste exemplo:

* Um modelo Pydantic Blog √© definido com os campos title e content.
* A tarefa task1 utiliza a propriedade output\_pydantic para especificar que sua sa√≠da deve seguir o modelo Blog.
* Ap√≥s executar o crew, voc√™ pode acessar a sa√≠da estruturada de v√°rias formas, como mostrado.

#### Explica√ß√£o sobre o acesso √† sa√≠da

1. Indexa√ß√£o estilo dicion√°rio: Acesse os campos diretamente usando result\["nome\_do\_campo"]. Isso funciona porque a classe CrewOutput implementa o m√©todo **getitem**.
2. Diretamente do modelo Pydantic: Acesse os atributos diretamente do objeto result.pydantic.
3. Usando o m√©todo to\_dict(): Converta a sa√≠da para um dicion√°rio e acesse os campos.
4. Imprimindo o objeto inteiro: Simplesmente imprima o objeto result para ver a sa√≠da estruturada.

### Usando `output_json`

A propriedade `output_json` permite definir o formato de sa√≠da esperado em JSON. Isso garante que a sa√≠da da tarefa seja uma estrutura JSON v√°lida que pode ser facilmente analisada e utilizada na aplica√ß√£o.

Veja um exemplo de uso do `output_json`:

```python Code
import json

from crewai import Agent, Crew, Process, Task
from pydantic import BaseModel


# Define o modelo Pydantic para o blog
class Blog(BaseModel):
    title: str
    content: str


# Define o agente
blog_agent = Agent(
    role="Blog Content Generator Agent",
    goal="Gerar um t√≠tulo e conte√∫do para blog",
    backstory="""Voc√™ √© um especialista em cria√ß√£o de conte√∫do, habilidoso em escrever posts de blogs engajadores e informativos.""",
    verbose=False,
    allow_delegation=False,
    llm="gpt-4o",
)

# Define a tarefa com output_json configurado para o modelo Blog
task1 = Task(
    description="""Crie um t√≠tulo e conte√∫do para blog sobre um t√≥pico. Certifique-se de que o conte√∫do tenha menos de 200 palavras.""",
    expected_output="Um objeto JSON com os campos 'title' e 'content'.",
    agent=blog_agent,
    output_json=Blog,
)

# Instancia o crew com processo sequencial
crew = Crew(
    agents=[blog_agent],
    tasks=[task1],
    verbose=True,
    process=Process.sequential,
)

# Executa o crew para realizar a tarefa
result = crew.kickoff()

# Op√ß√£o 1: Acessando propriedades via indexa√ß√£o de dicion√°rio
print("Acessando propriedades - Op√ß√£o 1")
title = result["title"]
content = result["content"]
print("T√≠tulo:", title)
print("Conte√∫do:", content)

# Op√ß√£o 2: Imprimindo o objeto Blog inteiro
print("Acessando propriedades - Op√ß√£o 2")
print("Blog:", result)
```

Neste exemplo:

* Um modelo Pydantic Blog √© definido com os campos title e content, usado para especificar a estrutura do JSON de sa√≠da.
* A tarefa task1 utiliza a propriedade output\_json para indicar que espera uma sa√≠da JSON que segue o modelo Blog.
* Ap√≥s executar o crew, voc√™ pode acessar a sa√≠da estruturada em JSON conforme demonstrado.

#### Explica√ß√£o sobre o acesso √† sa√≠da

1. Acessando propriedades via indexa√ß√£o de dicion√°rio: Voc√™ pode acessar os campos diretamente usando result\["nome\_do\_campo"]. Isso √© poss√≠vel pois a classe CrewOutput implementa o m√©todo **getitem**, permitindo tratar a sa√≠da como um dicion√°rio. Nesse caso, estamos acessando title e content do resultado.
2. Imprimindo o objeto Blog inteiro: Ao imprimir result, voc√™ obter√° a representa√ß√£o em string do objeto CrewOutput. Como o m√©todo **str** √© implementado para retornar a sa√≠da em JSON, isso exibir√° toda a sa√≠da como uma string formatada representando o objeto Blog.

***

Utilizando `output_pydantic` ou `output_json`, voc√™ garante que suas tarefas produzam sa√≠das em um formato estruturado e consistente, facilitando o processamento e uso dos dados na sua aplica√ß√£o ou entre m√∫ltiplas tarefas.

## Integrando Ferramentas com Tarefas

Utilize ferramentas do [CrewAI Toolkit](https://github.com/joaomdmoura/crewai-tools) e [LangChain Tools](https://python.langchain.com/docs/integrations/tools) para ampliar o desempenho das tarefas e aprimorar a intera√ß√£o dos agentes.

## Criando uma Tarefa com Ferramentas

```python Code
import os
os.environ["OPENAI_API_KEY"] = "Sua Chave"
os.environ["SERPER_API_KEY"] = "Sua Chave" # Chave serper.dev

from crewai import Agent, Task, Crew
from crewai_tools import SerperDevTool

research_agent = Agent(
  role='Researcher',
  goal='Encontrar e resumir as √∫ltimas not√≠cias de IA',
  backstory="""Voc√™ √© um pesquisador em uma grande empresa.
  Sua responsabilidade √© analisar dados e fornecer insights
  para o neg√≥cio.""",
  verbose=True
)

# Para realizar buscas sem√¢nticas de um termo a partir de textos da internet
search_tool = SerperDevTool()

task = Task(
  description='Encontre e resuma as √∫ltimas not√≠cias de IA',
  expected_output='Uma lista em bullet points com o resumo das 5 not√≠cias mais importantes de IA',
  agent=research_agent,
  tools=[search_tool]
)

crew = Crew(
    agents=[research_agent],
    tasks=[task],
    verbose=True
)

result = crew.kickoff()
print(result)
```

Isso demonstra como tarefas com ferramentas espec√≠ficas podem sobrescrever o conjunto padr√£o de um agente para uma execu√ß√£o mais personalizada da tarefa.

## Referenciando Outras Tarefas

No CrewAI, a sa√≠da de uma tarefa √© automaticamente repassada para a pr√≥xima, mas voc√™ pode definir explicitamente de quais tarefas a sa√≠da deve ser utilizada como contexto por outra, inclusive m√∫ltiplas sa√≠das.

√â √∫til especialmente quando voc√™ precisa que uma tarefa dependa do resultado de outra que n√£o √© executada imediatamente antes dela. Isso √© feito pelo atributo `context`:

```python Code
# ...

research_ai_task = Task(
    description="Pesquise os avan√ßos mais recentes em IA",
    expected_output="Uma lista de avan√ßos recentes em IA",
    async_execution=True,
    agent=research_agent,
    tools=[search_tool]
)

research_ops_task = Task(
    description="Pesquise os avan√ßos mais recentes em AI Ops",
    expected_output="Uma lista de avan√ßos recentes em AI Ops",
    async_execution=True,
    agent=research_agent,
    tools=[search_tool]
)

write_blog_task = Task(
    description="Escreva um post de blog completo sobre a import√¢ncia da IA e suas √∫ltimas not√≠cias",
    expected_output="Post de blog completo com 4 par√°grafos",
    agent=writer_agent,
    context=[research_ai_task, research_ops_task]
)

#...
```

## Execu√ß√£o Ass√≠ncrona

Voc√™ pode definir que uma tarefa seja executada de forma ass√≠ncrona. Isso significa que o crew n√£o aguardar√° sua conclus√£o para seguir para a pr√≥xima tarefa. √â √∫til para tarefas demoradas, ou que n√£o s√£o cruciais para as seguintes.

Depois, utilize o atributo `context` para indicar, em uma tarefa futura, que ela deve aguardar os resultados da tarefa ass√≠ncrona.

```python Code
#...

list_ideas = Task(
    description="Liste 5 ideias interessantes para explorar em um artigo sobre IA.",
    expected_output="Lista em bullet points com 5 ideias para um artigo.",
    agent=researcher,
    async_execution=True # Ser√° executada de forma ass√≠ncrona
)

list_important_history = Task(
    description="Pesquise a hist√≥ria da IA e forne√ßa os 5 eventos mais importantes.",
    expected_output="Lista em bullet points com 5 eventos importantes.",
    agent=researcher,
    async_execution=True # Ser√° executada de forma ass√≠ncrona
)

write_article = Task(
    description="Escreva um artigo sobre IA, sua hist√≥ria e ideias interessantes.",
    expected_output="Artigo de 4 par√°grafos sobre IA.",
    agent=writer,
    context=[list_ideas, list_important_history] # Vai esperar o resultado das duas tarefas
)

#...
```

## Mecanismo de Callback

A fun√ß√£o callback √© executada ap√≥s a conclus√£o da tarefa, permitindo acionar a√ß√µes ou notifica√ß√µes baseadas no resultado da tarefa.

```python Code
# ...

def callback_function(output: TaskOutput):
    # Realiza algo ap√≥s a conclus√£o da tarefa
    # Exemplo: Envia um e-mail ao gerente
    print(f"""
        Tarefa conclu√≠da!
        Tarefa: {output.description}
        Sa√≠da: {output.raw}
    """)

research_task = Task(
    description='Encontre e resuma as √∫ltimas not√≠cias de IA',
    expected_output='Uma lista em bullet points com o resumo das 5 not√≠cias mais importantes de IA',
    agent=research_agent,
    tools=[search_tool],
    callback=callback_function
)

#...
```

## Acessando a Sa√≠da de uma Tarefa Espec√≠fica

Assim que um crew finaliza sua execu√ß√£o, voc√™ pode acessar a sa√≠da de uma tarefa espec√≠fica por meio do atributo `output` do objeto da tarefa:

```python Code
# ...
task1 = Task(
    description='Encontre e resuma as √∫ltimas not√≠cias de IA',
    expected_output='Uma lista em bullet points com o resumo das 5 not√≠cias mais importantes de IA',
    agent=research_agent,
    tools=[search_tool]
)

#...

crew = Crew(
    agents=[research_agent],
    tasks=[task1, task2, task3],
    verbose=True
)

result = crew.kickoff()

# Retorna um objeto TaskOutput com a descri√ß√£o e resultado da tarefa
print(f"""
    Tarefa conclu√≠da!
    Tarefa: {task1.output.description}
    Sa√≠da: {task1.output.raw}
""")
```

## Mecanismo de Sobrescri√ß√£o de Ferramentas

Especificar ferramentas em uma tarefa permite a adapta√ß√£o din√¢mica das capacidades do agente, destacando a flexibilidade do CrewAI.

## Mecanismos de Valida√ß√£o e Tratamento de Erros

Ao criar e executar tarefas, determinados mecanismos de valida√ß√£o garantem a robustez e confiabilidade dos atributos das tarefas. Isso inclui, mas n√£o se limita a:

* Garantir que apenas um tipo de sa√≠da seja definido por tarefa para manter expectativas de sa√≠da claras.
* Impedir a atribui√ß√£o manual do atributo `id`, preservando a integridade do sistema de identificadores √∫nicos.

Estas valida√ß√µes colaboram para a consist√™ncia e confiabilidade das execu√ß√µes de tarefas no framework CrewAI.

## Guardrails em Tarefas

Guardrails de tarefas oferecem uma maneira poderosa de validar, transformar ou filtrar as sa√≠das das tarefas antes de serem encaminhadas √† pr√≥xima. S√£o fun√ß√µes opcionais que executam antes do in√≠cio da pr√≥xima tarefa, garantindo que as sa√≠das estejam em conformidade com requisitos ou formatos esperados.

### Uso B√°sico

#### Defina sua pr√≥pria l√≥gica de valida√ß√£o

```python Code
from typing import Tuple, Union
from crewai import Task

def validate_json_output(result: str) -> Tuple[bool, Union[dict, str]]:
    """Valida se a sa√≠da √© um JSON v√°lido."""
    try:
        json_data = json.loads(result)
        return (True, json_data)
    except json.JSONDecodeError:
        return (False, "A sa√≠da deve ser um JSON v√°lido")

task = Task(
    description="Gerar dados em JSON",
    expected_output="Objeto JSON v√°lido",
    guardrail=validate_json_output
)
```

#### Use uma abordagem no-code para valida√ß√£o

```python Code
from crewai import Task

task = Task(
    description="Gerar dados em JSON",
    expected_output="Objeto JSON v√°lido",
    guardrail="Garanta que a resposta √© um objeto JSON v√°lido"
)
```

#### Usando YAML

```yaml
research_task:
  ...
  guardrail: garanta que cada bullet tenha no m√≠nimo 100 palavras
  ...
```

```python Code
@CrewBase
class InternalCrew:
    agents_config = "config/agents.yaml"
    tasks_config = "config/tasks.yaml"

    ...
    @task
    def research_task(self):
        return Task(config=self.tasks_config["research_task"])  # type: ignore[index]
    ...
```

#### Use modelos customizados para gera√ß√£o de c√≥digo

```python Code
from crewai import Task
from crewai.llm import LLM

task = Task(
    description="Gerar dados em JSON",
    expected_output="Objeto JSON v√°lido",
    guardrail=LLMGuardrail(
        description="Garanta que a resposta √© um objeto JSON v√°lido",
        llm=LLM(model="gpt-4o-mini"),
    )
)
```

### Como Guardrails Funcionam

1. **Atributo Opcional**: Guardrails s√£o opcionais por tarefa, permitindo adicionar valida√ß√£o s√≥ onde for necess√°rio.
2. **Momento de Execu√ß√£o**: A fun√ß√£o guardrail √© executada antes do in√≠cio da pr√≥xima tarefa, garantindo fluxo de dados v√°lido entre tarefas.
3. **Formato de Retorno**: Guardrails devem retornar uma tupla `(sucesso, dados)`:
   * Se `sucesso` √© `True`, `dados` √© o resultado validado/transformado
   * Se `sucesso` √© `False`, `dados` √© a mensagem de erro
4. **Roteamento do Resultado**:
   * Sucesso (`True`): o resultado √© automaticamente passado para a pr√≥xima tarefa
   * Falha (`False`): o erro √© enviado de volta ao agente para gerar uma nova resposta

### Casos Comuns de Uso

#### Valida√ß√£o de Formato de Dados

```python Code
def validate_email_format(result: str) -> Tuple[bool, Union[str, str]]:
    """Garante que a sa√≠da contenha um e-mail v√°lido."""
    import re
    email_pattern = r'^[\w\.-]+@[\w\.-]+\.\w+$'
    if re.match(email_pattern, result.strip()):
        return (True, result.strip())
    return (False, "A sa√≠da deve ser um e-mail v√°lido")
```

#### Filtragem de Conte√∫do

```python Code
def filter_sensitive_info(result: str) -> Tuple[bool, Union[str, str]]:
    """Remove ou valida informa√ß√µes sens√≠veis."""
    sensitive_patterns = ['SSN:', 'password:', 'secret:']
    for pattern in sensitive_patterns:
        if pattern.lower() in result.lower():
            return (False, f"A sa√≠da cont√©m informa√ß√£o sens√≠vel ({pattern})")
    return (True, result)
```

#### Transforma√ß√£o de Dados

```python Code
def normalize_phone_number(result: str) -> Tuple[bool, Union[str, str]]:
    """Garante que n√∫meros de telefone estejam em formato consistente."""
    import re
    digits = re.sub(r'\D', '', result)
    if len(digits) == 10:
        formatted = f"({digits[:3]}) {digits[3:6]}-{digits[6:]}"
        return (True, formatted)
    return (False, "A sa√≠da deve ser um telefone com 10 d√≠gitos")
```

### Recursos Avan√ßados

#### Encadeando M√∫ltiplas Valida√ß√µes

```python Code
def chain_validations(*validators):
    """Encadeia m√∫ltiplos validadores."""
    def combined_validator(result):
        for validator in validators:
            success, data = validator(result)
            if not success:
                return (False, data)
            result = data
        return (True, result)
    return combined_validator

# Uso
task = Task(
    description="Obtenha informa√ß√µes de contato do usu√°rio",
    expected_output="E-mail e telefone",
    guardrail=chain_validations(
        validate_email_format,
        filter_sensitive_info
    )
)
```

#### L√≥gica Customizada de Retentativas

```python Code
task = Task(
    description="Gerar dados",
    expected_output="Dados v√°lidos",
    guardrail=validate_data,
    max_retries=5  # Sobrescreve o limite padr√£o de tentativas
)
```

## Criando Diret√≥rios ao Salvar Arquivos

Agora √© poss√≠vel especificar se uma tarefa deve criar diret√≥rios ao salvar sua sa√≠da em arquivo. Isso √© √∫til para organizar outputs e garantir que os caminhos estejam corretos.

```python Code
# ...

save_output_task = Task(
    description='Salve o resumo das not√≠cias de IA em um arquivo',
    expected_output='Arquivo salvo com sucesso',
    agent=research_agent,
    tools=[file_save_tool],
    output_file='outputs/ai_news_summary.txt',
    create_directory=True
)

#...
```

Veja o v√≠deo abaixo para aprender como utilizar sa√≠das estruturadas no CrewAI:

<iframe width="560" height="315" src="https://www.youtube.com/embed/dNpKQk5uxHw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen />

## Conclus√£o

Tarefas s√£o a for√ßa motriz por tr√°s das a√ß√µes dos agentes no CrewAI.
Ao definir corretamente as tarefas e seus resultados, voc√™ prepara seus agentes de IA para trabalhar de forma eficaz, seja de forma independente ou colaborativa.
Equipar tarefas com as ferramentas adequadas, compreender o processo de execu√ß√£o e seguir pr√°ticas s√≥lidas de valida√ß√£o s√£o fundamentais para maximizar o potencial do CrewAI,
assegurando que os agentes estejam devidamente preparados para suas atribui√ß√µes e que as tarefas sejam executadas conforme o esperado.


# Testes
Source: https://docs.crewai.com/pt-BR/concepts/testing

Saiba como testar sua CrewAI Crew e avaliar seu desempenho.

## Vis√£o Geral

Testar √© uma parte crucial do processo de desenvolvimento, sendo essencial para garantir que sua crew est√° performando conforme o esperado. Com o crewAI, voc√™ pode facilmente testar sua crew e avaliar seu desempenho utilizando as funcionalidades de teste integradas.

### Utilizando o Recurso de Teste

Adicionamos o comando de CLI `crewai test` para facilitar o teste da sua crew. Esse comando executar√° sua crew por um n√∫mero especificado de itera√ß√µes e fornecer√° m√©tricas de desempenho detalhadas. Os par√¢metros s√£o `n_iterations` e `model`, ambos opcionais e com valores padr√£o de 2 e `gpt-4o-mini`, respectivamente. Por enquanto, o √∫nico provedor dispon√≠vel √© a OpenAI.

```bash
crewai test
```

Se quiser rodar mais itera√ß√µes ou utilizar um modelo diferente, voc√™ pode especificar os par√¢metros assim:

```bash
crewai test --n_iterations 5 --model gpt-4o
```

ou usando as formas abreviadas:

```bash
crewai test -n 5 -m gpt-4o
```

Ao executar o comando `crewai test`, a crew ser√° executada pelo n√∫mero especificado de itera√ß√µes, e as m√©tricas de desempenho ser√£o exibidas ao final da execu√ß√£o.

Uma tabela de pontua√ß√µes ao final mostrar√° o desempenho da crew em rela√ß√£o √†s seguintes m√©tricas:

<center>**Pontua√ß√µes das Tarefas (1-10, quanto maior melhor)**</center>

| Tarefas/Crew/Agentes  | Exec. 1 | Exec. 2 | M√©d. Total |            Agentes           | Informa√ß√µes Adicionais         |
| :-------------------- | :-----: | :-----: | :--------: | :--------------------------: | :----------------------------- |
| Tarefa 1              |   9,0   |   9,5   |   **9,2**  |     Professional Insights    |                                |
|                       |         |         |            |          Researcher          |                                |
| Tarefa 2              |   9,0   |   10,0  |   **9,5**  | Company Profile Investigator |                                |
| Tarefa 3              |   9,0   |   9,0   |   **9,0**  |      Automation Insights     |                                |
|                       |         |         |            |          Specialist          |                                |
| Tarefa 4              |   9,0   |   9,0   |   **9,0**  |     Final Report Compiler    | Automation Insights Specialist |
| Crew                  |   9,00  |   9,38  |   **9,2**  |                              |                                |
| Tempo de Execu√ß√£o (s) |   126   |   145   |   **135**  |                              |                                |

O exemplo acima mostra os resultados dos testes para duas execu√ß√µes da crew com duas tarefas, apresentando a pontua√ß√£o m√©dia total de cada tarefa e da crew como um todo.


# Ferramentas
Source: https://docs.crewai.com/pt-BR/concepts/tools

Compreendendo e aproveitando ferramentas dentro do framework CrewAI para colabora√ß√£o e execu√ß√£o de tarefas por agentes.

## Vis√£o geral

As ferramentas do CrewAI capacitam agentes com habilidades que v√£o desde busca na web e an√°lise de dados at√© colabora√ß√£o e delega√ß√£o de tarefas entre colegas de trabalho.
Esta documenta√ß√£o descreve como criar, integrar e aproveitar essas ferramentas dentro do framework CrewAI, incluindo um novo foco em ferramentas de colabora√ß√£o.

## O que √© uma Ferramenta?

Uma ferramenta no CrewAI √© uma habilidade ou fun√ß√£o que os agentes podem utilizar para executar diversas a√ß√µes.
Isso inclui ferramentas do [CrewAI Toolkit](https://github.com/joaomdmoura/crewai-tools) e [LangChain Tools](https://python.langchain.com/docs/integrations/tools),
permitindo desde buscas simples at√© intera√ß√µes complexas e trabalho em equipe eficiente entre agentes.

<Note type="info" title="Aprimoramento para Empresas: Reposit√≥rio de Ferramentas">
  O CrewAI Enterprise oferece um Reposit√≥rio de Ferramentas abrangente, com integra√ß√µes pr√©-constru√≠das para sistemas empresariais e APIs comuns. Implemente agentes com ferramentas corporativas em minutos em vez de dias.

  O Reposit√≥rio de Ferramentas Empresariais inclui:

  * Conectores pr√©-constru√≠dos para sistemas empresariais populares
  * Interface para cria√ß√£o de ferramentas personalizadas
  * Controle de vers√£o e funcionalidades de compartilhamento
  * Recursos de seguran√ßa e conformidade
</Note>

## Caracter√≠sticas Principais das Ferramentas

* **Utilidade**: Desenvolvidas para tarefas como busca web, an√°lise de dados, gera√ß√£o de conte√∫do e colabora√ß√£o entre agentes.
* **Integra√ß√£o**: Potencializa as habilidades dos agentes ao integrar ferramentas de forma transparente ao seu fluxo de trabalho.
* **Personaliza√ß√£o**: Oferece flexibilidade para desenvolver ferramentas personalizadas ou utilizar existentes, atendendo necessidades espec√≠ficas dos agentes.
* **Tratamento de Erros**: Incorpora mecanismos robustos de tratamento de erros para garantir opera√ß√£o sem interrup√ß√µes.
* **Mecanismo de Cache**: Possui cache inteligente para otimizar desempenho e reduzir opera√ß√µes redundantes.
* **Suporte Ass√≠ncrono**: Suporta ferramentas s√≠ncronas e ass√≠ncronas, permitindo opera√ß√µes n√£o bloqueantes.

## Utilizando Ferramentas CrewAI

Para aprimorar as capacidades de seus agentes com as ferramentas do CrewAI, comece instalando nosso pacote extra de ferramentas:

```bash
pip install 'crewai[tools]'
```

Aqui est√° um exemplo demonstrando seu uso:

```python Code
import os
from crewai import Agent, Task, Crew
# Importando ferramentas do crewAI
from crewai_tools import (
    DirectoryReadTool,
    FileReadTool,
    SerperDevTool,
    WebsiteSearchTool
)

# Configure as chaves de API
os.environ["SERPER_API_KEY"] = "Your Key" # chave da API serper.dev
os.environ["OPENAI_API_KEY"] = "Your Key"

# Instanciar as ferramentas
docs_tool = DirectoryReadTool(directory='./blog-posts')
file_tool = FileReadTool()
search_tool = SerperDevTool()
web_rag_tool = WebsiteSearchTool()

# Criar agentes
researcher = Agent(
    role='Analista de Mercado',
    goal='Fornecer an√°lise de mercado atualizada da ind√∫stria de IA',
    backstory='Analista especialista com olhar atento para tend√™ncias de mercado.',
    tools=[search_tool, web_rag_tool],
    verbose=True
)

writer = Agent(
    role='Redator de Conte√∫do',
    goal='Criar posts de blog envolventes sobre a ind√∫stria de IA',
    backstory='Redator habilidoso com paix√£o por tecnologia.',
    tools=[docs_tool, file_tool],
    verbose=True
)

# Definir tarefas
research = Task(
    description='Research the latest trends in the AI industry and provide a summary.',
    expected_output='A summary of the top 3 trending developments in the AI industry with a unique perspective on their significance.',
    agent=researcher
)

write = Task(
    description='Write an engaging blog post about the AI industry, based on the research analyst's summary. Draw inspiration from the latest blog posts in the directory.',
    expected_output='A 4-paragraph blog post formatted in markdown with engaging, informative, and accessible content, avoiding complex jargon.',
    agent=writer,
    output_file='blog-posts/new_post.md'  # O post final do blog ser√° salvo aqui
)

# Montar um crew com o planejamento habilitado
crew = Crew(
    agents=[researcher, writer],
    tasks=[research, write],
    verbose=True,
    planning=True,  # Habilitar o recurso de planejamento
)

# Executar tarefas
crew.kickoff()
```

## Ferramentas CrewAI Dispon√≠veis

* **Tratamento de Erros**: Todas as ferramentas s√£o constru√≠das com capacidades de tratamento de erros, permitindo que os agentes administrem exce√ß√µes de forma adequada e prossigam com suas tarefas.
* **Mecanismo de Cache**: Todas as ferramentas suportam cache, possibilitando que agentes reutilizem de forma eficiente resultados obtidos anteriormente, reduzindo a carga em recursos externos e acelerando o tempo de execu√ß√£o. Tamb√©m √© poss√≠vel definir controles mais precisos sobre o mecanismo de cache usando o atributo `cache_function` na ferramenta.

Aqui est√° uma lista das ferramentas dispon√≠veis e suas descri√ß√µes:

| Ferramenta                       | Descri√ß√£o                                                                                            |
| :------------------------------- | :--------------------------------------------------------------------------------------------------- |
| **ApifyActorsTool**              | Ferramenta que integra Apify Actors aos seus fluxos de trabalho para web scraping e automa√ß√£o.       |
| **BrowserbaseLoadTool**          | Ferramenta para intera√ß√£o e extra√ß√£o de dados de navegadores web.                                    |
| **CodeDocsSearchTool**           | Uma ferramenta RAG otimizada para busca em documenta√ß√µes de c√≥digo e documentos t√©cnicos.            |
| **CodeInterpreterTool**          | Ferramenta para interpretar c√≥digo Python.                                                           |
| **ComposioTool**                 | Permite o uso de ferramentas Composio.                                                               |
| **CSVSearchTool**                | Ferramenta RAG projetada para busca em arquivos CSV, ideal para dados estruturados.                  |
| **DALL-E Tool**                  | Ferramenta para gerar imagens utilizando a API do DALL-E.                                            |
| **DirectorySearchTool**          | Ferramenta RAG para busca em diret√≥rios, √∫til para navega√ß√£o em sistemas de arquivos.                |
| **DOCXSearchTool**               | Ferramenta RAG voltada para busca em documentos DOCX, ideal para processar arquivos Word.            |
| **DirectoryReadTool**            | Facilita a leitura e processamento de estruturas de diret√≥rios e seus conte√∫dos.                     |
| **EXASearchTool**                | Ferramenta projetada para buscas exaustivas em diversas fontes de dados.                             |
| **FileReadTool**                 | Permite a leitura e extra√ß√£o de dados de arquivos, suportando diversos formatos.                     |
| **FirecrawlSearchTool**          | Ferramenta para buscar p√°ginas web usando Firecrawl e retornar os resultados.                        |
| **FirecrawlCrawlWebsiteTool**    | Ferramenta para rastrear p√°ginas web utilizando o Firecrawl.                                         |
| **FirecrawlScrapeWebsiteTool**   | Ferramenta para extrair o conte√∫do de URLs usando Firecrawl.                                         |
| **GithubSearchTool**             | Ferramenta RAG para buscar em reposit√≥rios GitHub, √∫til para pesquisa de c√≥digo e documenta√ß√£o.      |
| **SerperDevTool**                | Ferramenta especializada para finalidades de desenvolvimento, com funcionalidades em evolu√ß√£o.       |
| **TXTSearchTool**                | Ferramenta RAG voltada para busca em arquivos de texto (.txt), adaptada para dados n√£o estruturados. |
| **JSONSearchTool**               | Ferramenta RAG para busca em arquivos JSON, voltada ao manuseio de dados estruturados.               |
| **LlamaIndexTool**               | Permite o uso das ferramentas LlamaIndex.                                                            |
| **MDXSearchTool**                | Ferramenta RAG para busca em arquivos Markdown (MDX), √∫til para documenta√ß√£o.                        |
| **PDFSearchTool**                | Ferramenta RAG para busca em documentos PDF, ideal para processar documentos digitalizados.          |
| **PGSearchTool**                 | Ferramenta RAG otimizada para busca em bancos de dados PostgreSQL, adequada para consultas.          |
| **Vision Tool**                  | Ferramenta para gerar imagens utilizando a API do DALL-E.                                            |
| **RagTool**                      | Ferramenta RAG de uso geral, capaz de lidar com diferentes fontes e tipos de dados.                  |
| **ScrapeElementFromWebsiteTool** | Permite extrair elementos espec√≠ficos de sites, √∫til para extra√ß√£o de dados direcionada.             |
| **ScrapeWebsiteTool**            | Facilita o scraping de sites inteiros, ideal para coleta abrangente de dados.                        |
| **WebsiteSearchTool**            | Ferramenta RAG para busca em conte√∫dos de sites, otimizada para extra√ß√£o de dados web.               |
| **XMLSearchTool**                | Ferramenta RAG para busca em arquivos XML, adequada para formatos de dados estruturados.             |
| **YoutubeChannelSearchTool**     | Ferramenta RAG para busca em canais do YouTube, √∫til para an√°lise de conte√∫do em v√≠deo.              |
| **YoutubeVideoSearchTool**       | Ferramenta RAG para busca em v√≠deos do YouTube, ideal para extra√ß√£o de dados de v√≠deo.               |

## Criando suas pr√≥prias Ferramentas

<Tip>
  Desenvolvedores podem criar `ferramentas personalizadas` adaptadas para as necessidades de seus agentes ou utilizar op√ß√µes pr√©-constru√≠das.
</Tip>

Existem duas formas principais de criar uma ferramenta CrewAI:

### Heran√ßa de `BaseTool`

```python Code
from crewai.tools import BaseTool
from pydantic import BaseModel, Field

class MyToolInput(BaseModel):
    """Input schema for MyCustomTool."""
    argument: str = Field(..., description="Description of the argument.")

class MyCustomTool(BaseTool):
    name: str = "Name of my tool"
    description: str = "What this tool does. It's vital for effective utilization."
    args_schema: Type[BaseModel] = MyToolInput

    def _run(self, argument: str) -> str:
        # Seu c√≥digo da ferramenta aqui
        return "Tool's result"
```

## Suporte a Ferramentas Ass√≠ncronas

O CrewAI suporta ferramentas ass√≠ncronas, permitindo que voc√™ implemente ferramentas que realizam opera√ß√µes n√£o bloqueantes, como requisi√ß√µes de rede, I/O de arquivos ou outras opera√ß√µes async sem bloquear o fluxo principal de execu√ß√£o.

### Criando Ferramentas Ass√≠ncronas

Voc√™ pode criar ferramentas ass√≠ncronas de duas formas:

#### 1. Utilizando o Decorador `tool` com Fun√ß√µes Ass√≠ncronas

```python Code
from crewai.tools import tool

@tool("fetch_data_async")
async def fetch_data_async(query: str) -> str:
    """Asynchronously fetch data based on the query."""
    # Simulate async operation
    await asyncio.sleep(1)
    return f"Data retrieved for {query}"
```

#### 2. Implementando M√©todos Ass√≠ncronos em Classes de Ferramentas Personalizadas

```python Code
from crewai.tools import BaseTool

class AsyncCustomTool(BaseTool):
    name: str = "async_custom_tool"
    description: str = "An asynchronous custom tool"

    async def _run(self, query: str = "") -> str:
        """Asynchronously run the tool"""
        # Sua implementa√ß√£o ass√≠ncrona aqui
        await asyncio.sleep(1)
        return f"Processed {query} asynchronously"
```

### Utilizando Ferramentas Ass√≠ncronas

Ferramentas ass√≠ncronas funcionam perfeitamente tanto em fluxos tradicionais do Crew quanto em fluxos baseados em Flow:

```python Code
# No Crew tradicional
agent = Agent(role="researcher", tools=[async_custom_tool])

# Em Flow
class MyFlow(Flow):
    @start()
    async def begin(self):
        crew = Crew(agents=[agent])
        result = await crew.kickoff_async()
        return result
```

O framework CrewAI lida automaticamente com a execu√ß√£o de ferramentas s√≠ncronas e ass√≠ncronas, ent√£o voc√™ n√£o precisa se preocupar com diferen√ßas na chamada.

### Utilizando o Decorador `tool`

```python Code
from crewai.tools import tool
@tool("Name of my tool")
def my_tool(question: str) -> str:
    """Clear description for what this tool is useful for, your agent will need this information to use it."""
    # L√≥gica da fun√ß√£o aqui
    return "Result from your custom tool"
```

### Mecanismo de Cache Personalizado

<Tip>
  As ferramentas podem implementar opcionalmente uma `cache_function` para ajuste fino do comportamento de cache.
  Esta fun√ß√£o determina quando armazenar resultados em cache com base em condi√ß√µes espec√≠ficas, oferecendo controle granular sobre a l√≥gica de cache.
</Tip>

```python Code
from crewai.tools import tool

@tool
def multiplication_tool(first_number: int, second_number: int) -> str:
    """Useful for when you need to multiply two numbers together."""
    return first_number * second_number

def cache_func(args, result):
    # Neste exemplo, s√≥ cacheamos o resultado se for m√∫ltiplo de 2
    cache = result % 2 == 0
    return cache

multiplication_tool.cache_function = cache_func

writer1 = Agent(
        role="Writer",
        goal="You write lessons of math for kids.",
        backstory="You're an expert in writing and you love to teach kids but you know nothing of math.",
        tools=[multiplication_tool],
        allow_delegation=False,
    )
    #...
```

## Conclus√£o

Ferramentas s√£o fundamentais para expandir as capacidades dos agentes CrewAI, permitindo que assumam uma ampla gama de tarefas e colaborem de forma eficiente.
Ao construir solu√ß√µes com CrewAI, aproveite tanto ferramentas existentes quanto personalizadas para potencializar seus agentes e ampliar o ecossistema de IA. Considere utilizar tratamento de erros,
mecanismos de cache e a flexibilidade de argumentos das ferramentas para otimizar o desempenho e as capacidades dos seus agentes.


# Treinamento
Source: https://docs.crewai.com/pt-BR/concepts/training

Aprenda como treinar seus agentes CrewAI fornecendo feedback desde o in√≠cio e obtenha resultados consistentes.

## Vis√£o Geral

O recurso de treinamento no CrewAI permite que voc√™ treine seus agentes de IA usando a interface de linha de comando (CLI).
Ao executar o comando `crewai train -n <n_iterations>`, voc√™ pode especificar o n√∫mero de itera√ß√µes para o processo de treinamento.

Durante o treinamento, o CrewAI utiliza t√©cnicas para otimizar o desempenho dos seus agentes juntamente com o feedback humano.
Isso ajuda os agentes a aprimorar sua compreens√£o, tomada de decis√£o e habilidades de resolu√ß√£o de problemas.

### Treinando sua Crew Usando a CLI

Para utilizar o recurso de treinamento, siga estes passos:

1. Abra seu terminal ou prompt de comando.
2. Navegue at√© o diret√≥rio onde seu projeto CrewAI est√° localizado.
3. Execute o seguinte comando:

```shell
crewai train -n <n_iterations> <filename> (optional)
```

<Tip>
  Substitua `<n_iterations>` pelo n√∫mero desejado de itera√ß√µes de treinamento e `<filename>` pelo nome de arquivo apropriado terminando com `.pkl`.
</Tip>

### Treinando sua Crew Programaticamente

Para treinar sua crew de forma program√°tica, siga estes passos:

1. Defina o n√∫mero de itera√ß√µes para o treinamento.
2. Especifique os par√¢metros de entrada para o processo de treinamento.
3. Execute o comando de treinamento dentro de um bloco try-except para tratar poss√≠veis erros.

```python Code
n_iteracoes = 2
entradas = {"topic": "Treinamento CrewAI"}
nome_arquivo = "seu_modelo.pkl"

try:
    SuaCrew().crew().train(
      n_iterations=n_iteracoes,
      inputs=entradas,
      filename=nome_arquivo
    )
except Exception as e:
    raise Exception(f"Ocorreu um erro ao treinar a crew: {e}")
```

### Pontos Importantes

* **Requisito de N√∫mero Inteiro Positivo:** Certifique-se de que o n√∫mero de itera√ß√µes (`n_iterations`) seja um inteiro positivo. O c√≥digo lan√ßar√° um `ValueError` se essa condi√ß√£o n√£o for atendida.
* **Requisito de Nome de Arquivo:** Certifique-se de que o nome do arquivo termine com `.pkl`. O c√≥digo lan√ßar√° um `ValueError` se essa condi√ß√£o n√£o for atendida.
* **Tratamento de Erros:** O c√≥digo trata erros de subprocessos e exce√ß√µes inesperadas, fornecendo mensagens de erro ao usu√°rio.

√â importante observar que o processo de treinamento pode levar algum tempo, dependendo da complexidade dos seus agentes e tamb√©m exigir√° seu feedback em cada itera√ß√£o.

Uma vez conclu√≠do o treinamento, seus agentes estar√£o equipados com capacidades e conhecimentos aprimorados, prontos para enfrentar tarefas complexas e fornecer insights mais consistentes e valiosos.

Lembre-se de atualizar e treinar seus agentes regularmente para garantir que permane√ßam atualizados com as √∫ltimas informa√ß√µes e avan√ßos na √°rea.

Bom treinamento com o CrewAI! üöÄ


# Prote√ß√£o contra Alucina√ß√µes
Source: https://docs.crewai.com/pt-BR/enterprise/features/hallucination-guardrail

Previna e detecte alucina√ß√µes de IA nas suas tarefas do CrewAI

## Vis√£o Geral

A Prote√ß√£o contra Alucina√ß√µes √© um recurso empresarial que valida o conte√∫do gerado por IA para garantir que esteja fundamentado em fatos e n√£o contenha alucina√ß√µes. Ela analisa as sa√≠das das tarefas em rela√ß√£o ao contexto de refer√™ncia e fornece feedback detalhado quando √© detectado conte√∫do potencialmente alucinado.

## O que s√£o Alucina√ß√µes?

Alucina√ß√µes em IA ocorrem quando modelos de linguagem geram conte√∫dos que parecem plaus√≠veis, mas est√£o factualmente incorretos ou n√£o s√£o suportados pelo contexto fornecido. A Prote√ß√£o contra Alucina√ß√µes ajuda a prevenir esses problemas por meio de:

* Compara√ß√£o das sa√≠das com o contexto de refer√™ncia
* Avalia√ß√£o da fidelidade ao material de origem
* Fornecimento de feedback detalhado sobre conte√∫do problem√°tico
* Suporte a limiares personalizados para rigor da valida√ß√£o

## Uso B√°sico

### Configurando a Prote√ß√£o

```python
from crewai.tasks.hallucination_guardrail import HallucinationGuardrail
from crewai import LLM

# Uso b√°sico - utiliza o expected_output da tarefa como contexto
protecao = HallucinationGuardrail(
    llm=LLM(model="gpt-4o-mini")
)

# Com contexto de refer√™ncia expl√≠cito
protecao_com_contexto = HallucinationGuardrail(
    context="IA ajuda em v√°rias tarefas, incluindo an√°lise e gera√ß√£o.",
    llm=LLM(model="gpt-4o-mini")
)
```

### Adicionando √†s Tarefas

```python
from crewai import Task

# Crie sua tarefa com a prote√ß√£o
minha_tarefa = Task(
    description="Escreva um resumo sobre as capacidades da IA",
    expected_output="Um resumo factual baseado no contexto fornecido",
    agent=meu_agente,
    guardrail=protecao  # Adiciona a prote√ß√£o para validar a sa√≠da
)
```

## Configura√ß√£o Avan√ßada

### Valida√ß√£o com Limiar Personalizado

Para valida√ß√£o mais rigorosa, √© poss√≠vel definir um limiar de fidelidade personalizado (escala de 0-10):

```python
# Prote√ß√£o rigorosa exigindo alta pontua√ß√£o de fidelidade
protecao_rigorosa = HallucinationGuardrail(
    context="Computa√ß√£o qu√¢ntica utiliza qubits que existem em estados de superposi√ß√£o.",
    llm=LLM(model="gpt-4o-mini"),
    threshold=8.0  # Requer pontua√ß√£o >= 8 para validar
)
```

### Incluindo Contexto da Resposta de Ferramentas

Se sua tarefa utiliza ferramentas, voc√™ pode incluir as respostas das ferramentas para valida√ß√£o mais precisa:

```python
# Prote√ß√£o com contexto de resposta da ferramenta
protecao_clima = HallucinationGuardrail(
    context="Informa√ß√µes meteorol√≥gicas atuais para o local solicitado",
    llm=LLM(model="gpt-4o-mini"),
    tool_response="API do Clima retornou: Temperatura 22¬∞C, Umidade 65%, C√©u limpo"
)
```

## Como Funciona

### Processo de Valida√ß√£o

1. **An√°lise de Contexto**: A prote√ß√£o compara a sa√≠da da tarefa com o contexto de refer√™ncia fornecido
2. **Pontua√ß√£o de Fidelidade**: Usa um avaliador interno para atribuir uma pontua√ß√£o de fidelidade (0-10)
3. **Determina√ß√£o do Veredito**: Determina se o conte√∫do √© fiel ou cont√©m alucina√ß√µes
4. **Verifica√ß√£o de Limiar**: Se um limiar personalizado for definido, valida contra essa pontua√ß√£o
5. **Gera√ß√£o de Feedback**: Fornece motivos detalhados caso a valida√ß√£o falhe

### L√≥gica de Valida√ß√£o

* **Modo Padr√£o**: Utiliza valida√ß√£o baseada em veredito (FI√âL vs ALUCINADO)
* **Modo com Limiar**: Requer que a pontua√ß√£o de fidelidade atinja ou supere o limiar especificado
* **Tratamento de Erros**: Lida com erros de avalia√ß√£o de forma elegante e fornece feedback informativo

## Resultados da Prote√ß√£o

A prote√ß√£o retorna resultados estruturados indicando o status da valida√ß√£o:

```python
# Exemplo de estrutura de resultado da prote√ß√£o
{
    "valid": False,
    "feedback": "Content appears to be hallucinated (score: 4.2/10, verdict: HALLUCINATED). The output contains information not supported by the provided context."
}
```

### Propriedades do Resultado

* **valid**: Booleano indicando se a sa√≠da passou na valida√ß√£o
* **feedback**: Explica√ß√£o detalhada quando a valida√ß√£o falha, incluindo:
  * Pontua√ß√£o de fidelidade
  * Classifica√ß√£o do veredito
  * Motivos espec√≠ficos para a falha

## Integra√ß√£o com o Sistema de Tarefas

### Valida√ß√£o Autom√°tica

Quando uma prote√ß√£o √© adicionada √† tarefa, ela valida automaticamente a sa√≠da antes da tarefa ser marcada como conclu√≠da:

```python
# Fluxo de valida√ß√£o de sa√≠da da tarefa
task_output = meu_agente.execute_task(minha_tarefa)
resultado_validacao = protecao(task_output)

if resultado_validacao.valid:
    # Tarefa conclu√≠da com sucesso
    return task_output
else:
    # Tarefa falha com feedback de valida√ß√£o
    raise ValidationError(resultado_validacao.feedback)
```

### Rastreamento de Eventos

A prote√ß√£o se integra ao sistema de eventos do CrewAI para fornecer observabilidade:

* **Valida√ß√£o Iniciada**: Quando a avalia√ß√£o da prote√ß√£o come√ßa
* **Valida√ß√£o Conclu√≠da**: Quando a avalia√ß√£o termina com resultados
* **Falha na Valida√ß√£o**: Quando ocorrem erros t√©cnicos durante a avalia√ß√£o

## Melhores Pr√°ticas

### Diretrizes para o Contexto

<Steps>
  <Step title="Forne√ßa Contexto Abrangente">
    Inclua todas as informa√ß√µes factuais relevantes nas quais a IA deve basear sua sa√≠da:

    ```python
    contexto = """
    Empresa XYZ foi fundada em 2020 e √© especializada em solu√ß√µes de energia renov√°vel.
    Possui 150 funcion√°rios e faturou R$ 50 milh√µes em 2023.
    Seus principais produtos incluem pain√©is solares e turbinas e√≥licas.
    """
    ```
  </Step>

  <Step title="Mantenha o Contexto Relevante">
    Inclua apenas informa√ß√µes diretamente relacionadas √† tarefa para evitar confus√£o:

    ```python
    # Bom: Contexto focado
    contexto = "O clima atual em Nova York √© 18¬∞C com chuva leve."

    # Evite: Informa√ß√µes irrelevantes
    contexto = "The weather is 18¬∞C. The city has 8 million people. Traffic is heavy."
    ```
  </Step>

  <Step title="Atualize o Contexto Regularmente">
    Certifique-se de que seu contexto de refer√™ncia reflita informa√ß√µes atuais e precisas.
  </Step>
</Steps>

### Sele√ß√£o de Limiar

<Steps>
  <Step title="Comece com a Valida√ß√£o Padr√£o">
    Inicie sem limiares personalizados para entender a performance inicial.
  </Step>

  <Step title="Ajuste Conforme as Necessidades">
    * **Conte√∫do cr√≠tico**: Use limiar 8-10 para m√°xima precis√£o
    * **Conte√∫do geral**: Use limiar 6-7 para valida√ß√£o equilibrada
    * **Conte√∫do criativo**: Use limiar 4-5 ou valida√ß√£o padr√£o baseada em veredito
  </Step>

  <Step title="Monitore e Itere">
    Acompanhe os resultados da valida√ß√£o e ajuste os limiares conforme falsos positivos/negativos.
  </Step>
</Steps>

## Considera√ß√µes de Performance

### Impacto no Tempo de Execu√ß√£o

* **Sobrecarga de Valida√ß√£o**: Cada prote√ß√£o adiciona \~1-3 segundos por tarefa
* **Efici√™ncia do LLM**: Escolha modelos eficientes para avalia√ß√£o (ex: gpt-4o-mini)

### Otimiza√ß√£o de Custos

* **Sele√ß√£o de Modelo**: Utilize modelos menores e eficientes para avalia√ß√£o da prote√ß√£o
* **Tamanho do Contexto**: Mantenha o contexto de refer√™ncia conciso, mas abrangente
* **Cache**: Considere armazenar resultados de valida√ß√£o para conte√∫dos repetidos

## Solu√ß√£o de Problemas

<Accordion title="Valida√ß√£o Sempre Falha">
  **Poss√≠veis Causas:**

  * Contexto muito restrito ou n√£o relacionado √† sa√≠da da tarefa
  * Limiar configurado alto demais para o tipo de conte√∫do
  * Contexto de refer√™ncia desatualizado

  **Solu√ß√µes:**

  * Revise e atualize o contexto para corresponder aos requisitos da tarefa
  * Reduza o limiar ou utilize valida√ß√£o padr√£o baseada em veredito
  * Certifique-se de que o contexto esteja atual e correto
</Accordion>

<Accordion title="Falsos Positivos (Conte√∫do V√°lido Marcado como Inv√°lido)">
  **Poss√≠veis Causas:**

  * Limiar alto demais para tarefas criativas ou interpretativas
  * Contexto n√£o cobre todos os aspectos v√°lidos da sa√≠da
  * Modelo de avalia√ß√£o excessivamente conservador

  **Solu√ß√µes:**

  * Reduza o limiar ou utilize valida√ß√£o padr√£o
  * Expanda o contexto para incluir um espectro maior do conte√∫do aceit√°vel
  * Teste com diferentes modelos de avalia√ß√£o
</Accordion>

<Accordion title="Erros de Avalia√ß√£o">
  **Poss√≠veis Causas:**

  * Problemas de conex√£o de rede
  * Modelo LLM indispon√≠vel ou com limite de uso
  * Sa√≠da ou contexto da tarefa em formato inadequado

  **Solu√ß√µes:**

  * Verifique a conectividade de rede e o status do servi√ßo LLM
  * Implemente l√≥gica de retentativas para falhas transit√≥rias
  * Valide o formato da sa√≠da da tarefa antes da avalia√ß√£o da prote√ß√£o
</Accordion>

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nosso suporte para assist√™ncia na configura√ß√£o ou solu√ß√£o de problemas da prote√ß√£o contra alucina√ß√µes.
</Card>


# Integra√ß√µes
Source: https://docs.crewai.com/pt-BR/enterprise/features/integrations

Aplicativos conectados para que seus agentes possam tomar a√ß√µes.

## Vis√£o Geral

Permita que seus agentes autentiquem com qualquer provedor habilitado para OAuth e tomem a√ß√µes. Do Salesforce e HubSpot ao Google e GitHub, voc√™ conta com mais de 16 servi√ßos integrados.

<Frame>
  ![Integra√ß√µes](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew_connectors.png)
</Frame>

## Integra√ß√µes Suportadas

### **Comunica√ß√£o & Colabora√ß√£o**

* **Gmail** - Gerencie e-mails e rascunhos
* **Slack** - Notifica√ß√µes e alertas do workspace
* **Microsoft** - Integra√ß√£o com Office 365 e Teams

### **Gerenciamento de Projetos**

* **Jira** - Rastreamento de issues e gerenciamento de projetos
* **ClickUp** - Gerenciamento de tarefas e produtividade
* **Asana** - Coordena√ß√£o de tarefas e projetos de equipe
* **Notion** - Gerenciamento de p√°ginas e bases de dados
* **Linear** - Gerenciamento de projetos de software e bugs
* **GitHub** - Gerenciamento de reposit√≥rios e issues

### **Gest√£o de Relacionamento com o Cliente**

* **Salesforce** - Gerenciamento de contas e oportunidades de CRM
* **HubSpot** - Gest√£o de pipeline de vendas e contatos
* **Zendesk** - Administra√ß√£o de chamados de suporte ao cliente

### **Neg√≥cios & Finan√ßas**

* **Stripe** - Processamento de pagamentos e gerenciamento de clientes
* **Shopify** - Gest√£o de loja de e-commerce e produtos

### **Produtividade & Armazenamento**

* **Google Sheets** - Sincroniza√ß√£o de dados de planilhas
* **Google Calendar** - Gerenciamento de eventos e agendas
* **Box** - Armazenamento de arquivos e gerenciamento de documentos

e mais est√£o por vir!

## Pr√©-requisitos

Antes de usar as Integra√ß√µes de Autentica√ß√£o, certifique-se de que voc√™ possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com). Voc√™ pode come√ßar com uma avalia√ß√£o gratuita.

## Configurando Integra√ß√µes

### 1. Conecte sua Conta

1. Acesse o [CrewAI Enterprise](https://app.crewai.com)
2. V√° at√© a aba **Integra√ß√µes** - [https://app.crewai.com/crewai\_plus/connectors](https://app.crewai.com/crewai_plus/connectors)
3. Clique em **Conectar** no servi√ßo desejado na se√ß√£o Integra√ß√µes de Autentica√ß√£o
4. Complete o fluxo de autentica√ß√£o OAuth
5. Conceda as permiss√µes necess√°rias para seu caso de uso
6. Obtenha seu Token Enterprise na sua p√°gina de conta do [CrewAI Enterprise](https://app.crewai.com) - [https://app.crewai.com/crewai\_plus/settings/account](https://app.crewai.com/crewai_plus/settings/account)

<Frame>
  ![Integra√ß√µes](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/enterprise_action_auth_token.png)
</Frame>

### 2. Instale as Ferramentas de Integra√ß√£o

Tudo o que voc√™ precisa √© da vers√£o mais recente do pacote `crewai-tools`.

```bash
uv add crewai-tools
```

## Exemplos de Uso

### Uso B√°sico

<Tip>
  Todos os servi√ßos nos quais voc√™ estiver autenticado estar√£o dispon√≠veis como ferramentas. Portanto, tudo que voc√™ precisa fazer √© adicionar o `CrewaiEnterpriseTools` ao seu agente e pronto.
</Tip>

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Obtenha ferramentas enterprise (a ferramenta Gmail ser√° inclu√≠da)
ferramentas_enterprise = CrewaiEnterpriseTools(
    enterprise_token="seu_token_enterprise"
)
# imprima as ferramentas
printf(ferramentas_enterprise)

# Crie um agente com capacidades do Gmail
agente_email = Agent(
    role="Gerente de E-mails",
    goal="Gerenciar e organizar comunica√ß√µes por e-mail",
    backstory="Um assistente de IA especializado em gest√£o de e-mails e comunica√ß√£o.",
    tools=ferramentas_enterprise
)

# Tarefa para enviar um e-mail
tarefa_email = Task(
    description="Redigir e enviar um e-mail de acompanhamento para john@example.com sobre a atualiza√ß√£o do projeto",
    agent=agente_email,
    expected_output="Confirma√ß√£o de que o e-mail foi enviado com sucesso"
)

# Execute a tarefa
crew = Crew(
    agents=[agente_email],
    tasks=[tarefa_email]
)

# Execute o crew
crew.kickoff()
```

### Filtrando Ferramentas

```python
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    actions_list=["gmail_find_email"] # apenas a ferramenta gmail_find_email estar√° dispon√≠vel
)
gmail_tool = enterprise_tools["gmail_find_email"]

agente_gmail = Agent(
    role="Gerente do Gmail",
    goal="Gerenciar comunica√ß√µes e notifica√ß√µes do gmail",
    backstory="Um assistente de IA que ajuda a coordenar comunica√ß√µes no gmail.",
    tools=[gmail_tool]
)

tarefa_notificacao = Task(
    description="Encontrar o e-mail de john@example.com",
    agent=agente_gmail,
    expected_output="E-mail encontrado de john@example.com"
)

# Execute a tarefa
crew = Crew(
    agents=[agente_gmail],
    tasks=[tarefa_notificacao]
)
```

## Melhores Pr√°ticas

### Seguran√ßa

* **Princ√≠pio do Menor Privil√©gio**: Conceda apenas as permiss√µes m√≠nimas exigidas para as tarefas dos seus agentes
* **Auditorias Regulares**: Revise periodicamente as integra√ß√µes conectadas e suas permiss√µes
* **Credenciais Seguras**: Nunca insira credenciais diretamente no c√≥digo; utilize o fluxo seguro de autentica√ß√£o do CrewAI

### Filtrando Ferramentas

Em um crew implantado, voc√™ pode especificar quais a√ß√µes est√£o dispon√≠veis para cada integra√ß√£o a partir da p√°gina de configura√ß√µes do servi√ßo ao qual voc√™ se conectou.

<Frame>
  ![Integra√ß√µes](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/filtering_enterprise_action_tools.png)
</Frame>

### Implanta√ß√µes com Escopo para organiza√ß√µes multiusu√°rio

Voc√™ pode implantar seu crew e associar cada integra√ß√£o a um usu√°rio espec√≠fico. Por exemplo, um crew que se conecta ao Google pode usar a conta do Gmail de um usu√°rio espec√≠fico.

<Tip>
  Isso √© √∫til para organiza√ß√µes multiusu√°rio, onde voc√™ deseja direcionar a integra√ß√£o para um usu√°rio espec√≠fico.
</Tip>

Use o `user_bearer_token` para direcionar a integra√ß√£o a um usu√°rio espec√≠fico; assim, quando o crew for iniciado, ele usar√° o bearer token desse usu√°rio para autenticar com a integra√ß√£o. Se o usu√°rio n√£o estiver logado, o crew n√£o utilizar√° nenhuma integra√ß√£o conectada. Use o bearer token padr√£o para autenticar com as integra√ß√µes que est√£o sendo implantadas com o crew.

<Frame>
  ![Integra√ß√µes](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/user_bearer_token.png)
</Frame>

### Precisa de Ajuda?

<Card title="Precisa de ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nosso time de suporte para assist√™ncia com a configura√ß√£o de integra√ß√µes ou solu√ß√£o de problemas.
</Card>


# Reposit√≥rio de Ferramentas
Source: https://docs.crewai.com/pt-BR/enterprise/features/tool-repository

Usando o Reposit√≥rio de Ferramentas para gerenciar suas ferramentas

## Vis√£o geral

O Reposit√≥rio de Ferramentas √© um gerenciador de pacotes para ferramentas da CrewAI. Ele permite que usu√°rios publiquem, instalem e gerenciem ferramentas que se integram com crews e flows da CrewAI.

As ferramentas podem ser:

* **Privadas**: acess√≠veis apenas dentro da sua organiza√ß√£o (padr√£o)
* **P√∫blicas**: acess√≠veis a todos os usu√°rios CrewAI se publicadas com a flag `--public`

O reposit√≥rio n√£o √© um sistema de controle de vers√µes. Use o Git para rastrear mudan√ßas no c√≥digo e permitir colabora√ß√£o.

## Pr√©-requisitos

Antes de usar o Reposit√≥rio de Ferramentas, certifique-se de que voc√™ possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com)
* [CrewAI CLI](https://docs.crewai.com/concepts/cli#cli) instalada
* uv>=0.5.0 instalado. Veja [como atualizar](https://docs.astral.sh/uv/getting-started/installation/#upgrading-uv)
* [Git](https://git-scm.com) instalado e configurado
* Permiss√µes de acesso para publicar ou instalar ferramentas em sua organiza√ß√£o CrewAI Enterprise

## Instalando ferramentas

Para instalar uma ferramenta:

```bash
crewai tool install <nome-da-ferramenta>
```

Isso instala a ferramenta e a adiciona ao `pyproject.toml`.

## Criando e publicando ferramentas

Para criar um novo projeto de ferramenta:

```bash
crewai tool create <nome-da-ferramenta>
```

Isso gera um projeto de ferramenta estruturado localmente.

Ap√≥s fazer altera√ß√µes, inicialize um reposit√≥rio Git e fa√ßa o commit do c√≥digo:

```bash
git init
git add .
git commit -m "Initial version"
```

Para publicar a ferramenta:

```bash
crewai tool publish
```

Por padr√£o, as ferramentas s√£o publicadas como privadas. Para tornar uma ferramenta p√∫blica:

```bash
crewai tool publish --public
```

Para mais detalhes sobre como construir ferramentas, acesse [Criando suas pr√≥prias ferramentas](https://docs.crewai.com/concepts/tools#creating-your-own-tools).

## Atualizando ferramentas

Para atualizar uma ferramenta publicada:

1. Modifique a ferramenta localmente
2. Atualize a vers√£o no `pyproject.toml` (por exemplo, de `0.1.0` para `0.1.1`)
3. Fa√ßa o commit das altera√ß√µes e publique

```bash
git commit -m "Atualizar vers√£o para 0.1.1"
crewai tool publish
```

## Excluindo ferramentas

Para excluir uma ferramenta:

1. Acesse o [CrewAI Enterprise](https://app.crewai.com)
2. Navegue at√© **Ferramentas**
3. Selecione a ferramenta
4. Clique em **Excluir**

<Warning>
  A exclus√£o √© permanente. Ferramentas exclu√≠das n√£o podem ser restauradas ou reinstaladas.
</Warning>

## Verifica√ß√µes de seguran√ßa

Cada vers√£o publicada passa por verifica√ß√µes autom√°ticas de seguran√ßa e s√≥ fica dispon√≠vel para instala√ß√£o ap√≥s aprova√ß√£o.

Voc√™ pode verificar o status das verifica√ß√µes de seguran√ßa de uma ferramenta em:

`CrewAI Enterprise > Tools > Your Tool > Versions`

<Card title="Precisa de ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para assist√™ncia com integra√ß√£o de API ou resolu√ß√£o de problemas.
</Card>


# Traces
Source: https://docs.crewai.com/pt-BR/enterprise/features/traces

Usando Traces para monitorar seus Crews

## Vis√£o Geral

Traces fornecem visibilidade abrangente sobre as execu√ß√µes dos seus crews, ajudando voc√™ a monitorar o desempenho, depurar problemas e otimizar os fluxos de trabalho dos seus agentes de IA.

## O que s√£o Traces?

Traces no CrewAI Enterprise s√£o registros detalhados de execu√ß√£o que capturam todos os aspectos da opera√ß√£o do seu crew, desde as entradas iniciais at√© as sa√≠das finais. Eles registram:

* Pensamentos e racioc√≠nio do agente
* Detalhes da execu√ß√£o das tarefas
* Uso de ferramentas e resultados
* M√©tricas de consumo de tokens
* Tempos de execu√ß√£o
* Estimativas de custo

<Frame>
  ![Traces Overview](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/traces-overview.png)
</Frame>

## Acessando os Traces

<Steps>
  <Step title="Navegue at√© a aba Traces">
    No seu painel do CrewAI Enterprise, clique em **Traces** para ver todos os registros de execu√ß√£o.
  </Step>

  <Step title="Selecione uma Execu√ß√£o">
    Voc√™ ver√° uma lista de todas as execu√ß√µes do crew, ordenadas por data. Clique em qualquer execu√ß√£o para visualizar seu trace detalhado.
  </Step>
</Steps>

## Entendendo a Interface do Trace

A interface do trace √© dividida em v√°rias se√ß√µes, cada uma fornecendo diferentes insights sobre a execu√ß√£o do seu crew:

### 1. Resumo da Execu√ß√£o

A se√ß√£o superior exibe m√©tricas de alto n√≠vel sobre a execu√ß√£o:

* **Total de Tokens**: N√∫mero de tokens consumidos em todas as tarefas
* **Prompt Tokens**: Tokens usados em prompts para o LLM
* **Completion Tokens**: Tokens gerados nas respostas do LLM
* **Requisi√ß√µes**: N√∫mero de chamadas de API feitas
* **Tempo de Execu√ß√£o**: Dura√ß√£o total da execu√ß√£o do crew
* **Custo Estimado**: Custo aproximado com base no uso de tokens

<Frame>
  ![Execution Summary](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/trace-summary.png)
</Frame>

### 2. Tarefas & Agentes

Esta se√ß√£o mostra todas as tarefas e agentes que fizeram parte da execu√ß√£o do crew:

* Nome da tarefa e atribui√ß√£o do agente
* Agentes e LLMs usados em cada tarefa
* Status (conclu√≠do/falhou)
* Tempo de execu√ß√£o individual da tarefa

<Frame>
  ![Task List](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/trace-tasks.png)
</Frame>

### 3. Sa√≠da Final

Exibe o resultado final produzido pelo crew ap√≥s a conclus√£o de todas as tarefas.

<Frame>
  ![Final Output](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/final-output.png)
</Frame>

### 4. Linha do Tempo da Execu√ß√£o

Uma representa√ß√£o visual de quando cada tarefa come√ßou e terminou, ajudando a identificar gargalos ou padr√µes de execu√ß√£o paralela.

<Frame>
  ![Execution Timeline](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/trace-timeline.png)
</Frame>

### 5. Vis√£o Detalhada da Tarefa

Ao clicar em uma tarefa espec√≠fica na linha do tempo ou na lista de tarefas, voc√™ ver√°:

<Frame>
  ![Detailed Task View](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/trace-detailed-task.png)
</Frame>

* **Task Key**: Identificador √∫nico da tarefa
* **Task ID**: Identificador t√©cnico no sistema
* **Status**: Estado atual (conclu√≠da/em execu√ß√£o/falhou)
* **Agente**: Qual agente executou a tarefa
* **LLM**: Modelo de linguagem usado nesta tarefa
* **In√≠cio/Fim**: Quando a tarefa foi iniciada e conclu√≠da
* **Tempo de Execu√ß√£o**: Dura√ß√£o desta tarefa espec√≠fica
* **Descri√ß√£o da Tarefa**: O que o agente foi instru√≠do a fazer
* **Expected Output**: Qual formato de sa√≠da foi solicitado
* **Input**: Qualquer entrada fornecida a essa tarefa vinda de tarefas anteriores
* **Output**: O resultado real produzido pelo agente

## Usando Traces para Depura√ß√£o

Traces s√£o indispens√°veis para solucionar problemas nos seus crews:

<Steps>
  <Step title="Identifique Pontos de Falha">
    Quando uma execu√ß√£o de crew n√£o produzir os resultados esperados, examine o trace para encontrar onde ocorreu o problema. Procure por:

    * Tarefas que falharam
    * Decis√µes inesperadas dos agentes
    * Erros no uso de ferramentas
    * Instru√ß√µes mal interpretadas

    <Frame>
      ![Failure Points](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/failure.png)
    </Frame>
  </Step>

  <Step title="Otimizar Desempenho">
    Use m√©tricas de execu√ß√£o para identificar gargalos de desempenho:

    * Tarefas que demoraram mais do que o esperado
    * Uso excessivo de tokens
    * Opera√ß√µes redundantes de ferramentas
    * Chamadas de API desnecess√°rias
  </Step>

  <Step title="Melhore a Efici√™ncia de Custos">
    Analise o uso de tokens e as estimativas de custo para otimizar a efici√™ncia do seu crew:

    * Considere usar modelos menores para tarefas mais simples
    * Refine prompts para serem mais concisos
    * Fa√ßa cache de informa√ß√µes acessadas frequentemente
    * Estruture tarefas para minimizar opera√ß√µes redundantes
  </Step>
</Steps>

<Card title="Precisa de ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para assist√™ncia com an√°lise de traces ou outros recursos do CrewAI Enterprise.
</Card>


# Webhook Streaming
Source: https://docs.crewai.com/pt-BR/enterprise/features/webhook-streaming

Usando Webhook Streaming para transmitir eventos para o seu webhook

## Vis√£o Geral

O Enterprise Event Streaming permite que voc√™ receba atualiza√ß√µes em tempo real via webhook sobre suas crews e flows implantados no CrewAI Enterprise, como chamadas de modelo, uso de ferramentas e etapas do flow.

## Uso

Ao utilizar a API Kickoff, inclua um objeto `webhooks` em sua requisi√ß√£o, por exemplo:

# Exemplo de uso da API Kickoff com webhooks

```json
{
  "inputs": {"foo": "bar"},
  "webhooks": {
    "events": ["crew_kickoff_started", "llm_call_started"],
    "url": "https://seu.endpoint/webhook",
    "realtime": false,
    "authentication": {
      "strategy": "bearer",
      "token": "meu-token-secreto"
    }
  }
}
```

Se `realtime` estiver definido como `true`, cada evento ser√° entregue individualmente e imediatamente, com impacto no desempenho da crew/flow.

## Formato do Webhook

Cada webhook envia uma lista de eventos:

# Exemplo de evento enviado pelo webhook

```json
{
  "events": [
    {
      "id": "id-do-evento",
      "execution_id": "id-da-execucao-do-crew",
      "timestamp": "2025-02-16T10:58:44.965Z",
      "type": "llm_call_started",
      "data": {
        "model": "gpt-4",
        "messages": [
          {"role": "system", "content": "Voc√™ √© um assistente."},
          {"role": "user", "content": "Resuma este artigo."}
        ]
      }
    }
  ]
}
```

A estrutura do objeto `data` varia conforme o tipo de evento. Consulte a [lista de eventos](https://github.com/crewAIInc/crewAI/tree/main/src/crewai/utilities/events) no GitHub.

Como as requisi√ß√µes s√£o enviadas via HTTP, a ordem dos eventos n√£o pode ser garantida. Caso precise de ordena√ß√£o, utilize o campo `timestamp`.

## Eventos Suportados

O CrewAI oferece suporte a eventos do sistema e eventos personalizados no Enterprise Event Streaming. Esses eventos s√£o enviados para o endpoint do seu webhook configurado durante a execu√ß√£o das crews e flows.

* `crew_kickoff_started`
* `crew_step_started`
* `crew_step_completed`
* `crew_execution_completed`
* `llm_call_started`
* `llm_call_completed`
* `tool_usage_started`
* `tool_usage_completed`
* `crew_test_failed`
* *...e outros*

Os nomes dos eventos correspondem ao event bus interno. Veja o [c√≥digo fonte no GitHub](https://github.com/crewAIInc/crewAI/tree/main/src/crewai/utilities/events) para a lista completa.

Voc√™ pode emitir seus pr√≥prios eventos personalizados, e eles ser√£o entregues atrav√©s do webhook stream juntamente com os eventos do sistema.

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para assist√™ncia com integra√ß√£o de webhook ou solu√ß√£o de problemas.
</Card>


# Configura√ß√£o do Azure OpenAI
Source: https://docs.crewai.com/pt-BR/enterprise/guides/azure-openai-setup

Configure o Azure OpenAI com o Crew Studio para conex√µes empresariais de LLM

Este guia orienta voc√™ na conex√£o do Azure OpenAI com o Crew Studio para opera√ß√µes de IA empresarial sem interrup√ß√µes.

## Processo de Configura√ß√£o

<Steps>
  <Step title="Acesse o Azure OpenAI Studio">
    1. No Azure, v√° para `Servi√ßos de IA do Azure > selecione sua implanta√ß√£o > abra o Azure OpenAI Studio`.
    2. No menu √† esquerda, clique em `Implanta√ß√µes`. Se n√£o houver nenhuma, crie uma implanta√ß√£o com o modelo desejado.
    3. Uma vez criada, selecione sua implanta√ß√£o e localize o `Target URI` e a `Key` no lado direito da p√°gina. Mantenha esta p√°gina aberta, pois voc√™ precisar√° dessas informa√ß√µes.
       <Frame>
         <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/azure-openai-studio.png" alt="Azure OpenAI Studio" />
       </Frame>
  </Step>

  <Step title="Configure a Conex√£o Enterprise do CrewAI">
    4. Em outra aba, abra `CrewAI Enterprise > LLM Connections`. D√™ um nome √† sua LLM Connection, selecione Azure como provedor e escolha o mesmo modelo que voc√™ selecionou no Azure.
    5. Na mesma p√°gina, adicione as vari√°veis de ambiente do passo 3:
       * Uma chamada `AZURE_DEPLOYMENT_TARGET_URL` (usando o Target URI). A URL deve ser parecida com: [https://your-deployment.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-08-01-preview](https://your-deployment.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-08-01-preview)
       * Outra chamada `AZURE_API_KEY` (usando a Key).
    6. Clique em `Add Connection` para salvar sua LLM Connection.
  </Step>

  <Step title="Defina Configura√ß√µes Padr√£o">
    7. Em `CrewAI Enterprise > Settings > Defaults > Crew Studio LLM Settings`, defina a nova LLM Connection e o modelo como padr√£o.
  </Step>

  <Step title="Configure o Acesso √† Rede">
    8. Certifique-se das configura√ß√µes de acesso √† rede:
       * No Azure, v√° para `Azure OpenAI > selecione sua implanta√ß√£o`.
       * Navegue at√© `Resource Management > Networking`.
       * Certifique-se de que a op√ß√£o `Allow access from all networks` est√° habilitada. Se essa configura√ß√£o estiver restrita, o CrewAI pode ser impedido de acessar seu endpoint do Azure OpenAI.
  </Step>
</Steps>

## Verifica√ß√£o

Tudo pronto! O Crew Studio agora utilizar√° sua conex√£o Azure OpenAI. Teste a conex√£o criando um crew ou task simples para garantir que tudo est√° funcionando corretamente.

## Solu√ß√£o de Problemas

Se voc√™ encontrar problemas:

* Verifique se o formato do Target URI corresponde ao padr√£o esperado
* Confira se a API key est√° correta e com as permiss√µes adequadas
* Certifique-se de que o acesso √† rede est√° configurado para permitir conex√µes do CrewAI
* Confirme se o modelo da implanta√ß√£o corresponde ao que voc√™ configurou no CrewAI


# Build Crew
Source: https://docs.crewai.com/pt-BR/enterprise/guides/build-crew

Uma Crew √© um grupo de agentes que trabalham juntos para completar uma tarefa.

## Vis√£o Geral

[CrewAI Enterprise](https://app.crewai.com) simplifica o processo de **cria√ß√£o**, **implanta√ß√£o** e **gerenciamento** dos seus agentes de IA em ambientes de produ√ß√£o.

## Primeiros Passos

<iframe width="100%" height="400" src="https://www.youtube.com/embed/-kSOTtYzgEw" title="Building Crews with CrewAI CLI" frameborder="0" style={{ borderRadius: '10px' }} allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

### Instala√ß√£o e Configura√ß√£o

<Card title="Siga a Instala√ß√£o Padr√£o" icon="wrench" href="/pt-BR/installation">
  Siga nosso guia de instala√ß√£o padr√£o para configurar o CrewAI CLI e criar seu primeiro projeto.
</Card>

### Construindo Sua Crew

<Card title="Tutorial R√°pido" icon="rocket" href="/pt-BR/quickstart">
  Siga nosso tutorial r√°pido para criar sua primeira crew de agentes usando a configura√ß√£o YAML.
</Card>

## Suporte e Recursos

Para suporte ou d√∫vidas espec√≠ficas da vers√£o Enterprise, entre em contato com nossa equipe dedicada atrav√©s do [support@crewai.com](mailto:support@crewai.com).

<Card title="Agende uma Demonstra√ß√£o" icon="calendar" href="mailto:support@crewai.com">
  Reserve um hor√°rio com nossa equipe para saber mais sobre os recursos Enterprise e como eles podem beneficiar sua organiza√ß√£o.
</Card>


# Deploy Crew
Source: https://docs.crewai.com/pt-BR/enterprise/guides/deploy-crew

Implantando um Crew na CrewAI Enterprise

<Note>
  Depois de criar um crew localmente ou pelo Crew Studio, o pr√≥ximo passo √© implant√°-lo na plataforma CrewAI Enterprise. Este guia cobre m√∫ltiplos m√©todos de implanta√ß√£o para ajud√°-lo a escolher a melhor abordagem para o seu fluxo de trabalho.
</Note>

## Pr√©-requisitos

<CardGroup cols={2}>
  <Card title="Crew Pronto para Implanta√ß√£o" icon="users">
    Voc√™ deve ter um crew funcional, criado localmente ou pelo Crew Studio
  </Card>

  <Card title="Reposit√≥rio GitHub" icon="github">
    O c√≥digo do seu crew deve estar em um reposit√≥rio do GitHub (para o m√©todo de integra√ß√£o com GitHub)
  </Card>
</CardGroup>

## Op√ß√£o 1: Implantar Usando o CrewAI CLI

A CLI fornece a maneira mais r√°pida de implantar crews desenvolvidos localmente na plataforma Enterprise.

<Steps>
  <Step title="Instale o CrewAI CLI">
    Se ainda n√£o tiver, instale o CrewAI CLI:

    ```bash
    pip install crewai[tools]
    ```

    <Tip>
      A CLI vem com o pacote principal CrewAI, mas o extra `[tools]` garante todas as depend√™ncias de implanta√ß√£o.
    </Tip>
  </Step>

  <Step title="Autentique-se na Plataforma Enterprise">
    Primeiro, voc√™ precisa autenticar sua CLI com a plataforma CrewAI Enterprise:

    ```bash
    # Se j√° possui uma conta CrewAI Enterprise, ou deseja criar uma:
    crewai login
    ```

    Ao executar qualquer um dos comandos, a CLI ir√°:

    1. Exibir uma URL e um c√≥digo de dispositivo √∫nico
    2. Abrir seu navegador para a p√°gina de autentica√ß√£o
    3. Solicitar a confirma√ß√£o do dispositivo
    4. Completar o processo de autentica√ß√£o

    Ap√≥s a autentica√ß√£o bem-sucedida, voc√™ ver√° uma mensagem de confirma√ß√£o no terminal!
  </Step>

  <Step title="Criar uma Implanta√ß√£o">
    No diret√≥rio do seu projeto, execute:

    ```bash
    crewai deploy create
    ```

    Este comando ir√°:

    1. Detectar informa√ß√µes do seu reposit√≥rio GitHub
    2. Identificar vari√°veis de ambiente no seu arquivo `.env` local
    3. Transferir essas vari√°veis com seguran√ßa para a plataforma Enterprise
    4. Criar uma nova implanta√ß√£o com um identificador √∫nico

    Com a cria√ß√£o bem-sucedida, voc√™ ver√° uma mensagem como:

    ```shell
    Deployment created successfully!
    Name: your_project_name
    Deployment ID: 01234567-89ab-cdef-0123-456789abcdef
    Current Status: Deploy Enqueued
    ```
  </Step>

  <Step title="Acompanhe o Progresso da Implanta√ß√£o">
    Acompanhe o status da implanta√ß√£o com:

    ```bash
    crewai deploy status
    ```

    Para ver logs detalhados do processo de build:

    ```bash
    crewai deploy logs
    ```

    <Tip>
      A primeira implanta√ß√£o normalmente leva de 10 a 15 minutos, pois as imagens dos containers s√£o constru√≠das. As pr√≥ximas implanta√ß√µes s√£o bem mais r√°pidas.
    </Tip>
  </Step>
</Steps>

## Comandos Adicionais da CLI

O CrewAI CLI oferece v√°rios comandos para gerenciar suas implanta√ß√µes:

```bash
# Liste todas as suas implanta√ß√µes
crewai deploy list

# Consulte o status de uma implanta√ß√£o
crewai deploy status

# Veja os logs da implanta√ß√£o
crewai deploy logs

# Envie atualiza√ß√µes ap√≥s altera√ß√µes no c√≥digo
crewai deploy push

# Remova uma implanta√ß√£o
crewai deploy remove <deployment_id>
```

## Op√ß√£o 2: Implantar Diretamente pela Interface Web

Voc√™ tamb√©m pode implantar seus crews diretamente pela interface web da CrewAI Enterprise conectando sua conta do GitHub. Esta abordagem n√£o requer utilizar a CLI na sua m√°quina local.

<Steps>
  <Step title="Enviar no GitHub">
    Voc√™ precisa subir seu crew para um reposit√≥rio do GitHub. Caso ainda n√£o tenha criado um crew, voc√™ pode [seguir este tutorial](/pt-BR/quickstart).
  </Step>

  <Step title="Conectando o GitHub ao CrewAI Enterprise">
    1. Fa√ßa login em [CrewAI Enterprise](https://app.crewai.com)
    2. Clique no bot√£o "Connect GitHub"

    <Frame>
      ![Bot√£o Connect GitHub](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/connect-github.png)
    </Frame>
  </Step>

  <Step title="Selecionar o Reposit√≥rio">
    Ap√≥s conectar sua conta GitHub, voc√™ poder√° selecionar qual reposit√≥rio deseja implantar:

    <Frame>
      ![Selecionar Reposit√≥rio](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/select-repo.png)
    </Frame>
  </Step>

  <Step title="Definir as Vari√°veis de Ambiente">
    Antes de implantar, voc√™ precisar√° configurar as vari√°veis de ambiente para conectar ao seu provedor de LLM ou outros servi√ßos:

    1. Voc√™ pode adicionar vari√°veis individualmente ou em lote
    2. Digite suas vari√°veis no formato `KEY=VALUE` (uma por linha)

    <Frame>
      ![Definir Vari√°veis de Ambiente](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/set-env-variables.png)
    </Frame>
  </Step>

  <Step title="Implante Seu Crew">
    1. Clique no bot√£o "Deploy" para iniciar o processo de implanta√ß√£o
    2. Voc√™ pode monitorar o progresso pela barra de progresso
    3. A primeira implanta√ß√£o geralmente demora de 10 a 15 minutos; as pr√≥ximas ser√£o mais r√°pidas

    <Frame>
      ![Progresso da Implanta√ß√£o](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/deploy-progress.png)
    </Frame>

    Ap√≥s a conclus√£o, voc√™ ver√°:

    * A URL exclusiva do seu crew
    * Um Bearer token para proteger sua API crew
    * Um bot√£o "Delete" caso precise remover a implanta√ß√£o
  </Step>
</Steps>

## ‚ö†Ô∏è Requisitos de Seguran√ßa para Vari√°veis de Ambiente

<Warning>
  **Importante**: A CrewAI Enterprise possui restri√ß√µes de seguran√ßa sobre os nomes de vari√°veis de ambiente que podem causar falha na implanta√ß√£o caso n√£o sejam seguidas.
</Warning>

### Padr√µes de Vari√°veis de Ambiente Bloqueados

Por motivos de seguran√ßa, os seguintes padr√µes de nome de vari√°vel de ambiente s√£o **automaticamente filtrados** e causar√£o problemas de implanta√ß√£o:

**Padr√µes Bloqueados:**

* Vari√°veis terminando em `_TOKEN` (ex: `MY_API_TOKEN`)
* Vari√°veis terminando em `_PASSWORD` (ex: `DB_PASSWORD`)
* Vari√°veis terminando em `_SECRET` (ex: `API_SECRET`)
* Vari√°veis terminando em `_KEY` em certos contextos

**Vari√°veis Bloqueadas Espec√≠ficas:**

* `GITHUB_USER`, `GITHUB_TOKEN`
* `AWS_REGION`, `AWS_DEFAULT_REGION`
* Diversas vari√°veis internas do sistema CrewAI

### Exce√ß√µes Permitidas

Algumas vari√°veis s√£o explicitamente permitidas mesmo coincidindo com os padr√µes bloqueados:

* `AZURE_AD_TOKEN`
* `AZURE_OPENAI_AD_TOKEN`
* `ENTERPRISE_ACTION_TOKEN`
* `CREWAI_ENTEPRISE_TOOLS_TOKEN`

### Como Corrigir Problemas de Nomea√ß√£o

Se sua implanta√ß√£o falhar devido a restri√ß√µes de vari√°veis de ambiente:

```bash
# ‚ùå Estas ir√£o causar falhas na implanta√ß√£o
OPENAI_TOKEN=sk-...
DATABASE_PASSWORD=mysenha
API_SECRET=segredo123

# ‚úÖ Utilize estes padr√µes de nomea√ß√£o
OPENAI_API_KEY=sk-...
DATABASE_CREDENTIALS=mysenha
API_CONFIG=segredo123
```

### Melhores Pr√°ticas

1. **Use conven√ß√µes padr√£o de nomenclatura**: `PROVIDER_API_KEY` em vez de `PROVIDER_TOKEN`
2. **Teste localmente primeiro**: Certifique-se de que seu crew funciona com as vari√°veis renomeadas
3. **Atualize seu c√≥digo**: Altere todas as refer√™ncias aos nomes antigos das vari√°veis
4. **Documente as mudan√ßas**: Mantenha registro das vari√°veis renomeadas para seu time

<Tip>
  Se voc√™ se deparar com falhas de implanta√ß√£o com erros enigm√°ticos de vari√°veis de ambiente, confira primeiro os nomes das vari√°veis em rela√ß√£o a esses padr√µes.
</Tip>

### Interaja com Seu Crew Implantado

Ap√≥s a implanta√ß√£o, voc√™ pode acessar seu crew por meio de:

1. **REST API**: A plataforma gera um endpoint HTTPS exclusivo com estas rotas principais:
   * `/inputs`: Lista os par√¢metros de entrada requeridos
   * `/kickoff`: Inicia uma execu√ß√£o com os inputs fornecidos
   * `/status/{kickoff_id}`: Consulta o status da execu√ß√£o

2. **Interface Web**: Acesse [app.crewai.com](https://app.crewai.com) para visualizar:
   * **Aba Status**: Informa√ß√µes da implanta√ß√£o, detalhes do endpoint da API e token de autentica√ß√£o
   * **Aba Run**: Visualiza√ß√£o da estrutura do seu crew
   * **Aba Executions**: Hist√≥rico de todas as execu√ß√µes
   * **Aba Metrics**: An√°lises de desempenho
   * **Aba Traces**: Insights detalhados das execu√ß√µes

### Dispare uma Execu√ß√£o

No dashboard Enterprise, voc√™ pode:

1. Clicar no nome do seu crew para abrir seus detalhes
2. Selecionar "Trigger Crew" na interface de gerenciamento
3. Inserir os inputs necess√°rios no modal exibido
4. Monitorar o progresso √† medida que a execu√ß√£o avan√ßa pelo pipeline

### Monitoramento e An√°lises

A plataforma Enterprise oferece recursos abrangentes de observabilidade:

* **Gest√£o das Execu√ß√µes**: Acompanhe execu√ß√µes ativas e conclu√≠das
* **Traces**: Quebra detalhada de cada execu√ß√£o
* **M√©tricas**: Uso de tokens, tempos de execu√ß√£o e custos
* **Visualiza√ß√£o em Linha do Tempo**: Representa√ß√£o visual das sequ√™ncias de tarefas

### Funcionalidades Avan√ßadas

A plataforma Enterprise tamb√©m oferece:

* **Gerenciamento de Vari√°veis de Ambiente**: Armazene e gerencie com seguran√ßa as chaves de API
* **Conex√µes com LLM**: Configure integra√ß√µes com diversos provedores de LLM
* **Reposit√≥rio Custom Tools**: Crie, compartilhe e instale ferramentas
* **Crew Studio**: Monte crews via interface de chat sem escrever c√≥digo

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para ajuda com quest√µes de implanta√ß√£o ou d√∫vidas sobre a plataforma Enterprise.
</Card>


# Ativar Crew Studio
Source: https://docs.crewai.com/pt-BR/enterprise/guides/enable-crew-studio

Ativando o Crew Studio no CrewAI Enterprise

<Tip>
  Crew Studio √© uma poderosa ferramenta **no-code/low-code** que permite criar ou estruturar Crews rapidamente por meio de uma interface conversacional.
</Tip>

## O que √© o Crew Studio?

O Crew Studio √© uma forma inovadora de criar equipes de agentes de IA sem escrever c√≥digo.

<Frame>
  ![Crew Studio Interface](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-studio-interface.png)
</Frame>

Com o Crew Studio, voc√™ pode:

* Conversar com o Crew Assistant para descrever seu problema
* Gerar automaticamente agentes e tarefas
* Selecionar as ferramentas apropriadas
* Configurar os inputs necess√°rios
* Gerar c√≥digo para download e personaliza√ß√£o
* Fazer deploy diretamente na plataforma CrewAI Enterprise

## Etapas de Configura√ß√£o

Antes de come√ßar a usar o Crew Studio, voc√™ precisa configurar suas conex√µes LLM:

<Steps>
  <Step title="Configurar a Conex√£o LLM">
    Acesse a aba **LLM Connections** no painel do CrewAI Enterprise e crie uma nova conex√£o LLM.

    <Note>
      Sinta-se √† vontade para utilizar qualquer provedor LLM suportado pelo CrewAI.
    </Note>

    Configure sua conex√£o LLM:

    * Insira um `Connection Name` (por exemplo, `OpenAI`)
    * Selecione o provedor do modelo: `openai` ou `azure`
    * Selecione os modelos que deseja usar em suas Crews geradas pelo Studio
      * Recomendamos pelo menos `gpt-4o`, `o1-mini` e `gpt-4o-mini`
    * Adicione sua chave de API como uma vari√°vel de ambiente:
      * Para OpenAI: adicione `OPENAI_API_KEY` com sua chave de API
      * Para Azure OpenAI: consulte [este artigo](https://blog.crewai.com/configuring-azure-openai-with-crewai-a-comprehensive-guide/) para detalhes de configura√ß√£o
    * Clique em `Add Connection` para salvar sua configura√ß√£o

    <Frame>
      ![LLM Connection Configuration](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/llm-connection-config.png)
    </Frame>
  </Step>

  <Step title="Verificar Conex√£o Adicionada">
    Assim que concluir a configura√ß√£o, voc√™ ver√° sua nova conex√£o adicionada √† lista de conex√µes dispon√≠veis.

    <Frame>
      ![Connection Added](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/connection-added.png)
    </Frame>
  </Step>

  <Step title="Configurar Padr√µes do LLM">
    No menu principal, v√° em **Settings ‚Üí Defaults** e configure as op√ß√µes padr√£o do LLM:

    * Selecione os modelos padr√£o para agentes e outros componentes
    * Defina as configura√ß√µes padr√£o para o Crew Studio

    Clique em `Save Settings` para aplicar as altera√ß√µes.

    <Frame>
      ![LLM Defaults Configuration](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/llm-defaults.png)
    </Frame>
  </Step>
</Steps>

## Usando o Crew Studio

Agora que voc√™ configurou sua conex√£o LLM e os padr√µes, est√° pronto para come√ßar a usar o Crew Studio!

<Steps>
  <Step title="Acessar o Studio">
    Navegue at√© a se√ß√£o **Studio** no painel do CrewAI Enterprise.
  </Step>

  <Step title="Iniciar uma Conversa">
    Inicie uma conversa com o Crew Assistant descrevendo o problema que deseja resolver:

    ```md
    I need a crew that can research the latest AI developments and create a summary report.
    ```

    O Crew Assistant far√° perguntas de esclarecimento para entender melhor suas necessidades.
  </Step>

  <Step title="Revisar o Crew Gerado">
    Revise a configura√ß√£o do crew gerado, incluindo:

    * Agentes e seus pap√©is
    * Tarefas a serem realizadas
    * Inputs necess√°rios
    * Ferramentas a serem utilizadas

    Esta √© sua oportunidade para refinar a configura√ß√£o antes de prosseguir.
  </Step>

  <Step title="Fazer Deploy ou Baixar">
    Quando estiver satisfeito com a configura√ß√£o, voc√™ pode:

    * Baixar o c√≥digo gerado para personaliza√ß√£o local
    * Fazer deploy do crew diretamente na plataforma CrewAI Enterprise
    * Modificar a configura√ß√£o e gerar o crew novamente
  </Step>

  <Step title="Testar seu Crew">
    Ap√≥s o deploy, teste seu crew com inputs de exemplo para garantir que ele funcione conforme esperado.
  </Step>
</Steps>

<Tip>
  Para melhores resultados, forne√ßa descri√ß√µes claras e detalhadas do que deseja que seu crew realize. Inclua inputs espec√≠ficos e outputs esperados em sua descri√ß√£o.
</Tip>

## Exemplo de Fluxo de Trabalho

Veja um fluxo de trabalho t√≠pico para cria√ß√£o de um crew com o Crew Studio:

<Steps>
  <Step title="Descreva seu Problema">
    Comece descrevendo seu problema:

    ```md
    I need a crew that can analyze financial news and provide investment recommendations
    ```
  </Step>

  <Step title="Responder Perguntas">
    Responda √†s perguntas de esclarecimento do Crew Assistant para refinar seus requisitos.
  </Step>

  <Step title="Revisar o Plano">
    Revise o plano do crew gerado, que pode incluir:

    * Um Research Agent para coletar not√≠cias financeiras
    * Um Analysis Agent para interpretar os dados
    * Um Recommendations Agent para fornecer conselhos de investimento
  </Step>

  <Step title="Aprovar ou Modificar">
    Aprove o plano ou solicite altera√ß√µes, se necess√°rio.
  </Step>

  <Step title="Baixar ou Fazer Deploy">
    Baixe o c√≥digo para personaliza√ß√£o ou fa√ßa o deploy diretamente na plataforma.
  </Step>

  <Step title="Testar e Refinar">
    Teste seu crew com inputs de exemplo e fa√ßa ajustes conforme necess√°rio.
  </Step>
</Steps>

<Card title="Precisa de ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para obter assist√™ncia com o Crew Studio ou qualquer outro recurso do CrewAI Enterprise.
</Card>


# Gatilho HubSpot
Source: https://docs.crewai.com/pt-BR/enterprise/guides/hubspot-trigger

Acione crews do CrewAI diretamente a partir de Workflows do HubSpot

Este guia fornece um processo passo a passo para configurar gatilhos do HubSpot para o CrewAI Enterprise, permitindo iniciar crews diretamente a partir de Workflows do HubSpot.

## Pr√©-requisitos

* Uma conta CrewAI Enterprise
* Uma conta HubSpot com o recurso de [Workflows do HubSpot](https://knowledge.hubspot.com/workflows/create-workflows)

## Etapas de Configura√ß√£o

<Steps>
  <Step title="Conecte sua conta HubSpot com o CrewAI Enterprise">
    * Fa√ßa login na sua `Conta CrewAI Enterprise > Triggers`
    * Selecione `HubSpot` na lista de gatilhos dispon√≠veis
    * Escolha a conta HubSpot que deseja conectar ao CrewAI Enterprise
    * Siga as instru√ß√µes na tela para autorizar o acesso do CrewAI Enterprise √† sua conta HubSpot
    * Uma mensagem de confirma√ß√£o aparecer√° assim que o HubSpot estiver conectado com sucesso ao CrewAI Enterprise
  </Step>

  <Step title="Crie um Workflow no HubSpot">
    * Fa√ßa login na sua `Conta HubSpot > Automations > Workflows > New workflow`
    * Selecione o tipo de workflow que atende √†s suas necessidades (por exemplo, Come√ßar do zero)
    * No construtor de workflow, clique no √≠cone de mais (+) para adicionar uma nova a√ß√£o.
    * Escolha `Integrated apps > CrewAI > Kickoff a Crew`.
    * Selecione a Crew que deseja iniciar.
    * Clique em `Save` para adicionar a a√ß√£o ao seu workflow

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/hubspot-workflow-1.png" alt="HubSpot Workflow 1" />
    </Frame>
  </Step>

  <Step title="Use os resultados da Crew com outras a√ß√µes">
    * Ap√≥s a etapa Kickoff a Crew, clique no √≠cone de mais (+) para adicionar uma nova a√ß√£o.
    * Por exemplo, para enviar uma notifica√ß√£o de e-mail interna, escolha `Communications > Send internal email notification`
    * No campo Body, clique em `Insert data`, selecione `View properties or action outputs from > Action outputs > Crew Result` para incluir dados da Crew no e-mail
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/hubspot-workflow-2.png" alt="HubSpot Workflow 2" />
      </Frame>
    * Configure quaisquer a√ß√µes adicionais necess√°rias
    * Revise as etapas do seu workflow para garantir que tudo est√° configurado corretamente
    * Ative o workflow
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/hubspot-workflow-3.png" alt="HubSpot Workflow 3" />
      </Frame>
  </Step>
</Steps>

## Recursos Adicionais

Para informa√ß√µes mais detalhadas sobre as a√ß√µes dispon√≠veis e op√ß√µes de personaliza√ß√£o, consulte a [Documenta√ß√£o de Workflows do HubSpot](https://knowledge.hubspot.com/workflows/create-workflows).


# Workflows HITL
Source: https://docs.crewai.com/pt-BR/enterprise/guides/human-in-the-loop

Aprenda como implementar workflows Human-In-The-Loop no CrewAI para decis√µes aprimoradas

Human-In-The-Loop (HITL) √© uma abordagem poderosa que combina intelig√™ncia artificial com expertise humana para aprimorar a tomada de decis√£o e melhorar os resultados das tarefas. Este guia mostra como implementar HITL dentro do CrewAI.

## Configurando Workflows HITL

<Steps>
  <Step title="Configure Sua Tarefa">
    Configure sua tarefa com a entrada humana habilitada:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-human-input.png" alt="Crew Human Input" />
    </Frame>
  </Step>

  <Step title="Forne√ßa o URL do Webhook">
    Ao iniciar seu crew, inclua um URL de webhook para entrada humana:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-webhook-url.png" alt="Crew Webhook URL" />
    </Frame>
  </Step>

  <Step title="Receba a Notifica√ß√£o do Webhook">
    Assim que o crew concluir a tarefa que requer entrada humana, voc√™ receber√° uma notifica√ß√£o do webhook contendo:

    * **ID de Execu√ß√£o**
    * **ID da Tarefa**
    * **Sa√≠da da Tarefa**
  </Step>

  <Step title="Revise a Sa√≠da da Tarefa">
    O sistema ir√° pausar no estado `Pending Human Input`. Revise cuidadosamente a sa√≠da da tarefa.
  </Step>

  <Step title="Envie o Feedback Humano">
    Chame o endpoint de retomada do seu crew com as seguintes informa√ß√µes:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-resume-endpoint.png" alt="Crew Resume Endpoint" />
    </Frame>

    <Warning>
      **Impacto do Feedback na Execu√ß√£o da Tarefa**:
      √â crucial ter cuidado ao fornecer o feedback, pois todo o conte√∫do do feedback ser√° incorporado como contexto adicional para as pr√≥ximas execu√ß√µes da tarefa.
    </Warning>

    Isso significa:

    * Todas as informa√ß√µes do seu feedback passam a fazer parte do contexto da tarefa.
    * Detalhes irrelevantes podem prejudicar a execu√ß√£o.
    * Feedbacks concisos e relevantes ajudam a manter o foco e a efici√™ncia da tarefa.
    * Sempre revise atentamente seu feedback antes de envi√°-lo para garantir que ele cont√©m apenas informa√ß√µes pertinentes que ir√£o guiar positivamente a execu√ß√£o da tarefa.
  </Step>

  <Step title="Lide com Feedback Negativo">
    Se voc√™ fornecer um feedback negativo:

    * O crew ir√° tentar executar novamente a tarefa com o contexto adicional do seu feedback.
    * Voc√™ receber√° uma nova notifica√ß√£o de webhook para nova revis√£o.
    * Repita os passos 4-6 at√© estar satisfeito.
  </Step>

  <Step title="Continua√ß√£o da Execu√ß√£o">
    Quando voc√™ enviar um feedback positivo, a execu√ß√£o prosseguir√° para as pr√≥ximas etapas.
  </Step>
</Steps>

## Melhores Pr√°ticas

* **Seja Espec√≠fico**: Forne√ßa feedback claro e acion√°vel que trate diretamente da tarefa em quest√£o
* **Mantenha a Relev√¢ncia**: Inclua apenas informa√ß√µes que possam ajudar a melhorar a execu√ß√£o da tarefa
* **Seja √Ågil**: Responda rapidamente aos prompts HITL para evitar atrasos no workflow
* **Revise Cuidadosamente**: Verifique duas vezes o seu feedback antes de envi√°-lo para garantir precis√£o

## Casos de Uso Comuns

Workflows HITL s√£o particularmente valiosos para:

* Garantia de qualidade e valida√ß√£o
* Cen√°rios de tomada de decis√£o complexa
* Opera√ß√µes sens√≠veis ou de alto risco
* Tarefas criativas que exigem julgamento humano
* Revis√µes de conformidade e regulat√≥rias


# Kickoff Crew
Source: https://docs.crewai.com/pt-BR/enterprise/guides/kickoff-crew

Inicie um Crew no CrewAI Enterprise

## Vis√£o Geral

Uma vez que voc√™ tenha implantado seu crew na plataforma CrewAI Enterprise, √© poss√≠vel iniciar execu√ß√µes pela interface web ou pela API. Este guia aborda ambos os m√©todos.

## M√©todo 1: Usando a Interface Web

### Passo 1: Navegue at√© seu Crew Implantado

1. Fa√ßa login no [CrewAI Enterprise](https://app.crewai.com)
2. Clique no nome do crew na sua lista de projetos
3. Voc√™ ser√° direcionado para a p√°gina de detalhes do crew

<Frame>
  ![Crew Dashboard](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-dashboard.png)
</Frame>

### Passo 2: Iniciar Execu√ß√£o

Na p√°gina de detalhes do seu crew, voc√™ tem duas op√ß√µes para iniciar uma execu√ß√£o:

#### Op√ß√£o A: Kickoff R√°pido

1. Clique no link `Kickoff` na se√ß√£o Test Endpoints
2. Insira os par√¢metros de entrada necess√°rios para seu crew no editor JSON
3. Clique no bot√£o `Send Request`

<Frame>
  ![Kickoff Endpoint](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-endpoint.png)
</Frame>

#### Op√ß√£o B: Usando a Interface Visual

1. Clique na aba `Run` na p√°gina de detalhes do crew
2. Insira os inputs necess√°rios nos campos do formul√°rio
3. Clique no bot√£o `Run Crew`

<Frame>
  ![Run Crew](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/run-crew.png)
</Frame>

### Passo 3: Monitorar o Progresso da Execu√ß√£o

Ap√≥s iniciar a execu√ß√£o:

1. Voc√™ receber√° uma resposta contendo um `kickoff_id` - **copie este ID**
2. Esse ID √© fundamental para o acompanhamento da sua execu√ß√£o

<Frame>
  ![Copy Task ID](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/copy-task-id.png)
</Frame>

### Passo 4: Verificar o Status da Execu√ß√£o

Para monitorar o andamento da sua execu√ß√£o:

1. Clique no endpoint "Status" na se√ß√£o Test Endpoints
2. Cole o `kickoff_id` no campo indicado
3. Clique no bot√£o "Get Status"

<Frame>
  ![Get Status](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/get-status.png)
</Frame>

A resposta de status mostrar√°:

* Estado atual da execu√ß√£o (`running`, `completed`, etc.)
* Detalhes sobre quais tarefas est√£o em andamento
* Quaisquer outputs gerados at√© o momento

### Passo 5: Visualizar Resultados Finais

Quando a execu√ß√£o for conclu√≠da:

1. O status mudar√° para `completed`
2. Voc√™ poder√° visualizar todos os resultados e outputs da execu√ß√£o
3. Para uma vis√£o mais detalhada, acesse a aba `Executions` na p√°gina de detalhes do crew

## M√©todo 2: Usando a API

Voc√™ tamb√©m pode iniciar crews programaticamente usando a REST API do CrewAI Enterprise.

### Autentica√ß√£o

Todas as requisi√ß√µes √† API exigem um bearer token para autentica√ß√£o:

```bash
curl -H "Authorization: Bearer YOUR_CREW_TOKEN" https://your-crew-url.crewai.com
```

Seu bearer token est√° dispon√≠vel na aba Status na p√°gina de detalhes do seu crew.

### Verificando o Status do Crew

Antes de executar opera√ß√µes, voc√™ pode verificar se seu crew est√° funcionando corretamente:

```bash
curl -H "Authorization: Bearer YOUR_CREW_TOKEN" https://your-crew-url.crewai.com
```

Uma resposta de sucesso trar√° uma mensagem indicando que o crew est√° operacional:

```
Healthy%
```

### Passo 1: Recuperar Entradas Necess√°rias

Primeiro, descubra quais entradas seu crew exige:

```bash
curl -X GET \
  -H "Authorization: Bearer YOUR_CREW_TOKEN" \
  https://your-crew-url.crewai.com/inputs
```

A resposta ser√° um objeto JSON contendo um array de par√¢metros de entrada obrigat√≥rios, por exemplo:

```json
{"inputs":["topic","current_year"]}
```

Este exemplo mostra que este crew em particular requer dois inputs: `topic` e `current_year`.

### Passo 2: Iniciar Execu√ß√£o

Inicie a execu√ß√£o fornecendo os inputs obrigat√≥rios:

```bash
curl -X POST \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_CREW_TOKEN" \
  -d '{"inputs": {"topic": "AI Agent Frameworks", "current_year": "2025"}}' \
  https://your-crew-url.crewai.com/kickoff
```

A resposta incluir√° um `kickoff_id` que voc√™ precisar√° para o acompanhamento:

```json
{"kickoff_id":"abcd1234-5678-90ef-ghij-klmnopqrstuv"}
```

### Passo 3: Verificar Status da Execu√ß√£o

Acompanhe o progresso da execu√ß√£o usando o kickoff\_id:

```bash
curl -X GET \
  -H "Authorization: Bearer YOUR_CREW_TOKEN" \
  https://your-crew-url.crewai.com/status/abcd1234-5678-90ef-ghij-klmnopqrstuv
```

## Gerenciando Execu√ß√µes

### Execu√ß√µes de Longa Dura√ß√£o

Para execu√ß√µes que possam demandar mais tempo:

1. Considere implementar um mecanismo de polling para verificar status periodicamente
2. Utilize webhooks (se dispon√≠veis) para notifica√ß√£o quando a execu√ß√£o for conclu√≠da
3. Implemente tratamento de erros para poss√≠veis timeouts

### Contexto da Execu√ß√£o

O contexto da execu√ß√£o inclui:

* Inputs fornecidos no momento do kickoff
* Vari√°veis de ambiente configuradas durante o deploy
* Qualquer estado mantido entre as tarefas

### Depura√ß√£o de Execu√ß√µes com Falha

Se uma execu√ß√£o falhar:

1. Verifique a aba "Executions" para logs detalhados
2. Avalie a aba "Traces" para detalhes passo a passo da execu√ß√£o
3. Procure por respostas LLM e uso de ferramentas nos detalhes do trace

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para obter ajuda com problemas de execu√ß√£o ou d√∫vidas sobre a plataforma Enterprise.
</Card>


# Exporta√ß√£o de Componentes React
Source: https://docs.crewai.com/pt-BR/enterprise/guides/react-component-export

Aprenda como exportar e integrar componentes React do CrewAI Enterprise em suas aplica√ß√µes

Este guia explica como exportar crews do CrewAI Enterprise como componentes React e integr√°-los √†s suas pr√≥prias aplica√ß√µes.

## Exportando um Componente React

<Steps>
  <Step title="Exporte o Componente">
    Clique no menu de op√ß√µes (tr√™s pontos √† direita do seu crew implantado), selecione a op√ß√£o de exporta√ß√£o e salve o arquivo localmente. Usaremos o arquivo `CrewLead.jsx` como exemplo.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/export-react-component.png" alt="Exportar Componente React" />
    </Frame>
  </Step>
</Steps>

## Configurando seu Ambiente React

Para executar este componente React localmente, voc√™ precisar√° configurar um ambiente de desenvolvimento React e integrar este componente em um projeto React.

<Steps>
  <Step title="Instale o Node.js">
    * Baixe e instale o Node.js no site oficial: [https://nodejs.org/](https://nodejs.org/)
    * Escolha a vers√£o LTS (Long Term Support) para maior estabilidade.
  </Step>

  <Step title="Crie um novo projeto React">
    * Abra o Prompt de Comando ou PowerShell
    * Navegue at√© o diret√≥rio onde deseja criar seu projeto
    * Execute o seguinte comando para criar um novo projeto React:

      ```bash
      npx create-react-app my-crew-app
      ```
    * Entre no diret√≥rio do projeto:

      ```bash
      cd my-crew-app
      ```
  </Step>

  <Step title="Instale as depend√™ncias necess√°rias">
    ```bash
    npm install react-dom
    ```
  </Step>

  <Step title="Crie o componente CrewLead">
    * Mova o arquivo baixado `CrewLead.jsx` para a pasta `src` do seu projeto.
  </Step>

  <Step title="Modifique seu App.js para usar o componente CrewLead">
    * Abra o arquivo `src/App.js`
    * Substitua o conte√∫do por algo semelhante a isso:

    ```jsx
    import React from 'react';
    import CrewLead from './CrewLead';

    function App() {
        return (
            <div className="App">
                <CrewLead baseUrl="YOUR_API_BASE_URL" bearerToken="YOUR_BEARER_TOKEN" />
            </div>
        );
    }

    export default App;
    ```

    * Substitua `YOUR_API_BASE_URL` e `YOUR_BEARER_TOKEN` pelos valores reais da sua API.
  </Step>

  <Step title="Inicie o servidor de desenvolvimento">
    * No diret√≥rio do seu projeto, execute:

      ```bash
      npm start
      ```
    * Isso iniciar√° o servidor de desenvolvimento, e seu navegador padr√£o ser√° aberto automaticamente em [http://localhost:3000](http://localhost:3000), onde voc√™ ver√° sua aplica√ß√£o React rodando.
  </Step>
</Steps>

## Personaliza√ß√£o

Voc√™ pode ent√£o personalizar o `CrewLead.jsx` para adicionar cor, t√≠tulo etc.

<Frame>
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/customise-react-component.png" alt="Personalizar Componente React" />
</Frame>

<Frame>
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/customise-react-component-2.png" alt="Personalizar Componente React" />
</Frame>

## Pr√≥ximos Passos

* Personalize o estilo do componente para combinar com o design da sua aplica√ß√£o
* Adicione props adicionais para configura√ß√£o
* Integre com o gerenciamento de estado da sua aplica√ß√£o
* Adicione tratamento de erros e estados de carregamento


# Trigger Salesforce
Source: https://docs.crewai.com/pt-BR/enterprise/guides/salesforce-trigger

Dispare equipes CrewAI a partir de fluxos de trabalho do Salesforce para automa√ß√£o de CRM

A CrewAI Enterprise pode ser acionada a partir do Salesforce para automatizar fluxos de trabalho de gest√£o de relacionamento com o cliente e aprimorar suas opera√ß√µes de vendas.

## Vis√£o Geral

O Salesforce √© uma das principais plataformas de gest√£o de relacionamento com o cliente (CRM), que ajuda empresas a otimizar opera√ß√µes de vendas, atendimento e marketing. Ao configurar triggers da CrewAI a partir do Salesforce, voc√™ pode:

* Automatizar a classifica√ß√£o e qualifica√ß√£o de leads
* Gerar materiais de vendas personalizados
* Aprimorar o atendimento ao cliente com respostas baseadas em IA
* Otimizar an√°lise e relat√≥rios de dados

## Demonstra√ß√£o

<Frame>
  <iframe width="100%" height="400" src="https://www.youtube.com/embed/oJunVqjjfu4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />
</Frame>

## Primeiros Passos

Para configurar triggers no Salesforce:

1. **Contato com o Suporte**: Entre em contato com o suporte da CrewAI Enterprise para obter assist√™ncia na configura√ß√£o dos triggers no Salesforce
2. **Revisar Requisitos**: Certifique-se de possuir as permiss√µes necess√°rias no Salesforce e acesso √† API
3. **Configurar Conex√£o**: Trabalhe com a equipe de suporte para estabelecer a conex√£o entre a CrewAI e sua inst√¢ncia do Salesforce
4. **Testar Triggers**: Verifique se os triggers funcionam corretamente para os seus casos de uso espec√≠ficos

## Casos de Uso

Cen√°rios comuns de uso de triggers Salesforce + CrewAI incluem:

* **Processamento de Leads**: Analisar e classificar leads recebidos automaticamente
* **Gera√ß√£o de Propostas**: Criar propostas personalizadas com base nos dados das oportunidades
* **Insights de Clientes**: Gerar relat√≥rios de an√°lise a partir do hist√≥rico de intera√ß√µes com clientes
* **Automa√ß√£o de Follow-up**: Criar mensagens de follow-up e recomenda√ß√µes personalizadas

## Pr√≥ximos Passos

Para instru√ß√µes detalhadas de configura√ß√£o e op√ß√µes avan√ßadas, entre em contato com o suporte da CrewAI Enterprise, que pode fornecer orienta√ß√µes personalizadas para o seu ambiente Salesforce e necessidades de neg√≥cio.


# Slack Trigger
Source: https://docs.crewai.com/pt-BR/enterprise/guides/slack-trigger

Acione crews do CrewAI diretamente do Slack usando comandos de barra

Este guia explica como iniciar um crew diretamente do Slack usando triggers do CrewAI.

## Pr√©-requisitos

* Trigger do CrewAI para Slack instalado e conectado ao seu workspace do Slack
* Pelo menos um crew configurado no CrewAI

## Etapas de Configura√ß√£o

<Steps>
  <Step title="Garanta que o trigger do CrewAI para Slack est√° configurado">
    No dashboard do CrewAI, navegue at√© a se√ß√£o **Triggers**.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/slack-integration.png" alt="Integra√ß√£o CrewAI Slack" />
    </Frame>

    Verifique se o Slack est√° listado e conectado.
  </Step>

  <Step title="Abra o canal do Slack">
    * Navegue at√© o canal onde voc√™ deseja iniciar o crew.
    * Digite o comando de barra "**/kickoff**" para iniciar o processo de kickoff do crew.
    * Voc√™ dever√° ver "**Kickoff crew**" aparecendo enquanto digita:
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-slack-crew.png" alt="Kickoff crew" />
      </Frame>
    * Pressione Enter ou selecione a op√ß√£o "**Kickoff crew**". Uma caixa de di√°logo intitulada "**Kickoff an AI Crew**" aparecer√°.
  </Step>

  <Step title="Selecione o crew que deseja iniciar">
    * No menu suspenso rotulado "**Select of the crews online:**", escolha o crew que deseja iniciar.
    * No exemplo abaixo, "**prep-for-meeting**" est√° selecionado:
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-slack-crew-dropdown.png" alt="Kickoff crew dropdown" />
      </Frame>
    * Se o seu crew exigir algum input, clique no bot√£o "**Add Inputs**" para fornec√™-los.
      <Note>
        O bot√£o "**Add Inputs**" √© mostrado no exemplo acima, mas ainda n√£o foi clicado.
      </Note>
  </Step>

  <Step title="Clique em Kickoff e aguarde o t√©rmino do crew">
    * Assim que voc√™ tiver selecionado o crew e adicionado os inputs necess√°rios, clique em "**Kickoff**" para iniciar o crew.
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-slack-crew-kickoff.png" alt="Kickoff crew" />
      </Frame>
    * O crew come√ßar√° a ser executado e voc√™ ver√° os resultados no canal do Slack.
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-slack-crew-results.png" alt="Kickoff crew results" />
      </Frame>
  </Step>
</Steps>

## Dicas

* Certifique-se de que voc√™ possui as permiss√µes necess√°rias para usar o comando `/kickoff` em seu workspace do Slack.
* Se voc√™ n√£o visualizar o crew desejado no menu suspenso, verifique se ele est√° devidamente configurado e online no CrewAI.


# Gest√£o de Equipes
Source: https://docs.crewai.com/pt-BR/enterprise/guides/team-management

Aprenda como convidar e gerenciar membros da equipe em sua organiza√ß√£o CrewAI Enterprise

Como administrador de uma conta CrewAI Enterprise, voc√™ pode facilmente convidar novos membros para sua organiza√ß√£o. Este guia ir√° orient√°-lo passo a passo pelo processo.

## Convidando Membros da Equipe

<Steps>
  <Step title="Acesse a P√°gina de Configura√ß√µes">
    * Fa√ßa login na sua conta CrewAI Enterprise
    * Procure o √≠cone de engrenagem (‚öôÔ∏è) no canto superior direito do painel
    * Clique no √≠cone de engrenagem para acessar a p√°gina de **Configura√ß√µes**:
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/settings-page.png" alt="P√°gina de Configura√ß√µes" />
      </Frame>
  </Step>

  <Step title="Navegue at√© a Se√ß√£o de Membros">
    * Na p√°gina de Configura√ß√µes, voc√™ ver√° a aba `Members`
    * Clique na aba `Members` para acessar a p√°gina de **Membros**:
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/members-tab.png" alt="Aba Membros" />
      </Frame>
  </Step>

  <Step title="Convidar Novos Membros">
    * Na se√ß√£o de Membros, voc√™ ver√° uma lista dos membros atuais (incluindo voc√™)
    * Localize o campo de entrada `Email`
    * Digite o endere√ßo de e-mail da pessoa que voc√™ deseja convidar
    * Clique no bot√£o `Invite` para enviar o convite
  </Step>

  <Step title="Repita Conforme Necess√°rio">
    * Voc√™ pode repetir esse processo para convidar v√°rios membros da equipe
    * Cada membro convidado receber√° um convite por e-mail para ingressar na sua organiza√ß√£o
  </Step>
</Steps>

## Adicionando Fun√ß√µes

Voc√™ pode adicionar fun√ß√µes aos membros da equipe para controlar o acesso a diferentes partes da plataforma.

<Steps>
  <Step title="Acesse a P√°gina de Configura√ß√µes">
    * Fa√ßa login na sua conta CrewAI Enterprise
    * Procure o √≠cone de engrenagem (‚öôÔ∏è) no canto superior direito do painel
    * Clique no √≠cone de engrenagem para acessar a p√°gina de **Configura√ß√µes**:
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/settings-page.png" alt="P√°gina de Configura√ß√µes" />
      </Frame>
  </Step>

  <Step title="Navegue at√© a Se√ß√£o de Fun√ß√µes">
    * Na p√°gina de Configura√ß√µes, voc√™ ver√° a aba `Roles`
    * Clique na aba `Roles` para acessar a p√°gina de **Fun√ß√µes**.
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/roles-tab.png" alt="Aba Fun√ß√µes" />
      </Frame>
    * Clique no bot√£o `Add Role` para adicionar uma nova fun√ß√£o.
    * Insira os detalhes e as permiss√µes da fun√ß√£o e clique no bot√£o `Create Role` para criar a fun√ß√£o.
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/add-role-modal.png" alt="Modal Adicionar Fun√ß√£o" />
      </Frame>
  </Step>

  <Step title="Adicionar Fun√ß√µes aos Membros">
    * Na se√ß√£o de Membros, voc√™ ver√° uma lista dos membros atuais (incluindo voc√™)
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/member-accepted-invitation.png" alt="Membro Aceitou Convite" />
      </Frame>
    * Ap√≥s o membro aceitar o convite, voc√™ poder√° adicionar uma fun√ß√£o a ele.
    * Volte para a aba `Roles`
    * V√° at√© o membro ao qual deseja adicionar uma fun√ß√£o e, na coluna `Role`, clique no menu suspenso
    * Selecione a fun√ß√£o que deseja atribuir ao membro
    * Clique no bot√£o `Update` para salvar a fun√ß√£o
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/assign-role.png" alt="Adicionar Fun√ß√£o ao Membro" />
      </Frame>
  </Step>
</Steps>

## Notas Importantes

* **Privil√©gios de Administrador**: Apenas usu√°rios com privil√©gios administrativos podem convidar novos membros
* **Precis√£o do E-mail**: Certifique-se de que voc√™ tem os endere√ßos de e-mail corretos dos membros da equipe
* **Aceite do Convite**: Os membros convidados precisar√£o aceitar o convite para ingressar na sua organiza√ß√£o
* **Notifica√ß√µes por E-mail**: Oriente seus membros a verificarem o e-mail (incluindo a pasta de spam) para localizar o convite

Seguindo estes passos, voc√™ conseguir√° expandir sua equipe e colaborar de forma mais eficaz dentro da sua organiza√ß√£o CrewAI Enterprise.


# Atualizar Crew
Source: https://docs.crewai.com/pt-BR/enterprise/guides/update-crew

Atualizando uma Crew no CrewAI Enterprise

<Note>
  Ap√≥s implantar sua crew no CrewAI Enterprise, pode ser necess√°rio fazer atualiza√ß√µes no c√≥digo, configura√ß√µes de seguran√ßa ou configura√ß√£o.
  Este guia explica como realizar essas opera√ß√µes de atualiza√ß√£o comuns.
</Note>

## Por que atualizar sua Crew?

Por padr√£o, o CrewAI n√£o ir√° buscar atualiza√ß√µes do GitHub automaticamente, ent√£o voc√™ precisar√° acionar manualmente as atualiza√ß√µes, a menos que tenha marcado a op√ß√£o `Auto-update` ao implantar sua crew.

H√° v√°rias raz√µes para querer atualizar sua implanta√ß√£o de crew:

* Voc√™ deseja atualizar o c√≥digo com o commit mais recente que enviou para o GitHub
* Voc√™ deseja redefinir o bearer token por motivos de seguran√ßa
* Voc√™ deseja atualizar vari√°veis de ambiente

## 1. Atualizando o c√≥digo da sua Crew para o √∫ltimo commit

Quando voc√™ fizer push de novos commits no seu reposit√≥rio do GitHub e quiser atualizar sua implanta√ß√£o:

1. Navegue at√© sua crew na plataforma CrewAI Enterprise
2. Clique no bot√£o `Re-deploy` na p√°gina de detalhes da sua crew

<Frame>
  ![Bot√£o Re-deploy](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/redeploy-button.png)
</Frame>

Isso ir√° acionar uma atualiza√ß√£o que pode ser acompanhada pela barra de progresso. O sistema ir√° buscar o c√≥digo mais recente do seu reposit√≥rio e reconstruir sua implanta√ß√£o.

## 2. Redefinindo o Bearer Token

Se precisar gerar um novo bearer token (por exemplo, se suspeitar que o token atual possa ter sido comprometido):

1. Navegue at√© sua crew na plataforma CrewAI Enterprise
2. Encontre a se√ß√£o `Bearer Token`
3. Clique no bot√£o `Reset` ao lado do token atual

<Frame>
  ![Reset Token](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/reset-token.png)
</Frame>

<Warning>
  A redefini√ß√£o do bearer token invalidar√° imediatamente o token anterior. Certifique-se de atualizar quaisquer aplica√ß√µes ou scripts que estejam utilizando o token antigo.
</Warning>

## 3. Atualizando Vari√°veis de Ambiente

Para atualizar as vari√°veis de ambiente da sua crew:

1. Primeiro, acesse a p√°gina de implanta√ß√£o clicando no nome da sua crew

<Frame>
  ![Bot√£o Vari√°veis de Ambiente](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/env-vars-button.png)
</Frame>

2. Localize a se√ß√£o `Environment Variables` (voc√™ dever√° clicar no √≠cone de `Settings` para acess√°-la)
3. Edite as vari√°veis existentes ou adicione novas nos campos fornecidos
4. Clique no bot√£o `Update` ao lado de cada vari√°vel que voc√™ modificar

<Frame>
  ![Atualizar Vari√°veis de Ambiente](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/update-env-vars.png)
</Frame>

5. Por fim, clique no bot√£o `Update Deployment` na parte inferior da p√°gina para aplicar as altera√ß√µes

<Note>
  A atualiza√ß√£o das vari√°veis de ambiente ir√° acionar uma nova implanta√ß√£o, mas isso atualizar√° apenas a configura√ß√£o de ambiente e n√£o o c√≥digo em si.
</Note>

## Ap√≥s atualizar

Ap√≥s realizar qualquer atualiza√ß√£o:

1. O sistema ir√° reconstruir e reimplantar sua crew
2. Voc√™ poder√° monitorar o progresso da implanta√ß√£o em tempo real
3. Quando finalizado, teste sua crew para garantir que as altera√ß√µes est√£o funcionando como esperado

<Tip>
  Se encontrar algum problema ap√≥s a atualiza√ß√£o, √© poss√≠vel visualizar os logs de implanta√ß√£o na plataforma ou entrar em contato com o suporte para obter assist√™ncia.
</Tip>

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para obter assist√™ncia com a atualiza√ß√£o da sua crew ou solu√ß√£o de problemas de implanta√ß√£o.
</Card>


# Automa√ß√£o com Webhook
Source: https://docs.crewai.com/pt-BR/enterprise/guides/webhook-automation

Automatize fluxos de trabalho do CrewAI Enterprise usando webhooks com plataformas como ActivePieces, Zapier e Make.com

O CrewAI Enterprise permite que voc√™ automatize seu fluxo de trabalho usando webhooks. Este artigo ir√° gui√°-lo no processo de configura√ß√£o e uso de webhooks para iniciar a execu√ß√£o do crew, com foco na integra√ß√£o com o ActivePieces, uma plataforma de automa√ß√£o de fluxos de trabalho semelhante ao Zapier e Make.com.

## Configurando Webhooks

<Steps>
  <Step title="Acessando a Interface de Kickoff">
    * Navegue at√© o painel do CrewAI Enterprise
    * Procure pela se√ß√£o `/kickoff`, que √© usada para iniciar a execu√ß√£o do crew
      <Frame>
        <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/kickoff-interface.png" alt="Interface Kickoff" />
      </Frame>
  </Step>

  <Step title="Configurando o Conte√∫do JSON">
    Na se√ß√£o de Conte√∫do JSON, voc√™ dever√° fornecer as seguintes informa√ß√µes:

    * **inputs**: Um objeto JSON contendo:
      * `company`: O nome da empresa (ex.: "tesla")
      * `product_name`: O nome do produto (ex.: "crewai")
      * `form_response`: O tipo de resposta (ex.: "financial")
      * `icp_description`: Uma breve descri√ß√£o do Perfil de Cliente Ideal
      * `product_description`: Uma breve descri√ß√£o do produto
      * `taskWebhookUrl`, `stepWebhookUrl`, `crewWebhookUrl`: URLs para diversos endpoints de webhook (ActivePieces, Zapier, Make.com ou outra plataforma compat√≠vel)
  </Step>

  <Step title="Integra√ß√£o com ActivePieces">
    Neste exemplo usaremos o ActivePieces. Voc√™ pode utilizar outras plataformas, como Zapier e Make.com.

    Para integrar com o ActivePieces:

    1. Crie um novo flow no ActivePieces

    2. Adicione um gatilho (ex.: agendamento `Every Day`)
       <Frame>
         <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-trigger.png" alt="Gatilho ActivePieces" />
       </Frame>

    3. Adicione uma etapa de a√ß√£o HTTP
       * Configure a a√ß√£o como `Send HTTP request`

       * Use o m√©todo `POST`

       * Defina a URL para o endpoint de kickoff do CrewAI Enterprise

       * Adicione os headers necess√°rios (ex.: `Bearer Token`)
         <Frame>
           <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-headers.png" alt="Headers ActivePieces" />
         </Frame>

       * No corpo, inclua o conte√∫do JSON conforme configurado na etapa 2
         <Frame>
           <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-body.png" alt="Body ActivePieces" />
         </Frame>

       * O crew ser√° iniciado no hor√°rio pr√©-definido.
  </Step>

  <Step title="Configurando o Webhook">
    1. Crie um novo flow no ActivePieces e nomeie-o
       <Frame>
         <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-flow.png" alt="Flow ActivePieces" />
       </Frame>

    2. Adicione uma etapa de webhook como gatilho:
       * Selecione `Catch Webhook` como tipo de gatilho

       * Isso ir√° gerar uma URL √∫nica que receber√° requisi√ß√µes HTTP e disparar√° seu flow
         <Frame>
           <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-webhook.png" alt="Webhook ActivePieces" />
         </Frame>

       * Configure o e-mail para usar o corpo de texto do webhook do crew
         <Frame>
           <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/activepieces-email.png" alt="Email ActivePieces" />
         </Frame>
  </Step>
</Steps>

## Exemplos de Output do Webhook

<Tabs>
  <Tab title="Step Webhook">
    `stepWebhookUrl` - Callback executado a cada pensamento interno do agente

    ```json
    {
        "action": "**Preliminary Research Report on the Financial Industry for crewai Enterprise Solution**\n1. Industry Overview and Trends\nThe financial industry in ....\nConclusion:\nThe financial industry presents a fertile ground for implementing AI solutions like crewai, particularly in areas such as digital customer engagement, risk management, and regulatory compliance. Further engagement with the lead is recommended to better tailor the crewai solution to their specific needs and scale.",
        "task_id": "97eba64f-958c-40a0-b61c-625fe635a3c0"
    }
    ```
  </Tab>

  <Tab title="Task Webhook">
    `taskWebhookUrl` - Callback executado ao final de cada task

    ```json
    {
        "description": "Using the information gathered from the lead's data, conduct preliminary research on the lead's industry, company background, and potential use cases for crewai. Focus on finding relevant data that can aid in scoring the lead and planning a strategy to pitch them crewai.The financial industry presents a fertile ground for implementing AI solutions like crewai, particularly in areas such as digital customer engagement, risk management, and regulatory compliance. Further engagement with the lead is recommended to better tailor the crewai solution to their specific needs and scale.",
        "task_id": "97eba64f-958c-40a0-b61c-625fe635a3c0"
    }
    ```
  </Tab>

  <Tab title="Crew Webhook">
    `crewWebhookUrl` - Callback executado ao final da execu√ß√£o do crew

    ```json
    {
        "task_id": "97eba64f-958c-40a0-b61c-625fe635a3c0",
        "result": {
            "lead_score": "Customer service enhancement, and compliance are particularly relevant.",
            "talking_points": [
                "Highlight how crewai's AI solutions can transform customer service with automated, personalized experiences and 24/7 support, improving both customer satisfaction and operational efficiency.",
                "Discuss crewai's potential to help the institution achieve its sustainability goals through better data analysis and decision-making, contributing to responsible investing and green initiatives.",
                "Emphasize crewai's ability to enhance compliance with evolving regulations through efficient data processing and reporting, reducing the risk of non-compliance penalties.",
                "Stress the adaptability of crewai to support both extensive multinational operations and smaller, targeted projects, ensuring the solution grows with the institution's needs."
            ]
        }
    }
    ```
  </Tab>
</Tabs>


# Trigger Zapier
Source: https://docs.crewai.com/pt-BR/enterprise/guides/zapier-trigger

Dispare crews do CrewAI a partir de fluxos de trabalho no Zapier para automatizar fluxos multiaplicativos

Este guia ir√° conduzi-lo pelo processo de configura√ß√£o de triggers no Zapier para o CrewAI Enterprise, permitindo automatizar fluxos de trabalho entre CrewAI Enterprise e outros aplicativos.

## Pr√©-requisitos

* Uma conta CrewAI Enterprise
* Uma conta Zapier
* Uma conta Slack (para este exemplo espec√≠fico)

## Configura√ß√£o Passo a Passo

<Steps>
  <Step title="Configure o Trigger do Slack">
    * No Zapier, crie um novo Zap.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-1.png" alt="Zapier 1" />
    </Frame>
  </Step>

  <Step title="Escolha o Slack como seu app de trigger">
    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-2.png" alt="Zapier 2" />
    </Frame>

    * Selecione `New Pushed Message` como o Evento de Trigger.
    * Conecte sua conta Slack, caso ainda n√£o tenha feito isso.
  </Step>

  <Step title="Configure a a√ß√£o do CrewAI Enterprise">
    * Adicione uma nova etapa de a√ß√£o ao seu Zap.
    * Escolha CrewAI+ como o app de a√ß√£o e Kickoff como Evento de A√ß√£o.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-3.png" alt="Zapier 5" />
    </Frame>
  </Step>

  <Step title="Conecte sua conta CrewAI Enterprise">
    * Conecte sua conta CrewAI Enterprise.
    * Selecione o Crew apropriado para seu fluxo de trabalho.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-4.png" alt="Zapier 6" />
    </Frame>

    * Configure as entradas para o Crew usando os dados da mensagem do Slack.
  </Step>

  <Step title="Formate a sa√≠da do CrewAI Enterprise">
    * Adicione outra etapa de a√ß√£o para formatar a sa√≠da de texto do CrewAI Enterprise.
    * Utilize as ferramentas de formata√ß√£o do Zapier para converter a sa√≠da em Markdown para HTML.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-5.png" alt="Zapier 8" />
    </Frame>

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-6.png" alt="Zapier 9" />
    </Frame>
  </Step>

  <Step title="Envie a sa√≠da por e-mail">
    * Adicione uma etapa final de a√ß√£o para enviar a sa√≠da formatada por e-mail.
    * Escolha seu servi√ßo de e-mail preferido (ex.: Gmail, Outlook).
    * Configure os detalhes do e-mail, incluindo destinat√°rio, assunto e corpo.
    * Insira a sa√≠da formatada do CrewAI Enterprise no corpo do e-mail.

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-7.png" alt="Zapier 7" />
    </Frame>
  </Step>

  <Step title="Dispare o crew a partir do Slack">
    * Digite o texto no seu canal do Slack

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-7b.png" alt="Zapier 10" />
    </Frame>

    * Selecione o bot√£o de tr√™s pontos e ent√£o escolha Push to Zapier

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-8.png" alt="Zapier 11" />
    </Frame>
  </Step>

  <Step title="Selecione o crew e ent√£o pressione Push to Kick Off">
    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/zapier-9.png" alt="Zapier 12" />
    </Frame>
  </Step>
</Steps>

## Dicas para o Sucesso

* Certifique-se de que as entradas do CrewAI Enterprise estejam corretamente mapeadas a partir da mensagem do Slack.
* Teste seu Zap cuidadosamente antes de ativ√°-lo para identificar poss√≠veis problemas.
* Considere adicionar etapas de tratamento de erros para gerenciar poss√≠veis falhas no fluxo.

Seguindo estes passos, voc√™ ter√° configurado com sucesso triggers no Zapier para o CrewAI Enterprise, permitindo fluxos de trabalho automatizados disparados por mensagens no Slack e resultando em notifica√ß√µes por e-mail com a sa√≠da do CrewAI Enterprise.


# Integra√ß√£o com Asana
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/asana

Coordena√ß√£o de tarefas e projetos em equipe com a integra√ß√£o Asana para CrewAI.

## Vis√£o Geral

Permita que seus agentes gerenciem tarefas, projetos e a coordena√ß√£o da equipe atrav√©s do Asana. Crie tarefas, atualize o status de projetos, gerencie atribui√ß√µes e otimize o fluxo de trabalho da sua equipe com automa√ß√£o baseada em IA.

## Pr√©-requisitos

Antes de usar a integra√ß√£o com o Asana, assegure-se de ter:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Uma conta Asana com as permiss√µes apropriadas
* Sua conta Asana conectada atrav√©s da [p√°gina de Integra√ß√µes](https://app.crewai.com/crewai_plus/connectors)

## Configurando a Integra√ß√£o Asana

### 1. Conecte sua Conta Asana

1. Acesse [CrewAI Enterprise Integra√ß√µes](https://app.crewai.com/crewai_plus/connectors)
2. Encontre **Asana** na se√ß√£o Integra√ß√µes de Autentica√ß√£o
3. Clique em **Conectar** e complete o fluxo OAuth
4. Conceda as permiss√µes necess√°rias para gerenciamento de tarefas e projetos
5. Copie seu Token Enterprise em [Configura√ß√µes da Conta](https://app.crewai.com/crewai_plus/settings/account)

### 2. Instale o Pacote Necess√°rio

```bash
uv add crewai-tools
```

## A√ß√µes Dispon√≠veis

<AccordionGroup>
  <Accordion title="ASANA_CREATE_COMMENT">
    **Descri√ß√£o:** Cria um coment√°rio no Asana.

    **Par√¢metros:**

    * `task` (string, obrigat√≥rio): ID da Tarefa - O ID da tarefa √† qual o coment√°rio ser√° adicionado. O coment√°rio ser√° escrito pelo usu√°rio atualmente autenticado.
    * `text` (string, obrigat√≥rio): Texto (exemplo: "Este √© um coment√°rio.").
  </Accordion>

  <Accordion title="ASANA_CREATE_PROJECT">
    **Descri√ß√£o:** Cria um projeto no Asana.

    **Par√¢metros:**

    * `name` (string, obrigat√≥rio): Nome (exemplo: "Itens para comprar").
    * `workspace` (string, obrigat√≥rio): √Årea de trabalho - Use as Configura√ß√µes de Fluxo do Portal Connect para permitir que usu√°rios escolham em qual √°rea de trabalho criar projetos. Por padr√£o, ser√° usada a primeira √°rea de trabalho do usu√°rio se deixado em branco.
    * `team` (string, opcional): Equipe - Use as Configura√ß√µes de Fluxo do Portal Connect para permitir que usu√°rios escolham com qual equipe compartilhar o projeto. Por padr√£o, ser√° usada a primeira equipe do usu√°rio se deixado em branco.
    * `notes` (string, opcional): Notas (exemplo: "Esses s√£o itens que precisamos comprar.").
  </Accordion>

  <Accordion title="ASANA_GET_PROJECTS">
    **Descri√ß√£o:** Obt√©m uma lista de projetos do Asana.

    **Par√¢metros:**

    * `archived` (string, opcional): Arquivado - Escolha "true" para mostrar projetos arquivados, "false" para exibir apenas projetos ativos ou "default" para mostrar ambos.
      * Op√ß√µes: `default`, `true`, `false`
  </Accordion>

  <Accordion title="ASANA_GET_PROJECT_BY_ID">
    **Descri√ß√£o:** Obt√©m um projeto pelo ID no Asana.

    **Par√¢metros:**

    * `projectFilterId` (string, obrigat√≥rio): ID do Projeto.
  </Accordion>

  <Accordion title="ASANA_CREATE_TASK">
    **Descri√ß√£o:** Cria uma tarefa no Asana.

    **Par√¢metros:**

    * `name` (string, obrigat√≥rio): Nome (exemplo: "Nome da tarefa").
    * `workspace` (string, opcional): √Årea de trabalho - Use as Configura√ß√µes de Fluxo do Portal Connect para permitir que usu√°rios escolham em qual √°rea de trabalho criar tarefas. Por padr√£o, ser√° usada a primeira √°rea de trabalho do usu√°rio se deixado em branco.
    * `project` (string, opcional): Projeto - Use as Configura√ß√µes de Fluxo do Portal Connect para permitir que usu√°rios escolham em qual projeto criar a tarefa.
    * `notes` (string, opcional): Notas.
    * `dueOnDate` (string, opcional): Data de Vencimento - A data em que esta tarefa deve ser conclu√≠da. N√£o pode ser usada em conjunto com Due At. (exemplo: "YYYY-MM-DD").
    * `dueAtDate` (string, opcional): Vence Em - A data e hora (timestamp ISO) em que esta tarefa deve ser conclu√≠da. N√£o pode ser usada em conjunto com Due On. (exemplo: "2019-09-15T02:06:58.147Z").
    * `assignee` (string, opcional): Respons√°vel - O ID do usu√°rio Asana a quem esta tarefa ser√° atribu√≠da. Use as Configura√ß√µes de Fluxo do Portal Connect para permitir que usu√°rios selecionem um respons√°vel.
    * `gid` (string, opcional): ID Externo - Um ID da sua aplica√ß√£o para associar esta tarefa. Voc√™ pode usar este ID para sincronizar atualiza√ß√µes com esta tarefa posteriormente.
  </Accordion>

  <Accordion title="ASANA_UPDATE_TASK">
    **Descri√ß√£o:** Atualiza uma tarefa no Asana.

    **Par√¢metros:**

    * `taskId` (string, obrigat√≥rio): ID da Tarefa - O ID da tarefa a ser atualizada.
    * `completeStatus` (string, opcional): Status de Conclus√£o.
      * Op√ß√µes: `true`, `false`
    * `name` (string, opcional): Nome (exemplo: "Nome da Tarefa").
    * `notes` (string, opcional): Notas.
    * `dueOnDate` (string, opcional): Data de Vencimento - A data em que esta tarefa deve ser conclu√≠da. N√£o pode ser usada junto com Due At. (exemplo: "YYYY-MM-DD").
    * `dueAtDate` (string, opcional): Vence Em - A data e hora (timestamp ISO) em que esta tarefa deve ser conclu√≠da. N√£o pode ser usada junto com Due On. (exemplo: "2019-09-15T02:06:58.147Z").
    * `assignee` (string, opcional): Respons√°vel - O ID do usu√°rio Asana a quem esta tarefa ser√° atribu√≠da. Use as Configura√ß√µes de Fluxo do Portal Connect para permitir que usu√°rios selecionem o respons√°vel.
    * `gid` (string, opcional): ID Externo - Um ID da sua aplica√ß√£o para associar a tarefa. Voc√™ pode usar este ID para sincronizar atualiza√ß√µes posteriormente.
  </Accordion>

  <Accordion title="ASANA_GET_TASKS">
    **Descri√ß√£o:** Obt√©m uma lista de tarefas no Asana.

    **Par√¢metros:**

    * `workspace` (string, opcional): √Årea de trabalho - O ID da √°rea de trabalho para filtrar tarefas. Use as Configura√ß√µes de Fluxo do Portal Connect para permitir que usu√°rios selecionem uma √°rea de trabalho.
    * `project` (string, opcional): Projeto - O ID do projeto para filtrar as tarefas. Use as Configura√ß√µes de Fluxo do Portal Connect para permitir que usu√°rios selecionem um projeto.
    * `assignee` (string, opcional): Respons√°vel - O ID do respons√°vel para filtrar tarefas. Use as Configura√ß√µes de Fluxo do Portal Connect para permitir que usu√°rios selecionem um respons√°vel.
    * `completedSince` (string, opcional): Conclu√≠da desde - Retorna apenas tarefas que estejam incompletas ou que tenham sido conclu√≠das desde este hor√°rio (timestamp ISO ou Unix). (exemplo: "2014-04-25T16:15:47-04:00").
  </Accordion>

  <Accordion title="ASANA_GET_TASKS_BY_ID">
    **Descri√ß√£o:** Obt√©m uma lista de tarefas pelo ID no Asana.

    **Par√¢metros:**

    * `taskId` (string, obrigat√≥rio): ID da Tarefa.
  </Accordion>

  <Accordion title="ASANA_GET_TASK_BY_EXTERNAL_ID">
    **Descri√ß√£o:** Obt√©m uma tarefa pelo ID externo no Asana.

    **Par√¢metros:**

    * `gid` (string, obrigat√≥rio): ID Externo - O ID que esta tarefa est√° associada ou sincronizada, de sua aplica√ß√£o.
  </Accordion>

  <Accordion title="ASANA_ADD_TASK_TO_SECTION">
    **Descri√ß√£o:** Adiciona uma tarefa a uma se√ß√£o no Asana.

    **Par√¢metros:**

    * `sectionId` (string, obrigat√≥rio): ID da Se√ß√£o - O ID da se√ß√£o √† qual a tarefa ser√° adicionada.
    * `taskId` (string, obrigat√≥rio): ID da Tarefa - O ID da tarefa. (exemplo: "1204619611402340").
    * `beforeTaskId` (string, opcional): Antes da Tarefa - O ID de uma tarefa nesta se√ß√£o antes da qual esta tarefa ser√° inserida. N√£o pode ser usada junto com After Task ID. (exemplo: "1204619611402340").
    * `afterTaskId` (string, opcional): Ap√≥s a Tarefa - O ID de uma tarefa nesta se√ß√£o ap√≥s a qual esta tarefa ser√° inserida. N√£o pode ser usada junto com Before Task ID. (exemplo: "1204619611402340").
  </Accordion>

  <Accordion title="ASANA_GET_TEAMS">
    **Descri√ß√£o:** Obt√©m uma lista de equipes no Asana.

    **Par√¢metros:**

    * `workspace` (string, obrigat√≥rio): √Årea de trabalho - Retorna as equipes nesta √°rea de trabalho vis√≠veis para o usu√°rio autorizado.
  </Accordion>

  <Accordion title="ASANA_GET_WORKSPACES">
    **Descri√ß√£o:** Obt√©m uma lista de √°reas de trabalho do Asana.

    **Par√¢metros:** Nenhum obrigat√≥rio.
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configura√ß√£o B√°sica do Agente Asana

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Asana tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Asana capabilities
asana_agent = Agent(
    role="Project Manager",
    goal="Manage tasks and projects in Asana efficiently",
    backstory="An AI assistant specialized in project management and task coordination.",
    tools=[enterprise_tools]
)

# Task to create a new project
create_project_task = Task(
    description="Create a new project called 'Q1 Marketing Campaign' in the Marketing workspace",
    agent=asana_agent,
    expected_output="Confirmation that the project was created successfully with project ID"
)

# Run the task
crew = Crew(
    agents=[asana_agent],
    tasks=[create_project_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Espec√≠ficas do Asana

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Asana tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["asana_create_task", "asana_update_task", "asana_get_tasks"]
)

task_manager_agent = Agent(
    role="Task Manager",
    goal="Create and manage tasks efficiently",
    backstory="An AI assistant that focuses on task creation and management.",
    tools=enterprise_tools
)

# Task to create and assign a task
task_management = Task(
    description="Create a task called 'Review quarterly reports' and assign it to the appropriate team member",
    agent=task_manager_agent,
    expected_output="Task created and assigned successfully"
)

crew = Crew(
    agents=[task_manager_agent],
    tasks=[task_management]
)

crew.kickoff()
```

### Gerenciamento Avan√ßado de Projetos

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

project_coordinator = Agent(
    role="Project Coordinator",
    goal="Coordinate project activities and track progress",
    backstory="An experienced project coordinator who ensures projects run smoothly.",
    tools=[enterprise_tools]
)

# Complex task involving multiple Asana operations
coordination_task = Task(
    description="""
    1. Get all active projects in the workspace
    2. For each project, get the list of incomplete tasks
    3. Create a summary report task in the 'Management Reports' project
    4. Add comments to overdue tasks to request status updates
    """,
    agent=project_coordinator,
    expected_output="Summary report created and status update requests sent for overdue tasks"
)

crew = Crew(
    agents=[project_coordinator],
    tasks=[coordination_task]
)

crew.kickoff()
```


# Integra√ß√£o com Box
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/box

Armazenamento de arquivos e gerenciamento de documentos com a integra√ß√£o do Box para CrewAI.

## Vis√£o Geral

Permita que seus agentes gerenciem arquivos, pastas e documentos atrav√©s do Box. Fa√ßa upload de arquivos, organize estruturas de pastas, pesquise conte√∫dos e otimize o gerenciamento de documentos da sua equipe com automa√ß√£o alimentada por IA.

## Pr√©-requisitos

Antes de utilizar a integra√ß√£o com o Box, assegure-se de que voc√™ possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Uma conta Box com as permiss√µes apropriadas
* Sua conta Box conectada atrav√©s da [p√°gina de Integra√ß√µes](https://app.crewai.com/crewai_plus/connectors)

## Configurando a Integra√ß√£o com o Box

### 1. Conecte sua conta Box

1. Acesse [Integra√ß√µes do CrewAI Enterprise](https://app.crewai.com/crewai_plus/connectors)
2. Encontre **Box** na se√ß√£o de Integra√ß√µes de Autentica√ß√£o
3. Clique em **Conectar** e conclua o fluxo de OAuth
4. Conceda as permiss√µes necess√°rias para gerenciamento de arquivos e pastas
5. Copie seu Token Enterprise em [Configura√ß√µes da Conta](https://app.crewai.com/crewai_plus/settings/account)

### 2. Instale o pacote necess√°rio

```bash
uv add crewai-tools
```

## A√ß√µes Dispon√≠veis

<AccordionGroup>
  <Accordion title="BOX_SAVE_FILE">
    **Descri√ß√£o:** Salva um arquivo a partir de uma URL no Box.

    **Par√¢metros:**

    * `fileAttributes` (object, obrigat√≥rio): Atributos - Metadados do arquivo incluindo nome, pasta pai e datas.
      ```json
      {
        "content_created_at": "2012-12-12T10:53:43-08:00",
        "content_modified_at": "2012-12-12T10:53:43-08:00",
        "name": "qwerty.png",
        "parent": { "id": "1234567" }
      }
      ```
    * `file` (string, obrigat√≥rio): URL do arquivo - Os arquivos devem ter menos de 50MB. (exemplo: "[https://picsum.photos/200/300](https://picsum.photos/200/300)").
  </Accordion>

  <Accordion title="BOX_SAVE_FILE_FROM_OBJECT">
    **Descri√ß√£o:** Salva um arquivo no Box.

    **Par√¢metros:**

    * `file` (string, obrigat√≥rio): Arquivo - Aceita um Objeto de Arquivo contendo os dados. O arquivo deve ter menos de 50MB.
    * `fileName` (string, obrigat√≥rio): Nome do Arquivo (exemplo: "qwerty.png").
    * `folder` (string, opcional): Pasta - Use as configura√ß√µes de workflow do Connect Portal para permitir que usu√°rios escolham o destino da pasta. Caso em branco, o padr√£o √© a pasta raiz do usu√°rio.
  </Accordion>

  <Accordion title="BOX_GET_FILE_BY_ID">
    **Descri√ß√£o:** Obt√©m um arquivo pelo ID no Box.

    **Par√¢metros:**

    * `fileId` (string, obrigat√≥rio): ID do arquivo - Identificador √∫nico que representa um arquivo. (exemplo: "12345").
  </Accordion>

  <Accordion title="BOX_LIST_FILES">
    **Descri√ß√£o:** Lista arquivos no Box.

    **Par√¢metros:**

    * `folderId` (string, obrigat√≥rio): ID da pasta - Identificador √∫nico que representa uma pasta. (exemplo: "0").
    * `filterFormula` (object, opcional): Um filtro em forma normal disjuntiva - OU de grupos E de condi√ß√µes √∫nicas.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "direction",
                "operator": "$stringExactlyMatches",
                "value": "ASC"
              }
            ]
          }
        ]
      }
      ```
  </Accordion>

  <Accordion title="BOX_CREATE_FOLDER">
    **Descri√ß√£o:** Cria uma pasta no Box.

    **Par√¢metros:**

    * `folderName` (string, obrigat√≥rio): Nome - Nome para a nova pasta. (exemplo: "Nova Pasta").
    * `folderParent` (object, obrigat√≥rio): Pasta Pai - A pasta onde a nova pasta ser√° criada.
      ```json
      {
        "id": "123456"
      }
      ```
  </Accordion>

  <Accordion title="BOX_MOVE_FOLDER">
    **Descri√ß√£o:** Move uma pasta no Box.

    **Par√¢metros:**

    * `folderId` (string, obrigat√≥rio): ID da pasta - Identificador √∫nico que representa uma pasta. (exemplo: "0").
    * `folderName` (string, obrigat√≥rio): Nome - Nome da pasta. (exemplo: "Nova Pasta").
    * `folderParent` (object, obrigat√≥rio): Nova pasta pai de destino.
      ```json
      {
        "id": "123456"
      }
      ```
  </Accordion>

  <Accordion title="BOX_GET_FOLDER_BY_ID">
    **Descri√ß√£o:** Obt√©m uma pasta pelo ID no Box.

    **Par√¢metros:**

    * `folderId` (string, obrigat√≥rio): ID da pasta - Identificador √∫nico que representa uma pasta. (exemplo: "0").
  </Accordion>

  <Accordion title="BOX_SEARCH_FOLDERS">
    **Descri√ß√£o:** Pesquisa pastas no Box.

    **Par√¢metros:**

    * `folderId` (string, obrigat√≥rio): ID da pasta - A pasta na qual pesquisar.
    * `filterFormula` (object, opcional): Um filtro em forma normal disjuntiva - OU de grupos E de condi√ß√µes √∫nicas.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "sort",
                "operator": "$stringExactlyMatches",
                "value": "name"
              }
            ]
          }
        ]
      }
      ```
  </Accordion>

  <Accordion title="BOX_DELETE_FOLDER">
    **Descri√ß√£o:** Exclui uma pasta no Box.

    **Par√¢metros:**

    * `folderId` (string, obrigat√≥rio): ID da pasta - Identificador √∫nico que representa uma pasta. (exemplo: "0").
    * `recursive` (boolean, opcional): Recursivo - Exclui uma pasta que n√£o est√° vazia, deletando de forma recursiva a pasta e todo o seu conte√∫do.
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configura√ß√£o B√°sica de Agente Box

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Box tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Box capabilities
box_agent = Agent(
    role="Document Manager",
    goal="Manage files and folders in Box efficiently",
    backstory="An AI assistant specialized in document management and file organization.",
    tools=[enterprise_tools]
)

# Task to create a folder structure
create_structure_task = Task(
    description="Create a folder called 'Project Files' in the root directory and upload a document from URL",
    agent=box_agent,
    expected_output="Folder created and file uploaded successfully"
)

# Run the task
crew = Crew(
    agents=[box_agent],
    tasks=[create_structure_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Espec√≠ficas do Box

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Box tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["box_create_folder", "box_save_file", "box_list_files"]
)

file_organizer_agent = Agent(
    role="File Organizer",
    goal="Organize and manage file storage efficiently",
    backstory="An AI assistant that focuses on file organization and storage management.",
    tools=enterprise_tools
)

# Task to organize files
organization_task = Task(
    description="Create a folder structure for the marketing team and organize existing files",
    agent=file_organizer_agent,
    expected_output="Folder structure created and files organized"
)

crew = Crew(
    agents=[file_organizer_agent],
    tasks=[organization_task]
)

crew.kickoff()
```

### Gerenciamento Avan√ßado de Arquivos

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

file_manager = Agent(
    role="File Manager",
    goal="Maintain organized file structure and manage document lifecycle",
    backstory="An experienced file manager who ensures documents are properly organized and accessible.",
    tools=[enterprise_tools]
)

# Complex task involving multiple Box operations
management_task = Task(
    description="""
    1. List all files in the root folder
    2. Create monthly archive folders for the current year
    3. Move old files to appropriate archive folders
    4. Generate a summary report of the file organization
    """,
    agent=file_manager,
    expected_output="Files organized into archive structure with summary report"
)

crew = Crew(
    agents=[file_manager],
    tasks=[management_task]
)

crew.kickoff()
```


# Integra√ß√£o com ClickUp
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/clickup

Gerenciamento de tarefas e produtividade com integra√ß√£o ClickUp para CrewAI.

## Vis√£o Geral

Permita que seus agentes gerenciem tarefas, projetos e fluxos de produtividade por meio do ClickUp. Crie e atualize tarefas, organize projetos, gerencie a designa√ß√£o de equipes e otimize o gerenciamento da sua produtividade com automa√ß√£o impulsionada por IA.

## Pr√©-requisitos

Antes de utilizar a integra√ß√£o com o ClickUp, certifique-se de que voc√™ possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Uma conta ClickUp com as permiss√µes apropriadas
* Sua conta ClickUp conectada pela [P√°gina de Integra√ß√µes](https://app.crewai.com/crewai_plus/connectors)

## Configurando a Integra√ß√£o com o ClickUp

### 1. Conecte sua Conta ClickUp

1. Acesse [CrewAI Enterprise Integra√ß√µes](https://app.crewai.com/crewai_plus/connectors)
2. Encontre **ClickUp** na se√ß√£o Integra√ß√µes de Autentica√ß√£o
3. Clique em **Conectar** e complete o fluxo OAuth
4. Conceda as permiss√µes necess√°rias para gerenciamento de tarefas e projetos
5. Copie seu Token Enterprise das [Configura√ß√µes da Conta](https://app.crewai.com/crewai_plus/settings/account)

### 2. Instale o Pacote Necess√°rio

```bash
uv add crewai-tools
```

## A√ß√µes Dispon√≠veis

<AccordionGroup>
  <Accordion title="CLICKUP_SEARCH_TASKS">
    **Descri√ß√£o:** Busque tarefas no ClickUp utilizando filtros avan√ßados.

    **Par√¢metros:**

    * `taskFilterFormula` (objeto, opcional): Um filtro em forma normal disjuntiva - OU de grupos E de condi√ß√µes individuais.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "statuses%5B%5D",
                "operator": "$stringExactlyMatches",
                "value": "open"
              }
            ]
          }
        ]
      }
      ```
      Campos dispon√≠veis: `space_ids%5B%5D`, `project_ids%5B%5D`, `list_ids%5B%5D`, `statuses%5B%5D`, `include_closed`, `assignees%5B%5D`, `tags%5B%5D`, `due_date_gt`, `due_date_lt`, `date_created_gt`, `date_created_lt`, `date_updated_gt`, `date_updated_lt`
  </Accordion>

  <Accordion title="CLICKUP_GET_TASK_IN_LIST">
    **Descri√ß√£o:** Obtenha tarefas em uma lista espec√≠fica do ClickUp.

    **Par√¢metros:**

    * `listId` (string, obrigat√≥rio): Lista - Selecione uma Lista da qual obter as tarefas. Use as Configura√ß√µes do Usu√°rio no Portal de Conex√£o para permitir que os usu√°rios selecionem uma Lista ClickUp.
    * `taskFilterFormula` (string, opcional): Busque tarefas que correspondam aos filtros especificados. Por exemplo: name=task1.
  </Accordion>

  <Accordion title="CLICKUP_CREATE_TASK">
    **Descri√ß√£o:** Crie uma tarefa no ClickUp.

    **Par√¢metros:**

    * `listId` (string, obrigat√≥rio): Lista - Selecione uma Lista para criar esta tarefa. Use as Configura√ß√µes do Usu√°rio no Portal de Conex√£o para permitir que os usu√°rios selecionem uma Lista ClickUp.
    * `name` (string, obrigat√≥rio): Nome - O nome da tarefa.
    * `description` (string, opcional): Descri√ß√£o - Descri√ß√£o da tarefa.
    * `status` (string, opcional): Status - Selecione um Status para esta tarefa. Use as Configura√ß√µes do Usu√°rio no Portal de Conex√£o para permitir que os usu√°rios selecionem um Status ClickUp.
    * `assignees` (string, opcional): Respons√°veis - Selecione um Membro (ou um array de IDs de membros) para ser respons√°vel por esta tarefa. Use as Configura√ß√µes do Usu√°rio no Portal de Conex√£o para permitir que os usu√°rios selecionem um Membro ClickUp.
    * `dueDate` (string, opcional): Data de Vencimento - Especifique uma data para a conclus√£o desta tarefa.
    * `additionalFields` (string, opcional): Campos Adicionais - Especifique campos adicionais para incluir nesta tarefa em formato JSON.
  </Accordion>

  <Accordion title="CLICKUP_UPDATE_TASK">
    **Descri√ß√£o:** Atualize uma tarefa no ClickUp.

    **Par√¢metros:**

    * `taskId` (string, obrigat√≥rio): ID da tarefa - O ID da tarefa a ser atualizada.
    * `listId` (string, obrigat√≥rio): Lista - Selecione uma Lista para criar esta tarefa. Use as Configura√ß√µes do Usu√°rio no Portal de Conex√£o para permitir que os usu√°rios selecionem uma Lista ClickUp.
    * `name` (string, opcional): Nome - O nome da tarefa.
    * `description` (string, opcional): Descri√ß√£o - Descri√ß√£o da tarefa.
    * `status` (string, opcional): Status - Selecione um Status para esta tarefa. Use as Configura√ß√µes do Usu√°rio no Portal de Conex√£o para permitir que os usu√°rios selecionem um Status ClickUp.
    * `assignees` (string, opcional): Respons√°veis - Selecione um Membro (ou um array de IDs de membros) para ser respons√°vel por esta tarefa. Use as Configura√ß√µes do Usu√°rio no Portal de Conex√£o para permitir que os usu√°rios selecionem um Membro ClickUp.
    * `dueDate` (string, opcional): Data de Vencimento - Especifique uma data para a conclus√£o desta tarefa.
    * `additionalFields` (string, opcional): Campos Adicionais - Especifique campos adicionais para incluir nesta tarefa em formato JSON.
  </Accordion>

  <Accordion title="CLICKUP_DELETE_TASK">
    **Descri√ß√£o:** Exclua uma tarefa no ClickUp.

    **Par√¢metros:**

    * `taskId` (string, obrigat√≥rio): ID da tarefa - O ID da tarefa a ser exclu√≠da.
  </Accordion>

  <Accordion title="CLICKUP_GET_LIST">
    **Descri√ß√£o:** Obtenha informa√ß√µes da Lista no ClickUp.

    **Par√¢metros:**

    * `spaceId` (string, obrigat√≥rio): ID do Espa√ßo - O ID do espa√ßo que cont√©m as listas.
  </Accordion>

  <Accordion title="CLICKUP_GET_CUSTOM_FIELDS_IN_LIST">
    **Descri√ß√£o:** Obtenha Campos Personalizados em uma Lista no ClickUp.

    **Par√¢metros:**

    * `listId` (string, obrigat√≥rio): ID da Lista - O ID da lista da qual obter os campos personalizados.
  </Accordion>

  <Accordion title="CLICKUP_GET_ALL_FIELDS_IN_LIST">
    **Descri√ß√£o:** Obtenha Todos os Campos em uma Lista no ClickUp.

    **Par√¢metros:**

    * `listId` (string, obrigat√≥rio): ID da Lista - O ID da lista da qual obter todos os campos.
  </Accordion>

  <Accordion title="CLICKUP_GET_SPACE">
    **Descri√ß√£o:** Obtenha informa√ß√µes do Espa√ßo no ClickUp.

    **Par√¢metros:**

    * `spaceId` (string, opcional): ID do Espa√ßo - O ID do espa√ßo a ser recuperado.
  </Accordion>

  <Accordion title="CLICKUP_GET_FOLDERS">
    **Descri√ß√£o:** Obtenha Pastas no ClickUp.

    **Par√¢metros:**

    * `spaceId` (string, obrigat√≥rio): ID do Espa√ßo - O ID do espa√ßo que cont√©m as pastas.
  </Accordion>

  <Accordion title="CLICKUP_GET_MEMBER">
    **Descri√ß√£o:** Obtenha informa√ß√µes de Membro no ClickUp.

    **Par√¢metros:** Nenhum obrigat√≥rio.
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configura√ß√£o B√°sica do Agente ClickUp

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (ClickUp tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with ClickUp capabilities
clickup_agent = Agent(
    role="Task Manager",
    goal="Manage tasks and projects in ClickUp efficiently",
    backstory="An AI assistant specialized in task management and productivity coordination.",
    tools=[enterprise_tools]
)

# Task to create a new task
create_task = Task(
    description="Create a task called 'Review Q1 Reports' in the Marketing list with high priority",
    agent=clickup_agent,
    expected_output="Task created successfully with task ID"
)

# Run the task
crew = Crew(
    agents=[clickup_agent],
    tasks=[create_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Espec√≠ficas do ClickUp

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific ClickUp tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["clickup_create_task", "clickup_update_task", "clickup_search_tasks"]
)

task_coordinator = Agent(
    role="Task Coordinator",
    goal="Create and manage tasks efficiently",
    backstory="An AI assistant that focuses on task creation and status management.",
    tools=enterprise_tools
)

# Task to manage task workflow
task_workflow = Task(
    description="Create a task for project planning and assign it to the development team",
    agent=task_coordinator,
    expected_output="Task created and assigned successfully"
)

crew = Crew(
    agents=[task_coordinator],
    tasks=[task_workflow]
)

crew.kickoff()
```

### Gerenciamento Avan√ßado de Projetos

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

project_manager = Agent(
    role="Project Manager",
    goal="Coordinate project activities and track team productivity",
    backstory="An experienced project manager who ensures projects are delivered on time.",
    tools=[enterprise_tools]
)

# Complex task involving multiple ClickUp operations
project_coordination = Task(
    description="""
    1. Get all open tasks in the current space
    2. Identify overdue tasks and update their status
    3. Create a weekly report task summarizing project progress
    4. Assign the report task to the team lead
    """,
    agent=project_manager,
    expected_output="Project status updated and weekly report task created and assigned"
)

crew = Crew(
    agents=[project_manager],
    tasks=[project_coordination]
)

crew.kickoff()
```

### Busca e Gerenciamento de Tarefas

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

task_analyst = Agent(
    role="Task Analyst",
    goal="Analyze task patterns and optimize team productivity",
    backstory="An AI assistant that analyzes task data to improve team efficiency.",
    tools=[enterprise_tools]
)

# Task to analyze and optimize task distribution
task_analysis = Task(
    description="""
    Search for all tasks assigned to team members in the last 30 days,
    analyze completion patterns, and create optimization recommendations
    """,
    agent=task_analyst,
    expected_output="Task analysis report with optimization recommendations"
)

crew = Crew(
    agents=[task_analyst],
    tasks=[task_analysis]
)

crew.kickoff()
```

### Precisa de Ajuda?

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para aux√≠lio na configura√ß√£o ou solu√ß√£o de problemas da integra√ß√£o com ClickUp.
</Card>


# Integra√ß√£o com GitHub
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/github

Gerenciamento de reposit√≥rios e issues com a integra√ß√£o do GitHub para CrewAI.

## Vis√£o Geral

Permita que seus agentes gerenciem reposit√≥rios, issues e releases atrav√©s do GitHub. Crie e atualize issues, gerencie releases, acompanhe o desenvolvimento do projeto e otimize seu fluxo de trabalho de desenvolvimento de software com automa√ß√£o alimentada por IA.

## Pr√©-requisitos

Antes de usar a integra√ß√£o do GitHub, assegure-se de ter:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Uma conta GitHub com permiss√µes adequadas no reposit√≥rio
* Conta do GitHub conectada atrav√©s da [p√°gina de Integra√ß√µes](https://app.crewai.com/crewai_plus/connectors)

## Configurando a Integra√ß√£o com GitHub

### 1. Conecte sua conta GitHub

1. Acesse [Integra√ß√µes CrewAI Enterprise](https://app.crewai.com/crewai_plus/connectors)
2. Encontre **GitHub** na se√ß√£o de Integra√ß√µes de Autentica√ß√£o
3. Clique em **Conectar** e complete o fluxo OAuth
4. Conceda as permiss√µes necess√°rias para gerenciamento de reposit√≥rio e issues
5. Copie seu Token Enterprise nas [Configura√ß√µes de Conta](https://app.crewai.com/crewai_plus/settings/account)

### 2. Instale o pacote necess√°rio

```bash
uv add crewai-tools
```

## A√ß√µes Dispon√≠veis

<AccordionGroup>
  <Accordion title="GITHUB_CREATE_ISSUE">
    **Descri√ß√£o:** Cria uma issue no GitHub.

    **Par√¢metros:**

    * `owner` (string, obrigat√≥rio): Propriet√°rio - Especifique o nome do propriet√°rio da conta do reposit√≥rio associado a esta Issue. (exemplo: "abc").
    * `repo` (string, obrigat√≥rio): Reposit√≥rio - Especifique o nome do reposit√≥rio associado a esta Issue.
    * `title` (string, obrigat√≥rio): T√≠tulo da Issue - Especifique o t√≠tulo da issue a ser criada.
    * `body` (string, opcional): Corpo da Issue - Especifique o conte√∫do do corpo da issue a ser criada.
    * `assignees` (string, opcional): Respons√°veis - Especifique o login dos respons√°veis no GitHub como um array de strings para esta issue. (exemplo: `["octocat"]`).
  </Accordion>

  <Accordion title="GITHUB_UPDATE_ISSUE">
    **Descri√ß√£o:** Atualiza uma issue no GitHub.

    **Par√¢metros:**

    * `owner` (string, obrigat√≥rio): Propriet√°rio - Especifique o nome do propriet√°rio da conta do reposit√≥rio associado a esta Issue. (exemplo: "abc").
    * `repo` (string, obrigat√≥rio): Reposit√≥rio - Especifique o nome do reposit√≥rio associado a esta Issue.
    * `issue_number` (string, obrigat√≥rio): N√∫mero da Issue - Especifique o n√∫mero da issue a ser atualizada.
    * `title` (string, obrigat√≥rio): T√≠tulo da Issue - Especifique o t√≠tulo da issue a ser atualizada.
    * `body` (string, opcional): Corpo da Issue - Especifique o conte√∫do do corpo da issue a ser atualizada.
    * `assignees` (string, opcional): Respons√°veis - Especifique o login dos respons√°veis no GitHub como um array de strings para esta issue. (exemplo: `["octocat"]`).
    * `state` (string, opcional): Estado - Especifique o estado atualizado da issue.
      * Op√ß√µes: `open`, `closed`
  </Accordion>

  <Accordion title="GITHUB_GET_ISSUE_BY_NUMBER">
    **Descri√ß√£o:** Obt√©m uma issue pelo n√∫mero no GitHub.

    **Par√¢metros:**

    * `owner` (string, obrigat√≥rio): Propriet√°rio - Especifique o nome do propriet√°rio da conta do reposit√≥rio associado a esta Issue. (exemplo: "abc").
    * `repo` (string, obrigat√≥rio): Reposit√≥rio - Especifique o nome do reposit√≥rio associado a esta Issue.
    * `issue_number` (string, obrigat√≥rio): N√∫mero da Issue - Especifique o n√∫mero da issue a ser buscada.
  </Accordion>

  <Accordion title="GITHUB_LOCK_ISSUE">
    **Descri√ß√£o:** Bloqueia uma issue no GitHub.

    **Par√¢metros:**

    * `owner` (string, obrigat√≥rio): Propriet√°rio - Especifique o nome do propriet√°rio da conta do reposit√≥rio associado a esta Issue. (exemplo: "abc").
    * `repo` (string, obrigat√≥rio): Reposit√≥rio - Especifique o nome do reposit√≥rio associado a esta Issue.
    * `issue_number` (string, obrigat√≥rio): N√∫mero da Issue - Especifique o n√∫mero da issue a ser bloqueada.
    * `lock_reason` (string, obrigat√≥rio): Motivo do Bloqueio - Especifique um motivo para bloquear a discuss√£o da issue ou pull request.
      * Op√ß√µes: `off-topic`, `too heated`, `resolved`, `spam`
  </Accordion>

  <Accordion title="GITHUB_SEARCH_ISSUE">
    **Descri√ß√£o:** Busca por issues no GitHub.

    **Par√¢metros:**

    * `owner` (string, obrigat√≥rio): Propriet√°rio - Especifique o nome do propriet√°rio da conta do reposit√≥rio associado a esta Issue. (exemplo: "abc").
    * `repo` (string, obrigat√≥rio): Reposit√≥rio - Especifique o nome do reposit√≥rio associado a esta Issue.
    * `filter` (object, obrigat√≥rio): Um filtro em forma normal disjuntiva - OU de grupos E de condi√ß√µes simples.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "assignee",
                "operator": "$stringExactlyMatches",
                "value": "octocat"
              }
            ]
          }
        ]
      }
      ```
      Campos dispon√≠veis: `assignee`, `creator`, `mentioned`, `labels`
  </Accordion>

  <Accordion title="GITHUB_CREATE_RELEASE">
    **Descri√ß√£o:** Cria um release no GitHub.

    **Par√¢metros:**

    * `owner` (string, obrigat√≥rio): Propriet√°rio - Especifique o nome do propriet√°rio da conta do reposit√≥rio associado a este Release. (exemplo: "abc").
    * `repo` (string, obrigat√≥rio): Reposit√≥rio - Especifique o nome do reposit√≥rio associado a este Release.
    * `tag_name` (string, obrigat√≥rio): Nome - Especifique o nome da tag do release a ser criada. (exemplo: "v1.0.0").
    * `target_commitish` (string, opcional): Destino - Especifique o destino do release. Pode ser o nome de um branch ou o SHA de um commit. Padr√£o √© o branch principal. (exemplo: "master").
    * `body` (string, opcional): Descri√ß√£o - Especifique uma descri√ß√£o para este release.
    * `draft` (string, opcional): Rascunho - Especifique se o release criado deve ser um rascunho (n√£o publicado).
      * Op√ß√µes: `true`, `false`
    * `prerelease` (string, opcional): Pr√©-lan√ßamento - Especifique se o release criado deve ser um pr√©-lan√ßamento.
      * Op√ß√µes: `true`, `false`
    * `discussion_category_name` (string, opcional): Nome da Categoria de Discuss√£o - Se especificado, uma discuss√£o da categoria indicada √© criada e vinculada ao release. O valor deve ser uma categoria j√° existente no reposit√≥rio.
    * `generate_release_notes` (string, opcional): Notas de Release - Especifique se o release criado deve criar automaticamente notas de release usando o nome e a descri√ß√£o fornecidos.
      * Op√ß√µes: `true`, `false`
  </Accordion>

  <Accordion title="GITHUB_UPDATE_RELEASE">
    **Descri√ß√£o:** Atualiza um release no GitHub.

    **Par√¢metros:**

    * `owner` (string, obrigat√≥rio): Propriet√°rio - Especifique o nome do propriet√°rio da conta do reposit√≥rio associado a este Release. (exemplo: "abc").
    * `repo` (string, obrigat√≥rio): Reposit√≥rio - Especifique o nome do reposit√≥rio associado a este Release.
    * `id` (string, obrigat√≥rio): ID do Release - Especifique o ID do release a ser atualizado.
    * `tag_name` (string, opcional): Nome - Especifique o nome da tag do release a ser atualizado. (exemplo: "v1.0.0").
    * `target_commitish` (string, opcional): Destino - Especifique o destino do release. Pode ser o nome de um branch ou o SHA de um commit. Padr√£o √© o branch principal. (exemplo: "master").
    * `body` (string, opcional): Descri√ß√£o - Especifique uma descri√ß√£o para este release.
    * `draft` (string, opcional): Rascunho - Especifique se o release criado deve ser um rascunho (n√£o publicado).
      * Op√ß√µes: `true`, `false`
    * `prerelease` (string, opcional): Pr√©-lan√ßamento - Especifique se o release criado deve ser um pr√©-lan√ßamento.
      * Op√ß√µes: `true`, `false`
    * `discussion_category_name` (string, opcional): Nome da Categoria de Discuss√£o - Se especificado, uma discuss√£o da categoria indicada √© criada e vinculada ao release. O valor deve ser uma categoria j√° existente no reposit√≥rio.
    * `generate_release_notes` (string, opcional): Notas de Release - Especifique se o release criado deve criar automaticamente notas de release usando o nome e a descri√ß√£o fornecidos.
      * Op√ß√µes: `true`, `false`
  </Accordion>

  <Accordion title="GITHUB_GET_RELEASE_BY_ID">
    **Descri√ß√£o:** Obt√©m um release por ID no GitHub.

    **Par√¢metros:**

    * `owner` (string, obrigat√≥rio): Propriet√°rio - Especifique o nome do propriet√°rio da conta do reposit√≥rio associado a este Release. (exemplo: "abc").
    * `repo` (string, obrigat√≥rio): Reposit√≥rio - Especifique o nome do reposit√≥rio associado a este Release.
    * `id` (string, obrigat√≥rio): ID do Release - Especifique o ID do release a ser recuperado.
  </Accordion>

  <Accordion title="GITHUB_GET_RELEASE_BY_TAG_NAME">
    **Descri√ß√£o:** Obt√©m um release pelo nome da tag no GitHub.

    **Par√¢metros:**

    * `owner` (string, obrigat√≥rio): Propriet√°rio - Especifique o nome do propriet√°rio da conta do reposit√≥rio associado a este Release. (exemplo: "abc").
    * `repo` (string, obrigat√≥rio): Reposit√≥rio - Especifique o nome do reposit√≥rio associado a este Release.
    * `tag_name` (string, obrigat√≥rio): Nome - Especifique o nome da tag do release a ser recuperado. (exemplo: "v1.0.0").
  </Accordion>

  <Accordion title="GITHUB_DELETE_RELEASE">
    **Descri√ß√£o:** Exclui um release no GitHub.

    **Par√¢metros:**

    * `owner` (string, obrigat√≥rio): Propriet√°rio - Especifique o nome do propriet√°rio da conta do reposit√≥rio associado a este Release. (exemplo: "abc").
    * `repo` (string, obrigat√≥rio): Reposit√≥rio - Especifique o nome do reposit√≥rio associado a este Release.
    * `id` (string, obrigat√≥rio): ID do Release - Especifique o ID do release a ser exclu√≠do.
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configura√ß√£o B√°sica de Agente GitHub

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (GitHub tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with GitHub capabilities
github_agent = Agent(
    role="Repository Manager",
    goal="Manage GitHub repositories, issues, and releases efficiently",
    backstory="An AI assistant specialized in repository management and issue tracking.",
    tools=[enterprise_tools]
)

# Task to create a new issue
create_issue_task = Task(
    description="Create a bug report issue for the login functionality in the main repository",
    agent=github_agent,
    expected_output="Issue created successfully with issue number"
)

# Run the task
crew = Crew(
    agents=[github_agent],
    tasks=[create_issue_task]
)

crew.kickoff()
```

### Filtrando Ferramentas GitHub Espec√≠ficas

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific GitHub tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["github_create_issue", "github_update_issue", "github_search_issue"]
)

issue_manager = Agent(
    role="Issue Manager",
    goal="Create and manage GitHub issues efficiently",
    backstory="An AI assistant that focuses on issue tracking and management.",
    tools=enterprise_tools
)

# Task to manage issue workflow
issue_workflow = Task(
    description="Create a feature request issue and assign it to the development team",
    agent=issue_manager,
    expected_output="Feature request issue created and assigned successfully"
)

crew = Crew(
    agents=[issue_manager],
    tasks=[issue_workflow]
)

crew.kickoff()
```

### Gerenciamento de Releases

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

release_manager = Agent(
    role="Release Manager",
    goal="Manage software releases and versioning",
    backstory="An experienced release manager who handles version control and release processes.",
    tools=[enterprise_tools]
)

# Task to create a new release
release_task = Task(
    description="""
    Create a new release v2.1.0 for the project with:
    - Auto-generated release notes
    - Target the main branch
    - Include a description of new features and bug fixes
    """,
    agent=release_manager,
    expected_output="Release v2.1.0 created successfully with release notes"
)

crew = Crew(
    agents=[release_manager],
    tasks=[release_task]
)

crew.kickoff()
```

### Acompanhamento e Gerenciamento de Issues

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

project_coordinator = Agent(
    role="Project Coordinator",
    goal="Track and coordinate project issues and development progress",
    backstory="An AI assistant that helps coordinate development work and track project progress.",
    tools=[enterprise_tools]
)

# Complex task involving multiple GitHub operations
coordination_task = Task(
    description="""
    1. Search for all open issues assigned to the current milestone
    2. Identify overdue issues and update their priority labels
    3. Create a weekly progress report issue
    4. Lock resolved issues that have been inactive for 30 days
    """,
    agent=project_coordinator,
    expected_output="Project coordination completed with progress report and issue management"
)

crew = Crew(
    agents=[project_coordinator],
    tasks=[coordination_task]
)

crew.kickoff()
```

### Obtendo Ajuda

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para aux√≠lio na configura√ß√£o ou solu√ß√£o de problemas com a integra√ß√£o do GitHub.
</Card>


# Integra√ß√£o com Gmail
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/gmail

Gerenciamento de e-mails e contatos com a integra√ß√£o do Gmail para o CrewAI.

## Vis√£o Geral

Permita que seus agentes gerenciem e-mails, contatos e rascunhos atrav√©s do Gmail. Envie e-mails, pesquise mensagens, gerencie contatos, crie rascunhos e otimize suas comunica√ß√µes por e-mail com automa√ß√£o impulsionada por IA.

## Pr√©-requisitos

Antes de usar a integra√ß√£o com o Gmail, certifique-se de que voc√™ possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Uma conta do Gmail com as permiss√µes adequadas
* Conectou sua conta do Gmail atrav√©s da [p√°gina de Integra√ß√µes](https://app.crewai.com/crewai_plus/connectors)

## Configurando a Integra√ß√£o com o Gmail

### 1. Conecte sua Conta do Gmail

1. Navegue at√© [Integra√ß√µes CrewAI Enterprise](https://app.crewai.com/crewai_plus/connectors)
2. Encontre **Gmail** na se√ß√£o de Integra√ß√µes de Autentica√ß√£o
3. Clique em **Conectar** e conclua o fluxo OAuth
4. Conceda as permiss√µes necess√°rias para o gerenciamento de e-mail e contato
5. Copie seu Token Empresarial em [Configura√ß√µes de Conta](https://app.crewai.com/crewai_plus/settings/account)

### 2. Instale o Pacote Necess√°rio

```bash
uv add crewai-tools
```

## A√ß√µes Dispon√≠veis

<AccordionGroup>
  <Accordion title="GMAIL_SEND_EMAIL">
    **Descri√ß√£o:** Envia um e-mail pelo Gmail.

    **Par√¢metros:**

    * `toRecipients` (array, obrigat√≥rio): Para - Especifique os destinat√°rios como uma √∫nica string ou um array JSON.
      ```json
      [
        "recipient1@domain.com",
        "recipient2@domain.com"
      ]
      ```
    * `from` (string, obrigat√≥rio): De - Especifique o e-mail do remetente.
    * `subject` (string, obrigat√≥rio): Assunto - Especifique o assunto da mensagem.
    * `messageContent` (string, obrigat√≥rio): Conte√∫do da Mensagem - Especifique o conte√∫do do e-mail em texto simples ou HTML.
    * `attachments` (string, opcional): Anexos - Aceita um √∫nico objeto de arquivo ou um array JSON de objetos de arquivo.
    * `additionalHeaders` (object, opcional): Cabe√ßalhos Adicionais - Especifique quaisquer campos de cabe√ßalho adicionais aqui.
      ```json
      {
        "reply-to": "Nome do Remetente <sender@domain.com>"
      }
      ```
  </Accordion>

  <Accordion title="GMAIL_GET_EMAIL_BY_ID">
    **Descri√ß√£o:** Obt√©m um e-mail pelo ID no Gmail.

    **Par√¢metros:**

    * `userId` (string, obrigat√≥rio): ID do Usu√°rio - Especifique o endere√ßo de e-mail do usu√°rio. (exemplo: "[user@domain.com](mailto:user@domain.com)").
    * `messageId` (string, obrigat√≥rio): ID da Mensagem - Especifique o ID da mensagem a ser recuperada.
  </Accordion>

  <Accordion title="GMAIL_SEARCH_FOR_EMAIL">
    **Descri√ß√£o:** Pesquisa e-mails no Gmail usando filtros avan√ßados.

    **Par√¢metros:**

    * `emailFilterFormula` (object, opcional): Um filtro na forma normal disjuntiva - OU de grupos E de condi√ß√µes √∫nicas.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "from",
                "operator": "$stringContains",
                "value": "example@domain.com"
              }
            ]
          }
        ]
      }
      ```
      Campos dispon√≠veis: `from`, `to`, `date`, `label`, `subject`, `cc`, `bcc`, `category`, `deliveredto:`, `size`, `filename`, `older_than`, `newer_than`, `list`, `is:important`, `is:unread`, `is:snoozed`, `is:starred`, `is:read`, `has:drive`, `has:document`, `has:spreadsheet`, `has:presentation`, `has:attachment`, `has:youtube`, `has:userlabels`
    * `paginationParameters` (object, opcional): Par√¢metros de Pagina√ß√£o.
      ```json
      {
        "pageCursor": "page_cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="GMAIL_DELETE_EMAIL">
    **Descri√ß√£o:** Exclui um e-mail no Gmail.

    **Par√¢metros:**

    * `userId` (string, obrigat√≥rio): ID do Usu√°rio - Especifique o endere√ßo de e-mail do usu√°rio. (exemplo: "[user@domain.com](mailto:user@domain.com)").
    * `messageId` (string, obrigat√≥rio): ID da Mensagem - Especifique o ID da mensagem para enviar para a lixeira.
  </Accordion>

  <Accordion title="GMAIL_CREATE_A_CONTACT">
    **Descri√ß√£o:** Cria um contato no Gmail.

    **Par√¢metros:**

    * `givenName` (string, obrigat√≥rio): Primeiro Nome - Especifique o Primeiro Nome do contato a ser criado. (exemplo: "Jo√£o").
    * `familyName` (string, obrigat√≥rio): Sobrenome - Especifique o Sobrenome do contato a ser criado. (exemplo: "Silva").
    * `email` (string, obrigat√≥rio): E-mail - Especifique o endere√ßo de e-mail do contato a ser criado.
    * `additionalFields` (object, opcional): Campos Adicionais - Informa√ß√µes adicionais de contato.
      ```json
      {
        "addresses": [
          {
            "streetAddress": "1000 North St.",
            "city": "Los Angeles"
          }
        ]
      }
      ```
  </Accordion>

  <Accordion title="GMAIL_GET_CONTACT_BY_RESOURCE_NAME">
    **Descri√ß√£o:** Obt√©m um contato pelo nome do recurso no Gmail.

    **Par√¢metros:**

    * `resourceName` (string, obrigat√≥rio): Nome do Recurso - Especifique o nome do recurso do contato a ser buscado.
  </Accordion>

  <Accordion title="GMAIL_SEARCH_FOR_CONTACT">
    **Descri√ß√£o:** Pesquisa um contato no Gmail.

    **Par√¢metros:**

    * `searchTerm` (string, obrigat√≥rio): Termo - Especifique um termo para buscar correspond√™ncias aproximadas ou exatas nos campos nome, apelido, endere√ßos de e-mail, n√∫meros de telefone ou organiza√ß√µes do contato.
  </Accordion>

  <Accordion title="GMAIL_DELETE_CONTACT">
    **Descri√ß√£o:** Exclui um contato no Gmail.

    **Par√¢metros:**

    * `resourceName` (string, obrigat√≥rio): Nome do Recurso - Especifique o nome do recurso do contato a ser exclu√≠do.
  </Accordion>

  <Accordion title="GMAIL_CREATE_DRAFT">
    **Descri√ß√£o:** Cria um rascunho no Gmail.

    **Par√¢metros:**

    * `toRecipients` (array, opcional): Para - Especifique os destinat√°rios como uma √∫nica string ou um array JSON.
      ```json
      [
        "recipient1@domain.com",
        "recipient2@domain.com"
      ]
      ```
    * `from` (string, opcional): De - Especifique o e-mail do remetente.
    * `subject` (string, opcional): Assunto - Especifique o assunto da mensagem.
    * `messageContent` (string, opcional): Conte√∫do da Mensagem - Especifique o conte√∫do do e-mail em texto simples ou HTML.
    * `attachments` (string, opcional): Anexos - Aceita um √∫nico objeto de arquivo ou um array JSON de objetos de arquivo.
    * `additionalHeaders` (object, opcional): Cabe√ßalhos Adicionais - Especifique quaisquer campos de cabe√ßalho adicionais aqui.
      ```json
      {
        "reply-to": "Nome do Remetente <sender@domain.com>"
      }
      ```
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configura√ß√£o B√°sica de Agente Gmail

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Gmail tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Gmail capabilities
gmail_agent = Agent(
    role="Email Manager",
    goal="Manage email communications and contacts efficiently",
    backstory="An AI assistant specialized in email management and communication.",
    tools=[enterprise_tools]
)

# Task to send a follow-up email
send_email_task = Task(
    description="Send a follow-up email to john@example.com about the project update meeting",
    agent=gmail_agent,
    expected_output="Email sent successfully with confirmation"
)

# Run the task
crew = Crew(
    agents=[gmail_agent],
    tasks=[send_email_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Espec√≠ficas do Gmail

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Gmail tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["gmail_send_email", "gmail_search_for_email", "gmail_create_draft"]
)

email_coordinator = Agent(
    role="Email Coordinator",
    goal="Coordinate email communications and manage drafts",
    backstory="An AI assistant that focuses on email coordination and draft management.",
    tools=enterprise_tools
)

# Task to prepare and send emails
email_coordination = Task(
    description="Search for emails from the marketing team, create a summary draft, and send it to stakeholders",
    agent=email_coordinator,
    expected_output="Summary email sent to stakeholders"
)

crew = Crew(
    agents=[email_coordinator],
    tasks=[email_coordination]
)

crew.kickoff()
```

### Gerenciamento de Contatos

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

contact_manager = Agent(
    role="Contact Manager",
    goal="Manage and organize email contacts efficiently",
    backstory="An experienced contact manager who maintains organized contact databases.",
    tools=[enterprise_tools]
)

# Task to manage contacts
contact_task = Task(
    description="""
    1. Search for contacts from the 'example.com' domain
    2. Create new contacts for recent email senders not in the contact list
    3. Update contact information with recent interaction data
    """,
    agent=contact_manager,
    expected_output="Contact database updated with new contacts and recent interactions"
)

crew = Crew(
    agents=[contact_manager],
    tasks=[contact_task]
)

crew.kickoff()
```

### Pesquisa e An√°lise de E-mails

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

email_analyst = Agent(
    role="Email Analyst",
    goal="Analyze email patterns and provide insights",
    backstory="An AI assistant that analyzes email data to provide actionable insights.",
    tools=[enterprise_tools]
)

# Task to analyze email patterns
analysis_task = Task(
    description="""
    Search for all unread emails from the last 7 days,
    categorize them by sender domain,
    and create a summary report of communication patterns
    """,
    agent=email_analyst,
    expected_output="Email analysis report with communication patterns and recommendations"
)

crew = Crew(
    agents=[email_analyst],
    tasks=[analysis_task]
)

crew.kickoff()
```

### Fluxos de Trabalho Automatizados de E-mail

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

workflow_manager = Agent(
    role="Email Workflow Manager",
    goal="Automate email workflows and responses",
    backstory="An AI assistant that manages automated email workflows and responses.",
    tools=[enterprise_tools]
)

# Complex task involving multiple Gmail operations
workflow_task = Task(
    description="""
    1. Search for emails with 'urgent' in the subject from the last 24 hours
    2. Create draft responses for each urgent email
    3. Send automated acknowledgment emails to senders
    4. Create a summary report of urgent items requiring attention
    """,
    agent=workflow_manager,
    expected_output="Urgent emails processed with automated responses and summary report"
)

crew = Crew(
    agents=[workflow_manager],
    tasks=[workflow_task]
)

crew.kickoff()
```

### Precisa de Ajuda?

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nosso time de suporte para obter assist√™ncia na configura√ß√£o ou solu√ß√£o de problemas da integra√ß√£o Gmail.
</Card>


# Integra√ß√£o com Google Calendar
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/google_calendar

Gerenciamento de eventos e agendas com integra√ß√£o ao Google Calendar para o CrewAI.

## Vis√£o Geral

Permita que seus agentes gerenciem eventos de calend√°rio, agendas e disponibilidade atrav√©s do Google Calendar. Crie e atualize eventos, gerencie participantes, verifique disponibilidade e otimize seu fluxo de agendamento com automa√ß√£o potencializada por IA.

## Pr√©-requisitos

Antes de usar a integra√ß√£o com o Google Calendar, certifique-se de ter:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Uma conta Google com acesso ao Google Calendar
* Sua conta Google conectada pela [p√°gina de Integra√ß√µes](https://app.crewai.com/crewai_plus/connectors)

## Configurando a Integra√ß√£o com Google Calendar

### 1. Conecte sua Conta Google

1. Acesse [Integra√ß√µes do CrewAI Enterprise](https://app.crewai.com/crewai_plus/connectors)
2. Encontre **Google Calendar** na se√ß√£o de Integra√ß√µes de Autentica√ß√£o
3. Clique em **Conectar** e complete o fluxo OAuth
4. Conceda as permiss√µes necess√°rias para acesso ao calend√°rio e contatos
5. Copie seu Token Enterprise nas [Configura√ß√µes da Conta](https://app.crewai.com/crewai_plus/settings/account)

### 2. Instale o Pacote Necess√°rio

```bash
uv add crewai-tools
```

## A√ß√µes Dispon√≠veis

<AccordionGroup>
  <Accordion title="GOOGLE_CALENDAR_CREATE_EVENT">
    **Descri√ß√£o:** Cria um evento no Google Calendar.

    **Par√¢metros:**

    * `eventName` (string, obrigat√≥rio): Nome do evento.
    * `startTime` (string, obrigat√≥rio): Hor√°rio de in√≠cio ‚Äì Aceita timestamp Unix ou formatos de data ISO8601.
    * `endTime` (string, opcional): Hor√°rio de t√©rmino ‚Äì Padr√£o para uma hora ap√≥s o in√≠cio, se deixado em branco.
    * `calendar` (string, opcional): Calend√°rio ‚Äì Use as Configura√ß√µes de Workflow do Connect Portal para permitir que o usu√°rio selecione em qual calend√°rio o evento ser√° adicionado. Padr√£o para o calend√°rio principal do usu√°rio se deixado em branco.
    * `attendees` (string, opcional): Participantes ‚Äì Aceita um array de e-mails ou e-mails separados por v√≠rgula.
    * `eventLocation` (string, opcional): Local do evento.
    * `eventDescription` (string, opcional): Descri√ß√£o do evento.
    * `eventId` (string, opcional): ID do evento ‚Äì Um ID da sua aplica√ß√£o para associar a este evento. Voc√™ pode usar esse ID para sincronizar atualiza√ß√µes posteriores neste evento.
    * `includeMeetLink` (boolean, opcional): Incluir link do Google Meet? ‚Äì Cria automaticamente um link para confer√™ncia Google Meet para este evento.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_UPDATE_EVENT">
    **Descri√ß√£o:** Atualiza um evento existente no Google Calendar.

    **Par√¢metros:**

    * `eventId` (string, obrigat√≥rio): ID do evento ‚Äì O ID do evento a ser atualizado.
    * `eventName` (string, opcional): Nome do evento.
    * `startTime` (string, opcional): Hor√°rio de in√≠cio ‚Äì Aceita timestamp Unix ou formatos de data ISO8601.
    * `endTime` (string, opcional): Hor√°rio de t√©rmino ‚Äì Padr√£o para uma hora ap√≥s o in√≠cio, se deixado em branco.
    * `calendar` (string, opcional): Calend√°rio ‚Äì Use as Configura√ß√µes de Workflow do Connect Portal para permitir que o usu√°rio selecione em qual calend√°rio o evento ser√° adicionado. Padr√£o para o calend√°rio principal do usu√°rio se deixado em branco.
    * `attendees` (string, opcional): Participantes ‚Äì Aceita um array de e-mails ou e-mails separados por v√≠rgula.
    * `eventLocation` (string, opcional): Local do evento.
    * `eventDescription` (string, opcional): Descri√ß√£o do evento.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_LIST_EVENTS">
    **Descri√ß√£o:** Lista eventos do Google Calendar.

    **Par√¢metros:**

    * `calendar` (string, opcional): Calend√°rio ‚Äì Use as Configura√ß√µes de Workflow do Connect Portal para permitir que o usu√°rio selecione em qual calend√°rio o evento ser√° adicionado. Padr√£o para o calend√°rio principal do usu√°rio se deixado em branco.
    * `after` (string, opcional): Ap√≥s ‚Äì Filtra eventos que come√ßam ap√≥s a data fornecida (Unix em milissegundos ou timestamp ISO). (exemplo: "2025-04-12T10:00:00Z ou 1712908800000").
    * `before` (string, opcional): Antes ‚Äì Filtra eventos que terminam antes da data fornecida (Unix em milissegundos ou timestamp ISO). (exemplo: "2025-04-12T10:00:00Z ou 1712908800000").
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_GET_EVENT_BY_ID">
    **Descri√ß√£o:** Obt√©m um evento espec√≠fico pelo ID no Google Calendar.

    **Par√¢metros:**

    * `eventId` (string, obrigat√≥rio): ID do evento.
    * `calendar` (string, opcional): Calend√°rio ‚Äì Use as Configura√ß√µes de Workflow do Connect Portal para permitir que o usu√°rio selecione em qual calend√°rio o evento ser√° adicionado. Padr√£o para o calend√°rio principal do usu√°rio se deixado em branco.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_DELETE_EVENT">
    **Descri√ß√£o:** Exclui um evento do Google Calendar.

    **Par√¢metros:**

    * `eventId` (string, obrigat√≥rio): ID do evento ‚Äì O ID do evento do calend√°rio a ser exclu√≠do.
    * `calendar` (string, opcional): Calend√°rio ‚Äì Use as Configura√ß√µes de Workflow do Connect Portal para permitir que o usu√°rio selecione em qual calend√°rio o evento ser√° adicionado. Padr√£o para o calend√°rio principal do usu√°rio se deixado em branco.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_GET_CONTACTS">
    **Descri√ß√£o:** Obt√©m contatos do Google Calendar.

    **Par√¢metros:**

    * `paginationParameters` (objeto, opcional): Par√¢metros de Pagina√ß√£o.
      ```json
      {
        "pageCursor": "page_cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_SEARCH_CONTACTS">
    **Descri√ß√£o:** Pesquisa contatos no Google Calendar.

    **Par√¢metros:**

    * `query` (string, opcional): Termo de pesquisa para buscar contatos.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_LIST_DIRECTORY_PEOPLE">
    **Descri√ß√£o:** Lista pessoas do diret√≥rio.

    **Par√¢metros:**

    * `paginationParameters` (objeto, opcional): Par√¢metros de Pagina√ß√£o.
      ```json
      {
        "pageCursor": "page_cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_SEARCH_DIRECTORY_PEOPLE">
    **Descri√ß√£o:** Pesquisa pessoas no diret√≥rio.

    **Par√¢metros:**

    * `query` (string, obrigat√≥rio): Termo de pesquisa para buscar contatos.
    * `paginationParameters` (objeto, opcional): Par√¢metros de Pagina√ß√£o.
      ```json
      {
        "pageCursor": "page_cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_LIST_OTHER_CONTACTS">
    **Descri√ß√£o:** Lista outros contatos.

    **Par√¢metros:**

    * `paginationParameters` (objeto, opcional): Par√¢metros de Pagina√ß√£o.
      ```json
      {
        "pageCursor": "page_cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_SEARCH_OTHER_CONTACTS">
    **Descri√ß√£o:** Pesquisa outros contatos.

    **Par√¢metros:**

    * `query` (string, opcional): Termo de pesquisa para buscar contatos.
  </Accordion>

  <Accordion title="GOOGLE_CALENDAR_GET_AVAILABILITY">
    **Descri√ß√£o:** Obt√©m informa√ß√µes de disponibilidade para calend√°rios.

    **Par√¢metros:**

    * `timeMin` (string, obrigat√≥rio): In√≠cio do intervalo. Em formato ISO.
    * `timeMax` (string, obrigat√≥rio): Fim do intervalo. Em formato ISO.
    * `timeZone` (string, opcional): Fuso hor√°rio usado na resposta. Opcional. O padr√£o √© UTC.
    * `items` (array, opcional): Lista de calend√°rios e/ou grupos para consulta. Padr√£o para o calend√°rio padr√£o do usu√°rio.
      ```json
      [
        {
          "id": "calendar_id_1"
        },
        {
          "id": "calendar_id_2"
        }
      ]
      ```
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configura√ß√£o B√°sica de Agente de Calend√°rio

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Obter ferramentas empresariais (as ferramentas do Google Calendar ser√£o inclu√≠das)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Criar um agente com capacidades do Google Calendar
calendar_agent = Agent(
    role="Schedule Manager",
    goal="Gerenciar eventos de calend√°rio e agendamento de maneira eficiente",
    backstory="Um assistente de IA especializado em gerenciamento de agendas e coordena√ß√£o de hor√°rios.",
    tools=[enterprise_tools]
)

# Tarefa de cria√ß√£o de reuni√£o
create_meeting_task = Task(
    description="Crie uma reuni√£o di√°ria de equipe amanh√£ √†s 9h com o time de desenvolvimento",
    agent=calendar_agent,
    expected_output="Reuni√£o criada com sucesso com link do Google Meet"
)

# Executar a tarefa
crew = Crew(
    agents=[calendar_agent],
    tasks=[create_meeting_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Espec√≠ficas do Calend√°rio

```python
from crewai_tools import CrewaiEnterpriseTools

# Obter apenas ferramentas espec√≠ficas do Google Calendar
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["google_calendar_create_event", "google_calendar_list_events", "google_calendar_get_availability"]
)

meeting_coordinator = Agent(
    role="Meeting Coordinator",
    goal="Coordenar reuni√µes e verificar disponibilidade",
    backstory="Um assistente de IA que foca em agendamento de reuni√µes e gerenciamento de disponibilidade.",
    tools=enterprise_tools
)

# Tarefa para agendar reuni√£o com verifica√ß√£o de disponibilidade
schedule_meeting = Task(
    description="Verifique a disponibilidade para a pr√≥xima semana e agende uma reuni√£o de revis√£o do projeto com os stakeholders",
    agent=meeting_coordinator,
    expected_output="Reuni√£o agendada ap√≥s verifica√ß√£o da disponibilidade de todos os participantes"
)

crew = Crew(
    agents=[meeting_coordinator],
    tasks=[schedule_meeting]
)

crew.kickoff()
```

### Gerenciamento e Atualiza√ß√£o de Eventos

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

event_manager = Agent(
    role="Event Manager",
    goal="Gerenciar e atualizar eventos de calend√°rio de forma eficiente",
    backstory="Um experiente gestor de eventos respons√°vel pela log√≠stica e atualiza√ß√µes dos eventos.",
    tools=[enterprise_tools]
)

# Tarefa para gerenciar atualiza√ß√µes de eventos
event_management = Task(
    description="""
    1. Liste todos os eventos desta semana
    2. Atualize os eventos que precisarem de altera√ß√£o de local para incluir links de videoconfer√™ncia
    3. Envie convites de calend√°rio para novos membros do time para reuni√µes recorrentes
    """,
    agent=event_manager,
    expected_output="Eventos semanais atualizados com os locais corretos e novos participantes inclu√≠dos"
)

crew = Crew(
    agents=[event_manager],
    tasks=[event_management]
)

crew.kickoff()
```

### Gerenciamento de Contatos e Disponibilidade

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

availability_coordinator = Agent(
    role="Availability Coordinator",
    goal="Coordenar disponibilidade e gerenciar contatos para agendamento",
    backstory="Um assistente de IA que se especializa em gerenciamento de disponibilidade e coordena√ß√£o de contatos.",
    tools=[enterprise_tools]
)

# Tarefa de coordena√ß√£o de disponibilidade
availability_task = Task(
    description="""
    1. Pesquise contatos no departamento de engenharia
    2. Verifique a disponibilidade de todos os engenheiros para a pr√≥xima sexta-feira √† tarde
    3. Crie uma reuni√£o de equipe no primeiro intervalo de 2 horas dispon√≠vel
    4. Inclua o link do Google Meet e envie convites
    """,
    agent=availability_coordinator,
    expected_output="Reuni√£o agendada com base na disponibilidade com todos os engenheiros convidados"
)

crew = Crew(
    agents=[availability_coordinator],
    tasks=[availability_task]
)

crew.kickoff()
```

### Workflows de Agendamento Automatizado

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

scheduling_automator = Agent(
    role="Scheduling Automator",
    goal="Automatizar workflows de agendamento e gerenciamento de calend√°rios",
    backstory="Um assistente de IA que automatiza cen√°rios complexos de agendamento e workflows de agenda.",
    tools=[enterprise_tools]
)

# Tarefa de automa√ß√£o de agendamento complexo
automation_task = Task(
    description="""
    1. Liste todos os eventos futuros das pr√≥ximas duas semanas
    2. Identifique conflitos de agendamento ou reuni√µes consecutivas
    3. Sugira hor√°rios √≥timos de reuni√£o verificando as disponibilidades
    4. Crie intervalos entre reuni√µes quando necess√°rio
    5. Atualize a descri√ß√£o dos eventos com pautas e links de reuni√£o
    """,
    agent=scheduling_automator,
    expected_output="Calend√°rio otimizado com conflitos resolvidos, intervalos e detalhes das reuni√µes atualizados"
)

crew = Crew(
    agents=[scheduling_automator],
    tasks=[automation_task]
)

crew.kickoff()
```

## Solu√ß√£o de Problemas

### Problemas Comuns

**Erros de Autentica√ß√£o**

* Certifique-se de que sua conta Google possui as permiss√µes necess√°rias para acessar o calend√°rio
* Verifique se a conex√£o OAuth inclui todos os escopos necess√°rios para a API do Google Calendar
* Confirme se as configura√ß√µes de compartilhamento do calend√°rio permitem o n√≠vel de acesso necess√°rio

**Problemas na Cria√ß√£o de Eventos**

* Verifique se os formatos de hor√°rio est√£o corretos (ISO8601 ou timestamps Unix)
* Assegure-se de que os endere√ßos de e-mail dos participantes est√£o corretamente formatados
* Verifique se o calend√°rio de destino existe e est√° acess√≠vel
* Confirme se os fusos hor√°rios est√£o especificados corretamente

**Disponibilidade e Conflitos de Hor√°rio**

* Use formato ISO adequado para os intervalos de hor√°rio ao verificar disponibilidade
* Certifique-se de que os fusos hor√°rios est√£o consistentes em todas as opera√ß√µes
* Verifique se os IDs dos calend√°rios est√£o corretos ao consultar m√∫ltiplos calend√°rios

**Pesquisa de Contatos e Pessoas**

* Assegure-se de que os termos de pesquisa est√£o devidamente formatados
* Verifique se as permiss√µes para acesso ao diret√≥rio foram concedidas
* Certifique-se de que as informa√ß√µes de contato est√£o atualizadas e acess√≠veis

**Atualiza√ß√£o e Exclus√£o de Eventos**

* Verifique se os IDs dos eventos est√£o corretos e se os eventos existem
* Assegure-se de que voc√™ possui permiss√µes de edi√ß√£o para os eventos
* Verifique se a propriedade do calend√°rio permite modifica√ß√µes

### Obtendo Ajuda

<Card title="Precisa de ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nosso time de suporte para assist√™ncia na configura√ß√£o da integra√ß√£o com o Google Calendar ou solu√ß√£o de problemas.
</Card>


# Integra√ß√£o com Google Sheets
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/google_sheets

Sincroniza√ß√£o de dados de planilhas com a integra√ß√£o do Google Sheets para CrewAI.

## Vis√£o Geral

Permita que seus agentes gerenciem dados de planilhas por meio do Google Sheets. Leia linhas, crie novos registros, atualize dados existentes e otimize os fluxos de trabalho de gerenciamento de dados com automa√ß√£o alimentada por IA. Perfeito para acompanhamento de dados, relat√≥rios e gest√£o colaborativa de informa√ß√µes.

## Pr√©-requisitos

Antes de utilizar a integra√ß√£o com o Google Sheets, certifique-se de que voc√™ possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Uma conta Google com acesso ao Google Sheets
* Sua conta Google conectada pela [p√°gina de integra√ß√µes](https://app.crewai.com/crewai_plus/connectors)
* Planilhas com cabe√ßalhos de coluna adequados para opera√ß√µes com dados

## Configurando a Integra√ß√£o com Google Sheets

### 1. Conecte sua Conta Google

1. Acesse [Integra√ß√µes do CrewAI Enterprise](https://app.crewai.com/crewai_plus/connectors)
2. Localize **Google Sheets** na se√ß√£o Integra√ß√µes de Autentica√ß√£o
3. Clique em **Conectar** e conclua o fluxo OAuth
4. Conceda as permiss√µes necess√°rias para acesso √† planilha
5. Copie seu Token Enterprise em [Configura√ß√µes da Conta](https://app.crewai.com/crewai_plus/settings/account)

### 2. Instale o Pacote Necess√°rio

```bash
uv add crewai-tools
```

## A√ß√µes Dispon√≠veis

<AccordionGroup>
  <Accordion title="GOOGLE_SHEETS_GET_ROW">
    **Descri√ß√£o:** Obt√©m linhas de uma planilha Google Sheets.

    **Par√¢metros:**

    * `spreadsheetId` (string, obrigat√≥rio): Planilha - Use as Configura√ß√µes de Workflow do Portal de Conex√£o para permitir ao usu√°rio selecionar uma planilha. Por padr√£o, usa a primeira worksheet da planilha selecionada.
    * `limit` (string, opcional): Limite de linhas - Limita o n√∫mero m√°ximo de linhas retornadas.
  </Accordion>

  <Accordion title="GOOGLE_SHEETS_CREATE_ROW">
    **Descri√ß√£o:** Cria uma nova linha em uma planilha Google Sheets.

    **Par√¢metros:**

    * `spreadsheetId` (string, obrigat√≥rio): Planilha - Use as Configura√ß√µes de Workflow do Portal de Conex√£o para permitir ao usu√°rio selecionar uma planilha. Por padr√£o, usa a primeira worksheet da planilha selecionada.
    * `worksheet` (string, obrigat√≥rio): Worksheet - Sua worksheet deve conter cabe√ßalhos de coluna.
    * `additionalFields` (object, obrigat√≥rio): Campos - Inclua os campos para criar essa linha como um objeto, usando os nomes das colunas como chaves. Use as Configura√ß√µes de Workflow do Portal de Conex√£o para permitir ao usu√°rio selecionar um Mapeamento de Colunas.
      ```json
      {
        "columnName1": "columnValue1",
        "columnName2": "columnValue2",
        "columnName3": "columnValue3",
        "columnName4": "columnValue4"
      }
      ```
  </Accordion>

  <Accordion title="GOOGLE_SHEETS_UPDATE_ROW">
    **Descri√ß√£o:** Atualiza linhas existentes em uma planilha Google Sheets.

    **Par√¢metros:**

    * `spreadsheetId` (string, obrigat√≥rio): Planilha - Use as Configura√ß√µes de Workflow do Portal de Conex√£o para permitir ao usu√°rio selecionar uma planilha. Por padr√£o, usa a primeira worksheet da planilha selecionada.
    * `worksheet` (string, obrigat√≥rio): Worksheet - Sua worksheet deve conter cabe√ßalhos de coluna.
    * `filterFormula` (object, opcional): Filtro em forma normal disjuntiva - OU de grupos E (AND) de condi√ß√µes individuais para identificar quais linhas atualizar.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "status",
                "operator": "$stringExactlyMatches",
                "value": "pending"
              }
            ]
          }
        ]
      }
      ```
      Operadores dispon√≠veis: `$stringContains`, `$stringDoesNotContain`, `$stringExactlyMatches`, `$stringDoesNotExactlyMatch`, `$stringStartsWith`, `$stringDoesNotStartWith`, `$stringEndsWith`, `$stringDoesNotEndWith`, `$numberGreaterThan`, `$numberLessThan`, `$numberEquals`, `$numberDoesNotEqual`, `$dateTimeAfter`, `$dateTimeBefore`, `$dateTimeEquals`, `$booleanTrue`, `$booleanFalse`, `$exists`, `$doesNotExist`
    * `additionalFields` (object, obrigat√≥rio): Campos - Inclua os campos a serem atualizados como objeto, usando os nomes das colunas como chaves. Use as Configura√ß√µes de Workflow do Portal de Conex√£o para permitir ao usu√°rio selecionar um Mapeamento de Colunas.
      ```json
      {
        "columnName1": "newValue1",
        "columnName2": "newValue2",
        "columnName3": "newValue3",
        "columnName4": "newValue4"
      }
      ```
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configura√ß√£o B√°sica de um Agente Google Sheets

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Obtenha as ferramentas enterprise (ferramentas Google Sheets inclu√≠das)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Crie um agente com capacidades para Google Sheets
sheets_agent = Agent(
    role="Data Manager",
    goal="Gerenciar dados de planilha e rastrear informa√ß√µes de maneira eficiente",
    backstory="Um assistente de IA especializado em gest√£o de dados e opera√ß√µes em planilhas.",
    tools=[enterprise_tools]
)

# Tarefa para adicionar novos dados a uma planilha
data_entry_task = Task(
    description="Adicionar novo registro de cliente na planilha de banco de dados de clientes com nome, e-mail e data de cadastro",
    agent=sheets_agent,
    expected_output="Novo registro de cliente adicionado com sucesso √† planilha"
)

# Execute a tarefa
crew = Crew(
    agents=[sheets_agent],
    tasks=[data_entry_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Espec√≠ficas do Google Sheets

```python
from crewai_tools import CrewaiEnterpriseTools

# Obtenha apenas ferramentas espec√≠ficas do Google Sheets
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["google_sheets_get_row", "google_sheets_create_row"]
)

data_collector = Agent(
    role="Data Collector",
    goal="Coletar e organizar dados em planilhas",
    backstory="Um assistente de IA dedicado √† coleta e organiza√ß√£o de dados.",
    tools=enterprise_tools
)

# Tarefa para coletar e organizar dados
data_collection = Task(
    description="Recuperar dados atuais de invent√°rio e adicionar novos produtos √† planilha de invent√°rio",
    agent=data_collector,
    expected_output="Dados de invent√°rio recuperados e novos produtos adicionados com sucesso"
)

crew = Crew(
    agents=[data_collector],
    tasks=[data_collection]
)

crew.kickoff()
```

### An√°lise de Dados e Gera√ß√£o de Relat√≥rios

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

data_analyst = Agent(
    role="Data Analyst",
    goal="Analisar dados de planilhas e gerar insights",
    backstory="Um analista de dados experiente que extrai insights dos dados de planilhas.",
    tools=[enterprise_tools]
)

# Tarefa para analisar dados e criar relat√≥rios
analysis_task = Task(
    description="""
    1. Recuperar todos os dados de vendas da planilha do m√™s atual
    2. Analisar os dados em busca de tend√™ncias e padr√µes
    3. Criar um relat√≥rio resumo em uma nova linha com os principais indicadores
    """,
    agent=data_analyst,
    expected_output="Dados de vendas analisados e relat√≥rio resumo criado com os principais insights"
)

crew = Crew(
    agents=[data_analyst],
    tasks=[analysis_task]
)

crew.kickoff()
```

### Atualiza√ß√µes Automatizadas de Dados

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

data_updater = Agent(
    role="Data Updater",
    goal="Atualizar e manter dados de planilhas automaticamente",
    backstory="Um assistente de IA que mant√©m a precis√£o dos dados e atualiza registros automaticamente.",
    tools=[enterprise_tools]
)

# Tarefa para atualizar dados com base em condi√ß√µes
update_task = Task(
    description="""
    1. Encontrar todos os pedidos pendentes na planilha de pedidos
    2. Atualizar o status para 'processing'
    3. Adicionar um registro de data/hora da atualiza√ß√£o do status
    4. Registrar as altera√ß√µes em uma planilha de acompanhamento separada
    """,
    agent=data_updater,
    expected_output="Todos os pedidos pendentes atualizados para o status processing com registros de data/hora"
)

crew = Crew(
    agents=[data_updater],
    tasks=[update_task]
)

crew.kickoff()
```

### Fluxo de Trabalho Complexo com Dados

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

workflow_manager = Agent(
    role="Data Workflow Manager",
    goal="Gerenciar fluxos de dados complexos entre v√°rias planilhas",
    backstory="Um assistente de IA que orquestra opera√ß√µes complexas de dados entre v√°rias planilhas.",
    tools=[enterprise_tools]
)

# Tarefa de workflow complexa
workflow_task = Task(
    description="""
    1. Obter todos os dados de clientes da planilha principal de clientes
    2. Criar registros de resumo mensal para clientes ativos
    3. Atualizar o status de clientes com base na atividade nos √∫ltimos 30 dias
    4. Gerar um relat√≥rio mensal com m√©tricas dos clientes
    5. Arquivar registros de clientes inativos em uma planilha separada
    """,
    agent=workflow_manager,
    expected_output="Workflow mensal de clientes conclu√≠do com atualiza√ß√µes de status e relat√≥rios gerados"
)

crew = Crew(
    agents=[workflow_manager],
    tasks=[workflow_task]
)

crew.kickoff()
```

## Solu√ß√£o de Problemas

### Problemas Comuns

**Erros de Permiss√£o**

* Certifique-se de que sua conta Google tem acesso de edi√ß√£o √†s planilhas alvo
* Verifique se a conex√£o OAuth inclui os escopos necess√°rios para a API do Google Sheets
* Confira se as planilhas est√£o compartilhadas com a conta autenticada

**Problemas de Estrutura da Planilha**

* Certifique-se de que as worksheets t√™m cabe√ßalhos de coluna antes de criar ou atualizar linhas
* Verifique se os nomes das colunas em `additionalFields` correspondem exatamente aos cabe√ßalhos
* Confirme que a worksheet especificada existe na planilha

**Problemas de Tipo e Formato de Dados**

* Garanta que os valores dos dados estejam no formato esperado para cada coluna
* Utilize formatos de data adequados nas colunas de data (recomenda-se ISO)
* Verifique se valores num√©ricos est√£o devidamente formatados para colunas num√©ricas

**Problemas com F√≥rmulas de Filtro**

* Certifique-se de que as f√≥rmulas de filtro seguem a estrutura JSON correta para forma normal disjuntiva
* Use nomes de campos v√°lidos, correspondendo exatamente aos cabe√ßalhos das colunas
* Teste filtros simples antes de criar consultas com m√∫ltiplas condi√ß√µes
* Verifique se os tipos de operadores correspondem aos tipos de dados das colunas

**Limites de Linhas e Performance**

* Fique atento aos limites de linhas ao usar `GOOGLE_SHEETS_GET_ROW`
* Considere pagina√ß√£o para grandes volumes de dados
* Use filtros espec√≠ficos para reduzir a quantidade de dados processados

**Opera√ß√µes de Atualiza√ß√£o**

* Certifique-se de que as condi√ß√µes de filtro identifiquem corretamente as linhas a serem atualizadas
* Teste condi√ß√µes de filtro com pequenos conjuntos de dados antes de grandes atualiza√ß√µes
* Verifique se todos os campos obrigat√≥rios est√£o inclu√≠dos nas opera√ß√µes de atualiza√ß√£o

### Obtendo Ajuda

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nosso time de suporte para aux√≠lio na configura√ß√£o ou solu√ß√£o de problemas da integra√ß√£o com o Google Sheets.
</Card>


# Integra√ß√£o com HubSpot
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/hubspot

Gerencie empresas e contatos no HubSpot com o CrewAI.

## Vis√£o Geral

Permita que seus agentes gerenciem empresas e contatos dentro do HubSpot. Crie novos registros e otimize seus processos de CRM com automa√ß√£o baseada em IA.

## Pr√©-requisitos

Antes de utilizar a integra√ß√£o com o HubSpot, certifique-se de que voc√™ possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa.
* Uma conta HubSpot com permiss√µes adequadas.
* Sua conta HubSpot conectada pela [p√°gina de Integra√ß√µes](https://app.crewai.com/crewai_plus/connectors).

## Configurando a Integra√ß√£o com o HubSpot

### 1. Conecte Sua Conta HubSpot

1. Navegue at√© [CrewAI Enterprise Integra√ß√µes](https://app.crewai.com/crewai_plus/connectors).
2. Encontre **HubSpot** na se√ß√£o de Integra√ß√µes de Autentica√ß√£o.
3. Clique em **Conectar** e complete o fluxo OAuth.
4. Conceda as permiss√µes necess√°rias para gerenciamento de empresas e contatos.
5. Copie o seu Token Enterprise nas [Configura√ß√µes da Conta](https://app.crewai.com/crewai_plus/settings/account).

### 2. Instale o Pacote Necess√°rio

```bash
uv add crewai-tools
```

## A√ß√µes Dispon√≠veis

<AccordionGroup>
  <Accordion title="HUBSPOT_CREATE_RECORD_COMPANIES">
    **Descri√ß√£o:** Crie um novo registro de empresa no HubSpot.

    **Par√¢metros:**

    * `name` (string, obrigat√≥rio): Nome da empresa.
    * `domain` (string, opcional): Nome do dom√≠nio da empresa.
    * `industry` (string, opcional): Setor. Deve ser um dos valores predefinidos do HubSpot.
    * `phone` (string, opcional): Telefone.
    * `hubspot_owner_id` (string, opcional): ID do respons√°vel pela empresa.
    * `type` (string, opcional): Tipo da empresa. Valores dispon√≠veis: `PROSPECT`, `PARTNER`, `RESELLER`, `VENDOR`, `OTHER`.
    * `city` (string, opcional): Cidade.
    * `state` (string, opcional): Estado/Regi√£o.
    * `zip` (string, opcional): CEP.
    * `numberofemployees` (number, opcional): N√∫mero de funcion√°rios.
    * `annualrevenue` (number, opcional): Receita anual.
    * `timezone` (string, opcional): Fuso hor√°rio.
    * `description` (string, opcional): Descri√ß√£o.
    * `linkedin_company_page` (string, opcional): URL da p√°gina da empresa no LinkedIn.
    * `company_email` (string, opcional): E-mail da empresa.
    * `first_name` (string, opcional): Nome do contato na empresa.
    * `last_name` (string, opcional): Sobrenome do contato na empresa.
    * `about_us` (string, opcional): Sobre n√≥s.
    * `hs_csm_sentiment` (string, opcional): Sentimento CSM. Valores dispon√≠veis: `at_risk`, `neutral`, `healthy`.
    * `closedate` (string, opcional): Data de fechamento.
    * `hs_keywords` (string, opcional): Palavras-chave da empresa. Deve ser um dos valores predefinidos.
    * `country` (string, opcional): Pa√≠s/Regi√£o.
    * `hs_country_code` (string, opcional): C√≥digo do Pa√≠s/Regi√£o.
    * `hs_employee_range` (string, opcional): Faixa de funcion√°rios.
    * `facebook_company_page` (string, opcional): URL da p√°gina da empresa no Facebook.
    * `facebookfans` (number, opcional): N√∫mero de f√£s no Facebook.
    * `hs_gps_coordinates` (string, opcional): Coordenadas GPS.
    * `hs_gps_error` (string, opcional): Erro de GPS.
    * `googleplus_page` (string, opcional): URL da p√°gina do Google Plus.
    * `owneremail` (string, opcional): E-mail do propriet√°rio no HubSpot.
    * `ownername` (string, opcional): Nome do propriet√°rio no HubSpot.
    * `hs_ideal_customer_profile` (string, opcional): Tier de Perfil de Cliente Ideal. Valores dispon√≠veis: `tier_1`, `tier_2`, `tier_3`.
    * `hs_industry_group` (string, opcional): Grupo do setor.
    * `is_public` (boolean, opcional): √â p√∫blico.
    * `hs_last_metered_enrichment_timestamp` (string, opcional): √öltimo registro de enriquecimento medido.
    * `hs_lead_status` (string, opcional): Status do lead. Valores dispon√≠veis: `NEW`, `OPEN`, `IN_PROGRESS`, `OPEN_DEAL`, `UNQUALIFIED`, `ATTEMPTED_TO_CONTACT`, `CONNECTED`, `BAD_TIMING`.
    * `lifecyclestage` (string, opcional): Est√°gio no ciclo de vida. Valores dispon√≠veis: `subscriber`, `lead`, `marketingqualifiedlead`, `salesqualifiedlead`, `opportunity`, `customer`, `evangelist`, `other`.
    * `linkedinbio` (string, opcional): Bio do LinkedIn.
    * `hs_linkedin_handle` (string, opcional): Handle do LinkedIn.
    * `hs_live_enrichment_deadline` (string, opcional): Prazo para enriquecimento ao vivo.
    * `hs_logo_url` (string, opcional): URL do logotipo.
    * `hs_analytics_source` (string, opcional): Fonte original do tr√°fego.
    * `hs_pinned_engagement_id` (number, opcional): ID do engajamento fixado.
    * `hs_quick_context` (string, opcional): Contexto r√°pido.
    * `hs_revenue_range` (string, opcional): Faixa de receita.
    * `hs_state_code` (string, opcional): C√≥digo do Estado/Regi√£o.
    * `address` (string, opcional): Endere√ßo.
    * `address2` (string, opcional): Complemento de endere√ßo.
    * `hs_is_target_account` (boolean, opcional): Conta alvo.
    * `hs_target_account` (string, opcional): Tier da Conta Alvo. Valores dispon√≠veis: `tier_1`, `tier_2`, `tier_3`.
    * `hs_target_account_recommendation_snooze_time` (string, opcional): Tempo para adiar recomenda√ß√£o de conta alvo.
    * `hs_target_account_recommendation_state` (string, opcional): Estado da recomenda√ß√£o da conta alvo. Valores dispon√≠veis: `DISMISSED`, `NONE`, `SNOOZED`.
    * `total_money_raised` (string, opcional): Total arrecadado.
    * `twitterbio` (string, opcional): Bio do Twitter.
    * `twitterfollowers` (number, opcional): Seguidores no Twitter.
    * `twitterhandle` (string, opcional): Usu√°rio do Twitter.
    * `web_technologies` (string, opcional): Tecnologias web utilizadas. Deve ser um dos valores predefinidos.
    * `website` (string, opcional): URL do site.
    * `founded_year` (string, opcional): Ano de funda√ß√£o.
  </Accordion>

  <Accordion title="HUBSPOT_CREATE_RECORD_CONTACTS">
    **Descri√ß√£o:** Crie um novo registro de contato no HubSpot.

    **Par√¢metros:**

    * `email` (string, obrigat√≥rio): E-mail do contato.
    * `firstname` (string, opcional): Nome.
    * `lastname` (string, opcional): Sobrenome.
    * `phone` (string, opcional): Telefone.
    * `hubspot_owner_id` (string, opcional): Respons√°vel pelo contato.
    * `lifecyclestage` (string, opcional): Est√°gio no ciclo de vida. Valores dispon√≠veis: `subscriber`, `lead`, `marketingqualifiedlead`, `salesqualifiedlead`, `opportunity`, `customer`, `evangelist`, `other`.
    * `hs_lead_status` (string, opcional): Status do lead. Valores dispon√≠veis: `NEW`, `OPEN`, `IN_PROGRESS`, `OPEN_DEAL`, `UNQUALIFIED`, `ATTEMPTED_TO_CONTACT`, `CONNECTED`, `BAD_TIMING`.
    * `annualrevenue` (string, opcional): Receita anual.
    * `hs_buying_role` (string, opcional): Papel na compra.
    * `cc_emails` (string, opcional): E-mails em c√≥pia.
    * `ch_customer_id` (string, opcional): ID do cliente no Chargify.
    * `ch_customer_reference` (string, opcional): Refer√™ncia do cliente no Chargify.
    * `chargify_sites` (string, opcional): Sites Chargify.
    * `city` (string, opcional): Cidade.
    * `hs_facebook_ad_clicked` (boolean, opcional): Clicou em an√∫ncio do Facebook.
    * `hs_linkedin_ad_clicked` (string, opcional): Clicou em an√∫ncio do LinkedIn.
    * `hs_clicked_linkedin_ad` (string, opcional): Clicou em an√∫ncio do LinkedIn.
    * `closedate` (string, opcional): Data de fechamento.
    * `company` (string, opcional): Nome da empresa.
    * `company_size` (string, opcional): Tamanho da empresa.
    * `country` (string, opcional): Pa√≠s/Regi√£o.
    * `hs_country_region_code` (string, opcional): C√≥digo do Pa√≠s/Regi√£o.
    * `date_of_birth` (string, opcional): Data de nascimento.
    * `degree` (string, opcional): Grau de instru√ß√£o.
    * `hs_email_customer_quarantined_reason` (string, opcional): Motivo da quarentena de e-mail.
    * `hs_role` (string, opcional): Cargo. Deve ser um dos valores predefinidos.
    * `hs_seniority` (string, opcional): Senioridade. Deve ser um dos valores predefinidos.
    * `hs_sub_role` (string, opcional): Sub papel. Deve ser um dos valores predefinidos.
    * `hs_employment_change_detected_date` (string, opcional): Data da detec√ß√£o de mudan√ßa de emprego.
    * `hs_enriched_email_bounce_detected` (boolean, opcional): Bounce de e-mail enriquecido detectado.
    * `hs_facebookid` (string, opcional): Facebook ID.
    * `hs_facebook_click_id` (string, opcional): ID de clique no Facebook.
    * `fax` (string, opcional): Fax.
    * `field_of_study` (string, opcional): √Årea de estudo.
    * `followercount` (number, opcional): N√∫mero de seguidores.
    * `gender` (string, opcional): G√™nero.
    * `hs_google_click_id` (string, opcional): ID de clique no Google.
    * `graduation_date` (string, opcional): Data de gradua√ß√£o.
    * `owneremail` (string, opcional): E-mail do propriet√°rio no HubSpot (legado).
    * `ownername` (string, opcional): Nome do propriet√°rio no HubSpot (legado).
    * `industry` (string, opcional): Setor.
    * `hs_inferred_language_codes` (string, opcional): C√≥digos de idioma inferido. Deve ser um dos valores predefinidos.
    * `jobtitle` (string, opcional): Cargo.
    * `hs_job_change_detected_date` (string, opcional): Data de detec√ß√£o de mudan√ßa de emprego.
    * `job_function` (string, opcional): Fun√ß√£o.
    * `hs_journey_stage` (string, opcional): Est√°gio da jornada. Deve ser um dos valores predefinidos.
    * `kloutscoregeneral` (number, opcional): Klout Score.
    * `hs_last_metered_enrichment_timestamp` (string, opcional): √öltimo registro de enriquecimento medido.
    * `hs_latest_source` (string, opcional): Fonte de tr√°fego mais recente.
    * `hs_latest_source_timestamp` (string, opcional): Data da fonte mais recente.
    * `hs_legal_basis` (string, opcional): Base legal para o processamento dos dados do contato.
    * `linkedinbio` (string, opcional): Bio do LinkedIn.
    * `linkedinconnections` (number, opcional): Conex√µes no LinkedIn.
    * `hs_linkedin_url` (string, opcional): URL do LinkedIn.
    * `hs_linkedinid` (string, opcional): Linkedin ID.
    * `hs_live_enrichment_deadline` (string, opcional): Prazo para enriquecimento ao vivo.
    * `marital_status` (string, opcional): Estado civil.
    * `hs_content_membership_email` (string, opcional): E-mail de membro.
    * `hs_content_membership_notes` (string, opcional): Notas de associa√ß√£o.
    * `message` (string, opcional): Mensagem.
    * `military_status` (string, opcional): Status militar.
    * `mobilephone` (string, opcional): Celular.
    * `numemployees` (string, opcional): N√∫mero de funcion√°rios.
    * `hs_analytics_source` (string, opcional): Fonte original do tr√°fego.
    * `photo` (string, opcional): Foto.
    * `hs_pinned_engagement_id` (number, opcional): ID de engajamento fixado.
    * `zip` (string, opcional): CEP.
    * `hs_language` (string, opcional): Idioma preferencial. Deve ser um dos valores predefinidos.
    * `associatedcompanyid` (number, opcional): ID da empresa associada prim√°ria.
    * `hs_email_optout_survey_reason` (string, opcional): Motivo da recusa de e-mail.
    * `relationship_status` (string, opcional): Status de relacionamento.
    * `hs_returning_to_office_detected_date` (string, opcional): Data de retorno ao escrit√≥rio detectada.
    * `salutation` (string, opcional): Sauda√ß√£o.
    * `school` (string, opcional): Escola.
    * `seniority` (string, opcional): Senioridade.
    * `hs_feedback_show_nps_web_survey` (boolean, opcional): Mostrar pesquisa NPS na web.
    * `start_date` (string, opcional): Data de in√≠cio.
    * `state` (string, opcional): Estado/Regi√£o.
    * `hs_state_code` (string, opcional): C√≥digo do Estado/Regi√£o.
    * `hs_content_membership_status` (string, opcional): Status.
    * `address` (string, opcional): Endere√ßo.
    * `tax_exempt` (string, opcional): Isento de impostos.
    * `hs_timezone` (string, opcional): Fuso hor√°rio. Deve ser um dos valores predefinidos.
    * `twitterbio` (string, opcional): Bio do Twitter.
    * `hs_twitterid` (string, opcional): Twitter ID.
    * `twitterprofilephoto` (string, opcional): Foto de perfil do Twitter.
    * `twitterhandle` (string, opcional): Usu√°rio do Twitter.
    * `vat_number` (string, opcional): N√∫mero VAT.
    * `ch_verified` (string, opcional): Verificado para pagamentos ACH/eCheck.
    * `website` (string, opcional): URL do site.
    * `hs_whatsapp_phone_number` (string, opcional): N√∫mero do WhatsApp.
    * `work_email` (string, opcional): E-mail corporativo.
    * `hs_googleplusid` (string, opcional): googleplus ID.
  </Accordion>

  <Accordion title="HUBSPOT_CREATE_RECORD_DEALS">
    **Descri√ß√£o:** Crie um novo registro de neg√≥cio (deal) no HubSpot.

    **Par√¢metros:**

    * `dealname` (string, obrigat√≥rio): Nome do neg√≥cio.
    * `amount` (number, opcional): Valor do neg√≥cio.
    * `dealstage` (string, opcional): Est√°gio no pipeline.
    * `pipeline` (string, opcional): Pipeline ao qual o neg√≥cio pertence.
    * `closedate` (string, opcional): Data prevista de fechamento do neg√≥cio.
    * `hubspot_owner_id` (string, opcional): Respons√°vel pelo neg√≥cio.
    * `dealtype` (string, opcional): Tipo do neg√≥cio. Valores dispon√≠veis: `newbusiness`, `existingbusiness`.
    * `description` (string, opcional): Descri√ß√£o do neg√≥cio.
    * `hs_priority` (string, opcional): Prioridade do neg√≥cio. Valores dispon√≠veis: `low`, `medium`, `high`.
  </Accordion>

  <Accordion title="HUBSPOT_CREATE_RECORD_ENGAGEMENTS">
    **Descri√ß√£o:** Crie um novo engajamento (ex: nota, e-mail, liga√ß√£o, reuni√£o, tarefa) no HubSpot.

    **Par√¢metros:**

    * `engagementType` (string, obrigat√≥rio): Tipo de engajamento. Valores dispon√≠veis: `NOTE`, `EMAIL`, `CALL`, `MEETING`, `TASK`.
    * `hubspot_owner_id` (string, opcional): Usu√°rio respons√°vel pela atividade.
    * `hs_timestamp` (string, opcional): Data e hora da atividade.
    * `hs_note_body` (string, opcional): Corpo da nota. (Utilizado para `NOTE`)
    * `hs_task_subject` (string, opcional): T√≠tulo da tarefa. (Utilizado para `TASK`)
    * `hs_task_body` (string, opcional): Notas da tarefa. (Utilizado para `TASK`)
    * `hs_task_status` (string, opcional): Status da tarefa. (Utilizado para `TASK`)
    * `hs_meeting_title` (string, opcional): T√≠tulo da reuni√£o. (Utilizado para `MEETING`)
    * `hs_meeting_body` (string, opcional): Descri√ß√£o da reuni√£o. (Utilizado para `MEETING`)
    * `hs_meeting_start_time` (string, opcional): Hor√°rio de in√≠cio da reuni√£o. (Utilizado para `MEETING`)
    * `hs_meeting_end_time` (string, opcional): Hor√°rio de t√©rmino da reuni√£o. (Utilizado para `MEETING`)
  </Accordion>

  <Accordion title="HUBSPOT_UPDATE_RECORD_COMPANIES">
    **Descri√ß√£o:** Atualize um registro de empresa existente no HubSpot.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID da empresa a ser atualizada.
    * `name` (string, opcional): Nome da empresa.
    * `domain` (string, opcional): Nome do dom√≠nio da empresa.
    * `industry` (string, opcional): Setor.
    * `phone` (string, opcional): Telefone.
    * `city` (string, opcional): Cidade.
    * `state` (string, opcional): Estado/Regi√£o.
    * `zip` (string, opcional): CEP.
    * `numberofemployees` (number, opcional): N√∫mero de funcion√°rios.
    * `annualrevenue` (number, opcional): Receita anual.
    * `description` (string, opcional): Descri√ß√£o.
  </Accordion>

  <Accordion title="HUBSPOT_CREATE_RECORD_ANY">
    **Descri√ß√£o:** Crie um registro para um tipo de objeto especificado no HubSpot.

    **Par√¢metros:**

    * `recordType` (string, obrigat√≥rio): ID do tipo de objeto personalizado.
    * Par√¢metros adicionais dependem do esquema do objeto personalizado.
  </Accordion>

  <Accordion title="HUBSPOT_UPDATE_RECORD_CONTACTS">
    **Descri√ß√£o:** Atualize um registro de contato existente no HubSpot.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID do contato a ser atualizado.
    * `firstname` (string, opcional): Nome.
    * `lastname` (string, opcional): Sobrenome.
    * `email` (string, opcional): E-mail.
    * `phone` (string, opcional): Telefone.
    * `company` (string, opcional): Nome da empresa.
    * `jobtitle` (string, opcional): Cargo.
    * `lifecyclestage` (string, opcional): Est√°gio no ciclo de vida.
  </Accordion>

  <Accordion title="HUBSPOT_UPDATE_RECORD_DEALS">
    **Descri√ß√£o:** Atualize um registro de neg√≥cio existente no HubSpot.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID do neg√≥cio a ser atualizado.
    * `dealname` (string, opcional): Nome do neg√≥cio.
    * `amount` (number, opcional): Valor do neg√≥cio.
    * `dealstage` (string, opcional): Est√°gio do pipeline.
    * `pipeline` (string, opcional): Pipeline ao qual o neg√≥cio pertence.
    * `closedate` (string, opcional): Data prevista de fechamento.
    * `dealtype` (string, opcional): Tipo de neg√≥cio.
  </Accordion>

  <Accordion title="HUBSPOT_UPDATE_RECORD_ENGAGEMENTS">
    **Descri√ß√£o:** Atualize um engajamento existente no HubSpot.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID do engajamento a ser atualizado.
    * `hs_note_body` (string, opcional): Corpo da nota.
    * `hs_task_subject` (string, opcional): T√≠tulo da tarefa.
    * `hs_task_body` (string, opcional): Notas da tarefa.
    * `hs_task_status` (string, opcional): Status da tarefa.
  </Accordion>

  <Accordion title="HUBSPOT_UPDATE_RECORD_ANY">
    **Descri√ß√£o:** Atualize um registro para um tipo de objeto especificado no HubSpot.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID do registro a ser atualizado.
    * `recordType` (string, obrigat√≥rio): ID do tipo de objeto personalizado.
    * Par√¢metros adicionais dependem do esquema do objeto personalizado.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORDS_COMPANIES">
    **Descri√ß√£o:** Obtenha uma lista de registros de empresas do HubSpot.

    **Par√¢metros:**

    * `paginationParameters` (object, opcional): Use `pageCursor` para buscar p√°ginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORDS_CONTACTS">
    **Descri√ß√£o:** Obtenha uma lista de registros de contatos do HubSpot.

    **Par√¢metros:**

    * `paginationParameters` (object, opcional): Use `pageCursor` para buscar p√°ginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORDS_DEALS">
    **Descri√ß√£o:** Obtenha uma lista de registros de neg√≥cios do HubSpot.

    **Par√¢metros:**

    * `paginationParameters` (object, opcional): Use `pageCursor` para buscar p√°ginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORDS_ENGAGEMENTS">
    **Descri√ß√£o:** Obtenha uma lista de registros de engajamentos do HubSpot.

    **Par√¢metros:**

    * `objectName` (string, obrigat√≥rio): O tipo de engajamento a ser buscado (ex.: "notes").
    * `paginationParameters` (object, opcional): Use `pageCursor` para buscar p√°ginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORDS_ANY">
    **Descri√ß√£o:** Obtenha uma lista de registros de qualquer tipo de objeto no HubSpot.

    **Par√¢metros:**

    * `recordType` (string, obrigat√≥rio): O ID do tipo de objeto personalizado.
    * `paginationParameters` (object, opcional): Use `pageCursor` para buscar p√°ginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORD_BY_ID_COMPANIES">
    **Descri√ß√£o:** Obtenha um registro de empresa pelo seu ID.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID da empresa a ser consultada.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORD_BY_ID_CONTACTS">
    **Descri√ß√£o:** Obtenha um registro de contato pelo seu ID.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID do contato a ser consultado.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORD_BY_ID_DEALS">
    **Descri√ß√£o:** Obtenha um registro de neg√≥cio pelo seu ID.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID do neg√≥cio a ser consultado.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORD_BY_ID_ENGAGEMENTS">
    **Descri√ß√£o:** Obtenha um registro de engajamento pelo seu ID.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID do engajamento a ser consultado.
  </Accordion>

  <Accordion title="HUBSPOT_GET_RECORD_BY_ID_ANY">
    **Descri√ß√£o:** Obtenha um registro de qualquer tipo de objeto especificado pelo seu ID.

    **Par√¢metros:**

    * `recordType` (string, obrigat√≥rio): ID do tipo de objeto personalizado.
    * `recordId` (string, obrigat√≥rio): ID do registro a ser consultado.
  </Accordion>

  <Accordion title="HUBSPOT_SEARCH_RECORDS_COMPANIES">
    **Descri√ß√£o:** Pesquise registros de empresas no HubSpot utilizando uma f√≥rmula de filtro.

    **Par√¢metros:**

    * `filterFormula` (object, opcional): Filtro em forma normal disjuntiva (OU de E).
    * `paginationParameters` (object, opcional): Use `pageCursor` para buscar p√°ginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_SEARCH_RECORDS_CONTACTS">
    **Descri√ß√£o:** Pesquise registros de contatos no HubSpot utilizando uma f√≥rmula de filtro.

    **Par√¢metros:**

    * `filterFormula` (object, opcional): Filtro em forma normal disjuntiva (OU de E).
    * `paginationParameters` (object, opcional): Use `pageCursor` para buscar p√°ginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_SEARCH_RECORDS_DEALS">
    **Descri√ß√£o:** Pesquise registros de neg√≥cios no HubSpot utilizando uma f√≥rmula de filtro.

    **Par√¢metros:**

    * `filterFormula` (object, opcional): Filtro em forma normal disjuntiva (OU de E).
    * `paginationParameters` (object, opcional): Use `pageCursor` para buscar p√°ginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_SEARCH_RECORDS_ENGAGEMENTS">
    **Descri√ß√£o:** Pesquise registros de engajamento no HubSpot utilizando uma f√≥rmula de filtro.

    **Par√¢metros:**

    * `engagementFilterFormula` (object, opcional): Filtro para engajamentos.
    * `paginationParameters` (object, opcional): Use `pageCursor` para buscar p√°ginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_SEARCH_RECORDS_ANY">
    **Descri√ß√£o:** Pesquise registros de qualquer tipo de objeto no HubSpot.

    **Par√¢metros:**

    * `recordType` (string, obrigat√≥rio): O ID do tipo de objeto para pesquisa.
    * `filterFormula` (string, opcional): F√≥rmula de filtro a aplicar.
    * `paginationParameters` (object, opcional): Use `pageCursor` para buscar p√°ginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_DELETE_RECORD_COMPANIES">
    **Descri√ß√£o:** Exclua um registro de empresa pelo seu ID.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID da empresa a ser exclu√≠da.
  </Accordion>

  <Accordion title="HUBSPOT_DELETE_RECORD_CONTACTS">
    **Descri√ß√£o:** Exclua um registro de contato pelo seu ID.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID do contato a ser exclu√≠do.
  </Accordion>

  <Accordion title="HUBSPOT_DELETE_RECORD_DEALS">
    **Descri√ß√£o:** Exclua um registro de neg√≥cio pelo seu ID.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID do neg√≥cio a ser exclu√≠do.
  </Accordion>

  <Accordion title="HUBSPOT_DELETE_RECORD_ENGAGEMENTS">
    **Descri√ß√£o:** Exclua um registro de engajamento pelo seu ID.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID do engajamento a ser exclu√≠do.
  </Accordion>

  <Accordion title="HUBSPOT_DELETE_RECORD_ANY">
    **Descri√ß√£o:** Exclua um registro de qualquer tipo de objeto especificado pelo seu ID.

    **Par√¢metros:**

    * `recordType` (string, obrigat√≥rio): ID do tipo de objeto personalizado.
    * `recordId` (string, obrigat√≥rio): ID do registro a ser exclu√≠do.
  </Accordion>

  <Accordion title="HUBSPOT_GET_CONTACTS_BY_LIST_ID">
    **Descri√ß√£o:** Obtenha contatos de uma lista espec√≠fica pelo seu ID.

    **Par√¢metros:**

    * `listId` (string, obrigat√≥rio): ID da lista da qual obter os contatos.
    * `paginationParameters` (object, opcional): Use `pageCursor` para p√°ginas subsequentes.
  </Accordion>

  <Accordion title="HUBSPOT_DESCRIBE_ACTION_SCHEMA">
    **Descri√ß√£o:** Obtenha o esquema esperado para um dado tipo de objeto e opera√ß√£o.

    **Par√¢metros:**

    * `recordType` (string, obrigat√≥rio): ID do tipo de objeto (ex.: 'companies').
    * `operation` (string, obrigat√≥rio): Tipo de opera√ß√£o (ex.: 'CREATE\_RECORD').
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configura√ß√£o B√°sica de Agente HubSpot

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Obtenha as ferramentas enterprise (ferramentas HubSpot inclu√≠das)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Crie um agente com capacidades HubSpot
hubspot_agent = Agent(
    role="CRM Manager",
    goal="Manage company and contact records in HubSpot",
    backstory="An AI assistant specialized in CRM management.",
    tools=[enterprise_tools]
)

# Task para criar nova empresa
create_company_task = Task(
    description="Create a new company in HubSpot with name 'Innovate Corp' and domain 'innovatecorp.com'.",
    agent=hubspot_agent,
    expected_output="Company created successfully with confirmation"
)

# Execute a tarefa
crew = Crew(
    agents=[hubspot_agent],
    tasks=[create_company_task]
)

crew.kickoff()
```

### Filtrando Ferramentas HubSpot Espec√≠ficas

```python
from crewai_tools import CrewaiEnterpriseTools

# Obtenha somente a ferramenta para criar contatos
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["hubspot_create_record_contacts"]
)

contact_creator = Agent(
    role="Contact Creator",
    goal="Create new contacts in HubSpot",
    backstory="An AI assistant that focuses on creating new contact entries in the CRM.",
    tools=[enterprise_tools]
)

# Task para criar contato
create_contact = Task(
    description="Create a new contact for 'John Doe' with email 'john.doe@example.com'.",
    agent=contact_creator,
    expected_output="Contact created successfully in HubSpot."
)

crew = Crew(
    agents=[contact_creator],
    tasks=[create_contact]
)

crew.kickoff()
```

### Gerenciamento de Contatos

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

crm_manager = Agent(
    role="CRM Manager",
    goal="Manage and organize HubSpot contacts efficiently.",
    backstory="An experienced CRM manager who maintains an organized contact database.",
    tools=[enterprise_tools]
)

# Task para gerenciar contatos
contact_task = Task(
    description="Create a new contact for 'Jane Smith' at 'Global Tech Inc.' with email 'jane.smith@globaltech.com'.",
    agent=crm_manager,
    expected_output="Contact database updated with the new contact."
)

crew = Crew(
    agents=[crm_manager],
    tasks=[contact_task]
)

crew.kickoff()
```

### Precisa de Ajuda?

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para assist√™ncia na configura√ß√£o ou solu√ß√£o de problemas com a integra√ß√£o HubSpot.
</Card>


# Integra√ß√£o com Jira
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/jira

Rastreamento de problemas e gest√£o de projetos com a integra√ß√£o Jira para CrewAI.

## Vis√£o Geral

Permita que seus agentes gerenciem problemas, projetos e fluxos de trabalho pelo Jira. Crie e atualize issues, acompanhe o progresso de projetos, gerencie atribui√ß√µes e otimize sua gest√£o de projetos com automa√ß√£o potencializada por IA.

## Pr√©-requisitos

Antes de usar a integra√ß√£o com o Jira, certifique-se de ter:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Uma conta Jira com permiss√µes adequadas para o projeto
* Sua conta Jira conectada pela [P√°gina de Integra√ß√µes](https://app.crewai.com/crewai_plus/connectors)

## Configurando a Integra√ß√£o com o Jira

### 1. Conectar Sua Conta Jira

1. Acesse [Integra√ß√µes CrewAI Enterprise](https://app.crewai.com/crewai_plus/connectors)
2. Encontre **Jira** na se√ß√£o de Integra√ß√µes de Autentica√ß√£o
3. Clique em **Conectar** e complete o fluxo do OAuth
4. Conceda as permiss√µes necess√°rias para gest√£o de issues e projetos
5. Copie seu Token Enterprise em [Configura√ß√µes da Conta](https://app.crewai.com/crewai_plus/settings/account)

### 2. Instalar o Pacote Necess√°rio

```bash
uv add crewai-tools
```

## A√ß√µes Dispon√≠veis

<AccordionGroup>
  <Accordion title="JIRA_CREATE_ISSUE">
    **Descri√ß√£o:** Cria uma issue no Jira.

    **Par√¢metros:**

    * `summary` (string, obrigat√≥rio): Resumo - Um breve resumo da issue. (exemplo: "A impressora parou de funcionar").
    * `project` (string, opcional): Projeto - Projeto ao qual a issue pertence. Padr√£o para o primeiro projeto do usu√°rio se n√£o informado. Use as Configura√ß√µes de Workflow do Portal de Conex√£o para permitir a sele√ß√£o de Projeto.
    * `issueType` (string, opcional): Tipo de issue - Padr√£o para Task se n√£o informado.
    * `jiraIssueStatus` (string, opcional): Status - Padr√£o para o primeiro status do projeto se n√£o informado.
    * `assignee` (string, opcional): Respons√°vel - Padr√£o para o usu√°rio autenticado se n√£o informado.
    * `descriptionType` (string, opcional): Tipo de Descri√ß√£o - Selecione o Tipo de Descri√ß√£o.
      * Op√ß√µes: `description`, `descriptionJSON`
    * `description` (string, opcional): Descri√ß√£o - Uma descri√ß√£o detalhada da issue. Este campo aparece apenas se 'descriptionType' = 'description'.
    * `additionalFields` (string, opcional): Campos Adicionais - Especifique outros campos em formato JSON. Use as Configura√ß√µes de Workflow do Portal de Conex√£o para permitir ao usu√°rio selecionar quais campos atualizar.
      ```json
      {
        "customfield_10001": "value"
      }
      ```
  </Accordion>

  <Accordion title="JIRA_UPDATE_ISSUE">
    **Descri√ß√£o:** Atualiza uma issue no Jira.

    **Par√¢metros:**

    * `issueKey` (string, obrigat√≥rio): Chave da Issue (exemplo: "TEST-1234").
    * `summary` (string, opcional): Resumo - Breve resumo da issue. (exemplo: "A impressora parou de funcionar").
    * `issueType` (string, opcional): Tipo de issue - Use as Configura√ß√µes de Workflow do Portal de Conex√£o para permitir a sele√ß√£o.
    * `jiraIssueStatus` (string, opcional): Status - Use as Configura√ß√µes de Workflow do Portal de Conex√£o para permitir a sele√ß√£o.
    * `assignee` (string, opcional): Respons√°vel - Use as Configura√ß√µes de Workflow do Portal de Conex√£o para permitir a sele√ß√£o.
    * `descriptionType` (string, opcional): Tipo de Descri√ß√£o - Selecione o Tipo de Descri√ß√£o.
      * Op√ß√µes: `description`, `descriptionJSON`
    * `description` (string, opcional): Descri√ß√£o - Descri√ß√£o detalhada da issue. Este campo aparece apenas se 'descriptionType' = 'description'.
    * `additionalFields` (string, opcional): Campos Adicionais - Especifique outros campos em formato JSON.
  </Accordion>

  <Accordion title="JIRA_GET_ISSUE_BY_KEY">
    **Descri√ß√£o:** Obt√©m uma issue pelo identificador no Jira.

    **Par√¢metros:**

    * `issueKey` (string, obrigat√≥rio): Chave da Issue (exemplo: "TEST-1234").
  </Accordion>

  <Accordion title="JIRA_FILTER_ISSUES">
    **Descri√ß√£o:** Busca issues no Jira usando filtros.

    **Par√¢metros:**

    * `jqlQuery` (object, opcional): Filtro em forma normal disjuntiva - OU de grupos E de condi√ß√µes simples.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "status",
                "operator": "$stringExactlyMatches",
                "value": "Open"
              }
            ]
          }
        ]
      }
      ```
      Operadores dispon√≠veis: `$stringExactlyMatches`, `$stringDoesNotExactlyMatch`, `$stringIsIn`, `$stringIsNotIn`, `$stringContains`, `$stringDoesNotContain`, `$stringGreaterThan`, `$stringLessThan`
    * `limit` (string, opcional): Limitar resultados - Limite m√°ximo de issues retornados. Padr√£o para 10 se estiver em branco.
  </Accordion>

  <Accordion title="JIRA_SEARCH_BY_JQL">
    **Descri√ß√£o:** Busca issues no Jira utilizando JQL.

    **Par√¢metros:**

    * `jqlQuery` (string, obrigat√≥rio): Query JQL (exemplo: "project = PROJECT").
    * `paginationParameters` (object, opcional): Par√¢metros de pagina√ß√£o para resultados paginados.
      ```json
      {
        "pageCursor": "cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="JIRA_UPDATE_ISSUE_ANY">
    **Descri√ß√£o:** Atualiza qualquer issue no Jira. Use DESCRIBE\_ACTION\_SCHEMA para obter o schema de propriedades dessa fun√ß√£o.

    **Par√¢metros:** Nenhum par√¢metro espec√≠fico - use JIRA\_DESCRIBE\_ACTION\_SCHEMA primeiro para obter o schema esperado.
  </Accordion>

  <Accordion title="JIRA_DESCRIBE_ACTION_SCHEMA">
    **Descri√ß√£o:** Obt√©m o schema esperado para um tipo de issue. Use esta fun√ß√£o caso nenhuma outra fun√ß√£o atenda ao tipo de issue que deseja operar.

    **Par√¢metros:**

    * `issueTypeId` (string, obrigat√≥rio): ID do Tipo de Issue.
    * `projectKey` (string, obrigat√≥rio): Chave do projeto.
    * `operation` (string, obrigat√≥rio): Tipo de Opera√ß√£o, por exemplo CREATE\_ISSUE ou UPDATE\_ISSUE.
  </Accordion>

  <Accordion title="JIRA_GET_PROJECTS">
    **Descri√ß√£o:** Obt√©m os projetos no Jira.

    **Par√¢metros:**

    * `paginationParameters` (object, opcional): Par√¢metros de Pagina√ß√£o.
      ```json
      {
        "pageCursor": "cursor_string"
      }
      ```
  </Accordion>

  <Accordion title="JIRA_GET_ISSUE_TYPES_BY_PROJECT">
    **Descri√ß√£o:** Obt√©m os tipos de issues por projeto no Jira.

    **Par√¢metros:**

    * `project` (string, obrigat√≥rio): Chave do projeto.
  </Accordion>

  <Accordion title="JIRA_GET_ISSUE_TYPES">
    **Descri√ß√£o:** Obt√©m todos os tipos de issues no Jira.

    **Par√¢metros:** Nenhum obrigat√≥rio.
  </Accordion>

  <Accordion title="JIRA_GET_ISSUE_STATUS_BY_PROJECT">
    **Descri√ß√£o:** Obt√©m os status das issues de um projeto espec√≠fico.

    **Par√¢metros:**

    * `project` (string, obrigat√≥rio): Chave do projeto.
  </Accordion>

  <Accordion title="JIRA_GET_ALL_ASSIGNEES_BY_PROJECT">
    **Descri√ß√£o:** Obt√©m os respons√°veis por um projeto espec√≠fico.

    **Par√¢metros:**

    * `project` (string, obrigat√≥rio): Chave do projeto.
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configura√ß√£o B√°sica de um Agente Jira

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Obtenha as ferramentas enterprise (incluir√° ferramentas do Jira)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Cria√ß√£o de um agente com capacidades Jira
jira_agent = Agent(
    role="Issue Manager",
    goal="Gerenciar issues do Jira e acompanhar o progresso do projeto de forma eficiente",
    backstory="Um assistente de IA especializado em rastreamento de issues e gest√£o de projetos.",
    tools=[enterprise_tools]
)

# Tarefa para criar um relat√≥rio de bug
create_bug_task = Task(
    description="Criar um relat√≥rio de bug para a funcionalidade de login com alta prioridade e designar para o time de desenvolvimento",
    agent=jira_agent,
    expected_output="Bug report creado com sucesso e chave da issue"
)

# Executar a tarefa
crew = Crew(
    agents=[jira_agent],
    tasks=[create_bug_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Jira Espec√≠ficas

```python
from crewai_tools import CrewaiEnterpriseTools

# Obtenha apenas ferramentas Jira espec√≠ficas
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["jira_create_issue", "jira_update_issue", "jira_search_by_jql"]
)

issue_coordinator = Agent(
    role="Issue Coordinator",
    goal="Criar e gerenciar issues Jira de forma eficiente",
    backstory="Um assistente de IA focado na cria√ß√£o e gest√£o de issues.",
    tools=enterprise_tools
)

# Tarefa para gerenciar workflow de issues
issue_workflow = Task(
    description="Criar uma issue de solicita√ß√£o de feature e atualizar o status de issues relacionadas",
    agent=issue_coordinator,
    expected_output="Feature request criada e issues relacionadas atualizadas"
)

crew = Crew(
    agents=[issue_coordinator],
    tasks=[issue_workflow]
)

crew.kickoff()
```

### An√°lise e Relat√≥rios de Projeto

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

project_analyst = Agent(
    role="Project Analyst",
    goal="Analisar dados de projetos e gerar insights a partir do Jira",
    backstory="Um analista de projetos experiente que extrai insights de dados de gest√£o de projetos.",
    tools=[enterprise_tools]
)

# Tarefa para analisar status do projeto
analysis_task = Task(
    description="""
    1. Obtenha todos os projetos e seus tipos de issues
    2. Busque todas as issues abertas entre projetos
    3. Analise distribui√ß√£o de issues por status e respons√°vel
    4. Crie uma issue de relat√≥rio de resumo com os achados
    """,
    agent=project_analyst,
    expected_output="An√°lise do projeto completa com relat√≥rio de resumo criado"
)

crew = Crew(
    agents=[project_analyst],
    tasks=[analysis_task]
)

crew.kickoff()
```

### Gest√£o Automatizada de Issues

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

automation_manager = Agent(
    role="Automation Manager",
    goal="Automatizar gest√£o de issues e processos de workflow",
    backstory="Um assistente de IA que automatiza tarefas repetitivas de gest√£o de issues.",
    tools=[enterprise_tools]
)

# Tarefa para automatizar gest√£o de issues
automation_task = Task(
    description="""
    1. Buscar todas as issues n√£o atribu√≠das usando JQL
    2. Obter respons√°veis dispon√≠veis de cada projeto
    3. Atribuir issues automaticamente com base na carga de trabalho e especialidade
    4. Atualizar prioridades das issues baseando-se na idade e tipo
    5. Criar issues semanais de planejamento de sprint
    """,
    agent=automation_manager,
    expected_output="Issues atribu√≠das automaticamente e issues de planejamento de sprint criadas"
)

crew = Crew(
    agents=[automation_manager],
    tasks=[automation_task]
)

crew.kickoff()
```

### Opera√ß√µes Avan√ßadas Baseadas em Schema

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

schema_specialist = Agent(
    role="Schema Specialist",
    goal="Executar opera√ß√µes complexas no Jira usando schemas din√¢micos",
    backstory="Um assistente de IA que manipula schemas din√¢micos e tipos de issues customizadas do Jira.",
    tools=[enterprise_tools]
)

# Tarefa usando opera√ß√µes baseadas em schema
schema_task = Task(
    description="""
    1. Obtenha todos os projetos e seus tipos personalizados de issues
    2. Para cada tipo personalizado, descreva o schema de a√ß√£o
    3. Crie issues usando schema din√¢mico para campos complexos customizados
    4. Atualize issues com valores de campos personalizados a partir de regras de neg√≥cio
    """,
    agent=schema_specialist,
    expected_output="Issues customizadas criadas e atualizadas utilizando schemas din√¢micos"
)

crew = Crew(
    agents=[schema_specialist],
    tasks=[schema_task]
)

crew.kickoff()
```

## Solu√ß√£o de Problemas

### Problemas Comuns

**Erros de Permiss√£o**

* Certifique-se de que sua conta Jira tem as permiss√µes necess√°rias nos projetos alvo
* Verifique se a conex√£o OAuth inclui os escopos necess√°rios da API Jira
* Confira se voc√™ possui permiss√µes de criar/editar issues nos projetos especificados

**Chaves de Projeto ou Issue Inv√°lidas**

* Confira o formato das chaves dos projetos e issues (ex: "PROJ-123")
* Verifique se os projetos existem e s√£o acess√≠veis pela sua conta
* Certifique-se de que chaves de issues referenciam issues existentes

**Problemas de Tipo ou Status de Issue**

* Use JIRA\_GET\_ISSUE\_TYPES\_BY\_PROJECT para obter tipos v√°lidos de issue para um projeto
* Use JIRA\_GET\_ISSUE\_STATUS\_BY\_PROJECT para obter status v√°lidos
* Certifique-se de que tipos e status de issue est√£o dispon√≠veis no projeto alvo

**Problemas com Queries JQL**

* Teste as queries JQL na busca de issues do Jira antes de utilizar em chamadas de API
* Certifique-se de que os nomes dos campos em JQL estejam corretos e existam em sua inst√¢ncia do Jira
* Use a sintaxe correta de JQL para queries complexas

**Problemas com Campos Customizados e Schemas**

* Use JIRA\_DESCRIBE\_ACTION\_SCHEMA para obter o schema correto para tipos de issues complexas
* Certifique-se de que os IDs dos campos customizados est√£o corretos (ex: "customfield\_10001")
* Verifique se esses campos est√£o dispon√≠veis no projeto e tipo de issue alvo

**Problemas de F√≥rmulas de Filtro**

* Garanta que as f√≥rmulas de filtro sigam a estrutura JSON correta para forma normal disjuntiva
* Use apenas campos v√°lidos conforme configura√ß√£o do seu Jira
* Teste filtros simples antes de construir queries complexas com m√∫ltiplas condi√ß√µes

### Obtenha Ajuda

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nosso time de suporte para obter assist√™ncia na configura√ß√£o ou solu√ß√£o de problemas da integra√ß√£o Jira.
</Card>


# Integra√ß√£o com o Linear
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/linear

Acompanhamento de projetos de software e rastreamento de bugs com a integra√ß√£o Linear para CrewAI.

## Vis√£o Geral

Permita que seus agentes gerenciem issues, projetos e fluxos de trabalho de desenvolvimento atrav√©s do Linear. Crie e atualize issues, gerencie cronogramas de projetos, organize equipes e otimize seu processo de desenvolvimento de software com automa√ß√£o impulsionada por IA.

## Pr√©-requisitos

Antes de utilizar a integra√ß√£o com o Linear, certifique-se de que voc√™ possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com uma assinatura ativa
* Uma conta Linear com permiss√µes apropriadas no workspace
* Conectou sua conta Linear atrav√©s da [p√°gina de Integra√ß√µes](https://app.crewai.com/crewai_plus/connectors)

## Configurando a Integra√ß√£o com o Linear

### 1. Conecte sua Conta Linear

1. Navegue at√© [Integra√ß√µes CrewAI Enterprise](https://app.crewai.com/crewai_plus/connectors)
2. Encontre **Linear** na se√ß√£o Integra√ß√µes de Autentica√ß√£o
3. Clique em **Conectar** e complete o fluxo OAuth
4. Conceda as permiss√µes necess√°rias para gerenciamento de issues e projetos
5. Copie seu Token Empresarial em [Configura√ß√µes da Conta](https://app.crewai.com/crewai_plus/settings/account)

### 2. Instale o Pacote Necess√°rio

```bash
uv add crewai-tools
```

## A√ß√µes Dispon√≠veis

<AccordionGroup>
  <Accordion title="LINEAR_CREATE_ISSUE">
    **Descri√ß√£o:** Crie uma nova issue no Linear.

    **Par√¢metros:**

    * `teamId` (string, obrigat√≥rio): ID da Equipe - Especifique o ID da equipe respons√°vel para esta nova issue. Use as Configura√ß√µes de Fluxo do Connect Portal para permitir que usu√°rios escolham um ID de Equipe. (exemplo: "a70bdf0f-530a-4887-857d-46151b52b47c").
    * `title` (string, obrigat√≥rio): T√≠tulo - Especifique um t√≠tulo para esta issue.
    * `description` (string, opcional): Descri√ß√£o - Especifique uma descri√ß√£o para esta issue.
    * `statusId` (string, opcional): Status - Especifique o status desta issue.
    * `priority` (string, opcional): Prioridade - Especifique a prioridade desta issue como um inteiro.
    * `dueDate` (string, opcional): Data de Vencimento - Especifique a data de vencimento desta issue no formato ISO 8601.
    * `cycleId` (string, opcional): ID do Ciclo - Especifique o ciclo associado a esta issue.
    * `additionalFields` (object, opcional): Campos Adicionais.
      ```json
      {
        "assigneeId": "a70bdf0f-530a-4887-857d-46151b52b47c",
        "labelIds": ["a70bdf0f-530a-4887-857d-46151b52b47c"]
      }
      ```
  </Accordion>

  <Accordion title="LINEAR_UPDATE_ISSUE">
    **Descri√ß√£o:** Atualize uma issue no Linear.

    **Par√¢metros:**

    * `issueId` (string, obrigat√≥rio): ID da Issue - Especifique o ID da issue a ser atualizada. (exemplo: "90fbc706-18cd-42c9-ae66-6bd344cc8977").
    * `title` (string, opcional): T√≠tulo - Especifique um t√≠tulo para esta issue.
    * `description` (string, opcional): Descri√ß√£o - Especifique uma descri√ß√£o para esta issue.
    * `statusId` (string, opcional): Status - Especifique o status desta issue.
    * `priority` (string, opcional): Prioridade - Especifique a prioridade desta issue como um inteiro.
    * `dueDate` (string, opcional): Data de Vencimento - Especifique a data de vencimento desta issue no formato ISO 8601.
    * `cycleId` (string, opcional): ID do Ciclo - Especifique o ciclo associado a esta issue.
    * `additionalFields` (object, opcional): Campos Adicionais.
      ```json
      {
        "assigneeId": "a70bdf0f-530a-4887-857d-46151b52b47c",
        "labelIds": ["a70bdf0f-530a-4887-857d-46151b52b47c"]
      }
      ```
  </Accordion>

  <Accordion title="LINEAR_GET_ISSUE_BY_ID">
    **Descri√ß√£o:** Obtenha uma issue pelo ID no Linear.

    **Par√¢metros:**

    * `issueId` (string, obrigat√≥rio): ID da Issue - Especifique o ID do registro da issue a ser buscada. (exemplo: "90fbc706-18cd-42c9-ae66-6bd344cc8977").
  </Accordion>

  <Accordion title="LINEAR_GET_ISSUE_BY_ISSUE_IDENTIFIER">
    **Descri√ß√£o:** Obtenha uma issue atrav√©s do identificador da issue no Linear.

    **Par√¢metros:**

    * `externalId` (string, obrigat√≥rio): ID Externo - Especifique o identificador leg√≠vel da issue a ser buscada. (exemplo: "ABC-1").
  </Accordion>

  <Accordion title="LINEAR_SEARCH_ISSUE">
    **Descri√ß√£o:** Pesquise issues no Linear.

    **Par√¢metros:**

    * `queryTerm` (string, obrigat√≥rio): Termo de Pesquisa - O termo a ser localizado na busca.
    * `issueFilterFormula` (object, opcional): Um filtro na forma normal disjuntiva ‚Äì OU de grupos E de condi√ß√µes √∫nicas.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "title",
                "operator": "$stringContains",
                "value": "bug"
              }
            ]
          }
        ]
      }
      ```
      Campos dispon√≠veis: `title`, `number`, `project`, `createdAt`
      Operadores dispon√≠veis: `$stringExactlyMatches`, `$stringDoesNotExactlyMatch`, `$stringIsIn`, `$stringIsNotIn`, `$stringStartsWith`, `$stringDoesNotStartWith`, `$stringEndsWith`, `$stringDoesNotEndWith`, `$stringContains`, `$stringDoesNotContain`, `$stringGreaterThan`, `$stringLessThan`, `$numberGreaterThanOrEqualTo`, `$numberLessThanOrEqualTo`, `$numberGreaterThan`, `$numberLessThan`, `$dateTimeAfter`, `$dateTimeBefore`
  </Accordion>

  <Accordion title="LINEAR_DELETE_ISSUE">
    **Descri√ß√£o:** Exclua uma issue no Linear.

    **Par√¢metros:**

    * `issueId` (string, obrigat√≥rio): ID da Issue - Especifique o ID do registro da issue a ser exclu√≠da. (exemplo: "90fbc706-18cd-42c9-ae66-6bd344cc8977").
  </Accordion>

  <Accordion title="LINEAR_ARCHIVE_ISSUE">
    **Descri√ß√£o:** Arquive uma issue no Linear.

    **Par√¢metros:**

    * `issueId` (string, obrigat√≥rio): ID da Issue - Especifique o ID do registro da issue a ser arquivada. (exemplo: "90fbc706-18cd-42c9-ae66-6bd344cc8977").
  </Accordion>

  <Accordion title="LINEAR_CREATE_SUB_ISSUE">
    **Descri√ß√£o:** Crie uma sub-issue no Linear.

    **Par√¢metros:**

    * `parentId` (string, obrigat√≥rio): ID do Pai - Especifique o ID da issue pai desta nova issue.
    * `teamId` (string, obrigat√≥rio): ID da Equipe - Especifique o ID da equipe respons√°vel pela nova sub-issue. Use as Configura√ß√µes de Fluxo do Connect Portal para permitir que usu√°rios escolham um ID de Equipe. (exemplo: "a70bdf0f-530a-4887-857d-46151b52b47c").
    * `title` (string, obrigat√≥rio): T√≠tulo - Especifique um t√≠tulo para esta issue.
    * `description` (string, opcional): Descri√ß√£o - Especifique uma descri√ß√£o para esta issue.
    * `additionalFields` (object, opcional): Campos Adicionais.
      ```json
      {
        "lead": "linear_user_id"
      }
      ```
  </Accordion>

  <Accordion title="LINEAR_CREATE_PROJECT">
    **Descri√ß√£o:** Crie um novo projeto no Linear.

    **Par√¢metros:**

    * `teamIds` (object, obrigat√≥rio): ID da Equipe - Especifique o(s) ID(s) da equipe associada a este projeto como string ou array JSON. Use as Configura√ß√µes de Usu√°rio do Connect Portal para que seu usu√°rio selecione um ID de Equipe.
      ```json
      [
        "a70bdf0f-530a-4887-857d-46151b52b47c",
        "4ac7..."
      ]
      ```
    * `projectName` (string, obrigat√≥rio): Nome do Projeto - Especifique o nome do projeto. (exemplo: "Meu Projeto Linear").
    * `description` (string, opcional): Descri√ß√£o do Projeto - Especifique uma descri√ß√£o para este projeto.
    * `additionalFields` (object, opcional): Campos Adicionais.
      ```json
      {
        "state": "planned",
        "description": ""
      }
      ```
  </Accordion>

  <Accordion title="LINEAR_UPDATE_PROJECT">
    **Descri√ß√£o:** Atualize um projeto no Linear.

    **Par√¢metros:**

    * `projectId` (string, obrigat√≥rio): ID do Projeto - Especifique o ID do projeto a ser atualizado. (exemplo: "a6634484-6061-4ac7-9739-7dc5e52c796b").
    * `projectName` (string, opcional): Nome do Projeto - Especifique o nome do projeto a ser atualizado. (exemplo: "Meu Projeto Linear").
    * `description` (string, opcional): Descri√ß√£o do Projeto - Especifique uma descri√ß√£o para este projeto.
    * `additionalFields` (object, opcional): Campos Adicionais.
      ```json
      {
        "state": "planned",
        "description": ""
      }
      ```
  </Accordion>

  <Accordion title="LINEAR_GET_PROJECT_BY_ID">
    **Descri√ß√£o:** Obtenha um projeto pelo ID no Linear.

    **Par√¢metros:**

    * `projectId` (string, obrigat√≥rio): ID do Projeto - Especifique o ID do projeto a ser buscado. (exemplo: "a6634484-6061-4ac7-9739-7dc5e52c796b").
  </Accordion>

  <Accordion title="LINEAR_DELETE_PROJECT">
    **Descri√ß√£o:** Exclua um projeto no Linear.

    **Par√¢metros:**

    * `projectId` (string, obrigat√≥rio): ID do Projeto - Especifique o ID do projeto a ser exclu√≠do. (exemplo: "a6634484-6061-4ac7-9739-7dc5e52c796b").
  </Accordion>

  <Accordion title="LINEAR_SEARCH_TEAMS">
    **Descri√ß√£o:** Pesquise equipes no Linear.

    **Par√¢metros:**

    * `teamFilterFormula` (object, opcional): Um filtro na forma normal disjuntiva ‚Äì OU de grupos E de condi√ß√µes √∫nicas.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "name",
                "operator": "$stringContains",
                "value": "Engineering"
              }
            ]
          }
        ]
      }
      ```
      Campos dispon√≠veis: `id`, `name`
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configura√ß√£o B√°sica do Agente Linear

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Obtenha ferramentas empresariais (ferramentas do Linear ser√£o inclu√≠das)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Crie um agente com funcionalidades do Linear
linear_agent = Agent(
    role="Development Manager",
    goal="Gerenciar issues do Linear e acompanhar o progresso do desenvolvimento de forma eficiente",
    backstory="Um assistente de IA especializado em gerenciamento de projetos de desenvolvimento de software.",
    tools=[enterprise_tools]
)

# Tarefa para criar um relat√≥rio de bug
create_bug_task = Task(
    description="Crie um relat√≥rio de bug de alta prioridade para o sistema de autentica√ß√£o e atribua √† equipe de backend",
    agent=linear_agent,
    expected_output="Bug report criado com sucesso com ID da issue"
)

# Execute a tarefa
crew = Crew(
    agents=[linear_agent],
    tasks=[create_bug_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Lineares Espec√≠ficas

```python
from crewai_tools import CrewaiEnterpriseTools

# Obtenha apenas ferramentas lineares espec√≠ficas
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["linear_create_issue", "linear_update_issue", "linear_search_issue"]
)

issue_manager = Agent(
    role="Issue Manager",
    goal="Criar e gerenciar issues no Linear de forma eficiente",
    backstory="Um assistente de IA focado na cria√ß√£o e no gerenciamento do ciclo de vida de issues.",
    tools=enterprise_tools
)

# Tarefa para gerenciar fluxo de issues
issue_workflow = Task(
    description="Crie uma issue de solicita√ß√£o de recurso e atualize os status das issues relacionadas para refletir o progresso atual",
    agent=issue_manager,
    expected_output="Solicita√ß√£o de recurso criada e issues relacionadas atualizadas"
)

crew = Crew(
    agents=[issue_manager],
    tasks=[issue_workflow]
)

crew.kickoff()
```

### Gerenciamento de Projetos e Equipes

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

project_coordinator = Agent(
    role="Project Coordinator",
    goal="Coordenar projetos e equipes no Linear de forma eficiente",
    backstory="Um coordenador de projetos experiente que gerencia ciclos de desenvolvimento e fluxos de trabalho de equipe.",
    tools=[enterprise_tools]
)

# Tarefa para coordenar a configura√ß√£o de projeto
project_coordination = Task(
    description="""
    1. Pesquise por equipes de engenharia no Linear
    2. Crie um novo projeto para o desenvolvimento de recursos do Q2
    3. Associe o projeto √†s equipes relevantes
    4. Crie marcos iniciais do projeto como issues
    """,
    agent=project_coordinator,
    expected_output="Projeto Q2 criado com equipes atribu√≠das e marcos iniciais estabelecidos"
)

crew = Crew(
    agents=[project_coordinator],
    tasks=[project_coordination]
)

crew.kickoff()
```

### Hierarquia de Issues e Gerenciamento de Sub-tarefas

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

task_organizer = Agent(
    role="Task Organizer",
    goal="Organizar issues complexas em sub-tarefas gerenci√°veis",
    backstory="Um assistente de IA que divide trabalhos de desenvolvimento complexos em sub-tarefas organizadas.",
    tools=[enterprise_tools]
)

# Tarefa para criar hierarquia de issues
hierarchy_task = Task(
    description="""
    1. Pesquise por issues de recursos grandes que precisam ser divididos
    2. Para cada issue complexa, crie sub-issues para diferentes componentes
    3. Atualize as issues principais com descri√ß√µes adequadas e links para sub-issues
    4. Atribua sub-issues aos membros apropriados da equipe com base na especialidade
    """,
    agent=task_organizer,
    expected_output="Issues complexas divididas em sub-tarefas gerenci√°veis com atribui√ß√µes corretas"
)

crew = Crew(
    agents=[task_organizer],
    tasks=[hierarchy_task]
)

crew.kickoff()
```

### Fluxo de Trabalho de Desenvolvimento Automatizado

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

workflow_automator = Agent(
    role="Workflow Automator",
    goal="Automatizar processos de fluxo de trabalho de desenvolvimento no Linear",
    backstory="Um assistente de IA que automatiza tarefas repetitivas de fluxo de trabalho de desenvolvimento.",
    tools=[enterprise_tools]
)

# Tarefa de automa√ß√£o de workflow complexa
automation_task = Task(
    description="""
    1. Pesquise por issues que estejam em progresso h√° mais de 7 dias
    2. Atualize suas prioridades com base nas datas de vencimento e import√¢ncia do projeto
    3. Crie issues semanais de planejamento de sprint para cada equipe
    4. Arquive issues conclu√≠das do ciclo anterior
    5. Gere relat√≥rios de status do projeto como novas issues
    """,
    agent=workflow_automator,
    expected_output="Fluxo de desenvolvimento automatizado com prioridades atualizadas, planejamento de sprint e relat√≥rios de status"
)

crew = Crew(
    agents=[workflow_automator],
    tasks=[automation_task]
)

crew.kickoff()
```

## Solu√ß√£o de Problemas

### Problemas Comuns

**Erros de Permiss√£o**

* Certifique-se de que sua conta Linear possui as permiss√µes necess√°rias no workspace de destino
* Verifique se a conex√£o OAuth inclui os escopos requeridos pela API do Linear
* Confirme se voc√™ tem permiss√µes para criar/editar issues e projetos no workspace

**IDs e Refer√™ncias Inv√°lidas**

* Verifique os IDs de equipes, IDs de issues e IDs de projetos para garantir o formato UUID correto
* Assegure que as entidades referenciadas (equipes, projetos, ciclos) existem e est√£o acess√≠veis
* Verifique se os identificadores de issues seguem o formato correto (ex: "ABC-1")

**Problemas de Associa√ß√£o entre Equipe e Projeto**

* Use LINEAR\_SEARCH\_TEAMS para obter IDs de equipe v√°lidos antes de criar issues ou projetos
* Certifique-se de que as equipes existem e est√£o ativas no seu workspace
* Verifique se os IDs das equipes est√£o devidamente formatados como UUIDs

**Problemas com Status e Prioridade das Issues**

* Verifique se os IDs de status referenciam estados de workflow v√°lidos para a equipe
* Certifique-se de que os valores de prioridade est√£o dentro do intervalo v√°lido para sua configura√ß√£o do Linear
* Confirme que campos personalizados e labels existem antes de referenci√°-los

**Problemas com Formato de Data e Hora**

* Use o formato ISO 8601 para datas de vencimento e timestamps
* Certifique-se de que os fusos hor√°rios est√£o corretos para c√°lculos de datas de vencimento
* Verifique se os valores de data s√£o v√°lidos e posteriores √† data atual para datas de vencimento

**Problemas de Pesquisa e Filtros**

* Garanta que as consultas de busca estejam formatadas corretamente e n√£o estejam vazias
* Utilize nomes de campos v√°lidos nas f√≥rmulas de filtro: `title`, `number`, `project`, `createdAt`
* Teste filtros simples antes de montar consultas complexas com m√∫ltiplas condi√ß√µes
* Verifique se os tipos de operadores correspondem aos tipos de dados dos campos filtrados

**Problemas na Cria√ß√£o de Sub-issues**

* Certifique-se de que os IDs das issues pai s√£o v√°lidos e acess√≠veis
* Verifique se o ID da equipe para as sub-issues corresponde ou √© compat√≠vel com o da issue pai
* Assegure-se de que as issues pai n√£o estejam arquivadas ou exclu√≠das

### Obtendo Ajuda

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para assist√™ncia na configura√ß√£o ou solu√ß√£o de problemas da integra√ß√£o com o Linear.
</Card>


# Integra√ß√£o com o Notion
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/notion

Gerenciamento de p√°ginas e bancos de dados com integra√ß√£o do Notion para o CrewAI.

## Vis√£o Geral

Permita que seus agentes gerenciem p√°ginas, bancos de dados e conte√∫dos atrav√©s do Notion. Crie e atualize p√°ginas, gerencie blocos de conte√∫do, organize bases de conhecimento e otimize seus fluxos de documenta√ß√£o com automa√ß√£o alimentada por IA.

## Pr√©-requisitos

Antes de usar a integra√ß√£o com o Notion, certifique-se de que voc√™ tem:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Uma conta Notion com permiss√µes adequadas no workspace
* Sua conta Notion conectada atrav√©s da [p√°gina de Integra√ß√µes](https://app.crewai.com/crewai_plus/connectors)

## Configurando a Integra√ß√£o com o Notion

### 1. Conecte sua Conta Notion

1. Acesse [Integra√ß√µes do CrewAI Enterprise](https://app.crewai.com/crewai_plus/connectors)
2. Procure por **Notion** na se√ß√£o de Integra√ß√µes de Autentica√ß√£o
3. Clique em **Conectar** e complete o fluxo de OAuth
4. Conceda as permiss√µes necess√°rias para gerenciamento de p√°ginas e bancos de dados
5. Copie seu Token Enterprise em [Configura√ß√µes da Conta](https://app.crewai.com/crewai_plus/settings/account)

### 2. Instale o Pacote Necess√°rio

```bash
uv add crewai-tools
```

## A√ß√µes Dispon√≠veis

<AccordionGroup>
  <Accordion title="NOTION_CREATE_PAGE">
    **Descri√ß√£o:** Cria uma p√°gina no Notion.

    **Par√¢metros:**

    * `parent` (object, obrigat√≥rio): Parent - A p√°gina ou banco de dados pai onde a nova p√°gina ser√° inserida, representado como um objeto JSON com uma chave page\_id ou database\_id.
      ```json
      {
        "database_id": "DATABASE_ID"
      }
      ```
    * `properties` (object, obrigat√≥rio): Properties - Os valores das propriedades da p√°gina. Se o pai for um banco de dados, o schema deve corresponder √†s propriedades do banco de dados.
      ```json
      {
        "title": [
          {
            "text": {
              "content": "My Page"
            }
          }
        ]
      }
      ```
    * `icon` (object, obrigat√≥rio): Icon - O √≠cone da p√°gina.
      ```json
      {
        "emoji": "ü•¨"
      }
      ```
    * `children` (object, opcional): Children - Blocos de conte√∫do a serem adicionados √† p√°gina.
      ```json
      [
        {
          "object": "block",
          "type": "heading_2",
          "heading_2": {
            "rich_text": [
              {
                "type": "text",
                "text": {
                  "content": "Lacinato kale"
                }
              }
            ]
          }
        }
      ]
      ```
    * `cover` (object, opcional): Cover - A imagem de capa da p√°gina.
      ```json
      {
        "external": {
          "url": "https://upload.wikimedia.org/wikipedia/commons/6/62/Tuscankale.jpg"
        }
      }
      ```
  </Accordion>

  <Accordion title="NOTION_UPDATE_PAGE">
    **Descri√ß√£o:** Atualiza uma p√°gina no Notion.

    **Par√¢metros:**

    * `pageId` (string, obrigat√≥rio): Page ID - Especifique o ID da P√°gina a ser atualizada. (exemplo: "59833787-2cf9-4fdf-8782-e53db20768a5").
    * `icon` (object, obrigat√≥rio): Icon - O √≠cone da p√°gina.
      ```json
      {
        "emoji": "ü•¨"
      }
      ```
    * `archived` (boolean, opcional): Archived - Indica se a p√°gina est√° arquivada (exclu√≠da). Defina como true para arquivar a p√°gina. Defina como false para restaurar.
    * `properties` (object, opcional): Properties - Os valores das propriedades a serem atualizados na p√°gina.
      ```json
      {
        "title": [
          {
            "text": {
              "content": "My Updated Page"
            }
          }
        ]
      }
      ```
    * `cover` (object, opcional): Cover - A imagem de capa da p√°gina.
      ```json
      {
        "external": {
          "url": "https://upload.wikimedia.org/wikipedia/commons/6/62/Tuscankale.jpg"
        }
      }
      ```
  </Accordion>

  <Accordion title="NOTION_GET_PAGE_BY_ID">
    **Descri√ß√£o:** Busca uma p√°gina pelo ID no Notion.

    **Par√¢metros:**

    * `pageId` (string, obrigat√≥rio): Page ID - Especifique o ID da P√°gina a ser buscada. (exemplo: "59833787-2cf9-4fdf-8782-e53db20768a5").
  </Accordion>

  <Accordion title="NOTION_ARCHIVE_PAGE">
    **Descri√ß√£o:** Arquiva uma p√°gina no Notion.

    **Par√¢metros:**

    * `pageId` (string, obrigat√≥rio): Page ID - Especifique o ID da P√°gina a ser arquivada. (exemplo: "59833787-2cf9-4fdf-8782-e53db20768a5").
  </Accordion>

  <Accordion title="NOTION_SEARCH_PAGES">
    **Descri√ß√£o:** Pesquisa p√°ginas no Notion utilizando filtros.

    **Par√¢metros:**

    * `searchByTitleFilterSearch` (object, opcional): Um filtro na forma normal disjuntiva - OU de grupos E de condi√ß√µes simples.
      ```json
      {
        "operator": "OR",
        "conditions": [
          {
            "operator": "AND",
            "conditions": [
              {
                "field": "query",
                "operator": "$stringExactlyMatches",
                "value": "meeting notes"
              }
            ]
          }
        ]
      }
      ```
      Campos dispon√≠veis: `query`, `filter.value`, `direction`, `page_size`
  </Accordion>

  <Accordion title="NOTION_GET_PAGE_CONTENT">
    **Descri√ß√£o:** Obt√©m o conte√∫do (blocos) de uma p√°gina no Notion.

    **Par√¢metros:**

    * `blockId` (string, obrigat√≥rio): Page ID - Especifique o ID de um Bloco ou P√°gina para receber todos os seus blocos filhos na ordem correta. (exemplo: "59833787-2cf9-4fdf-8782-e53db20768a5").
  </Accordion>

  <Accordion title="NOTION_UPDATE_BLOCK">
    **Descri√ß√£o:** Atualiza um bloco no Notion.

    **Par√¢metros:**

    * `blockId` (string, obrigat√≥rio): Block ID - Especifique o ID do Bloco a ser atualizado. (exemplo: "9bc30ad4-9373-46a5-84ab-0a7845ee52e6").
    * `archived` (boolean, opcional): Archived - Defina como true para arquivar (excluir) um bloco. Defina como false para restaurar um bloco.
    * `paragraph` (object, opcional): Conte√∫do do par√°grafo.
      ```json
      {
        "rich_text": [
          {
            "type": "text",
            "text": {
              "content": "Lacinato kale",
              "link": null
            }
          }
        ],
        "color": "default"
      }
      ```
    * `image` (object, opcional): Bloco de imagem.
      ```json
      {
        "type": "external",
        "external": {
          "url": "https://website.domain/images/image.png"
        }
      }
      ```
    * `bookmark` (object, opcional): Bloco de bookmark.
      ```json
      {
        "caption": [],
        "url": "https://companywebsite.com"
      }
      ```
    * `code` (object, opcional): Bloco de c√≥digo.
      ```json
      {
        "rich_text": [
          {
            "type": "text",
            "text": {
              "content": "const a = 3"
            }
          }
        ],
        "language": "javascript"
      }
      ```
    * `pdf` (object, opcional): Bloco de PDF.
      ```json
      {
        "type": "external",
        "external": {
          "url": "https://website.domain/files/doc.pdf"
        }
      }
      ```
    * `table` (object, opcional): Bloco de Tabela.
      ```json
      {
        "table_width": 2,
        "has_column_header": false,
        "has_row_header": false
      }
      ```
    * `tableOfContent` (object, opcional): Bloco de Sum√°rio.
      ```json
      {
        "color": "default"
      }
      ```
    * `additionalFields` (object, opcional): Blocos adicionais.
      ```json
      {
        "child_page": {
          "title": "Lacinato kale"
        },
        "child_database": {
          "title": "My database"
        }
      }
      ```
  </Accordion>

  <Accordion title="NOTION_GET_BLOCK_BY_ID">
    **Descri√ß√£o:** Busca um bloco pelo ID no Notion.

    **Par√¢metros:**

    * `blockId` (string, obrigat√≥rio): Block ID - Especifique o ID do Bloco a ser buscado. (exemplo: "9bc30ad4-9373-46a5-84ab-0a7845ee52e6").
  </Accordion>

  <Accordion title="NOTION_DELETE_BLOCK">
    **Descri√ß√£o:** Exclui um bloco no Notion.

    **Par√¢metros:**

    * `blockId` (string, obrigat√≥rio): Block ID - Especifique o ID do Bloco a ser exclu√≠do. (exemplo: "9bc30ad4-9373-46a5-84ab-0a7845ee52e6").
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configura√ß√£o B√°sica do Agente Notion

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Notion tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Notion capabilities
notion_agent = Agent(
    role="Documentation Manager",
    goal="Manage documentation and knowledge base in Notion efficiently",
    backstory="An AI assistant specialized in content management and documentation.",
    tools=[enterprise_tools]
)

# Task to create a meeting notes page
create_notes_task = Task(
    description="Create a new meeting notes page in the team database with today's date and agenda items",
    agent=notion_agent,
    expected_output="Meeting notes page created successfully with structured content"
)

# Run the task
crew = Crew(
    agents=[notion_agent],
    tasks=[create_notes_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Espec√≠ficas do Notion

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Notion tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["notion_create_page", "notion_update_block", "notion_search_pages"]
)

content_manager = Agent(
    role="Content Manager",
    goal="Create and manage content pages efficiently",
    backstory="An AI assistant that focuses on content creation and management.",
    tools=enterprise_tools
)

# Task to manage content workflow
content_workflow = Task(
    description="Create a new project documentation page and add structured content blocks for requirements and specifications",
    agent=content_manager,
    expected_output="Project documentation created with organized content sections"
)

crew = Crew(
    agents=[content_manager],
    tasks=[content_workflow]
)

crew.kickoff()
```

### Gerenciamento de Base de Conhecimento

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

knowledge_curator = Agent(
    role="Knowledge Curator",
    goal="Curate and organize knowledge base content in Notion",
    backstory="An experienced knowledge manager who organizes and maintains comprehensive documentation.",
    tools=[enterprise_tools]
)

# Task to curate knowledge base
curation_task = Task(
    description="""
    1. Search for existing documentation pages related to our new product feature
    2. Create a comprehensive feature documentation page with proper structure
    3. Add code examples, images, and links to related resources
    4. Update existing pages with cross-references to the new documentation
    """,
    agent=knowledge_curator,
    expected_output="Feature documentation created and integrated with existing knowledge base"
)

crew = Crew(
    agents=[knowledge_curator],
    tasks=[curation_task]
)

crew.kickoff()
```

### Estrutura e Organiza√ß√£o de Conte√∫do

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

content_organizer = Agent(
    role="Content Organizer",
    goal="Organize and structure content blocks for optimal readability",
    backstory="An AI assistant that specializes in content structure and user experience.",
    tools=[enterprise_tools]
)

# Task to organize content structure
organization_task = Task(
    description="""
    1. Get content from existing project pages
    2. Analyze the structure and identify improvement opportunities
    3. Update content blocks to use proper headings, tables, and formatting
    4. Add table of contents and improve navigation between related pages
    5. Create templates for future documentation consistency
    """,
    agent=content_organizer,
    expected_output="Content reorganized with improved structure and navigation"
)

crew = Crew(
    agents=[content_organizer],
    tasks=[organization_task]
)

crew.kickoff()
```

### Fluxos de Trabalho de Documenta√ß√£o Automatizados

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

doc_automator = Agent(
    role="Documentation Automator",
    goal="Automate documentation workflows and maintenance",
    backstory="An AI assistant that automates repetitive documentation tasks.",
    tools=[enterprise_tools]
)

# Complex documentation automation task
automation_task = Task(
    description="""
    1. Search for pages that haven't been updated in the last 30 days
    2. Review and update outdated content blocks
    3. Create weekly team update pages with consistent formatting
    4. Add status indicators and progress tracking to project pages
    5. Generate monthly documentation health reports
    6. Archive completed project pages and organize them in archive sections
    """,
    agent=doc_automator,
    expected_output="Documentation automated with updated content, weekly reports, and organized archives"
)

crew = Crew(
    agents=[doc_automator],
    tasks=[automation_task]
)

crew.kickoff()
```

## Solu√ß√£o de Problemas

### Problemas Comuns

**Erros de Permiss√£o**

* Certifique-se de que sua conta Notion possui acesso de edi√ß√£o ao workspace desejado
* Verifique se a conex√£o OAuth inclui os escopos necess√°rios para a API do Notion
* Confira se as p√°ginas e bancos de dados est√£o compartilhados com a integra√ß√£o autenticada

**IDs de P√°gina e Bloco Inv√°lidos**

* Revise os IDs de p√°gina e bloco para garantir que estejam no formato UUID correto
* Garanta que as p√°ginas e blocos referenciados existem e s√£o acess√≠veis
* Verifique se os IDs da p√°gina ou banco de dados pai s√£o v√°lidos ao criar novas p√°ginas

**Problemas com Schema de Propriedades**

* Assegure que as propriedades da p√°gina correspondem ao schema do banco de dados ao criar p√°ginas em bancos de dados
* Verifique se os nomes e tipos das propriedades est√£o corretos para o banco de dados alvo
* Confirme que as propriedades obrigat√≥rias est√£o inclu√≠das ao criar ou atualizar p√°ginas

**Estrutura dos Blocos de Conte√∫do**

* Assegure que o conte√∫do dos blocos segue as especifica√ß√µes de rich text do Notion
* Verifique se estruturas aninhadas de blocos est√£o devidamente formatadas
* Confira se URLs de m√≠dias s√£o acess√≠veis e est√£o corretamente formatadas

**Problemas de Pesquisa e Filtros**

* Certifique-se de que as queries de pesquisa est√£o devidamente formatadas e n√£o est√£o vazias
* Use nomes de campos v√°lidos em f√≥rmulas de filtro: `query`, `filter.value`, `direction`, `page_size`
* Teste pesquisas simples antes de construir condi√ß√µes de filtro mais complexas

**Relacionamentos Pai-Filho**

* Verifique se a p√°gina ou banco de dados pai existe antes de criar p√°ginas filhas
* Assegure que existam permiss√µes apropriadas para o container pai
* Confirme que os schemas do banco permitem definir as propriedades desejadas

**Rich Text e Conte√∫do de M√≠dia**

* Assegure que URLs para imagens externas, PDFs e bookmarks sejam acess√≠veis
* Verifique se a formata√ß√£o rich text segue as especifica√ß√µes da API do Notion
* Confira se os tipos de linguagem nos blocos de c√≥digo s√£o suportados pelo Notion

**Opera√ß√µes de Arquivamento e Exclus√£o**

* Entenda a diferen√ßa entre arquivar (revers√≠vel) e excluir (permanente)
* Certifique-se de ter permiss√µes para arquivar ou excluir o conte√∫do desejado
* Tenha cuidado com opera√ß√µes em massa que possam afetar m√∫ltiplas p√°ginas ou blocos

### Obtendo Ajuda

<Card title="Precisa de ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nosso time de suporte para aux√≠lio na configura√ß√£o ou solu√ß√£o de problemas com a integra√ß√£o Notion.
</Card>


# Integra√ß√£o com Salesforce
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/salesforce

Automa√ß√£o de vendas e CRM com integra√ß√£o Salesforce para CrewAI.

## Vis√£o Geral

Permita que seus agentes gerenciem relacionamentos com clientes, processos de vendas e dados atrav√©s do Salesforce. Crie e atualize registros, gerencie leads e oportunidades, execute consultas SOQL e otimize seus fluxos de trabalho de CRM com automa√ß√£o potencializada por IA.

## Pr√©-requisitos

Antes de usar a integra√ß√£o Salesforce, certifique-se de que voc√™ possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Uma conta Salesforce com permiss√µes apropriadas
* Sua conta Salesforce conectada via a [p√°gina de Integra√ß√µes](https://app.crewai.com/integrations)

## Ferramentas Dispon√≠veis

### **Gerenciamento de Registros**

<AccordionGroup>
  <Accordion title="SALESFORCE_CREATE_RECORD_CONTACT">
    **Descri√ß√£o:** Crie um novo registro de Contato no Salesforce.

    **Par√¢metros:**

    * `FirstName` (string, opcional): Primeiro nome
    * `LastName` (string, obrigat√≥rio): Sobrenome - Este campo √© obrigat√≥rio
    * `accountId` (string, opcional): ID da Conta - Conta √† qual o contato pertence
    * `Email` (string, opcional): Endere√ßo de e-mail
    * `Title` (string, opcional): Cargo do contato, como CEO ou Vice-presidente
    * `Description` (string, opcional): Descri√ß√£o do contato
    * `additionalFields` (object, opcional): Campos adicionais no formato JSON para campos personalizados de Contato
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_RECORD_LEAD">
    **Descri√ß√£o:** Crie um novo registro de Lead no Salesforce.

    **Par√¢metros:**

    * `FirstName` (string, opcional): Primeiro nome
    * `LastName` (string, obrigat√≥rio): Sobrenome - Este campo √© obrigat√≥rio
    * `Company` (string, obrigat√≥rio): Empresa - Este campo √© obrigat√≥rio
    * `Email` (string, opcional): Endere√ßo de e-mail
    * `Phone` (string, opcional): N√∫mero de telefone
    * `Website` (string, opcional): URL do site
    * `Title` (string, opcional): Cargo do contato, como CEO ou Vice-presidente
    * `Status` (string, opcional): Status do Lead - Use as Configura√ß√µes de Workflow do Connect Portal para selecionar o status do Lead
    * `Description` (string, opcional): Descri√ß√£o do lead
    * `additionalFields` (object, opcional): Campos adicionais no formato JSON para campos personalizados de Lead
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_RECORD_OPPORTUNITY">
    **Descri√ß√£o:** Crie um novo registro de Oportunidade no Salesforce.

    **Par√¢metros:**

    * `Name` (string, obrigat√≥rio): Nome da Oportunidade - Este campo √© obrigat√≥rio
    * `StageName` (string, opcional): Est√°gio da Oportunidade - Use as Configura√ß√µes de Workflow do Connect Portal para selecionar o est√°gio
    * `CloseDate` (string, opcional): Data de fechamento no formato YYYY-MM-DD - Padr√£o para 30 dias a partir da data atual
    * `AccountId` (string, opcional): Conta √† qual a Oportunidade pertence
    * `Amount` (string, opcional): Valor total estimado da venda
    * `Description` (string, opcional): Descri√ß√£o da oportunidade
    * `OwnerId` (string, opcional): Usu√°rio Salesforce designado para esta Oportunidade
    * `NextStep` (string, opcional): Descri√ß√£o da pr√≥xima tarefa no fechamento da Oportunidade
    * `additionalFields` (object, opcional): Campos adicionais no formato JSON para campos personalizados de Oportunidade
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_RECORD_TASK">
    **Descri√ß√£o:** Crie um novo registro de Tarefa no Salesforce.

    **Par√¢metros:**

    * `whatId` (string, opcional): Relacionado ao ID - ID da Conta ou Oportunidade relacionada √† Tarefa
    * `whoId` (string, opcional): ID do Nome - ID do Contato ou Lead relacionado √† Tarefa
    * `subject` (string, obrigat√≥rio): Assunto da tarefa
    * `activityDate` (string, opcional): Data da Atividade no formato YYYY-MM-DD
    * `description` (string, opcional): Descri√ß√£o da tarefa
    * `taskSubtype` (string, obrigat√≥rio): Subtipo da Tarefa - Op√ß√µes: task, email, listEmail, call
    * `Status` (string, opcional): Status - Op√ß√µes: Not Started, In Progress, Completed
    * `ownerId` (string, opcional): ID do respons√°vel - Usu√°rio Salesforce designado para a Tarefa
    * `callDurationInSeconds` (string, opcional): Dura√ß√£o da chamada em segundos
    * `isReminderSet` (boolean, opcional): Se o lembrete est√° definido
    * `reminderDateTime` (string, opcional): Data/Hora do lembrete no formato ISO
    * `additionalFields` (object, opcional): Campos adicionais no formato JSON para campos personalizados de Tarefa
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_RECORD_ACCOUNT">
    **Descri√ß√£o:** Crie um novo registro de Conta no Salesforce.

    **Par√¢metros:**

    * `Name` (string, obrigat√≥rio): Nome da Conta - Este campo √© obrigat√≥rio
    * `OwnerId` (string, opcional): Usu√°rio Salesforce respons√°vel por esta Conta
    * `Website` (string, opcional): URL do site
    * `Phone` (string, opcional): N√∫mero de telefone
    * `Description` (string, opcional): Descri√ß√£o da conta
    * `additionalFields` (object, opcional): Campos adicionais no formato JSON para campos personalizados de Conta
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_RECORD_ANY">
    **Descri√ß√£o:** Crie um registro de qualquer tipo de objeto no Salesforce.

    **Nota:** Esta √© uma ferramenta flex√≠vel para criar registros de tipos de objetos personalizados ou desconhecidos.
  </Accordion>
</AccordionGroup>

### **Atualiza√ß√£o de Registros**

<AccordionGroup>
  <Accordion title="SALESFORCE_UPDATE_RECORD_CONTACT">
    **Descri√ß√£o:** Atualize um registro de Contato existente no Salesforce.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID do registro a ser atualizado
    * `FirstName` (string, opcional): Primeiro nome
    * `LastName` (string, opcional): Sobrenome
    * `accountId` (string, opcional): ID da Conta √† qual o contato pertence
    * `Email` (string, opcional): Endere√ßo de e-mail
    * `Title` (string, opcional): Cargo do contato
    * `Description` (string, opcional): Descri√ß√£o do contato
    * `additionalFields` (object, opcional): Campos adicionais no formato JSON para campos personalizados de Contato
  </Accordion>

  <Accordion title="SALESFORCE_UPDATE_RECORD_LEAD">
    **Descri√ß√£o:** Atualize um registro de Lead existente no Salesforce.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID do registro a ser atualizado
    * `FirstName` (string, opcional): Primeiro nome
    * `LastName` (string, opcional): Sobrenome
    * `Company` (string, opcional): Nome da empresa
    * `Email` (string, opcional): Endere√ßo de e-mail
    * `Phone` (string, opcional): N√∫mero de telefone
    * `Website` (string, opcional): URL do site
    * `Title` (string, opcional): Cargo do contato
    * `Status` (string, opcional): Status do Lead
    * `Description` (string, opcional): Descri√ß√£o do lead
    * `additionalFields` (object, opcional): Campos adicionais no formato JSON para campos personalizados de Lead
  </Accordion>

  <Accordion title="SALESFORCE_UPDATE_RECORD_OPPORTUNITY">
    **Descri√ß√£o:** Atualize um registro de Oportunidade existente no Salesforce.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID do registro a ser atualizado
    * `Name` (string, opcional): Nome da Oportunidade
    * `StageName` (string, opcional): Est√°gio da oportunidade
    * `CloseDate` (string, opcional): Data de fechamento no formato YYYY-MM-DD
    * `AccountId` (string, opcional): Conta √† qual a Oportunidade pertence
    * `Amount` (string, opcional): Valor total estimado da venda
    * `Description` (string, opcional): Descri√ß√£o da oportunidade
    * `OwnerId` (string, opcional): Usu√°rio Salesforce respons√°vel por esta Oportunidade
    * `NextStep` (string, opcional): Descri√ß√£o da pr√≥xima tarefa no fechamento da Oportunidade
    * `additionalFields` (object, opcional): Campos adicionais no formato JSON para campos personalizados de Oportunidade
  </Accordion>

  <Accordion title="SALESFORCE_UPDATE_RECORD_TASK">
    **Descri√ß√£o:** Atualize um registro de Tarefa existente no Salesforce.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID do registro a ser atualizado
    * `whatId` (string, opcional): Relacionado ao ID - ID da Conta ou Oportunidade relacionada
    * `whoId` (string, opcional): ID do Nome - ID do Contato ou Lead relacionado √† Tarefa
    * `subject` (string, opcional): Assunto da tarefa
    * `activityDate` (string, opcional): Data da Atividade no formato YYYY-MM-DD
    * `description` (string, opcional): Descri√ß√£o da tarefa
    * `Status` (string, opcional): Status - Op√ß√µes: Not Started, In Progress, Completed
    * `ownerId` (string, opcional): ID do respons√°vel - Usu√°rio Salesforce designado para a Tarefa
    * `callDurationInSeconds` (string, opcional): Dura√ß√£o da chamada em segundos
    * `isReminderSet` (boolean, opcional): Se o lembrete est√° definido
    * `reminderDateTime` (string, opcional): Data/Hora do lembrete em formato ISO
    * `additionalFields` (object, opcional): Campos adicionais no formato JSON para campos personalizados de Tarefa
  </Accordion>

  <Accordion title="SALESFORCE_UPDATE_RECORD_ACCOUNT">
    **Descri√ß√£o:** Atualize um registro de Conta existente no Salesforce.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID do registro a ser atualizado
    * `Name` (string, opcional): Nome da Conta
    * `OwnerId` (string, opcional): Usu√°rio Salesforce respons√°vel por esta Conta
    * `Website` (string, opcional): URL do site
    * `Phone` (string, opcional): N√∫mero de telefone
    * `Description` (string, opcional): Descri√ß√£o da conta
    * `additionalFields` (object, opcional): Campos adicionais no formato JSON para campos personalizados de Conta
  </Accordion>

  <Accordion title="SALESFORCE_UPDATE_RECORD_ANY">
    **Descri√ß√£o:** Atualize um registro de qualquer tipo de objeto no Salesforce.

    **Nota:** Esta √© uma ferramenta flex√≠vel para atualizar registros de tipos de objetos personalizados ou desconhecidos.
  </Accordion>
</AccordionGroup>

### **Recupera√ß√£o de Registros**

<AccordionGroup>
  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_CONTACT">
    **Descri√ß√£o:** Obtenha um registro de Contato pelo seu ID.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID do registro do Contato
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_LEAD">
    **Descri√ß√£o:** Obtenha um registro de Lead pelo seu ID.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID do registro do Lead
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_OPPORTUNITY">
    **Descri√ß√£o:** Obtenha um registro de Oportunidade pelo seu ID.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID do registro da Oportunidade
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_TASK">
    **Descri√ß√£o:** Obtenha um registro de Tarefa pelo seu ID.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID do registro da Tarefa
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_ACCOUNT">
    **Descri√ß√£o:** Obtenha um registro de Conta pelo seu ID.

    **Par√¢metros:**

    * `recordId` (string, obrigat√≥rio): ID do registro da Conta
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_ID_ANY">
    **Descri√ß√£o:** Obtenha um registro de qualquer tipo de objeto pelo seu ID.

    **Par√¢metros:**

    * `recordType` (string, obrigat√≥rio): Tipo do registro (ex.: "CustomObject\_\_c")
    * `recordId` (string, obrigat√≥rio): ID do registro
  </Accordion>
</AccordionGroup>

### **Busca de Registros**

<AccordionGroup>
  <Accordion title="SALESFORCE_SEARCH_RECORDS_CONTACT">
    **Descri√ß√£o:** Pesquise registros de Contato com filtragem avan√ßada.

    **Par√¢metros:**

    * `filterFormula` (object, opcional): Filtro avan√ßado em forma normal disjuntiva com operadores espec√≠ficos de campo
    * `sortBy` (string, opcional): Campo para ordena√ß√£o (ex.: "CreatedDate")
    * `sortDirection` (string, opcional): Dire√ß√£o da ordena√ß√£o - Op√ß√µes: ASC, DESC
    * `includeAllFields` (boolean, opcional): Incluir todos os campos nos resultados
    * `paginationParameters` (object, opcional): Configura√ß√µes de pagina√ß√£o com pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_SEARCH_RECORDS_LEAD">
    **Descri√ß√£o:** Pesquise registros de Lead com filtragem avan√ßada.

    **Par√¢metros:**

    * `filterFormula` (object, opcional): Filtro avan√ßado em forma normal disjuntiva com operadores espec√≠ficos de campo
    * `sortBy` (string, opcional): Campo para ordena√ß√£o (ex.: "CreatedDate")
    * `sortDirection` (string, opcional): Dire√ß√£o da ordena√ß√£o - Op√ß√µes: ASC, DESC
    * `includeAllFields` (boolean, opcional): Incluir todos os campos nos resultados
    * `paginationParameters` (object, opcional): Configura√ß√µes de pagina√ß√£o com pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_SEARCH_RECORDS_OPPORTUNITY">
    **Descri√ß√£o:** Pesquise registros de Oportunidade com filtragem avan√ßada.

    **Par√¢metros:**

    * `filterFormula` (object, opcional): Filtro avan√ßado em forma normal disjuntiva com operadores espec√≠ficos de campo
    * `sortBy` (string, opcional): Campo para ordena√ß√£o (ex.: "CreatedDate")
    * `sortDirection` (string, opcional): Dire√ß√£o da ordena√ß√£o - Op√ß√µes: ASC, DESC
    * `includeAllFields` (boolean, opcional): Incluir todos os campos nos resultados
    * `paginationParameters` (object, opcional): Configura√ß√µes de pagina√ß√£o com pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_SEARCH_RECORDS_TASK">
    **Descri√ß√£o:** Pesquise registros de Tarefa com filtragem avan√ßada.

    **Par√¢metros:**

    * `filterFormula` (object, opcional): Filtro avan√ßado em forma normal disjuntiva com operadores espec√≠ficos de campo
    * `sortBy` (string, opcional): Campo para ordena√ß√£o (ex.: "CreatedDate")
    * `sortDirection` (string, opcional): Dire√ß√£o da ordena√ß√£o - Op√ß√µes: ASC, DESC
    * `includeAllFields` (boolean, opcional): Incluir todos os campos nos resultados
    * `paginationParameters` (object, opcional): Configura√ß√µes de pagina√ß√£o com pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_SEARCH_RECORDS_ACCOUNT">
    **Descri√ß√£o:** Pesquise registros de Conta com filtragem avan√ßada.

    **Par√¢metros:**

    * `filterFormula` (object, opcional): Filtro avan√ßado em forma normal disjuntiva com operadores espec√≠ficos de campo
    * `sortBy` (string, opcional): Campo para ordena√ß√£o (ex.: "CreatedDate")
    * `sortDirection` (string, opcional): Dire√ß√£o da ordena√ß√£o - Op√ß√µes: ASC, DESC
    * `includeAllFields` (boolean, opcional): Incluir todos os campos nos resultados
    * `paginationParameters` (object, opcional): Configura√ß√µes de pagina√ß√£o com pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_SEARCH_RECORDS_ANY">
    **Descri√ß√£o:** Pesquise registros de qualquer tipo de objeto.

    **Par√¢metros:**

    * `recordType` (string, obrigat√≥rio): Tipo de registro para buscar
    * `filterFormula` (string, opcional): Crit√©rios de busca por filtro
    * `includeAllFields` (boolean, opcional): Incluir todos os campos nos resultados
    * `paginationParameters` (object, opcional): Configura√ß√µes de pagina√ß√£o com pageCursor
  </Accordion>
</AccordionGroup>

### **Recupera√ß√£o por List View**

<AccordionGroup>
  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_CONTACT">
    **Descri√ß√£o:** Obtenha registros de Contato de um List View espec√≠fico.

    **Par√¢metros:**

    * `listViewId` (string, obrigat√≥rio): ID do List View
    * `paginationParameters` (object, opcional): Configura√ß√µes de pagina√ß√£o com pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_LEAD">
    **Descri√ß√£o:** Obtenha registros de Lead de um List View espec√≠fico.

    **Par√¢metros:**

    * `listViewId` (string, obrigat√≥rio): ID do List View
    * `paginationParameters` (object, opcional): Configura√ß√µes de pagina√ß√£o com pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_OPPORTUNITY">
    **Descri√ß√£o:** Obtenha registros de Oportunidade de um List View espec√≠fico.

    **Par√¢metros:**

    * `listViewId` (string, obrigat√≥rio): ID do List View
    * `paginationParameters` (object, opcional): Configura√ß√µes de pagina√ß√£o com pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_TASK">
    **Descri√ß√£o:** Obtenha registros de Tarefa de um List View espec√≠fico.

    **Par√¢metros:**

    * `listViewId` (string, obrigat√≥rio): ID do List View
    * `paginationParameters` (object, opcional): Configura√ß√µes de pagina√ß√£o com pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_ACCOUNT">
    **Descri√ß√£o:** Obtenha registros de Conta de um List View espec√≠fico.

    **Par√¢metros:**

    * `listViewId` (string, obrigat√≥rio): ID do List View
    * `paginationParameters` (object, opcional): Configura√ß√µes de pagina√ß√£o com pageCursor
  </Accordion>

  <Accordion title="SALESFORCE_GET_RECORD_BY_VIEW_ID_ANY">
    **Descri√ß√£o:** Obtenha registros de qualquer tipo de objeto a partir de um List View espec√≠fico.

    **Par√¢metros:**

    * `recordType` (string, obrigat√≥rio): Tipo do registro
    * `listViewId` (string, obrigat√≥rio): ID do List View
    * `paginationParameters` (object, opcional): Configura√ß√µes de pagina√ß√£o com pageCursor
  </Accordion>
</AccordionGroup>

### **Campos Personalizados**

<AccordionGroup>
  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_CONTACT">
    **Descri√ß√£o:** Crie campos personalizados para objetos de Contato.

    **Par√¢metros:**

    * `label` (string, obrigat√≥rio): R√≥tulo do campo para exibi√ß√µes e refer√™ncia interna
    * `type` (string, obrigat√≥rio): Tipo do campo - Op√ß√µes: Checkbox, Currency, Date, Email, Number, Percent, Phone, Picklist, MultiselectPicklist, Text, TextArea, LongTextArea, Html, Time, Url
    * `defaultCheckboxValue` (boolean, opcional): Valor padr√£o para campos checkbox
    * `length` (string, obrigat√≥rio): Comprimento para campos num√©ricos/texto
    * `decimalPlace` (string, obrigat√≥rio): Casas decimais para campos num√©ricos
    * `pickListValues` (string, obrigat√≥rio): Valores para campos picklist (separados por novas linhas)
    * `visibleLines` (string, obrigat√≥rio): Linhas vis√≠veis para campos multisele√ß√£o/√°rea de texto
    * `description` (string, opcional): Descri√ß√£o do campo
    * `helperText` (string, opcional): Texto de ajuda exibido ao passar o mouse
    * `defaultFieldValue` (string, opcional): Valor padr√£o do campo
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_LEAD">
    **Descri√ß√£o:** Crie campos personalizados para objetos de Lead.

    **Par√¢metros:**

    * `label` (string, obrigat√≥rio): R√≥tulo do campo para exibi√ß√µes e refer√™ncia interna
    * `type` (string, obrigat√≥rio): Tipo do campo - Op√ß√µes: Checkbox, Currency, Date, Email, Number, Percent, Phone, Picklist, MultiselectPicklist, Text, TextArea, LongTextArea, Html, Time, Url
    * `defaultCheckboxValue` (boolean, opcional): Valor padr√£o para campos checkbox
    * `length` (string, obrigat√≥rio): Comprimento para campos num√©ricos/texto
    * `decimalPlace` (string, obrigat√≥rio): Casas decimais para campos num√©ricos
    * `pickListValues` (string, obrigat√≥rio): Valores para campos picklist (separados por novas linhas)
    * `visibleLines` (string, obrigat√≥rio): Linhas vis√≠veis para campos multisele√ß√£o/√°rea de texto
    * `description` (string, opcional): Descri√ß√£o do campo
    * `helperText` (string, opcional): Texto de ajuda exibido ao passar o mouse
    * `defaultFieldValue` (string, opcional): Valor padr√£o do campo
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_OPPORTUNITY">
    **Descri√ß√£o:** Crie campos personalizados para objetos de Oportunidade.

    **Par√¢metros:**

    * `label` (string, obrigat√≥rio): R√≥tulo do campo para exibi√ß√µes e refer√™ncia interna
    * `type` (string, obrigat√≥rio): Tipo do campo - Op√ß√µes: Checkbox, Currency, Date, Email, Number, Percent, Phone, Picklist, MultiselectPicklist, Text, TextArea, LongTextArea, Html, Time, Url
    * `defaultCheckboxValue` (boolean, opcional): Valor padr√£o para campos checkbox
    * `length` (string, obrigat√≥rio): Comprimento para campos num√©ricos/texto
    * `decimalPlace` (string, obrigat√≥rio): Casas decimais para campos num√©ricos
    * `pickListValues` (string, obrigat√≥rio): Valores para campos picklist (separados por novas linhas)
    * `visibleLines` (string, obrigat√≥rio): Linhas vis√≠veis para campos multisele√ß√£o/√°rea de texto
    * `description` (string, opcional): Descri√ß√£o do campo
    * `helperText` (string, opcional): Texto de ajuda exibido ao passar o mouse
    * `defaultFieldValue` (string, opcional): Valor padr√£o do campo
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_TASK">
    **Descri√ß√£o:** Crie campos personalizados para objetos de Tarefa.

    **Par√¢metros:**

    * `label` (string, obrigat√≥rio): R√≥tulo do campo para exibi√ß√µes e refer√™ncia interna
    * `type` (string, obrigat√≥rio): Tipo do campo - Op√ß√µes: Checkbox, Currency, Date, Email, Number, Percent, Phone, Picklist, MultiselectPicklist, Text, TextArea, Time, Url
    * `defaultCheckboxValue` (boolean, opcional): Valor padr√£o para campos checkbox
    * `length` (string, obrigat√≥rio): Comprimento para campos num√©ricos/texto
    * `decimalPlace` (string, obrigat√≥rio): Casas decimais para campos num√©ricos
    * `pickListValues` (string, obrigat√≥rio): Valores para campos picklist (separados por novas linhas)
    * `visibleLines` (string, obrigat√≥rio): Linhas vis√≠veis para campos multisele√ß√£o
    * `description` (string, opcional): Descri√ß√£o do campo
    * `helperText` (string, opcional): Texto de ajuda exibido ao passar o mouse
    * `defaultFieldValue` (string, opcional): Valor padr√£o do campo
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_ACCOUNT">
    **Descri√ß√£o:** Crie campos personalizados para objetos de Conta.

    **Par√¢metros:**

    * `label` (string, obrigat√≥rio): R√≥tulo do campo para exibi√ß√µes e refer√™ncia interna
    * `type` (string, obrigat√≥rio): Tipo do campo - Op√ß√µes: Checkbox, Currency, Date, Email, Number, Percent, Phone, Picklist, MultiselectPicklist, Text, TextArea, LongTextArea, Html, Time, Url
    * `defaultCheckboxValue` (boolean, opcional): Valor padr√£o para campos checkbox
    * `length` (string, obrigat√≥rio): Comprimento para campos num√©ricos/texto
    * `decimalPlace` (string, obrigat√≥rio): Casas decimais para campos num√©ricos
    * `pickListValues` (string, obrigat√≥rio): Valores para campos picklist (separados por novas linhas)
    * `visibleLines` (string, obrigat√≥rio): Linhas vis√≠veis para campos multisele√ß√£o/√°rea de texto
    * `description` (string, opcional): Descri√ß√£o do campo
    * `helperText` (string, opcional): Texto de ajuda exibido ao passar o mouse
    * `defaultFieldValue` (string, opcional): Valor padr√£o do campo
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_FIELD_ANY">
    **Descri√ß√£o:** Crie campos personalizados para qualquer tipo de objeto.

    **Nota:** Esta √© uma ferramenta flex√≠vel para criar campos personalizados para tipos de objetos personalizados ou desconhecidos.
  </Accordion>
</AccordionGroup>

### **Opera√ß√µes Avan√ßadas**

<AccordionGroup>
  <Accordion title="SALESFORCE_WRITE_SOQL_QUERY">
    **Descri√ß√£o:** Execute consultas SOQL personalizadas em seus dados do Salesforce.

    **Par√¢metros:**

    * `query` (string, obrigat√≥rio): Consulta SOQL (ex.: "SELECT Id, Name FROM Account WHERE Name = 'Exemplo'")
  </Accordion>

  <Accordion title="SALESFORCE_CREATE_CUSTOM_OBJECT">
    **Descri√ß√£o:** Crie um novo objeto personalizado no Salesforce.

    **Par√¢metros:**

    * `label` (string, obrigat√≥rio): R√≥tulo do objeto para abas, layouts de p√°gina e relat√≥rios
    * `pluralLabel` (string, obrigat√≥rio): R√≥tulo plural (ex.: "Contas")
    * `description` (string, opcional): Uma descri√ß√£o do Objeto Personalizado
    * `recordName` (string, obrigat√≥rio): Nome do registro exibido em layouts e buscas (ex.: "Nome da Conta")
  </Accordion>

  <Accordion title="SALESFORCE_DESCRIBE_ACTION_SCHEMA">
    **Descri√ß√£o:** Obtenha o schema esperado para opera√ß√µes em tipos de objetos espec√≠ficos.

    **Par√¢metros:**

    * `recordType` (string, obrigat√≥rio): Tipo de registro a ser detalhado
    * `operation` (string, obrigat√≥rio): Tipo de Opera√ß√£o (ex.: "CREATE\_RECORD" ou "UPDATE\_RECORD")

    **Nota:** Use esta fun√ß√£o primeiro ao trabalhar com objetos personalizados para entender seu schema antes de realizar opera√ß√µes.
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configura√ß√£o B√°sica de um Agente Salesforce

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Obtenha ferramentas enterprise (ferramentas Salesforce ser√£o inclu√≠das)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Crie um agente com capacidades Salesforce
salesforce_agent = Agent(
    role="CRM Manager",
    goal="Manage customer relationships and sales processes efficiently",
    backstory="An AI assistant specialized in CRM operations and sales automation.",
    tools=[enterprise_tools]
)

# Task to create a new lead
create_lead_task = Task(
    description="Create a new lead for John Doe from Example Corp with email john.doe@example.com",
    agent=salesforce_agent,
    expected_output="Lead created successfully with lead ID"
)

# Run the task
crew = Crew(
    agents=[salesforce_agent],
    tasks=[create_lead_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Salesforce Espec√≠ficas

```python
from crewai_tools import CrewaiEnterpriseTools

# Obtenha apenas ferramentas Salesforce espec√≠ficas
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["salesforce_create_record_lead", "salesforce_update_record_opportunity", "salesforce_search_records_contact"]
)

sales_manager = Agent(
    role="Sales Manager",
    goal="Manage leads and opportunities in the sales pipeline",
    backstory="An experienced sales manager who handles lead qualification and opportunity management.",
    tools=enterprise_tools
)

# Task to manage sales pipeline
pipeline_task = Task(
    description="Create a qualified lead and convert it to an opportunity with $50,000 value",
    agent=sales_manager,
    expected_output="Lead created and opportunity established successfully"
)

crew = Crew(
    agents=[sales_manager],
    tasks=[pipeline_task]
)

crew.kickoff()
```

### Gerenciamento de Contatos e Contas

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

account_manager = Agent(
    role="Account Manager",
    goal="Manage customer accounts and maintain strong relationships",
    backstory="An AI assistant that specializes in account management and customer relationship building.",
    tools=[enterprise_tools]
)

# Task to manage customer accounts
account_task = Task(
    description="""
    1. Create a new account for TechCorp Inc.
    2. Add John Doe as the primary contact for this account
    3. Create a follow-up task for next week to check on their project status
    """,
    agent=account_manager,
    expected_output="Account, contact, and follow-up task created successfully"
)

crew = Crew(
    agents=[account_manager],
    tasks=[account_task]
)

crew.kickoff()
```

### Consultas SOQL Avan√ßadas e Relat√≥rios

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

data_analyst = Agent(
    role="Sales Data Analyst",
    goal="Generate insights from Salesforce data using SOQL queries",
    backstory="An analytical AI that excels at extracting meaningful insights from CRM data.",
    tools=[enterprise_tools]
)

# Complex task involving SOQL queries and data analysis
analysis_task = Task(
    description="""
    1. Execute a SOQL query to find all opportunities closing this quarter
    2. Search for contacts at companies with opportunities over $100K
    3. Create a summary report of the sales pipeline status
    4. Update high-value opportunities with next steps
    """,
    agent=data_analyst,
    expected_output="Comprehensive sales pipeline analysis with actionable insights"
)

crew = Crew(
    agents=[data_analyst],
    tasks=[analysis_task]
)

crew.kickoff()
```

Esta documenta√ß√£o abrangente cobre todas as ferramentas Salesforce organizadas por funcionalidade, facilitando que os usu√°rios encontrem as opera√ß√µes espec√≠ficas de que necessitam para automa√ß√£o de seu CRM.

### Precisa de ajuda?

<Card title="Precisa de ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para assist√™ncia na configura√ß√£o da integra√ß√£o com Salesforce ou para resolu√ß√£o de problemas.
</Card>


# Integra√ß√£o com Shopify
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/shopify

Gest√£o de e-commerce e loja online com integra√ß√£o do Shopify para CrewAI.

## Vis√£o Geral

Permita que seus agentes gerenciem opera√ß√µes de e-commerce atrav√©s do Shopify. Gerencie clientes, pedidos, produtos, invent√°rio e an√°lises da loja para otimizar sua empresa online com automa√ß√£o alimentada por IA.

## Pr√©-requisitos

Antes de utilizar a integra√ß√£o com o Shopify, certifique-se de que voc√™ possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com uma assinatura ativa
* Uma loja Shopify com permiss√µes administrativas adequadas
* Sua loja Shopify conectada atrav√©s da [p√°gina de Integra√ß√µes](https://app.crewai.com/integrations)

## Ferramentas Dispon√≠veis

### **Gerenciamento de Clientes**

<AccordionGroup>
  <Accordion title="SHOPIFY_GET_CUSTOMERS">
    **Descri√ß√£o:** Recupera uma lista de clientes da sua loja Shopify.

    **Par√¢metros:**

    * `customerIds` (string, opcional): Lista de IDs de clientes separada por v√≠rgula para filtrar (exemplo: "207119551, 207119552")
    * `createdAtMin` (string, opcional): Retorna somente clientes criados ap√≥s esta data (ISO ou timestamp Unix)
    * `createdAtMax` (string, opcional): Retorna somente clientes criados antes desta data (ISO ou timestamp Unix)
    * `updatedAtMin` (string, opcional): Retorna somente clientes atualizados ap√≥s esta data (ISO ou timestamp Unix)
    * `updatedAtMax` (string, opcional): Retorna somente clientes atualizados antes desta data (ISO ou timestamp Unix)
    * `limit` (string, opcional): N√∫mero m√°ximo de clientes a retornar (padr√£o 250)
  </Accordion>

  <Accordion title="SHOPIFY_SEARCH_CUSTOMERS">
    **Descri√ß√£o:** Pesquise por clientes usando crit√©rios de filtragem avan√ßados.

    **Par√¢metros:**

    * `filterFormula` (object, opcional): Filtro avan√ßado em forma normal disjuntiva com operadores espec√≠ficos de campo
    * `limit` (string, opcional): N√∫mero m√°ximo de clientes a retornar (padr√£o 250)
  </Accordion>

  <Accordion title="SHOPIFY_CREATE_CUSTOMER">
    **Descri√ß√£o:** Crie um novo cliente em sua loja Shopify.

    **Par√¢metros:**

    * `firstName` (string, obrigat√≥rio): Primeiro nome do cliente
    * `lastName` (string, obrigat√≥rio): Sobrenome do cliente
    * `email` (string, obrigat√≥rio): Endere√ßo de e-mail do cliente
    * `company` (string, opcional): Nome da empresa
    * `streetAddressLine1` (string, opcional): Endere√ßo
    * `streetAddressLine2` (string, opcional): Complemento do endere√ßo
    * `city` (string, opcional): Cidade
    * `state` (string, opcional): Estado ou c√≥digo da prov√≠ncia
    * `country` (string, opcional): Pa√≠s
    * `zipCode` (string, opcional): CEP
    * `phone` (string, opcional): Telefone
    * `tags` (string, opcional): Tags como array ou lista separada por v√≠rgula
    * `note` (string, opcional): Observa√ß√£o sobre o cliente
    * `sendEmailInvite` (boolean, opcional): Se deve enviar convite por e-mail
    * `metafields` (object, opcional): Metacampos adicionais em formato JSON
  </Accordion>

  <Accordion title="SHOPIFY_UPDATE_CUSTOMER">
    **Descri√ß√£o:** Atualize um cliente existente em sua loja Shopify.

    **Par√¢metros:**

    * `customerId` (string, obrigat√≥rio): O ID do cliente a ser atualizado
    * `firstName` (string, opcional): Primeiro nome do cliente
    * `lastName` (string, opcional): Sobrenome do cliente
    * `email` (string, opcional): Endere√ßo de e-mail do cliente
    * `company` (string, opcional): Nome da empresa
    * `streetAddressLine1` (string, opcional): Endere√ßo
    * `streetAddressLine2` (string, opcional): Complemento do endere√ßo
    * `city` (string, opcional): Cidade
    * `state` (string, opcional): Estado ou c√≥digo da prov√≠ncia
    * `country` (string, opcional): Pa√≠s
    * `zipCode` (string, opcional): CEP
    * `phone` (string, opcional): Telefone
    * `tags` (string, opcional): Tags como array ou lista separada por v√≠rgula
    * `note` (string, opcional): Observa√ß√£o sobre o cliente
    * `sendEmailInvite` (boolean, opcional): Se deve enviar convite por e-mail
    * `metafields` (object, opcional): Metacampos adicionais em formato JSON
  </Accordion>
</AccordionGroup>

### **Gest√£o de Pedidos**

<AccordionGroup>
  <Accordion title="SHOPIFY_GET_ORDERS">
    **Descri√ß√£o:** Recupera uma lista de pedidos da sua loja Shopify.

    **Par√¢metros:**

    * `orderIds` (string, opcional): Lista de IDs de pedidos separada por v√≠rgula para filtrar (exemplo: "450789469, 450789470")
    * `createdAtMin` (string, opcional): Retorna somente pedidos criados ap√≥s esta data (ISO ou timestamp Unix)
    * `createdAtMax` (string, opcional): Retorna somente pedidos criados antes desta data (ISO ou timestamp Unix)
    * `updatedAtMin` (string, opcional): Retorna somente pedidos atualizados ap√≥s esta data (ISO ou timestamp Unix)
    * `updatedAtMax` (string, opcional): Retorna somente pedidos atualizados antes desta data (ISO ou timestamp Unix)
    * `limit` (string, opcional): N√∫mero m√°ximo de pedidos a retornar (padr√£o 250)
  </Accordion>

  <Accordion title="SHOPIFY_CREATE_ORDER">
    **Descri√ß√£o:** Crie um novo pedido em sua loja Shopify.

    **Par√¢metros:**

    * `email` (string, obrigat√≥rio): Endere√ßo de e-mail do cliente
    * `lineItems` (object, obrigat√≥rio): Itens do pedido em formato JSON com t√≠tulo, pre√ßo, quantidade e variant\_id
    * `sendReceipt` (boolean, opcional): Se deve enviar recibo do pedido
    * `fulfillmentStatus` (string, opcional): Status de atendimento - Op√ß√µes: fulfilled, null, partial, restocked
    * `financialStatus` (string, opcional): Status financeiro - Op√ß√µes: pending, authorized, partially\_paid, paid, partially\_refunded, refunded, voided
    * `inventoryBehaviour` (string, opcional): Comportamento de invent√°rio - Op√ß√µes: bypass, decrement\_ignoring\_policy, decrement\_obeying\_policy
    * `note` (string, opcional): Observa√ß√£o do pedido
  </Accordion>

  <Accordion title="SHOPIFY_UPDATE_ORDER">
    **Descri√ß√£o:** Atualize um pedido existente em sua loja Shopify.

    **Par√¢metros:**

    * `orderId` (string, obrigat√≥rio): O ID do pedido a ser atualizado
    * `email` (string, opcional): Endere√ßo de e-mail do cliente
    * `lineItems` (object, opcional): Itens do pedido atualizados em formato JSON
    * `sendReceipt` (boolean, opcional): Se deve enviar recibo do pedido
    * `fulfillmentStatus` (string, opcional): Status de atendimento - Op√ß√µes: fulfilled, null, partial, restocked
    * `financialStatus` (string, opcional): Status financeiro - Op√ß√µes: pending, authorized, partially\_paid, paid, partially\_refunded, refunded, voided
    * `inventoryBehaviour` (string, opcional): Comportamento de invent√°rio - Op√ß√µes: bypass, decrement\_ignoring\_policy, decrement\_obeying\_policy
    * `note` (string, opcional): Observa√ß√£o do pedido
  </Accordion>

  <Accordion title="SHOPIFY_GET_ABANDONED_CARTS">
    **Descri√ß√£o:** Recupera carrinhos abandonados da sua loja Shopify.

    **Par√¢metros:**

    * `createdWithInLast` (string, opcional): Restringe os resultados para checkouts criados dentro do per√≠odo especificado
    * `createdAfterId` (string, opcional): Restringe os resultados ap√≥s o ID especificado
    * `status` (string, opcional): Mostra checkouts com o status especificado - Op√ß√µes: open, closed (padr√£o open)
    * `createdAtMin` (string, opcional): Retorna somente carrinhos criados ap√≥s esta data (ISO ou timestamp Unix)
    * `createdAtMax` (string, opcional): Retorna somente carrinhos criados antes desta data (ISO ou timestamp Unix)
    * `limit` (string, opcional): N√∫mero m√°ximo de carrinhos a retornar (padr√£o 250)
  </Accordion>
</AccordionGroup>

### **Gest√£o de Produtos (REST API)**

<AccordionGroup>
  <Accordion title="SHOPIFY_GET_PRODUCTS">
    **Descri√ß√£o:** Recupera uma lista de produtos da sua loja Shopify utilizando a REST API.

    **Par√¢metros:**

    * `productIds` (string, opcional): Lista de IDs de produtos separada por v√≠rgula para filtrar (exemplo: "632910392, 632910393")
    * `title` (string, opcional): Filtrar pelo t√≠tulo do produto
    * `productType` (string, opcional): Filtrar pelo tipo de produto
    * `vendor` (string, opcional): Filtrar por fornecedor
    * `status` (string, opcional): Filtrar por status - Op√ß√µes: active, archived, draft
    * `createdAtMin` (string, opcional): Retorna somente produtos criados ap√≥s esta data (ISO ou timestamp Unix)
    * `createdAtMax` (string, opcional): Retorna somente produtos criados antes desta data (ISO ou timestamp Unix)
    * `updatedAtMin` (string, opcional): Retorna somente produtos atualizados ap√≥s esta data (ISO ou timestamp Unix)
    * `updatedAtMax` (string, opcional): Retorna somente produtos atualizados antes desta data (ISO ou timestamp Unix)
    * `limit` (string, opcional): N√∫mero m√°ximo de produtos a retornar (padr√£o 250)
  </Accordion>

  <Accordion title="SHOPIFY_CREATE_PRODUCT">
    **Descri√ß√£o:** Crie um novo produto em sua loja Shopify utilizando a REST API.

    **Par√¢metros:**

    * `title` (string, obrigat√≥rio): T√≠tulo do produto
    * `productType` (string, obrigat√≥rio): Tipo/categoria do produto
    * `vendor` (string, obrigat√≥rio): Fornecedor do produto
    * `productDescription` (string, opcional): Descri√ß√£o do produto (aceita texto simples ou HTML)
    * `tags` (string, opcional): Tags do produto como array ou lista separada por v√≠rgula
    * `price` (string, opcional): Pre√ßo do produto
    * `inventoryPolicy` (string, opcional): Pol√≠tica de estoque - Op√ß√µes: deny, continue
    * `imageUrl` (string, opcional): URL da imagem do produto
    * `isPublished` (boolean, opcional): Se o produto est√° publicado
    * `publishToPointToSale` (boolean, opcional): Se deve publicar no ponto de venda
  </Accordion>

  <Accordion title="SHOPIFY_UPDATE_PRODUCT">
    **Descri√ß√£o:** Atualize um produto existente em sua loja Shopify utilizando a REST API.

    **Par√¢metros:**

    * `productId` (string, obrigat√≥rio): O ID do produto a ser atualizado
    * `title` (string, opcional): T√≠tulo do produto
    * `productType` (string, opcional): Tipo/categoria do produto
    * `vendor` (string, opcional): Fornecedor do produto
    * `productDescription` (string, opcional): Descri√ß√£o do produto (aceita texto simples ou HTML)
    * `tags` (string, opcional): Tags do produto como array ou lista separada por v√≠rgula
    * `price` (string, opcional): Pre√ßo do produto
    * `inventoryPolicy` (string, opcional): Pol√≠tica de estoque - Op√ß√µes: deny, continue
    * `imageUrl` (string, opcional): URL da imagem do produto
    * `isPublished` (boolean, opcional): Se o produto est√° publicado
    * `publishToPointToSale` (boolean, opcional): Se deve publicar no ponto de venda
  </Accordion>
</AccordionGroup>

### **Gest√£o de Produtos (GraphQL)**

<AccordionGroup>
  <Accordion title="SHOPIFY_GET_PRODUCTS_GRAPHQL">
    **Descri√ß√£o:** Recupere produtos utilizando filtros avan√ßados do GraphQL.

    **Par√¢metros:**

    * `productFilterFormula` (object, opcional): Filtro avan√ßado em forma normal disjuntiva com suporte a campos como id, title, vendor, status, handle, tag, created\_at, updated\_at, published\_at
  </Accordion>

  <Accordion title="SHOPIFY_CREATE_PRODUCT_GRAPHQL">
    **Descri√ß√£o:** Crie um novo produto utilizando a API GraphQL com suporte aprimorado a m√≠dias.

    **Par√¢metros:**

    * `title` (string, obrigat√≥rio): T√≠tulo do produto
    * `productType` (string, obrigat√≥rio): Tipo/categoria do produto
    * `vendor` (string, obrigat√≥rio): Fornecedor do produto
    * `productDescription` (string, opcional): Descri√ß√£o do produto (aceita texto simples ou HTML)
    * `tags` (string, opcional): Tags do produto como array ou lista separada por v√≠rgula
    * `media` (object, opcional): Objetos de m√≠dia com texto alternativo, tipo de conte√∫do e URL de origem
    * `additionalFields` (object, opcional): Campos adicionais do produto como status, requiresSellingPlan, giftCard
  </Accordion>

  <Accordion title="SHOPIFY_UPDATE_PRODUCT_GRAPHQL">
    **Descri√ß√£o:** Atualize um produto existente utilizando a API GraphQL com suporte aprimorado a m√≠dias.

    **Par√¢metros:**

    * `productId` (string, obrigat√≥rio): O ID GraphQL do produto a ser atualizado (ex.: "gid://shopify/Product/913144112")
    * `title` (string, opcional): T√≠tulo do produto
    * `productType` (string, opcional): Tipo/categoria do produto
    * `vendor` (string, opcional): Fornecedor do produto
    * `productDescription` (string, opcional): Descri√ß√£o do produto (aceita texto simples ou HTML)
    * `tags` (string, opcional): Tags do produto como array ou lista separada por v√≠rgula
    * `media` (object, opcional): Objetos de m√≠dia atualizados com texto alternativo, tipo de conte√∫do e URL de origem
    * `additionalFields` (object, opcional): Campos adicionais do produto como status, requiresSellingPlan, giftCard
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configura√ß√£o B√°sica do Agente Shopify

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Shopify tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Shopify capabilities
shopify_agent = Agent(
    role="E-commerce Manager",
    goal="Manage online store operations and customer relationships efficiently",
    backstory="An AI assistant specialized in e-commerce operations and online store management.",
    tools=[enterprise_tools]
)

# Task to create a new customer
create_customer_task = Task(
    description="Create a new VIP customer Jane Smith with email jane.smith@example.com and phone +1-555-0123",
    agent=shopify_agent,
    expected_output="Customer created successfully with customer ID"
)

# Run the task
crew = Crew(
    agents=[shopify_agent],
    tasks=[create_customer_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Espec√≠ficas do Shopify

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Shopify tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["shopify_create_customer", "shopify_create_order", "shopify_get_products"]
)

store_manager = Agent(
    role="Store Manager",
    goal="Manage customer orders and product catalog",
    backstory="An experienced store manager who handles customer relationships and inventory management.",
    tools=enterprise_tools
)

# Task to manage store operations
store_task = Task(
    description="Create a new customer and process their order for 2 Premium Coffee Mugs",
    agent=store_manager,
    expected_output="Customer created and order processed successfully"
)

crew = Crew(
    agents=[store_manager],
    tasks=[store_task]
)

crew.kickoff()
```

### Gest√£o de Produtos com GraphQL

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

product_manager = Agent(
    role="Product Manager",
    goal="Manage product catalog and inventory with advanced GraphQL capabilities",
    backstory="An AI assistant that specializes in product management and catalog optimization.",
    tools=[enterprise_tools]
)

# Task to manage product catalog
catalog_task = Task(
    description="""
    1. Create a new product "Premium Coffee Mug" from Coffee Co vendor
    2. Add high-quality product images and descriptions
    3. Search for similar products from the same vendor
    4. Update product tags and pricing strategy
    """,
    agent=product_manager,
    expected_output="Product created and catalog optimized successfully"
)

crew = Crew(
    agents=[product_manager],
    tasks=[catalog_task]
)

crew.kickoff()
```

### An√°lise de Pedidos e Clientes

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

analytics_agent = Agent(
    role="E-commerce Analyst",
    goal="Analyze customer behavior and order patterns to optimize store performance",
    backstory="An analytical AI that excels at extracting insights from e-commerce data.",
    tools=[enterprise_tools]
)

# Complex task involving multiple operations
analytics_task = Task(
    description="""
    1. Retrieve recent customer data and order history
    2. Identify abandoned carts from the last 7 days
    3. Analyze product performance and inventory levels
    4. Generate recommendations for customer retention
    """,
    agent=analytics_agent,
    expected_output="Comprehensive e-commerce analytics report with actionable insights"
)

crew = Crew(
    agents=[analytics_agent],
    tasks=[analytics_task]
)

crew.kickoff()
```

### Precisa de Ajuda?

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para assist√™ncia na configura√ß√£o ou resolu√ß√£o de problemas de integra√ß√£o com o Shopify.
</Card>


# Integra√ß√£o com Slack
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/slack

Comunica√ß√£o e colabora√ß√£o em equipe com a integra√ß√£o Slack para CrewAI.

## Vis√£o Geral

Permita que seus agentes gerenciem a comunica√ß√£o da equipe pelo Slack. Envie mensagens, pesquise conversas, gerencie canais e coordene as atividades do time para otimizar os fluxos de colabora√ß√£o com automa√ß√£o impulsionada por IA.

## Pr√©-requisitos

Antes de usar a integra√ß√£o com o Slack, certifique-se de que voc√™ tenha:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com assinatura ativa
* Um workspace do Slack com permiss√µes apropriadas
* Seu workspace do Slack conectado por meio da [p√°gina de Integra√ß√µes](https://app.crewai.com/integrations)

## Ferramentas Dispon√≠veis

### **Gerenciamento de Usu√°rios**

<AccordionGroup>
  <Accordion title="SLACK_LIST_MEMBERS">
    **Descri√ß√£o:** Lista todos os membros de um canal do Slack.

    **Par√¢metros:**

    * Nenhum par√¢metro necess√°rio ‚Äì recupera todos os membros do canal
  </Accordion>

  <Accordion title="SLACK_GET_USER_BY_EMAIL">
    **Descri√ß√£o:** Encontre um usu√°rio no seu workspace do Slack pelo endere√ßo de e-mail.

    **Par√¢metros:**

    * `email` (string, obrigat√≥rio): O endere√ßo de e-mail de um usu√°rio do workspace
  </Accordion>

  <Accordion title="SLACK_GET_USERS_BY_NAME">
    **Descri√ß√£o:** Pesquise usu√°rios pelo nome ou nome de exibi√ß√£o.

    **Par√¢metros:**

    * `name` (string, obrigat√≥rio): Nome real do usu√°rio para a pesquisa
    * `displayName` (string, obrigat√≥rio): Nome de exibi√ß√£o do usu√°rio para a pesquisa
    * `paginationParameters` (object, opcional): Configura√ß√µes de pagina√ß√£o
      * `pageCursor` (string, opcional): Cursor de p√°gina para pagina√ß√£o
  </Accordion>
</AccordionGroup>

### **Gerenciamento de Canais**

<AccordionGroup>
  <Accordion title="SLACK_LIST_CHANNELS">
    **Descri√ß√£o:** Lista todos os canais do seu workspace no Slack.

    **Par√¢metros:**

    * Nenhum par√¢metro necess√°rio ‚Äì recupera todos os canais acess√≠veis
  </Accordion>
</AccordionGroup>

### **Mensagens**

<AccordionGroup>
  <Accordion title="SLACK_SEND_MESSAGE">
    **Descri√ß√£o:** Envie uma mensagem para um canal do Slack.

    **Par√¢metros:**

    * `channel` (string, obrigat√≥rio): Nome ou ID do canal ‚Äì Use as Configura√ß√µes de Workflow do Connect Portal para que usu√°rios selecionem o canal, ou insira o nome do canal para criar um novo
    * `message` (string, obrigat√≥rio): Texto da mensagem a ser enviada
    * `botName` (string, obrigat√≥rio): Nome do bot que enviar√° a mensagem
    * `botIcon` (string, obrigat√≥rio): √çcone do bot ‚Äì Pode ser uma URL de imagem ou um emoji (ex.: ":dog:")
    * `blocks` (object, opcional): JSON do Slack Block Kit para mensagens ricas com anexos e elementos interativos
    * `authenticatedUser` (boolean, opcional): Se verdadeiro, a mensagem aparecer√° como enviada pelo seu usu√°rio autenticado do Slack ao inv√©s do aplicativo (por padr√£o √© falso)
  </Accordion>

  <Accordion title="SLACK_SEND_DIRECT_MESSAGE">
    **Descri√ß√£o:** Envie uma mensagem direta para um usu√°rio espec√≠fico no Slack.

    **Par√¢metros:**

    * `memberId` (string, obrigat√≥rio): ID do usu√°rio destinat√°rio ‚Äì Use as Configura√ß√µes de Workflow do Connect Portal para que usu√°rios selecionem um membro
    * `message` (string, obrigat√≥rio): Texto da mensagem a ser enviada
    * `botName` (string, obrigat√≥rio): Nome do bot que enviar√° a mensagem
    * `botIcon` (string, obrigat√≥rio): √çcone do bot ‚Äì Pode ser uma URL de imagem ou um emoji (ex.: ":dog:")
    * `blocks` (object, opcional): JSON do Slack Block Kit para formata√ß√£o rica com anexos e elementos interativos
    * `authenticatedUser` (boolean, opcional): Se verdadeiro, a mensagem aparecer√° como enviada pelo seu usu√°rio autenticado do Slack (padr√£o √© falso)
  </Accordion>
</AccordionGroup>

### **Pesquisa & Descoberta**

<AccordionGroup>
  <Accordion title="SLACK_SEARCH_MESSAGES">
    **Descri√ß√£o:** Procure por mensagens em todo o seu workspace do Slack.

    **Par√¢metros:**

    * `query` (string, obrigat√≥rio): Consulta de pesquisa usando a sintaxe do Slack para encontrar mensagens que correspondam aos crit√©rios especificados

    **Exemplos de Consultas de Pesquisa:**

    * `"project update"` ‚Äì Busca mensagens contendo "project update"
    * `from:@john in:#general` ‚Äì Busca mensagens do John no canal #general
    * `has:link after:2023-01-01` ‚Äì Busca mensagens com links ap√≥s 1¬∫ de janeiro de 2023
    * `in:@channel before:yesterday` ‚Äì Busca mensagens em um canal espec√≠fico antes de ontem
  </Accordion>
</AccordionGroup>

## Integra√ß√£o com Block Kit

O Block Kit do Slack permite criar mensagens ricas e interativas. Veja alguns exemplos de como usar o par√¢metro `blocks`:

### Texto Simples com Anexo

```json
[
  {
    "text": "I am a test message",
    "attachments": [
      {
        "text": "And here's an attachment!"
      }
    ]
  }
]
```

### Formata√ß√£o Rica com Se√ß√µes

```json
[
  {
    "type": "section",
    "text": {
      "type": "mrkdwn",
      "text": "*Project Update*\nStatus: ‚úÖ Complete"
    }
  },
  {
    "type": "divider"
  },
  {
    "type": "section",
    "text": {
      "type": "plain_text",
      "text": "All tasks have been completed successfully."
    }
  }
]
```

## Exemplos de Uso

### Configura√ß√£o B√°sica de Agente Slack

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Slack tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Slack capabilities
slack_agent = Agent(
    role="Team Communication Manager",
    goal="Facilitate team communication and coordinate collaboration efficiently",
    backstory="An AI assistant specialized in team communication and workspace coordination.",
    tools=[enterprise_tools]
)

# Task to send project updates
update_task = Task(
    description="Send a project status update to the #general channel with current progress",
    agent=slack_agent,
    expected_output="Project update message sent successfully to team channel"
)

# Run the task
crew = Crew(
    agents=[slack_agent],
    tasks=[update_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Espec√≠ficas do Slack

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Slack tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["slack_send_message", "slack_send_direct_message", "slack_search_messages"]
)

communication_manager = Agent(
    role="Communication Coordinator",
    goal="Manage team communications and ensure important messages reach the right people",
    backstory="An experienced communication coordinator who handles team messaging and notifications.",
    tools=enterprise_tools
)

# Task to coordinate team communication
coordination_task = Task(
    description="Send task completion notifications to team members and update project channels",
    agent=communication_manager,
    expected_output="Team notifications sent and project channels updated successfully"
)

crew = Crew(
    agents=[communication_manager],
    tasks=[coordination_task]
)

crew.kickoff()
```

### Mensagens Avan√ßadas com Block Kit

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

notification_agent = Agent(
    role="Notification Manager",
    goal="Create rich, interactive notifications and manage workspace communication",
    backstory="An AI assistant that specializes in creating engaging team notifications and updates.",
    tools=[enterprise_tools]
)

# Task to send rich notifications
notification_task = Task(
    description="""
    1. Send a formatted project completion message to #general with progress charts
    2. Send direct messages to team leads with task summaries
    3. Create interactive notification with action buttons for team feedback
    """,
    agent=notification_agent,
    expected_output="Rich notifications sent with interactive elements and formatted content"
)

crew = Crew(
    agents=[notification_agent],
    tasks=[notification_task]
)

crew.kickoff()
```

### Pesquisa de Mensagens e An√°lises

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

analytics_agent = Agent(
    role="Communication Analyst",
    goal="Analyze team communication patterns and extract insights from conversations",
    backstory="An analytical AI that excels at understanding team dynamics through communication data.",
    tools=[enterprise_tools]
)

# Complex task involving search and analysis
analysis_task = Task(
    description="""
    1. Search for recent project-related messages across all channels
    2. Find users by email to identify team members
    3. Analyze communication patterns and response times
    4. Generate weekly team communication summary
    """,
    agent=analytics_agent,
    expected_output="Comprehensive communication analysis with team insights and recommendations"
)

crew = Crew(
    agents=[analytics_agent],
    tasks=[analysis_task]
)

crew.kickoff()
```

## Fale com o Suporte

<Card title="Precisa de Ajuda?" icon="headset" href="mailto:support@crewai.com">
  Entre em contato com nossa equipe de suporte para obter ajuda na configura√ß√£o ou solu√ß√£o de problemas da integra√ß√£o com o Slack.
</Card>


# Integra√ß√£o Stripe
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/stripe

Processamento de pagamentos e gerenciamento de assinaturas com integra√ß√£o Stripe para CrewAI.

## Vis√£o Geral

Permita que seus agentes gerenciem pagamentos, assinaturas e faturamento de clientes atrav√©s do Stripe. Gerencie dados de clientes, processe assinaturas, gerencie produtos e acompanhe transa√ß√µes financeiras para otimizar seus fluxos de pagamento com automa√ß√£o impulsionada por IA.

## Pr√©-requisitos

Antes de usar a integra√ß√£o com o Stripe, certifique-se de que voc√™ tem:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com uma assinatura ativa
* Uma conta Stripe com permiss√µes apropriadas de API
* Sua conta Stripe conectada atrav√©s da [p√°gina de Integra√ß√µes](https://app.crewai.com/integrations)

## Ferramentas Dispon√≠veis

### **Gerenciamento de Clientes**

<AccordionGroup>
  <Accordion title="STRIPE_CREATE_CUSTOMER">
    **Descri√ß√£o:** Crie um novo cliente em sua conta Stripe.

    **Par√¢metros:**

    * `emailCreateCustomer` (string, obrigat√≥rio): Endere√ßo de e-mail do cliente
    * `name` (string, opcional): Nome completo do cliente
    * `description` (string, opcional): Descri√ß√£o do cliente para refer√™ncia interna
    * `metadataCreateCustomer` (objeto, opcional): Metadados adicionais como pares chave-valor (exemplo: `{"field1": 1, "field2": 2}`)
  </Accordion>

  <Accordion title="STRIPE_GET_CUSTOMER_BY_ID">
    **Descri√ß√£o:** Recupera um cliente espec√≠fico pelo ID do cliente Stripe.

    **Par√¢metros:**

    * `idGetCustomer` (string, obrigat√≥rio): O ID do cliente Stripe a ser recuperado
  </Accordion>

  <Accordion title="STRIPE_GET_CUSTOMERS">
    **Descri√ß√£o:** Recupera uma lista de clientes com filtragem opcional.

    **Par√¢metros:**

    * `emailGetCustomers` (string, opcional): Filtra clientes pelo endere√ßo de e-mail
    * `createdAfter` (string, opcional): Filtra clientes criados ap√≥s esta data (timestamp Unix)
    * `createdBefore` (string, opcional): Filtra clientes criados antes desta data (timestamp Unix)
    * `limitGetCustomers` (string, opcional): N√∫mero m√°ximo de clientes a retornar (padr√£o: 10)
  </Accordion>

  <Accordion title="STRIPE_UPDATE_CUSTOMER">
    **Descri√ß√£o:** Atualiza as informa√ß√µes de um cliente existente.

    **Par√¢metros:**

    * `customerId` (string, obrigat√≥rio): O ID do cliente a ser atualizado
    * `emailUpdateCustomer` (string, opcional): Novo endere√ßo de e-mail
    * `name` (string, opcional): Novo nome do cliente
    * `description` (string, opcional): Nova descri√ß√£o do cliente
    * `metadataUpdateCustomer` (objeto, opcional): Novos metadados como pares chave-valor
  </Accordion>
</AccordionGroup>

### **Gerenciamento de Assinaturas**

<AccordionGroup>
  <Accordion title="STRIPE_CREATE_SUBSCRIPTION">
    **Descri√ß√£o:** Cria uma nova assinatura para um cliente.

    **Par√¢metros:**

    * `customerIdCreateSubscription` (string, obrigat√≥rio): O ID do cliente para o qual a assinatura ser√° criada
    * `plan` (string, obrigat√≥rio): O ID do plano para assinatura - Use as Configura√ß√µes do Workflow do Portal Connect para permitir que usu√°rios selecionem um plano
    * `metadataCreateSubscription` (objeto, opcional): Metadados adicionais para a assinatura
  </Accordion>

  <Accordion title="STRIPE_GET_SUBSCRIPTIONS">
    **Descri√ß√£o:** Recupera assinaturas com filtragem opcional.

    **Par√¢metros:**

    * `customerIdGetSubscriptions` (string, opcional): Filtra assinaturas por ID do cliente
    * `subscriptionStatus` (string, opcional): Filtra por status da assinatura - Op√ß√µes: incomplete, incomplete\_expired, trialing, active, past\_due, canceled, unpaid
    * `limitGetSubscriptions` (string, opcional): N√∫mero m√°ximo de assinaturas a retornar (padr√£o: 10)
  </Accordion>
</AccordionGroup>

### **Gerenciamento de Produtos**

<AccordionGroup>
  <Accordion title="STRIPE_CREATE_PRODUCT">
    **Descri√ß√£o:** Cria um novo produto no seu cat√°logo Stripe.

    **Par√¢metros:**

    * `productName` (string, obrigat√≥rio): Nome do produto
    * `description` (string, opcional): Descri√ß√£o do produto
    * `metadataProduct` (objeto, opcional): Metadados adicionais do produto como pares chave-valor
  </Accordion>

  <Accordion title="STRIPE_GET_PRODUCT_BY_ID">
    **Descri√ß√£o:** Recupera um produto espec√≠fico pelo ID do produto Stripe.

    **Par√¢metros:**

    * `productId` (string, obrigat√≥rio): O ID do produto Stripe a ser recuperado
  </Accordion>

  <Accordion title="STRIPE_GET_PRODUCTS">
    **Descri√ß√£o:** Recupera uma lista de produtos com filtragem opcional.

    **Par√¢metros:**

    * `createdAfter` (string, opcional): Filtra produtos criados ap√≥s esta data (timestamp Unix)
    * `createdBefore` (string, opcional): Filtra produtos criados antes desta data (timestamp Unix)
    * `limitGetProducts` (string, opcional): N√∫mero m√°ximo de produtos a retornar (padr√£o: 10)
  </Accordion>
</AccordionGroup>

### **Opera√ß√µes Financeiras**

<AccordionGroup>
  <Accordion title="STRIPE_GET_BALANCE_TRANSACTIONS">
    **Descri√ß√£o:** Recupera transa√ß√µes de saldo da sua conta Stripe.

    **Par√¢metros:**

    * `balanceTransactionType` (string, opcional): Filtra por tipo de transa√ß√£o - Op√ß√µes: charge, refund, payment, payment\_refund
    * `paginationParameters` (objeto, opcional): Configura√ß√µes de pagina√ß√£o
      * `pageCursor` (string, opcional): Cursor da p√°gina para pagina√ß√£o
  </Accordion>

  <Accordion title="STRIPE_GET_PLANS">
    **Descri√ß√£o:** Recupera planos de assinatura da sua conta Stripe.

    **Par√¢metros:**

    * `isPlanActive` (boolean, opcional): Filtra por status do plano - true para planos ativos, false para inativos
    * `paginationParameters` (objeto, opcional): Configura√ß√µes de pagina√ß√£o
      * `pageCursor` (string, opcional): Cursor da p√°gina para pagina√ß√£o
  </Accordion>
</AccordionGroup>

## Exemplos de Uso

### Configura√ß√£o B√°sica do Agente Stripe

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Get enterprise tools (Stripe tools will be included)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Create an agent with Stripe capabilities
stripe_agent = Agent(
    role="Payment Manager",
    goal="Manage customer payments, subscriptions, and billing operations efficiently",
    backstory="An AI assistant specialized in payment processing and subscription management.",
    tools=[enterprise_tools]
)

# Task to create a new customer
create_customer_task = Task(
    description="Create a new premium customer John Doe with email john.doe@example.com",
    agent=stripe_agent,
    expected_output="Customer created successfully with customer ID"
)

# Run the task
crew = Crew(
    agents=[stripe_agent],
    tasks=[create_customer_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Stripe Espec√≠ficas

```python
from crewai_tools import CrewaiEnterpriseTools

# Get only specific Stripe tools
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["stripe_create_customer", "stripe_create_subscription", "stripe_get_balance_transactions"]
)

billing_manager = Agent(
    role="Billing Manager",
    goal="Handle customer billing, subscriptions, and payment processing",
    backstory="An experienced billing manager who handles subscription lifecycle and payment operations.",
    tools=enterprise_tools
)

# Task to manage billing operations
billing_task = Task(
    description="Create a new customer and set up their premium subscription plan",
    agent=billing_manager,
    expected_output="Customer created and subscription activated successfully"
)

crew = Crew(
    agents=[billing_manager],
    tasks=[billing_task]
)

crew.kickoff()
```

### Gerenciamento de Assinaturas

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

subscription_manager = Agent(
    role="Subscription Manager",
    goal="Manage customer subscriptions and optimize recurring revenue",
    backstory="An AI assistant that specializes in subscription lifecycle management and customer retention.",
    tools=[enterprise_tools]
)

# Task to manage subscription operations
subscription_task = Task(
    description="""
    1. Create a new product "Premium Service Plan" with advanced features
    2. Set up subscription plans with different tiers
    3. Create customers and assign them to appropriate plans
    4. Monitor subscription status and handle billing issues
    """,
    agent=subscription_manager,
    expected_output="Subscription management system configured with customers and active plans"
)

crew = Crew(
    agents=[subscription_manager],
    tasks=[subscription_task]
)

crew.kickoff()
```

### An√°lises e Relat√≥rios Financeiros

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

financial_analyst = Agent(
    role="Financial Analyst",
    goal="Analyze payment data and generate financial insights",
    backstory="An analytical AI that excels at extracting insights from payment and subscription data.",
    tools=[enterprise_tools]
)

# Complex task involving financial analysis
analytics_task = Task(
    description="""
    1. Retrieve balance transactions for the current month
    2. Analyze customer payment patterns and subscription trends
    3. Identify high-value customers and subscription performance
    4. Generate monthly financial performance report
    """,
    agent=financial_analyst,
    expected_output="Comprehensive financial analysis with payment insights and recommendations"
)

crew = Crew(
    agents=[financial_analyst],
    tasks=[analytics_task]
)

crew.kickoff()
```

## Refer√™ncia de Status de Assinatura

Compreendendo os status de assinaturas:

* **incomplete** - A assinatura requer m√©todo de pagamento ou confirma√ß√£o de pagamento
* **incomplete\_expired** - A assinatura expirou antes da confirma√ß√£o do pagamento
* **trialing** - A assinatura est√° em per√≠odo de avalia√ß√£o
* **active** - A assinatura est√° ativa e em dia
* **past\_due** - O pagamento falhou mas a assinatura ainda est√° ativa
* **canceled** - A assinatura foi cancelada
* **unpaid** - O pagamento falhou e a assinatura n√£o est√° mais ativa

## Uso de Metadados

Os metadados permitem que voc√™ armazene informa√ß√µes adicionais sobre clientes, assinaturas e produtos:

```json
{
  "customer_segment": "enterprise",
  "acquisition_source": "google_ads",
  "lifetime_value": "high",
  "custom_field_1": "value1"
}
```

Esta integra√ß√£o permite uma automa√ß√£o abrangente do gerenciamento de pagamentos e assinaturas, possibilitando que seus agentes de IA administrem opera√ß√µes de faturamento perfeitamente dentro do seu ecossistema Stripe.


# Integra√ß√£o com Zendesk
Source: https://docs.crewai.com/pt-BR/enterprise/integrations/zendesk

Gest√£o de suporte ao cliente e helpdesk com integra√ß√£o Zendesk para CrewAI.

## Vis√£o Geral

Permita que seus agentes gerenciem opera√ß√µes de suporte ao cliente atrav√©s do Zendesk. Crie e atualize tickets, gerencie usu√°rios, monitore m√©tricas de suporte e otimize seus fluxos de atendimento ao cliente com automa√ß√£o impulsionada por IA.

## Pr√©-requisitos

Antes de usar a integra√ß√£o com o Zendesk, certifique-se de que voc√™ possui:

* Uma conta [CrewAI Enterprise](https://app.crewai.com) com uma assinatura ativa
* Uma conta Zendesk com permiss√µes apropriadas de API
* Sua conta Zendesk conectada atrav√©s da [p√°gina de Integra√ß√µes](https://app.crewai.com/integrations)

## Ferramentas Dispon√≠veis

### **Gerenciamento de Tickets**

<AccordionGroup>
  <Accordion title="ZENDESK_CREATE_TICKET">
    **Descri√ß√£o:** Crie um novo ticket de suporte no Zendesk.

    **Par√¢metros:**

    * `ticketSubject` (string, obrigat√≥rio): Assunto do ticket (ex.: "Socorro, minha impressora est√° pegando fogo!")
    * `ticketDescription` (string, obrigat√≥rio): Primeiro coment√°rio que aparece no ticket (ex.: "A fuma√ßa √© muito colorida.")
    * `requesterName` (string, obrigat√≥rio): Nome do usu√°rio solicitando suporte (ex.: "Jane Cliente")
    * `requesterEmail` (string, obrigat√≥rio): E-mail do solicitante do suporte (ex.: "[jane@example.com](mailto:jane@example.com)")
    * `assigneeId` (string, opcional): ID do agente Zendesk atribu√≠do ao ticket - Use as Configura√ß√µes de Fluxo de Trabalho do Portal Connect para permitir a sele√ß√£o do respons√°vel
    * `ticketType` (string, opcional): Tipo de ticket - Op√ß√µes: problem, incident, question, task
    * `ticketPriority` (string, opcional): N√≠vel de prioridade - Op√ß√µes: urgent, high, normal, low
    * `ticketStatus` (string, opcional): Status do ticket - Op√ß√µes: new, open, pending, hold, solved, closed
    * `ticketDueAt` (string, opcional): Data de vencimento para tickets do tipo tarefa (timestamp ISO 8601)
    * `ticketTags` (string, opcional): Array de tags a aplicar (ex.: `["enterprise", "outra_tag"]`)
    * `ticketExternalId` (string, opcional): ID externo para vincular tickets a registros locais
    * `ticketCustomFields` (object, opcional): Valores de campos personalizados em formato JSON
  </Accordion>

  <Accordion title="ZENDESK_UPDATE_TICKET">
    **Descri√ß√£o:** Atualize um ticket de suporte existente no Zendesk.

    **Par√¢metros:**

    * `ticketId` (string, obrigat√≥rio): ID do ticket a ser atualizado (ex.: "35436")
    * `ticketSubject` (string, opcional): Assunto atualizado do ticket
    * `requesterName` (string, obrigat√≥rio): Nome do solicitante deste ticket
    * `requesterEmail` (string, obrigat√≥rio): E-mail do solicitante deste ticket
    * `assigneeId` (string, opcional): ID atualizado do respons√°vel - Use as Configura√ß√µes de Fluxo de Trabalho do Portal Connect
    * `ticketType` (string, opcional): Tipo atualizado - Op√ß√µes: problem, incident, question, task
    * `ticketPriority` (string, opcional): Prioridade atualizada - Op√ß√µes: urgent, high, normal, low
    * `ticketStatus` (string, opcional): Status atualizado - Op√ß√µes: new, open, pending, hold, solved, closed
    * `ticketDueAt` (string, opcional): Nova data de vencimento (timestamp ISO 8601)
    * `ticketTags` (string, opcional): Array de tags atualizadas
    * `ticketExternalId` (string, opcional): Novo ID externo
    * `ticketCustomFields` (object, opcional): Valores atualizados dos campos personalizados
  </Accordion>

  <Accordion title="ZENDESK_GET_TICKET_BY_ID">
    **Descri√ß√£o:** Recupere um ticket espec√≠fico pelo ID.

    **Par√¢metros:**

    * `ticketId` (string, obrigat√≥rio): ID do ticket a ser recuperado (ex.: "35436")
  </Accordion>

  <Accordion title="ZENDESK_ADD_COMMENT_TO_TICKET">
    **Descri√ß√£o:** Adicione um coment√°rio ou nota interna a um ticket existente.

    **Par√¢metros:**

    * `ticketId` (string, obrigat√≥rio): ID do ticket para adicionar o coment√°rio (ex.: "35436")
    * `commentBody` (string, obrigat√≥rio): Mensagem do coment√°rio (aceita texto simples ou HTML, ex.: "Obrigado pela sua ajuda!")
    * `isInternalNote` (boolean, opcional): Defina como verdadeiro para notas internas ao inv√©s de respostas p√∫blicas (padr√£o √© falso)
    * `isPublic` (boolean, opcional): Verdadeiro para coment√°rios p√∫blicos, falso para notas internas
  </Accordion>

  <Accordion title="ZENDESK_SEARCH_TICKETS">
    **Descri√ß√£o:** Busque tickets usando diversos filtros e crit√©rios.

    **Par√¢metros:**

    * `ticketSubject` (string, opcional): Filtrar pelo texto no assunto do ticket
    * `ticketDescription` (string, opcional): Filtrar por texto na descri√ß√£o e coment√°rios do ticket
    * `ticketStatus` (string, opcional): Filtrar por status - Op√ß√µes: new, open, pending, hold, solved, closed
    * `ticketType` (string, opcional): Filtrar por tipo - Op√ß√µes: problem, incident, question, task, no\_type
    * `ticketPriority` (string, opcional): Filtrar por prioridade - Op√ß√µes: urgent, high, normal, low, no\_priority
    * `requesterId` (string, opcional): Filtrar por ID do solicitante
    * `assigneeId` (string, opcional): Filtrar pelo ID do agente respons√°vel
    * `recipientEmail` (string, opcional): Filtrar pelo e-mail do destinat√°rio original
    * `ticketTags` (string, opcional): Filtrar por tags do ticket
    * `ticketExternalId` (string, opcional): Filtrar por ID externo
    * `createdDate` (object, opcional): Filtrar por data de cria√ß√£o com operador (EQUALS, LESS\_THAN\_EQUALS, GREATER\_THAN\_EQUALS) e valor
    * `updatedDate` (object, opcional): Filtrar por data de atualiza√ß√£o com operador e valor
    * `dueDate` (object, opcional): Filtrar por data de vencimento com operador e valor
    * `sort_by` (string, opcional): Campo de ordena√ß√£o - Op√ß√µes: created\_at, updated\_at, priority, status, ticket\_type
    * `sort_order` (string, opcional): Dire√ß√£o da ordena√ß√£o - Op√ß√µes: asc, desc
  </Accordion>
</AccordionGroup>

### **Gerenciamento de Usu√°rios**

<AccordionGroup>
  <Accordion title="ZENDESK_CREATE_USER">
    **Descri√ß√£o:** Crie um novo usu√°rio no Zendesk.

    **Par√¢metros:**

    * `name` (string, obrigat√≥rio): Nome completo do usu√°rio
    * `email` (string, opcional): E-mail do usu√°rio (ex.: "[jane@example.com](mailto:jane@example.com)")
    * `phone` (string, opcional): Telefone do usu√°rio
    * `role` (string, opcional): Papel do usu√°rio - Op√ß√µes: admin, agent, end-user
    * `externalId` (string, opcional): Identificador √∫nico de outro sistema
    * `details` (string, opcional): Detalhes adicionais do usu√°rio
    * `notes` (string, opcional): Notas internas sobre o usu√°rio
  </Accordion>

  <Accordion title="ZENDESK_UPDATE_USER">
    **Descri√ß√£o:** Atualize informa√ß√µes de um usu√°rio existente.

    **Par√¢metros:**

    * `userId` (string, obrigat√≥rio): ID do usu√°rio a ser atualizado
    * `name` (string, opcional): Nome atualizado do usu√°rio
    * `email` (string, opcional): Novo e-mail (adicionado como e-mail secund√°rio na atualiza√ß√£o)
    * `phone` (string, opcional): Novo telefone
    * `role` (string, opcional): Novo papel - Op√ß√µes: admin, agent, end-user
    * `externalId` (string, opcional): Novo ID externo
    * `details` (string, opcional): Novos detalhes do usu√°rio
    * `notes` (string, opcional): Novas notas internas
  </Accordion>

  <Accordion title="ZENDESK_GET_USER_BY_ID">
    **Descri√ß√£o:** Recupere um usu√°rio espec√≠fico pelo ID.

    **Par√¢metros:**

    * `userId` (string, obrigat√≥rio): ID do usu√°rio a ser recuperado
  </Accordion>

  <Accordion title="ZENDESK_SEARCH_USERS">
    **Descri√ß√£o:** Busque usu√°rios utilizando v√°rios crit√©rios.

    **Par√¢metros:**

    * `name` (string, opcional): Filtrar por nome do usu√°rio
    * `email` (string, opcional): Filtrar por e-mail do usu√°rio (ex.: "[jane@example.com](mailto:jane@example.com)")
    * `role` (string, opcional): Filtrar por papel - Op√ß√µes: admin, agent, end-user
    * `externalId` (string, opcional): Filtrar por ID externo
    * `sort_by` (string, opcional): Campo de ordena√ß√£o - Op√ß√µes: created\_at, updated\_at
    * `sort_order` (string, opcional): Dire√ß√£o de ordena√ß√£o - Op√ß√µes: asc, desc
  </Accordion>
</AccordionGroup>

### **Ferramentas Administrativas**

<AccordionGroup>
  <Accordion title="ZENDESK_GET_TICKET_FIELDS">
    **Descri√ß√£o:** Recupere todos os campos padr√£o e personalizados dispon√≠veis para tickets.

    **Par√¢metros:**

    * `paginationParameters` (object, opcional): Configura√ß√µes de pagina√ß√£o
      * `pageCursor` (string, opcional): Cursor de p√°gina para pagina√ß√£o
  </Accordion>

  <Accordion title="ZENDESK_GET_TICKET_AUDITS">
    **Descri√ß√£o:** Obtenha registros de auditoria (hist√≥rico somente leitura) dos tickets.

    **Par√¢metros:**

    * `ticketId` (string, opcional): Obtenha auditorias para um ticket espec√≠fico (se vazio, recupera auditorias de todos os tickets n√£o arquivados, ex.: "1234")
    * `paginationParameters` (object, opcional): Configura√ß√µes de pagina√ß√£o
      * `pageCursor` (string, opcional): Cursor de p√°gina para pagina√ß√£o
  </Accordion>
</AccordionGroup>

## Campos Personalizados

Campos personalizados permitem armazenar informa√ß√µes adicionais espec√≠ficas para sua organiza√ß√£o:

```json
[
  { "id": 27642, "value": "745" },
  { "id": 27648, "value": "yes" }
]
```

## N√≠veis de Prioridade dos Tickets

Compreendendo os n√≠veis de prioridade:

* **urgent** - Quest√µes cr√≠ticas que exigem aten√ß√£o imediata
* **high** - Quest√µes importantes que devem ser tratadas rapidamente
* **normal** - Prioridade padr√£o para a maioria dos tickets
* **low** - Quest√µes menores que podem ser tratadas quando conveniente

## Fluxo de Status dos Tickets

Progresso padr√£o de status dos tickets:

* **new** - Rec√©m-criado, ainda n√£o atribu√≠do
* **open** - Em andamento
* **pending** - Aguardando resposta do cliente ou a√ß√£o externa
* **hold** - Pausa tempor√°ria
* **solved** - Problema resolvido, aguardando confirma√ß√£o do cliente
* **closed** - Ticket finalizado e fechado

## Exemplos de Uso

### Configura√ß√£o B√°sica de Agente Zendesk

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

# Obtenha as ferramentas enterprise (as ferramentas Zendesk ser√£o inclu√≠das)
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

# Crie um agente com capacidades Zendesk
zendesk_agent = Agent(
    role="Gerente de Suporte",
    goal="Gerenciar tickets de suporte ao cliente e oferecer excelente atendimento",
    backstory="Um assistente de IA especializado em opera√ß√µes de suporte ao cliente e gerenciamento de tickets.",
    tools=[enterprise_tools]
)

# Tarefa para criar um novo ticket de suporte
create_ticket_task = Task(
    description="Crie um ticket de suporte de alta prioridade para John Smith que n√£o consegue acessar sua conta ap√≥s redefinir a senha",
    agent=zendesk_agent,
    expected_output="Ticket de suporte criado com sucesso com o ID do ticket"
)

# Execute a tarefa
crew = Crew(
    agents=[zendesk_agent],
    tasks=[create_ticket_task]
)

crew.kickoff()
```

### Filtrando Ferramentas Zendesk Espec√≠ficas

```python
from crewai_tools import CrewaiEnterpriseTools

# Obtenha apenas ferramentas Zendesk espec√≠ficas
enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token",
    actions_list=["zendesk_create_ticket", "zendesk_update_ticket", "zendesk_add_comment_to_ticket"]
)

support_agent = Agent(
    role="Agente de Suporte ao Cliente",
    goal="Atender consultas de clientes e resolver issues de suporte de forma eficiente",
    backstory="Um agente de suporte experiente que se especializa em resolu√ß√£o de tickets e comunica√ß√£o com clientes.",
    tools=enterprise_tools
)

# Tarefa para gerenciar o fluxo de suporte
support_task = Task(
    description="Crie um ticket para problemas de login, adicione coment√°rios de troubleshooting e atualize o status para resolvido",
    agent=support_agent,
    expected_output="Ticket de suporte gerenciado atrav√©s de todo o fluxo de resolu√ß√£o"
)

crew = Crew(
    agents=[support_agent],
    tasks=[support_task]
)

crew.kickoff()
```

### Gerenciamento Avan√ßado de Tickets

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

ticket_manager = Agent(
    role="Gerente de Tickets",
    goal="Gerenciar fluxos de tickets de suporte e garantir resolu√ß√£o tempestiva",
    backstory="Um assistente de IA que se especializa em triagem de tickets de suporte e otimiza√ß√£o de fluxos de trabalho.",
    tools=[enterprise_tools]
)

# Tarefa para gerenciar o ciclo de vida do ticket
ticket_workflow = Task(
    description="""
    1. Crie um novo ticket de suporte para problemas de acesso √† conta
    2. Adicione notas internas com as etapas de troubleshooting
    3. Atualize a prioridade do ticket de acordo com o n√≠vel do cliente
    4. Adicione coment√°rios de resolu√ß√£o e feche o ticket
    """,
    agent=ticket_manager,
    expected_output="Ciclo de vida completo do ticket gerenciado da cria√ß√£o √† resolu√ß√£o"
)

crew = Crew(
    agents=[ticket_manager],
    tasks=[ticket_workflow]
)

crew.kickoff()
```

### An√°lise e Relat√≥rios de Suporte

```python
from crewai import Agent, Task, Crew
from crewai_tools import CrewaiEnterpriseTools

enterprise_tools = CrewaiEnterpriseTools(
    enterprise_token="your_enterprise_token"
)

support_analyst = Agent(
    role="Analista de Suporte",
    goal="Analisar m√©tricas de suporte e gerar insights para desempenho da equipe",
    backstory="Um IA anal√≠tico que se destaca na extra√ß√£o de insights a partir de dados de suporte e padr√µes de tickets.",
    tools=[enterprise_tools]
)

# Tarefa complexa envolvendo an√°lise e gera√ß√£o de relat√≥rios
analytics_task = Task(
    description="""
    1. Busque todos os tickets abertos nos √∫ltimos 30 dias
    2. Analise tempos de resolu√ß√£o dos tickets e satisfa√ß√£o do cliente
    3. Identifique problemas comuns e padr√µes de suporte
    4. Gere relat√≥rio semanal de desempenho do suporte
    """,
    agent=support_analyst,
    expected_output="Relat√≥rio anal√≠tico abrangente de suporte com insights de desempenho e recomenda√ß√µes"
)

crew = Crew(
    agents=[support_analyst],
    tasks=[analytics_task]
)

crew.kickoff()
```


# CrewAI Enterprise
Source: https://docs.crewai.com/pt-BR/enterprise/introduction

Implemente, monitore e escale seus fluxos de trabalho de agentes de IA

## Introdu√ß√£o

CrewAI Enterprise fornece uma plataforma para implementar, monitorar e escalar seus crews e agentes em um ambiente de produ√ß√£o.

<Frame>
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crewai-enterprise-dashboard.png" alt="CrewAI Enterprise Dashboard" />
</Frame>

CrewAI Enterprise expande o poder do framework open-source com funcionalidades projetadas para implanta√ß√µes em produ√ß√£o, colabora√ß√£o e escalabilidade. Implemente seus crews em uma infraestrutura gerenciada e monitore sua execu√ß√£o em tempo real.

## Principais Funcionalidades

<CardGroup cols={2}>
  <Card title="Implanta√ß√£o de Crews" icon="rocket">
    Implemente seus crews em uma infraestrutura gerenciada com apenas alguns cliques
  </Card>

  <Card title="Acesso via API" icon="code">
    Acesse seus crews implantados via REST API para integra√ß√£o com sistemas existentes
  </Card>

  <Card title="Observabilidade" icon="chart-line">
    Monitore seus crews com rastreamentos de execu√ß√£o e logs detalhados
  </Card>

  <Card title="Reposit√≥rio de Ferramentas" icon="toolbox">
    Publique e instale ferramentas para aprimorar as capacidades de seus crews
  </Card>

  <Card title="Transmiss√£o via Webhook" icon="webhook">
    Transmita eventos e atualiza√ß√µes em tempo real para seus sistemas
  </Card>

  <Card title="Crew Studio" icon="paintbrush">
    Crie e personalize crews utilizando uma interface no-code/low-code
  </Card>
</CardGroup>

## Op√ß√µes de Implanta√ß√£o

<CardGroup cols={3}>
  <Card title="Integra√ß√£o com GitHub" icon="github">
    Conecte-se diretamente aos seus reposit√≥rios do GitHub para implementar c√≥digo
  </Card>

  <Card title="Crew Studio" icon="palette">
    Implemente crews criados pela interface no-code do Crew Studio
  </Card>

  <Card title="Implanta√ß√£o via CLI" icon="terminal">
    Use o CrewAI CLI para fluxos de trabalho de implanta√ß√£o mais avan√ßados
  </Card>
</CardGroup>

## Primeiros Passos

<Steps>
  <Step title="Cadastre-se para uma conta">
    Crie sua conta em [app.crewai.com](https://app.crewai.com)

    <Card title="Cadastre-se" icon="user" href="https://app.crewai.com/signup">
      Cadastre-se
    </Card>
  </Step>

  <Step title="Construa seu primeiro crew">
    Utilize c√≥digo ou o Crew Studio para construir seu crew

    <Card title="Construir Crew" icon="paintbrush" href="/pt-BR/enterprise/guides/build-crew">
      Construir Crew
    </Card>
  </Step>

  <Step title="Implemente seu crew">
    Implemente seu crew na plataforma Enterprise

    <Card title="Implantar Crew" icon="rocket" href="/pt-BR/enterprise/guides/deploy-crew">
      Implantar Crew
    </Card>
  </Step>

  <Step title="Acesse seu crew">
    Integre-se ao seu crew atrav√©s dos endpoints de API gerados

    <Card title="Acesso via API" icon="code" href="/pt-BR/enterprise/guides/deploy-crew">
      Usar a API do Crew
    </Card>
  </Step>
</Steps>

Para instru√ß√µes detalhadas, consulte nosso [guia de implanta√ß√£o](/pt-BR/enterprise/guides/deploy-crew) ou clique no bot√£o abaixo para come√ßar.


# FAQs
Source: https://docs.crewai.com/pt-BR/enterprise/resources/frequently-asked-questions

Perguntas frequentes sobre CrewAI Enterprise

<AccordionGroup>
  <Accordion title="Como a execu√ß√£o de tarefas √© tratada no processo hier√°rquico?">
    No processo hier√°rquico, um agente gerente √© criado automaticamente e coordena o fluxo de trabalho, delegando tarefas e validando resultados para uma execu√ß√£o eficiente e simplificada. O agente gerente utiliza ferramentas para facilitar a delega√ß√£o e execu√ß√£o de tarefas por agentes sob sua orienta√ß√£o. O LLM do gerente √© fundamental para o processo hier√°rquico e deve ser configurado corretamente para funcionar adequadamente.
  </Accordion>

  <Accordion title="Onde posso encontrar a documenta√ß√£o mais recente da CrewAI?">
    A documenta√ß√£o mais atualizada da CrewAI est√° dispon√≠vel em nosso site oficial de documenta√ß√£o: [https://docs.crewai.com/](https://docs.crewai.com/)
    <Card href="https://docs.crewai.com/" icon="books">CrewAI Docs</Card>
  </Accordion>

  <Accordion title="Quais as principais diferen√ßas entre os Processos Hier√°rquico e Sequencial na CrewAI?">
    #### Processo Hier√°rquico:

    * As tarefas s√£o delegadas e executadas com base em uma cadeia de comando estruturada
    * Um modelo de linguagem do gerente (`manager_llm`) deve ser especificado para o agente gerente
    * O agente gerente supervisiona a execu√ß√£o de tarefas, planejamento, delega√ß√£o e valida√ß√£o
    * As tarefas n√£o s√£o pr√©-atribu√≠das; o gerente aloca tarefas para os agentes com base em suas capacidades

    #### Processo Sequencial:

    * As tarefas s√£o executadas uma ap√≥s a outra, garantindo uma progress√£o ordenada
    * O resultado de uma tarefa serve como contexto para a pr√≥xima
    * A execu√ß√£o das tarefas segue a ordem predefinida na lista de tarefas

    #### Qual Processo √© Melhor para Projetos Complexos?

    O processo hier√°rquico √© mais adequado para projetos complexos porque permite:

    * **Aloca√ß√£o e delega√ß√£o din√¢mica de tarefas**: O agente gerente pode atribuir tarefas de acordo com as capacidades dos agentes
    * **Valida√ß√£o e supervis√£o estruturadas**: O agente gerente revisa os resultados das tarefas e garante a conclus√£o
    * **Gest√£o de tarefas complexas**: Controle preciso da disponibilidade de ferramentas por agente
  </Accordion>

  <Accordion title="Quais s√£o os benef√≠cios do uso de mem√≥ria no framework CrewAI?">
    * **Aprendizado adaptativo**: As crews tornam-se mais eficientes ao longo do tempo, adaptando-se a novas informa√ß√µes e aprimorando sua abordagem √†s tarefas
    * **Personaliza√ß√£o aprimorada**: A mem√≥ria permite que os agentes recordem prefer√™ncias do usu√°rio e intera√ß√µes anteriores, possibilitando experi√™ncias personalizadas
    * **Resolu√ß√£o aprimorada de problemas**: O acesso a um reposit√≥rio rico em mem√≥ria auxilia os agentes a tomarem decis√µes mais informadas, baseando-se em aprendizados anteriores e insights contextuais
  </Accordion>

  <Accordion title="Qual √© o prop√≥sito de definir um limite m√°ximo de RPM para um agente?">
    Definir um limite m√°ximo de RPM para um agente evita que ele fa√ßa solicita√ß√µes excessivas a servi√ßos externos, o que pode ajudar a evitar limites de taxa e melhorar o desempenho.
  </Accordion>

  <Accordion title="Qual o papel da entrada humana na execu√ß√£o de tarefas dentro de uma crew da CrewAI?">
    A entrada humana permite que os agentes solicitem informa√ß√µes adicionais ou esclarecimentos quando necess√°rio. Este recurso √© fundamental em processos de tomada de decis√£o complexos ou quando os agentes precisam de mais detalhes para concluir uma tarefa com efic√°cia.

    Para integrar a entrada humana na execu√ß√£o do agente, defina a flag `human_input` na defini√ß√£o da tarefa. Quando habilitada, o agente solicitar√° a entrada do usu√°rio antes de entregar sua resposta final. Essa entrada pode fornecer contexto extra, esclarecer ambiguidades ou validar a sa√≠da do agente.

    Para orienta√ß√µes detalhadas de implementa√ß√£o, veja nosso [guia Human-in-the-Loop](/pt-BR/how-to/human-in-the-loop).
  </Accordion>

  <Accordion title="Quais op√ß√µes avan√ßadas de customiza√ß√£o est√£o dispon√≠veis para aprimorar e personalizar o comportamento e as capacidades dos agentes na CrewAI?">
    A CrewAI oferece diversas op√ß√µes avan√ßadas de customiza√ß√£o:

    * **Customiza√ß√£o de Modelo de Linguagem**: Os agentes podem ser personalizados com modelos de linguagem espec√≠ficos (`llm`) e modelos de linguagem para chamadas de fun√ß√£o (`function_calling_llm`)
    * **Configura√ß√µes de Desempenho e Debug**: Ajuste o desempenho do agente e monitore suas opera√ß√µes
    * **Modo Verbose**: Habilita registros detalhados das a√ß√µes do agente, √∫til para depura√ß√£o e otimiza√ß√£o
    * **Limite de RPM**: Define o n√∫mero m√°ximo de solicita√ß√µes por minuto (`max_rpm`)
    * **M√°ximo de Itera√ß√µes**: O atributo `max_iter` permite definir o n√∫mero m√°ximo de itera√ß√µes que um agente pode executar para uma √∫nica tarefa
    * **Delega√ß√£o e Autonomia**: Controle a capacidade do agente de delegar ou fazer perguntas com o atributo `allow_delegation` (padr√£o: True)
    * **Integra√ß√£o de Entrada Humana**: Os agentes podem solicitar informa√ß√µes adicionais ou esclarecimentos quando necess√°rio
  </Accordion>

  <Accordion title="Em quais cen√°rios a entrada humana √© particularmente √∫til na execu√ß√£o de agentes?">
    A entrada humana √© especialmente √∫til quando:

    * **Os agentes precisam de informa√ß√µes adicionais ou esclarecimentos**: Quando se deparam com ambiguidade ou dados incompletos
    * **Os agentes precisam tomar decis√µes complexas ou sens√≠veis**: A entrada humana pode auxiliar em decis√µes √©ticas ou de nuances
    * **Supervis√£o e valida√ß√£o da sa√≠da do agente**: A entrada humana pode ajudar a validar resultados e prevenir erros
    * **Personaliza√ß√£o do comportamento do agente**: Entradas humanas podem fornecer feedback para aprimorar respostas dos agentes ao longo do tempo
    * **Identifica√ß√£o e resolu√ß√£o de erros ou limita√ß√µes**: A entrada humana auxilia a suprir lacunas de capacidade dos agentes
  </Accordion>

  <Accordion title="Quais s√£o os diferentes tipos de mem√≥ria dispon√≠veis na crewAI?">
    Os diferentes tipos de mem√≥ria dispon√≠veis na CrewAI s√£o:

    * **Mem√≥ria de curto prazo**: Armazenamento tempor√°rio para contexto imediato
    * **Mem√≥ria de longo prazo**: Armazenamento persistente para padr√µes aprendidos e informa√ß√µes
    * **Mem√≥ria de entidade**: Armazenamento focado em entidades espec√≠ficas e seus atributos
    * **Mem√≥ria contextual**: Mem√≥ria que mant√©m o contexto ao longo das intera√ß√µes

    Saiba mais sobre os diferentes tipos de mem√≥ria:
    <Card href="https://docs.crewai.com/concepts/memory" icon="brain">CrewAI Memory</Card>
  </Accordion>

  <Accordion title="Como fa√ßo para usar Output Pydantic em uma Tarefa?">
    Para usar Output Pydantic em uma tarefa, voc√™ precisa definir a sa√≠da esperada da tarefa como um modelo Pydantic. Veja um exemplo r√°pido:

    <Steps>
      <Step title="Defina um modelo Pydantic">
        ```python
        from pydantic import BaseModel

        class User(BaseModel):
            name: str
            age: int
        ```
      </Step>

      <Step title="Crie uma tarefa com Output Pydantic">
        ```python
        from crewai import Task, Crew, Agent
        from my_models import User

        task = Task(
            description="Create a user with the provided name and age",
            expected_output=User,  # This is the Pydantic model
            agent=agent,
            tools=[tool1, tool2]
        )
        ```
      </Step>

      <Step title="Defina o atributo output_pydantic no seu agente">
        ```python
        from crewai import Agent
        from my_models import User

        agent = Agent(
            role='User Creator',
            goal='Create users',
            backstory='I am skilled in creating user accounts',
            tools=[tool1, tool2],
            output_pydantic=User
        )
        ```
      </Step>
    </Steps>

    Aqui est√° um tutorial de como obter sa√≠das estruturadas de forma consistente dos seus agentes:

    <Frame>
      <iframe height="400" width="100%" src="https://www.youtube.com/embed/dNpKQk5uxHw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />
    </Frame>
  </Accordion>

  <Accordion title="Como posso criar ferramentas personalizadas para meus agentes CrewAI?">
    Voc√™ pode criar ferramentas personalizadas herdando da classe `BaseTool` fornecida pela CrewAI ou usando o decorador de ferramenta. Herdar envolve definir uma nova classe que herda de `BaseTool`, especificando o nome, a descri√ß√£o e o m√©todo `_run` para a l√≥gica operacional. O decorador de ferramenta permite criar um objeto `Tool` diretamente com os atributos necess√°rios e uma l√≥gica funcional.

    <Card href="https://docs.crewai.com/how-to/create-custom-tools" icon="code">CrewAI Tools Guide</Card>
  </Accordion>

  <Accordion title="Como controlar o n√∫mero m√°ximo de solicita√ß√µes por minuto que toda a crew pode realizar?">
    O atributo `max_rpm` define o n√∫mero m√°ximo de solicita√ß√µes por minuto que a crew pode realizar para evitar limites de taxa, e ir√° sobrescrever as defini√ß√µes de `max_rpm` dos agentes individuais se voc√™ defini-lo.
  </Accordion>
</AccordionGroup>


# Exemplos CrewAI
Source: https://docs.crewai.com/pt-BR/examples/example

Uma cole√ß√£o de exemplos que mostram como usar o framework CrewAI para automatizar fluxos de trabalho.

<CardGroup cols={3}>
  <Card title="Estrat√©gia de Marketing" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/marketing_strategy" icon="bullhorn" iconType="solid">
    Automatize a cria√ß√£o de estrat√©gias de marketing com CrewAI.
  </Card>

  <Card title="Viagem Surpresa" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/surprise_trip" icon="plane" iconType="duotone">
    Crie um roteiro de viagem surpresa com CrewAI.
  </Card>

  <Card title="Relacionar Perfil a Posi√ß√µes" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/match_profile_to_positions" icon="linkedin" iconType="duotone">
    Relacione um perfil a vagas de emprego com CrewAI.
  </Card>

  <Card title="Criar Vaga" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/job-posting" icon="newspaper" iconType="duotone">
    Crie uma vaga de emprego com CrewAI.
  </Card>

  <Card title="Gerador de Jogos" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/game-builder-crew" icon="gamepad" iconType="duotone">
    Crie um jogo com CrewAI.
  </Card>

  <Card title="Encontrar Candidatos" color="#F3A78B" href="https://github.com/crewAIInc/crewAI-examples/tree/main/recruitment" icon="user-group" iconType="duotone">
    Encontre candidatos a vagas com CrewAI.
  </Card>
</CardGroup>


# Personalizando Prompts
Source: https://docs.crewai.com/pt-BR/guides/advanced/customizing-prompts

Aprofunde-se na personaliza√ß√£o de prompts de baixo n√≠vel no CrewAI, habilitando casos de uso super customizados e complexos para diferentes modelos e idiomas.

## Por Que Personalizar Prompts?

Embora os prompts padr√£o do CrewAI funcionem bem para muitos cen√°rios, a personaliza√ß√£o de baixo n√≠vel permite comportamentos de agentes significativamente mais flex√≠veis e poderosos. Veja por que voc√™ pode querer aproveitar esse controle mais profundo:

1. **Otimizar para LLMs espec√≠ficas** ‚Äì Diferentes modelos (como GPT-4, Claude ou Llama) funcionam melhor com formatos de prompt adaptados √†s suas arquiteturas exclusivas.
2. **Alterar o idioma** ‚Äì Construa agentes que operam exclusivamente em idiomas al√©m do ingl√™s, lidando com nuances com precis√£o.
3. **Especializar para dom√≠nios complexos** ‚Äì Adapte prompts para setores altamente especializados como sa√∫de, finan√ßas ou jur√≠dico.
4. **Ajustar tom e estilo** ‚Äì Torne os agentes mais formais, casuais, criativos ou anal√≠ticos.
5. **Suportar casos de uso super customizados** ‚Äì Utilize estruturas e formata√ß√µes avan√ßadas de prompt para atender requisitos detalhados e espec√≠ficos do projeto.

Este guia explora como acessar os prompts do CrewAI em um n√≠vel mais baixo, oferecendo controle granular sobre como os agentes pensam e interagem.

## Entendendo o Sistema de Prompt do CrewAI

Nos bastidores, o CrewAI adota um sistema de prompt modular que pode ser amplamente customizado:

* **Templates de agente** ‚Äì Determinam o modo como cada agente aborda o papel que lhe foi atribu√≠do.
* **Prompt slices** ‚Äì Controlam comportamentos especializados como tarefas, o uso de ferramentas e a estrutura de sa√≠da.
* **Tratamento de erros** ‚Äì Definem como os agentes respondem a falhas, exce√ß√µes ou timeouts.
* **Prompts espec√≠ficos de ferramentas** ‚Äì Definem instru√ß√µes detalhadas para como as ferramentas s√£o invocadas ou utilizadas.

Confira os [templates de prompt originais no reposit√≥rio do CrewAI](https://github.com/crewAIInc/crewAI/blob/main/src/crewai/translations/en.json) para ver como esses elementos s√£o organizados. A partir da√≠, voc√™ pode sobrescrever ou adaptar conforme necess√°rio para desbloquear comportamentos avan√ßados.

## Entendendo as Instru√ß√µes de Sistema Padr√£o

<Warning>
  **Quest√£o de Transpar√™ncia em Produ√ß√£o**: O CrewAI injeta automaticamente instru√ß√µes padr√£o nos seus prompts que talvez voc√™ n√£o conhe√ßa. Esta se√ß√£o explica o que acontece nos bastidores e como obter controle total.
</Warning>

Ao definir um agente com `role`, `goal` e `backstory`, o CrewAI automaticamente adiciona instru√ß√µes de sistema adicionais que controlam a formata√ß√£o e o comportamento. Entender essas inje√ß√µes padr√£o √© essencial para sistemas em produ√ß√£o onde voc√™ precisa de total transpar√™ncia nos prompts.

### O Que CrewAI Injeta Automaticamente

Baseado na configura√ß√£o do seu agente, o CrewAI adiciona diferentes instru√ß√µes padr√£o:

#### Para Agentes Sem Ferramentas

```text
"I MUST use these formats, my job depends on it!"
```

#### Para Agentes Com Ferramentas

```text
"IMPORTANT: Use the following format in your response:

Thought: you should always think about what to do
Action: the action to take, only one name of [tool_names]
Action Input: the input to the action, just a simple JSON object...
```

#### Para Sa√≠das Estruturadas (JSON/Pydantic)

````text
"Ensure your final answer contains only the content in the following format: {output_format}
Ensure the final output does not include any code block markers like ```json or ```python."
````

### Visualizando o Prompt de Sistema Completo

Para ver exatamente qual prompt est√° sendo enviado para seu LLM, voc√™ pode inspecionar o prompt gerado:

```python
from crewai import Agent, Crew, Task
from crewai.utilities.prompts import Prompts

# Crie seu agente
agent = Agent(
    role="Data Analyst",
    goal="Analyze data and provide insights",
    backstory="You are an expert data analyst with 10 years of experience.",
    verbose=True
)

# Crie uma tarefa de exemplo
task = Task(
    description="Analyze the sales data and identify trends",
    expected_output="A detailed analysis with key insights and trends",
    agent=agent
)

# Crie o gerador de prompt
prompt_generator = Prompts(
    agent=agent,
    has_tools=len(agent.tools) > 0,
    use_system_prompt=agent.use_system_prompt
)

# Gere e inspecione o prompt atual
generated_prompt = prompt_generator.task_execution()

# Imprima o prompt completo de sistema que ser√° enviado ao LLM
if "system" in generated_prompt:
    print("=== SYSTEM PROMPT ===")
    print(generated_prompt["system"])
    print("\n=== USER PROMPT ===")
    print(generated_prompt["user"])
else:
    print("=== COMPLETE PROMPT ===")
    print(generated_prompt["prompt"])

# Voc√™ tamb√©m pode ver como a descri√ß√£o da tarefa √© formatada
print("\n=== TASK CONTEXT ===")
print(f"Task Description: {task.description}")
print(f"Expected Output: {task.expected_output}")
```

### Sobrescrevendo Instru√ß√µes Padr√£o

Voc√™ tem v√°rias op√ß√µes para obter controle total sobre os prompts:

#### Op√ß√£o 1: Templates Personalizados (Recomendado)

```python
from crewai import Agent

# Defina seu pr√≥prio template de sistema sem instru√ß√µes padr√£o
custom_system_template = """You are {role}. {backstory}
Your goal is: {goal}

Respond naturally and conversationally. Focus on providing helpful, accurate information."""

custom_prompt_template = """Task: {input}

Please complete this task thoughtfully."""

agent = Agent(
    role="Research Assistant",
    goal="Help users find accurate information",
    backstory="You are a helpful research assistant.",
    system_template=custom_system_template,
    prompt_template=custom_prompt_template,
    use_system_prompt=True  # Use mensagens separadas system/user
)
```

#### Op√ß√£o 2: Arquivo de Prompt Personalizado

Crie um arquivo `custom_prompts.json` para sobrescrever slices espec√≠ficas de prompt:

```json
{
  "slices": {
    "no_tools": "\nProvide your best answer in a natural, conversational way.",
    "tools": "\nYou have access to these tools: {tools}\n\nUse them when helpful, but respond naturally.",
    "formatted_task_instructions": "Format your response as: {output_format}"
  }
}
```

Em seguida, utilize no seu crew:

```python
crew = Crew(
    agents=[agent],
    tasks=[task],
    prompt_file="custom_prompts.json",
    verbose=True
)
```

#### Op√ß√£o 3: Desativar Prompts de Sistema para Modelos o1

```python
agent = Agent(
    role="Analyst",
    goal="Analyze data",
    backstory="Expert analyst",
    use_system_prompt=False  # Desativa separa√ß√£o de mensagens system prompt
)
```

### Depura√ß√£o com Ferramentas de Observabilidade

Para garantir transpar√™ncia em produ√ß√£o, integre com plataformas de observabilidade para monitorar todos os prompts e intera√ß√µes com LLM. Isso permite que voc√™ veja exatamente quais prompts (incluindo instru√ß√µes padr√£o) est√£o sendo enviados para os seus LLMs.

Veja nossa [documenta√ß√£o sobre Observabilidade](/pt-BR/observability/overview) para guias detalhados de integra√ß√£o com diversas plataformas como Langfuse, MLflow, Weights & Biases e solu√ß√µes de logging customizadas.

### Boas Pr√°ticas para Produ√ß√£o

1. **Sempre inspecione prompts gerados** antes de implantar em produ√ß√£o
2. **Use templates customizados** quando precisar de controle total sobre o conte√∫do do prompt
3. **Integre ferramentas de observabilidade** para monitoramento cont√≠nuo de prompts (veja [docs de Observabilidade](/pt-BR/observability/overview))
4. **Teste com diferentes LLMs** j√° que instru√ß√µes padr√£o podem se comportar de maneira diferente em cada modelo
5. **Documente suas customiza√ß√µes de prompt** para transpar√™ncia da equipe

<Tip>
  As instru√ß√µes padr√£o existem para garantir comportamento consistente nos agentes, mas podem interferir com requisitos de dom√≠nio espec√≠ficos. Use as op√ß√µes de customiza√ß√£o acima para manter controle total sobre o comportamento do seu agente em sistemas de produ√ß√£o.
</Tip>

## Melhores Pr√°ticas para Gerenciar Arquivos de Prompt

Ao realizar personaliza√ß√£o de prompts em baixo n√≠vel, siga estas diretrizes para manter tudo organizado e f√°cil de manter:

1. **Mantenha arquivos separados** ‚Äì Armazene seus prompts personalizados em arquivos JSON dedicados fora do c√≥digo principal.
2. **Controle de vers√£o** ‚Äì Acompanhe as altera√ß√µes no seu reposit√≥rio, garantindo documenta√ß√£o clara das mudan√ßas nos prompts ao longo do tempo.
3. **Organize por modelo ou idioma** ‚Äì Utilize nomes como `prompts_llama.json` ou `prompts_es.json` para identificar rapidamente configura√ß√µes especializadas.
4. **Documente as altera√ß√µes** ‚Äì Adicione coment√°rios ou mantenha um README detalhando o prop√≥sito e o escopo das customiza√ß√µes.
5. **Minimize altera√ß√µes** ‚Äì Sobrescreva apenas os slices espec√≠ficos que realmente precisam de ajuste, mantendo a funcionalidade padr√£o para o restante.

## O Jeito Mais Simples de Personalizar Prompts

Uma abordagem direta √© criar um arquivo JSON para os prompts que deseja sobrescrever e ent√£o indicar este arquivo no seu Crew:

1. Crie um arquivo JSON com os slices de prompt atualizados.
2. Referencie este arquivo no par√¢metro `prompt_file` do seu Crew.

O CrewAI ent√£o mescla suas customiza√ß√µes com os padr√µes, assim voc√™ n√£o precisa redefinir todos os prompts. Veja como:

### Exemplo: Customiza√ß√£o B√°sica de Prompt

Crie um arquivo `custom_prompts.json` com os prompts que deseja modificar. Certifique-se de listar todos os prompts de n√≠vel superior que ele deve conter, n√£o apenas suas altera√ß√µes:

```json
{
  "slices": {
    "format": "When responding, follow this structure:\n\nTHOUGHTS: Your step-by-step thinking\nACTION: Any tool you're using\nRESULT: Your final answer or conclusion"
  }
}
```

Integre assim:

```python
from crewai import Agent, Crew, Task, Process

# Crie agentes e tarefas normalmente
researcher = Agent(
    role="Research Specialist",
    goal="Find information on quantum computing",
    backstory="You are a quantum physics expert",
    verbose=True
)

research_task = Task(
    description="Research quantum computing applications",
    expected_output="A summary of practical applications",
    agent=researcher
)

# Crie um crew com seu arquivo de prompt personalizado
crew = Crew(
    agents=[researcher],
    tasks=[research_task],
    prompt_file="path/to/custom_prompts.json",
    verbose=True
)

# Execute o crew
result = crew.kickoff()
```

Com essas poucas edi√ß√µes, voc√™ conquista controle de baixo n√≠vel sobre como seus agentes se comunicam e solucionam tarefas.

## Otimizando para Modelos Espec√≠ficos

Modelos diferentes respondem melhor a estruturas de prompt diferentes. Ajustes mais profundos podem aumentar significativamente o desempenho ao alinhar seus prompts √†s nuances de cada modelo.

### Exemplo: Template de Prompt para Llama 3.3

Por exemplo, ao lidar com o Llama 3.3 da Meta, a personaliza√ß√£o de baixo n√≠vel pode refletir a estrutura recomendada descrita em:
[https://www.llama.com/docs/model-cards-and-prompt-formats/llama3\_1/#prompt-template](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1/#prompt-template)

Veja um exemplo destacando como voc√™ pode ajustar um Agent para usar o Llama 3.3 em c√≥digo:

```python
from crewai import Agent, Crew, Task, Process
from crewai_tools import DirectoryReadTool, FileReadTool

# Defina templates para mensagens de system, user (prompt) e assistant (resposta)
system_template = """<|begin_of_text|><|start_header_id|>system<|end_header_id|>{{ .System }}<|eot_id|>"""
prompt_template = """<|start_header_id|>user<|end_header_id|>{{ .Prompt }}<|eot_id|>"""
response_template = """<|start_header_id|>assistant<|end_header_id|>{{ .Response }}<|eot_id|>"""

# Crie um Agent usando layouts espec√≠ficos do Llama
principal_engineer = Agent(
    role="Principal Engineer",
    goal="Oversee AI architecture and make high-level decisions",
    backstory="You are the lead engineer responsible for critical AI systems",
    verbose=True,
    llm="groq/llama-3.3-70b-versatile",  # Usando o modelo Llama 3
    system_template=system_template,
    prompt_template=prompt_template,
    response_template=response_template,
    tools=[DirectoryReadTool(), FileReadTool()]
)

# Defina uma tarefa de exemplo
engineering_task = Task(
    description="Review AI implementation files for potential improvements",
    expected_output="A summary of key findings and recommendations",
    agent=principal_engineer
)

# Crie um Crew para a tarefa
llama_crew = Crew(
    agents=[principal_engineer],
    tasks=[engineering_task],
    process=Process.sequential,
    verbose=True
)

# Execute o crew
result = llama_crew.kickoff()
print(result.raw)
```

Com essa configura√ß√£o, voc√™ exerce controle abrangente e de baixo n√≠vel sobre seus fluxos de trabalho baseados em Llama sem precisar de um arquivo JSON separado.

## Conclus√£o

A personaliza√ß√£o de prompts em baixo n√≠vel no CrewAI abre portas para casos de uso super customizados e complexos. Mantendo arquivos de prompt organizados (ou templates inline diretos), √© poss√≠vel acomodar diferentes modelos, idiomas e dom√≠nios especializados. Esse n√≠vel de flexibilidade garante que voc√™ possa criar exatamente o comportamento de IA que precisa, sabendo que o CrewAI ainda fornece padr√µes confi√°veis quando voc√™ n√£o sobrescreve.

<Check>
  Agora voc√™ tem a base para customiza√ß√µes avan√ßadas de prompt no CrewAI. Seja adaptando para estruturas espec√≠ficas de modelo ou restri√ß√µes de dom√≠nio, esta abordagem de baixo n√≠vel permite moldar as intera√ß√µes dos agentes de forma altamente especializada.
</Check>


# Impress√£o digital
Source: https://docs.crewai.com/pt-BR/guides/advanced/fingerprinting

Saiba como usar o sistema de impress√£o digital da CrewAI para identificar e rastrear componentes de forma √∫nica durante todo o seu ciclo de vida.

## Vis√£o geral

As impress√µes digitais na CrewAI fornecem uma maneira de identificar e rastrear componentes de forma √∫nica durante todo o seu ciclo de vida. Cada `Agent`, `Crew` e `Task` recebe automaticamente uma impress√£o digital √∫nica quando criado, que n√£o pode ser sobrescrita manualmente.

Essas impress√µes digitais podem ser usadas para:

* Auditoria e rastreamento do uso de componentes
* Garantir a integridade da identidade dos componentes
* Anexar metadados aos componentes
* Criar uma cadeia rastre√°vel de opera√ß√µes

## Como funciona a impress√£o digital

Uma impress√£o digital √© uma inst√¢ncia da classe `Fingerprint` do m√≥dulo `crewai.security`. Cada impress√£o digital cont√©m:

* Uma string UUID: Um identificador √∫nico para o componente, gerado automaticamente e que n√£o pode ser definido manualmente
* Um timestamp de cria√ß√£o: Quando a impress√£o digital foi gerada, definido automaticamente e que n√£o pode ser modificado manualmente
* Metadados: Um dicion√°rio de informa√ß√µes adicionais que pode ser customizado

As impress√µes digitais s√£o geradas e atribu√≠das automaticamente quando um componente √© criado. Cada componente exp√µe sua impress√£o digital por meio de uma propriedade de somente leitura.

## Uso b√°sico

### Acessando impress√µes digitais

```python
from crewai import Agent, Crew, Task

# Criar componentes - impress√µes digitais s√£o geradas automaticamente
agent = Agent(
    role="Data Scientist",
    goal="Analyze data",
    backstory="Expert in data analysis"
)

crew = Crew(
    agents=[agent],
    tasks=[]
)

task = Task(
    description="Analyze customer data",
    expected_output="Insights from data analysis",
    agent=agent
)

# Acessar as impress√µes digitais
agent_fingerprint = agent.fingerprint
crew_fingerprint = crew.fingerprint
task_fingerprint = task.fingerprint

# Imprimir as strings UUID
print(f"Agent fingerprint: {agent_fingerprint.uuid_str}")
print(f"Crew fingerprint: {crew_fingerprint.uuid_str}")
print(f"Task fingerprint: {task_fingerprint.uuid_str}")
```

### Trabalhando com metadados das impress√µes digitais

Voc√™ pode adicionar metadados √†s impress√µes digitais para fornecer contexto adicional:

```python
# Adicionar metadados √† impress√£o digital do agente
agent.security_config.fingerprint.metadata = {
    "version": "1.0",
    "department": "Data Science",
    "project": "Customer Analysis"
}

# Acessar os metadados
print(f"Agent metadata: {agent.fingerprint.metadata}")
```

## Persist√™ncia das impress√µes digitais

As impress√µes digitais foram projetadas para persistir e permanecer inalteradas durante todo o ciclo de vida de um componente. Se voc√™ modificar um componente, a impress√£o digital permanece a mesma:

```python
original_fingerprint = agent.fingerprint.uuid_str

# Modificar o agente
agent.goal = "New goal for analysis"

# A impress√£o digital permanece inalterada
assert agent.fingerprint.uuid_str == original_fingerprint
```

## Impress√µes digitais determin√≠sticas

Apesar de n√£o ser poss√≠vel definir diretamente o UUID e o timestamp de cria√ß√£o, √© poss√≠vel criar impress√µes digitais determin√≠sticas usando o m√©todo `generate` com uma seed:

```python
from crewai.security import Fingerprint

# Criar uma impress√£o digital determin√≠stica usando uma string seed
deterministic_fingerprint = Fingerprint.generate(seed="my-agent-id")

# A mesma seed sempre gera a mesma impress√£o digital
same_fingerprint = Fingerprint.generate(seed="my-agent-id")
assert deterministic_fingerprint.uuid_str == same_fingerprint.uuid_str

# Tamb√©m √© poss√≠vel definir metadados
custom_fingerprint = Fingerprint.generate(
    seed="my-agent-id",
    metadata={"version": "1.0"}
)
```

## Uso avan√ßado

### Estrutura da impress√£o digital

Cada impress√£o digital possui a seguinte estrutura:

```python
from crewai.security import Fingerprint

fingerprint = agent.fingerprint

# String UUID - identificador √∫nico (gerado automaticamente)
uuid_str = fingerprint.uuid_str  # e.g., "123e4567-e89b-12d3-a456-426614174000"

# Timestamp de cria√ß√£o (gerado automaticamente)
created_at = fingerprint.created_at  # Um objeto datetime

# Metadados - informa√ß√µes adicionais (podem ser customizadas)
metadata = fingerprint.metadata  # Um dicion√°rio, padr√£o {}
```


# Criando Agentes Eficazes
Source: https://docs.crewai.com/pt-BR/guides/agents/crafting-effective-agents

Aprenda as melhores pr√°ticas para projetar agentes de IA poderosos e especializados que colaboram de forma eficaz para resolver problemas complexos.

## A Arte e a Ci√™ncia do Design de Agentes

No n√∫cleo do CrewAI est√° o agente ‚Äì uma entidade de IA especializada projetada para desempenhar fun√ß√µes espec√≠ficas dentro de um framework colaborativo. Embora criar agentes b√°sicos seja simples, criar agentes verdadeiramente eficazes que geram resultados excepcionais requer a compreens√£o de princ√≠pios fundamentais de design e boas pr√°ticas.

Este guia vai ajud√°-lo a dominar a arte de projetar agentes, permitindo criar personas de IA especializadas que colaboram de forma eficaz, pensam criticamente e produzem resultados de alta qualidade adaptados √†s suas necessidades espec√≠ficas.

### Por Que o Design de Agentes √© Importante

A forma como voc√™ define seus agentes impacta significativamente:

1. **Qualidade do resultado**: Agentes bem projetados produzem resultados mais relevantes e de alta qualidade
2. **Efici√™ncia da colabora√ß√£o**: Agentes com habilidades complementares trabalham juntos de maneira mais eficiente
3. **Desempenho nas tarefas**: Agentes com pap√©is e objetivos claros executam tarefas de forma mais eficaz
4. **Escalabilidade do sistema**: Agentes bem projetados podem ser reutilizados em m√∫ltiplos crews e contextos

Vamos explorar as melhores pr√°ticas para criar agentes que se destacam nessas dimens√µes.

## A Regra 80/20: Foque Mais nas Tarefas do que nos Agentes

Ao construir sistemas de IA eficazes, lembre-se deste princ√≠pio crucial: **80% do seu esfor√ßo deve ser dedicado ao design das tarefas, e apenas 20% √† defini√ß√£o dos agentes**.

Por qu√™? Porque mesmo o agente mais perfeitamente definido ir√° falhar com tarefas mal elaboradas, mas tarefas bem projetadas podem elevar at√© mesmo agentes simples. Isso significa:

* Dedique a maior parte do seu tempo escrevendo instru√ß√µes claras para as tarefas
* Defina entradas detalhadas e sa√≠das esperadas
* Adicione exemplos e contexto para orientar a execu√ß√£o
* Reserve o tempo restante para o papel, objetivo e hist√≥rico do agente

Isso n√£o quer dizer que o design do agente n√£o seja importante ‚Äì ele √©, sim. Mas o design das tarefas √© onde ocorrem a maioria das falhas de execu√ß√£o, ent√£o priorize de acordo.

## Princ√≠pios Fundamentais do Design de Agentes Eficazes

### 1. O Framework Papel‚ÄìObjetivo‚ÄìHist√≥rico

Os agentes mais poderosos no CrewAI t√™m uma base s√≥lida em tr√™s elementos-chave:

#### Papel: A Fun√ß√£o Especializada do Agente

O papel define o que o agente faz e sua √°rea de especializa√ß√£o. Ao criar pap√©is:

* **Seja espec√≠fico e especializado**: Em vez de ‚ÄúEscritor‚Äù, use ‚ÄúEspecialista em Documenta√ß√£o T√©cnica‚Äù ou ‚ÄúContador de Hist√≥rias Criativo‚Äù
* **Alinhe com profiss√µes do mundo real**: Baseie os pap√©is em arqu√©tipos profissionais reconhec√≠veis
* **Inclua expertise no dom√≠nio**: Especifique o campo de conhecimento do agente (ex: ‚ÄúAnalista Financeiro especializado em tend√™ncias de mercado‚Äù)

**Exemplos de pap√©is eficazes:**

```yaml
role: "Pesquisador S√™nior de UX especializado em an√°lise de entrevistas com usu√°rios"
role: "Arquiteto de Software Full-Stack com expertise em sistemas distribu√≠dos"
role: "Diretor de Comunica√ß√£o Corporativa especializado em gest√£o de crises"
```

#### Objetivo: A Finalidade e Motiva√ß√£o do Agente

O objetivo direciona os esfor√ßos do agente e orienta seu processo de tomada de decis√£o. Objetivos eficazes devem:

* **Ser claros e focados em resultado**: Defina o que o agente precisa alcan√ßar
* **Enfatizar padr√µes de qualidade**: Inclua expectativas sobre a qualidade do trabalho
* **Incorporar crit√©rios de sucesso**: Ajude o agente a entender o que √© considerado ‚Äúbom‚Äù

**Exemplos de objetivos eficazes:**

```yaml
goal: "Descobrir insights acion√°veis analisando dados de entrevistas, identificando padr√µes recorrentes, necessidades n√£o atendidas e oportunidades de melhoria"
goal: "Projetar arquiteturas de sistemas robustas e escal√°veis que equilibrem performance, manuten√ß√£o e custo-benef√≠cio"
goal: "Criar comunica√ß√µes de crise claras e emp√°ticas, abordando as preocupa√ß√µes das partes interessadas e protegendo a reputa√ß√£o organizacional"
```

#### Hist√≥rico: Experi√™ncia e Perspectiva do Agente

O hist√≥rico aprofunda o agente, influenciando como ele aborda problemas e interage com os demais. Bons hist√≥ricos:

* **Estabelecem expertise e experi√™ncia**: Explique como o agente adquiriu suas habilidades
* **Definem estilo de trabalho e valores**: Descreva como o agente encara seu trabalho
* **Criam uma persona coesa**: Garanta que todos os elementos do hist√≥rico estejam alinhados ao papel e ao objetivo

**Exemplos de hist√≥ricos eficazes:**

```yaml
backstory: "Voc√™ passou 15 anos conduzindo e analisando pesquisas com usu√°rios em grandes empresas de tecnologia. Tem talento para ler nas entrelinhas e identificar padr√µes que outros n√£o enxergam. Acredita que uma boa experi√™ncia do usu√°rio √© invis√≠vel e que os melhores insights v√™m tanto do que os usu√°rios n√£o dizem quanto do que dizem."

backstory: "Com mais de 20 anos de experi√™ncia construindo sistemas distribu√≠dos em larga escala, voc√™ desenvolveu uma abordagem pragm√°tica para arquitetura de software. Viu sistemas bem sucedidos e fracassados e aprendeu li√ß√µes valiosas com ambos. Equilibra as melhores pr√°ticas te√≥ricas com restri√ß√µes pr√°ticas e sempre considera os aspectos de manuten√ß√£o e opera√ß√£o em seus projetos."

backstory: "Como um profissional de comunica√ß√£o experiente que j√° orientou m√∫ltiplas organiza√ß√µes em crises de grande repercuss√£o, voc√™ entende a import√¢ncia da transpar√™ncia, agilidade e empatia em respostas a crises. Tem uma abordagem met√≥dica para criar mensagens que abordam preocupa√ß√µes mantendo a credibilidade da organiza√ß√£o."
```

### 2. Especialistas em vez de Generalistas

Agentes desempenham muito melhor quando recebem pap√©is especializados em vez de pap√©is gen√©ricos. Um agente altamente focado gera resultados mais precisos e relevantes:

**Gen√©rico (Menos Eficaz):**

```yaml
role: "Writer"
```

**Especializado (Mais Eficaz):**

```yaml
role: "Redator T√©cnico de Blog especializado em explicar conceitos complexos de IA para p√∫blicos n√£o t√©cnicos"
```

**Vantagens dos Especialistas:**

* Compreens√£o mais clara do resultado esperado
* Performance mais consistente
* Melhor alinhamento com tarefas espec√≠ficas
* Maior capacidade de fazer julgamentos espec√≠ficos do dom√≠nio

### 3. Equilibrando Especializa√ß√£o e Versatilidade

Agentes eficazes equilibram bem a especializa√ß√£o (fazer uma coisa muito bem) e a versatilidade (adaptar-se a diversas situa√ß√µes):

* **Especialize no papel, seja vers√°til na aplica√ß√£o**: Crie agentes com habilidades especializadas aplic√°veis em m√∫ltiplos contextos
* **Evite defini√ß√µes excessivamente restritas**: Garanta que agentes possam lidar com varia√ß√µes dentro de sua √°rea de expertise
* **Considere o contexto colaborativo**: Projete agentes cujas especialidades complementem os demais do crew

### 4. Defini√ß√£o N√≠vel Apropriado de Expertise

O n√≠vel de expertise atribu√≠do ao agente determina como ele realiza as tarefas:

* **Agentes iniciantes**: Bons para tarefas simples, brainstorm, rascunhos iniciais
* **Agentes intermedi√°rios**: Adequados para a maioria das tarefas padr√£o com execu√ß√£o confi√°vel
* **Agentes especialistas**: Ideais para tarefas complexas e especializadas que exigem profundidade e nuances
* **Agentes de classe mundial**: Reservados para tarefas cr√≠ticas onde a qualidade excepcional √© essencial

Escolha o n√≠vel de expertise baseado na complexidade da tarefa e no padr√£o de qualidade exigido. Em crews colaborativos, tendem a funcionar melhor equipes com n√≠veis variados de expertise, reservando maior especializa√ß√£o para as fun√ß√µes mais chave.

## Exemplos Pr√°ticos: Antes e Depois

Veja exemplos de defini√ß√µes de agentes antes e depois de aplicar essas boas pr√°ticas:

### Exemplo 1: Agente de Cria√ß√£o de Conte√∫do

**Antes:**

```yaml
role: "Writer"
goal: "Write good content"
backstory: "You are a writer who creates content for websites."
```

**Depois:**

```yaml
role: "Estrategista de Conte√∫do B2B para Tecnologia"
goal: "Criar conte√∫dos envolventes e tecnicamente precisos, explicando t√≥picos complexos em linguagem acess√≠vel, promovendo engajamento e apoiando os objetivos do neg√≥cio"
backstory: "Voc√™ passou uma d√©cada criando conte√∫dos para empresas l√≠deres em tecnologia, especializando-se na tradu√ß√£o de conceitos t√©cnicos para p√∫blicos empresariais. √â √≥timo em pesquisa, entrevistas com especialistas e estrutura√ß√£o da informa√ß√£o para m√°xima clareza e impacto. Acredita que o melhor conte√∫do B2B educa antes de vender, construindo confian√ßa atrav√©s da expertise genu√≠na e n√£o do hype de marketing."
```

### Exemplo 2: Agente de Pesquisa

**Antes:**

```yaml
role: "Researcher"
goal: "Find information"
backstory: "You are good at finding information online."
```

**Depois:**

```yaml
role: "Especialista em Pesquisa Acad√™mica de Tecnologias Emergentes"
goal: "Descobrir e sintetizar pesquisas de ponta, identificando tend√™ncias, metodologias e resultados principais, avaliando a qualidade e confiabilidade das fontes"
backstory: "Com forma√ß√£o em ci√™ncia da computa√ß√£o e biblioteconomia, voc√™ dominou a arte da pesquisa digital. J√° trabalhou com equipes de pesquisa em universidades de prest√≠gio e sabe como navegar bancos de dados acad√™micos, avaliar a qualidade das pesquisas e sintetizar descobertas em diferentes √°reas. Seu m√©todo √© rigoroso: sempre cruza informa√ß√µes e rastreia a origem dos dados antes de chegar a conclus√µes."
```

## Criando Tarefas Eficazes para seus Agentes

Embora o design dos agentes seja importante, o design das tarefas √© cr√≠tico para uma boa execu√ß√£o. Aqui est√£o as melhores pr√°ticas para definir tarefas que ir√£o impulsionar o sucesso dos seus agentes:

### A Anatomia de uma Tarefa Eficaz

Uma tarefa bem projetada tem dois componentes-chave com prop√≥sitos distintos:

#### Descri√ß√£o da Tarefa: O Processo

A descri√ß√£o deve focar no que fazer e como fazer, incluindo:

* Instru√ß√µes detalhadas de execu√ß√£o
* Contexto e informa√ß√µes de fundo
* Escopo e restri√ß√µes
* Passos do processo a serem seguidos

#### Sa√≠da Esperada: O Entreg√°vel

A sa√≠da esperada deve definir como o resultado final deve ser apresentado:

* Especifica√ß√µes de formato (markdown, JSON, etc.)
* Estrutura exigida
* Crit√©rios de qualidade
* Exemplos de bons entreg√°veis (sempre que poss√≠vel)

### Melhores Pr√°ticas para Design de Tarefas

#### 1. Prop√≥sito √önico, Sa√≠da √önica

Tarefas funcionam melhor quando s√£o focadas em um objetivo claro:

**Exemplo Ruim (Muito Abrangente):**

```yaml
task_description: "Research market trends, analyze the data, and create a visualization."
```

**Exemplo Bom (Focado):**

```yaml
# Task 1
research_task:
  description: "Research the top 5 market trends in the AI industry for 2024."
  expected_output: "A markdown list of the 5 trends with supporting evidence."

# Task 2
analysis_task:
  description: "Analyze the identified trends to determine potential business impacts."
  expected_output: "A structured analysis with impact ratings (High/Medium/Low)."

# Task 3
visualization_task:
  description: "Create a visual representation of the analyzed trends."
  expected_output: "A description of a chart showing trends and their impact ratings."
```

#### 2. Seja Expl√≠cito Sobre Entradas e Sa√≠das

Sempre especifique claramente quais s√£o as entradas da tarefa e como deve ser o resultado:

**Exemplo:**

```yaml
analysis_task:
  description: >
    Analyze the customer feedback data from the CSV file.
    Focus on identifying recurring themes related to product usability.
    Consider sentiment and frequency when determining importance.
  expected_output: >
    A markdown report with the following sections:
    1. Executive summary (3-5 bullet points)
    2. Top 3 usability issues with supporting data
    3. Recommendations for improvement
```

#### 3. Inclua Prop√≥sito e Contexto

Explique por que a tarefa importa e como ela se encaixa no fluxo de trabalho maior:

**Exemplo:**

```yaml
competitor_analysis_task:
  description: >
    Analyze our three main competitors' pricing strategies.
    This analysis will inform our upcoming pricing model revision.
    Focus on identifying patterns in how they price premium features
    and how they structure their tiered offerings.
```

#### 4. Use Ferramentas de Sa√≠da Estruturada

Para sa√≠das leg√≠veis por m√°quina, especifique claramente o formato:

**Exemplo:**

```yaml
data_extraction_task:
  description: "Extract key metrics from the quarterly report."
  expected_output: "JSON object with the following keys: revenue, growth_rate, customer_acquisition_cost, and retention_rate."
```

## Erros Comuns a Evitar

Baseando-se em experi√™ncias de casos reais, estes s√£o os erros mais comuns no design de agentes e tarefas:

### 1. Instru√ß√µes de Tarefa Pouco Claras

**Problema:** Tarefas sem detalhes suficientes, dificultando a execu√ß√£o pelo agente.

**Exemplo de Design Ruim:**

```yaml
research_task:
  description: "Research AI trends."
  expected_output: "A report on AI trends."
```

**Vers√£o Melhorada:**

```yaml
research_task:
  description: >
    Research the top emerging AI trends for 2024 with a focus on:
    1. Enterprise adoption patterns
    2. Technical breakthroughs in the past 6 months
    3. Regulatory developments affecting implementation

    For each trend, identify key companies, technologies, and potential business impacts.
  expected_output: >
    A comprehensive markdown report with:
    - Executive summary (5 bullet points)
    - 5-7 major trends with supporting evidence
    - For each trend: definition, examples, and business implications
    - References to authoritative sources
```

### 2. "Tarefas-Deus" Que Tentam Fazer Demais

**Problema:** Tarefas que combinam m√∫ltiplas opera√ß√µes complexas em um √∫nico conjunto de instru√ß√µes.

**Exemplo de Design Ruim:**

```yaml
comprehensive_task:
  description: "Research market trends, analyze competitor strategies, create a marketing plan, and design a launch timeline."
```

**Vers√£o Melhorada:**
Divida em tarefas sequenciais e focadas:

```yaml
# Task 1: Research
market_research_task:
  description: "Research current market trends in the SaaS project management space."
  expected_output: "A markdown summary of key market trends."

# Task 2: Competitive Analysis
competitor_analysis_task:
  description: "Analyze strategies of the top 3 competitors based on the market research."
  expected_output: "A comparison table of competitor strategies."
  context: [market_research_task]

# Continue with additional focused tasks...
```

### 3. Descri√ß√£o e Sa√≠da Esperada Desalinhadas

**Problema:** O que a descri√ß√£o pede n√£o corresponde ao que a sa√≠da esperada especifica.

**Exemplo de Design Ruim:**

```yaml
analysis_task:
  description: "Analyze customer feedback to find areas of improvement."
  expected_output: "A marketing plan for the next quarter."
```

**Vers√£o Melhorada:**

```yaml
analysis_task:
  description: "Analyze customer feedback to identify the top 3 areas for product improvement."
  expected_output: "A report listing the 3 priority improvement areas with supporting customer quotes and data points."
```

### 4. N√£o Entender o Processo Voc√™ Mesmo

**Problema:** Pedir para o agente executar tarefas que voc√™ mesmo n√£o entende completamente.

**Solu√ß√£o:**

1. Tente realizar a tarefa manualmente primeiro
2. Documente o processo, pontos de decis√£o e fontes de informa√ß√£o
3. Use esta documenta√ß√£o como base para a descri√ß√£o da tarefa

### 5. Uso Prematuro de Estruturas Hier√°rquicas

**Problema:** Criar hierarquias de agentes desnecessariamente complexas quando processos sequenciais seriam suficientes.

**Solu√ß√£o:** Comece com processos sequenciais e s√≥ adote modelos hier√°rquicos quando a complexidade do fluxo de trabalho realmente justificar.

### 6. Defini√ß√µes Gen√©ricas ou Pouco Claras de Agentes

**Problema:** Defini√ß√µes gen√©ricas de agentes levam a resultados gen√©ricos.

**Exemplo de Design Ruim:**

```yaml
agent:
  role: "Business Analyst"
  goal: "Analyze business data"
  backstory: "You are good at business analysis."
```

**Vers√£o Melhorada:**

```yaml
agent:
  role: "Especialista em M√©tricas SaaS focado em startups em fase de crescimento"
  goal: "Identificar insights acion√°veis em dados de neg√≥cios que possam impactar diretamente a reten√ß√£o de clientes e o crescimento de receita"
  backstory: "Com mais de 10 anos analisando modelos de neg√≥cios SaaS, voc√™ desenvolveu um olhar apurado para as m√©tricas que realmente impulsionam crescimento sustent√°vel. J√° ajudou diversas empresas a identificar pontos de alavancagem que mudaram o rumo dos neg√≥cios. Acredita em conectar dados a recomenda√ß√µes espec√≠ficas e acion√°veis, e n√£o apenas a observa√ß√µes gen√©ricas."
```

## Estrat√©gias Avan√ßadas de Design de Agentes

### Projetando para Colabora√ß√£o

Ao criar agentes que trabalhar√£o em conjunto em um crew, pense em:

* **Habilidades complementares**: Projete agentes com compet√™ncias distintas, por√©m complementares
* **Pontos de transfer√™ncia**: Defina interfaces claras para a passagem de trabalho entre agentes
* **Tens√£o construtiva**: √Äs vezes, agentes com perspectivas um pouco diferentes promovem melhores resultados por meio de di√°logos construtivos

Por exemplo, um crew de cria√ß√£o de conte√∫do pode incluir:

```yaml
# Research Agent
role: "Research Specialist for technical topics"
goal: "Gather comprehensive, accurate information from authoritative sources"
backstory: "You are a meticulous researcher with a background in library science..."

# Writer Agent
role: "Technical Content Writer"
goal: "Transform research into engaging, clear content that educates and informs"
backstory: "You are an experienced writer who excels at explaining complex concepts..."

# Editor Agent
role: "Content Quality Editor"
goal: "Ensure content is accurate, well-structured, and polished while maintaining consistency"
backstory: "With years of experience in publishing, you have a keen eye for detail..."
```

### Criando Usu√°rios Especializados de Ferramentas

Alguns agentes podem ser projetados para explorar certas ferramentas de maneira eficiente:

```yaml
role: "Data Analysis Specialist"
goal: "Derive meaningful insights from complex datasets through statistical analysis"
backstory: "With a background in data science, you excel at working with structured and unstructured data..."
tools: [PythonREPLTool, DataVisualizationTool, CSVAnalysisTool]
```

### Personalizando Agentes para Capacidades do LLM

Diferentes LLMs t√™m pontos fortes distintos. Projete seus agentes levando essas capacidades em conta:

```yaml
# For complex reasoning tasks
analyst:
  role: "Data Insights Analyst"
  goal: "..."
  backstory: "..."
  llm: openai/gpt-4o

# For creative content
writer:
  role: "Creative Content Writer"
  goal: "..."
  backstory: "..."
  llm: anthropic/claude-3-opus
```

## Testando e Iterando no Design de Agentes

A constru√ß√£o de agentes geralmente √© um processo iterativo. Veja como colocar em pr√°tica:

1. **Comece com um prot√≥tipo**: Crie uma defini√ß√£o inicial do agente
2. **Teste com tarefas de exemplo**: Avalie o desempenho em tarefas representativas
3. **Analise os resultados**: Identifique pontos fortes e fracos
4. **Refine a defini√ß√£o**: Ajuste papel, objetivo e hist√≥rico conforme suas observa√ß√µes
5. **Teste em colabora√ß√£o**: Avalie como o agente se sai em conjunto no crew

## Conclus√£o

Criar agentes eficazes √© tanto arte quanto ci√™ncia. Ao definir cuidadosamente pap√©is, objetivos e hist√≥ricos alinhados √†s suas necessidades, e combinar isso com tarefas bem projetadas, voc√™ constr√≥i colaboradores de IA especializados capazes de gerar resultados excepcionais.

Lembre-se de que o design de agentes e tarefas √© um processo iterativo. Comece com essas boas pr√°ticas, observe os agentes em a√ß√£o e refine sua abordagem conforme necess√°rio. E sempre tenha em mente a regra 80/20 ‚Äì concentre a maior parte do esfor√ßo em criar tarefas claras e focadas para tirar o melhor de seus agentes.

<Check>
  Parab√©ns! Agora voc√™ entende os princ√≠pios e pr√°ticas do design eficaz de agentes. Aplique estas t√©cnicas para criar agentes poderosos e especializados que trabalham juntos perfeitamente e realizam tarefas complexas.
</Check>

## Pr√≥ximos Passos

* Experimente diferentes configura√ß√µes de agentes para o seu caso de uso
* Aprenda sobre [como construir seu primeiro crew](/pt-BR/guides/crews/first-crew) para ver como agentes trabalham juntos
* Explore os [CrewAI Flows](/pt-BR/guides/flows/first-flow) para uma orquestra√ß√£o mais avan√ßada


# Avaliando Casos de Uso para CrewAI
Source: https://docs.crewai.com/pt-BR/guides/concepts/evaluating-use-cases

Aprenda a avaliar as necessidades da sua aplica√ß√£o de IA e escolher a abordagem certa entre Crews e Flows com base nos requisitos de complexidade e precis√£o.

## Entendendo o Framework de Decis√£o

Ao construir aplica√ß√µes de IA com CrewAI, uma das decis√µes mais importantes que voc√™ tomar√° √© escolher a abordagem correta para o seu caso de uso espec√≠fico. Voc√™ deve usar uma Crew? Um Flow? Uma combina√ß√£o dos dois? Este guia vai ajudar voc√™ a avaliar seus requisitos e tomar decis√µes arquitet√¥nicas embasadas.

No centro dessa decis√£o est√° o entendimento da rela√ß√£o entre **complexidade** e **precis√£o** em sua aplica√ß√£o:

<Frame caption="Matriz de Complexidade vs. Precis√£o para Aplica√ß√µes CrewAI">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/complexity_precision.png" alt="Matriz de Complexidade vs. Precis√£o" />
</Frame>

Essa matriz ajuda a visualizar como diferentes abordagens se alinham com os requisitos variados de complexidade e precis√£o. Vamos explorar o significado de cada quadrante e como isso orienta suas escolhas arquiteturais.

## Explicando a Matriz Complexidade-Precis√£o

### O que √© Complexidade?

No contexto das aplica√ß√µes CrewAI, **complexidade** refere-se a:

* O n√∫mero de etapas ou opera√ß√µes distintas necess√°rias
* A diversidade de tarefas que precisam ser realizadas
* As interdepend√™ncias entre diferentes componentes
* A necessidade de l√≥gica condicional e ramifica√ß√µes
* A sofistica√ß√£o do fluxo de trabalho como um todo

### O que √© Precis√£o?

**Precis√£o** nesse contexto refere-se a:

* O grau de exatid√£o exigido no resultado final
* A necessidade de resultados estruturados e previs√≠veis
* A import√¢ncia da reprodutibilidade
* O n√≠vel de controle necess√°rio sobre cada etapa
* A toler√¢ncia √† varia√ß√£o nos resultados

### Os Quatro Quadrantes

#### 1. Baixa Complexidade, Baixa Precis√£o

**Caracter√≠sticas:**

* Tarefas simples e diretas
* Toler√¢ncia a alguma varia√ß√£o nos resultados
* N√∫mero limitado de etapas
* Aplica√ß√µes criativas ou explorat√≥rias

**Abordagem Recomendada:** Crews simples com poucos agentes

**Exemplos de Casos de Uso:**

* Gera√ß√£o b√°sica de conte√∫do
* Brainstorming de ideias
* Tarefas simples de sumariza√ß√£o
* Assist√™ncia √† escrita criativa

#### 2. Baixa Complexidade, Alta Precis√£o

**Caracter√≠sticas:**

* Fluxos de trabalho simples que exigem resultados exatos e estruturados
* Necessidade de resultados reproduz√≠veis
* Poucas etapas, mas alto requisito de precis√£o
* Frequentemente envolve processamento ou transforma√ß√£o de dados

**Abordagem Recomendada:** Flows com chamadas diretas a LLM ou Crews simples com sa√≠das estruturadas

**Exemplos de Casos de Uso:**

* Extra√ß√£o e transforma√ß√£o de dados
* Preenchimento e valida√ß√£o de formul√°rios
* Gera√ß√£o estruturada de conte√∫do (JSON, XML)
* Tarefas simples de classifica√ß√£o

#### 3. Alta Complexidade, Baixa Precis√£o

**Caracter√≠sticas:**

* Processos multiest√°gio com muitas etapas
* Sa√≠das criativas ou explorat√≥rias
* Intera√ß√µes complexas entre componentes
* Toler√¢ncia √† varia√ß√£o nos resultados finais

**Abordagem Recomendada:** Crews complexas com m√∫ltiplos agentes especializados

**Exemplos de Casos de Uso:**

* Pesquisa e an√°lise
* Pipelines de cria√ß√£o de conte√∫do
* An√°lise explorat√≥ria de dados
* Solu√ß√£o criativa de problemas

#### 4. Alta Complexidade, Alta Precis√£o

**Caracter√≠sticas:**

* Fluxos de trabalho complexos que requerem sa√≠das estruturadas
* M√∫ltiplas etapas interdependentes com r√≠gida exig√™ncia de precis√£o
* Necessidade tanto de processamento sofisticado quanto de resultados precisos
* Frequentemente aplica√ß√µes cr√≠ticas

**Abordagem Recomendada:** Flows orquestrando m√∫ltiplas Crews com etapas de valida√ß√£o

**Exemplos de Casos de Uso:**

* Sistemas corporativos de suporte √† decis√£o
* Pipelines complexos de processamento de dados
* Processamento de documentos em m√∫ltiplos est√°gios
* Aplica√ß√µes em ind√∫strias reguladas

## Escolhendo Entre Crews e Flows

### Quando Escolher Crews

Crews s√£o ideais quando:

1. **Voc√™ precisa de intelig√™ncia colaborativa** - M√∫ltiplos agentes com especializa√ß√µes diferentes precisam trabalhar juntos
2. **O problema requer pensamento emergente** - A solu√ß√£o se beneficia de diferentes perspectivas e abordagens
3. **A tarefa √© principalmente criativa ou anal√≠tica** - O trabalho envolve pesquisa, cria√ß√£o de conte√∫do ou an√°lise
4. **Voc√™ valoriza adaptabilidade mais do que estrutura r√≠gida** - O fluxo de trabalho pode se beneficiar da autonomia dos agentes
5. **O formato da sa√≠da pode ser um pouco flex√≠vel** - Alguma varia√ß√£o na estrutura do resultado √© aceit√°vel

```python
# Example: Research Crew for market analysis
from crewai import Agent, Crew, Process, Task

# Create specialized agents
researcher = Agent(
    role="Market Research Specialist",
    goal="Find comprehensive market data on emerging technologies",
    backstory="You are an expert at discovering market trends and gathering data."
)

analyst = Agent(
    role="Market Analyst",
    goal="Analyze market data and identify key opportunities",
    backstory="You excel at interpreting market data and spotting valuable insights."
)

# Define their tasks
research_task = Task(
    description="Research the current market landscape for AI-powered healthcare solutions",
    expected_output="Comprehensive market data including key players, market size, and growth trends",
    agent=researcher
)

analysis_task = Task(
    description="Analyze the market data and identify the top 3 investment opportunities",
    expected_output="Analysis report with 3 recommended investment opportunities and rationale",
    agent=analyst,
    context=[research_task]
)

# Create the crew
market_analysis_crew = Crew(
    agents=[researcher, analyst],
    tasks=[research_task, analysis_task],
    process=Process.sequential,
    verbose=True
)

# Run the crew
result = market_analysis_crew.kickoff()
```

### Quando Escolher Flows

Flows s√£o ideais quando:

1. **Voc√™ precisa de controle preciso da execu√ß√£o** - O fluxo de trabalho exige sequenciamento exato e gerenciamento de estado
2. **A aplica√ß√£o tem requisitos complexos de estado** - Voc√™ precisa manter e transformar estado ao longo de m√∫ltiplas etapas
3. **Voc√™ precisa de sa√≠das estruturadas e previs√≠veis** - A aplica√ß√£o exige resultados consistentes e formatados
4. **O fluxo de trabalho envolve l√≥gica condicional** - Caminhos diferentes precisam ser seguidos com base em resultados intermedi√°rios
5. **Voc√™ precisa combinar IA com c√≥digo procedural** - A solu√ß√£o demanda tanto capacidades de IA quanto programa√ß√£o tradicional

```python
# Example: Customer Support Flow with structured processing
from crewai.flow.flow import Flow, listen, router, start
from pydantic import BaseModel
from typing import List, Dict

# Define structured state
class SupportTicketState(BaseModel):
    ticket_id: str = ""
    customer_name: str = ""
    issue_description: str = ""
    category: str = ""
    priority: str = "medium"
    resolution: str = ""
    satisfaction_score: int = 0

class CustomerSupportFlow(Flow[SupportTicketState]):
    @start()
    def receive_ticket(self):
        # In a real app, this might come from an API
        self.state.ticket_id = "TKT-12345"
        self.state.customer_name = "Alex Johnson"
        self.state.issue_description = "Unable to access premium features after payment"
        return "Ticket received"

    @listen(receive_ticket)
    def categorize_ticket(self, _):
        # Use a direct LLM call for categorization
        from crewai import LLM
        llm = LLM(model="openai/gpt-4o-mini")

        prompt = f"""
        Categorize the following customer support issue into one of these categories:
        - Billing
        - Account Access
        - Technical Issue
        - Feature Request
        - Other

        Issue: {self.state.issue_description}

        Return only the category name.
        """

        self.state.category = llm.call(prompt).strip()
        return self.state.category

    @router(categorize_ticket)
    def route_by_category(self, category):
        # Route to different handlers based on category
        return category.lower().replace(" ", "_")

    @listen("billing")
    def handle_billing_issue(self):
        # Handle billing-specific logic
        self.state.priority = "high"
        # More billing-specific processing...
        return "Billing issue handled"

    @listen("account_access")
    def handle_access_issue(self):
        # Handle access-specific logic
        self.state.priority = "high"
        # More access-specific processing...
        return "Access issue handled"

    # Additional category handlers...

    @listen("billing", "account_access", "technical_issue", "feature_request", "other")
    def resolve_ticket(self, resolution_info):
        # Final resolution step
        self.state.resolution = f"Issue resolved: {resolution_info}"
        return self.state.resolution

# Run the flow
support_flow = CustomerSupportFlow()
result = support_flow.kickoff()
```

### Quando Combinar Crews e Flows

As aplica√ß√µes mais sofisticadas frequentemente se beneficiam da combina√ß√£o de Crews e Flows:

1. **Processos complexos em m√∫ltiplos est√°gios** - Use Flows para orquestrar o processo geral e Crews para sub-tarefas complexas
2. **Aplica√ß√µes que exigem criatividade e estrutura** - Use Crews para tarefas criativas e Flows para processamento estruturado
3. **Aplica√ß√µes corporativas de IA** - Use Flows para gerenciar estado e fluxo de processo enquanto aproveita Crews para tarefas especializadas

```python
# Example: Content Production Pipeline combining Crews and Flows
from crewai.flow.flow import Flow, listen, start
from crewai import Agent, Crew, Process, Task
from pydantic import BaseModel
from typing import List, Dict

class ContentState(BaseModel):
    topic: str = ""
    target_audience: str = ""
    content_type: str = ""
    outline: Dict = {}
    draft_content: str = ""
    final_content: str = ""
    seo_score: int = 0

class ContentProductionFlow(Flow[ContentState]):
    @start()
    def initialize_project(self):
        # Set initial parameters
        self.state.topic = "Sustainable Investing"
        self.state.target_audience = "Millennial Investors"
        self.state.content_type = "Blog Post"
        return "Project initialized"

    @listen(initialize_project)
    def create_outline(self, _):
        # Use a research crew to create an outline
        researcher = Agent(
            role="Content Researcher",
            goal=f"Research {self.state.topic} for {self.state.target_audience}",
            backstory="You are an expert researcher with deep knowledge of content creation."
        )

        outliner = Agent(
            role="Content Strategist",
            goal=f"Create an engaging outline for a {self.state.content_type}",
            backstory="You excel at structuring content for maximum engagement."
        )

        research_task = Task(
            description=f"Research {self.state.topic} focusing on what would interest {self.state.target_audience}",
            expected_output="Comprehensive research notes with key points and statistics",
            agent=researcher
        )

        outline_task = Task(
            description=f"Create an outline for a {self.state.content_type} about {self.state.topic}",
            expected_output="Detailed content outline with sections and key points",
            agent=outliner,
            context=[research_task]
        )

        outline_crew = Crew(
            agents=[researcher, outliner],
            tasks=[research_task, outline_task],
            process=Process.sequential,
            verbose=True
        )

        # Run the crew and store the result
        result = outline_crew.kickoff()

        # Parse the outline (in a real app, you might use a more robust parsing approach)
        import json
        try:
            self.state.outline = json.loads(result.raw)
        except:
            # Fallback if not valid JSON
            self.state.outline = {"sections": result.raw}

        return "Outline created"

    @listen(create_outline)
    def write_content(self, _):
        # Use a writing crew to create the content
        writer = Agent(
            role="Content Writer",
            goal=f"Write engaging content for {self.state.target_audience}",
            backstory="You are a skilled writer who creates compelling content."
        )

        editor = Agent(
            role="Content Editor",
            goal="Ensure content is polished, accurate, and engaging",
            backstory="You have a keen eye for detail and a talent for improving content."
        )

        writing_task = Task(
            description=f"Write a {self.state.content_type} about {self.state.topic} following this outline: {self.state.outline}",
            expected_output="Complete draft content in markdown format",
            agent=writer
        )

        editing_task = Task(
            description="Edit and improve the draft content for clarity, engagement, and accuracy",
            expected_output="Polished final content in markdown format",
            agent=editor,
            context=[writing_task]
        )

        writing_crew = Crew(
            agents=[writer, editor],
            tasks=[writing_task, editing_task],
            process=Process.sequential,
            verbose=True
        )

        # Run the crew and store the result
        result = writing_crew.kickoff()
        self.state.final_content = result.raw

        return "Content created"

    @listen(write_content)
    def optimize_for_seo(self, _):
        # Use a direct LLM call for SEO optimization
        from crewai import LLM
        llm = LLM(model="openai/gpt-4o-mini")

        prompt = f"""
        Analyze this content for SEO effectiveness for the keyword "{self.state.topic}".
        Rate it on a scale of 1-100 and provide 3 specific recommendations for improvement.

        Content: {self.state.final_content[:1000]}... (truncated for brevity)

        Format your response as JSON with the following structure:
        {{
            "score": 85,
            "recommendations": [
                "Recommendation 1",
                "Recommendation 2",
                "Recommendation 3"
            ]
        }}
        """

        seo_analysis = llm.call(prompt)

        # Parse the SEO analysis
        import json
        try:
            analysis = json.loads(seo_analysis)
            self.state.seo_score = analysis.get("score", 0)
            return analysis
        except:
            self.state.seo_score = 50
            return {"score": 50, "recommendations": ["Unable to parse SEO analysis"]}

# Run the flow
content_flow = ContentProductionFlow()
result = content_flow.kickoff()
```

## Framework Pr√°tico de Avalia√ß√£o

Para determinar a abordagem certa para seu caso de uso espec√≠fico, siga este framework passo a passo:

### Passo 1: Avalie a Complexidade

Classifique a complexidade do seu aplicativo numa escala de 1-10 considerando:

1. **N√∫mero de etapas**: Quantas opera√ß√µes distintas s√£o necess√°rias?
   * 1-3 etapas: Baixa complexidade (1-3)
   * 4-7 etapas: M√©dia complexidade (4-7)
   * 8+ etapas: Alta complexidade (8-10)

2. **Interdepend√™ncias**: Qu√£o interligadas est√£o as partes diferentes?
   * Poucas depend√™ncias: Baixa complexidade (1-3)
   * Algumas depend√™ncias: M√©dia complexidade (4-7)
   * Muitas depend√™ncias complexas: Alta complexidade (8-10)

3. **L√≥gica condicional**: Quanto de ramifica√ß√£o e tomada de decis√£o √© necess√°rio?
   * Processo linear: Baixa complexidade (1-3)
   * Alguma ramifica√ß√£o: M√©dia complexidade (4-7)
   * √Årvores de decis√£o complexas: Alta complexidade (8-10)

4. **Conhecimento de dom√≠nio**: Qu√£o especializado deve ser o conhecimento requerido?
   * Conhecimento geral: Baixa complexidade (1-3)
   * Algum conhecimento especializado: M√©dia complexidade (4-7)
   * Grande especializa√ß√£o em m√∫ltiplos dom√≠nios: Alta complexidade (8-10)

Calcule a m√©dia das pontua√ß√µes para determinar sua complexidade geral.

### Passo 2: Avalie os Requisitos de Precis√£o

Classifique seus requisitos de precis√£o numa escala de 1-10 considerando:

1. **Estrutura da sa√≠da**: Qu√£o estruturado o resultado deve ser?
   * Texto livre: Baixa precis√£o (1-3)
   * Semi-estruturado: M√©dia precis√£o (4-7)
   * Estritamente formatado (JSON, XML): Alta precis√£o (8-10)

2. **Necessidade de exatid√£o**: Qual a import√¢ncia da precis√£o factual?
   * Conte√∫do criativo: Baixa precis√£o (1-3)
   * Conte√∫do informacional: M√©dia precis√£o (4-7)
   * Informa√ß√£o cr√≠tica: Alta precis√£o (8-10)

3. **Reprodutibilidade**: Qu√£o consistentes devem ser os resultados entre execu√ß√µes?
   * Varia√ß√£o aceit√°vel: Baixa precis√£o (1-3)
   * Alguma consist√™ncia necess√°ria: M√©dia precis√£o (4-7)
   * Exata reprodutibilidade: Alta precis√£o (8-10)

4. **Toler√¢ncia a erros**: Qual o impacto de erros?
   * Baixo impacto: Baixa precis√£o (1-3)
   * Impacto moderado: M√©dia precis√£o (4-7)
   * Alto impacto: Alta precis√£o (8-10)

Calcule a m√©dia das pontua√ß√µes para determinar seu requisito geral de precis√£o.

### Passo 3: Mapeie na Matriz

Plote as pontua√ß√µes de complexidade e precis√£o na matriz:

* **Baixa Complexidade (1-4), Baixa Precis√£o (1-4)**: Crews simples
* **Baixa Complexidade (1-4), Alta Precis√£o (5-10)**: Flows com chamadas diretas a LLM
* **Alta Complexidade (5-10), Baixa Precis√£o (1-4)**: Crews complexas
* **Alta Complexidade (5-10), Alta Precis√£o (5-10)**: Flows orquestrando Crews

### Passo 4: Considere Fatores Adicionais

Al√©m de complexidade e precis√£o, considere:

1. **Tempo de desenvolvimento**: Crews costumam ser mais r√°pidas para prototipar
2. **Necessidades de manuten√ß√£o**: Flows proporcionam melhor manuten√ß√£o a longo prazo
3. **Expertise do time**: Considere a familiaridade de sua equipe com as abordagens
4. **Requisitos de escalabilidade**: Flows normalmente escalam melhor para aplica√ß√µes complexas
5. **Necessidades de integra√ß√£o**: Considere como a solu√ß√£o se integrar√° aos sistemas existentes

## Conclus√£o

Escolher entre Crews e Flows ‚Äî ou combin√°-los ‚Äî √© uma decis√£o arquitet√¥nica cr√≠tica que impacta a efetividade, manutenibilidade e escalabilidade da sua aplica√ß√£o CrewAI. Ao avaliar seu caso de uso nas dimens√µes de complexidade e precis√£o, voc√™ toma decis√µes inteligentes que alinham-se aos seus requisitos.

Lembre-se de que a melhor abordagem geralmente evolui na medida em que sua aplica√ß√£o amadurece. Comece com a solu√ß√£o mais simples que atenda √†s suas necessidades e esteja preparado para refinar sua arquitetura conforme for ganhando experi√™ncia e seus requisitos se tornarem mais claros.

<Check>
  Agora voc√™ tem um framework para avaliar casos de uso CrewAI e escolher a abordagem certa de acordo com requisitos de complexidade e precis√£o. Isso vai ajudar voc√™ a construir aplica√ß√µes de IA mais eficientes, de f√°cil manuten√ß√£o e escal√°veis.
</Check>

## Pr√≥ximos Passos

* Saiba mais sobre [como criar agentes eficazes](/pt-BR/guides/agents/crafting-effective-agents)
* Explore [como construir sua primeira crew](/pt-BR/guides/crews/first-crew)
* Aprofunde-se em [gerenciamento de estado em flows](/pt-BR/guides/flows/mastering-flow-state)
* Confira os [conceitos centrais](/pt-BR/concepts/agents) para um entendimento mais aprofundado


# Monte sua Primeira Crew
Source: https://docs.crewai.com/pt-BR/guides/crews/first-crew

Tutorial passo a passo para criar uma equipe colaborativa de IA que trabalha junta para resolver problemas complexos.

## Liberando o Poder da IA Colaborativa

Imagine ter uma equipe de agentes de IA especializados trabalhando juntos de forma harmoniosa para resolver problemas complexos, cada um contribuindo com suas habilidades √∫nicas para alcan√ßar um objetivo comum. Esse √© o poder da CrewAI ‚Äì um framework que permite criar sistemas colaborativos de IA que podem realizar tarefas muito al√©m do que uma √∫nica IA conseguiria sozinha.

Neste guia, vamos criar uma crew de pesquisa que ir√° nos ajudar a pesquisar e analisar um tema, e ent√£o criar um relat√≥rio abrangente. Este exemplo pr√°tico demonstra como agentes de IA podem colaborar para realizar tarefas complexas, mas √© apenas o come√ßo do que √© poss√≠vel com a CrewAI.

### O que Voc√™ Vai Construir e Aprender

Ao final deste guia, voc√™ ter√°:

1. **Criado uma equipe de pesquisa em IA especializada** com pap√©is e responsabilidades distintas
2. **Orquestrado a colabora√ß√£o** entre m√∫ltiplos agentes de IA
3. **Automatizado um fluxo de trabalho complexo** que envolve coleta de informa√ß√µes, an√°lise e gera√ß√£o de relat√≥rios
4. **Desenvolvido habilidades fundamentais** que podem ser aplicadas em projetos mais ambiciosos

Embora estejamos criando uma crew de pesquisa simples neste guia, os mesmos padr√µes e t√©cnicas podem ser aplicados para criar equipes muito mais sofisticadas para tarefas como:

* Cria√ß√£o de conte√∫do em m√∫ltiplas etapas com redatores, editores e checadores de fatos especializados
* Sistemas de atendimento ao cliente complexos com agentes de suporte em diferentes n√≠veis
* Analistas de neg√≥cios aut√¥nomos que coletam dados, criam visualiza√ß√µes e geram insights
* Equipes de desenvolvimento de produto que idealizam, projetam e planejam a implementa√ß√£o

Vamos come√ßar a construir sua primeira crew!

### Pr√©-requisitos

Antes de come√ßar, certifique-se de que voc√™:

1. Instalou a CrewAI seguindo o [guia de instala√ß√£o](/pt-BR/installation)
2. Configurou sua chave de API de LLM no ambiente, conforme o [guia de configura√ß√£o do LLM](/pt-BR/concepts/llms#setting-up-your-llm)
3. Tem conhecimento b√°sico de Python

## Passo 1: Crie um Novo Projeto CrewAI

Primeiro, vamos criar um novo projeto CrewAI usando a CLI. Este comando ir√° configurar toda a estrutura do projeto com os arquivos necess√°rios, permitindo que voc√™ foque em definir seus agentes e suas tarefas, em vez de se preocupar com c√≥digo boilerplate.

```bash
crewai create crew research_crew
cd research_crew
```

Isso ir√° gerar um projeto com a estrutura b√°sica necess√°ria para sua crew. A CLI cria automaticamente:

* Um diret√≥rio de projeto com os arquivos necess√°rios
* Arquivos de configura√ß√£o para agentes e tarefas
* Uma implementa√ß√£o b√°sica da crew
* Um script principal para rodar a crew

<Frame caption="CrewAI Framework Overview">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crews.png" alt="CrewAI Framework Overview" />
</Frame>

## Passo 2: Explore a Estrutura do Projeto

Vamos dedicar um momento para entender a estrutura do projeto criada pela CLI. A CrewAI segue boas pr√°ticas para projetos Python, tornando f√°cil manter e estender seu c√≥digo √† medida que suas crews se tornam mais complexas.

```
research_crew/
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ .env
‚îî‚îÄ‚îÄ src/
    ‚îî‚îÄ‚îÄ research_crew/
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îú‚îÄ‚îÄ main.py
        ‚îú‚îÄ‚îÄ crew.py
        ‚îú‚îÄ‚îÄ tools/
        ‚îÇ   ‚îú‚îÄ‚îÄ custom_tool.py
        ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
        ‚îî‚îÄ‚îÄ config/
            ‚îú‚îÄ‚îÄ agents.yaml
            ‚îî‚îÄ‚îÄ tasks.yaml
```

Esta estrutura segue as melhores pr√°ticas para projetos Python e facilita a organiza√ß√£o do seu c√≥digo. A separa√ß√£o dos arquivos de configura√ß√£o (em YAML) do c√≥digo de implementa√ß√£o (em Python) permite modificar o comportamento da sua crew sem alterar o c√≥digo subjacente.

## Passo 3: Configure seus Agentes

Agora vem a parte divertida ‚Äì definir seus agentes de IA! Na CrewAI, agentes s√£o entidades especializadas com pap√©is, objetivos e hist√≥ricos espec√≠ficos que moldam seu comportamento. Pense neles como personagens em uma pe√ßa, cada um com sua personalidade e prop√≥sito pr√≥prios.

Para nossa crew de pesquisa, vamos criar dois agentes:

1. Um **pesquisador** que √© especialista em encontrar e organizar informa√ß√µes
2. Um **analista** que pode interpretar os resultados da pesquisa e criar relat√≥rios perspicazes

Vamos modificar o arquivo `agents.yaml` para definir esses agentes especializados. Certifique-se de
definir `llm` para o provedor que voc√™ est√° utilizando.

```yaml
# src/research_crew/config/agents.yaml
researcher:
  role: >
    Especialista S√™nior em Pesquisa para {topic}
  goal: >
    Encontrar informa√ß√µes abrangentes e precisas sobre {topic}
    com foco em desenvolvimentos recentes e insights chave
  backstory: >
    Voc√™ √© um especialista em pesquisa experiente com talento para
    encontrar informa√ß√µes relevantes de diversas fontes. Voc√™ se destaca em
    organizar informa√ß√µes de forma clara e estruturada, tornando temas complexos acess√≠veis para outros.
  llm: provider/model-id  # ex: openai/gpt-4o, google/gemini-2.0-flash, anthropic/claude...

analyst:
  role: >
    Analista de Dados e Redator de Relat√≥rios para {topic}
  goal: >
    Analisar os resultados da pesquisa e criar um relat√≥rio abrangente e bem estruturado
    que apresente os insights de forma clara e envolvente
  backstory: >
    Voc√™ √© um analista habilidoso com experi√™ncia em interpreta√ß√£o de dados
    e reda√ß√£o t√©cnica. Tem talento para identificar padr√µes
    e extrair insights relevantes dos dados de pesquisa, comunicando esses insights de forma eficaz por meio de relat√≥rios bem elaborados.
  llm: provider/model-id  # ex: openai/gpt-4o, google/gemini-2.0-flash, anthropic/claude...
```

Perceba como cada agente tem um papel, objetivo e hist√≥rico distintos. Esses elementos n√£o s√£o apenas descritivos ‚Äì eles efetivamente moldam como o agente aborda suas tarefas. Ao criar cuidadosamente esses detalhes, voc√™ pode ter agentes com habilidades e perspectivas que se complementam.

## Passo 4: Defina suas Tarefas

Com nossos agentes definidos, agora precisamos atribuir tarefas espec√≠ficas para eles realizarem. Tarefas na CrewAI representam o trabalho concreto que os agentes ir√£o executar, com instru√ß√µes detalhadas e sa√≠das esperadas.

Para nossa crew de pesquisa, vamos definir duas tarefas principais:

1. Uma **tarefa de pesquisa** para coletar informa√ß√µes abrangentes
2. Uma **tarefa de an√°lise** para criar um relat√≥rio com insights

Vamos modificar o arquivo `tasks.yaml`:

```yaml
# src/research_crew/config/tasks.yaml
research_task:
  description: >
    Realize uma pesquisa aprofundada sobre {topic}. Foque em:
    1. Conceitos e defini√ß√µes chave
    2. Desenvolvimento hist√≥rico e tend√™ncias recentes
    3. Principais desafios e oportunidades
    4. Aplica√ß√µes relevantes ou estudos de caso
    5. Perspectivas futuras e novos desenvolvimentos

    Certifique-se de organizar seus achados em um formato estruturado, com se√ß√µes claras.
  expected_output: >
    Um documento de pesquisa abrangente com se√ß√µes bem organizadas cobrindo
    todos os aspectos solicitados de {topic}. Inclua fatos, n√∫meros
    e exemplos espec√≠ficos sempre que poss√≠vel.
  agent: researcher

analysis_task:
  description: >
    Analise os resultados da pesquisa e crie um relat√≥rio abrangente sobre {topic}.
    Seu relat√≥rio deve:
    1. Iniciar com um resumo executivo
    2. Incluir todas as informa√ß√µes relevantes da pesquisa
    3. Oferecer uma an√°lise perspicaz de tend√™ncias e padr√µes
    4. Apresentar recomenda√ß√µes ou considera√ß√µes futuras
    5. Estar formatado de forma profissional, clara e com t√≠tulos bem definidos
  expected_output: >
    Um relat√≥rio profissional, polido e estruturado sobre {topic} com apresenta√ß√£o dos resultados da pesquisa,
    acrescentando an√°lise e insights. O relat√≥rio deve ser bem estruturado,
    incluindo resumo executivo, sess√µes principais e conclus√£o.
  agent: analyst
  context:
    - research_task
  output_file: output/report.md
```

Note o campo `context` na tarefa de an√°lise ‚Äì esse √© um recurso poderoso que permite ao analista acessar a sa√≠da da tarefa de pesquisa. Isso cria um fluxo de trabalho em que a informa√ß√£o circula naturalmente entre os agentes, como aconteceria em uma equipe humana.

## Passo 5: Configure sua Crew

Agora √© hora de juntar tudo configurando nossa crew. A crew √© o container que orquestra como os agentes trabalham juntos para completar as tarefas.

Vamos modificar o arquivo `crew.py`:

```python
# src/research_crew/crew.py
from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task
from crewai_tools import SerperDevTool
from crewai.agents.agent_builder.base_agent import BaseAgent
from typing import List

@CrewBase
class ResearchCrew():
    """Research crew for comprehensive topic analysis and reporting"""

    agents: List[BaseAgent]
    tasks: List[Task]

    @agent
    def researcher(self) -> Agent:
        return Agent(
            config=self.agents_config['researcher'], # type: ignore[index]
            verbose=True,
            tools=[SerperDevTool()]
        )

    @agent
    def analyst(self) -> Agent:
        return Agent(
            config=self.agents_config['analyst'], # type: ignore[index]
            verbose=True
        )

    @task
    def research_task(self) -> Task:
        return Task(
            config=self.tasks_config['research_task'] # type: ignore[index]
        )

    @task
    def analysis_task(self) -> Task:
        return Task(
            config=self.tasks_config['analysis_task'], # type: ignore[index]
            output_file='output/report.md'
        )

    @crew
    def crew(self) -> Crew:
        """Creates the research crew"""
        return Crew(
            agents=self.agents,
            tasks=self.tasks,
            process=Process.sequential,
            verbose=True,
        )
```

Neste c√≥digo, estamos:

1. Criando o agente pesquisador e equipando-o com o SerperDevTool para buscas web
2. Criando o agente analista
3. Definindo as tarefas de pesquisa e an√°lise
4. Configurando a crew para executar as tarefas sequencialmente (o analista espera o pesquisador terminar)

√â aqui que a m√°gica acontece ‚Äì com poucas linhas de c√≥digo, definimos um sistema colaborativo de IA onde agentes especializados trabalham juntos em um processo coordenado.

## Passo 6: Prepare seu Script Principal

Agora, vamos preparar o script principal que ir√° rodar nossa crew. √â aqui que informamos o tema espec√≠fico que queremos pesquisar.

```python
#!/usr/bin/env python
# src/research_crew/main.py
import os
from research_crew.crew import ResearchCrew

# Crie o diret√≥rio de sa√≠da se n√£o existir
os.makedirs('output', exist_ok=True)

def run():
    """
    Rodar a crew de pesquisa.
    """
    inputs = {
        'topic': 'Intelig√™ncia Artificial na Sa√∫de'
    }

    # Criar e rodar a crew
    result = ResearchCrew().crew().kickoff(inputs=inputs)

    # Imprimir o resultado
    print("\n\n=== RELAT√ìRIO FINAL ===\n\n")
    print(result.raw)

    print("\n\nRelat√≥rio salvo em output/report.md")

if __name__ == "__main__":
    run()
```

Este script prepara o ambiente, define o tema de pesquisa e inicia o trabalho da crew. O poder da CrewAI fica evidente em como esse c√≥digo √© simples ‚Äì toda a complexidade do gerenciamento de m√∫ltiplos agentes de IA √© tratada pelo framework.

## Passo 7: Defina suas Vari√°veis de Ambiente

Crie um arquivo `.env` na raiz do seu projeto com suas chaves de API:

```sh
SERPER_API_KEY=sua_serper_api_key
# Adicione a chave de API do seu provedor tamb√©m.
```

Confira o [guia de configura√ß√£o do LLM](/pt-BR/concepts/llms#setting-up-your-llm) para detalhes sobre como configurar o provedor de sua escolha. Voc√™ pode obter a chave da Serper em [Serper.dev](https://serper.dev/).

## Passo 8: Instale as Depend√™ncias

Instale as depend√™ncias necess√°rias usando a CLI da CrewAI:

```bash
crewai install
```

Este comando ir√°:

1. Ler as depend√™ncias da configura√ß√£o do seu projeto
2. Criar um ambiente virtual se necess√°rio
3. Instalar todos os pacotes necess√°rios

## Passo 9: Execute sua Crew

Agora chega o momento empolgante ‚Äì √© hora de rodar sua crew e assistir √† colabora√ß√£o de IA em a√ß√£o!

```bash
crewai run
```

Ao rodar esse comando, voc√™ ver√° sua crew ganhando vida. O pesquisador ir√° coletar informa√ß√µes sobre o tema especificado, e o analista ir√° criar um relat√≥rio abrangente baseado nessa pesquisa. Voc√™ poder√° acompanhar em tempo real o racioc√≠nio, as a√ß√µes e os resultados dos agentes √† medida que colaboram para concluir as tarefas.

## Passo 10: Revise o Resultado

Ap√≥s a conclus√£o do trabalho da crew, voc√™ encontrar√° o relat√≥rio final em `output/report.md`. O relat√≥rio incluir√°:

1. Um resumo executivo
2. Informa√ß√µes detalhadas sobre o tema
3. An√°lises e insights
4. Recomenda√ß√µes ou considera√ß√µes futuras

Tire um momento para valorizar o que voc√™ realizou ‚Äì voc√™ criou um sistema no qual m√∫ltiplos agentes de IA colaboraram em uma tarefa complexa, cada um contribuindo com suas habilidades especializadas para gerar um resultado maior do que qualquer agente conseguiria sozinho.

## Explorando Outros Comandos da CLI

A CrewAI oferece v√°rios outros comandos √∫teis de CLI para trabalhar com crews:

```bash
# Ver todos os comandos dispon√≠veis
crewai --help

# Rodar a crew
crewai run

# Testar a crew
crewai test

# Resetar as mem√≥rias da crew
crewai reset-memories

# Repetir a partir de uma tarefa espec√≠fica
crewai replay -t <task_id>
```

## O que Mais √© Poss√≠vel: Al√©m da sua Primeira Crew

O que voc√™ construiu neste guia √© s√≥ o come√ßo. As habilidades e padr√µes aprendidos aqui podem ser aplicados para criar sistemas de IA cada vez mais sofisticados. Veja algumas maneiras de expandir sua crew de pesquisa b√°sica:

### Expandindo sua Crew

Voc√™ pode adicionar mais agentes especializados √† sua crew:

* Um **checador de fatos** para verificar as informa√ß√µes encontradas
* Um **visualizador de dados** para criar gr√°ficos e tabelas
* Um **especialista de dom√≠nio** com conhecimento aprofundado em uma √°rea espec√≠fica
* Um **cr√≠tico** para identificar pontos fracos na an√°lise

### Adicionando Ferramentas e Capacidades

Voc√™ pode potencializar seus agentes com ferramentas adicionais:

* Ferramentas de navega√ß√£o web para pesquisa em tempo real
* Ferramentas para CSV ou bancos de dados para an√°lise de dados
* Ferramentas de execu√ß√£o de c√≥digo para processamento de dados
* Conex√µes de API com servi√ßos externos

### Criando Fluxos de Trabalho Mais Complexos

Voc√™ pode implementar processos mais sofisticados:

* Processos hier√°rquicos em que agentes gestores delegam para agentes
* Processos iterativos com loops de feedback para refinamento
* Processos paralelos onde m√∫ltiplos agentes trabalham simultaneamente
* Processos din√¢micos que se adaptam a resultados intermedi√°rios

### Aplicando em Diferentes Dom√≠nios

Os mesmos padr√µes podem ser aplicados para criar crews para:

* **Cria√ß√£o de conte√∫do:** Redatores, editores, checadores de fatos e designers trabalhando juntos
* **Atendimento ao cliente:** Agentes de triagem, especialistas e controle de qualidade atuando colaborativamente
* **Desenvolvimento de produto:** Pesquisadores, designers e planejadores trabalhando em conjunto
* **An√°lise de dados:** Coletores de dados, analistas e especialistas em visualiza√ß√£o

## Pr√≥ximos Passos

Agora que voc√™ montou sua primeira crew, voc√™ pode:

1. Experimentar diferentes configura√ß√µes e personalidades de agentes
2. Testar estruturas de tarefas e fluxos de trabalho mais complexos
3. Implementar ferramentas customizadas para dar novas capacidades aos agentes
4. Aplicar sua crew em outros temas ou dom√≠nios de problemas
5. Explorar [CrewAI Flows](/pt-BR/guides/flows/first-flow) para fluxos de trabalho avan√ßados usando programa√ß√£o procedural

<Check>
  Parab√©ns! Voc√™ construiu com sucesso sua primeira crew com o CrewAI, capaz de pesquisar e analisar qualquer tema que desejar. Essa experi√™ncia fundamental lhe deu as habilidades para criar sistemas de IA cada vez mais sofisticados, aptos a encarar problemas complexos e de m√∫ltiplas etapas por meio da intelig√™ncia colaborativa.
</Check>


# Construa Seu Primeiro Flow
Source: https://docs.crewai.com/pt-BR/guides/flows/first-flow

Aprenda como criar fluxos de trabalho estruturados e orientados a eventos com controle preciso sobre a execu√ß√£o.

## Assumindo o Controle de Workflows de IA com Flows

Os Flows do CrewAI representam o pr√≥ximo n√≠vel em orquestra√ß√£o de IA ‚Äì combinando o poder colaborativo de equipes de agentes de IA com a precis√£o e flexibilidade da programa√ß√£o procedural. Enquanto os crews se destacam em colabora√ß√£o de agentes, os flows d√£o a voc√™ controle detalhado sobre exatamente como e quando diferentes componentes do seu sistema de IA interagem.

Neste guia, vamos percorrer a cria√ß√£o de um poderoso CrewAI Flow que gera um guia de aprendizado abrangente sobre qualquer tema. Este tutorial demonstrar√° como os Flows oferecem controle estruturado e orientado a eventos sobre seus workflows de IA ao combinar c√≥digo regular, chamadas diretas a LLM e processamento baseado em crews.

### O Que Torna os Flows Poderosos

Com flows, voc√™ pode:

1. **Combinar diferentes padr√µes de intera√ß√£o com IA** ‚Äì Use crews para tarefas colaborativas complexas, chamadas diretas √†s LLMs para opera√ß√µes mais simples, e c√≥digo regular para l√≥gica procedural.
2. **Construir sistemas orientados a eventos** ‚Äì Defina como os componentes respondem a eventos e mudan√ßas de dados espec√≠ficos.
3. **Manter estado entre componentes** ‚Äì Compartilhe e transforme dados entre diferentes partes da sua aplica√ß√£o.
4. **Integrar com sistemas externos** ‚Äì Conecte seu fluxo de trabalho de IA com bancos de dados, APIs e interfaces de usu√°rio de forma transparente.
5. **Criar caminhos de execu√ß√£o complexos** ‚Äì Projete ramifica√ß√µes condicionais, processamento paralelo e workflows din√¢micos.

### O Que Voc√™ Vai Construir e Aprender

Ao final deste guia, voc√™ ter√°:

1. **Criado um sistema sofisticado de gera√ß√£o de conte√∫do** que combina entrada do usu√°rio, planejamento por IA e cria√ß√£o de conte√∫do multiagente.
2. **Orquestrado o fluxo de informa√ß√µes** entre diferentes componentes do seu sistema.
3. **Implementado uma arquitetura orientada a eventos** onde cada etapa responde √† conclus√£o das etapas anteriores.
4. **Constru√≠do uma base para aplica√ß√µes de IA mais complexas** que voc√™ pode expandir e personalizar.

Este flow de cria√ß√£o de guia demonstra padr√µes fundamentais que podem ser aplicados para criar aplica√ß√µes muito mais avan√ßadas, como:

* Assistentes de IA interativos que combinam m√∫ltiplos subsistemas especializados.
* Pipelines de processamento de dados complexos com transforma√ß√µes aprimoradas por IA.
* Agentes aut√¥nomos integrados a servi√ßos e APIs externas.
* Sistemas de tomada de decis√£o em m√∫ltiplas etapas com processos envolvendo humanos no loop.

Vamos come√ßar e construir seu primeiro flow!

## Pr√©-requisitos

Antes de come√ßar, certifique-se de ter:

1. Instalado o CrewAI seguindo o [guia de instala√ß√£o](/pt-BR/installation)
2. Configurado sua chave de API LLM no ambiente, conforme o [guia de configura√ß√£o do LLM](/pt-BR/concepts/llms#setting-up-your-llm)
3. Conhecimentos b√°sicos de Python

## Passo 1: Crie um Novo Projeto de CrewAI Flow

Primeiro, vamos criar um novo projeto de Flow do CrewAI usando a CLI. Este comando configura um projeto com todos os diret√≥rios necess√°rios e arquivos de template para seu flow.

```bash
crewai create flow guide_creator_flow
cd guide_creator_flow
```

Isso gerar√° um projeto com a estrutura b√°sica necess√°ria para seu flow.

<Frame caption="Vis√£o Geral do Framework CrewAI">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/flows.png" alt="CrewAI Framework Overview" />
</Frame>

## Passo 2: Entendendo a Estrutura do Projeto

O projeto gerado possui a seguinte estrutura. Reserve um momento para conhec√™-la, pois isso ajudar√° voc√™ a criar flows mais complexos no futuro.

```
guide_creator_flow/
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ crews/
‚îÇ   ‚îî‚îÄ‚îÄ poem_crew/
‚îÇ       ‚îú‚îÄ‚îÄ config/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ agents.yaml
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ tasks.yaml
‚îÇ       ‚îî‚îÄ‚îÄ poem_crew.py
‚îî‚îÄ‚îÄ tools/
    ‚îî‚îÄ‚îÄ custom_tool.py
```

Esta estrutura oferece uma separa√ß√£o clara entre os diferentes componentes do seu flow:

* A l√≥gica principal do flow no arquivo `main.py`
* Crews especializados no diret√≥rio `crews`
* Ferramentas customizadas no diret√≥rio `tools`

Vamos modificar esta estrutura para criar nosso flow de cria√ß√£o de guias, que ir√° orquestrar o processo de gera√ß√£o de guias de aprendizagem abrangentes.

## Passo 3: Adicione um Crew de Redator de Conte√∫do

Nosso flow precisar√° de um crew especializado para lidar com o processo de cria√ß√£o de conte√∫do. Vamos usar a CLI do CrewAI para adicionar um crew de redatores de conte√∫do:

```bash
crewai flow add-crew content-crew
```

Este comando cria automaticamente os diret√≥rios e arquivos de template necess√°rios para seu crew. O crew de redatores ser√° respons√°vel por escrever e revisar se√ß√µes do nosso guia, trabalhando dentro do flow orquestrado pela aplica√ß√£o principal.

## Passo 4: Configure o Crew de Redator de Conte√∫do

Agora, vamos modificar os arquivos gerados para o crew de redatores. Vamos configurar dois agentes especializados ‚Äì um escritor e um revisor ‚Äì que ir√£o colaborar para criar um conte√∫do de alta qualidade para o nosso guia.

1. Primeiro, atualize o arquivo de configura√ß√£o de agents para definir a equipe de cria√ß√£o de conte√∫do:

   Lembre-se de configurar o `llm` com o provedor que est√° utilizando.

```yaml
# src/guide_creator_flow/crews/content_crew/config/agents.yaml
content_writer:
  role: >
    Redator de Conte√∫do Educacional
  goal: >
    Criar conte√∫do envolvente e informativo que explique completamente o tema proposto
    e forne√ßa insights valiosos ao leitor
  backstory: >
    Voc√™ √© um talentoso escritor educacional com experi√™ncia em criar conte√∫do claro
    e atraente. Voc√™ tem facilidade para explicar conceitos complexos em linguagem acess√≠vel
    e organizar as informa√ß√µes de forma a ajudar o leitor a construir seu entendimento.
  llm: provider/model-id  # e.g. openai/gpt-4o, google/gemini-2.0-flash, anthropic/claude...

content_reviewer:
  role: >
    Revisor(a) e Editor(a) de Conte√∫do Educacional
  goal: >
    Garantir que o conte√∫do seja preciso, abrangente, bem estruturado e mantenha
    consist√™ncia com as se√ß√µes previamente escritas
  backstory: >
    Voc√™ √© um editor(a) meticuloso(a) com anos de experi√™ncia revisando conte√∫do educacional.
    Tem aten√ß√£o aos detalhes, clareza e coes√£o. Voc√™ se destaca em aprimorar conte√∫do
    mantendo o estilo do autor original e garantindo qualidade consistente em v√°rias se√ß√µes.
  llm: provider/model-id  # e.g. openai/gpt-4o, google/gemini-2.0-flash, anthropic/claude...
```

Essas defini√ß√µes de agents estabelecem pap√©is e perspectivas especializadas que ir√£o moldar como nossos agentes de IA abordam a cria√ß√£o de conte√∫do. Note como cada agent possui um prop√≥sito e expertise distintos.

2. Em seguida, atualize o arquivo de configura√ß√£o de tarefas para definir as tarefas espec√≠ficas de escrita e revis√£o:

```yaml
# src/guide_creator_flow/crews/content_crew/config/tasks.yaml
write_section_task:
  description: >
    Escreva uma se√ß√£o abrangente sobre o tema: "{section_title}"

    Descri√ß√£o da se√ß√£o: {section_description}
    P√∫blico-alvo: {audience_level} aprendizes

    Seu conte√∫do deve:
    1. Come√ßar com uma breve introdu√ß√£o ao tema da se√ß√£o
    2. Explicar claramente todos os conceitos principais com exemplos
    3. Incluir aplica√ß√µes pr√°ticas ou exerc√≠cios onde apropriado
    4. Terminar com um resumo dos pontos principais
    5. Ter aproximadamente 500-800 palavras

    Formate seu conte√∫do em Markdown com t√≠tulos, listas e √™nfase apropriados.

    Se√ß√µes previamente escritas:
    {previous_sections}

    Certifique-se de que seu conte√∫do mantenha consist√™ncia com as se√ß√µes j√° escritas
    e amplie os conceitos que j√° foram explicados.
  expected_output: >
    Uma se√ß√£o bem estruturada e abrangente em formato Markdown que explique
    totalmente o tema e √© apropriada para o p√∫blico-alvo.
  agent: content_writer

review_section_task:
  description: >
    Revise e melhore a seguinte se√ß√£o sobre "{section_title}":

    {draft_content}

    P√∫blico-alvo: {audience_level} aprendizes

    Se√ß√µes previamente escritas:
    {previous_sections}

    Sua revis√£o deve:
    1. Corrigir qualquer erro gramatical ou de ortografia
    2. Melhorar clareza e legibilidade
    3. Garantir que o conte√∫do seja abrangente e preciso
    4. Verificar a consist√™ncia com as se√ß√µes j√° escritas
    5. Aprimorar a estrutura e o fluxo
    6. Adicionar qualquer informa√ß√£o-chave ausente

    Forne√ßa a vers√£o aprimorada da se√ß√£o em formato Markdown.
  expected_output: >
    Uma vers√£o melhorada e refinada da se√ß√£o, mantendo a estrutura original,
    mas aprimorando clareza, precis√£o e consist√™ncia.
  agent: content_reviewer
  context:
    - write_section_task
```

Essas defini√ß√µes de tarefas fornecem instru√ß√µes detalhadas para nossos agents, garantindo que eles produzam conte√∫do que atenda aos padr√µes de qualidade. Observe como o par√¢metro `context` na tarefa de revis√£o cria um fluxo onde o revisor tem acesso √† produ√ß√£o do redator.

3. Agora, atualize o arquivo de implementa√ß√£o do crew para definir como nossos agents e tasks trabalham juntos:

```python
# src/guide_creator_flow/crews/content_crew/content_crew.py
from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task
from crewai.agents.agent_builder.base_agent import BaseAgent
from typing import List

@CrewBase
class ContentCrew():
    """Crew de reda√ß√£o de conte√∫do"""

    agents: List[BaseAgent]
    tasks: List[Task]

    @agent
    def content_writer(self) -> Agent:
        return Agent(
            config=self.agents_config['content_writer'], # type: ignore[index]
            verbose=True
        )

    @agent
    def content_reviewer(self) -> Agent:
        return Agent(
            config=self.agents_config['content_reviewer'], # type: ignore[index]
            verbose=True
        )

    @task
    def write_section_task(self) -> Task:
        return Task(
            config=self.tasks_config['write_section_task'] # type: ignore[index]
        )

    @task
    def review_section_task(self) -> Task:
        return Task(
            config=self.tasks_config['review_section_task'], # type: ignore[index]
            context=[self.write_section_task()]
        )

    @crew
    def crew(self) -> Crew:
        """Cria o crew de reda√ß√£o de conte√∫do"""
        return Crew(
            agents=self.agents,
            tasks=self.tasks,
            process=Process.sequential,
            verbose=True,
        )
```

Essa defini√ß√£o de crew estabelece o relacionamento entre nossos agents e tasks, definindo um processo sequencial onde o redator cria o rascunho e o revisor o aprimora. Embora este crew possa funcionar de forma independente, em nosso flow ele ser√° orquestrado como parte de um sistema maior.

## Passo 5: Crie o Flow

Agora vem a parte emocionante ‚Äì criar o flow que ir√° orquestrar todo o processo de cria√ß√£o do guia. Aqui iremos combinar c√≥digo Python regular, chamadas diretas a LLM e nosso crew de cria√ß√£o de conte√∫do em um sistema coeso.

Nosso flow ir√°:

1. Obter a entrada do usu√°rio sobre o tema e n√≠vel do p√∫blico
2. Fazer uma chamada direta √† LLM para criar um roteiro estruturado do guia
3. Processar cada se√ß√£o sequencialmente usando o crew de redatores
4. Combinar tudo em um documento final abrangente

Vamos criar nosso flow no arquivo `main.py`:

```python
# [C√ìDIGO N√ÉO TRADUZIDO, MANTER COMO EST√Å]
```

Vamos analisar o que est√° acontecendo neste flow:

1. Definimos modelos Pydantic para dados estruturados, garantindo seguran√ßa de tipos e representa√ß√£o clara dos dados.
2. Criamos uma classe de estado para manter dados entre os diferentes passos do flow.
3. Implementamos tr√™s etapas principais para o flow:
   * Obten√ß√£o da entrada do usu√°rio com o decorator `@start()`
   * Cria√ß√£o do roteiro do guia com uma chamada direta √† LLM
   * Processamento das se√ß√µes com nosso crew de conte√∫do
4. Usamos o decorator `@listen()` para estabelecer rela√ß√µes orientadas a eventos entre as etapas

Este √© o poder dos flows ‚Äì combinar diferentes tipos de processamento (intera√ß√£o com usu√°rio, chamadas diretas a IA, tarefas colaborativas com crews) em um sistema orientado a eventos e coeso.

## Passo 6: Configure suas Vari√°veis de Ambiente

Crie um arquivo `.env` na raiz do projeto com suas chaves de API. Veja o [guia de configura√ß√£o do LLM](/pt-BR/concepts/llms#setting-up-your-llm) para detalhes sobre como configurar o provedor.

```sh .env
OPENAI_API_KEY=sua_chave_openai
# ou
GEMINI_API_KEY=sua_chave_gemini
# ou
ANTHROPIC_API_KEY=sua_chave_anthropic
```

## Passo 7: Instale as Depend√™ncias

Instale as depend√™ncias necess√°rias:

```bash
crewai install
```

## Passo 8: Execute Seu Flow

Agora √© hora de ver seu flow em a√ß√£o! Execute-o usando a CLI do CrewAI:

```bash
crewai flow kickoff
```

Quando voc√™ rodar esse comando, ver√° seu flow ganhando vida:

1. Ele solicitar√° um tema e o n√≠vel do p√∫blico para voc√™
2. Criar√° um roteiro estruturado para o seu guia
3. Processar√° cada se√ß√£o, com o redator e o revisor colaborando em cada uma
4. Por fim, ir√° compilar tudo em um guia abrangente

Isso demonstra o poder dos flows para orquestrar processos complexos envolvendo m√∫ltiplos componentes, tanto de IA quanto n√£o-IA.

## Passo 9: Visualize Seu Flow

Uma das funcionalidades mais poderosas dos flows √© a possibilidade de visualizar sua estrutura:

```bash
crewai flow plot
```

Isso ir√° criar um arquivo HTML que mostra a estrutura do seu flow, incluindo os relacionamentos entre etapas e o fluxo de dados. Essa visualiza√ß√£o pode ser inestim√°vel para entender e depurar flows complexos.

## Passo 10: Revise o Resultado

Depois que o flow finalizar, voc√™ encontrar√° dois arquivos no diret√≥rio `output`:

1. `guide_outline.json`: Cont√©m o roteiro estruturado do guia
2. `complete_guide.md`: O guia abrangente com todas as se√ß√µes

Reserve um momento para revisar esses arquivos e apreciar o que voc√™ construiu ‚Äì um sistema que combina entrada do usu√°rio, intera√ß√µes diretas com IA e trabalho colaborativo de agents para produzir um output complexo e de alta qualidade.

## A Arte do Poss√≠vel: Al√©m do Seu Primeiro Flow

O que voc√™ aprendeu neste guia √© uma base para criar sistemas de IA muito mais sofisticados. Veja algumas formas de expandir este flow b√°sico:

### Aprimorando a Intera√ß√£o com o Usu√°rio

Voc√™ pode criar flows mais interativos com:

* Interfaces web para entrada e sa√≠da de dados
* Atualiza√ß√µes em tempo real de progresso
* Loops de feedback e refinamento interativos
* Intera√ß√µes multi-stage com o usu√°rio

### Adicionando Mais Etapas de Processamento

Voc√™ pode expandir seu flow com etapas adicionais para:

* Pesquisa antes da cria√ß√£o do roteiro
* Gera√ß√£o de imagens para ilustra√ß√µes
* Gera√ß√£o de snippets de c√≥digo para guias t√©cnicos
* Garantia de qualidade e checagem final de fatos

### Criando Flows Mais Complexos

Voc√™ pode implementar padr√µes de flow mais sofisticados:

* Ramifica√ß√µes condicionais com base na prefer√™ncia do usu√°rio ou tipo de conte√∫do
* Processamento paralelo de se√ß√µes independentes
* Loops de refinamento iterativo com feedback
* Integra√ß√£o a APIs e servi√ßos externos

### Aplicando a Diferentes Dom√≠nios

Os mesmos padr√µes podem ser usados para criar flows de:

* **Narrativas interativas**: cria√ß√£o de hist√≥rias personalizadas com base na entrada do usu√°rio
* **Intelig√™ncia de neg√≥cios**: processamento de dados, gera√ß√£o de insights e cria√ß√£o de relat√≥rios
* **Desenvolvimento de produtos**: facilita√ß√£o de idea√ß√£o, design e planejamento
* **Sistemas educacionais**: cria√ß√£o de experi√™ncias de aprendizagem personalizadas

## Principais Funcionalidades Demonstradas

Este flow de cria√ß√£o de guia demonstra diversos recursos poderosos do CrewAI:

1. **Intera√ß√£o com o usu√°rio**: O flow coleta input diretamente do usu√°rio
2. **Chamadas diretas √† LLM**: Usa a classe LLM para intera√ß√µes eficientes e direcionadas com IA
3. **Dados estruturados com Pydantic**: Usa Pydantic para garantir seguran√ßa de tipos
4. **Processamento sequencial com contexto**: Escreve se√ß√µes em ordem, fornecendo as anteriores como contexto
5. **Crews multiagentes**: Utiliza agents especializados (redator e revisor) para cria√ß√£o de conte√∫do
6. **Gerenciamento de estado**: Mant√©m estado entre diferentes etapas do processo
7. **Arquitetura orientada a eventos**: Usa o decorator `@listen` para responder a eventos

## Entendendo a Estrutura do Flow

Vamos decompor os principais componentes dos flows para ajud√°-lo a entender como construir o seu:

### 1. Chamadas Diretas √† LLM

Flows permitem que voc√™ fa√ßa chamadas diretas a modelos de linguagem quando precisa de respostas simples e estruturadas:

```python
llm = LLM(
    model="model-id-here",  # gpt-4o, gemini-2.0-flash, anthropic/claude...
    response_format=GuideOutline
)
response = llm.call(messages=messages)
```

Isso √© mais eficiente do que usar um crew quando voc√™ precisa de um output espec√≠fico e estruturado.

### 2. Arquitetura Orientada a Eventos

Flows usam decorators para estabelecer rela√ß√µes entre componentes:

```python
@start()
def get_user_input(self):
    # Primeira etapa no flow
    # ...

@listen(get_user_input)
def create_guide_outline(self, state):
    # Esta roda quando get_user_input √© conclu√≠da
    # ...
```

Isso cria uma estrutura clara e declarativa para sua aplica√ß√£o.

### 3. Gerenciamento de Estado

Flows mant√™m o estado entre as etapas, facilitando o compartilhamento de dados:

```python
class GuideCreatorState(BaseModel):
    topic: str = ""
    audience_level: str = ""
    guide_outline: GuideOutline = None
    sections_content: Dict[str, str] = {}
```

Isso fornece uma maneira segura e tipada de rastrear e transformar dados ao longo do flow.

### 4. Integra√ß√£o com Crews

Flows podem integrar crews para tarefas colaborativas complexas:

```python
result = ContentCrew().crew().kickoff(inputs={
    "section_title": section.title,
    # ...
})
```

Assim, voc√™ usa a ferramenta certa para cada parte da aplica√ß√£o ‚Äì chamadas diretas para tarefas simples e crews para colabora√ß√£o avan√ßada.

## Pr√≥ximos Passos

Agora que voc√™ construiu seu primeiro flow, pode:

1. Experimentar estruturas e padr√µes mais complexos de flow
2. Testar o uso do `@router()` para criar ramifica√ß√µes condicionais em seus flows
3. Explorar as fun√ß√µes `and_` e `or_` para execu√ß√µes paralelas e mais complexas
4. Conectar seu flow a APIs externas, bancos de dados ou interfaces de usu√°rio
5. Combinar m√∫ltiplos crews especializados em um √∫nico flow

<Check>
  Parab√©ns! Voc√™ construiu seu primeiro CrewAI Flow que combina c√≥digo regular, chamadas diretas a LLM e processamento baseado em crews para criar um guia abrangente. Essas habilidades fundamentais permitem criar aplica√ß√µes de IA cada vez mais sofisticadas, capazes de resolver problemas complexos de m√∫ltiplas etapas por meio de controle procedural e intelig√™ncia colaborativa.
</Check>


# Dominando o Gerenciamento de Estado em Flows
Source: https://docs.crewai.com/pt-BR/guides/flows/mastering-flow-state

Um guia abrangente sobre como gerenciar, persistir e utilizar o estado em CrewAI Flows para construir aplica√ß√µes de IA robustas.

## Entendendo o Poder do Estado em Flows

O gerenciamento de estado √© a espinha dorsal de qualquer workflow de IA sofisticado. Nos Flows da CrewAI, o sistema de estado permite manter o contexto, compartilhar dados entre etapas e construir l√≥gicas de aplica√ß√£o complexas. Dominar o gerenciamento de estado √© essencial para criar aplica√ß√µes de IA confi√°veis, sustent√°veis e poderosas.

Este guia vai te levar por tudo o que voc√™ precisa saber sobre como gerenciar o estado em CrewAI Flows, desde conceitos b√°sicos at√© t√©cnicas avan√ßadas, com exemplos pr√°ticos de c√≥digo ao longo do conte√∫do.

### Por Que o Gerenciamento de Estado Importa

Um gerenciamento de estado efetivo possibilita que voc√™:

1. **Mantenha o contexto entre as etapas de execu√ß√£o** ‚Äì Transfira informa√ß√µes de forma transparente entre diferentes est√°gios do seu workflow
2. **Construa l√≥gicas condicionais complexas** ‚Äì Tome decis√µes baseadas nos dados acumulados
3. **Crie aplica√ß√µes persistentes** ‚Äì Salve e recupere o progresso do workflow
4. **Trate erros de forma elegante** ‚Äì Implemente padr√µes de recupera√ß√£o para aplica√ß√µes mais robustas
5. **Escalone suas aplica√ß√µes** ‚Äì Ofere√ßa suporte a workflows complexos com organiza√ß√£o apropriada dos dados
6. **Habilite aplica√ß√µes conversacionais** ‚Äì Armazene e acesse o hist√≥rico da conversa para intera√ß√µes de IA com contexto

Vamos explorar como aproveitar essas capacidades de forma eficiente.

## Fundamentos do Gerenciamento de Estado

### O Ciclo de Vida do Estado em um Flow

Nos Flows da CrewAI, o estado segue um ciclo de vida previs√≠vel:

1. **Inicializa√ß√£o** ‚Äì Quando um flow √© criado, seu estado √© inicializado (como um dicion√°rio vazio ou uma inst√¢ncia de modelo Pydantic)
2. **Modifica√ß√£o** ‚Äì Os m√©todos do flow acessam e modificam o estado durante a execu√ß√£o
3. **Transmiss√£o** ‚Äì O estado √© automaticamente passado entre os m√©todos do flow
4. **Persist√™ncia** (opcional) ‚Äì O estado pode ser salvo em um armazenamento e recuperado posteriormente
5. **Conclus√£o** ‚Äì O estado final reflete as mudan√ßas acumuladas de todos os m√©todos executados

Compreender esse ciclo de vida √© crucial para projetar flows eficientes.

### Duas Abordagens Para Gerenciar Estado

A CrewAI oferece duas maneiras para voc√™ gerenciar o estado nos seus flows:

1. **Estado N√£o Estruturado** ‚Äì Usando objetos do tipo dicion√°rio para mais flexibilidade
2. **Estado Estruturado** ‚Äì Usando modelos Pydantic para seguran√ßa de tipo e valida√ß√£o

Vamos analisar cada abordagem em detalhe.

## Gerenciamento de Estado N√£o Estruturado

O estado n√£o estruturado utiliza uma abordagem semelhante a dicion√°rios, oferecendo flexibilidade e simplicidade para aplica√ß√µes diretas.

### Como Funciona

Com estado n√£o estruturado:

* Voc√™ acessa o estado via `self.state`, que se comporta como um dicion√°rio
* Pode adicionar, modificar ou remover chaves livremente a qualquer momento
* Todo o estado est√° dispon√≠vel automaticamente para todos os m√©todos do flow

### Exemplo B√°sico

Veja um exemplo simples de gerenciamento de estado n√£o estruturado:

```python
# c√≥digo n√£o traduzido
```

### Quando Usar Estado N√£o Estruturado

O estado n√£o estruturado √© ideal para:

* Prototipagem r√°pida e flows simples
* Necessidade de estado que evolui dinamicamente
* Casos onde a estrutura pode n√£o ser conhecida antecipadamente
* Flows com requisitos de estado simples

Embora seja flex√≠vel, o estado n√£o estruturado n√£o possui checagem de tipos nem valida√ß√£o de esquema, o que pode gerar erros em aplica√ß√µes mais complexas.

## Gerenciamento de Estado Estruturado

O estado estruturado utiliza modelos Pydantic para definir um esquema para o estado do seu flow, provendo seguran√ßa de tipo, valida√ß√£o e melhor experi√™ncia de desenvolvimento.

### Como Funciona

Ao utilizar estado estruturado:

* Voc√™ define um modelo Pydantic que representa a estrutura do seu estado
* Passa este tipo de modelo para sua classe Flow como par√¢metro de tipo
* Acessa o estado via `self.state`, que se comporta como uma inst√¢ncia do modelo Pydantic
* Todos os campos s√£o validados de acordo com os tipos definidos
* O IDE oferece autocompletar e suporte √† checagem de tipos

### Exemplo B√°sico

Veja como implementar o gerenciamento de estado estruturado:

```python
# c√≥digo n√£o traduzido
```

### Benef√≠cios do Estado Estruturado

Utilizar estado estruturado traz v√°rias vantagens:

1. **Seguran√ßa de Tipo** ‚Äì Detecte erros de tipo durante o desenvolvimento
2. **Autodocumenta√ß√£o** ‚Äì O modelo de estado documenta claramente quais dados est√£o dispon√≠veis
3. **Valida√ß√£o** ‚Äì Valida√ß√£o autom√°tica de tipos de dados e restri√ß√µes
4. **Suporte do IDE** ‚Äì Obtenha autocompletar e documenta√ß√£o inline
5. **Valores Padr√£o** ‚Äì Defina facilmente valores padr√µes para falta de dados

### Quando Usar Estado Estruturado

O estado estruturado √© recomendado para:

* Flows complexos com esquemas de dados bem definidos
* Projetos em equipe com m√∫ltiplos desenvolvedores no mesmo c√≥digo
* Aplica√ß√µes onde a valida√ß√£o de dados √© importante
* Flows que precisam impor tipos de dados e restri√ß√µes espec√≠ficas

## O ID de Estado Autom√°tico

Tanto estados n√£o estruturados quanto estruturados recebem automaticamente um identificador √∫nico (UUID) para ajudar a rastrear e gerenciar inst√¢ncias de estado.

### Como Funciona

* Para estado n√£o estruturado, o ID √© acess√≠vel via `self.state["id"]`
* Para estado estruturado, o ID √© acess√≠vel via `self.state.id`
* Este ID √© gerado automaticamente ao criar o flow
* O ID permanece igual durante todo o ciclo de vida do flow
* O ID pode ser usado para rastreamento, logs e recupera√ß√£o de estados persistidos

Este UUID √© √∫til especialmente ao implementar persist√™ncia ou monitorar m√∫ltiplas execu√ß√µes de flows.

## Atualiza√ß√µes Din√¢micas de Estado

Independente de voc√™ usar estado estruturado ou n√£o estruturado, √© poss√≠vel atualizar o estado dinamicamente ao longo da execu√ß√£o do flow.

### Passando Dados Entre Etapas

M√©todos do flow podem retornar valores que ser√£o passados como argumento para m√©todos listeners:

```python
# c√≥digo n√£o traduzido
```

Esse padr√£o permite combinar passagem de dados direta com atualiza√ß√µes de estado para obter m√°xima flexibilidade.

## Persistindo o Estado do Flow

Uma das funcionalidades mais poderosas da CrewAI √© a habilidade de persistir o estado do flow entre execu√ß√µes. Isso habilita workflows que podem ser pausados, retomados e at√© recuperados ap√≥s falhas.

### O Decorador @persist()

O decorador `@persist()` automatiza a persist√™ncia de estado, salvando o estado do flow em pontos chave da execu√ß√£o.

#### Persist√™ncia em N√≠vel de Classe

Ao aplicar em n√≠vel de classe, `@persist()` salva o estado ap√≥s cada execu√ß√£o de m√©todo:

```python
# c√≥digo n√£o traduzido
```

#### Persist√™ncia em N√≠vel de M√©todo

Para mais controle, voc√™ pode aplicar `@persist()` em m√©todos espec√≠ficos:

```python
# c√≥digo n√£o traduzido
```

## Padr√µes Avan√ßados de Estado

### L√≥gica Condicional Baseada no Estado

Voc√™ pode usar o estado para implementar l√≥gicas condicionais complexas em seus flows:

```python
# c√≥digo n√£o traduzido
```

### Manipula√ß√µes Complexas de Estado

Para transformar estados complexos, voc√™ pode criar m√©todos dedicados:

```python
# c√≥digo n√£o traduzido
```

Esse padr√£o de criar m√©todos auxiliares mant√©m seus m√©todos de flow limpos, enquanto permite manipula√ß√µes complexas de estado.

## Gerenciamento de Estado com Crews

Um dos padr√µes mais poderosos na CrewAI √© combinar o gerenciamento de estado do flow com a execu√ß√£o de crews.

### Passando Estado para Crews

Voc√™ pode usar o estado do flow para parametrizar crews:

```python
# c√≥digo n√£o traduzido
```

### Manipulando Sa√≠das de Crews no Estado

Quando um crew finaliza, √© poss√≠vel processar sua sa√≠da e armazen√°-la no estado do flow:

```python
# c√≥digo n√£o traduzido
```

## Boas Pr√°ticas para Gerenciamento de Estado

### 1. Mantenha o Estado Focado

Projete seu estado para conter somente o necess√°rio:

```python
# Exemplo n√£o traduzido
```

### 2. Use Estado Estruturado em Flows Complexos

√Ä medida que seus flows evoluem em complexidade, o estado estruturado se torna cada vez mais valioso:

```python
# Exemplo n√£o traduzido
```

### 3. Documente Transi√ß√µes de Estado

Para flows complexos, documente como o estado muda ao longo da execu√ß√£o:

```python
# Exemplo n√£o traduzido
```

### 4. Trate Erros de Estado de Forma Elegante

Implemente tratamento de erros ao acessar o estado:

```python
# Exemplo n√£o traduzido
```

### 5. Use o Estado Para Acompanhar o Progresso

Aproveite o estado para monitorar o progresso em flows de longa dura√ß√£o:

```python
# Exemplo n√£o traduzido
```

### 6. Prefira Opera√ß√µes Imut√°veis Quando Poss√≠vel

Especialmente com estado estruturado, prefira opera√ß√µes imut√°veis para maior clareza:

```python
# Exemplo n√£o traduzido
```

## Depurando o Estado do Flow

### Logando Altera√ß√µes no Estado

Ao desenvolver, adicione logs para acompanhar mudan√ßas no estado:

```python
# Exemplo n√£o traduzido
```

### Visualizando o Estado

Voc√™ pode adicionar m√©todos para visualizar seu estado durante o debug:

```python
# Exemplo n√£o traduzido
```

## Conclus√£o

Dominar o gerenciamento de estado em CrewAI Flows te d√° poder para construir aplica√ß√µes de IA sofisticadas e robustas, que mant√™m contexto, tomam decis√µes complexas e entregam resultados consistentes.

Seja escolhendo estado n√£o estruturado ou estruturado, implementar boas pr√°ticas de gerenciamento de estado ir√° ajudar a criar flows manten√≠veis, extens√≠veis e eficazes na resolu√ß√£o de problemas do mundo real.

√Ä medida que desenvolver flows mais complexos, lembre-se de que um bom gerenciamento de estado est√° relacionado ao equil√≠brio entre flexibilidade e estrutura, tornando seu c√≥digo tanto poderoso quanto f√°cil de entender.

<Check>
  Agora voc√™ domina os conceitos e pr√°ticas de gerenciamento de estado em CrewAI Flows! Com este conhecimento, voc√™ pode criar workflows de IA robustos que mant√™m contexto, compartilham dados entre as etapas e constroem l√≥gicas avan√ßadas de aplica√ß√£o.
</Check>

## Pr√≥ximos Passos

* Experimente usar estado estruturado e n√£o estruturado em seus flows
* Teste a implementa√ß√£o de persist√™ncia de estado para workflows de longa dura√ß√£o
* Explore [como construir seu primeiro crew](/pt-BR/guides/crews/first-crew) para ver como crews e flows podem funcionar juntos
* Confira a [documenta√ß√£o de refer√™ncia de Flow](/pt-BR/concepts/flows) para funcionalidades mais avan√ßadas


# Instala√ß√£o
Source: https://docs.crewai.com/pt-BR/installation

Comece a usar o CrewAI - Instale, configure e crie seu primeiro crew de IA

## Tutorial em V√≠deo

Assista a este tutorial em v√≠deo para uma demonstra√ß√£o passo a passo do processo de instala√ß√£o:

<iframe width="100%" height="400" src="https://www.youtube.com/embed/-kSOTtYzgEw" title="CrewAI Installation Guide" frameborder="0" style={{ borderRadius: '10px' }} allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

## Tutorial em Texto

<Note>
  **Requisitos de Vers√£o do Python**

  CrewAI requer `Python >=3.10 e <3.14`. Veja como verificar sua vers√£o:

  ```bash
  python3 --version
  ```

  Se voc√™ precisar atualizar o Python, acesse [python.org/downloads](https://python.org/downloads)
</Note>

CrewAI utiliza o `uv` como ferramenta de gerenciamento de depend√™ncias e pacotes. Ele simplifica a configura√ß√£o e execu√ß√£o do projeto, oferecendo uma experi√™ncia fluida.

Se voc√™ ainda n√£o instalou o `uv`, siga o **passo 1** para instal√°-lo rapidamente em seu sistema, caso contr√°rio, avance para o **passo 2**.

<Steps>
  <Step title="Instale o uv">
    * **No macOS/Linux:**

      Use `curl` para baixar o script e execut√°-lo com `sh`:

      ```shell
      curl -LsSf https://astral.sh/uv/install.sh | sh
      ```

      Se seu sistema n√£o possuir `curl`, voc√™ pode usar `wget`:

      ```shell
      wget -qO- https://astral.sh/uv/install.sh | sh
      ```

    * **No Windows:**

      Use `irm` para baixar o script e `iex` para execut√°-lo:

      ```shell
      powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
      ```

      Caso enfrente algum problema, consulte o [guia de instala√ß√£o do UV](https://docs.astral.sh/uv/getting-started/installation/) para mais informa√ß√µes.
  </Step>

  <Step title="Instale o CrewAI üöÄ">
    * Execute o seguinte comando para instalar o CLI do `crewai`:

      ```shell
      uv tool install crewai
      ```

      <Warning>
        Se aparecer um aviso relacionado ao `PATH`, execute este comando para atualizar seu shell:

        ```shell
        uv tool update-shell
        ```
      </Warning>

      <Warning>
        Se voc√™ encontrar o erro de build ao instalar `chroma-hnswlib==0.7.6` (`fatal error C1083: Cannot open include file: 'float.h'`) no Windows, instale o (Visual Studio Build Tools)\[[https://visualstudio.microsoft.com/downloads/](https://visualstudio.microsoft.com/downloads/)] com o *Desenvolvimento de Desktop com C++*.
      </Warning>

    * Para verificar se o `crewai` est√° instalado, execute:
      ```shell
      uv tool list
      ```

    * Voc√™ dever√° ver algo assim:
      ```shell
      crewai v0.102.0
      - crewai
      ```

    * Caso precise atualizar o `crewai`, execute:
      ```shell
      uv tool install crewai --upgrade
      ```

    <Check>Instala√ß√£o realizada com sucesso! Voc√™ est√° pronto para criar seu primeiro crew! üéâ</Check>
  </Step>
</Steps>

# Criando um Projeto CrewAI

Recomendamos utilizar o template de scaffolding `YAML` para uma abordagem estruturada na defini√ß√£o dos agentes e tarefas. Veja como come√ßar:

<Steps>
  <Step title="Gerar Scaffolding do Projeto">
    * Execute o comando CLI do `crewai`:
      ```shell
      crewai create crew <your_project_name>
      ```

    * Isso criar√° um novo projeto com a seguinte estrutura:
      <Frame>
        ```
        my_project/
        ‚îú‚îÄ‚îÄ .gitignore
        ‚îú‚îÄ‚îÄ knowledge/
        ‚îú‚îÄ‚îÄ pyproject.toml
        ‚îú‚îÄ‚îÄ README.md
        ‚îú‚îÄ‚îÄ .env
        ‚îî‚îÄ‚îÄ src/
            ‚îî‚îÄ‚îÄ my_project/
                ‚îú‚îÄ‚îÄ __init__.py
                ‚îú‚îÄ‚îÄ main.py
                ‚îú‚îÄ‚îÄ crew.py
                ‚îú‚îÄ‚îÄ tools/
                ‚îÇ   ‚îú‚îÄ‚îÄ custom_tool.py
                ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
                ‚îî‚îÄ‚îÄ config/
                    ‚îú‚îÄ‚îÄ agents.yaml
                    ‚îî‚îÄ‚îÄ tasks.yaml
        ```
      </Frame>
  </Step>

  <Step title="Personalize Seu Projeto">
    * Seu projeto conter√° estes arquivos essenciais:
      | Arquivo       | Finalidade                                            |
      | ------------- | ----------------------------------------------------- |
      | `agents.yaml` | Defina seus agentes de IA e seus pap√©is               |
      | `tasks.yaml`  | Configure as tarefas e fluxos de trabalho dos agentes |
      | `.env`        | Armazene chaves de API e vari√°veis de ambiente        |
      | `main.py`     | Ponto de entrada e fluxo de execu√ß√£o do projeto       |
      | `crew.py`     | Orquestra√ß√£o e coordena√ß√£o do crew                    |
      | `tools/`      | Diret√≥rio para ferramentas customizadas dos agentes   |
      | `knowledge/`  | Diret√≥rio para base de conhecimento                   |

    * Comece editando `agents.yaml` e `tasks.yaml` para definir o comportamento do seu crew.

    * Mantenha informa√ß√µes sens√≠veis como chaves de API no arquivo `.env`.
  </Step>

  <Step title="Execute seu Crew">
    * Antes de rodar seu crew, execute:
      ```bash
      crewai install
      ```
    * Se precisar instalar pacotes adicionais, utilize:
      ```shell
      uv add <package-name>
      ```
    * Para rodar seu crew, execute o seguinte comando na raiz do seu projeto:
      ```bash
      crewai run
      ```
  </Step>
</Steps>

## Op√ß√µes de Instala√ß√£o Enterprise

<Note type="info">
  Para equipes e organiza√ß√µes, o CrewAI oferece op√ß√µes de implanta√ß√£o corporativa que eliminam a complexidade da configura√ß√£o:

  ### CrewAI Enterprise (SaaS)

  * Zero instala√ß√£o necess√°ria - basta se cadastrar gratuitamente em [app.crewai.com](https://app.crewai.com)
  * Atualiza√ß√µes e manuten√ß√£o autom√°ticas
  * Infraestrutura e escalabilidade gerenciadas
  * Construa crews sem c√≥digo

  ### CrewAI Factory (Auto-Hospedado)

  * Implanta√ß√£o containerizada para sua infraestrutura
  * Compat√≠vel com qualquer hyperscaler, incluindo ambientes on-premises
  * Integra√ß√£o com seus sistemas de seguran√ßa existentes

  <Card title="Explore as Op√ß√µes Enterprise" icon="building" href="https://crewai.com/enterprise">
    Saiba mais sobre as solu√ß√µes enterprise do CrewAI e agende uma demonstra√ß√£o
  </Card>
</Note>

## Pr√≥ximos Passos

<CardGroup cols={2}>
  <Card title="Construa Seu Primeiro Agente" icon="code" href="/pt-BR/quickstart">
    Siga nosso guia de in√≠cio r√°pido para criar seu primeiro agente CrewAI e obter experi√™ncia pr√°tica.
  </Card>

  <Card title="Junte-se √† Comunidade" icon="comments" href="https://community.crewai.com">
    Conecte-se com outros desenvolvedores, obtenha ajuda e compartilhe suas experi√™ncias com o CrewAI.
  </Card>
</CardGroup>


# Introdu√ß√£o
Source: https://docs.crewai.com/pt-BR/introduction

Construa equipes de agentes de IA que trabalham juntas para resolver tarefas complexas

# O que √© CrewAI?

**CrewAI √© um framework Python enxuto e ultrarr√°pido, constru√≠do totalmente do zero‚Äîcompletamente independente do LangChain ou de outros frameworks de agentes.**

O CrewAI capacita desenvolvedores tanto com simplicidade de alto n√≠vel quanto com controle detalhado de baixo n√≠vel, ideal para criar agentes de IA aut√¥nomos sob medida para qualquer cen√°rio:

* **[Crews do CrewAI](/pt-BR/guides/crews/first-crew)**: Otimizados para autonomia e intelig√™ncia colaborativa, permitindo criar equipes de IA onde cada agente possui fun√ß√µes, ferramentas e objetivos espec√≠ficos.
* **[Flows do CrewAI](/pt-BR/guides/flows/first-flow)**: Proporcionam controle granular, orientado por eventos, com chamadas LLM individuais para uma orquestra√ß√£o precisa das tarefas, al√©m de suportar Crews nativamente.

Com mais de 100.000 desenvolvedores certificados em nossos cursos comunit√°rios, o CrewAI est√° se tornando rapidamente o padr√£o para automa√ß√£o de IA pronta para empresas.

## Como funcionam os Crews

<Note>
  Assim como uma empresa possui departamentos (Vendas, Engenharia, Marketing) trabalhando juntos sob uma lideran√ßa para atingir objetivos de neg√≥cio, o CrewAI ajuda voc√™ a criar uma ‚Äúorganiza√ß√£o‚Äù de agentes de IA com fun√ß√µes especializadas colaborando para realizar tarefas complexas.
</Note>

<Frame caption="Vis√£o Geral do Framework CrewAI">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/crews.png" alt="Vis√£o Geral do Framework CrewAI" />
</Frame>

| Componente        |                Descri√ß√£o               | Principais Funcionalidades                                                                                                                                |
| :---------------- | :------------------------------------: | :-------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Crew**          |     Organiza√ß√£o de mais alto n√≠vel     | ‚Ä¢ Gerencia equipes de agentes de IA<br />‚Ä¢ Supervisiona fluxos de trabalho<br />‚Ä¢ Garante colabora√ß√£o<br />‚Ä¢ Entrega resultados                           |
| **Agentes de IA** |    Membros especializados da equipe    | ‚Ä¢ Possuem fun√ß√µes espec√≠ficas (pesquisador, escritor)<br />‚Ä¢ Utilizam ferramentas designadas<br />‚Ä¢ Podem delegar tarefas<br />‚Ä¢ Tomam decis√µes aut√¥nomas |
| **Process**       | Sistema de gest√£o do fluxo de trabalho | ‚Ä¢ Define padr√µes de colabora√ß√£o<br />‚Ä¢ Controla designa√ß√£o de tarefas<br />‚Ä¢ Gerencia intera√ß√µes<br />‚Ä¢ Garante execu√ß√£o eficiente                        |
| **Tasks**         |         Atribui√ß√µes individuais        | ‚Ä¢ Objetivos claros<br />‚Ä¢ Utilizam ferramentas espec√≠ficas<br />‚Ä¢ Alimentam processos maiores<br />‚Ä¢ Geram resultados acion√°veis                          |

### Como tudo trabalha junto

1. O **Crew** organiza toda a opera√ß√£o
2. **Agentes de IA** realizam tarefas especializadas
3. O **Process** garante colabora√ß√£o fluida
4. **Tasks** s√£o conclu√≠das para alcan√ßar o objetivo

## Principais Funcionalidades

<CardGroup cols={2}>
  <Card title="Agentes Baseados em Fun√ß√µes" icon="users">
    Crie agentes especializados com fun√ß√µes, conhecimentos e objetivos definidos ‚Äì de pesquisadores e analistas a escritores
  </Card>

  <Card title="Ferramentas Flex√≠veis" icon="screwdriver-wrench">
    Equipe os agentes com ferramentas e APIs personalizadas para interagir com servi√ßos e fontes de dados externas
  </Card>

  <Card title="Colabora√ß√£o Inteligente" icon="people-arrows">
    Agentes trabalham juntos, compartilhando insights e coordenando tarefas para conquistar objetivos complexos
  </Card>

  <Card title="Gerenciamento de Tarefas" icon="list-check">
    Defina fluxos de trabalho sequenciais ou paralelos, com agentes lidando automaticamente com depend√™ncias entre tarefas
  </Card>
</CardGroup>

## Como funcionam os Flows

<Note>
  Enquanto Crews se destacam na colabora√ß√£o aut√¥noma, Flows proporcionam automa√ß√µes estruturadas, oferecendo controle granular sobre a execu√ß√£o dos fluxos de trabalho. Flows garantem execu√ß√£o confi√°vel, segura e eficiente, lidando com l√≥gica condicional, loops e gerenciamento din√¢mico de estados com precis√£o. Flows se integram perfeitamente com Crews, permitindo equilibrar alta autonomia com controle rigoroso.
</Note>

<Frame caption="Vis√£o Geral do Framework CrewAI">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/flows.png" alt="Vis√£o Geral do Framework CrewAI" />
</Frame>

| Componente       |                   Descri√ß√£o                   | Principais Funcionalidades                                                                                                                                        |
| :--------------- | :-------------------------------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Flow**         | Orquestra√ß√£o de fluxo de trabalho estruturada | ‚Ä¢ Gerencia caminhos de execu√ß√£o<br />‚Ä¢ Lida com transi√ß√µes de estado<br />‚Ä¢ Controla a sequ√™ncia de tarefas<br />‚Ä¢ Garante execu√ß√£o confi√°vel                     |
| **Events**       |         Gatilhos para a√ß√µes nos fluxos        | ‚Ä¢ Iniciam processos espec√≠ficos<br />‚Ä¢ Permitem respostas din√¢micas<br />‚Ä¢ Suportam ramifica√ß√µes condicionais<br />‚Ä¢ Adaptam-se em tempo real                     |
| **States**       |        Contextos de execu√ß√£o dos fluxos       | ‚Ä¢ Mant√™m dados de execu√ß√£o<br />‚Ä¢ Permitem persist√™ncia<br />‚Ä¢ Suportam retomada<br />‚Ä¢ Garantem integridade na execu√ß√£o                                          |
| **Crew Support** |          Aprimora automa√ß√£o de fluxos         | ‚Ä¢ Injeta autonomia quando necess√°rio<br />‚Ä¢ Complementa fluxos estruturados<br />‚Ä¢ Equilibra automa√ß√£o e intelig√™ncia<br />‚Ä¢ Permite tomada de decis√£o adaptativa |

### Capacidades-Chave

<CardGroup cols={2}>
  <Card title="Orquestra√ß√£o Orientada por Eventos" icon="bolt">
    Defina caminhos de execu√ß√£o precisos respondendo dinamicamente a eventos
  </Card>

  <Card title="Controle Detalhado" icon="sliders">
    Gerencie estados de fluxo de trabalho e execu√ß√£o condicional de forma segura e eficiente
  </Card>

  <Card title="Integra√ß√£o Nativa com Crew" icon="puzzle-piece">
    Combine de forma simples com Crews para maior autonomia e intelig√™ncia
  </Card>

  <Card title="Execu√ß√£o Determin√≠stica" icon="route">
    Garanta resultados previs√≠veis com controle expl√≠cito de fluxo e tratamento de erros
  </Card>
</CardGroup>

## Quando usar Crews versus Flows

<Note>
  Entender quando utilizar [Crews](/pt-BR/guides/crews/first-crew) ou [Flows](/pt-BR/guides/flows/first-flow) √© fundamental para maximizar o potencial do CrewAI em suas aplica√ß√µes.
</Note>

| Caso de uso              | Abordagem recomendada                   | Por qu√™?                                                                                                                                                  |
| :----------------------- | :-------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Pesquisa aberta**      | [Crews](/pt-BR/guides/crews/first-crew) | Quando as tarefas exigem criatividade, explora√ß√£o e adapta√ß√£o                                                                                             |
| **Gera√ß√£o de conte√∫do**  | [Crews](/pt-BR/guides/crews/first-crew) | Para cria√ß√£o colaborativa de artigos, relat√≥rios ou materiais de marketing                                                                                |
| **Fluxos de decis√£o**    | [Flows](/pt-BR/guides/flows/first-flow) | Quando √© necess√°rio caminhos de decis√£o previs√≠veis, audit√°veis e com controle preciso                                                                    |
| **Orquestra√ß√£o de APIs** | [Flows](/pt-BR/guides/flows/first-flow) | Para integra√ß√£o confi√°vel com m√∫ltiplos servi√ßos externos em sequ√™ncia espec√≠fica                                                                         |
| **Aplica√ß√µes h√≠bridas**  | Abordagem combinada                     | Use [Flows](/pt-BR/guides/flows/first-flow) para orquestrar o processo geral com [Crews](/pt-BR/guides/crews/first-crew) lidando com subtarefas complexas |

### Framework de Decis√£o

* **Escolha [Crews](/pt-BR/guides/crews/first-crew) quando:** Precisa de resolu√ß√£o aut√¥noma de problemas, colabora√ß√£o criativa ou tarefas explorat√≥rias
* **Escolha [Flows](/pt-BR/guides/flows/first-flow) quando:** Requer resultados determin√≠sticos, auditabilidade ou controle preciso sobre a execu√ß√£o
* **Combine ambos quando:** Sua aplica√ß√£o precisa de processos estruturados e tamb√©m de bols√µes de intelig√™ncia aut√¥noma

## Por que escolher o CrewAI?

* üß† **Opera√ß√£o Aut√¥noma**: Agentes tomam decis√µes inteligentes com base em suas fun√ß√µes e nas ferramentas dispon√≠veis
* üìù **Intera√ß√£o Natural**: Agentes se comunicam e colaboram como membros humanos de uma equipe
* üõ†Ô∏è **Design Extens√≠vel**: F√°cil de adicionar novas ferramentas, fun√ß√µes e capacidades
* üöÄ **Pronto para Produ√ß√£o**: Constru√≠do para confiabilidade e escalabilidade em aplica√ß√µes reais
* üîí **Foco em Seguran√ßa**: Desenvolvido para atender requisitos de seguran√ßa empresarial
* üí∞ **Custo-Efetivo**: Otimizado para minimizar o uso de tokens e chamadas de API

## Pronto para come√ßar a construir?

<CardGroup cols={2}>
  <Card title="Crie Seu Primeiro Crew" icon="users-gear" href="/pt-BR/guides/crews/first-crew">
    Tutorial passo a passo para criar uma equipe de IA colaborativa que trabalha junto para resolver problemas complexos.
  </Card>

  <Card title="Crie Seu Primeiro Flow" icon="diagram-project" href="/pt-BR/guides/flows/first-flow">
    Aprenda a criar fluxos de trabalho estruturados e orientados por eventos com controle preciso de execu√ß√£o.
  </Card>
</CardGroup>

<CardGroup cols={3}>
  <Card title="Instale o CrewAI" icon="wrench" href="/pt-BR/installation">
    Comece a usar o CrewAI em seu ambiente de desenvolvimento.
  </Card>

  <Card title="Primeiros Passos" icon="bolt" href="/pt-BR/quickstart">
    Siga nosso guia r√°pido para criar seu primeiro agente CrewAI e colocar a m√£o na massa.
  </Card>

  <Card title="Junte-se √† Comunidade" icon="comments" href="https://community.crewai.com">
    Conecte-se com outros desenvolvedores, obtenha ajuda e compartilhe suas experi√™ncias com o CrewAI.
  </Card>
</CardGroup>


# Hooks Antes e Depois do Kickoff
Source: https://docs.crewai.com/pt-BR/learn/before-and-after-kickoff-hooks

Aprenda a usar hooks antes e depois do kickoff em CrewAI

O CrewAI fornece hooks que permitem executar c√≥digo antes e depois do kickoff de uma crew. Esses hooks s√£o √∫teis para pr√©-processar entradas ou p√≥s-processar resultados.

## Hook Antes do Kickoff

O hook antes do kickoff √© executado antes da crew iniciar suas tarefas. Ele recebe o dicion√°rio de entradas e pode modific√°-lo antes de pass√°-lo para a crew. Voc√™ pode usar esse hook para configurar seu ambiente, carregar dados necess√°rios ou pr√©-processar suas entradas. Isso √© √∫til em cen√°rios onde os dados de entrada podem precisar de enriquecimento ou valida√ß√£o antes de serem processados pela crew.

Aqui est√° um exemplo de como definir uma fun√ß√£o antes do kickoff em seu `crew.py`:

```python
from crewai import CrewBase
from crewai.project import before_kickoff

@CrewBase
class MinhaEquipe:
    @before_kickoff
    def preparar_dados(self, entradas):
        # Pr√©-processa ou modifica as entradas
        entradas['processado'] = True
        return entradas

#...
```

Neste exemplo, a fun√ß√£o preparar\_dados modifica as entradas adicionando um novo par chave-valor indicando que as entradas foram processadas.

## Hook Depois do Kickoff

O hook depois do kickoff √© executado ap√≥s a crew completar suas tarefas. Ele recebe o objeto de resultado, que cont√©m as sa√≠das da execu√ß√£o da crew. Este hook √© ideal para p√≥s-processar resultados, como log, transforma√ß√£o de dados ou an√°lise adicional.

Veja como voc√™ pode definir uma fun√ß√£o depois do kickoff em seu `crew.py`:

```python
from crewai import CrewBase
from crewai.project import after_kickoff

@CrewBase
class MinhaEquipe:
    @after_kickoff
    def registrar_resultados(self, resultado):
        # Registra ou modifica os resultados
        print("Execu√ß√£o da equipe conclu√≠da com resultado:", resultado)
        return resultado

# ...
```

Na fun√ß√£o `registrar_resultados`, os resultados da execu√ß√£o da crew s√£o simplesmente impressos. Voc√™ pode estender isso para realizar opera√ß√µes mais complexas, como enviar notifica√ß√µes ou integrar com outros servi√ßos.

## Utilizando Ambos os Hooks

Ambos os hooks podem ser usados juntos para oferecer um processo completo de prepara√ß√£o e finaliza√ß√£o na execu√ß√£o da sua crew. Eles s√£o particularmente √∫teis para manter uma arquitetura de c√≥digo limpa, separando responsabilidades e melhorando a modularidade das suas implementa√ß√µes com CrewAI.

## Conclus√£o

Os hooks antes e depois do kickoff em CrewAI oferecem formas poderosas de interagir com o ciclo de vida da execu√ß√£o de uma crew. Ao entender e utilizar esses hooks, voc√™ pode aumentar significativamente a robustez e flexibilidade dos seus agentes de IA.


# Traga seu pr√≥prio agente
Source: https://docs.crewai.com/pt-BR/learn/bring-your-own-agent

Aprenda como trazer seus pr√≥prios agentes que funcionam dentro de uma Crew.

Interoperabilidade √© um conceito fundamental no CrewAI. Este guia mostrar√° como trazer seus pr√≥prios agentes para funcionar dentro de uma Crew.

## Guia de Adapta√ß√£o para trazer seus pr√≥prios agentes (Agentes Langgraph, Agentes OpenAI, etc...)

Requeremos 3 adaptadores para tornar qualquer agente de diferentes frameworks compat√≠vel com uma crew.

1. BaseAgentAdapter
2. BaseToolAdapter
3. BaseConverter

## BaseAgentAdapter

Esta classe abstrata define a interface comum e a funcionalidade que todos
os adaptadores de agente devem implementar. Ela estende BaseAgent para manter compatibilidade
com o framework CrewAI, ao mesmo tempo em que adiciona requisitos espec√≠ficos do adaptador.

M√©todos obrigat√≥rios:

1. `def configure_tools`
2. `def configure_structured_output`

## Criando seu pr√≥prio Adaptador

Para integrar um agente de um framework diferente (por exemplo, LangGraph, Autogen, OpenAI Assistants) ao CrewAI, voc√™ precisa criar um adaptador customizado herdando de `BaseAgentAdapter`. Esse adaptador atua como uma camada de compatibilidade, traduzindo entre as interfaces do CrewAI e os requisitos espec√≠ficos do seu agente externo.

Veja como implementar seu adaptador customizado:

1. **Herdar de `BaseAgentAdapter`**:
   ```python
   from crewai.agents.agent_adapters.base_agent_adapter import BaseAgentAdapter
   from crewai.tools import BaseTool
   from typing import List, Optional, Any, Dict

   class MyCustomAgentAdapter(BaseAgentAdapter):
       # ... detalhes da implementa√ß√£o ...
   ```

2. **Implementar `__init__`**:
   O construtor deve chamar o construtor da classe pai `super().__init__(**kwargs)` e executar qualquer inicializa√ß√£o espec√≠fica do seu agente externo. Voc√™ pode usar o dicion√°rio opcional `agent_config` passado durante a inicializa√ß√£o do `Agent` do CrewAI para configurar seu adaptador e o agente subjacente.

   ```python
   def __init__(self, agent_config: Optional[Dict[str, Any]] = None, **kwargs: Any):
       super().__init__(agent_config=agent_config, **kwargs)
       # Inicialize seu agente externo aqui, possivelmente usando agent_config
       # Exemplo: self.external_agent = initialize_my_agent(agent_config)
       print(f"Inicializando MyCustomAgentAdapter com config: {agent_config}")
   ```

3. **Implementar `configure_tools`**:
   Este m√©todo abstrato √© crucial. Ele recebe uma lista de inst√¢ncias de `BaseTool` do CrewAI. Sua implementa√ß√£o deve converter ou adaptar essas ferramentas para o formato esperado pelo seu framework de agente externo. Isso pode envolver encapsulamento, extra√ß√£o de atributos espec√≠ficos ou registro delas na inst√¢ncia do agente externo.

   ```python
   def configure_tools(self, tools: Optional[List[BaseTool]] = None) -> None:
       if tools:
           adapted_tools = []
           for tool in tools:
               # Adapte o CrewAI BaseTool para o formato que seu agente espera
               # Exemplo: adapted_tool = adapt_to_my_framework(tool)
               # adapted_tools.append(adapted_tool)
               pass # Substitua pela sua l√≥gica real de adapta√ß√£o

           # Configure o agente externo com as ferramentas adaptadas
           # Exemplo: self.external_agent.set_tools(adapted_tools)
           print(f"Configurando ferramentas para MyCustomAgentAdapter: {adapted_tools}") # Placeholder
       else:
           # Caso nenhum ferramenta seja fornecida
           # Exemplo: self.external_agent.set_tools([])
           print("Nenhuma ferramenta fornecida para MyCustomAgentAdapter.")
   ```

4. **Implementar `configure_structured_output`**:
   Esse m√©todo √© chamado quando o `Agent` do CrewAI √© configurado com requisitos de sa√≠da estruturada (por exemplo, `output_json` ou `output_pydantic`). Seu adaptador precisa garantir que o agente externo esteja configurado para cumprir esses requisitos. Isso pode envolver definir par√¢metros espec√≠ficos no agente externo ou garantir que seu modelo subjacente suporte o formato solicitado. Se o agente externo n√£o suportar sa√≠da estruturada de forma compat√≠vel com as expectativas do CrewAI, talvez seja necess√°rio lidar com a convers√£o ou lan√ßar um erro apropriado.

   ```python
   def configure_structured_output(self, structured_output: Any) -> None:
       # Configure seu agente externo para produzir sa√≠da no formato especificado
       # Exemplo: self.external_agent.set_output_format(structured_output)
       self.adapted_structured_output = True # Sinaliza que a sa√≠da estruturada foi tratada
       print(f"Configurando sa√≠da estruturada para MyCustomAgentAdapter: {structured_output}")
   ```

Implementando esses m√©todos, seu `MyCustomAgentAdapter` permitir√° que sua implementa√ß√£o personalizada de agente funcione corretamente dentro de uma crew do CrewAI, interagindo com tarefas e ferramentas de forma transparente. Lembre-se de substituir os coment√°rios e prints de exemplo pela sua l√≥gica real de adapta√ß√£o espec√≠fica do framework externo que est√° integrando.

## Implementa√ß√£o de BaseToolAdapter

A classe `BaseToolAdapter` √© respons√°vel por converter os objetos nativos `BaseTool` do CrewAI em um formato que o seu framework de agente externo possa entender e utilizar. Diferentes frameworks de agentes (como LangGraph, OpenAI Assistants, etc.) possuem suas pr√≥prias formas de definir e tratar ferramentas, e o `BaseToolAdapter` age como tradutor.

Veja como implementar seu adaptador de ferramentas personalizado:

1. **Herdar de `BaseToolAdapter`**:
   ```python
   from crewai.agents.agent_adapters.base_tool_adapter import BaseToolAdapter
   from crewai.tools import BaseTool
   from typing import List, Any

   class MyCustomToolAdapter(BaseToolAdapter):
       # ... detalhes da implementa√ß√£o ...
   ```

2. **Implementar `configure_tools`**:
   Este √© o m√©todo abstrato principal que voc√™ deve implementar. Ele recebe uma lista de inst√¢ncias de `BaseTool` fornecidas ao agente. Sua tarefa √© iterar por essa lista, adaptar cada `BaseTool` para o formato esperado pelo seu framework externo e armazenar as ferramentas convertidas na lista `self.converted_tools` (inicializada no construtor da classe base).

   ```python
   def configure_tools(self, tools: List[BaseTool]) -> None:
       """Configura e converte ferramentas do CrewAI para a implementa√ß√£o espec√≠fica."""
       self.converted_tools = [] # Reseta caso seja chamado m√∫ltiplas vezes
       for tool in tools:
           # Sanitizar o nome da ferramenta se necess√°rio pelo framework alvo
           sanitized_name = self.sanitize_tool_name(tool.name)

           # --- Sua l√≥gica de convers√£o aqui ---
           # Exemplo: Converter BaseTool para formato de dicion√°rio para LangGraph
           # converted_tool = {
           #     "name": sanitized_name,
           #     "description": tool.description,
           #     "parameters": tool.args_schema.schema() if tool.args_schema else {},
           #     # Adicione outros campos espec√≠ficos do framework
           # }

           # Exemplo: Converter BaseTool para defini√ß√£o de fun√ß√£o OpenAI
           # converted_tool = {
           #     "type": "function",
           #     "function": {
           #         "name": sanitized_name,
           #         "description": tool.description,
           #         "parameters": tool.args_schema.schema() if tool.args_schema else {"type": "object", "properties": {}},
           #     }
           # }

           # --- Substitua os exemplos acima pela sua adapta√ß√£o real ---
           converted_tool = self.adapt_tool_to_my_framework(tool, sanitized_name) # Placeholder

           self.converted_tools.append(converted_tool)
           print(f"Ferramenta '{tool.name}' adaptada para '{sanitized_name}' em MyCustomToolAdapter") # Placeholder

       print(f"MyCustomToolAdapter terminou de configurar ferramentas: {len(self.converted_tools)} adaptadas.") # Placeholder

   # --- M√©todo auxiliar para adapta√ß√£o (Exemplo) ---
   def adapt_tool_to_my_framework(self, tool: BaseTool, sanitized_name: str) -> Any:
       # Substitua pela l√≥gica real para converter um CrewAI BaseTool
       # para o formato necess√°rio do framework de agente externo espec√≠fico.
       # Isso pode variar bastante de acordo com o framework.
       adapted_representation = {
           "framework_specific_name": sanitized_name,
           "framework_specific_description": tool.description,
           "inputs": tool.args_schema.schema() if tool.args_schema else None,
           "implementation_reference": tool.run # Ou conforme o framework precisa chamar
       }
       # Certifique-se tamb√©m que a ferramenta funcione tanto s√≠ncrona quanto assincronamente
       async def async_tool_wrapper(*args, **kwargs):
           output = tool.run(*args, **kwargs)
           if inspect.isawaitable(output):
               return await output
           else:
               return output

       adapted_tool = MyFrameworkTool(
           name=sanitized_name,
           description=tool.description,
           inputs=tool.args_schema.schema() if tool.args_schema else None,
           implementation_reference=async_tool_wrapper
       )

       return adapted_representation

   ```

3. **Utilizando o Adaptador**:
   Normalmente, voc√™ instanciaria seu `MyCustomToolAdapter` dentro do m√©todo `configure_tools` do seu `MyCustomAgentAdapter` e o usaria para processar as ferramentas antes de configurar o agente externo.

   ```python
   # Dentro de MyCustomAgentAdapter.configure_tools
   def configure_tools(self, tools: Optional[List[BaseTool]] = None) -> None:
       if tools:
           tool_adapter = MyCustomToolAdapter() # Instancia seu adaptador de ferramenta
           tool_adapter.configure_tools(tools)  # Converte as ferramentas
           adapted_tools = tool_adapter.tools() # Obt√©m as ferramentas convertidas

           # Agora configure seu agente externo com as ferramentas adaptadas
           # Exemplo: self.external_agent.set_tools(adapted_tools)
           print(f"Configurando agente externo com ferramentas adaptadas: {adapted_tools}") # Placeholder
       else:
           # Caso sem ferramentas
           print("Nenhuma ferramenta fornecida para MyCustomAgentAdapter.")
   ```

Ao criar um `BaseToolAdapter`, voc√™ desacopla a l√≥gica de convers√£o de ferramenta da adapta√ß√£o de agente, tornando a integra√ß√£o mais limpa e modular. Lembre-se de substituir os exemplos de placeholder pela l√≥gica de convers√£o real exigida pelo seu framework externo espec√≠fico.

## BaseConverter

O `BaseConverterAdapter` desempenha um papel crucial quando uma `Task` do CrewAI exige que um agente retorne sua sa√≠da final em um formato estruturado espec√≠fico, como JSON ou um modelo Pydantic. Ele faz a ponte entre os requisitos de sa√≠da estruturada do CrewAI e as capacidades do seu agente externo.

Suas responsabilidades principais s√£o:

1. **Configurar o Agente para Sa√≠da Estruturada:** Com base nos requisitos da `Task` (`output_json` ou `output_pydantic`), ele instrui o `BaseAgentAdapter` associado (e indiretamente, o agente externo) sobre qual formato √© esperado.
2. **Apriorar o Prompt do Sistema:** Ele modifica o prompt do sistema do agente para incluir instru√ß√µes claras sobre *como* gerar a sa√≠da na estrutura exigida.
3. **P√≥s-processamento do Resultado:** Pega a sa√≠da bruta do agente e tenta fazer parsing, validar e formatar conforme a estrutura requerida, retornando por fim uma representa√ß√£o em string (por exemplo, uma string JSON).

Veja como implementar seu adaptador de convers√£o customizado:

1. **Herdar de `BaseConverterAdapter`**:
   ```python
   from crewai.agents.agent_adapters.base_converter_adapter import BaseConverterAdapter
   # Supondo que o seu MyCustomAgentAdapter foi definido
   # from .my_custom_agent_adapter import MyCustomAgentAdapter
   from crewai.task import Task
   from typing import Any

   class MyCustomConverterAdapter(BaseConverterAdapter):
       # Armazena o tipo de sa√≠da esperado (ex: 'json', 'pydantic', 'text')
       _output_type: str = 'text'
       _output_schema: Any = None # Armazena o schema JSON ou modelo Pydantic

       # ... detalhes da implementa√ß√£o ...
   ```

2. **Implementar `__init__`**:
   O construtor deve aceitar a inst√¢ncia correspondente de `agent_adapter` com a qual ir√° trabalhar.

   ```python
   def __init__(self, agent_adapter: Any): # Use um type hint espec√≠fico para seu AgentAdapter
       self.agent_adapter = agent_adapter
       print(f"Inicializando MyCustomConverterAdapter para o adaptador de agente: {type(agent_adapter).__name__}")
   ```

3. **Implementar `configure_structured_output`**:
   Esse m√©todo recebe o objeto `Task` do CrewAI. Voc√™ precisa checar os atributos `output_json` e `output_pydantic` da task para determinar a estrutura de sa√≠da exigida. Armazene essa informa√ß√£o (por exemplo, em `_output_type` e `_output_schema`) e, potencialmente, chame m√©todos de configura√ß√£o no seu `self.agent_adapter` se o agente externo necessitar de um ajuste espec√≠fico para sa√≠da estruturada (algo que pode j√° ter sido parcialmente feito no `configure_structured_output` do adaptador de agente).

   ```python
   def configure_structured_output(self, task: Task) -> None:
       """Configura a sa√≠da estruturada esperada baseada na task."""
       if task.output_pydantic:
           self._output_type = 'pydantic'
           self._output_schema = task.output_pydantic
           print(f"Converter: Configurado para sa√≠da Pydantic: {self._output_schema.__name__}")
       elif task.output_json:
           self._output_type = 'json'
           self._output_schema = task.output_json
           print(f"Converter: Configurado para sa√≠da JSON com schema: {self._output_schema}")
       else:
           self._output_type = 'text'
           self._output_schema = None
           print("Converter: Configurado para sa√≠da de texto padr√£o.")

       # Opcionalmente, informe o agent_adapter se necess√°rio
       # self.agent_adapter.set_output_mode(self._output_type, self._output_schema)
   ```

4. **Implementar `enhance_system_prompt`**:
   Este m√©todo recebe o prompt base do sistema do agente e deve anexar instru√ß√µes adaptadas para o `_output_type` e `_output_schema` atualmente configurados. O objetivo √© guiar o LLM que alimenta o agente a produzir sa√≠da no formato correto.

   ````python
   def enhance_system_prompt(self, base_prompt: str) -> str:
       """Aprimore o prompt do sistema com instru√ß√µes de sa√≠da estruturada."""
       if self._output_type == 'text':
           return base_prompt # Nenhum aprimoramento necess√°rio para texto puro

       instructions = "\n\nSua resposta final DEVE estar formatada como "
       if self._output_type == 'json':
           schema_str = json.dumps(self._output_schema, indent=2)
           instructions += f"um objeto JSON conforme o seguinte schema:\n```json\n{schema_str}\n```"
       elif self._output_type == 'pydantic':
           schema_str = json.dumps(self._output_schema.model_json_schema(), indent=2)
           instructions += f"um objeto JSON conforme o modelo Pydantic '{self._output_schema.__name__}' com o seguinte schema:\n```json\n{schema_str}\n```"

       instructions += "\nGaranta que toda a sua resposta seja APENAS o objeto JSON v√°lido, sem nenhum texto introdut√≥rio, explica√ß√µes ou considera√ß√µes finais."

       print(f"Converter: Aprimorando prompt para sa√≠da {self._output_type}.")
       return base_prompt + instructions
   ````

   *Nota: O prompt pode precisar de ajustes conforme o agente/LLM usado.*

5. **Implementar `post_process_result`**:
   Esse m√©todo recebe a sa√≠da em string bruta do agente. Se uma sa√≠da estruturada foi solicitada (`json` ou `pydantic`), voc√™ deve tentar convert√™-la para o formato esperado. Trate erros de parsing caso ocorram (por exemplo, registre-os, tente corrigir, ou lance uma exce√ß√£o). O m√©todo **deve sempre retornar uma string**, mesmo se o formato intermedi√°rio seja um dicion√°rio ou objeto Pydantic (por exemplo, serializando novamente para JSON).

   ```python
   import json
   from pydantic import ValidationError

   def post_process_result(self, result: str) -> str:
       """P√≥s-processa o resultado do agente para garantir que corresponde ao formato esperado."""
       print(f"Converter: P√≥s-processando resultado para sa√≠da {self._output_type}.")
       if self._output_type == 'json':
           try:
               # Tenta fazer parsing e re-serializar para garantir validade e formato consistente
               parsed_json = json.loads(result)
               # Opcional: Validar contra o schema se for um dicion√°rio JSON schema
               # from jsonschema import validate
               # validate(instance=parsed_json, schema=self._output_schema)
               return json.dumps(parsed_json)
           except json.JSONDecodeError as e:
               print(f"Erro: Falha ao fazer parsing da sa√≠da JSON: {e}\nSa√≠da bruta:\n{result}")
               # Trate o erro: retorne bruto, lance exce√ß√£o, ou tente corrigir
               return result # Exemplo: retorna a sa√≠da bruta caso falhe
           # except Exception as e: # Captura erros de valida√ß√£o se usar jsonschema
           #     print(f"Erro: sa√≠da JSON falhou na valida√ß√£o do schema: {e}\nSa√≠da bruta:\n{result}")
           #     return result
       elif self._output_type == 'pydantic':
           try:
               # Tenta fazer parsing para o modelo Pydantic
               model_instance = self._output_schema.model_validate_json(result)
               # Retorna o modelo serializado de volta para JSON
               return model_instance.model_dump_json()
           except ValidationError as e:
               print(f"Erro: Falha ao validar sa√≠da Pydantic: {e}\nSa√≠da bruta:\n{result}")
               # Trate o erro
               return result # Exemplo: retorna a sa√≠da bruta caso falhe
           except json.JSONDecodeError as e:
                print(f"Erro: Falha ao fazer parsing do JSON para o modelo Pydantic: {e}\nSa√≠da bruta:\n{result}")
                return result
       else: # 'text'
           return result # Sem processamento para texto puro
   ```

Implementando esses m√©todos, seu `MyCustomConverterAdapter` assegurar√° que as solicita√ß√µes de sa√≠da estruturada das tarefas do CrewAI sejam corretamente tratadas pelo seu agente externo integrado, aumentando a confiabilidade e a usabilidade do seu agente customizado dentro do framework CrewAI.

## Adapters prontos para uso

Fornecemos adapters prontos para uso para os seguintes frameworks:

1. LangGraph
2. Agentes OpenAI

## Iniciando uma crew com agentes adaptados:

```python
import json
import os
from typing import List

from crewai_tools import SerperDevTool
from src.crewai import Agent, Crew, Task
from langchain_openai import ChatOpenAI
from pydantic import BaseModel

from crewai.agents.agent_adapters.langgraph.langgraph_adapter import (
    LangGraphAgentAdapter,
)
from crewai.agents.agent_adapters.openai_agents.openai_adapter import OpenAIAgentAdapter

# Agente CrewAI
code_helper_agent = Agent(
    role="Code Helper",
    goal="Help users solve coding problems effectively and provide clear explanations.",
    backstory="You are an experienced programmer with deep knowledge across multiple programming languages and frameworks. You specialize in solving complex coding challenges and explaining solutions clearly.",
    allow_delegation=False,
    verbose=True,
)
# OpenAI Agent Adapter
link_finder_agent = OpenAIAgentAdapter(
    role="Link Finder",
    goal="Find the most relevant and high-quality resources for coding tasks.",
    backstory="You are a research specialist with a talent for finding the most helpful resources. You're skilled at using search tools to discover documentation, tutorials, and examples that directly address the user's coding needs.",
    tools=[SerperDevTool()],
    allow_delegation=False,
    verbose=True,
)

# LangGraph Agent Adapter
reporter_agent = LangGraphAgentAdapter(
    role="Reporter",
    goal="Report the results of the tasks.",
    backstory="You are a reporter who reports the results of the other tasks",
    llm=ChatOpenAI(model="gpt-4o"),
    allow_delegation=True,
    verbose=True,
)


class Code(BaseModel):
    code: str


task = Task(
    description="Give an answer to the coding question: {task}",
    expected_output="A thorough answer to the coding question: {task}",
    agent=code_helper_agent,
    output_json=Code,
)
task2 = Task(
    description="Find links to resources that can help with coding tasks. Use the serper tool to find resources that can help.",
    expected_output="A list of links to resources that can help with coding tasks",
    agent=link_finder_agent,
)


class Report(BaseModel):
    code: str
    links: List[str]


task3 = Task(
    description="Report the results of the tasks.",
    expected_output="A report of the results of the tasks. this is the code produced and then the links to the resources that can help with the coding task.",
    agent=reporter_agent,
    output_json=Report,
)
# Usando no CrewAI
crew = Crew(
    agents=[code_helper_agent, link_finder_agent, reporter_agent],
    tasks=[task, task2, task3],
    verbose=True,
)

result = crew.kickoff(
    inputs={"task": "How do you implement an abstract class in python?"}
)

# Imprima o resultado bruto primeiro
print("Raw result:", result)

# Lide com o resultado de acordo com seu tipo
if hasattr(result, "json_dict") and result.json_dict:
    json_result = result.json_dict
    print("\nStructured JSON result:")
    print(f"{json.dumps(json_result, indent=2)}")

    # Acesse os campos de forma segura
    if isinstance(json_result, dict):
        if "code" in json_result:
            print("\nCode:")
            print(
                json_result["code"][:200] + "..."
                if len(json_result["code"]) > 200
                else json_result["code"]
            )

        if "links" in json_result:
            print("\nLinks:")
            for link in json_result["links"][:5]:  # Print first 5 links
                print(f"- {link}")
            if len(json_result["links"]) > 5:
                print(f"...and {len(json_result['links']) - 5} more links")
elif hasattr(result, "pydantic") and result.pydantic:
    print("\nPydantic model result:")
    print(result.pydantic.model_dump_json(indent=2))
else:
    # Fallback para sa√≠da bruta
    print("\nNo structured result available, using raw output:")
    print(result.raw[:500] + "..." if len(result.raw) > 500 else result.raw)

```


# Agentes de Codifica√ß√£o
Source: https://docs.crewai.com/pt-BR/learn/coding-agents

Aprenda como habilitar seus Agentes CrewAI para escrever e executar c√≥digo, e explore funcionalidades avan√ßadas para maior potencial.

## Introdu√ß√£o

Os Agentes CrewAI agora t√™m a poderosa capacidade de escrever e executar c√≥digo, aumentando significativamente suas habilidades de resolu√ß√£o de problemas. Esse recurso √© particularmente √∫til para tarefas que exigem solu√ß√µes computacionais ou program√°ticas.

## Habilitando a Execu√ß√£o de C√≥digo

Para habilitar a execu√ß√£o de c√≥digo para um agente, defina o par√¢metro `allow_code_execution` como `True` ao criar o agente.

Veja um exemplo:

```python Code
from crewai import Agent

coding_agent = Agent(
    role="Senior Python Developer",
    goal="Craft well-designed and thought-out code",
    backstory="You are a senior Python developer with extensive experience in software architecture and best practices.",
    allow_code_execution=True
)
```

<Note>
  Observe que o par√¢metro `allow_code_execution` √© `False` por padr√£o.
</Note>

## Considera√ß√µes Importantes

1. **Sele√ß√£o de Modelo**: √â fortemente recomendado utilizar modelos mais avan√ßados como Claude 3.5 Sonnet e GPT-4 ao habilitar a execu√ß√£o de c√≥digo.
   Esses modelos t√™m melhor compreens√£o de conceitos de programa√ß√£o e tendem a gerar c√≥digos mais corretos e eficientes.

2. **Tratamento de Erros**: O recurso de execu√ß√£o de c√≥digo inclui tratamento de erros. Se o c√≥digo executado gerar uma exce√ß√£o, o agente receber√° a mensagem de erro e poder√° tentar corrigir o c√≥digo ou
   fornecer solu√ß√µes alternativas. O par√¢metro `max_retry_limit`, que por padr√£o √© 2, controla o n√∫mero m√°ximo de tentativas para uma tarefa.

3. **Depend√™ncias**: Para usar o recurso de execu√ß√£o de c√≥digo, √© necess√°rio instalar o pacote `crewai_tools`. Caso n√£o esteja instalado, o agente registrar√° uma mensagem informativa:
   "Ferramentas de codifica√ß√£o n√£o dispon√≠veis. Instale crewai\_tools."

## Processo de Execu√ß√£o de C√≥digo

Quando um agente com execu√ß√£o de c√≥digo habilitada encontra uma tarefa que requer programa√ß√£o:

<Steps>
  <Step title="An√°lise da Tarefa">
    O agente analisa a tarefa e determina que a execu√ß√£o de c√≥digo √© necess√°ria.
  </Step>

  <Step title="Formula√ß√£o do C√≥digo">
    Ele formula o c√≥digo Python necess√°rio para resolver o problema.
  </Step>

  <Step title="Execu√ß√£o do C√≥digo">
    O c√≥digo √© enviado para a ferramenta interna de execu√ß√£o de c√≥digo (`CodeInterpreterTool`).
  </Step>

  <Step title="Interpreta√ß√£o dos Resultados">
    O agente interpreta o resultado e o incorpora na sua resposta ou o utiliza para aprofundar a solu√ß√£o do problema.
  </Step>
</Steps>

## Exemplo de Uso

Veja um exemplo detalhado de como criar um agente com capacidade de execu√ß√£o de c√≥digo e utiliz√°-lo em uma tarefa:

```python Code
from crewai import Agent, Task, Crew

# Create an agent with code execution enabled
coding_agent = Agent(
    role="Python Data Analyst",
    goal="Analyze data and provide insights using Python",
    backstory="You are an experienced data analyst with strong Python skills.",
    allow_code_execution=True
)

# Create a task that requires code execution
data_analysis_task = Task(
    description="Analyze the given dataset and calculate the average age of participants.",
    agent=coding_agent
)

# Create a crew and add the task
analysis_crew = Crew(
    agents=[coding_agent],
    tasks=[data_analysis_task]
)

# Execute the crew
result = analysis_crew.kickoff()

print(result)
```

Neste exemplo, o `coding_agent` pode escrever e executar c√≥digo Python para realizar tarefas de an√°lise de dados.


# Tarefas Condicionais
Source: https://docs.crewai.com/pt-BR/learn/conditional-tasks

Saiba como usar tarefas condicionais em um kickoff do crewAI

## Introdu√ß√£o

As Tarefas Condicionais no crewAI permitem a adapta√ß√£o din√¢mica do fluxo de trabalho com base nos resultados de tarefas anteriores.
Esse recurso poderoso possibilita que crews tomem decis√µes e executem tarefas seletivamente, aumentando a flexibilidade e a efici√™ncia dos seus processos orientados por IA.

## Exemplo de Uso

```python Code
from typing import List
from pydantic import BaseModel
from crewai import Agent, Crew
from crewai.tasks.conditional_task import ConditionalTask
from crewai.tasks.task_output import TaskOutput
from crewai.task import Task
from crewai_tools import SerperDevTool

# Define a condition function for the conditional task
# If false, the task will be skipped, if true, then execute the task.
def is_data_missing(output: TaskOutput) -> bool:
    return len(output.pydantic.events) < 10  # this will skip this task

# Define the agents
data_fetcher_agent = Agent(
    role="Data Fetcher",
    goal="Fetch data online using Serper tool",
    backstory="Backstory 1",
    verbose=True,
    tools=[SerperDevTool()]
)

data_processor_agent = Agent(
    role="Data Processor",
    goal="Process fetched data",
    backstory="Backstory 2",
    verbose=True
)

summary_generator_agent = Agent(
    role="Summary Generator",
    goal="Generate summary from fetched data",
    backstory="Backstory 3",
    verbose=True
)

class EventOutput(BaseModel):
    events: List[str]

task1 = Task(
    description="Fetch data about events in San Francisco using Serper tool",
    expected_output="List of 10 things to do in SF this week",
    agent=data_fetcher_agent,
    output_pydantic=EventOutput,
)

conditional_task = ConditionalTask(
    description="""
        Check if data is missing. If we have less than 10 events,
        fetch more events using Serper tool so that
        we have a total of 10 events in SF this week..
        """,
    expected_output="List of 10 Things to do in SF this week",
    condition=is_data_missing,
    agent=data_processor_agent,
)

task3 = Task(
    description="Generate summary of events in San Francisco from fetched data",
    expected_output="A complete report on the customer and their customers and competitors, including their demographics, preferences, market positioning and audience engagement.",
    agent=summary_generator_agent,
)

# Create a crew with the tasks
crew = Crew(
    agents=[data_fetcher_agent, data_processor_agent, summary_generator_agent],
    tasks=[task1, conditional_task, task3],
    verbose=True,
    planning=True
)

# Run the crew
result = crew.kickoff()
print("results", result)
```


# Criar Ferramentas Personalizadas
Source: https://docs.crewai.com/pt-BR/learn/create-custom-tools

Guia abrangente sobre como criar, utilizar e gerenciar ferramentas personalizadas dentro do framework CrewAI, incluindo novas funcionalidades e tratamento de erros.

## Criando e Utilizando Ferramentas no CrewAI

Este guia traz instru√ß√µes detalhadas sobre como criar ferramentas personalizadas para o framework CrewAI e como gerenciar e utilizar essas ferramentas de forma eficiente,
incorporando funcionalidades recentes, como delega√ß√£o de ferramentas, tratamento de erros e chamada din√¢mica de ferramentas. Destaca tamb√©m a import√¢ncia de ferramentas de colabora√ß√£o,
permitindo que agentes executem uma ampla gama de a√ß√µes.

### Subclassificando `BaseTool`

Para criar uma ferramenta personalizada, herde de `BaseTool` e defina os atributos necess√°rios, incluindo o `args_schema` para valida√ß√£o de entrada e o m√©todo `_run`.

```python Code
from typing import Type
from crewai.tools import BaseTool
from pydantic import BaseModel, Field

class MyToolInput(BaseModel):
    """Input schema for MyCustomTool."""
    argument: str = Field(..., description="Description of the argument.")

class MyCustomTool(BaseTool):
    name: str = "Name of my tool"
    description: str = "What this tool does. It's vital for effective utilization."
    args_schema: Type[BaseModel] = MyToolInput

    def _run(self, argument: str) -> str:
        # Your tool's logic here
        return "Tool's result"
```

### Usando o Decorador `tool`

Como alternativa, voc√™ pode utilizar o decorador de ferramenta `@tool`. Esta abordagem permite definir os atributos e as funcionalidades da ferramenta diretamente em uma fun√ß√£o,
oferecendo uma maneira concisa e eficiente de criar ferramentas especializadas de acordo com suas necessidades.

```python Code
from crewai.tools import tool

@tool("Tool Name")
def my_simple_tool(question: str) -> str:
    """Tool description for clarity."""
    # Tool logic here
    return "Tool output"
```

### Definindo uma Fun√ß√£o de Cache para a Ferramenta

Para otimizar o desempenho da ferramenta com cache, defina estrat√©gias de cache personalizadas utilizando o atributo `cache_function`.

```python Code
@tool("Tool with Caching")
def cached_tool(argument: str) -> str:
    """Tool functionality description."""
    return "Cacheable result"

def my_cache_strategy(arguments: dict, result: str) -> bool:
    # Define custom caching logic
    return True if some_condition else False

cached_tool.cache_function = my_cache_strategy
```

Seguindo essas orienta√ß√µes e incorporando novas funcionalidades e ferramentas de colabora√ß√£o nos seus processos de cria√ß√£o e gerenciamento de ferramentas,
voc√™ pode aproveitar ao m√°ximo as capacidades do framework CrewAI, aprimorando tanto a experi√™ncia de desenvolvimento quanto a efici√™ncia dos seus agentes de IA.


# Implementa√ß√£o de LLM Personalizada
Source: https://docs.crewai.com/pt-BR/learn/custom-llm

Aprenda a criar implementa√ß√µes personalizadas de LLM no CrewAI.

## Vis√£o Geral

O CrewAI oferece suporte a implementa√ß√µes personalizadas de LLM por meio da classe abstrata `BaseLLM`. Isso permite integrar qualquer provedor de LLM que n√£o tenha suporte nativo no LiteLLM ou implementar mecanismos de autentica√ß√£o personalizados.

## In√≠cio R√°pido

Aqui est√° uma implementa√ß√£o m√≠nima de LLM personalizada:

```python
# (n√£o traduzir blocos de c√≥digo)
```

## Usando Seu LLM Personalizado

```python
# (n√£o traduzir blocos de c√≥digo)
```

## M√©todos Necess√°rios

### Construtor: `__init__()`

**Cr√≠tico**: Voc√™ deve chamar `super().__init__(model, temperature)` com os par√¢metros necess√°rios:

```python
# (n√£o traduzir blocos de c√≥digo)
```

### M√©todo Abstrato: `call()`

O m√©todo `call()` √© o n√∫cleo da sua implementa√ß√£o de LLM. Ele deve:

* Aceitar mensagens (string ou lista de dicion√°rios com 'role' e 'content')
* Retornar uma resposta como string
* Lidar com ferramentas e chamada de fun√ß√µes, se suportado
* Lan√ßar exce√ß√µes apropriadas para erros

### M√©todos Opcionais

```python
# (n√£o traduzir blocos de c√≥digo)
```

## Padr√µes Comuns

### Tratamento de Erros

```python
# (n√£o traduzir blocos de c√≥digo)
```

### Autentica√ß√£o Personalizada

```python
# (n√£o traduzir blocos de c√≥digo)
```

### Suporte a Stop Words

O CrewAI adiciona automaticamente `"\nObservation:"` como stop word para controlar o comportamento do agente. Se o seu LLM suporta stop words:

```python
# (n√£o traduzir blocos de c√≥digo)
```

Se o seu LLM n√£o suporta stop words nativamente:

```python
# (n√£o traduzir blocos de c√≥digo)
```

## Chamada de Fun√ß√µes

Se o seu LLM suporta chamada de fun√ß√µes, implemente o fluxo completo:

```python
# (n√£o traduzir blocos de c√≥digo)
```

## Solu√ß√£o de Problemas

### Problemas Comuns

**Erros no Construtor**

```python
# ‚ùå Errado - par√¢metros obrigat√≥rios ausentes
def __init__(self, api_key: str):
    super().__init__()

# ‚úÖ Correto
def __init__(self, model: str, api_key: str, temperature: Optional[float] = None):
    super().__init__(model=model, temperature=temperature)
```

**Chamada de Fun√ß√µes N√£o Funciona**

* Certifique-se de que `supports_function_calling()` retorna `True`
* Verifique se voc√™ lida com `tool_calls` na resposta
* Assegure-se de que o par√¢metro `available_functions` est√° sendo corretamente utilizado

**Falhas de Autentica√ß√£o**

* Verifique o formato e as permiss√µes da chave de API
* Confira o formato do header de autentica√ß√£o
* Certifique-se de que as URLs dos endpoints est√£o corretas

**Erros de Parsing de Resposta**

* Valide a estrutura da resposta antes de acessar campos aninhados
* Trate casos em que o content pode ser None
* Adicione tratamento de erros para respostas malformadas

## Testando Seu LLM Personalizado

```python
# (n√£o traduzir blocos de c√≥digo)
```

Este guia cobre o essencial para implementar LLMs personalizados no CrewAI.


# Agente Gerente Personalizado
Source: https://docs.crewai.com/pt-BR/learn/custom-manager-agent

Saiba como definir um agente personalizado como gerente no CrewAI, proporcionando mais controle sobre o gerenciamento e a coordena√ß√£o das tarefas.

# Definindo um Agente Espec√≠fico como Gerente no CrewAI

O CrewAI permite que usu√°rios definam um agente espec√≠fico como gerente da crew, oferecendo mais controle sobre o gerenciamento e a coordena√ß√£o das tarefas.
Esse recurso possibilita a personaliza√ß√£o do papel gerencial para se adequar melhor √†s necessidades do seu projeto.

## Utilizando o Atributo `manager_agent`

### Agente Gerente Personalizado

O atributo `manager_agent` permite que voc√™ defina um agente personalizado para gerenciar a crew. Este agente supervisionar√° todo o processo, garantindo que as tarefas sejam conclu√≠das de forma eficiente e com o mais alto padr√£o de qualidade.

### Exemplo

```python Code
import os
from crewai import Agent, Task, Crew, Process

# Define your agents
researcher = Agent(
    role="Researcher",
    goal="Conduct thorough research and analysis on AI and AI agents",
    backstory="You're an expert researcher, specialized in technology, software engineering, AI, and startups. You work as a freelancer and are currently researching for a new client.",
    allow_delegation=False,
)

writer = Agent(
    role="Senior Writer",
    goal="Create compelling content about AI and AI agents",
    backstory="You're a senior writer, specialized in technology, software engineering, AI, and startups. You work as a freelancer and are currently writing content for a new client.",
    allow_delegation=False,
)

# Define your task
task = Task(
    description="Generate a list of 5 interesting ideas for an article, then write one captivating paragraph for each idea that showcases the potential of a full article on this topic. Return the list of ideas with their paragraphs and your notes.",
    expected_output="5 bullet points, each with a paragraph and accompanying notes.",
)

# Define the manager agent
manager = Agent(
    role="Project Manager",
    goal="Efficiently manage the crew and ensure high-quality task completion",
    backstory="You're an experienced project manager, skilled in overseeing complex projects and guiding teams to success. Your role is to coordinate the efforts of the crew members, ensuring that each task is completed on time and to the highest standard.",
    allow_delegation=True,
)

# Instantiate your crew with a custom manager
crew = Crew(
    agents=[researcher, writer],
    tasks=[task],
    manager_agent=manager,
    process=Process.hierarchical,
)

# Start the crew's work
result = crew.kickoff()
```

## Benef√≠cios de um Agente Gerente Personalizado

* **Controle aprimorado**: Adapte a abordagem de gerenciamento para atender √†s necessidades espec√≠ficas do seu projeto.
* **Coordena√ß√£o melhorada**: Assegure uma coordena√ß√£o e gest√£o eficiente das tarefas por um agente experiente.
* **Gest√£o personaliz√°vel**: Defina fun√ß√µes e responsabilidades gerenciais que estejam alinhadas aos objetivos do seu projeto.

## Definindo um Manager LLM

Se voc√™ estiver utilizando o processo hierarchical e n√£o quiser definir um agente gerente personalizado, √© poss√≠vel especificar o modelo de linguagem para o gerente:

```python Code
from crewai import LLM

manager_llm = LLM(model="gpt-4o")

crew = Crew(
    agents=[researcher, writer],
    tasks=[task],
    process=Process.hierarchical,
    manager_llm=manager_llm
)
```

<Note>
  √â necess√°rio definir `manager_agent` ou `manager_llm` ao utilizar o processo hierarchical.
</Note>


# Personalize Agentes
Source: https://docs.crewai.com/pt-BR/learn/customizing-agents

Um guia abrangente para adaptar agentes a fun√ß√µes espec√≠ficas, tarefas e customiza√ß√µes avan√ßadas dentro do framework CrewAI.

## Atributos Personaliz√°veis

A constru√ß√£o de uma equipe CrewAI eficiente depende da capacidade de adaptar dinamicamente seus agentes de IA para atender aos requisitos √∫nicos de qualquer projeto. Esta se√ß√£o aborda os atributos fundamentais que voc√™ pode personalizar.

### Principais Atributos para Personaliza√ß√£o

| Atributo                            | Descri√ß√£o                                                                                                                                    |
| :---------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------- |
| **Role**                            | Especifica a fun√ß√£o do agente dentro da equipe, como 'Analista' ou 'Representante de Atendimento ao Cliente'.                                |
| **Goal**                            | Define os objetivos do agente, alinhados √† sua fun√ß√£o e √† miss√£o geral da equipe.                                                            |
| **Backstory**                       | Fornece profundidade √† persona do agente, aprimorando motiva√ß√µes e engajamento dentro da equipe.                                             |
| **Tools** *(Opcional)*              | Representa as capacidades ou m√©todos que o agente utiliza para tarefas, desde fun√ß√µes simples at√© integra√ß√µes complexas.                     |
| **Cache** *(Opcional)*              | Determina se o agente deve usar cache para o uso de ferramentas.                                                                             |
| **Max RPM**                         | Define o n√∫mero m√°ximo de requisi√ß√µes por minuto (`max_rpm`). Pode ser definido como `None` para requisi√ß√µes ilimitadas a servi√ßos externos. |
| **Verbose** *(Opcional)*            | Ativa registros detalhados para depura√ß√£o e otimiza√ß√£o, fornecendo insights sobre os processos de execu√ß√£o.                                  |
| **Allow Delegation** *(Opcional)*   | Controla a delega√ß√£o de tarefas para outros agentes, padr√£o √© `False`.                                                                       |
| **Max Iter** *(Opcional)*           | Limita o n√∫mero m√°ximo de itera√ß√µes (`max_iter`) para uma tarefa, prevenindo loops infinitos, com valor padr√£o de 25.                        |
| **Max Execution Time** *(Opcional)* | Define o tempo m√°ximo permitido para que o agente complete uma tarefa.                                                                       |
| **System Template** *(Opcional)*    | Define o formato do sistema para o agente.                                                                                                   |
| **Prompt Template** *(Opcional)*    | Define o formato do prompt para o agente.                                                                                                    |
| **Response Template** *(Opcional)*  | Define o formato da resposta para o agente.                                                                                                  |
| **Use System Prompt** *(Opcional)*  | Controla se o agente ir√° usar um prompt de sistema durante a execu√ß√£o de tarefas.                                                            |
| **Respect Context Window**          | Ativa uma janela deslizante de contexto por padr√£o, mantendo o tamanho do contexto.                                                          |
| **Max Retry Limit**                 | Define o n√∫mero m√°ximo de tentativas (`max_retry_limit`) para um agente em caso de erros.                                                    |

## Op√ß√µes Avan√ßadas de Personaliza√ß√£o

Al√©m dos atributos b√°sicos, o CrewAI permite customiza√ß√µes mais profundas para aprimorar significativamente o comportamento e as capacidades de um agente.

### Personaliza√ß√£o de Modelo de Linguagem

Agentes podem ser personalizados com modelos de linguagem espec√≠ficos (`llm`) e modelos de linguagem com chamada de fun√ß√£o (`function_calling_llm`), oferecendo controle avan√ßado sobre o processamento e a tomada de decis√£o.
√â importante notar que definir o `function_calling_llm` permite sobrescrever o modelo padr√£o de chamada de fun√ß√£o da equipe, proporcionando maior grau de personaliza√ß√£o.

## Ajustes de Performance e Depura√ß√£o

Ajustar a performance do agente e monitorar suas opera√ß√µes √© fundamental para a execu√ß√£o eficiente de tarefas.

### Modo Verbose e Limite de RPM

* **Modo Verbose**: Ativa o registro detalhado das a√ß√µes do agente, √∫til para depura√ß√£o e otimiza√ß√£o. Especificamente, fornece insights sobre os processos de execu√ß√£o do agente, auxiliando na otimiza√ß√£o de performance.
* **Limite de RPM**: Define o n√∫mero m√°ximo de requisi√ß√µes por minuto (`max_rpm`). Este atributo √© opcional e pode ser definido como `None` para n√£o haver limite, permitindo consultas ilimitadas a servi√ßos externos, se necess√°rio.

### M√°ximo de Itera√ß√µes por Execu√ß√£o de Tarefa

O atributo `max_iter` permite ao usu√°rio definir o n√∫mero m√°ximo de itera√ß√µes que um agente pode executar para uma √∫nica tarefa, prevenindo loops infinitos ou execu√ß√µes excessivamente longas.
O valor padr√£o √© 25, fornecendo um equil√≠brio entre profundidade e efici√™ncia. Quando o agente chega pr√≥ximo a esse n√∫mero, ele tentar√° entregar a melhor resposta poss√≠vel.

## Personalizando Agentes e Ferramentas

Agentes s√£o personalizados definindo seus atributos e ferramentas durante a inicializa√ß√£o. As ferramentas s√£o cr√≠ticas para a funcionalidade do agente, permitindo que realizem tarefas especializadas.
O atributo `tools` deve ser um array de ferramentas que o agente pode utilizar, e, por padr√£o, √© inicializado como uma lista vazia. As ferramentas podem ser adicionadas ou modificadas ap√≥s a cria√ß√£o do agente para se adaptar a novos requisitos.

```shell
pip install 'crewai[tools]'
```

### Exemplo: Atribuindo Ferramentas a um Agente

```python Code
import os
from crewai import Agent
from crewai_tools import SerperDevTool

# Defina as chaves de API para inicializa√ß√£o da ferramenta
os.environ["OPENAI_API_KEY"] = "Sua Chave"
os.environ["SERPER_API_KEY"] = "Sua Chave"

# Inicialize uma ferramenta de busca
search_tool = SerperDevTool()

# Inicialize o agente com op√ß√µes avan√ßadas
agent = Agent(
  role='Analista de Pesquisa',
  goal='Fornecer an√°lises de mercado atualizadas',
  backstory='Um analista especialista com olhar atento para tend√™ncias de mercado.',
  tools=[search_tool],
  memory=True, # Ativa mem√≥ria
  verbose=True,
  max_rpm=None, # Sem limite de requisi√ß√µes por minuto
  max_iter=25, # Valor padr√£o de m√°ximo de itera√ß√µes
)
```

## Delega√ß√£o e Autonomia

Controlar a capacidade de um agente delegar tarefas ou fazer perguntas √© fundamental para ajustar sua autonomia e a din√¢mica de colabora√ß√£o dentro do framework CrewAI. Por padr√£o,
o atributo `allow_delegation` agora √© definido como `False`, desabilitando para que agentes busquem assist√™ncia ou deleguem tarefas conforme necess√°rio. Esse comportamento padr√£o pode ser alterado para promover resolu√ß√£o colaborativa de problemas e
efici√™ncia dentro do ecossistema CrewAI. Se necess√°rio, a delega√ß√£o pode ser ativada para atender requisitos operacionais espec√≠ficos.

### Exemplo: Desabilitando Delega√ß√£o para um Agente

```python Code
agent = Agent(
  role='Redator de Conte√∫do',
  goal='Escrever conte√∫do envolvente sobre tend√™ncias de mercado',
  backstory='Um redator experiente com expertise em an√°lise de mercado.',
  allow_delegation=True # Habilitando delega√ß√£o
)
```


# Gera√ß√£o de Imagens com DALL-E
Source: https://docs.crewai.com/pt-BR/learn/dalle-image-generation

Aprenda a usar o DALL-E para gera√ß√£o de imagens com IA em seus projetos CrewAI

O CrewAI oferece integra√ß√£o com o DALL-E da OpenAI, permitindo que seus agentes de IA gerem imagens como parte de suas tarefas. Este guia ir√° orient√°-lo sobre como configurar e utilizar a ferramenta DALL-E em seus projetos CrewAI.

## Pr√©-requisitos

* crewAI instalado (√∫ltima vers√£o)
* Chave de API OpenAI com acesso ao DALL-E

## Configurando a Ferramenta DALL-E

<Steps>
  <Step title="Importe a ferramenta DALL-E">
    ```python
    from crewai_tools import DallETool
    ```
  </Step>

  <Step title="Adicione a ferramenta DALL-E na configura√ß√£o do seu agente">
    ```python
    @agent
    def researcher(self) -> Agent:
        return Agent(
            config=self.agents_config['researcher'],
            tools=[SerperDevTool(), DallETool()],  # Add DallETool to the list of tools
            allow_delegation=False,
            verbose=True
        )
    ```
  </Step>
</Steps>

## Utilizando a Ferramenta DALL-E

Depois de adicionar a ferramenta DALL-E ao seu agente, ele poder√° gerar imagens baseadas em prompts de texto. A ferramenta retornar√° uma URL para a imagem gerada, que pode ser utilizada na resposta do agente ou repassada para outros agentes para processamento adicional.

### Exemplo de Configura√ß√£o de Agente

```yaml
role: >
    Pesquisador S√™nior de Dados para Perfis do LinkedIn
goal: >
    Encontrar perfis detalhados do LinkedIn com base no nome fornecido {name} e dom√≠nio {domain}
    Gerar uma imagem com o Dall-e baseada no dom√≠nio {domain}
backstory: >
    Voc√™ √© um pesquisador experiente com habilidade para encontrar os perfis do LinkedIn mais relevantes.
    Conhecido por sua efici√™ncia em navegar no LinkedIn, voc√™ se destaca em reunir e apresentar
    informa√ß√µes profissionais de forma clara e concisa.
```

### Resultado Esperado

O agente com a ferramenta DALL-E conseguir√° gerar a imagem e fornecer uma URL em sua resposta. Voc√™ poder√° ent√£o baixar a imagem.

<Frame>
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/dall-e-image.png" alt="Imagem DALL-E" />
</Frame>

## Boas Pr√°ticas

1. **Seja espec√≠fico nos prompts de gera√ß√£o de imagem** para obter melhores resultados.
2. **Considere o tempo de gera√ß√£o** - A gera√ß√£o de imagens pode levar algum tempo, ent√£o inclua isso no seu planejamento de tarefas.
3. **Siga as pol√≠ticas de uso** - Sempre cumpra as pol√≠ticas de uso da OpenAI ao gerar imagens.

## Solu√ß√£o de Problemas

1. **Verifique o acesso √† API** - Certifique-se de que sua chave de API OpenAI possui acesso ao DALL-E.
2. **Compatibilidade de vers√µes** - Verifique se voc√™ est√° utilizando a vers√£o mais recente do crewAI e crewai-tools.
3. **Configura√ß√£o da ferramenta** - Confirme que a ferramenta DALL-E foi corretamente adicionada √† lista de ferramentas do agente.


# For√ßar a Sa√≠da da Ferramenta como Resultado
Source: https://docs.crewai.com/pt-BR/learn/force-tool-output-as-result

Aprenda como for√ßar a sa√≠da de uma ferramenta como resultado em uma tarefa de Agent no CrewAI.

## Introdu√ß√£o

No CrewAI, voc√™ pode for√ßar a sa√≠da de uma ferramenta como o resultado de uma tarefa de um agent.\
Esse recurso √© √∫til quando voc√™ deseja garantir que a sa√≠da da ferramenta seja capturada e retornada como resultado da tarefa, evitando quaisquer modifica√ß√µes pelo agent durante a execu√ß√£o da tarefa.

## For√ßando a Sa√≠da da Ferramenta como Resultado

Para for√ßar a sa√≠da da ferramenta como resultado da tarefa de um agent, voc√™ precisa definir o par√¢metro `result_as_answer` como `True` ao adicionar uma ferramenta ao agent.\
Esse par√¢metro garante que a sa√≠da da ferramenta seja capturada e retornada como resultado da tarefa, sem qualquer modifica√ß√£o pelo agent.

Veja um exemplo de como for√ßar a sa√≠da da ferramenta como resultado da tarefa de um agent:

```python Code
from crewai.agent import Agent
from my_tool import MyCustomTool

# Create a coding agent with the custom tool
coding_agent = Agent(
        role="Data Scientist",
        goal="Produce amazing reports on AI",
        backstory="You work with data and AI",
        tools=[MyCustomTool(result_as_answer=True)],
    )

# Assuming the tool's execution and result population occurs within the system
task_result = coding_agent.execute_task(task)
```

## Fluxo de Trabalho em A√ß√£o

<Steps>
  <Step title="Execu√ß√£o da Tarefa">
    O agent executa a tarefa utilizando a ferramenta fornecida.
  </Step>

  <Step title="Sa√≠da da Ferramenta">
    A ferramenta gera a sa√≠da, que √© capturada como resultado da tarefa.
  </Step>

  <Step title="Intera√ß√£o do Agent">
    O agent pode refletir e aprender com a ferramenta, mas a sa√≠da n√£o √© modificada.
  </Step>

  <Step title="Retorno do Resultado">
    A sa√≠da da ferramenta √© retornada como resultado da tarefa sem quaisquer modifica√ß√µes.
  </Step>
</Steps>


# Processo Hier√°rquico
Source: https://docs.crewai.com/pt-BR/learn/hierarchical-process

Um guia abrangente para compreender e aplicar o processo hier√°rquico em seus projetos CrewAI, atualizado para refletir as pr√°ticas de codifica√ß√£o e funcionalidades mais recentes.

## Introdu√ß√£o

O processo hier√°rquico no CrewAI introduz uma abordagem estruturada para a gest√£o de tarefas, simulando hierarquias organizacionais tradicionais para uma delega√ß√£o e execu√ß√£o eficiente de tarefas.
Esse fluxo de trabalho sistem√°tico melhora os resultados do projeto ao garantir que as tarefas sejam tratadas com m√°xima efici√™ncia e precis√£o.

<Tip>
  O processo hier√°rquico foi projetado para alavancar modelos avan√ßados como o GPT-4, otimizando o uso de tokens enquanto lida com tarefas complexas de forma mais eficiente.
</Tip>

## Vis√£o Geral do Processo Hier√°rquico

Por padr√£o, as tarefas no CrewAI s√£o gerenciadas por meio de um processo sequencial. No entanto, adotar uma abordagem hier√°rquica permite uma hierarquia clara na gest√£o de tarefas,
onde um agente 'gerente' coordena o fluxo de trabalho, delega tarefas e valida os resultados para uma execu√ß√£o eficaz e simplificada. Esse agente gerente pode agora ser
criado automaticamente pelo CrewAI ou explicitamente definido pelo usu√°rio.

### Principais Caracter√≠sticas

* **Delega√ß√£o de Tarefas**: Um agente gerente distribui tarefas entre os membros da crew com base em seus pap√©is e capacidades.
* **Valida√ß√£o de Resultados**: O gerente avalia os resultados para garantir que atendam aos padr√µes exigidos.
* **Fluxo de Trabalho Eficiente**: Emula estruturas corporativas, oferecendo uma abordagem organizada para a gest√£o de tarefas.
* **Manipula√ß√£o de System Prompt**: Opcionalmente, especifique se o sistema deve usar prompts predefinidos.
* **Controle de Stop Words**: Opcionalmente, especifique se stop words devem ser usadas, oferecendo suporte a diversos modelos, incluindo os modelos o1.
* **Respeito √† Context Window**: Prioriza√ß√£o de contexto relevante ativando o respeito √† context window, que agora √© o comportamento padr√£o.
* **Controle de Delega√ß√£o**: A delega√ß√£o agora est√° desativada por padr√£o para dar controle expl√≠cito ao usu√°rio.
* **M√°ximo de Requisi√ß√µes por Minuto**: Op√ß√£o configur√°vel para definir o n√∫mero m√°ximo de requisi√ß√µes por minuto.
* **M√°ximo de Itera√ß√µes**: Limita√ß√£o do n√∫mero m√°ximo de itera√ß√µes at√© a obten√ß√£o de uma resposta final.

## Implementando o Processo Hier√°rquico

Para utilizar o processo hier√°rquico, √© essencial definir explicitamente o atributo de processo como `Process.hierarchical`, j√° que o comportamento padr√£o √© `Process.sequential`.
Defina uma crew com um gerente designado e estabele√ßa uma cadeia de comando clara.

<Tip>
  Atribua ferramentas no n√≠vel do agente para facilitar a delega√ß√£o e execu√ß√£o de tarefas pelos agentes designados sob a orienta√ß√£o do gerente.
  Ferramentas tamb√©m podem ser especificadas no n√≠vel da tarefa, para um controle preciso sobre a disponibilidade de ferramentas durante a execu√ß√£o das tarefas.
</Tip>

<Tip>
  Configurar o par√¢metro `manager_llm` √© fundamental para o processo hier√°rquico.
  O sistema exige a configura√ß√£o de um LLM do gerente para funcionar corretamente, garantindo tomadas de decis√£o personalizadas.
</Tip>

```python Code
from crewai import Crew, Process, Agent

# Agents are defined with attributes for backstory, cache, and verbose mode
researcher = Agent(
    role='Researcher',
    goal='Conduct in-depth analysis',
    backstory='Experienced data analyst with a knack for uncovering hidden trends.',
)
writer = Agent(
    role='Writer',
    goal='Create engaging content',
    backstory='Creative writer passionate about storytelling in technical domains.',
)

# Establishing the crew with a hierarchical process and additional configurations
project_crew = Crew(
    tasks=[...],  # Tasks to be delegated and executed under the manager's supervision
    agents=[researcher, writer],
    manager_llm="gpt-4o",  # Specify which LLM the manager should use
    process=Process.hierarchical,
    planning=True,
)
```

### Usando um Agente Gerente Personalizado

Alternativamente, voc√™ pode criar um agente gerente personalizado com atributos espec√≠ficos adaptados √†s necessidades de gest√£o do seu projeto. Isso oferece maior controle sobre o comportamento e as capacidades do gerente.

```python
# Define a custom manager agent
manager = Agent(
    role="Project Manager",
    goal="Efficiently manage the crew and ensure high-quality task completion",
    backstory="You're an experienced project manager, skilled in overseeing complex projects and guiding teams to success.",
    allow_delegation=True,
)

# Use the custom manager in your crew
project_crew = Crew(
    tasks=[...],
    agents=[researcher, writer],
    manager_agent=manager,  # Use your custom manager agent
    process=Process.hierarchical,
    planning=True,
)
```

<Tip>
  Para mais detalhes sobre a cria√ß√£o e personaliza√ß√£o de um agente gerente, confira a [documenta√ß√£o do Custom Manager Agent](https://docs.crewai.com/how-to/custom-manager-agent#custom-manager-agent).
</Tip>

### Fluxo de Trabalho na Pr√°tica

1. **Atribui√ß√£o de Tarefas**: O gerente atribui as tarefas estrategicamente, considerando as capacidades de cada agente e as ferramentas dispon√≠veis.
2. **Execu√ß√£o e Revis√£o**: Os agentes concluem suas tarefas com a op√ß√£o de execu√ß√£o ass√≠ncrona e fun√ß√µes de callback para fluxos de trabalho otimizados.
3. **Progresso Sequencial das Tarefas**: Apesar de ser um processo hier√°rquico, as tarefas seguem uma ordem l√≥gica para um progresso fluido, facilitado pela supervis√£o do gerente.

## Conclus√£o

Adotar o processo hier√°rquico no CrewAI, com as configura√ß√µes corretas e o entendimento das capacidades do sistema, facilita uma abordagem organizada e eficiente para o gerenciamento de projetos.
Aproveite os recursos avan√ßados e as personaliza√ß√µes para ajustar o fluxo de trabalho conforme suas necessidades, garantindo a execu√ß√£o ideal das tarefas e o sucesso do projeto.


# Workflows Human-in-the-Loop (HITL)
Source: https://docs.crewai.com/pt-BR/learn/human-in-the-loop

Aprenda como implementar workflows Human-in-the-Loop na CrewAI para aprimorar a tomada de decis√µes

Human-in-the-Loop (HITL) √© uma abordagem poderosa que combina a intelig√™ncia artificial com a experi√™ncia humana para aprimorar a tomada de decis√µes e melhorar os resultados das tarefas. Este guia mostra como implementar HITL dentro da CrewAI.

## Configurando Workflows HITL

<Steps>
  <Step title="Configure sua Tarefa">
    Configure sua tarefa com a entrada humana habilitada:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-human-input.png" alt="Entrada Humana Crew" />
    </Frame>
  </Step>

  <Step title="Forne√ßa a URL do Webhook">
    Ao iniciar seu crew, inclua uma URL de webhook para entrada humana:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-webhook-url.png" alt="URL do Webhook Crew" />
    </Frame>
  </Step>

  <Step title="Receba Notifica√ß√£o do Webhook">
    Assim que o crew concluir a tarefa que requer entrada humana, voc√™ receber√° uma notifica√ß√£o de webhook contendo:

    * Execution ID
    * Task ID
    * Task output
  </Step>

  <Step title="Revise o Resultado da Tarefa">
    O sistema ir√° pausar no estado `Pending Human Input`. Revise cuidadosamente o resultado da tarefa.
  </Step>

  <Step title="Envie o Feedback Humano">
    Chame o endpoint de retomada do seu crew com as seguintes informa√ß√µes:

    <Frame>
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-resume-endpoint.png" alt="Endpoint de Retomada Crew" />
    </Frame>

    <Warning>
      **Impacto do Feedback na Execu√ß√£o da Tarefa**:
      √â fundamental ter cuidado ao fornecer feedback, pois todo o conte√∫do do feedback ser√° incorporado como contexto adicional para execu√ß√µes futuras da tarefa.
    </Warning>

    Isso significa:

    * Todas as informa√ß√µes do seu feedback passam a fazer parte do contexto da tarefa.
    * Detalhes irrelevantes podem influenciar negativamente.
    * Feedback conciso e relevante ajuda a manter o foco e a efici√™ncia da tarefa.
    * Sempre revise seu feedback cuidadosamente antes de enviar para garantir que contenha apenas informa√ß√µes pertinentes que ir√£o guiar positivamente a execu√ß√£o da tarefa.
  </Step>

  <Step title="Lidar com Feedback Negativo">
    Se voc√™ fornecer um feedback negativo:

    * O crew ir√° tentar novamente a tarefa com o contexto adicionado do seu feedback.
    * Voc√™ receber√° outra notifica√ß√£o de webhook para nova revis√£o.
    * Repita os passos 4-6 at√© ficar satisfeito.
  </Step>

  <Step title="Continua√ß√£o da Execu√ß√£o">
    Quando voc√™ enviar um feedback positivo, a execu√ß√£o prosseguir√° para as pr√≥ximas etapas.
  </Step>
</Steps>

## Melhores Pr√°ticas

* **Seja Espec√≠fico**: Forne√ßa feedback claro e acion√°vel que trate diretamente da tarefa em quest√£o
* **Mantenha-se Relevante**: Inclua apenas informa√ß√µes que ajudem a melhorar a execu√ß√£o da tarefa
* **Seja √Ågil**: Responda rapidamente √†s solicita√ß√µes HITL para evitar atrasos no fluxo
* **Reveja Cuidadosamente**: Verifique seu feedback antes de enviar para garantir a precis√£o

## Casos de Uso Comuns

Workflows HITL s√£o particularmente valiosos para:

* Garantia de qualidade e valida√ß√£o
* Cen√°rios de tomada de decis√£o complexa
* Opera√ß√µes sens√≠veis ou de alto risco
* Tarefas criativas que requerem julgamento humano
* Revis√µes de conformidade e regulamenta√ß√£o


# Input Humano na Execu√ß√£o
Source: https://docs.crewai.com/pt-BR/learn/human-input-on-execution

Integrando o CrewAI com input humano durante a execu√ß√£o em processos complexos de tomada de decis√£o e aproveitando ao m√°ximo todos os atributos e ferramentas do agente.

## Input humano na execu√ß√£o dos agentes

O input humano √© fundamental em v√°rios cen√°rios de execu√ß√£o de agentes, permitindo que os agentes solicitem informa√ß√µes adicionais ou esclarecimentos quando necess√°rio.
Esse recurso √© especialmente √∫til em processos complexos de tomada de decis√£o ou quando os agentes precisam de mais detalhes para concluir uma tarefa de forma eficaz.

## Usando input humano com CrewAI

Para integrar input humano durante a execu√ß√£o do agente, defina o par√¢metro `human_input` na defini√ß√£o da tarefa. Quando ativado, o agente solicitar√° informa√ß√µes ao usu√°rio antes de fornecer sua resposta final.
Esse input pode oferecer contexto extra, esclarecer ambiguidades ou validar a sa√≠da produzida pelo agente.

### Exemplo:

```shell
pip install crewai
```

```python Code
import os
from crewai import Agent, Task, Crew
from crewai_tools import SerperDevTool

os.environ["SERPER_API_KEY"] = "Your Key"  # serper.dev API key
os.environ["OPENAI_API_KEY"] = "Your Key"

# Loading Tools
search_tool = SerperDevTool()

# Define your agents with roles, goals, tools, and additional attributes
researcher = Agent(
    role='Senior Research Analyst',
    goal='Uncover cutting-edge developments in AI and data science',
    backstory=(
        "You are a Senior Research Analyst at a leading tech think tank. "
        "Your expertise lies in identifying emerging trends and technologies in AI and data science. "
        "You have a knack for dissecting complex data and presenting actionable insights."
    ),
    verbose=True,
    allow_delegation=False,
    tools=[search_tool]
)
writer = Agent(
    role='Tech Content Strategist',
    goal='Craft compelling content on tech advancements',
    backstory=(
        "You are a renowned Tech Content Strategist, known for your insightful and engaging articles on technology and innovation. "
        "With a deep understanding of the tech industry, you transform complex concepts into compelling narratives."
    ),
    verbose=True,
    allow_delegation=True,
    tools=[search_tool],
    cache=False,  # Disable cache for this agent
)

# Create tasks for your agents
task1 = Task(
    description=(
        "Conduct a comprehensive analysis of the latest advancements in AI in 2025. "
        "Identify key trends, breakthrough technologies, and potential industry impacts. "
        "Compile your findings in a detailed report. "
        "Make sure to check with a human if the draft is good before finalizing your answer."
    ),
    expected_output='A comprehensive full report on the latest AI advancements in 2025, leave nothing out',
    agent=researcher,
    human_input=True
)

task2 = Task(
    description=(
        "Using the insights from the researcher\'s report, develop an engaging blog post that highlights the most significant AI advancements. "
        "Your post should be informative yet accessible, catering to a tech-savvy audience. "
        "Aim for a narrative that captures the essence of these breakthroughs and their implications for the future."
    ),
    expected_output='A compelling 3 paragraphs blog post formatted as markdown about the latest AI advancements in 2025',
    agent=writer,
    human_input=True
)

# Instantiate your crew with a sequential process
crew = Crew(
    agents=[researcher, writer],
    tasks=[task1, task2],
    verbose=True,
    memory=True,
    planning=True  # Enable planning feature for the crew
)

# Get your crew to work!
result = crew.kickoff()

print("######################")
print(result)
```


# Inicie uma Crew de Forma Ass√≠ncrona
Source: https://docs.crewai.com/pt-BR/learn/kickoff-async

Inicie uma Crew de Forma Ass√≠ncrona

## Introdu√ß√£o

A CrewAI oferece a capacidade de iniciar uma crew de forma ass√≠ncrona, permitindo que voc√™ comece a execu√ß√£o da crew de maneira n√£o bloqueante.
Esse recurso √© especialmente √∫til quando voc√™ deseja executar m√∫ltiplas crews simultaneamente ou quando precisa realizar outras tarefas enquanto a crew est√° em execu√ß√£o.

## Execu√ß√£o Ass√≠ncrona de Crew

Para iniciar uma crew de forma ass√≠ncrona, utilize o m√©todo `kickoff_async()`. Este m√©todo inicia a execu√ß√£o da crew em uma thread separada, permitindo que a thread principal continue executando outras tarefas.

### Assinatura do M√©todo

```python Code
def kickoff_async(self, inputs: dict) -> CrewOutput:
```

### Par√¢metros

* `inputs` (dict): Um dicion√°rio contendo os dados de entrada necess√°rios para as tarefas.

### Retorno

* `CrewOutput`: Um objeto que representa o resultado da execu√ß√£o da crew.

## Poss√≠veis Casos de Uso

* **Gera√ß√£o Paralela de Conte√∫do**: Inicie m√∫ltiplas crews independentes de forma ass√≠ncrona, cada uma respons√°vel por gerar conte√∫do sobre temas diferentes. Por exemplo, uma crew pode pesquisar e redigir um artigo sobre tend√™ncias em IA, enquanto outra gera posts para redes sociais sobre o lan√ßamento de um novo produto. Cada crew atua de forma independente, permitindo a escala eficiente da produ√ß√£o de conte√∫do.

* **Tarefas Conjuntas de Pesquisa de Mercado**: Lance m√∫ltiplas crews de forma ass√≠ncrona para realizar pesquisas de mercado em paralelo. Uma crew pode analisar tend√™ncias do setor, outra examinar estrat√©gias de concorrentes e ainda outra avaliar o sentimento do consumidor. Cada crew conclui sua tarefa de forma independente, proporcionando insights mais r√°pidos e abrangentes.

* **M√≥dulos Independentes de Planejamento de Viagem**: Execute crews separadas para planejar diferentes aspectos de uma viagem de forma independente. Uma crew pode cuidar das op√ß√µes de voo, outra das acomoda√ß√µes e uma terceira do planejamento das atividades. Cada crew trabalha de maneira ass√≠ncrona, permitindo que os v√°rios componentes da viagem sejam planejados ao mesmo tempo e de maneira independente, para resultados mais r√°pidos.

## Exemplo: Execu√ß√£o Ass√≠ncrona de uma √önica Crew

Veja um exemplo de como iniciar uma crew de forma ass√≠ncrona utilizando asyncio e aguardando o resultado:

```python Code
import asyncio
from crewai import Crew, Agent, Task

# Create an agent with code execution enabled
coding_agent = Agent(
    role="Analista de Dados Python",
    goal="Analisar dados e fornecer insights usando Python",
    backstory="Voc√™ √© um analista de dados experiente com fortes habilidades em Python.",
    allow_code_execution=True
)

# Create a task that requires code execution
data_analysis_task = Task(
    description="Analise o conjunto de dados fornecido e calcule a idade m√©dia dos participantes. Idades: {ages}",
    agent=coding_agent,
    expected_output="A idade m√©dia dos participantes."
)

# Create a crew and add the task
analysis_crew = Crew(
    agents=[coding_agent],
    tasks=[data_analysis_task]
)

# Async function to kickoff the crew asynchronously
async def async_crew_execution():
    result = await analysis_crew.kickoff_async(inputs={"ages": [25, 30, 35, 40, 45]})
    print("Crew Result:", result)

# Run the async function
asyncio.run(async_crew_execution())
```

## Exemplo: Execu√ß√£o Ass√≠ncrona de M√∫ltiplas Crews

Neste exemplo, mostraremos como iniciar m√∫ltiplas crews de forma ass√≠ncrona e aguardar todas serem conclu√≠das usando `asyncio.gather()`:

```python Code
import asyncio
from crewai import Crew, Agent, Task

# Create an agent with code execution enabled
coding_agent = Agent(
    role="Analista de Dados Python",
    goal="Analisar dados e fornecer insights usando Python",
    backstory="Voc√™ √© um analista de dados experiente com fortes habilidades em Python.",
    allow_code_execution=True
)

# Create tasks that require code execution
task_1 = Task(
    description="Analise o primeiro conjunto de dados e calcule a idade m√©dia dos participantes. Idades: {ages}",
    agent=coding_agent,
    expected_output="A idade m√©dia dos participantes."
)

task_2 = Task(
    description="Analise o segundo conjunto de dados e calcule a idade m√©dia dos participantes. Idades: {ages}",
    agent=coding_agent,
    expected_output="A idade m√©dia dos participantes."
)

# Create two crews and add tasks
crew_1 = Crew(agents=[coding_agent], tasks=[task_1])
crew_2 = Crew(agents=[coding_agent], tasks=[task_2])

# Async function to kickoff multiple crews asynchronously and wait for all to finish
async def async_multiple_crews():
    # Create coroutines for concurrent execution
    result_1 = crew_1.kickoff_async(inputs={"ages": [25, 30, 35, 40, 45]})
    result_2 = crew_2.kickoff_async(inputs={"ages": [20, 22, 24, 28, 30]})

    # Wait for both crews to finish
    results = await asyncio.gather(result_1, result_2)

    for i, result in enumerate(results, 1):
        print(f"Crew {i} Result:", result)

# Run the async function
asyncio.run(async_multiple_crews())
```


# Kickoff Crew para Cada
Source: https://docs.crewai.com/pt-BR/learn/kickoff-for-each

Kickoff Crew para Cada Item em uma Lista

## Introdu√ß√£o

A CrewAI oferece a capacidade de iniciar um crew para cada item em uma lista, permitindo que voc√™ execute o crew para cada item da lista.
Esse recurso √© particularmente √∫til quando √© necess√°rio realizar o mesmo conjunto de tarefas para v√°rios itens.

## Iniciando um Crew para Cada Item

Para iniciar um crew para cada item em uma lista, utilize o m√©todo `kickoff_for_each()`.
Esse m√©todo executa o crew para cada item da lista, permitindo o processamento eficiente de m√∫ltiplos itens.

Veja um exemplo de como iniciar um crew para cada item em uma lista:

```python Code
from crewai import Crew, Agent, Task

# Create an agent with code execution enabled
coding_agent = Agent(
    role="Python Data Analyst",
    goal="Analyze data and provide insights using Python",
    backstory="You are an experienced data analyst with strong Python skills.",
    allow_code_execution=True
)

# Create a task that requires code execution
data_analysis_task = Task(
    description="Analyze the given dataset and calculate the average age of participants. Ages: {ages}",
    agent=coding_agent,
    expected_output="The average age calculated from the dataset"
)

# Create a crew and add the task
analysis_crew = Crew(
    agents=[coding_agent],
    tasks=[data_analysis_task],
    verbose=True,
    memory=False
)

datasets = [
  { "ages": [25, 30, 35, 40, 45] },
  { "ages": [20, 25, 30, 35, 40] },
  { "ages": [30, 35, 40, 45, 50] }
]

# Execute the crew
result = analysis_crew.kickoff_for_each(inputs=datasets)
```


# Conecte-se a qualquer LLM
Source: https://docs.crewai.com/pt-BR/learn/llm-connections

Guia abrangente sobre como integrar o CrewAI a diversos Large Language Models (LLMs) usando o LiteLLM, incluindo provedores compat√≠veis e op√ß√µes de configura√ß√£o.

## Conecte o CrewAI a LLMs

O CrewAI utiliza o LiteLLM para conectar-se a uma grande variedade de Modelos de Linguagem (LLMs). Essa integra√ß√£o proporciona grande versatilidade, permitindo que voc√™ utilize modelos de in√∫meros provedores por meio de uma interface simples e unificada.

<Note>
  Por padr√£o, o CrewAI usa o modelo `gpt-4o-mini`. Isso √© determinado pela vari√°vel de ambiente `OPENAI_MODEL_NAME`, que tem como padr√£o "gpt-4o-mini" se n√£o for definida.
  Voc√™ pode facilmente configurar seus agentes para usar um modelo ou provedor diferente, conforme descrito neste guia.
</Note>

## Provedores Compat√≠veis

O LiteLLM oferece suporte a uma ampla gama de provedores, incluindo, mas n√£o se limitando a:

* OpenAI
* Anthropic
* Google (Vertex AI, Gemini)
* Azure OpenAI
* AWS (Bedrock, SageMaker)
* Cohere
* VoyageAI
* Hugging Face
* Ollama
* Mistral AI
* Replicate
* Together AI
* AI21
* Cloudflare Workers AI
* DeepInfra
* Groq
* SambaNova
* [NVIDIA NIMs](https://docs.api.nvidia.com/nim/reference/models-1)
* E muitos outros!

Para uma lista completa e sempre atualizada dos provedores suportados, consulte a [documenta√ß√£o de Provedores do LiteLLM](https://docs.litellm.ai/docs/providers).

## Alterando a LLM

Para utilizar uma LLM diferente com seus agentes CrewAI, voc√™ tem v√°rias op√ß√µes:

<Tabs>
  <Tab title="Usando um Identificador de String">
    Passe o nome do modelo como uma string ao inicializar o agente:

    <CodeGroup>
      ```python Code
      from crewai import Agent

      # Usando o GPT-4 da OpenAI
      openai_agent = Agent(
          role='OpenAI Expert',
          goal='Provide insights using GPT-4',
          backstory="An AI assistant powered by OpenAI's latest model.",
          llm='gpt-4'
      )

      # Usando o Claude da Anthropic
      claude_agent = Agent(
          role='Anthropic Expert',
          goal='Analyze data using Claude',
          backstory="An AI assistant leveraging Anthropic's language model.",
          llm='claude-2'
      )
      ```
    </CodeGroup>
  </Tab>

  <Tab title="Usando a Classe LLM">
    Para uma configura√ß√£o mais detalhada, utilize a classe LLM:

    <CodeGroup>
      ```python Code
      from crewai import Agent, LLM

      llm = LLM(
          model="gpt-4",
          temperature=0.7,
          base_url="https://api.openai.com/v1",
          api_key="your-api-key-here"
      )

      agent = Agent(
          role='Customized LLM Expert',
          goal='Provide tailored responses',
          backstory="An AI assistant with custom LLM settings.",
          llm=llm
      )
      ```
    </CodeGroup>
  </Tab>
</Tabs>

## Op√ß√µes de Configura√ß√£o

Ao configurar uma LLM para o seu agente, voc√™ tem acesso a uma variedade de par√¢metros:

| Par√¢metro              |        Tipo        | Descri√ß√£o                                                                  |
| :--------------------- | :----------------: | :------------------------------------------------------------------------- |
| **model**              |        `str`       | O nome do modelo a ser utilizado (ex.: "gpt-4", "claude-2")                |
| **temperature**        |       `float`      | Controla o grau de aleatoriedade nas respostas (0.0 a 1.0)                 |
| **max\_tokens**        |        `int`       | N√∫mero m√°ximo de tokens a serem gerados                                    |
| **top\_p**             |       `float`      | Controla a diversidade das respostas (0.0 a 1.0)                           |
| **frequency\_penalty** |       `float`      | Penaliza novos tokens com base na frequ√™ncia em que j√° apareceram no texto |
| **presence\_penalty**  |       `float`      | Penaliza novos tokens com base na presen√ßa deles no texto at√© o momento    |
| **stop**               | `str`, `List[str]` | Sequ√™ncia(s) que interrompem a gera√ß√£o do texto                            |
| **base\_url**          |        `str`       | URL base do endpoint da API                                                |
| **api\_key**           |        `str`       | Sua chave de API para autentica√ß√£o                                         |

Para uma lista completa de par√¢metros e suas respectivas descri√ß√µes, consulte a documenta√ß√£o da classe LLM.

## Conectando-se a LLMs Compat√≠veis com OpenAI

Voc√™ pode se conectar a LLMs compat√≠veis com a OpenAI usando vari√°veis de ambiente ou definindo atributos espec√≠ficos na classe LLM:

<Tabs>
  <Tab title="Usando Vari√°veis de Ambiente">
    <CodeGroup>
      ```python Generic
      import os

      os.environ["OPENAI_API_KEY"] = "your-api-key"
      os.environ["OPENAI_API_BASE"] = "https://api.your-provider.com/v1"
      os.environ["OPENAI_MODEL_NAME"] = "your-model-name"
      ```

      ```python Google
      import os

      # Exemplo usando a API compat√≠vel com OpenAI do Gemini.
      os.environ["OPENAI_API_KEY"] = "your-gemini-key"  # Deve come√ßar com AIza...
      os.environ["OPENAI_API_BASE"] = "https://generativelanguage.googleapis.com/v1beta/openai/"
      os.environ["OPENAI_MODEL_NAME"] = "openai/gemini-2.0-flash"  # Adicione aqui seu modelo do Gemini, sob openai/
      ```
    </CodeGroup>
  </Tab>

  <Tab title="Usando Atributos da Classe LLM">
    <CodeGroup>
      ```python Generic
      llm = LLM(
          model="custom-model-name",
          api_key="your-api-key",
          base_url="https://api.your-provider.com/v1"
      )
      agent = Agent(llm=llm, ...)
      ```

      ```python Google
      # Exemplo usando a API compat√≠vel com OpenAI do Gemini
      llm = LLM(
          model="openai/gemini-2.0-flash",
          base_url="https://generativelanguage.googleapis.com/v1beta/openai/",
          api_key="your-gemini-key",  # Deve come√ßar com AIza...
      )
      agent = Agent(llm=llm, ...)
      ```
    </CodeGroup>
  </Tab>
</Tabs>

## Utilizando Modelos Locais com Ollama

Para modelos locais como os oferecidos pelo Ollama:

<Steps>
  <Step title="Baixe e instale o Ollama">
    [Clique aqui para baixar e instalar o Ollama](https://ollama.com/download)
  </Step>

  <Step title="Puxe o modelo desejado">
    Por exemplo, execute `ollama pull llama3.2` para baixar o modelo.
  </Step>

  <Step title="Configure seu agente">
    <CodeGroup>
      ```python Code
          agent = Agent(
              role='Local AI Expert',
              goal='Process information using a local model',
              backstory="An AI assistant running on local hardware.",
              llm=LLM(model="ollama/llama3.2", base_url="http://localhost:11434")
          )
      ```
    </CodeGroup>
  </Step>
</Steps>

## Alterando a URL Base da API

Voc√™ pode alterar a URL base da API para qualquer provedor de LLM definindo o par√¢metro `base_url`:

```python Code
llm = LLM(
    model="custom-model-name",
    base_url="https://api.your-provider.com/v1",
    api_key="your-api-key"
)
agent = Agent(llm=llm, ...)
```

Isso √© particularmente √∫til ao trabalhar com APIs compat√≠veis com a OpenAI ou quando voc√™ precisa especificar um endpoint diferente para o provedor escolhido.

## Conclus√£o

Ao utilizar o LiteLLM, o CrewAI oferece integra√ß√£o transparente com uma vasta gama de LLMs. Essa flexibilidade permite que voc√™ escolha o modelo mais adequado para sua necessidade espec√≠fica, seja priorizando desempenho, custo-benef√≠cio ou implanta√ß√£o local. Lembre-se de consultar a [documenta√ß√£o do LiteLLM](https://docs.litellm.ai/docs/) para obter as informa√ß√µes mais atualizadas sobre modelos suportados e op√ß√µes de configura√ß√£o.


# Guia Estrat√©gico de Sele√ß√£o de LLMs
Source: https://docs.crewai.com/pt-BR/learn/llm-selection-guide

Framework estrat√©gico para escolher o LLM certo para seus agentes CrewAI e escrever defini√ß√µes eficazes de tarefas e agentes

## A Abordagem CrewAI para Sele√ß√£o de LLMs

Em vez de recomenda√ß√µes prescritivas de modelos, defendemos um **framework de pensamento** que ajude voc√™ a tomar decis√µes informadas com base no seu caso de uso, restri√ß√µes e requisitos espec√≠ficos. O cen√°rio de LLMs evolui rapidamente, com novos modelos surgindo regularmente e os existentes sendo atualizados frequentemente. O que mais importa √© desenvolver uma abordagem sistem√°tica de avalia√ß√£o que permane√ßa relevante independentemente dos modelos dispon√≠veis no momento.

<Note>
  Este guia foca em pensamento estrat√©gico em vez de recomenda√ß√µes de modelos espec√≠ficos, j√° que o cen√°rio dos LLMs evolui rapidamente.
</Note>

## Framework de Decis√£o R√°pida

<Steps>
  <Step title="Analise Suas Tarefas">
    Comece entendendo profundamente o que suas tarefas realmente exigem. Considere a complexidade cognitiva envolvida, a profundidade de racioc√≠nio necess√°ria, o formato dos resultados esperados e a quantidade de contexto que o modelo precisar√° processar. Essa an√°lise fundamental guiar√° todas as decis√µes seguintes.
  </Step>

  <Step title="Mapeie as Capacidades dos Modelos">
    Assim que voc√™ compreende seus requisitos, mapeie-os para as for√ßas dos modelos. Diferentes fam√≠lias de modelos se destacam em diferentes tipos de trabalho; alguns s√£o otimizados para racioc√≠nio e an√°lise, outros para criatividade e gera√ß√£o de conte√∫do, e outros para velocidade e efici√™ncia.
  </Step>

  <Step title="Considere Restri√ß√µes">
    Leve em conta suas reais restri√ß√µes operacionais, incluindo limita√ß√µes or√ßament√°rias, requisitos de lat√™ncia, necessidades de privacidade de dados e capacidades de infraestrutura. O melhor modelo teoricamente pode n√£o ser a melhor escolha pr√°tica para sua situa√ß√£o.
  </Step>

  <Step title="Teste e Itere">
    Comece com modelos confi√°veis e bem conhecidos e otimize com base no desempenho real no seu caso de uso. Os resultados pr√°ticos frequentemente diferem dos benchmarks te√≥ricos, ent√£o testes emp√≠ricos s√£o cruciais.
  </Step>
</Steps>

## Framework Central de Sele√ß√£o

### a. Pensamento Orientado √† Tarefa

O passo mais cr√≠tico na sele√ß√£o de LLMs √© entender o que sua tarefa realmente exige. Frequentemente, equipes escolhem modelos com base em reputa√ß√£o geral ou pontua√ß√µes de benchmark, sem analisar cuidadosamente suas necessidades espec√≠ficas. Essa abordagem leva tanto ao superdimensionamento de tarefas simples usando modelos caros e complexos quanto √† subutiliza√ß√£o em tarefas sofisticadas com modelos sem as capacidades necess√°rias.

<Tabs>
  <Tab title="Complexidade de Racioc√≠nio">
    * **Tarefas Simples** representam a maioria do trabalho di√°rio de IA e incluem seguir instru√ß√µes b√°sicas, processar dados simples e formata√ß√£o elementar. Estas tarefas geralmente t√™m entradas e sa√≠das claras, com m√≠nima ambiguidade. A carga cognitiva √© baixa e o modelo precisa apenas seguir instru√ß√µes expl√≠citas, n√£o realizar racioc√≠nio complexo.

    * **Tarefas Complexas** exigem racioc√≠nio de m√∫ltiplas etapas, pensamento estrat√©gico e a capacidade de lidar com informa√ß√µes amb√≠guas ou incompletas. Podem envolver an√°lise de m√∫ltiplas fontes de dados, desenvolvimento de estrat√©gias abrangentes ou resolu√ß√£o de problemas que precisam ser decompostos em componentes menores. O modelo deve manter o contexto ao longo de v√°rias etapas de racioc√≠nio e frequentemente precisa inferir informa√ß√µes n√£o explicitamente declaradas.

    * **Tarefas Criativas** exigem um tipo diferente de capacidade cognitiva, focada em gerar conte√∫do novo, envolvente e adequado ao contexto. Isso inclui storytelling, cria√ß√£o de textos de marketing e solu√ß√£o criativa de problemas. O modelo deve compreender nuances, tom e p√∫blico, produzindo conte√∫do aut√™ntico e envolvente, n√£o apenas f√≥rmulas.
  </Tab>

  <Tab title="Requisitos de Sa√≠da">
    * **Dados Estruturados** exigem precis√£o e consist√™ncia na ades√£o ao formato. Ao trabalhar com JSON, XML ou formatos de banco de dados, o modelo deve produzir sa√≠das sintaticamente corretas, que possam ser processadas programaticamente. Essas tarefas possuem requisitos r√≠gidos de valida√ß√£o e pouca toler√¢ncia a erros de formato, tornando a confiabilidade mais importante que a criatividade.

    * **Conte√∫do Criativo** requer equil√≠brio entre compet√™ncia t√©cnica e criatividade. O modelo precisa compreender o p√∫blico, tom e voz da marca, ao mesmo tempo em que produz conte√∫do que engaja leitores e atinge objetivos comunicativos espec√≠ficos. A qualidade aqui √© mais subjetiva e exige modelos capazes de adaptar o estilo de escrita a diferentes contextos e prop√≥sitos.

    * **Conte√∫do T√©cnico** situa-se entre dados estruturados e conte√∫do criativo, demandando precis√£o e clareza. Documenta√ß√£o, gera√ß√£o de c√≥digo e an√°lises t√©cnicas precisam ser exatas e completas, mas ainda assim acess√≠veis ao p√∫blico-alvo. O modelo deve entender conceitos t√©cnicos complexos e comunic√°-los de forma eficaz.
  </Tab>

  <Tab title="Necessidades de Contexto">
    * **Contexto Curto** envolve tarefas imediatas e focalizadas, onde o modelo processa informa√ß√µes limitadas rapidamente. S√£o intera√ß√µes transacionais em que velocidade e efici√™ncia importam mais do que compreens√£o profunda. O modelo n√£o precisa manter hist√≥rico extenso ou processar grandes documentos.

    * **Contexto Longo** √© necess√°rio ao lidar com documentos substanciais, conversas extensas ou tarefas complexas de m√∫ltiplas partes. O modelo precisa manter coer√™ncia ao longo de milhares de tokens, referenciando informa√ß√µes anteriores com precis√£o. Essencial para an√°lise de documentos, pesquisa abrangente e sistemas de di√°logo sofisticados.

    * **Contexto Muito Longo** ultrapassa os limites do poss√≠vel hoje, com processamento de documentos massivos, s√≠ntese de pesquisas extensas ou intera√ß√µes multi-sess√£o. S√£o casos que exigem modelos projetados especificamente para lidar com contexto estendido e envolvem trade-offs entre extens√£o e velocidade.
  </Tab>
</Tabs>

### b. Mapeamento de Capacidades do Modelo

Entender as capacidades dos modelos exige ir al√©m do marketing e dos benchmarks, analisando for√ßas e limita√ß√µes fundamentais das arquiteturas e m√©todos de treinamento.

<AccordionGroup>
  <Accordion title="Modelos de Racioc√≠nio" icon="brain">
    Modelos de racioc√≠nio formam uma categoria especializada, projetada para tarefas de pensamento complexo e de m√∫ltiplas etapas. Eles se destacam na resolu√ß√£o de problemas que requerem an√°lise cuidadosa, planejamento estrat√©gico ou decomposi√ß√£o sistem√°tica. Normalmente aplicam t√©cnicas como chain-of-thought ou tree-of-thought para conduzir o racioc√≠nio passo a passo.

    O ponto forte √© manter consist√™ncia l√≥gica em cadeias longas de racioc√≠nio e decompor problemas complexos em partes gerenci√°veis. S√£o especialmente valiosos para planejamento estrat√©gico, an√°lise complexa e situa√ß√µes onde a qualidade do racioc√≠nio importa mais que a velocidade.

    Entretanto, h√° trade-offs em termos de custo e velocidade. Podem ser menos adequados para tarefas criativas ou opera√ß√µes simples, onde suas capacidades avan√ßadas n√£o s√£o necess√°rias. Considere-os quando as tarefas realmente se beneficiarem dessa an√°lise detalhada.
  </Accordion>

  <Accordion title="Modelos de Uso Geral" icon="microchip">
    Modelos de uso geral oferecem uma abordagem equilibrada, com desempenho s√≥lido em uma ampla gama de tarefas, sem especializa√ß√£o extrema. S√£o treinados em conjuntos de dados diversificados e otimizados para versatilidade.

    A principal vantagem √© a confiabilidade previs√≠vel em diversos trabalhos: pesquisa, an√°lise, cria√ß√£o de conte√∫do, processamento de dados. S√£o √≥timas op√ß√µes iniciais para equipes que buscam consist√™ncia ao lidar com fluxos variados.

    Embora n√£o atinjam picos de desempenho como modelos especializados, oferecem simplicidade operacional e baixa complexidade na gest√£o. S√£o o melhor ponto de partida para novos projetos, permitindo descobertas de necessidades antes de avan√ßar para otimiza√ß√µes.
  </Accordion>

  <Accordion title="Modelos R√°pidos & Eficientes" icon="bolt">
    Modelos r√°pidos e eficientes priorizam velocidade, custo e efici√™ncia de recursos, em vez de racioc√≠nio sofisticado. S√£o otimizados para cen√°rios de alto volume onde respostas r√°pidas e baixos custos s√£o mais importantes que compreens√£o ou criatividade profunda.

    Brilham em opera√ß√µes rotineiras, processamento simples de dados, chamadas de fun√ß√µes e tarefas de alto volume. Aplica√ß√µes que processam muitos pedidos rapidamente ou operam sob restri√ß√µes or√ßament√°rias se beneficiam desses modelos.

    O ponto crucial √© garantir que suas capacidades atendam √†s exig√™ncias da tarefa. Podem n√£o atender tarefas que exijam entendimento profundo, racioc√≠nio complexo ou gera√ß√£o de conte√∫do sofisticado. S√£o ideais para tarefas rotineiras bem definidas.
  </Accordion>

  <Accordion title="Modelos Criativos" icon="pen">
    Modelos criativos s√£o otimizados para gera√ß√£o de conte√∫do, qualidade de escrita e pensamento inovador. Excelentes na compreens√£o de nuances, tom e estilo, produzindo conte√∫do envolvente e natural.

    O ponto forte est√° em adaptar o estilo para diferentes p√∫blicos, manter voz e tom consistentes e engajar leitores. Performam melhor em storytelling, textos publicit√°rios, comunica√ß√µes de marca e outras tarefas com criatividade como foco.

    Ao selecionar esses modelos, considere n√£o apenas a habilidade de gerar texto, mas a compreens√£o de p√∫blico, contexto e objetivo. Os melhores modelos criativos adaptam a sa√≠da √† voz da marca, diferentes segmentos e mant√™m consist√™ncia em pe√ßas longas.
  </Accordion>

  <Accordion title="Modelos Open Source" icon="code">
    Modelos open source oferecem vantagens em controle de custos, potencial de customiza√ß√£o, privacidade de dados e flexibilidade de deployment. Podem ser rodados localmente ou em infraestrutura pr√≥pria, dando controle total sobre dados e comportamento.

    Os principais benef√≠cios incluem elimina√ß√£o de custos por token, possibilidade de fine-tuning, privacidade total e independ√™ncia de fornecedores externos. Perfeitos para organiza√ß√µes com necessidade de privacidade, or√ßamento limitado ou desejo de customiza√ß√£o.

    Contudo, requerem maior expertise t√©cnica para implantar e manter. Considere custos de infraestrutura, complexidade de gest√£o e esfor√ßos cont√≠nuos de atualiza√ß√£o e otimiza√ß√£o ao avaliar modelos open source. O custo total pode ser maior que o de alternativas em nuvem devido a esse overhead.
  </Accordion>
</AccordionGroup>

## Padr√µes Estrat√©gicos de Configura√ß√£o

### a. Abordagem Multi-Modelo

<Tip>
  Use diferentes modelos para diferentes prop√≥sitos dentro da mesma crew para otimizar desempenho e custos.
</Tip>

As implementa√ß√µes CrewAI mais sofisticadas empregam m√∫ltiplos modelos estrategicamente, designando-os conforme as fun√ß√µes e necessidades dos agentes. Assim, √© poss√≠vel otimizar desempenho e custos usando o modelo mais adequado para cada tipo de tarefa.

Agentes de planejamento se beneficiam de modelos de racioc√≠nio para pensamento estrat√©gico e an√°lise multi-etapas. Esses agentes funcionam como o "c√©rebro" da opera√ß√£o. Agentes de conte√∫do t√™m melhor desempenho com modelos criativos focados em qualidade de escrita e engajamento. Agentes de processamento, respons√°veis por opera√ß√µes rotineiras, podem usar modelos eficientes priorizando velocidade.

**Exemplo: Crew de Pesquisa e An√°lise**

```python
from crewai import Agent, Task, Crew, LLM

# Modelo de racioc√≠nio para planejamento estrat√©gico
manager_llm = LLM(model="gemini-2.5-flash-preview-05-20", temperature=0.1)

# Modelo criativo para gerar conte√∫do
content_llm = LLM(model="claude-3-5-sonnet-20241022", temperature=0.7)

# Modelo eficiente para processamento de dados
processing_llm = LLM(model="gpt-4o-mini", temperature=0)

research_manager = Agent(
    role="Research Strategy Manager",
    goal="Develop comprehensive research strategies and coordinate team efforts",
    backstory="Expert research strategist with deep analytical capabilities",
    llm=manager_llm,  # Modelo de alto n√≠vel para racioc√≠nio complexo
    verbose=True
)

content_writer = Agent(
    role="Research Content Writer",
    goal="Transform research findings into compelling, well-structured reports",
    backstory="Skilled writer who excels at making complex topics accessible",
    llm=content_llm,  # Modelo criativo para conte√∫do envolvente
    verbose=True
)

data_processor = Agent(
    role="Data Analysis Specialist",
    goal="Extract and organize key data points from research sources",
    backstory="Detail-oriented analyst focused on accuracy and efficiency",
    llm=processing_llm,  # Modelo r√°pido para tarefas rotineiras
    verbose=True
)

crew = Crew(
    agents=[research_manager, content_writer, data_processor],
    tasks=[...],  # Suas tarefas espec√≠ficas
    manager_llm=manager_llm,  # Manager usa o modelo de racioc√≠nio
    verbose=True
)
```

O segredo do sucesso na implementa√ß√£o multi-modelo est√° em entender como os agentes interagem e garantir que as capacidades dos modelos estejam alinhadas √†s responsabilidades. Isso exige planejamento estrat√©gico, mas traz ganhos significativos em qualidade dos resultados e efici√™ncia operacional.

### b. Sele√ß√£o Espec√≠fica por Componente

<Tabs>
  <Tab title="Manager LLM">
    O manager LLM desempenha papel central em fluxos hier√°rquicos CrewAI, coordenando agentes e tarefas. Este modelo precisa se destacar em delega√ß√£o, prioriza√ß√£o de tarefas e manuten√ß√£o de contexto em v√°rias opera√ß√µes simult√¢neas.

    LLMs de manager eficazes exigem forte racioc√≠nio para delegar bem, desempenho consistente para coordenar previsivelmente e excelente gest√£o de contexto para acompanhar o estado dos agentes. O modelo deve entender capacidades e limita√ß√µes dos agentes enquanto otimiza a aloca√ß√£o de tarefas.

    O custo √© especialmente relevante, j√° que este LLM participa de todas as opera√ß√µes. O modelo precisa entregar capacidades suficientes, sem o pre√ßo premium de op√ß√µes sofisticadas demais, buscando sempre o equil√≠brio entre performance e valor.
  </Tab>

  <Tab title="Function Calling LLM">
    LLMs de function calling gerenciam o uso de ferramentas por todos os agentes, sendo cr√≠ticos em crews que dependem fortemente de APIs externas e ferramentas. Devem ser precisos na extra√ß√£o de par√¢metros e no processamento das respostas.

    As caracter√≠sticas mais importantes s√£o precis√£o e confiabilidade, n√£o criatividade ou racioc√≠nio avan√ßado. O modelo deve extrair par√¢metros corretos de comandos em linguagem natural consistentemente e processar respostas de ferramentas adequadamente. Velocidade tamb√©m importa, pois o uso de ferramentas pode envolver m√∫ltiplas idas e vindas de informa√ß√£o.

    Muitas equipes descobrem que modelos especializados em function calling ou de uso geral com forte suporte a ferramentas funcionam melhor do que modelos criativos ou de racioc√≠nio nesse papel. O fundamental √© assegurar que o modelo consiga converter instru√ß√µes em chamadas estruturadas sem falhas.
  </Tab>

  <Tab title="Sobrescritas Espec√≠ficas de Agente">
    Agentes individuais podem sobrescrever o LLM do n√≠vel da crew quando suas necessidades diferem significativamente das do restante. Isso permite otimiza√ß√£o pontual, mantendo a simplicidade operacional para os demais agentes.

    Considere sobrescritas quando a fun√ß√£o do agente exige capacidades distintas. Por exemplo, um agente de reda√ß√£o criativa pode se beneficiar de um LLM otimizado para gera√ß√£o de conte√∫do, enquanto um analista de dados pode preferir um modelo voltado ao racioc√≠nio.

    O desafio √© balancear otimiza√ß√£o com complexidade operacional. Cada modelo adicional aumenta a complexidade de deployment, monitoramento e custos. Foque em sobrescritas apenas quando a melhoria justificar essa complexidade.
  </Tab>
</Tabs>

## Framework de Defini√ß√£o de Tarefas

### a. Foque em Clareza, N√£o em Complexidade

Definir bem as tarefas √© frequentemente mais importante do que a sele√ß√£o do modelo no resultado gerado pelos agentes CrewAI. Tarefas bem formuladas orientam claramente mesmo modelos simples a terem bom desempenho. J√° tarefas mal definidas prejudicam at√© os modelos mais avan√ßados.

<AccordionGroup>
  <Accordion title="Descri√ß√µes de Tarefas Eficazes" icon="list-check">
    As melhores descri√ß√µes de tarefas equilibram detalhamento e clareza. Devem definir o objetivo de forma clara e sem ambiguidade, al√©m de explicar o m√©todo a ser usado com detalhes que permitam ao agente agir corretamente.

    Descri√ß√µes eficazes incluem contexto relevante e restri√ß√µes, ajudando o agente a entender o prop√≥sito maior e quaisquer limita√ß√µes. Divida trabalhos complexos em etapas gerenci√°veis em vez de objetivos gen√©ricos e sobrecarregados.

    Erros comuns incluem objetivos vagos, falta de contexto, crit√©rios de sucesso mal definidos ou mistura de tarefas totalmente distintas em um mesmo texto. O objetivo √© passar informa√ß√£o suficiente para o sucesso, mas mantendo foco no resultado claro.
  </Accordion>

  <Accordion title="Diretrizes para a Sa√≠da Esperada" icon="bullseye">
    As diretrizes da sa√≠da esperada funcionam como contrato entre defini√ß√£o de tarefa e agente, especificando claramente o que deve ser entregue e como ser√° avaliado. Elas abrangem formato, estrutura e elementos essenciais.

    As melhores diretrizes incluem exemplos concretos de indicadores de qualidade e crit√©rios claros de conclus√£o, de modo que agente e revisores humanos possam avaliar o resultado facilmente. Isso reduz ambiguidades e garante resultados consistentes.

    Evite descri√ß√µes gen√©ricas que serviriam para qualquer tarefa, aus√™ncia de especifica√ß√µes de formato, padr√µes vagos ou falta de exemplos/modelos que ajudem o agente a entender as expectativas.
  </Accordion>
</AccordionGroup>

### b. Estrat√©gia de Sequenciamento de Tarefas

<Tabs>
  <Tab title="Depend√™ncias Sequenciais">
    Depend√™ncias s√£o essenciais quando as tarefas se baseiam em resultados pr√©vios, informa√ß√µes fluem de uma tarefa para outra, ou a qualidade depende da conclus√£o de fases anteriores. Assim, cada tarefa recebe o contexto correto para o sucesso.

    Para implementar bem, use o par√¢metro de contexto para encadear tarefas, desenvolvendo gradualmente a complexidade. Cada tarefa deve gerar sa√≠das que alimentam as pr√≥ximas. O objetivo √© manter um fluxo l√≥gico entre as tarefas dependentes, evitando gargalos desnecess√°rios.

    Funciona melhor quando h√° progress√£o l√≥gica evidente e quando a sa√≠da de uma tarefa realmente agrega valor nas etapas seguintes. Cuidado com os gargalos; foque nas depend√™ncias essenciais.
  </Tab>

  <Tab title="Execu√ß√£o Paralela">
    A execu√ß√£o paralela √© valiosa quando as tarefas s√£o independentes, o tempo √© cr√≠tico ou h√° expertise distintas que n√£o exigem coordena√ß√£o. Pode reduzir drasticamente o tempo total, permitindo que agentes especializados atuem simultaneamente.

    Para isso, identifique tarefas realmente independentes, agrupe fluxos de trabalho distintos e planeje a integra√ß√£o dos resultados posteriormente. O ponto-chave √© garantir que tarefas paralelas n√£o gerem conflitos ou redund√¢ncias.

    Considere o paralelo em m√∫ltiplos fluxos independentes, diferentes tipos de an√°lise aut√¥noma, ou cria√ß√£o de conte√∫do que pode ser feita ao mesmo tempo. Mas atente-se √† aloca√ß√£o de recursos, evitando sobrecarga de modelos ou estouro no or√ßamento.
  </Tab>
</Tabs>

## Otimizando a Configura√ß√£o dos Agentes para Desempenho de LLMs

### a. Sele√ß√£o de LLM Guiada pelo Papel

<Warning>
  Fun√ß√µes gen√©ricas de agentes tornam imposs√≠vel escolher o LLM certo. Fun√ß√µes espec√≠ficas permitem otimiza√ß√£o do modelo conforme a fun√ß√£o.
</Warning>

A especificidade das fun√ß√µes dos agentes determina quais capacidades de LLM mais importam para alto desempenho, criando oportunidade estrat√©gica de alinhar for√ßas do modelo ao papel do agente.

**Impacto de Fun√ß√µes Gen√©ricas vs. Espec√≠ficas:**

Ao definir fun√ß√µes, pense no conhecimento do dom√≠nio, estilo de trabalho e frameworks decis√≥rios mais valiosos para o tipo de tarefa do agente. Quanto mais espec√≠fica e contextualizada a fun√ß√£o, melhor o modelo incorporar√° esse papel.

```python
# ‚úÖ Fun√ß√£o espec√≠fica - requisitos claros de LLM
specific_agent = Agent(
    role="SaaS Revenue Operations Analyst",  # Expertise de dom√≠nio clara
    goal="Analyze recurring revenue metrics and identify growth opportunities",
    backstory="Specialist in SaaS business models with deep understanding of ARR, churn, and expansion revenue",
    llm=LLM(model="gpt-4o")  # Racioc√≠nio justificado para an√°lise complexa
)
```

**Estrat√©gia de Mapeamento de Fun√ß√£o para Modelo:**

* **"Research Analyst"** ‚Üí Modelo de racioc√≠nio (GPT-4o, Claude Sonnet) para an√°lise complexa
* **"Content Editor"** ‚Üí Modelo criativo (Claude, GPT-4o) para qualidade de escrita
* **"Data Processor"** ‚Üí Modelo eficiente (GPT-4o-mini, Gemini Flash) para tarefas estruturadas
* **"API Coordinator"** ‚Üí Modelo otimizado para function calling (GPT-4o, Claude) para uso de ferramentas

### b. Backstory como Amplificador de Contexto do Modelo

<Info>
  Backstories estrat√©gicos maximizam a efic√°cia do LLM ao contextualizar as respostas de forma que prompts gen√©ricos n√£o conseguem.
</Info>

Um bom backstory transforma a escolha do LLM de gen√©rica a especializada. Isso √© crucial para otimizar custos: um modelo eficiente com contexto certo pode superar um premium sem contexto.

**Exemplo de Performance Guiada por Contexto:**

```python
# Contexto amplifica a efetividade do modelo
domain_expert = Agent(
    role="B2B SaaS Marketing Strategist",
    goal="Develop comprehensive go-to-market strategies for enterprise software",
    backstory="""
    You have 10+ years of experience scaling B2B SaaS companies from Series A to IPO.
    You understand the nuances of enterprise sales cycles, the importance of product-market
    fit in different verticals, and how to balance growth metrics with unit economics.
    You've worked with companies like Salesforce, HubSpot, and emerging unicorns, giving
    you perspective on both established and disruptive go-to-market strategies.
    """,
    llm=LLM(model="claude-3-5-sonnet", temperature=0.3)  # Criatividade balanceada com conhecimento de dom√≠nio
)

# Esse contexto faz o Claude agir como especialista do setor
# Sem isso, mesmo ele entregaria respostas gen√©ricas
```

**Elementos de Backstory que Potencializam a Performance de LLMs:**

* **Experi√™ncia de Dom√≠nio**: "10+ anos em vendas enterprise SaaS"
* **Expertise Espec√≠fica**: "Especialista em due diligence t√©cnica para S√©rie B+"
* **Estilo de Trabalho**: "Decis√µes orientadas a dados, documenta√ß√£o clara"
* **Padr√µes de Qualidade**: "Sempre cita fontes e mostra an√°lise detalhada"

### c. Otimiza√ß√£o Hol√≠stica de Agente + LLM

As configura√ß√µes mais eficazes criam sinergia entre fun√ß√£o espec√≠fica, profundidade do backstory e escolha do LLM. Cada elemento refor√ßa o outro para maximizar rendimento.

**Framework de Otimiza√ß√£o:**

```python
# Exemplo: Agente de Documenta√ß√£o T√©cnica
tech_writer = Agent(
    role="API Documentation Specialist",
    goal="Create comprehensive, developer-friendly API documentation",
    backstory="""
    You're a technical writer with 8+ years documenting REST APIs, GraphQL endpoints,
    and SDK integration guides. You've worked with developer tools companies and
    understand what developers need: clear examples, comprehensive error handling,
    and practical use cases. You prioritize accuracy and usability over marketing fluff.
    """,
    llm=LLM(
        model="claude-3-5-sonnet",
        temperature=0.1
    ),
    tools=[code_analyzer_tool, api_scanner_tool],
    verbose=True
)
```

**Checklist de Alinhamento:**

* ‚úÖ **Fun√ß√£o Espec√≠fica**: Dom√≠nio e responsabilidades claras
* ‚úÖ **Correspond√™ncia do LLM**: For√ßas do modelo conectadas √† fun√ß√£o
* ‚úÖ **Profundidade do Backstory**: Contexto de dom√≠nio dispon√≠vel pro modelo
* ‚úÖ **Integra√ß√£o de Ferramentas**: Ferramentas fortalecem a fun√ß√£o do agente
* ‚úÖ **Ajuste de Par√¢metros**: Temperatura e configs otimizadas para a fun√ß√£o

O segredo √© criar agentes onde cada configura√ß√£o refor√ßa sua estrat√©gia de escolha do LLM, maximizando rendimento e otimizando custos.

## Checklist Pr√°tico de Implementa√ß√£o

Em vez de repetir o framework estrat√©gico, segue um checklist t√°tico para implementar as decis√µes de sele√ß√£o de LLM em CrewAI:

<Steps>
  <Step title="Audite Sua Configura√ß√£o Atual" icon="clipboard-check">
    **O que analisar:**

    * Todos os agentes usam o mesmo LLM por padr√£o?
    * Quais agentes lidam com tarefas mais complexas?
    * Quais agentes s√≥ processam ou formatam dados?
    * Algum agente depende fortemente de ferramentas?

    **A√ß√£o**: Documente fun√ß√µes dos agentes e identifique oportunidades de otimiza√ß√£o.
  </Step>

  <Step title="Implemente Estrat√©gia no N√≠vel da Crew" icon="users-gear">
    **Defina sua Base:**

    ```python
    # Comece com um padr√£o confi√°vel para a crew
    default_crew_llm = LLM(model="gpt-4o-mini")  # Base econ√¥mica

    crew = Crew(
        agents=[...],
        tasks=[...],
        memory=True
    )
    ```

    **A√ß√£o**: Defina o LLM padr√£o da crew antes de otimizar agentes individuais.
  </Step>

  <Step title="Otimize Agentes de Maior Impacto" icon="star">
    **Identifique e Aprimore Agentes-Chave:**

    ```python
    # Agentes gerenciadores ou de coordena√ß√£o
    manager_agent = Agent(
        role="Project Manager",
        llm=LLM(model="gemini-2.5-flash-preview-05-20"),
        # ... demais configs
    )

    # Agentes criativos ou customer-facing
    content_agent = Agent(
        role="Content Creator",
        llm=LLM(model="claude-3-5-sonnet"),
        # ... demais configs
    )
    ```

    **A√ß√£o**: Fa√ßa upgrade dos 20% dos agentes que tratam 80% da complexidade.
  </Step>

  <Step title="Valide com Testes Empresariais" icon="test-tube">
    **Ap√≥s colocar os agentes em produ√ß√£o:**

    * Use [CrewAI Enterprise platform](https://app.crewai.com) para testar sele√ß√µes de modelo A/B
    * Execute m√∫ltiplas itera√ß√µes com inputs reais para medir consist√™ncia e performance
    * Compare custo vs performance na configura√ß√£o otimizada
    * Compartilhe resultados com o time para tomada coletiva de decis√£o

    **A√ß√£o**: Substitua achismos por valida√ß√£o com dados reais usando a plataforma de testes.
  </Step>
</Steps>

### Quando Usar Tipos Diferentes de Modelos

<Tabs>
  <Tab title="Modelos de Racioc√≠nio">
    Modelos de racioc√≠nio tornam-se essenciais quando tarefas exigem pensamento l√≥gico genu√≠no em m√∫ltiplas etapas, planejamento estrat√©gico ou decis√µes complexas beneficiadas por an√°lise sistem√°tica. Brilham na decomposi√ß√£o de problemas e an√°lise estruturada, n√£o no simples seguimento de padr√µes.

    Considere-os para desenvolvimento de estrat√©gias de neg√≥cios, an√°lise de dados combinados de m√∫ltiplas fontes, resolu√ß√£o de problemas dependente de etapas sucessivas e planejamento estrat√©gico envolvendo m√∫ltiplas vari√°veis.

    Entretanto, esses modelos s√£o mais caros e lentos, devendo ser reservados para tarefas onde suas capacidades agregam valor real ‚Äî evite us√°-los apenas para opera√ß√µes simples.
  </Tab>

  <Tab title="Modelos Criativos">
    Modelos criativos s√£o valiosos quando a principal entrega √© gera√ß√£o de conte√∫do e a qualidade, estilo e engajamento desse conte√∫do impactam o sucesso. Se destacam quando reda√ß√£o e estilo importam, idea√ß√£o criativa √© necess√°ria, ou voz de marca √© fundamental.

    Use-os em reda√ß√£o de posts, cria√ß√£o de artigos, textos de marketing com vi√©s persuasivo, storytelling e comunica√ß√µes da marca. Costumam captar nuances e contexto melhor do que generalistas.

    Podem ser menos adequados para tarefas t√©cnicas ou anal√≠ticas, onde precis√£o supera criatividade. Use-os quando aspectos comunicativos s√£o fatores cr√≠ticos de sucesso.
  </Tab>

  <Tab title="Modelos Eficientes">
    Modelos eficientes s√£o ideais para opera√ß√µes frequentes e rotineiras, onde velocidade e custo s√£o prioridade. Trabalham melhor em tarefas com par√¢metros bem definidos, sem necessidade de racioc√≠nio avan√ßado ou criatividade.

    Considere-os para processamento e transforma√ß√£o de dados, formata√ß√£o simples, chamadas de fun√ß√µes (function calling) e opera√ß√µes em alto volume onde custo importa mais.

    O ponto cr√≠tico √© verificar adequa√ß√£o √† tarefa. Funcionam para muitos fluxos rotineiros, mas podem falhar se a tarefa exigir compreens√£o t√©cnica ou racioc√≠nio.
  </Tab>

  <Tab title="Modelos Open Source">
    Modelos open source s√£o atraentes quando h√° restri√ß√£o or√ßament√°ria, necessidade de privacidade, personaliza√ß√£o especial ou exig√™ncia de deployment local.

    Considere para ferramentas internas de empresas, aplica√ß√µes sens√≠veis, projetos onde n√£o √© poss√≠vel usar APIs externas, casos com or√ßamento apertado ou requisitos de customiza√ß√£o.

    Mas lembre-se: exigem mais expertise, manuten√ß√£o e investimentos em infraestrutura. Avalie o custo total da opera√ß√£o ao avaliar esses modelos.
  </Tab>
</Tabs>

## Armadilhas Comuns na Sele√ß√£o de Modelos CrewAI

<AccordionGroup>
  <Accordion title="A Armadilha do 'Um Modelo Serve para Tudo'" icon="triangle-exclamation">
    **O problema**: Usar o mesmo LLM para todos os agentes, independentemente das fun√ß√µes. Pr√°tica padr√£o, mas raramente √≥tima.

    **Exemplo real**: Usar GPT-4o tanto para planejamento estrat√©gico quanto para extra√ß√£o simples de dados. O manager precisa do racioc√≠nio premium, mas o extrator poderia usar o GPT-4o-mini, muito mais barato.

    **Solu√ß√£o CrewAI**: Configure modelos espec√≠ficos por agente:

    ```python
    # Agente estrat√©gico recebe modelo premium
    manager = Agent(role="Strategy Manager", llm=LLM(model="gpt-4o"))

    # Agente de processamento recebe modelo eficiente
    processor = Agent(role="Data Processor", llm=LLM(model="gpt-4o-mini"))
    ```
  </Accordion>

  <Accordion title="Ignorar Hierarquia de LLM entre Crew e Agente" icon="shuffle">
    **O problema**: N√£o entender como funciona a hierarquia LLM da CrewAI ‚Äî configura√ß√µes conflitam entre crew, manager e agentes.

    **Exemplo real**: Configurar crew com Claude, mas agentes com GPT, gerando comportamento inconsistente e trocas desnecess√°rias.

    **Solu√ß√£o CrewAI**: Planeje a hierarquia estrategicamente:

    ```python
    crew = Crew(
        agents=[agent1, agent2],
        tasks=[task1, task2],
        manager_llm=LLM(model="gpt-4o"),
        process=Process.hierarchical
    )

    # Agentes herdam o LLM da crew, salvo sobrescrita
    agent1 = Agent(llm=LLM(model="claude-3-5-sonnet"))
    ```
  </Accordion>

  <Accordion title="Incompatibilidade para Function Calling" icon="screwdriver-wrench">
    **O problema**: Escolher modelos pela capacidade geral e ignorar o desempenho em function calling em workflows intensivos em ferramentas.

    **Exemplo real**: Selecionar modelo criativo para agente que s√≥ precisa chamar APIs e processar dados estruturados, resultando em m√° extra√ß√£o de par√¢metros.

    **Solu√ß√£o CrewAI**: Priorize desempenho em function calling para agentes que usam ferramentas:

    ```python
    # Para agentes com muitas ferramentas
    tool_agent = Agent(
        role="API Integration Specialist",
        tools=[search_tool, api_tool, data_tool],
        llm=LLM(model="gpt-4o"),
        # OU
        llm=LLM(model="claude-3-5-sonnet")
    )
    ```
  </Accordion>

  <Accordion title="Otimiza√ß√£o Prematura sem Teste" icon="gear">
    **O problema**: Decidir configura√ß√µes complexas de modelo com base em hip√≥teses n√£o validadas nos fluxos e tarefas reais CrewAI.

    **Exemplo real**: Implementar l√≥gica elaborada de troca de modelo por tipo de tarefa sem testar se os ganhos compensam a complexidade.

    **Solu√ß√£o CrewAI**: Comece simples e otimize baseado em dados reais:

    ```python
    # Comece assim
    crew = Crew(agents=[...], tasks=[...], llm=LLM(model="gpt-4o-mini"))

    # Teste a performance e s√≥ depois otimize agentes espec√≠ficos
    # Use testes Enterprise para validar melhorias
    ```
  </Accordion>

  <Accordion title="Ignorar Limites de Contexto e Mem√≥ria" icon="brain">
    **O problema**: N√£o considerar como janela de contexto dos modelos interage com mem√≥ria e compartilhamento de contexto entre agentes CrewAI.

    **Exemplo real**: Usar modelo de contexto curto para agentes que precisam manter hist√≥rico ao longo de m√∫ltiplas itera√ß√µes ou equipes com comunica√ß√£o extensiva agent-to-agent.

    **Solu√ß√£o CrewAI**: Alinhe capacidades de contexto ao padr√£o de comunica√ß√£o da crew.
  </Accordion>
</AccordionGroup>

## Estrat√©gia de Teste e Itera√ß√£o

<Steps>
  <Step title="Comece Simples" icon="play">
    Comece com modelos de uso geral, confi√°veis e amplamente suportados. Isso estabelece base est√°vel para entender necessidades e expectativas de desempenho antes de otimizar para demandas especializadas.
  </Step>

  <Step title="Me√ßa o que Importa" icon="chart-line">
    Desenvolva m√©tricas alinhadas ao seu caso de uso e metas de neg√≥cio, n√£o apenas benchmarks gerais. Foque na mensura√ß√£o de resultados relevantes ao seu sucesso.
  </Step>

  <Step title="Itere Baseado em Resultados" icon="arrows-rotate">
    Fa√ßa mudan√ßas baseadas no desempenho observado no seu contexto, n√£o apenas considera√ß√µes te√≥ricas ou recomenda√ß√µes gen√©ricas. O desempenho pr√°tico costuma ser bem diferente dos benchmarks.
  </Step>

  <Step title="Considere o Custo Total" icon="calculator">
    Avalie todo custo de opera√ß√£o, incluindo modelo, tempo de desenvolvimento, manuten√ß√£o e complexidade. O modelo mais barato por token pode n√£o ser o mais econ√¥mico ao considerar todos os fatores.
  </Step>
</Steps>

<Tip>
  Foque em entender seus requisitos primeiro, e ent√£o escolha modelos que melhor correspondam a essas necessidades. O melhor LLM √© aquele que consistentemente entrega os resultados esperados dentro das suas restri√ß√µes.
</Tip>

### Valida√ß√£o de Modelos em N√≠vel Enterprise

Para equipes s√©rias sobre otimiza√ß√£o, a **plataforma CrewAI Enterprise** oferece testes sofisticados que v√£o al√©m do CLI. Ela permite avalia√ß√£o completa para decis√µes orientadas por dados na estrat√©gia de LLM.

<Frame>
  ![Enterprise Testing Interface](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/enterprise-testing.png)
</Frame>

**Funcionalidades Avan√ßadas de Teste:**

* **Compara√ß√£o Multi-Modelo**: Teste diversos LLMs simultaneamente nas mesmas tarefas e entradas. Compare desempenho entre GPT-4o, Claude, Llama, Groq, Cerebras, e outros l√≠deres em paralelo para identificar a melhor op√ß√£o para voc√™.

* **Rigor Estat√≠stico**: Configure m√∫ltiplas itera√ß√µes com inputs consistentes para medir confiabilidade e varia√ß√£o no desempenho. Assim, identifica modelos que performam bem e de modo consistente.

* **Valida√ß√£o no Mundo Real**: Use os inputs e cen√°rios reais da sua crew, e n√£o apenas benchmarks sint√©ticos. A plataforma permite testar no contexto da sua ind√∫stria, empresa e casos de uso.

* **Analytics Completo**: Acesse m√©tricas detalhadas de desempenho, tempos de execu√ß√£o e an√°lise de custos para todos os modelos testados. Decis√µes baseadas em dados reais, n√£o apenas reputa√ß√£o.

* **Colabora√ß√£o em Equipe**: Compartilhe resultados e an√°lises com seu time, favorecendo decis√µes coletivas e estrat√©gias alinhadas.

Acesse [app.crewai.com](https://app.crewai.com) para come√ßar!

<Info>
  A plataforma Enterprise transforma a sele√ß√£o de modelos de um "palpite" para um processo orientado por dados, permitindo validar os princ√≠pios deste guia com seus pr√≥prios casos de uso.
</Info>

## Resumo dos Princ√≠pios-Chave

<CardGroup cols={2}>
  <Card title="Sele√ß√£o Orientada √† Tarefa" icon="bullseye">
    Escolha os modelos pelo que sua tarefa realmente requer, n√£o por reputa√ß√£o ou capacidades te√≥ricas.
  </Card>

  <Card title="Combina√ß√£o de Capacidades" icon="puzzle-piece">
    Alinhe for√ßas do modelo a pap√©is e responsabilidades dos agentes para melhor desempenho.
  </Card>

  <Card title="Consist√™ncia Estrat√©gica" icon="link">
    Mantenha uma estrat√©gia coerente de sele√ß√£o de modelos em fluxos e componentes relacionados.
  </Card>

  <Card title="Testes Pr√°ticos" icon="flask">
    Valide escolhas em uso real, n√£o apenas em benchmarks.
  </Card>

  <Card title="Itera√ß√£o Cont√≠nua" icon="arrow-up">
    Comece simples e otimize com base na performance e necessidade pr√°ticas.
  </Card>

  <Card title="Equil√≠brio Operacional" icon="scale-balanced">
    Equilibre performance requerida, custo e complexidade.
  </Card>
</CardGroup>

<Check>
  Lembre-se: o melhor LLM √© o que entrega consistentemente os resultados de que voc√™ precisa dentro de suas restri√ß√µes. Conhe√ßa seu requisito primeiro, depois selecione o modelo mais adequado.
</Check>

## Panorama Atual dos Modelos (Junho/2025)

<Warning>
  **Retrato do Momento**: Os rankings a seguir representam o estado da arte em Junho de 2025, compilados do [LMSys Arena](https://arena.lmsys.org/), [Artificial Analysis](https://artificialanalysis.ai/) e outros benchmarks l√≠deres. Performance, disponibilidade e pre√ßo mudam rapidamente. Sempre valide com seus dados e casos reais.
</Warning>

### Principais Modelos por Categoria

As tabelas abaixo mostram uma amostra dos modelos de maior destaque em cada categoria, junto de orienta√ß√£o sobre aplica√ß√£o em agentes CrewAI:

<Note>
  Estas tabelas exibem apenas alguns modelos l√≠deres por categoria. Existem muitos outros excelentes. O objetivo √© ilustrar exemplos de capacidades buscadas em vez de apresentar um cat√°logo completo.
</Note>

<Tabs>
  <Tab title="Racioc√≠nio & Planejamento">
    **Melhores para LLMs Manager e An√°lises Complexas**

    | Modelo                     | Score de Intelig√™ncia | Custo (\$/M tokens) | Velocidade | Melhor Uso em CrewAI                                         |
    | :------------------------- | :-------------------- | :------------------ | :--------- | :----------------------------------------------------------- |
    | **o3**                     | 70                    | \$17.50             | R√°pido     | Manager LLM para coordena√ß√£o multi-agente                    |
    | **Gemini 2.5 Pro**         | 69                    | \$3.44              | R√°pido     | Agentes de planejamento estrat√©gico, coordena√ß√£o de pesquisa |
    | **DeepSeek R1**            | 68                    | \$0.96              | Moderada   | Racioc√≠nio com bom custo-benef√≠cio                           |
    | **Claude 4 Sonnet**        | 53                    | \$6.00              | R√°pido     | Agentes de an√°lise que precisam de nuance                    |
    | **Qwen3 235B (Reasoning)** | 62                    | \$2.63              | Moderada   | Alternativa open source para racioc√≠nio                      |

    Esses modelos se destacam em racioc√≠nio multi-etapas e s√£o ideais para agentes que desenvolvem estrat√©gias, coordenam outros agentes ou analisam informa√ß√µes complexas.
  </Tab>

  <Tab title="Codifica√ß√£o & T√©cnica">
    **Melhores para Desenvolvimento e Workflows com Ferramentas**

    | Modelo                | Performance em Coding | Tool Use Score | Custo (\$/M tokens) | Melhor Uso em CrewAI                                             |
    | :-------------------- | :-------------------- | :------------- | :------------------ | :--------------------------------------------------------------- |
    | **Claude 4 Sonnet**   | Excelente             | 72.7%          | \$6.00              | Agente principal de c√≥digo/documenta√ß√£o t√©cnica                  |
    | **Claude 4 Opus**     | Excelente             | 72.5%          | \$30.00             | Arquitetura complexa, code review                                |
    | **DeepSeek V3**       | Muito bom             | Alto           | \$0.48              | Coding econ√¥mico para desenvolvimentos rotineiros                |
    | **Qwen2.5 Coder 32B** | Muito bom             | M√©dio          | \$0.15              | Agente de c√≥digo econ√¥mico                                       |
    | **Llama 3.1 405B**    | Bom                   | 81.1%          | \$3.50              | LLM para function calling em workflows intensivos em ferramentas |

    Otimizados para gera√ß√£o de c√≥digo, debugging e solu√ß√£o t√©cnica, ideais para equipes de desenvolvimento.
  </Tab>

  <Tab title="Velocidade & Efici√™ncia">
    **Melhores para Opera√ß√µes em Massa e Aplica√ß√µes em Tempo Real**

    | Modelo                  | Velocidade (tokens/s) | Lat√™ncia (TTFT) | Custo (\$/M tokens) | Melhor Uso em CrewAI                     |
    | :---------------------- | :-------------------- | :-------------- | :------------------ | :--------------------------------------- |
    | **Llama 4 Scout**       | 2.600                 | 0.33s           | \$0.27              | Agentes de processamento de alto volume  |
    | **Gemini 2.5 Flash**    | 376                   | 0.30s           | \$0.26              | Agentes de resposta em tempo real        |
    | **DeepSeek R1 Distill** | 383                   | Vari√°vel        | \$0.04              | Processamento r√°pido de baixo custo      |
    | **Llama 3.3 70B**       | 2.500                 | 0.52s           | \$0.60              | Equil√≠brio entre velocidade e capacidade |
    | **Nova Micro**          | Alto                  | 0.30s           | \$0.04              | Execu√ß√£o r√°pida de tarefas simples       |

    Priorizam velocidade e efici√™ncia, perfeitos para agentes em opera√ß√µes de rotina ou resposta √°gil. **Dica:** Usar provedores de inference r√°pidos como Groq potencializa open source como Llama.
  </Tab>

  <Tab title="Performance Equilibrada">
    **Melhores Modelos Coringa para Crews Diversos**

    | Modelo                | Score Global | Versatilidade | Custo (\$/M tokens) | Melhor Uso em CrewAI                  |
    | :-------------------- | :----------- | :------------ | :------------------ | :------------------------------------ |
    | **GPT-4.1**           | 53           | Excelente     | \$3.50              | LLM generalista para equipes variadas |
    | **Claude 3.7 Sonnet** | 48           | Muito boa     | \$6.00              | Racioc√≠nio e criatividade balanceados |
    | **Gemini 2.0 Flash**  | 48           | Boa           | \$0.17              | Generalista de bom custo benef√≠cio    |
    | **Llama 4 Maverick**  | 51           | Boa           | \$0.37              | Open source para usos gerais          |
    | **Qwen3 32B**         | 44           | Boa           | \$1.23              | Versatilidade econ√¥mica               |

    Oferecem bom desempenho geral, adequados para crews com demandas amplas.
  </Tab>
</Tabs>

### Framework de Sele√ß√£o para Modelos Atuais

<AccordionGroup>
  <Accordion title="Crews de Alta Performance" icon="rocket">
    **Priorizando performance**: Use modelos topo de linha como **o3**, **Gemini 2.5 Pro** ou **Claude 4 Sonnet** para managers e agentes cr√≠ticos. Excelentes em racioc√≠nio e coordena√ß√£o, por√©m mais caros.

    **Estrat√©gia**: Implemente abordagem multi-modelo, reservando premium para racioc√≠nio estrat√©gico e eficientes para opera√ß√µes rotineiras.
  </Accordion>

  <Accordion title="Crews de Baixo Custo" icon="dollar-sign">
    **Foco no or√ßamento**: Foque em modelos como **DeepSeek R1**, **Llama 4 Scout** ou **Gemini 2.0 Flash**, que trazem √≥timo desempenho com investimento reduzido.

    **Estrat√©gia**: Use modelos econ√¥micos para maioria dos agentes, reservando premium apenas para fun√ß√µes cr√≠ticas.
  </Accordion>

  <Accordion title="Workflows Especializados" icon="screwdriver-wrench">
    **Para expertise espec√≠fica**: Escolha modelos otimizados para seu principal caso de uso: **Claude 4** em c√≥digo, **Gemini 2.5 Pro** em pesquisa, **Llama 405B** em function calling.

    **Estrat√©gia**: Selecione conforme a principal fun√ß√£o da crew, garantindo alinhamento de capacidade e modelo.
  </Accordion>

  <Accordion title="Empresa & Privacidade" icon="shield">
    **Para opera√ß√µes sens√≠veis**: Avalie modelos open source como **Llama 4** series, **DeepSeek V3** ou **Qwen3** para deployment privado, mantendo performance competitiva.

    **Estrat√©gia**: Use open source em infraestrutura pr√≥pria e aceite poss√≠veis trade-offs por controle dos dados.
  </Accordion>
</AccordionGroup>

### Considera√ß√µes-Chave na Sele√ß√£o de Modelos

* **Tend√™ncias de Performance**: O cen√°rio atual mostra competi√ß√£o forte entre modelos de racioc√≠nio (o3, Gemini 2.5 Pro) e equilibrados (Claude 4, GPT-4.1). Modelos como DeepSeek R1 entregam excelente custo/performance.
* **Trade-off Velocidade x Intelig√™ncia**: Modelos como Llama 4 Scout priorizam velocidade (2.600 tokens/s) e intelig√™ncia razo√°vel, enquanto outros como o3 maximizam racioc√≠nio em detrimento de velocidade/pre√ßo.
* **Viabilidade Open Source**: A dist√¢ncia entre open source e propriet√°rios diminui a cada m√™s, com Llama 4 Maverick e DeepSeek V3 entregando performance competitiva a pre√ßos atrativos. Infer√™ncia r√°pida via Groq maximiza custo-benef√≠cio nesses casos.

<Info>
  **Testes s√£o essenciais**: Rankings servem de orienta√ß√£o geral, mas seu caso de uso, prompt e crit√©rio podem gerar resultados distintos. Sempre teste modelos candidatos com suas tarefas e dados reais antes de decidir.
</Info>

### Estrat√©gia Pr√°tica de Implementa√ß√£o

<Steps>
  <Step title="Comece por Modelos Validados">
    Inicie com op√ß√µes consagradas como **GPT-4.1**, **Claude 3.7 Sonnet** ou **Gemini 2.0 Flash**, que oferecem bom desempenho e ampla valida√ß√£o.
  </Step>

  <Step title="Identifique Demandas Especializadas">
    Descubra se sua crew possui requisitos espec√≠ficos (c√≥digo, racioc√≠nio, velocidade) que justifiquem modelos como **Claude 4 Sonnet** para desenvolvimento ou **o3** para an√°lise. Para aplica√ß√µes cr√≠ticas em velocidade, considere Groq aliado √† sele√ß√£o do modelo.
  </Step>

  <Step title="Implemente Estrat√©gia Multi-Modelo">
    Use modelos diferentes para agentes distintos conforme o papel. Modelos de alta capacidade para managers e tarefas complexas, eficientes para rotinas.
  </Step>

  <Step title="Monitore e Otimize">
    Acompanhe m√©tricas relevantes ao seu caso e esteja pronto para ajustar modelos conforme lan√ßamentos ou mudan√ßas de pre√ßos.
  </Step>
</Steps>


# Usando Agentes Multimodais
Source: https://docs.crewai.com/pt-BR/learn/multimodal-agents

Aprenda como habilitar e usar capacidades multimodais em seus agentes para processar imagens e outros conte√∫dos n√£o textuais dentro do framework CrewAI.

## Usando Agentes Multimodais

O CrewAI suporta agentes multimodais que podem processar tanto conte√∫do textual quanto n√£o textual, como imagens. Este guia mostrar√° como habilitar e utilizar capacidades multimodais em seus agentes.

### Habilitando Capacidades Multimodais

Para criar um agente multimodal, basta definir o par√¢metro `multimodal` como `True` ao inicializar seu agente:

```python
from crewai import Agent

agent = Agent(
    role="Image Analyst",
    goal="Analyze and extract insights from images",
    backstory="An expert in visual content interpretation with years of experience in image analysis",
    multimodal=True  # This enables multimodal capabilities
)
```

Ao definir `multimodal=True`, o agente √© automaticamente configurado com as ferramentas necess√°rias para lidar com conte√∫do n√£o textual, incluindo a `AddImageTool`.

### Trabalhando com Imagens

O agente multimodal vem pr√©-configurado com a `AddImageTool`, permitindo que ele processe imagens. N√£o √© necess√°rio adicionar esta ferramenta manualmente ‚Äì ela √© automaticamente inclu√≠da ao habilitar capacidades multimodais.

Aqui est√° um exemplo completo mostrando como usar um agente multimodal para analisar uma imagem:

```python
from crewai import Agent, Task, Crew

# Create a multimodal agent
image_analyst = Agent(
    role="Product Analyst",
    goal="Analyze product images and provide detailed descriptions",
    backstory="Expert in visual product analysis with deep knowledge of design and features",
    multimodal=True
)

# Create a task for image analysis
task = Task(
    description="Analyze the product image at https://example.com/product.jpg and provide a detailed description",
    expected_output="A detailed description of the product image",
    agent=image_analyst
)

# Create and run the crew
crew = Crew(
    agents=[image_analyst],
    tasks=[task]
)

result = crew.kickoff()
```

### Uso Avan√ßado com Contexto

Voc√™ pode fornecer contexto adicional ou perguntas espec√≠ficas sobre a imagem ao criar tarefas para agentes multimodais. A descri√ß√£o da tarefa pode incluir aspectos espec√≠ficos nos quais voc√™ deseja que o agente foque:

```python
from crewai import Agent, Task, Crew

# Create a multimodal agent for detailed analysis
expert_analyst = Agent(
    role="Visual Quality Inspector",
    goal="Perform detailed quality analysis of product images",
    backstory="Senior quality control expert with expertise in visual inspection",
    multimodal=True  # AddImageTool is automatically included
)

# Create a task with specific analysis requirements
inspection_task = Task(
    description="""
    Analyze the product image at https://example.com/product.jpg with focus on:
    1. Quality of materials
    2. Manufacturing defects
    3. Compliance with standards
    Provide a detailed report highlighting any issues found.
    """,
    expected_output="A detailed report highlighting any issues found",
    agent=expert_analyst
)

# Create and run the crew
crew = Crew(
    agents=[expert_analyst],
    tasks=[inspection_task]
)

result = crew.kickoff()
```

### Detalhes da Ferramenta

Ao trabalhar com agentes multimodais, a `AddImageTool` √© automaticamente configurada com o seguinte esquema:

```python
class AddImageToolSchema:
    image_url: str  # Required: The URL or path of the image to process
    action: Optional[str] = None  # Optional: Additional context or specific questions about the image
```

O agente multimodal ir√° automaticamente realizar o processamento de imagens por meio de suas ferramentas internas, permitindo que ele:

* Acesse imagens via URLs ou caminhos de arquivos locais
* Processe o conte√∫do da imagem com contexto opcional ou perguntas espec√≠ficas
* Forne√ßa an√°lises e insights com base nas informa√ß√µes visuais e requisitos da tarefa

### Boas Pr√°ticas

Ao trabalhar com agentes multimodais, tenha em mente as seguintes boas pr√°ticas:

1. **Acesso √† Imagem**
   * Certifique-se de que suas imagens estejam acess√≠veis via URLs alcan√ß√°veis pelo agente
   * Para imagens locais, considere hosped√°-las temporariamente ou utilize caminhos absolutos
   * Verifique se as URLs das imagens s√£o v√°lidas e acess√≠veis antes de rodar as tarefas

2. **Descri√ß√£o da Tarefa**
   * Seja espec√≠fico sobre quais aspectos da imagem voc√™ deseja que o agente analise
   * Inclua perguntas ou requisitos claros na descri√ß√£o da tarefa
   * Considere usar o par√¢metro opcional `action` para uma an√°lise focada

3. **Gerenciamento de Recursos**
   * O processamento de imagens pode exigir mais recursos computacionais do que tarefas apenas textuais
   * Alguns modelos de linguagem podem exigir codifica√ß√£o em base64 para dados de imagem
   * Considere o processamento em lote para m√∫ltiplas imagens visando otimizar o desempenho

4. **Configura√ß√£o do Ambiente**
   * Verifique se seu ambiente possui as depend√™ncias necess√°rias para processamento de imagens
   * Certifique-se de que seu modelo de linguagem suporta capacidades multimodais
   * Teste primeiro com imagens pequenas para validar sua configura√ß√£o

5. **Tratamento de Erros**
   * Implemente tratamento apropriado para falhas no carregamento de imagens
   * Tenha estrat√©gias de conting√™ncia para casos onde o processamento de imagens falhar
   * Monitore e registre opera√ß√µes de processamento de imagens para depura√ß√£o


# Vis√£o Geral
Source: https://docs.crewai.com/pt-BR/learn/overview

Aprenda como construir, personalizar e otimizar suas aplica√ß√µes CrewAI com guias e tutoriais completos

## Aprenda CrewAI

Esta se√ß√£o fornece guias e tutoriais completos para ajudar voc√™ a dominar o CrewAI, desde conceitos b√°sicos at√© t√©cnicas avan√ßadas. Seja voc√™ iniciante ou esteja buscando otimizar suas implementa√ß√µes existentes, estes recursos o guiar√£o por todos os aspectos da constru√ß√£o de workflows poderosos de agentes de IA.

## Guias de Introdu√ß√£o

### Conceitos Centrais

<CardGroup cols={2}>
  <Card title="Processo Sequencial" icon="list-ol" href="/pt-BR/learn/sequential-process">
    Aprenda a executar tarefas em ordem sequencial para workflows estruturados.
  </Card>

  <Card title="Processo Hier√°rquico" icon="sitemap" href="/pt-BR/learn/hierarchical-process">
    Implemente execu√ß√£o hier√°rquica de tarefas com agentes gerentes supervisionando workflows.
  </Card>

  <Card title="Tarefas Condicionais" icon="code-branch" href="/pt-BR/learn/conditional-tasks">
    Crie workflows din√¢micos com execu√ß√£o condicional de tarefas baseada em resultados.
  </Card>

  <Card title="Kickoff Ass√≠ncrono" icon="bolt" href="/pt-BR/learn/kickoff-async">
    Execute crews de forma ass√≠ncrona para melhorar desempenho e concorr√™ncia.
  </Card>
</CardGroup>

### Desenvolvimento de Agentes

<CardGroup cols={2}>
  <Card title="Personalizando Agentes" icon="user-gear" href="/pt-BR/learn/customizing-agents">
    Aprenda como personalizar o comportamento, fun√ß√µes e capacidades dos agentes.
  </Card>

  <Card title="Codificando Agentes" icon="code" href="/pt-BR/learn/coding-agents">
    Construa agentes que podem escrever, executar e depurar c√≥digo automaticamente.
  </Card>

  <Card title="Agentes Multimodais" icon="images" href="/pt-BR/learn/multimodal-agents">
    Crie agentes capazes de processar texto, imagens e outros tipos de m√≠dia.
  </Card>

  <Card title="Agente Gerente Personalizado" icon="user-tie" href="/pt-BR/learn/custom-manager-agent">
    Implemente agentes gerentes personalizados para workflows hier√°rquicos complexos.
  </Card>
</CardGroup>

## Funcionalidades Avan√ßadas

### Controle de Workflow

<CardGroup cols={2}>
  <Card title="Humano no Loop" icon="user-check" href="/pt-BR/learn/human-in-the-loop">
    Integre supervis√£o e interven√ß√£o humana aos workflows dos agentes.
  </Card>

  <Card title="Entrada Humana na Execu√ß√£o" icon="hand-paper" href="/pt-BR/learn/human-input-on-execution">
    Permita entrada humana durante a execu√ß√£o de tarefas para tomada de decis√µes din√¢micas.
  </Card>

  <Card title="Repetir Tarefas" icon="rotate-left" href="/pt-BR/learn/replay-tasks-from-latest-crew-kickoff">
    Refa√ßa e retome tarefas a partir de execu√ß√µes anteriores de crews.
  </Card>

  <Card title="Kickoff para Cada" icon="repeat" href="/pt-BR/learn/kickoff-for-each">
    Execute crews m√∫ltiplas vezes com diferentes entradas de maneira eficiente.
  </Card>
</CardGroup>

### Personaliza√ß√£o & Integra√ß√£o

<CardGroup cols={2}>
  <Card title="LLM Personalizado" icon="brain" href="/pt-BR/learn/custom-llm">
    Integre modelos de linguagem personalizados e provedores ao CrewAI.
  </Card>

  <Card title="Conex√µes LLM" icon="link" href="/pt-BR/learn/llm-connections">
    Configure e gerencie conex√µes com v√°rios provedores de LLM.
  </Card>

  <Card title="Criar Ferramentas Personalizadas" icon="wrench" href="/pt-BR/learn/create-custom-tools">
    Construa ferramentas personalizadas para estender as capacidades dos agentes.
  </Card>

  <Card title="Usando Anota√ß√µes" icon="at" href="/pt-BR/learn/using-annotations">
    Use anota√ß√µes Python para um c√≥digo mais limpo e f√°cil de manter.
  </Card>
</CardGroup>

## Aplica√ß√µes Especializadas

### Conte√∫do & M√≠dia

<CardGroup cols={2}>
  <Card title="Gera√ß√£o de Imagens DALL-E" icon="image" href="/pt-BR/learn/dalle-image-generation">
    Gere imagens utilizando a integra√ß√£o DALL-E com seus agentes.
  </Card>

  <Card title="Traga Seu Pr√≥prio Agente" icon="user-plus" href="/pt-BR/learn/bring-your-own-agent">
    Integre agentes e modelos j√° existentes aos workflows do CrewAI.
  </Card>
</CardGroup>

### Gerenciamento de Ferramentas

<CardGroup cols={2}>
  <Card title="For√ßar Sa√≠da da Ferramenta como Resultado" icon="hammer" href="/pt-BR/learn/force-tool-output-as-result">
    Configure ferramentas para retornarem sua sa√≠da diretamente como resultado da tarefa.
  </Card>
</CardGroup>

## Recomenda√ß√µes de Rotas de Aprendizagem

### Para Iniciantes

1. Comece pelo **Processo Sequencial** para entender a execu√ß√£o b√°sica de workflows
2. Aprenda **Personalizando Agentes** para criar configura√ß√µes de agentes eficazes
3. Explore **Criar Ferramentas Personalizadas** para estender funcionalidades
4. Experimente **Humano no Loop** para workflows interativos

### Para Usu√°rios Intermedi√°rios

1. Domine **Processo Hier√°rquico** para sistemas multiagente complexos
2. Implemente **Tarefas Condicionais** para workflows din√¢micos
3. Utilize **Kickoff Ass√≠ncrono** para otimizar desempenho
4. Integre **LLM Personalizado** para modelos especializados

### Para Usu√°rios Avan√ßados

1. Construa **Agentes Multimodais** para processamento complexo de m√≠dias
2. Crie **Agentes Gerentes Personalizados** para orquestra√ß√£o sofisticada
3. Implemente **Traga Seu Pr√≥prio Agente** para sistemas h√≠bridos
4. Use **Repetir Tarefas** para recupera√ß√£o de erros robusta

## Melhores Pr√°ticas

### Desenvolvimento

* **Comece Simples**: Inicie com workflows sequenciais b√°sicos antes de adicionar complexidade
* **Teste de Forma Incremental**: Teste cada componente antes de integrar em sistemas maiores
* **Use Anota√ß√µes**: Aproveite as anota√ß√µes Python para c√≥digo mais limpo e sustent√°vel
* **Ferramentas Personalizadas**: Crie ferramentas reutiliz√°veis que possam ser compartilhadas entre diferentes agentes

### Produ√ß√£o

* **Tratamento de Erros**: Implemente mecanismos robustos de tratamento e recupera√ß√£o de erros
* **Desempenho**: Utilize execu√ß√£o ass√≠ncrona e otimize chamadas a LLM para melhor desempenho
* **Monitoramento**: Integre ferramentas de observabilidade para acompanhar o desempenho dos agentes
* **Supervis√£o Humana**: Inclua checkpoints humanos para decis√µes cr√≠ticas

### Otimiza√ß√£o

* **Gest√£o de Recursos**: Monitore e otimize o uso de tokens e custos de API
* **Design de Workflow**: Elabore workflows que minimizem chamadas desnecess√°rias ao LLM
* **Efici√™ncia das Ferramentas**: Crie ferramentas eficientes que ofere√ßam m√°ximo valor com o m√≠nimo de overhead
* **Aprimoramento Iterativo**: Use feedback e m√©tricas para melhorar continuamente o desempenho dos agentes

## Obtendo Ajuda

* **Documenta√ß√£o**: Cada guia inclui exemplos detalhados e explica√ß√µes
* **Comunidade**: Participe do [F√≥rum CrewAI](https://community.crewai.com) para discuss√µes e suporte
* **Exemplos**: Consulte a se√ß√£o de Exemplos para implementa√ß√µes completas e funcionais
* **Suporte**: Entre em contato via [support@crewai.com](mailto:support@crewai.com) para assist√™ncia t√©cnica

Comece pelos guias que atendem √†s suas necessidades atuais e, gradualmente, explore t√≥picos mais avan√ßados conforme voc√™ se sentir confort√°vel com os fundamentos.


# Reexecutar Tarefas a partir do √öltimo Crew Kickoff
Source: https://docs.crewai.com/pt-BR/learn/replay-tasks-from-latest-crew-kickoff

Reexecute tarefas a partir do √∫ltimo crew.kickoff(...)

## Introdu√ß√£o

O CrewAI oferece a capacidade de reexecutar uma tarefa especificada a partir do √∫ltimo crew kickoff. Esse recurso √© particularmente √∫til quando voc√™ concluiu um kickoff e deseja tentar novamente determinadas tarefas, ou n√£o precisa buscar dados novamente porque seus agentes j√° possuem o contexto salvo da execu√ß√£o do kickoff, sendo necess√°rio apenas reexecutar as tarefas desejadas.

<Note>
  Voc√™ deve executar `crew.kickoff()` antes de poder reexecutar uma tarefa.
  Atualmente, apenas o kickoff mais recente √© suportado, ent√£o se voc√™ utilizar `kickoff_for_each`, ser√° poss√≠vel reexecutar apenas a partir da execu√ß√£o de crew mais recente.
</Note>

Aqui est√° um exemplo de como reexecutar a partir de uma tarefa:

### Reexecutando a partir de uma Tarefa Espec√≠fica Usando o CLI

Para utilizar o recurso de reexecu√ß√£o, siga estes passos:

<Steps>
  <Step title="Abra seu terminal ou prompt de comando." />

  <Step title="Navegue at√© o diret√≥rio onde est√° localizado seu projeto CrewAI." />

  <Step title="Execute os seguintes comandos:">
    Para visualizar os task\_ids do √∫ltimo kickoff, utilize:

    ```shell
    crewai log-tasks-outputs
    ```

    Ap√≥s identificar o `task_id` que deseja reexecutar, utilize:

    ```shell
    crewai replay -t <task_id>
    ```
  </Step>
</Steps>

<Note>
  Certifique-se de que o `crewai` est√° instalado e devidamente configurado no seu ambiente de desenvolvimento.
</Note>

### Reexecutando uma Tarefa Programaticamente

Para reexecutar uma tarefa programaticamente, siga os passos abaixo:

<Steps>
  <Step title="Especifique o `task_id` e os par√¢metros de entrada para o processo de reexecu√ß√£o.">
    Especifique o `task_id` e os par√¢metros de entrada para o processo de reexecu√ß√£o.
  </Step>

  <Step title="Execute o comando de reexecu√ß√£o dentro de um bloco try-except para lidar com poss√≠veis erros.">
    Execute o comando de reexecu√ß√£o dentro de um bloco try-except para lidar com poss√≠veis erros.

    <CodeGroup>
      ```python Code
        def replay():
        """
        Replay the crew execution from a specific task.
        """
        task_id = '<task_id>'
        inputs = {"topic": "CrewAI Training"}  # This is optional; you can pass in the inputs you want to replay; otherwise, it uses the previous kickoff's inputs.
        try:
            YourCrewName_Crew().crew().replay(task_id=task_id, inputs=inputs)

        except subprocess.CalledProcessError as e:
            raise Exception(f"An error occurred while replaying the crew: {e}")

        except Exception as e:
            raise Exception(f"An unexpected error occurred: {e}")
      ```
    </CodeGroup>
  </Step>
</Steps>

## Conclus√£o

Com as melhorias acima e funcionalidades detalhadas, a reexecu√ß√£o de tarefas espec√≠ficas no CrewAI ficou mais eficiente e robusta.
Certifique-se de seguir exatamente os comandos e passos para aproveitar ao m√°ximo esses recursos.


# Processos Sequenciais
Source: https://docs.crewai.com/pt-BR/learn/sequential-process

Um guia abrangente para utilizar os processos sequenciais na execu√ß√£o de tarefas em projetos CrewAI.

## Introdu√ß√£o

O CrewAI oferece uma estrutura flex√≠vel para execu√ß√£o de tarefas de maneira estruturada, suportando tanto processos sequenciais quanto hier√°rquicos.
Este guia descreve como implementar esses processos de forma eficaz para garantir execu√ß√£o eficiente das tarefas e a conclus√£o do projeto.

## Vis√£o Geral do Processo Sequencial

O processo sequencial garante que as tarefas sejam executadas uma ap√≥s a outra, seguindo um progresso linear.
Essa abordagem √© ideal para projetos nos quais as tarefas precisam ser conclu√≠das em uma ordem espec√≠fica.

### Principais Caracter√≠sticas

* **Fluxo Linear de Tarefas**: Garante o progresso ordenado ao tratar tarefas em uma sequ√™ncia pr√©-determinada.
* **Simplicidade**: Melhor op√ß√£o para projetos com tarefas claras e passo a passo.
* **F√°cil Monitoramento**: Facilita o acompanhamento da conclus√£o das tarefas e do progresso do projeto.

## Implementando o Processo Sequencial

Para utilizar o processo sequencial, monte sua crew e defina as tarefas na ordem em que devem ser executadas.

```python Code
from crewai import Crew, Process, Agent, Task, TaskOutput, CrewOutput

# Define your agents
researcher = Agent(
  role='Researcher',
  goal='Conduct foundational research',
  backstory='An experienced researcher with a passion for uncovering insights'
)
analyst = Agent(
  role='Data Analyst',
  goal='Analyze research findings',
  backstory='A meticulous analyst with a knack for uncovering patterns'
)
writer = Agent(
  role='Writer',
  goal='Draft the final report',
  backstory='A skilled writer with a talent for crafting compelling narratives'
)

# Define your tasks
research_task = Task(
  description='Gather relevant data...',
  agent=researcher,
  expected_output='Raw Data'
)
analysis_task = Task(
  description='Analyze the data...',
  agent=analyst,
  expected_output='Data Insights'
)
writing_task = Task(
  description='Compose the report...',
  agent=writer,
  expected_output='Final Report'
)

# Form the crew with a sequential process
report_crew = Crew(
  agents=[researcher, analyst, writer],
  tasks=[research_task, analysis_task, writing_task],
  process=Process.sequential
)

# Execute the crew
result = report_crew.kickoff()

# Accessing the type-safe output
task_output: TaskOutput = result.tasks[0].output
crew_output: CrewOutput = result.output
```

### Nota:

Cada tarefa em um processo sequencial **deve** ter um agente atribu√≠do. Certifique-se de que todo `Task` inclua um par√¢metro `agent`.

### Fluxo de Trabalho em A√ß√£o

1. **Tarefa Inicial**: Em um processo sequencial, o primeiro agente conclui sua tarefa e sinaliza a finaliza√ß√£o.
2. **Tarefas Subsequentes**: Os agentes assumem suas tarefas conforme o tipo de processo, com os resultados das tarefas anteriores ou diretrizes orientando sua execu√ß√£o.
3. **Finaliza√ß√£o**: O processo √© conclu√≠do assim que a √∫ltima tarefa √© executada, levando √† conclus√£o do projeto.

## Funcionalidades Avan√ßadas

### Delega√ß√£o de Tarefas

Em processos sequenciais, se um agente possui `allow_delegation` definido como `True`, ele pode delegar tarefas para outros agentes na crew.
Esse recurso √© configurado automaticamente quando h√° m√∫ltiplos agentes na crew.

### Execu√ß√£o Ass√≠ncrona

As tarefas podem ser executadas de forma ass√≠ncrona, permitindo processamento paralelo quando apropriado.
Para criar uma tarefa ass√≠ncrona, defina `async_execution=True` ao criar a tarefa.

### Mem√≥ria e Cache

O CrewAI suporta recursos de mem√≥ria e cache:

* **Mem√≥ria**: Habilite definindo `memory=True` ao criar a Crew. Isso permite aos agentes reter informa√ß√µes entre as tarefas.
* **Cache**: Por padr√£o, o cache est√° habilitado. Defina `cache=False` para desativ√°-lo.

### Callbacks

Voc√™ pode definir callbacks tanto no n√≠vel da tarefa quanto no n√≠vel de etapa:

* `task_callback`: Executado ap√≥s a conclus√£o de cada tarefa.
* `step_callback`: Executado ap√≥s cada etapa na execu√ß√£o de um agente.

### M√©tricas de Uso

O CrewAI rastreia o uso de tokens em todas as tarefas e agentes. Voc√™ pode acessar essas m√©tricas ap√≥s a execu√ß√£o.

## Melhores Pr√°ticas para Processos Sequenciais

1. **A Ordem Importa**: Organize as tarefas em uma sequ√™ncia l√≥gica, onde cada uma aproveite o resultado da anterior.
2. **Descri√ß√µes Claras de Tarefas**: Forne√ßa descri√ß√µes detalhadas para cada tarefa, orientando os agentes de forma eficaz.
3. **Sele√ß√£o Apropriada de Agentes**: Relacione as habilidades e fun√ß√µes dos agentes √†s necessidades de cada tarefa.
4. **Use o Contexto**: Aproveite o contexto das tarefas anteriores para informar as seguintes.

Esta documenta√ß√£o atualizada garante que os detalhes reflitam com precis√£o as √∫ltimas mudan√ßas no c√≥digo e descreve claramente como aproveitar novos recursos e configura√ß√µes.
O conte√∫do foi mantido simples e direto para garantir f√°cil compreens√£o.


# Usando Anota√ß√µes no crew.py
Source: https://docs.crewai.com/pt-BR/learn/using-annotations

Aprenda como usar anota√ß√µes para estruturar corretamente agentes, tarefas e componentes no CrewAI

Este guia explica como utilizar anota√ß√µes para referenciar corretamente **agentes**, **tarefas** e outros componentes no arquivo `crew.py`.

## Introdu√ß√£o

As anota√ß√µes no framework CrewAI s√£o utilizadas para decorar classes e m√©todos, fornecendo metadados e funcionalidades para diversos componentes do seu crew. Essas anota√ß√µes auxiliam na organiza√ß√£o e estrutura√ß√£o do seu c√≥digo, tornando-o mais leg√≠vel e f√°cil de manter.

## Anota√ß√µes Dispon√≠veis

O framework CrewAI fornece as seguintes anota√ß√µes:

* `@CrewBase`: Usada para decorar a classe principal do crew.
* `@agent`: Decora m√©todos que definem e retornam objetos Agent.
* `@task`: Decora m√©todos que definem e retornam objetos Task.
* `@crew`: Decora o m√©todo que cria e retorna o objeto Crew.
* `@llm`: Decora m√©todos que inicializam e retornam objetos Language Model.
* `@tool`: Decora m√©todos que inicializam e retornam objetos Tool.
* `@callback`: Utilizada para definir m√©todos de callback.
* `@output_json`: Utilizada para m√©todos que retornam dados em JSON.
* `@output_pydantic`: Utilizada para m√©todos que retornam modelos Pydantic.
* `@cache_handler`: Utilizada para defini√ß√£o de m√©todos de manipula√ß√£o de cache.

## Exemplos de Uso

Vamos passar por exemplos de como utilizar essas anota√ß√µes:

### 1. Classe Base do Crew

```python
@CrewBase
class LinkedinProfileCrew():
    """LinkedinProfile crew"""
    agents_config = 'config/agents.yaml'
    tasks_config = 'config/tasks.yaml'
```

A anota√ß√£o `@CrewBase` √© usada para decorar a classe principal do crew. Esta classe geralmente cont√©m as configura√ß√µes e m√©todos para cria√ß√£o de agentes, tarefas e do pr√≥prio crew.

### 2. Defini√ß√£o de Tool

```python
@tool
def myLinkedInProfileTool(self):
    return LinkedInProfileTool()
```

A anota√ß√£o `@tool` √© usada para decorar m√©todos que retornam objetos tool. Essas ferramentas podem ser usadas por agentes para executar tarefas espec√≠ficas.

### 3. Defini√ß√£o de LLM

```python
@llm
def groq_llm(self):
    api_key = os.getenv('api_key')
    return ChatGroq(api_key=api_key, temperature=0, model_name="mixtral-8x7b-32768")
```

A anota√ß√£o `@llm` √© usada para decorar m√©todos que inicializam e retornam objetos Language Model. Esses LLMs s√£o utilizados pelos agentes para tarefas de processamento de linguagem natural.

### 4. Defini√ß√£o de Agente

```python
@agent
def researcher(self) -> Agent:
    return Agent(
        config=self.agents_config['researcher']
    )
```

A anota√ß√£o `@agent` √© usada para decorar m√©todos que definem e retornam objetos Agent.

### 5. Defini√ß√£o de Tarefa

```python
@task
def research_task(self) -> Task:
    return Task(
        config=self.tasks_config['research_linkedin_task'],
        agent=self.researcher()
    )
```

A anota√ß√£o `@task` √© usada para decorar m√©todos que definem e retornam objetos Task. Esses m√©todos especificam a configura√ß√£o da tarefa e o agente respons√°vel por ela.

### 6. Cria√ß√£o do Crew

```python
@crew
def crew(self) -> Crew:
    """Creates the LinkedinProfile crew"""
    return Crew(
        agents=self.agents,
        tasks=self.tasks,
        process=Process.sequential,
        verbose=True
    )
```

A anota√ß√£o `@crew` √© usada para decorar o m√©todo que cria e retorna o objeto `Crew`. Este m√©todo re√∫ne todos os componentes (agentes e tarefas) em um crew funcional.

## Configura√ß√£o YAML

As configura√ß√µes dos agentes geralmente s√£o armazenadas em um arquivo YAML. Veja um exemplo de como o arquivo `agents.yaml` pode ser estruturado para o agente researcher:

```yaml
researcher:
    role: >
        LinkedIn Profile Senior Data Researcher
    goal: >
        Uncover detailed LinkedIn profiles based on provided name {name} and domain {domain}
        Generate a Dall-E image based on domain {domain}
    backstory: >
        You're a seasoned researcher with a knack for uncovering the most relevant LinkedIn profiles.
        Known for your ability to navigate LinkedIn efficiently, you excel at gathering and presenting
        professional information clearly and concisely.
    allow_delegation: False
    verbose: True
    llm: groq_llm
    tools:
        - myLinkedInProfileTool
        - mySerperDevTool
        - myDallETool
```

Esta configura√ß√£o YAML corresponde ao agente researcher definido na classe `LinkedinProfileCrew`. A configura√ß√£o especifica o papel do agente, objetivo, contexto e outras propriedades, como o LLM e as tools que ele utiliza.

Repare como os campos `llm` e `tools` no arquivo YAML correspondem aos m√©todos decorados com `@llm` e `@tool` na classe Python.

## Boas Pr√°ticas

* **Nomenclatura Consistente**: Utilize nomenclatura clara e consistente para seus m√©todos. Por exemplo, m√©todos de agentes podem ser nomeados de acordo com suas fun√ß√µes (ex: researcher, reporting\_analyst).
* **Vari√°veis de Ambiente**: Utilize vari√°veis de ambiente para informa√ß√µes sens√≠veis como chaves de API.
* **Flexibilidade**: Estruture seu crew de forma flex√≠vel, permitindo f√°cil adi√ß√£o ou remo√ß√£o de agentes e tarefas.
* **Correspond√™ncia YAML-C√≥digo**: Assegure que os nomes e estruturas nos arquivos YAML correspondam corretamente aos m√©todos decorados em seu c√≥digo Python.

Seguindo essas orienta√ß√µes e utilizando corretamente as anota√ß√µes, voc√™ conseguir√° criar crews bem estruturados e de f√°cil manuten√ß√£o utilizando o framework CrewAI.


# Conectando a M√∫ltiplos Servidores MCP
Source: https://docs.crewai.com/pt-BR/mcp/multiple-servers

Saiba como usar o MCPServerAdapter no CrewAI para conectar-se simultaneamente a m√∫ltiplos servidores MCP e agregar suas ferramentas.

## Vis√£o Geral

O `MCPServerAdapter` em `crewai-tools` permite que voc√™ conecte-se a v√°rios servidores MCP simultaneamente. Isso √© √∫til quando seus agentes precisam acessar ferramentas distribu√≠das entre diferentes servi√ßos ou ambientes. O adaptador agrega as ferramentas de todos os servidores especificados, tornando-as dispon√≠veis para seus agentes CrewAI.

## Configura√ß√£o

Para conectar-se a m√∫ltiplos servidores, voc√™ fornece uma lista de dicion√°rios de par√¢metros de servidor para o `MCPServerAdapter`. Cada dicion√°rio na lista deve definir os par√¢metros para um servidor MCP.

Os tipos de transporte suportados para cada servidor na lista incluem `stdio`, `sse` e `streamable-http`.

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter
from mcp import StdioServerParameters # Needed for Stdio example

# Define parameters for multiple MCP servers
server_params_list = [
    # Streamable HTTP Server
    {
        "url": "http://localhost:8001/mcp",
        "transport": "streamable-http"
    },
    # SSE Server
    {
        "url": "http://localhost:8000/sse",
        "transport": "sse"
    },
    # StdIO Server
    StdioServerParameters(
        command="python3",
        args=["servers/your_stdio_server.py"],
        env={"UV_PYTHON": "3.12", **os.environ},
    )
]

try:
    with MCPServerAdapter(server_params_list) as aggregated_tools:
        print(f"Available aggregated tools: {[tool.name for tool in aggregated_tools]}")

        agente_multiservidor = Agent(
            role="Assistente Vers√°til",
            goal="Utilizar ferramentas de servidores MCP locais Stdio, remotos SSE e remotos HTTP.",
            backstory="Um agente de IA capaz de aproveitar um conjunto diversificado de ferramentas de m√∫ltiplas fontes.",
            tools=aggregated_tools, # Todas as ferramentas est√£o dispon√≠veis aqui
            verbose=True,
        )

        ... # Your other agent, tasks, and crew code here

except Exception as e:
    print(f"Error connecting to or using multiple MCP servers (Managed): {e}")
    print("Ensure all MCP servers are running and accessible with correct configurations.")

```

## Gerenciamento de Conex√£o

Ao utilizar o gerenciador de contexto (`with` statement), o `MCPServerAdapter` gerencia o ciclo de vida (in√≠cio e t√©rmino) de todas as conex√µes aos servidores MCP configurados. Isso simplifica o gerenciamento de recursos e garante que todas as conex√µes sejam devidamente fechadas ao sair do contexto.


# Servidores MCP como Ferramentas no CrewAI
Source: https://docs.crewai.com/pt-BR/mcp/overview

Aprenda como integrar servidores MCP como ferramentas nos seus agentes CrewAI usando a biblioteca `crewai-tools`.

## Vis√£o Geral

O [Model Context Protocol](https://modelcontextprotocol.io/introduction) (MCP) fornece uma maneira padronizada para agentes de IA fornecerem contexto para LLMs comunicando-se com servi√ßos externos, conhecidos como Servidores MCP.
A biblioteca `crewai-tools` expande as capacidades do CrewAI permitindo que voc√™ integre facilmente ferramentas desses servidores MCP em seus agentes.
Isso oferece √†s suas crews acesso a um vasto ecossistema de funcionalidades.

Atualmente, suportamos os seguintes mecanismos de transporte:

* **Stdio**: para servidores locais (comunica√ß√£o via entrada/sa√≠da padr√£o entre processos na mesma m√°quina)
* **Server-Sent Events (SSE)**: para servidores remotos (transmiss√£o de dados unidirecional em tempo real do servidor para o cliente via HTTP)
* **Streamable HTTP**: para servidores remotos (comunica√ß√£o flex√≠vel e potencialmente bidirecional via HTTP, geralmente utilizando SSE para streams do servidor para o cliente)

## Tutorial em V√≠deo

Assista a este tutorial em v√≠deo para um guia abrangente sobre a integra√ß√£o do MCP com o CrewAI:

<iframe width="100%" height="400" src="https://www.youtube.com/embed/TpQ45lAZh48" title="CrewAI MCP Integration Guide" frameborder="0" style={{ borderRadius: '10px' }} allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

## Instala√ß√£o

Antes de come√ßar a usar MCP com `crewai-tools`, √© necess√°rio instalar a depend√™ncia extra `mcp` do `crewai-tools` com o seguinte comando:

```shell
uv pip install 'crewai-tools[mcp]'
```

## Conceitos Chave & Primeiros Passos

A classe `MCPServerAdapter` da `crewai-tools` √© a principal forma de conectar-se a um servidor MCP e disponibilizar suas ferramentas aos seus agentes CrewAI. Ela suporta diferentes mecanismos de transporte e simplifica o gerenciamento de conex√µes.

O uso de um gerenciador de contexto Python (`with`) √© a **abordagem recomendada** para o `MCPServerAdapter`. Ele lida automaticamente com a abertura e o fechamento da conex√£o com o servidor MCP.

```python
from crewai import Agent
from crewai_tools import MCPServerAdapter
from mcp import StdioServerParameters # Para servidor Stdio

# Exemplo de server_params (escolha um baseado no seu tipo de servidor):
# 1. Servidor Stdio:
server_params=StdioServerParameters(
    command="python3",
    args=["servers/your_server.py"],
    env={"UV_PYTHON": "3.12", **os.environ},
)

# 2. Servidor SSE:
server_params = {
    "url": "http://localhost:8000/sse",
    "transport": "sse"
}

# 3. Servidor Streamable HTTP:
server_params = {
    "url": "http://localhost:8001/mcp",
    "transport": "streamable-http"
}

# Exemplo de uso (descomente e adapte ap√≥s definir server_params):
with MCPServerAdapter(server_params) as mcp_tools:
    print(f"Available tools: {[tool.name for tool in mcp_tools]}")

    meu_agente = Agent(
        role="Usu√°rio de Ferramentas MCP",
        goal="Utilizar ferramentas de um servidor MCP.",
        backstory="Posso conectar a servidores MCP e usar suas ferramentas.",
        tools=mcp_tools, # Passe as ferramentas carregadas para o seu agente
        reasoning=True,
        verbose=True
    )
    # ... restante da configura√ß√£o do seu crew ...
```

Este padr√£o geral mostra como integrar ferramentas. Para exemplos espec√≠ficos para cada transporte, consulte os guias detalhados abaixo.

## Filtrando Ferramentas

```python
with MCPServerAdapter(server_params) as mcp_tools:
    print(f"Available tools: {[tool.name for tool in mcp_tools]}")

    meu_agente = Agent(
        role="Usu√°rio de Ferramentas MCP",
        goal="Utilizar ferramentas de um servidor MCP.",
        backstory="Posso conectar a servidores MCP e usar suas ferramentas.",
        tools=mcp_tools["tool_name"], # Passe as ferramentas filtradas para o seu agente
        reasoning=True,
        verbose=True
    )
    # ... restante da configura√ß√£o do seu crew ...
```

## Usando com CrewBase

Para usar ferramentas de servidores MCP dentro de uma classe CrewBase, utilize o m√©todo `mcp_tools`. As configura√ß√µes dos servidores devem ser fornecidas via o atributo mcp\_server\_params. Voc√™ pode passar uma configura√ß√£o √∫nica ou uma lista com m√∫ltiplas configura√ß√µes.

```python
@CrewBase
class CrewWithMCP:
  # ... defina o arquivo de configura√ß√£o de agentes e tasks ...

  mcp_server_params = [
    # Servidor Streamable HTTP
    {
        "url": "http://localhost:8001/mcp",
        "transport": "streamable-http"
    },
    # Servidor SSE
    {
        "url": "http://localhost:8000/sse",
        "transport": "sse"
    },
    # Servidor StdIO
    StdioServerParameters(
        command="python3",
        args=["servers/your_stdio_server.py"],
        env={"UV_PYTHON": "3.12", **os.environ},
    )
  ]

  @agent
  def your_agent(self):
      return Agent(config=self.agents_config["your_agent"], tools=self.get_mcp_tools()) # voc√™ tamb√©m pode filtrar quais ferramentas estar√£o dispon√≠veis

    # ... restante da configura√ß√£o do seu crew ...
```

## Explore Integra√ß√µes MCP

<CardGroup cols={2}>
  <Card title="Transporte Stdio" icon="server" href="/pt-BR/mcp/stdio" color="#3B82F6">
    Conecte-se a servidores MCP locais via entrada/sa√≠da padr√£o. Ideal para scripts e execut√°veis locais.
  </Card>

  <Card title="Transporte SSE" icon="wifi" href="/pt-BR/mcp/sse" color="#10B981">
    Integre com servidores MCP remotos usando Server-Sent Events para streaming de dados em tempo real.
  </Card>

  <Card title="Transporte HTTP Streamable" icon="globe" href="/pt-BR/mcp/streamable-http" color="#F59E0B">
    Utilize HTTP Streamable para uma comunica√ß√£o robusta com servidores MCP remotos.
  </Card>

  <Card title="Conectando a M√∫ltiplos Servidores" icon="layer-group" href="/pt-BR/mcp/multiple-servers" color="#8B5CF6">
    Agregue ferramentas de v√°rios servidores MCP simultaneamente usando um √∫nico adaptador.
  </Card>

  <Card title="Considera√ß√µes de Seguran√ßa" icon="lock" href="/pt-BR/mcp/security" color="#EF4444">
    Revise pr√°ticas importantes de seguran√ßa para integra√ß√£o MCP e mantenha seus agentes protegidos.
  </Card>
</CardGroup>

Confira este reposit√≥rio para demonstra√ß√µes completas e exemplos de integra√ß√£o MCP com CrewAI! üëá

<Card title="Reposit√≥rio GitHub" icon="github" href="https://github.com/tonykipkemboi/crewai-mcp-demo" target="_blank">
  Demo MCP do CrewAI
</Card>

## Seguran√ßa ao Usar MCP

<Warning>
  Sempre assegure-se de confiar no servidor MCP antes de utiliz√°-lo.
</Warning>

#### Aviso de Seguran√ßa: Ataques de DNS Rebinding

Transportes SSE podem ser vulner√°veis a ataques de DNS rebinding se n√£o forem devidamente protegidos.
Para prevenir isso:

1. **Sempre valide os cabe√ßalhos Origin** das conex√µes SSE recebidas para garantir que venham de fontes esperadas
2. **Evite vincular servidores a todas as interfaces de rede** (0.0.0.0) quando executando localmente ‚Äì fa√ßa o bind apenas para localhost (127.0.0.1)
3. **Implemente autentica√ß√£o adequada** para todas as conex√µes SSE

Sem essas prote√ß√µes, invasores podem usar DNS rebinding para interagir com servidores MCP locais via sites remotos.

Para mais detalhes, consulte a [documenta√ß√£o de Seguran√ßa de Transporte da MCP da Anthropic](https://modelcontextprotocol.io/docs/concepts/transports#security-considerations).

### Limita√ß√µes

* **Primitivas Suportadas**: Atualmente, o `MCPServerAdapter` suporta principalmente a adapta√ß√£o de `tools` MCP.
  Outras primitivas MCP como `prompts` ou `resources` n√£o s√£o integradas diretamente como componentes CrewAI atrav√©s deste adaptador por enquanto.
* **Manipula√ß√£o de Sa√≠da**: O adaptador normalmente processa a sa√≠da principal de texto de uma ferramenta MCP (por exemplo, `.content[0].text`). Sa√≠das complexas ou multimodais podem exigir tratamento customizado caso n√£o se encaixem nesse padr√£o.


# Considera√ß√µes de Seguran√ßa MCP
Source: https://docs.crewai.com/pt-BR/mcp/security

Saiba mais sobre as principais melhores pr√°ticas de seguran√ßa ao integrar servidores MCP com seus agentes CrewAI.

## Vis√£o Geral

<Warning>
  O aspecto mais cr√≠tico da seguran√ßa MCP √© a **confian√ßa**. Voc√™ deve **apenas** conectar seus agentes CrewAI a servidores MCP nos quais confie plenamente.
</Warning>

Ao integrar servi√ßos externos como servidores MCP (Model Context Protocol) aos seus agentes CrewAI, a seguran√ßa √© fundamental.
Servidores MCP podem executar c√≥digo, acessar dados ou interagir com outros sistemas com base nas ferramentas que exp√µem.
√â crucial compreender as implica√ß√µes e seguir as melhores pr√°ticas para proteger suas aplica√ß√µes e dados.

### Riscos

* Executar c√≥digo arbitr√°rio na m√°quina onde o agente est√° rodando (especialmente com o transporte `Stdio` se o servidor puder controlar o comando executado).
* Expor dados sens√≠veis do seu agente ou do seu ambiente.
* Manipular o comportamento do seu agente de maneiras n√£o intencionais, incluindo realizar chamadas de API n√£o autorizadas em seu nome.
* Sequestrar o processo de racioc√≠nio do agente atrav√©s de t√©cnicas sofisticadas de prompt injection (veja abaixo).

### 1. Confiando em Servidores MCP

<Warning>
  **Somente conecte-se a servidores MCP em que confie.**
</Warning>

Antes de configurar o `MCPServerAdapter` para conectar a um servidor MCP, certifique-se de saber:

* **Quem opera o servidor?** √â um servi√ßo conhecido, de reputa√ß√£o confi√°vel, ou um servidor interno sob o seu controle?
* **Quais ferramentas ele exp√µe?** Entenda as capacidades das ferramentas. Elas poderiam ser mal utilizadas caso um invasor obtenha controle ou se o pr√≥prio servidor for malicioso?
* **Quais dados ele acessa ou processa?** Saiba se h√° informa√ß√µes sens√≠veis que possam ser enviadas ou manipuladas pelo servidor MCP.

Evite conectar-se a servidores MCP desconhecidos ou n√£o verificados, especialmente se seus agentes lidam com tarefas ou dados sens√≠veis.

### 2. Prompt Injection Seguro via Metadados de Ferramentas: O Risco do "Model Control Protocol"

Um risco significativo e sutil √© o potencial para prompt injection atrav√©s dos metadados das ferramentas. Veja como funciona:

1. Quando seu agente CrewAI se conecta a um servidor MCP, ele normalmente solicita uma lista de ferramentas dispon√≠veis.
2. O servidor MCP responde com metadados para cada ferramenta, incluindo nome, descri√ß√£o e descri√ß√µes de par√¢metros.
3. O LLM (Modelo de Linguagem) subjacente do seu agente usa esses metadados para entender como e quando usar as ferramentas. Muitas vezes esses metadados s√£o incorporados no system prompt ou contexto do LLM.
4. Um servidor MCP malicioso pode construir seus metadados (nomes, descri√ß√µes) para incluir instru√ß√µes ocultas ou expl√≠citas. Essas instru√ß√µes podem atuar como prompt injection, efetivamente fazendo o LLM se comportar de determinada maneira, revelar informa√ß√µes sens√≠veis ou executar a√ß√µes maliciosas.

**Crucialmente, esse ataque pode ocorrer simplesmente ao conectar-se a um servidor malicioso e listar suas ferramentas, mesmo que seu agente nunca decida *usar* essas ferramentas.** A mera exposi√ß√£o aos metadados maliciosos pode ser suficiente para comprometer o comportamento do agente.

**Mitiga√ß√£o:**

* **Extrema Cautela com Servidores N√£o Confi√°veis:** Reitere: *N√£o conecte-se a servidores MCP nos quais voc√™ n√£o confie totalmente.* O risco de injection de metadados torna isso fundamental.

### Seguran√ßa do Transporte Stdio

O transporte Stdio (Entrada/Sa√≠da Padr√£o) √© tipicamente usado para servidores MCP locais, rodando na mesma m√°quina que sua aplica√ß√£o CrewAI.

* **Isolamento de Processo**: Embora geralmente seja mais seguro pois n√£o envolve exposi√ß√£o de rede por padr√£o, assegure-se de que o script ou comando executado pelo `StdioServerParameters` √© de uma fonte confi√°vel e possui permiss√µes de sistema de arquivos adequadas. Um script Stdio servidor malicioso pode ainda prejudicar seu sistema local.
* **Saneamento de Entrada**: Se o seu script de servidor Stdio recebe entradas complexas derivadas das intera√ß√µes do agente, garanta que o script saneie essas entradas para evitar injection de comandos ou outras vulnerabilidades na l√≥gica do script.
* **Limite de Recursos**: Esteja atento ao fato de que o processo servidor Stdio consome recursos locais (CPU, mem√≥ria). Assegure-se de que seja bem comportado, evitando esgotar os recursos do sistema.

### Ataques de Confused Deputy

O [Problema do Confused Deputy](https://en.wikipedia.org/wiki/Confused_deputy_problem) √© uma vulnerabilidade cl√°ssica de seguran√ßa que pode se manifestar em integra√ß√µes MCP, especialmente quando um servidor MCP atua como proxy para outros servi√ßos de terceiros (ex: Google Calendar, GitHub) que usam OAuth 2.0 para autoriza√ß√£o.

**Cen√°rio:**

1. Um servidor MCP (vamos cham√°-lo de `MCP-Proxy`) permite que seu agente interaja com o `ThirdPartyAPI`.
2. O `MCP-Proxy` usa seu pr√≥prio `client_id` est√°tico ao comunicar-se com o servidor de autoriza√ß√£o do `ThirdPartyAPI`.
3. Voc√™, como usu√°rio, autoriza legitimamente o `MCP-Proxy` a acessar o `ThirdPartyAPI` em seu nome. Durante esse processo, o servidor de autentica√ß√£o pode definir um cookie no seu navegador indicando seu consentimento para o `client_id` do `MCP-Proxy`.
4. Um invasor cria um link malicioso. Esse link inicia um fluxo OAuth com o `MCP-Proxy`, mas √© projetado para enganar o servidor de autentica√ß√£o do `ThirdPartyAPI`.
5. Se voc√™ clicar nesse link e o servidor de autentica√ß√£o do `ThirdPartyAPI` encontrar seu cookie de consentimento existente para o `client_id` do `MCP-Proxy`, pode *deixar de* pedir seu consentimento novamente.
6. O `MCP-Proxy` pode, ent√£o, ser enganado a encaminhar um c√≥digo de autoriza√ß√£o (para o `ThirdPartyAPI`) para o atacante, ou um c√≥digo de autoriza√ß√£o MCP que o atacante possa usar para se passar por voc√™ perante o `MCP-Proxy`.

**Mitiga√ß√£o (Principalmente para Desenvolvedores de Servidores MCP):**

* Servidores proxy MCP usando IDs de cliente est√°ticos para servi√ßos downstream **devem** obter consentimento expl√≠cito do usu√°rio para *cada aplica√ß√£o cliente ou agente* conectando-se a eles *antes* de iniciar um fluxo OAuth com o servi√ßo de terceiros. Isso significa que o `MCP-Proxy` deve exibir uma tela de consentimento.

**Implica√ß√£o para Usu√°rios CrewAI:**

* Fique atento se um servidor MCP redireciona voc√™ para m√∫ltiplas autentica√ß√µes OAuth, especialmente se isso for inesperado ou se as permiss√µes solicitadas forem muito amplas.
* Prefira servidores MCP que deixem clara sua pr√≥pria identidade e a identidade dos servi√ßos de terceiros que possam fazer proxy.

### Seguran√ßa no Transporte Remoto (SSE & HTTP Transmit√≠vel)

Ao conectar-se a servidores MCP remotos via Server-Sent Events (SSE) ou HTTP transmit√≠vel, pr√°ticas padr√£o de seguran√ßa web s√£o essenciais.

### Considera√ß√µes de Seguran√ßa SSE

### a. Ataques de DNS Rebinding (Especialmente para SSE)

<Critical>
  **Proteja-se contra ataques de DNS Rebinding.**
</Critical>

DNS rebinding permite que um site controlado por atacante contorne a pol√≠tica de mesma origem e fa√ßa requisi√ß√µes para servidores na rede local do usu√°rio (ex: `localhost`) ou intranet. Isso √© particularmente arriscado se voc√™ roda um servidor MCP localmente (ex: para desenvolvimento) e um agente em um ambiente do tipo navegador (embora menos comum no backend CrewAI) ou se o servidor MCP est√° em uma rede interna.

**Estrat√©gias de Mitiga√ß√£o para Implementadores de Servidores MCP:**

* **Valide os Headers `Origin` e `Host`**: Servidores MCP (especialmente com SSE) devem validar os headers HTTP `Origin` e/ou `Host` para garantir que as requisi√ß√µes venham dos dom√≠nios/clientes esperados.
* **Ligue em `localhost` (127.0.0.1)**: Ao rodar servidores MCP localmente para desenvolvimento, conecte-se a `127.0.0.1` em vez de `0.0.0.0`. Isso impede que sejam acess√≠veis por outras m√°quinas na rede.
* **Autentica√ß√£o**: Exija autentica√ß√£o para todas as conex√µes ao seu servidor MCP caso n√£o seja destinado a acesso p√∫blico an√¥nimo.

### b. Use HTTPS

* **Criptografe Dados em Tr√¢nsito**: Sempre use HTTPS (HTTP Seguro) para URLs de servidores MCP remotos. Isso criptografa a comunica√ß√£o entre sua aplica√ß√£o CrewAI e o servidor MCP, protegendo contra escuta e ataques Man-in-the-Middle (MitM). O `MCPServerAdapter` respeitar√° o esquema (`http` ou `https`) fornecido na URL.

### c. Token Passthrough (Anti-Padr√£o)

Isso √© uma preocupa√ß√£o principalmente para desenvolvedores de servidores MCP, mas entender o conceito ajuda a escolher servidores seguros.

"Token passthrough" √© quando um servidor MCP aceita um token de acesso do seu agente CrewAI (que pode ser um token para um servi√ßo *diferente*, por exemplo, `ServiceA`) e simplesmente o repassa para outra API ( `ServiceB`) downstream sem valida√ß√£o adequada. Especificamente, `ServiceB` (ou o pr√≥prio servidor MCP) s√≥ deveria aceitar tokens explicitamente emitidos *para eles* (ou seja, o claim 'audience' no token deve corresponder ao servidor/servi√ßo).

**Riscos:**

* Burlar controles de seguran√ßa (como limites de taxa ou permiss√µes granulares) no servidor MCP ou na API downstream.
* Quebra trilhas de auditoria e responsabiliza√ß√£o.
* Permite uso indevido de tokens roubados.

**Mitiga√ß√£o (Para Desenvolvedores de Servidores MCP):**

* Servidores MCP **N√ÉO DEVEM** aceitar tokens que n√£o foram explicitamente emitidos para eles. Devem validar o claim de audi√™ncia dos tokens.

**Implica√ß√£o para Usu√°rios CrewAI:**

* Embora isso n√£o seja diretamente control√°vel pelo usu√°rio, destaca a import√¢ncia de conectar-se a servidores MCP bem projetados e que sigam as melhores pr√°ticas de seguran√ßa.

#### Autentica√ß√£o e Autoriza√ß√£o

* **Verifique a Identidade**: Se o servidor MCP fornece ferramentas sens√≠veis ou acesso a dados privados, ele DEVE implementar mecanismos de autentica√ß√£o robustos para verificar a identidade do cliente (sua aplica√ß√£o CrewAI). Isso pode envolver chaves de API, tokens OAuth ou outros m√©todos padr√£o.
* **Princ√≠pio do Menor Privil√©gio**: Certifique-se de que as credenciais usadas pelo `MCPServerAdapter` (se houver) tenham apenas as permiss√µes necess√°rias para acessar as ferramentas requeridas.

### d. Valida√ß√£o e Saneamento de Entrada

* **Valida√ß√£o de Entrada √© Cr√≠tica**: Servidores MCP **devem** validar rigorosamente todas as entradas recebidas de agentes *antes* de process√°-las ou pass√°-las para as ferramentas. Esta √© a principal defesa contra diversas vulnerabilidades comuns:
  * **Injection de Comando:** Caso uma ferramenta construa comandos de shell, queries SQL ou outras instru√ß√µes de linguagens interpretadas a partir da entrada, o servidor deve sanitizar cuidadosamente esta entrada para evitar que comandos maliciosos sejam injetados e executados.
  * **Path Traversal:** Se uma ferramenta acessa arquivos com base em par√¢metros de entrada, o servidor deve validar e sanitizar esses caminhos para evitar acesso a arquivos ou diret√≥rios n√£o autorizados (por exemplo, bloqueando sequ√™ncias `../`).
  * **Verifica√ß√µes de Tipo e Faixa de Dados:** Servidores devem garantir que os dados de entrada estejam nos tipos esperados (ex: string, n√∫mero, booleano) e dentro de faixas aceit√°veis ou em formatos definidos (ex: regex para URLs).
  * **Valida√ß√£o de Schema JSON:** Todos os par√¢metros das ferramentas devem ser validados estritamente com seus esquemas JSON definidos. Isso ajuda a capturar requisi√ß√µes mal formatadas precocemente.
* **Aten√ß√£o do Lado do Cliente**: Embora a valida√ß√£o no servidor seja fundamental, como usu√°rio CrewAI, fique atento aos dados que seus agentes s√£o configurados para enviar a ferramentas MCP, especialmente ao interagir com servidores MCP novos ou menos confi√°veis.

### e. Limite de Taxa e Gerenciamento de Recursos

* **Previna Abusos**: Servidores MCP devem implementar limite de taxa para prevenir abusos, seja intencional (ataques de nega√ß√£o de servi√ßo) ou n√£o intencional (ex: um agente mal configurado fazendo muitas requisi√ß√µes).
* **Re-tentativas do Lado do Cliente**: Implemente l√≥gica de repeti√ß√£o sensata em suas tarefas CrewAI se problemas de rede transit√≥rios ou limites de taxa do servidor forem esperados, mas evite re-tentativas agressivas que possam aumentar a carga do servidor.

## 4. Conselhos para Implementa√ß√£o de Servidor MCP Seguro (Para Desenvolvedores)

Se voc√™ est√° desenvolvendo um servidor MCP ao qual agentes CrewAI possam se conectar, considere estas melhores pr√°ticas al√©m dos pontos acima:

* **Siga Pr√°ticas de C√≥digo Seguro**: Adote princ√≠pios padr√£o de programa√ß√£o segura para sua linguagem e framework escolhidos (ex: OWASP Top 10).
* **Princ√≠pio do Menor Privil√©gio**: Certifique-se de que o processo que executa o servidor MCP (especialmente para `Stdio`) tenha apenas as permiss√µes m√≠nimas necess√°rias. As pr√≥prias ferramentas tamb√©m devem operar com o m√≠nimo de privil√©gio necess√°rio para executar sua fun√ß√£o.
* **Gerenciamento de Depend√™ncias**: Mantenha todas as depend√™ncias do lado do servidor, incluindo pacotes do sistema operacional, runtimes de linguagem e bibliotecas de terceiros, sempre atualizadas para corrigir vulnerabilidades conhecidas. Use ferramentas para escanear por depend√™ncias vulner√°veis.
* **Padr√µes Seguros por Padr√£o**: Projete seu servidor e suas ferramentas para serem seguros por padr√£o. Por exemplo, recursos potencialmente arriscados devem ser desabilitados por padr√£o ou requerer ativa√ß√£o expl√≠cita, com avisos claros.
* **Controle de Acesso para Ferramentas**: Implemente mecanismos robustos para controlar quais agentes ou usu√°rios autenticados e autorizados podem acessar ferramentas espec√≠ficas, especialmente as que s√£o poderosas, sens√≠veis ou incorram em custos.
* **Tratamento Seguro de Erros**: Servidores n√£o devem expor mensagens detalhadas de erro interno, traces de stack ou informa√ß√µes de debug para o cliente, pois estas podem revelar detalhes internos ou potenciais vulnerabilidades. Logue os erros de forma abrangente no lado do servidor para diagn√≥stico.
* **Log e Monitoramento Abrangentes**: Implemente um log detalhado de eventos relevantes para seguran√ßa (ex: tentativas de autentica√ß√£o, invoca√ß√µes de ferramenta, erros, mudan√ßas de autoriza√ß√£o). Monitore esses logs em busca de atividades suspeitas ou padr√µes de abuso.
* **Ader√™ncia √† Especifica√ß√£o de Autoriza√ß√£o MCP**: Caso implemente autentica√ß√£o e autoriza√ß√£o, siga estritamente a [especifica√ß√£o de autoriza√ß√£o MCP](https://modelcontextprotocol.io/specification/draft/basic/authorization) e as [melhores pr√°ticas de seguran√ßa OAuth 2.0](https://datatracker.ietf.org/doc/html/rfc9700) relevantes.
* **Auditorias de Seguran√ßa Regulares**: Caso seu servidor MCP manipule dados sens√≠veis, realize opera√ß√µes cr√≠ticas ou seja exposto publicamente, considere auditorias de seguran√ßa peri√≥dicas conduzidas por profissionais qualificados.

## 5. Leituras Adicionais

Para informa√ß√µes mais detalhadas sobre seguran√ßa MCP, consulte a documenta√ß√£o oficial:

* **[Seguran√ßa de Transporte MCP](https://modelcontextprotocol.io/docs/concepts/transports#security-considerations)**

Ao entender essas considera√ß√µes de seguran√ßa e implementar as melhores pr√°ticas, voc√™ pode aproveitar com seguran√ßa o poder dos servidores MCP em seus projetos CrewAI.
Estes pontos n√£o esgotam o assunto, mas cobrem as quest√µes de seguran√ßa mais comuns e cr√≠ticas.
As amea√ßas continuar√£o a evoluir, por isso √© importante se manter informado e adaptar suas medidas de seguran√ßa de acordo.


# Transporte SSE
Source: https://docs.crewai.com/pt-BR/mcp/sse

Saiba como conectar o CrewAI a servidores MCP remotos usando Server-Sent Events (SSE) para comunica√ß√£o em tempo real.

## Vis√£o Geral

Server-Sent Events (SSE) fornecem uma forma padr√£o para um servidor web enviar atualiza√ß√µes a um cliente atrav√©s de uma √∫nica conex√£o HTTP de longa dura√ß√£o. No contexto do MCP, SSE √© utilizado para que servidores remotos transmitam dados (como respostas de ferramentas) para sua aplica√ß√£o CrewAI em tempo real.

## Conceitos-Chave

* **Servidores Remotos**: SSE √© adequado para servidores MCP hospedados remotamente.
* **Fluxo Unidirecional**: Normalmente, SSE √© um canal de comunica√ß√£o de m√£o √∫nica, do servidor para o cliente.
* **Configura√ß√£o do `MCPServerAdapter`**: Para SSE, voc√™ fornecer√° a URL do servidor e especificar√° o tipo de transporte.

## Conectando via SSE

Voc√™ pode se conectar a um servidor MCP baseado em SSE usando duas abordagens principais para gerenciar o ciclo de vida da conex√£o:

### 1. Conex√£o Totalmente Gerenciada (Recomendado)

Utilizar um gerenciador de contexto Python (`with` statement) √© a abordagem recomendada. Ele lida automaticamente com o estabelecimento e o encerramento da conex√£o com o servidor MCP SSE.

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter

server_params = {
    "url": "http://localhost:8000/sse", # Replace with your actual SSE server URL
    "transport": "sse"
}

# Using MCPServerAdapter with a context manager
try:
    with MCPServerAdapter(server_params) as tools:
        print(f"Available tools from SSE MCP server: {[tool.name for tool in tools]}")

        # Example: Using a tool from the SSE MCP server
        agente_sse = Agent(
            role="Usu√°rio de Servi√ßo Remoto",
            goal="Utilizar uma ferramenta fornecida por um servidor MCP remoto via SSE.",
            backstory="Um agente de IA que conecta a servi√ßos externos via SSE.",
            tools=tools,
            reasoning=True,
            verbose=True,
        )

        sse_task = Task(
            description="Buscar atualiza√ß√µes em tempo real das a√ß√µes 'AAPL' usando uma ferramenta SSE.",
            expected_output="O pre√ßo mais recente da a√ß√£o AAPL.",
            agent=agente_sse,
            markdown=True
        )

        sse_crew = Crew(
            agents=[agente_sse],
            tasks=[sse_task],
            verbose=True,
            process=Process.sequential
        )

        if tools: # Only kickoff if tools were loaded
            result = sse_crew.kickoff() # Add inputs={'stock_symbol': 'AAPL'} if tool requires it
            print("\nCrew Task Result (SSE - Managed):\n", result)
        else:
            print("Skipping crew kickoff as tools were not loaded (check server connection).")

except Exception as e:
    print(f"Error connecting to or using SSE MCP server (Managed): {e}")
    print("Ensure the SSE MCP server is running and accessible at the specified URL.")

```

<Note>
  Substitua `"http://localhost:8000/sse"` pela URL real do seu servidor MCP SSE.
</Note>

### 2. Ciclo de Vida Manual da Conex√£o

Caso precise de um controle mais detalhado, voc√™ pode gerenciar manualmente o ciclo de vida da conex√£o do `MCPServerAdapter`.

<Info>
  Voc√™ **DEVE** chamar `mcp_server_adapter.stop()` para garantir que a conex√£o seja encerrada e os recursos liberados. O uso de um bloco `try...finally` √© altamente recomendado.
</Info>

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter

server_params = {
    "url": "http://localhost:8000/sse", # Replace with your actual SSE server URL
    "transport": "sse"
}

mcp_server_adapter = None
try:
    mcp_server_adapter = MCPServerAdapter(server_params)
    mcp_server_adapter.start()
    tools = mcp_server_adapter.tools
    print(f"Available tools (manual SSE): {[tool.name for tool in tools]}")

    manual_sse_agent = Agent(
        role="Analista Remoto de Dados",
        goal="Analisar dados obtidos de um servidor MCP remoto SSE usando gerenciamento manual de conex√£o.",
        backstory="Um agente de IA especializado em gerenciar conex√µes SSE explicitamente.",
        tools=tools,
        verbose=True
    )

    analysis_task = Task(
        description="Buscar e analisar as tend√™ncias mais recentes de atividade de usu√°rios do servidor SSE.",
        expected_output="Um relat√≥rio resumido das tend√™ncias de atividade dos usu√°rios.",
        agent=manual_sse_agent
    )

    analysis_crew = Crew(
        agents=[manual_sse_agent],
        tasks=[analysis_task],
        verbose=True,
        process=Process.sequential
    )

    result = analysis_crew.kickoff()
    print("\nCrew Task Result (SSE - Manual):\n", result)

except Exception as e:
    print(f"An error occurred during manual SSE MCP integration: {e}")
    print("Ensure the SSE MCP server is running and accessible.")
finally:
    if mcp_server_adapter and mcp_server_adapter.is_connected:
        print("Stopping SSE MCP server connection (manual)...")
        mcp_server_adapter.stop()  # **Crucial: Ensure stop is called**
    elif mcp_server_adapter:
        print("SSE MCP server adapter was not connected. No stop needed or start failed.")

```

## Considera√ß√µes de Seguran√ßa para SSE

<Warning>
  **Ataques de DNS Rebinding**: Transportes SSE podem ser vulner√°veis a ataques de DNS rebinding se o servidor MCP n√£o estiver devidamente protegido. Isso pode permitir que sites maliciosos interajam com servidores MCP locais ou da intranet.
</Warning>

Para mitigar esse risco:

* As implementa√ß√µes do servidor MCP devem **validar os cabe√ßalhos `Origin`** em conex√µes SSE recebidas.
* Ao rodar servidores MCP SSE locais para desenvolvimento, **fa√ßa o bind apenas em `localhost` (`127.0.0.1`)** ao inv√©s de todas as interfaces de rede (`0.0.0.0`).
* Implemente **autentica√ß√£o adequada** para todas as conex√µes SSE caso exponham ferramentas ou dados sens√≠veis.

Para uma vis√£o abrangente das melhores pr√°ticas de seguran√ßa, consulte nossa p√°gina de [Considera√ß√µes de Seguran√ßa](./security.mdx) e a documenta√ß√£o oficial [MCP Transport Security](https://modelcontextprotocol.io/docs/concepts/transports#security-considerations).


# Transporte Stdio
Source: https://docs.crewai.com/pt-BR/mcp/stdio

Aprenda como conectar o CrewAI a servidores MCP locais usando o mecanismo de transporte Stdio (Entrada/Sa√≠da Padr√£o).

## Vis√£o Geral

O transporte Stdio (Entrada/Sa√≠da Padr√£o) √© projetado para conectar o `MCPServerAdapter` a servidores MCP locais que se comunicam por meio de seus fluxos de entrada e sa√≠da padr√£o. Isso √© normalmente utilizado quando o servidor MCP √© um script ou execut√°vel rodando na mesma m√°quina da sua aplica√ß√£o CrewAI.

## Conceitos-Chave

* **Execu√ß√£o Local**: O transporte Stdio gerencia um processo localmente em execu√ß√£o para o servidor MCP.
* **`StdioServerParameters`**: Esta classe da biblioteca `mcp` √© usada para configurar o comando, argumentos e vari√°veis de ambiente para iniciar o servidor Stdio.

## Conectando via Stdio

Voc√™ pode se conectar a um servidor MCP baseado em Stdio usando duas abordagens principais para gerenciar o ciclo de vida da conex√£o:

### 1. Conex√£o Totalmente Gerenciada (Recomendado)

Usar um context manager do Python (declara√ß√£o `with`) √© a abordagem recomendada. Ela lida automaticamente com o in√≠cio do processo do servidor MCP e sua finaliza√ß√£o quando o contexto √© encerrado.

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter
from mcp import StdioServerParameters
import os

# Criar um objeto StdioServerParameters
server_params=StdioServerParameters(
    command="python3",
    args=["servers/your_stdio_server.py"],
    env={"UV_PYTHON": "3.12", **os.environ},
)

with MCPServerAdapter(server_params) as tools:
    print(f"Available tools from Stdio MCP server: {[tool.name for tool in tools]}")

    # Exemplo: Usando as ferramentas do servidor MCP Stdio em um Agente CrewAI
    pesquisador_local = Agent(
        role="Processador Local de Dados",
        goal="Processar dados usando uma ferramenta local baseada em Stdio.",
        backstory="Uma IA que utiliza scripts locais via MCP para tarefas especializadas.",
        tools=tools,
        reasoning=True,
        verbose=True,
    )

    processing_task = Task(
        description="Processar o arquivo de dados de entrada 'data.txt' e resumir seu conte√∫do.",
        expected_output="Um resumo dos dados processados.",
        agent=pesquisador_local,
        markdown=True
    )

    data_crew = Crew(
        agents=[pesquisador_local],
        tasks=[processing_task],
        verbose=True,
        process=Process.sequential
    )

    result = data_crew.kickoff()
    print("\nCrew Task Result (Stdio - Managed):\n", result)

```

### 2. Ciclo de Vida Manual da Conex√£o

Se voc√™ precisa de um controle mais refinado sobre quando o processo do servidor MCP Stdio √© iniciado e finalizado, pode gerenciar o ciclo de vida do `MCPServerAdapter` manualmente.

<Info>
  Voc√™ **DEVE** chamar `mcp_server_adapter.stop()` para garantir que o processo do servidor seja finalizado e os recursos, liberados. Recomenda-se fortemente o uso de um bloco `try...finally`.
</Info>

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter
from mcp import StdioServerParameters
import os

# Criar um objeto StdioServerParameters
stdio_params=StdioServerParameters(
    command="python3",
    args=["servers/your_stdio_server.py"],
    env={"UV_PYTHON": "3.12", **os.environ},
)

mcp_server_adapter = MCPServerAdapter(server_params=stdio_params)
try:
    mcp_server_adapter.start()  # Inicia manualmente a conex√£o e o processo do servidor
    tools = mcp_server_adapter.tools
    print(f"Available tools (manual Stdio): {[tool.name for tool in tools]}")

    # Exemplo: Usando as ferramentas com sua configura√ß√£o de Agent, Task, Crew
    manual_agent = Agent(
        role="Executor Local de Tarefas",
        goal="Executar uma tarefa local espec√≠fica usando uma ferramenta Stdio gerenciada manualmente.",
        backstory="Uma IA proficiente em controlar processos locais via MCP.",
        tools=tools,
        verbose=True
    )

    manual_task = Task(
        description="Executar o comando 'perform_analysis' via ferramenta Stdio.",
        expected_output="Resultados da an√°lise.",
        agent=manual_agent
    )

    manual_crew = Crew(
        agents=[manual_agent],
        tasks=[manual_task],
        verbose=True,
        process=Process.sequential
    )


    result = manual_crew.kickoff() # As entradas reais dependem da sua ferramenta
    print("\nCrew Task Result (Stdio - Manual):\n", result)

except Exception as e:
    print(f"An error occurred during manual Stdio MCP integration: {e}")
finally:
    if mcp_server_adapter and mcp_server_adapter.is_connected: # Verifica se est√° conectado antes de parar
        print("Stopping Stdio MCP server connection (manual)...")
        mcp_server_adapter.stop()  # **Crucial: Assegure que stop seja chamado**
    elif mcp_server_adapter: # Se o adaptador existe mas n√£o est√° conectado (ex.: start falhou)
        print("Stdio MCP server adapter was not connected. No stop needed or start failed.")

```

Lembre-se de substituir caminhos e comandos de exemplo pelos detalhes reais do seu servidor Stdio. O par√¢metro `env` em `StdioServerParameters` pode ser usado para definir vari√°veis de ambiente para o processo do servidor, o que pode ser √∫til para configurar seu comportamento ou fornecer caminhos necess√°rios (como `PYTHONPATH`).


# Transporte HTTP Streamable
Source: https://docs.crewai.com/pt-BR/mcp/streamable-http

Saiba como conectar o CrewAI a servidores MCP remotos usando o transporte HTTP Streamable flex√≠vel.

## Vis√£o Geral

O transporte HTTP Streamable oferece uma maneira flex√≠vel de se conectar a servidores MCP remotos. Ele √© frequentemente baseado em HTTP e pode suportar v√°rios padr√µes de comunica√ß√£o, incluindo requisi√ß√£o-resposta e streaming, √†s vezes utilizando Server-Sent Events (SSE) para fluxos do servidor para o cliente dentro de uma intera√ß√£o HTTP mais ampla.

## Conceitos-Chave

* **Servidores Remotos**: Projetado para servidores MCP hospedados remotamente.
* **Flexibilidade**: Pode suportar padr√µes de intera√ß√£o mais complexos do que SSE puro, potencialmente incluindo comunica√ß√£o bidirecional se o servidor implement√°-la.
* **Configura√ß√£o do `MCPServerAdapter`**: Voc√™ precisar√° fornecer a URL base do servidor para comunica√ß√£o MCP e especificar `"streamable-http"` como o tipo de transporte.

## Conectando via HTTP Streamable

Voc√™ tem dois m√©todos principais para gerenciar o ciclo de vida da conex√£o com um servidor MCP HTTP Streamable:

### 1. Conex√£o Totalmente Gerenciada (Recomendado)

A abordagem recomendada √© usar um gerenciador de contexto Python (`with` statement), que lida automaticamente com a configura√ß√£o e encerramento da conex√£o.

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter

server_params = {
    "url": "http://localhost:8001/mcp", # Replace with your actual Streamable HTTP server URL
    "transport": "streamable-http"
}

try:
    with MCPServerAdapter(server_params) as tools:
        print(f"Available tools from Streamable HTTP MCP server: {[tool.name for tool in tools]}")

        agente_http = Agent(
            role="Integrador de Servi√ßos HTTP",
            goal="Utilizar ferramentas de um servidor MCP remoto via Streamable HTTP.",
            backstory="Um agente de IA especializado em interagir com servi√ßos web complexos.",
            tools=tools,
            verbose=True,
        )

        http_task = Task(
            description="Realizar uma consulta de dados complexa usando uma ferramenta do servidor Streamable HTTP.",
            expected_output="O resultado da consulta de dados complexa.",
            agent=agente_http,
        )

        http_crew = Crew(
            agents=[agente_http],
            tasks=[http_task],
            verbose=True,
            process=Process.sequential
        )

        result = http_crew.kickoff()
        print("\nCrew Task Result (Streamable HTTP - Managed):\n", result)

except Exception as e:
    print(f"Error connecting to or using Streamable HTTP MCP server (Managed): {e}")
    print("Ensure the Streamable HTTP MCP server is running and accessible at the specified URL.")

```

**Nota:** Substitua `"http://localhost:8001/mcp"` pela URL real do seu servidor MCP HTTP Streamable.

### 2. Ciclo de Vida da Conex√£o Manual

Para cen√°rios que exigem controle mais expl√≠cito, voc√™ pode gerenciar a conex√£o do `MCPServerAdapter` manualmente.

<Info>
  √â **cr√≠tico** chamar `mcp_server_adapter.stop()` quando terminar para fechar a conex√£o e liberar recursos. Usar um bloco `try...finally` √© a forma mais segura de garantir isso.
</Info>

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import MCPServerAdapter

server_params = {
    "url": "http://localhost:8001/mcp", # Replace with your actual Streamable HTTP server URL
    "transport": "streamable-http"
}

mcp_server_adapter = None
try:
    mcp_server_adapter = MCPServerAdapter(server_params)
    mcp_server_adapter.start()
    tools = mcp_server_adapter.tools
    print(f"Available tools (manual Streamable HTTP): {[tool.name for tool in tools]}")

    manual_http_agent = Agent(
        role="Usu√°rio Avan√ßado de Servi√ßos Web",
        goal="Interagir com um servidor MCP usando conex√µes HTTP Streamable gerenciadas manualmente.",
        backstory="Um especialista em IA em ajustar integra√ß√µes baseadas em HTTP.",
        tools=tools,
        verbose=True
    )

    data_processing_task = Task(
        description="Enviar dados para processamento e recuperar resultados via Streamable HTTP.",
        expected_output="Dados processados ou confirma√ß√£o.",
        agent=manual_http_agent
    )

    data_crew = Crew(
        agents=[manual_http_agent],
        tasks=[data_processing_task],
        verbose=True,
        process=Process.sequential
    )

    result = data_crew.kickoff()
    print("\nCrew Task Result (Streamable HTTP - Manual):\n", result)

except Exception as e:
    print(f"An error occurred during manual Streamable HTTP MCP integration: {e}")
    print("Ensure the Streamable HTTP MCP server is running and accessible.")
finally:
    if mcp_server_adapter and mcp_server_adapter.is_connected:
        print("Stopping Streamable HTTP MCP server connection (manual)...")
        mcp_server_adapter.stop()  # **Crucial: Ensure stop is called**
    elif mcp_server_adapter:
        print("Streamable HTTP MCP server adapter was not connected. No stop needed or start failed.")
```

## Considera√ß√µes de Seguran√ßa

Ao utilizar o transporte HTTP Streamable, as melhores pr√°ticas gerais de seguran√ßa web s√£o fundamentais:

* **Use HTTPS**: Sempre prefira HTTPS (HTTP Seguro) para as URLs do seu servidor MCP para criptografar os dados em tr√¢nsito.
* **Autentica√ß√£o**: Implemente mecanismos robustos de autentica√ß√£o se seu servidor MCP expuser ferramentas ou dados sens√≠veis.
* **Valida√ß√£o de Entrada**: Garanta que seu servidor MCP valide todas as requisi√ß√µes e par√¢metros recebidos.

Para um guia abrangente sobre como proteger suas integra√ß√µes MCP, consulte nossa p√°gina de [Considera√ß√µes de Seguran√ßa](./security.mdx) e a documenta√ß√£o oficial de [Seguran√ßa em Transportes MCP](https://modelcontextprotocol.io/docs/concepts/transports#security-considerations).


# Integra√ß√£o com AgentOps
Source: https://docs.crewai.com/pt-BR/observability/agentops

Entendendo e registrando a performance do seu agente com AgentOps.

# Introdu√ß√£o

Observabilidade √© um aspecto fundamental no desenvolvimento e implanta√ß√£o de agentes de IA conversacional. Ela permite que desenvolvedores compreendam como seus agentes est√£o performando,
como eles est√£o interagindo com os usu√°rios e como utilizam ferramentas externas e APIs.
AgentOps √© um produto independente do CrewAI que fornece uma solu√ß√£o completa de observabilidade para agentes.

## AgentOps

[AgentOps](https://agentops.ai/?=crew) oferece replay de sess√µes, m√©tricas e monitoramento para agentes.

Em um alto n√≠vel, o AgentOps oferece a capacidade de monitorar custos, uso de tokens, lat√™ncia, falhas do agente, estat√≠sticas de sess√£o e muito mais.
Para mais informa√ß√µes, confira o [Reposit√≥rio do AgentOps](https://github.com/AgentOps-AI/agentops).

### Vis√£o Geral

AgentOps fornece monitoramento para agentes em desenvolvimento e produ√ß√£o.
Disponibiliza um dashboard para acompanhamento de performance dos agentes, replay de sess√µes e relat√≥rios personalizados.

Al√©m disso, o AgentOps traz an√°lises detalhadas das sess√µes para visualizar intera√ß√µes do agente Crew, chamadas LLM e uso de ferramentas em tempo real.
Esse recurso √© √∫til para depura√ß√£o e entendimento de como os agentes interagem com usu√°rios e entre si.

![Vis√£o geral de uma s√©rie selecionada de execu√ß√µes de sess√µes do agente](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/agentops-overview.png)
![Vis√£o geral das an√°lises detalhadas de sess√µes para examinar execu√ß√µes de agentes](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/agentops-session.png)
![Visualizando um gr√°fico de execu√ß√£o passo a passo do replay do agente](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/agentops-replay.png)

### Funcionalidades

* **Gerenciamento e Rastreamento de Custos de LLM**: Acompanhe gastos com provedores de modelos fundamentais.
* **An√°lises de Replay**: Assista gr√°ficos de execu√ß√£o do agente, passo a passo.
* **Detec√ß√£o de Pensamento Recursivo**: Identifique quando agentes entram em loops infinitos.
* **Relat√≥rios Personalizados**: Crie an√°lises customizadas sobre a performance dos agentes.
* **Dashboard Anal√≠tico**: Monitore estat√≠sticas gerais de agentes em desenvolvimento e produ√ß√£o.
* **Teste de Modelos P√∫blicos**: Teste seus agentes em benchmarks e rankings.
* **Testes Personalizados**: Execute seus agentes em testes espec√≠ficos de dom√≠nio.
* **Depura√ß√£o com Viagem no Tempo**: Reinicie suas sess√µes a partir de checkpoints.
* **Conformidade e Seguran√ßa**: Crie registros de auditoria e detecte poss√≠veis amea√ßas como uso de palavr√µes e vazamento de dados pessoais.
* **Detec√ß√£o de Prompt Injection**: Identifique poss√≠veis inje√ß√µes de c√≥digo e vazamentos de segredos.

### Utilizando o AgentOps

<Steps>
  <Step title="Crie uma Chave de API">
    Crie uma chave de API de usu√°rio aqui: [Create API Key](https://app.agentops.ai/account)
  </Step>

  <Step title="Configure seu Ambiente">
    Adicione sua chave API nas vari√°veis de ambiente:

    ```bash
    AGENTOPS_API_KEY=<YOUR_AGENTOPS_API_KEY>
    ```
  </Step>

  <Step title="Instale o AgentOps">
    Instale o AgentOps com:

    ```bash
    pip install 'crewai[agentops]'
    ```

    ou

    ```bash
    pip install agentops
    ```
  </Step>

  <Step title="Inicialize o AgentOps">
    Antes de utilizar o `Crew` no seu script, inclua estas linhas:

    ```python
    import agentops
    agentops.init()
    ```

    Isso ir√° iniciar uma sess√£o do AgentOps e tamb√©m rastrear automaticamente os agentes Crew. Para mais detalhes sobre como adaptar sistemas de agentes mais complexos,
    confira a [documenta√ß√£o do AgentOps](https://docs.agentops.ai) ou participe do [Discord](https://discord.gg/j4f3KbeH).
  </Step>
</Steps>

### Exemplos de Crew + AgentOps

<CardGroup cols={3}>
  <Card title="Vaga de Emprego" color="#F3A78B" href="https://github.com/joaomdmoura/crewAI-examples/tree/main/job-posting" icon="briefcase" iconType="solid">
    Exemplo de um agente Crew que gera vagas de emprego.
  </Card>

  <Card title="Validador de Markdown" color="#F3A78B" href="https://github.com/joaomdmoura/crewAI-examples/tree/main/markdown_validator" icon="markdown" iconType="solid">
    Exemplo de um agente Crew que valida arquivos Markdown.
  </Card>

  <Card title="Post no Instagram" color="#F3A78B" href="https://github.com/joaomdmoura/crewAI-examples/tree/main/instagram_post" icon="square-instagram" iconType="brands">
    Exemplo de um agente Crew que gera posts para Instagram.
  </Card>
</CardGroup>

### Mais Informa√ß√µes

Para come√ßar, crie uma [conta AgentOps](https://agentops.ai/?=crew).

Para sugest√µes de funcionalidades ou relatos de bugs, entre em contato com o time do AgentOps pelo [Reposit√≥rio do AgentOps](https://github.com/AgentOps-AI/agentops).

#### Links Extras

<a href="https://twitter.com/agentopsai/">üê¶ Twitter</a>
<span>¬†¬†‚Ä¢¬†¬†</span>
<a href="https://discord.gg/JHPt4C7r">üì¢ Discord</a>
<span>¬†¬†‚Ä¢¬†¬†</span>
<a href="https://app.agentops.ai/?=crew">üñáÔ∏è Dashboard AgentOps</a>
<span>¬†¬†‚Ä¢¬†¬†</span>
<a href="https://docs.agentops.ai/introduction">üìô Documenta√ß√£o</a>


# Arize Phoenix
Source: https://docs.crewai.com/pt-BR/observability/arize-phoenix

Integra√ß√£o do Arize Phoenix para CrewAI com OpenTelemetry e OpenInference

# Integra√ß√£o com Arize Phoenix

Este guia demonstra como integrar o **Arize Phoenix** ao **CrewAI** usando o OpenTelemetry atrav√©s do [OpenInference](https://github.com/openinference/openinference) SDK. Ao final deste guia, voc√™ ser√° capaz de rastrear seus agentes CrewAI e depur√°-los com facilidade.

> **O que √© o Arize Phoenix?** O [Arize Phoenix](https://phoenix.arize.com) √© uma plataforma de observabilidade de LLM que oferece rastreamento e avalia√ß√£o para aplica√ß√µes de IA.

[![Assista a um v√≠deo demonstrando a nossa integra√ß√£o com o Phoenix](https://storage.googleapis.com/arize-assets/fixtures/setup_crewai.png)](https://www.youtube.com/watch?v=Yc5q3l6F7Ww)

## Primeiros Passos

Vamos percorrer um exemplo simples de uso do CrewAI e integra√ß√£o com o Arize Phoenix via OpenTelemetry utilizando o OpenInference.

Voc√™ tamb√©m pode acessar este guia no [Google Colab](https://colab.research.google.com/github/Arize-ai/phoenix/blob/main/tutorials/tracing/crewai_tracing_tutorial.ipynb).

### Passo 1: Instale as Depend√™ncias

```bash
pip install openinference-instrumentation-crewai crewai crewai-tools arize-phoenix-otel
```

### Passo 2: Configure as Vari√°veis de Ambiente

Configure as chaves de API do Phoenix Cloud e ajuste o OpenTelemetry para enviar rastros ao Phoenix. O Phoenix Cloud √© uma vers√£o hospedada do Arize Phoenix, mas n√£o √© obrigat√≥rio para utilizar esta integra√ß√£o.

Voc√™ pode obter uma chave de API gratuita do Serper [aqui](https://serper.dev/).

```python
import os
from getpass import getpass

# Obtenha suas credenciais do Phoenix Cloud
PHOENIX_API_KEY = getpass("üîë Digite sua Phoenix Cloud API Key: ")

# Obtenha as chaves de API para os servi√ßos
OPENAI_API_KEY = getpass("üîë Digite sua OpenAI API key: ")
SERPER_API_KEY = getpass("üîë Digite sua Serper API key: ")

# Defina as vari√°veis de ambiente
os.environ["PHOENIX_CLIENT_HEADERS"] = f"api_key={PHOENIX_API_KEY}"
os.environ["PHOENIX_COLLECTOR_ENDPOINT"] = "https://app.phoenix.arize.com" # Phoenix Cloud, altere para seu endpoint se estiver utilizando uma inst√¢ncia self-hosted
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
os.environ["SERPER_API_KEY"] = SERPER_API_KEY
```

### Passo 3: Inicialize o OpenTelemetry com o Phoenix

Inicialize o SDK de instrumenta√ß√£o OpenTelemetry do OpenInference para come√ßar a capturar rastros e envi√°-los ao Phoenix.

```python
from phoenix.otel import register

tracer_provider = register(
    project_name="crewai-tracing-demo",
    auto_instrument=True,
)
```

### Passo 4: Crie uma Aplica√ß√£o CrewAI

Vamos criar uma aplica√ß√£o CrewAI em que dois agentes colaboram para pesquisar e escrever um post de blog sobre avan√ßos em IA.

```python
from crewai import Agent, Crew, Process, Task
from crewai_tools import SerperDevTool
from openinference.instrumentation.crewai import CrewAIInstrumentor
from phoenix.otel import register

# configure o monitoramento para seu crew
tracer_provider = register(
    endpoint="http://localhost:6006/v1/traces")
CrewAIInstrumentor().instrument(skip_dep_check=True, tracer_provider=tracer_provider)
search_tool = SerperDevTool()

# Defina seus agentes com pap√©is e objetivos
pesquisador = Agent(
    role="Analista S√™nior de Pesquisa",
    goal="Descobrir os avan√ßos mais recentes em IA e ci√™ncia de dados",
    backstory="""
Voc√™ trabalha em um importante think tank de tecnologia. Sua especialidade √© identificar tend√™ncias emergentes. Voc√™ tem habilidade para dissecar dados complexos e apresentar insights acion√°veis.
""",
    verbose=True,
    allow_delegation=False,
    tools=[search_tool],
)
writer = Agent(
    role="Estrategista de Conte√∫do T√©cnico",
    goal="Criar conte√∫do envolvente sobre avan√ßos tecnol√≥gicos",
    backstory="Voc√™ √© um Estrategista de Conte√∫do renomado, conhecido por seus artigos perspicazes e envolventes. Voc√™ transforma conceitos complexos em narrativas atraentes.",
    verbose=True,
    allow_delegation=True,
)

# Crie tarefas para seus agentes
task1 = Task(
    description="Realize uma an√°lise abrangente dos avan√ßos mais recentes em IA em 2024. Identifique tend√™ncias-chave, tecnologias inovadoras e impactos potenciais na ind√∫stria.",
    expected_output="Relat√≥rio anal√≠tico completo em t√≥picos",
    agent=pesquisador,
)

task2 = Task(
    description="Utilizando os insights fornecidos, desenvolva um blog envolvente destacando os avan√ßos mais significativos em IA. O post deve ser informativo e acess√≠vel, voltado para um p√∫blico t√©cnico. D√™ um tom interessante, evite palavras complexas para n√£o soar como IA.",
    expected_output="Post de blog completo com pelo menos 4 par√°grafos",
    agent=writer,
)

# Instancie seu crew com um processo sequencial
crew = Crew(
    agents=[pesquisador, writer], tasks=[task1, task2], verbose=1, process=Process.sequential
)

# Coloque seu crew para trabalhar!
result = crew.kickoff()

print("######################")
print(result)
```

### Passo 5: Visualize os Rastros no Phoenix

Ap√≥s executar o agente, voc√™ poder√° visualizar os rastros gerados pela sua aplica√ß√£o CrewAI no Phoenix. Voc√™ ver√° etapas detalhadas das intera√ß√µes dos agentes e chamadas de LLM, o que pode ajudar na depura√ß√£o e otimiza√ß√£o dos seus agentes de IA.

Acesse sua conta Phoenix Cloud e navegue at√© o projeto que voc√™ especificou no par√¢metro `project_name`. Voc√™ ver√° uma visualiza√ß√£o de linha do tempo do seu rastro, incluindo todas as intera√ß√µes dos agentes, uso de ferramentas e chamadas LLM.

![Exemplo de rastro no Phoenix mostrando intera√ß√µes de agentes](https://storage.googleapis.com/arize-assets/fixtures/crewai_traces.png)

### Informa√ß√µes de Compatibilidade de Vers√£o

* Python 3.8+
* CrewAI >= 0.86.0
* Arize Phoenix >= 7.0.1
* OpenTelemetry SDK >= 1.31.0

### Refer√™ncias

* [Documenta√ß√£o do Phoenix](https://docs.arize.com/phoenix/) - Vis√£o geral da plataforma Phoenix.
* [Documenta√ß√£o do CrewAI](https://docs.crewai.com/) - Vis√£o geral do framework CrewAI.
* [Documenta√ß√£o do OpenTelemetry](https://opentelemetry.io/docs/) - Guia do OpenTelemetry
* [OpenInference GitHub](https://github.com/openinference/openinference) - C√≥digo-fonte do SDK OpenInference.


# Integra√ß√£o Langfuse
Source: https://docs.crewai.com/pt-BR/observability/langfuse

Saiba como integrar o Langfuse ao CrewAI via OpenTelemetry usando OpenLit

# Integre o Langfuse ao CrewAI

Este notebook demonstra como integrar o **Langfuse** ao **CrewAI** usando OpenTelemetry via o SDK **OpenLit**. Ao final deste notebook, voc√™ ser√° capaz de rastrear suas aplica√ß√µes CrewAI com o Langfuse para melhorar a observabilidade e a depura√ß√£o.

> **O que √© Langfuse?** [Langfuse](https://langfuse.com) √© uma plataforma open-source de engenharia LLM. Ela fornece recursos de rastreamento e monitoramento para aplica√ß√µes LLM, ajudando desenvolvedores a depurar, analisar e otimizar seus sistemas de IA. O Langfuse se integra com v√°rias ferramentas e frameworks atrav√©s de integra√ß√µes nativas, OpenTelemetry e APIs/SDKs.

[![V√≠deo de Vis√£o Geral do Langfuse](https://github.com/user-attachments/assets/3926b288-ff61-4b95-8aa1-45d041c70866)](https://langfuse.com/watch-demo)

## Primeiros Passos

Vamos passar por um exemplo simples usando CrewAI e integrando ao Langfuse via OpenTelemetry utilizando o OpenLit.

### Passo 1: Instale as Depend√™ncias

```python
%pip install langfuse openlit crewai crewai_tools
```

### Passo 2: Configure as Vari√°veis de Ambiente

Defina suas chaves de API do Langfuse e configure as op√ß√µes de exporta√ß√£o do OpenTelemetry para enviar os traces ao Langfuse. Consulte a [Documenta√ß√£o Langfuse OpenTelemetry](https://langfuse.com/docs/opentelemetry/get-started) para mais informa√ß√µes sobre o endpoint Langfuse OpenTelemetry `/api/public/otel` e autentica√ß√£o.

```python
import os

# Obtenha as chaves do seu projeto na p√°gina de configura√ß√µes do projeto: https://cloud.langfuse.com
os.environ["LANGFUSE_PUBLIC_KEY"] = "pk-lf-..."
os.environ["LANGFUSE_SECRET_KEY"] = "sk-lf-..."
os.environ["LANGFUSE_HOST"] = "https://cloud.langfuse.com" # üá™üá∫ Regi√£o UE
# os.environ["LANGFUSE_HOST"] = "https://us.cloud.langfuse.com" # üá∫üá∏ Regi√£o EUA


# Sua chave OpenAI
os.environ["OPENAI_API_KEY"] = "sk-proj-..."
```

Com as vari√°veis de ambiente configuradas, agora podemos inicializar o cliente Langfuse. A fun√ß√£o get\_client() inicializa o cliente Langfuse usando as credenciais fornecidas nas vari√°veis de ambiente.

```python
from langfuse import get_client

langfuse = get_client()

# Verificar conex√£o
if langfuse.auth_check():
    print("Cliente Langfuse autenticado e pronto!")
else:
    print("Falha na autentica√ß√£o. Verifique suas credenciais e host.")
```

### Passo 3: Inicialize o OpenLit

Inicialize o SDK de instrumenta√ß√£o OpenTelemetry do OpenLit para come√ßar a capturar traces do OpenTelemetry.

```python
import openlit

openlit.init()
```

### Passo 4: Crie uma Aplica√ß√£o Simples CrewAI

Vamos criar uma aplica√ß√£o simples CrewAI onde m√∫ltiplos agentes colaboram para responder √† pergunta de um usu√°rio.

```python
from crewai import Agent, Task, Crew

from crewai_tools import (
    WebsiteSearchTool
)

web_rag_tool = WebsiteSearchTool()

escritor = Agent(
    role="Escritor",
    goal="Voc√™ torna a matem√°tica envolvente e compreens√≠vel para crian√ßas pequenas atrav√©s de poesias",
    backstory="Voc√™ √© especialista em escrever haicais mas n√£o sabe nada de matem√°tica.",
    tools=[web_rag_tool],
)

tarefa = Task(description=("O que √© {multiplica√ß√£o}?"),
              expected_output=("Componha um haicai que inclua a resposta."),
              agent=escritor)

equipe = Crew(
  agents=[escritor],
  tasks=[tarefa],
  share_crew=False
)
```

### Passo 5: Veja os Traces no Langfuse

Ap√≥s rodar o agente, voc√™ pode visualizar os traces gerados pela sua aplica√ß√£o CrewAI no [Langfuse](https://cloud.langfuse.com). Voc√™ ver√° etapas detalhadas das intera√ß√µes do LLM, o que pode ajudar na depura√ß√£o e otimiza√ß√£o do seu agente de IA.

![Exemplo de trace CrewAI no Langfuse](https://langfuse.com/images/cookbook/integration_crewai/crewai-example-trace.png)

*[Exemplo p√∫blico de trace no Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/e2cf380ffc8d47d28da98f136140642b?timestamp=2025-02-05T15%3A12%3A02.717Z\&observation=3b32338ee6a5d9af)*

## Refer√™ncias

* [Documenta√ß√£o Langfuse OpenTelemetry](https://langfuse.com/docs/opentelemetry/get-started)


# Integra√ß√£o com Langtrace
Source: https://docs.crewai.com/pt-BR/observability/langtrace

Como monitorar custo, lat√™ncia e desempenho dos Agentes CrewAI usando o Langtrace, uma ferramenta externa de observabilidade.

# Vis√£o Geral do Langtrace

O Langtrace √© uma ferramenta externa e open-source que auxilia na configura√ß√£o de observabilidade e avalia√ß√µes para Modelos de Linguagem de Grande Porte (LLMs), frameworks de LLM e Bancos de Dados Vetoriais.
Apesar de n√£o ser integrado diretamente ao CrewAI, o Langtrace pode ser utilizado em conjunto com o CrewAI para fornecer uma visibilidade aprofundada sobre o custo, lat√™ncia e desempenho dos seus Agentes CrewAI.
Essa integra√ß√£o permite o registro de hiperpar√¢metros, o monitoramento de regress√µes de desempenho e o estabelecimento de um processo de melhoria cont√≠nua dos seus Agentes.

![Vis√£o geral de uma sele√ß√£o de execu√ß√µes de sess√µes de agentes](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/langtrace1.png)
![Vis√£o geral dos traces de agentes](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/langtrace2.png)
![Vis√£o detalhada dos traces de LLM](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/langtrace3.png)

## Instru√ß√µes de Configura√ß√£o

<Steps>
  <Step title="Crie uma conta no Langtrace">
    Cadastre-se acessando [https://langtrace.ai/signup](https://langtrace.ai/signup).
  </Step>

  <Step title="Crie um projeto">
    Defina o tipo do projeto como `CrewAI` e gere uma chave de API.
  </Step>

  <Step title="Instale o Langtrace no seu projeto CrewAI">
    Use o seguinte comando:

    ```bash
    pip install langtrace-python-sdk
    ```
  </Step>

  <Step title="Importe o Langtrace">
    Importe e inicialize o Langtrace no in√≠cio do seu script, antes de quaisquer imports do CrewAI:

    ```python
    from langtrace_python_sdk import langtrace
    langtrace.init(api_key='<SUA_CHAVE_LANGTRACE>')

    # Agora importe os m√≥dulos do CrewAI
    from crewai import Agent, Task, Crew
    ```
  </Step>
</Steps>

### Funcionalidades e Sua Aplica√ß√£o no CrewAI

1. **Rastreamento de Token e Custo do LLM**

   * Monitore o uso de tokens e os custos associados para cada intera√ß√£o dos agentes CrewAI.

2. **Gr√°fico de Trace para Etapas de Execu√ß√£o**

   * Visualize o fluxo de execu√ß√£o das suas tarefas CrewAI, incluindo lat√™ncia e logs.
   * √ötil para identificar gargalos nos fluxos de trabalho dos seus agentes.

3. **Curadoria de Dataset com Anota√ß√£o Manual**

   * Crie conjuntos de dados a partir das sa√≠das das suas tarefas CrewAI para futuros treinamentos ou avalia√ß√µes.

4. **Versionamento e Gerenciamento de Prompt**

   * Acompanhe as diferentes vers√µes de prompts utilizados em seus agentes CrewAI.
   * √ötil para testes A/B e otimiza√ß√£o de desempenho dos agentes.

5. **Playground de Prompt com Compara√ß√µes de Modelos**

   * Teste e compare diferentes prompts e modelos para seus agentes CrewAI antes da implanta√ß√£o.

6. **Testes e Avalia√ß√µes**

   * Configure testes automatizados para seus agentes e tarefas CrewAI.


# Integra√ß√£o Maxim
Source: https://docs.crewai.com/pt-BR/observability/maxim

Inicie o monitoramento, avalia√ß√£o e observabilidade de agentes

# Integra√ß√£o Maxim

Maxim AI oferece monitoramento completo de agentes, avalia√ß√£o e observabilidade para suas aplica√ß√µes CrewAI. Com a integra√ß√£o de uma linha do Maxim, voc√™ pode facilmente rastrear e analisar intera√ß√µes dos agentes, m√©tricas de desempenho e muito mais.

## Funcionalidades: Integra√ß√£o com Uma Linha

* **Rastreamento de Agentes de Ponta a Ponta**: Monitore todo o ciclo de vida dos seus agentes
* **An√°lise de Desempenho**: Acompanhe lat√™ncia, tokens consumidos e custos
* **Monitoramento de Hiperpar√¢metros**: Visualize detalhes de configura√ß√£o das execu√ß√µes dos agentes
* **Rastreamento de Chamadas de Ferramentas**: Observe quando e como os agentes usam suas ferramentas
* **Visualiza√ß√£o Avan√ßada**: Entenda as trajet√≥rias dos agentes atrav√©s de dashboards intuitivos

## Come√ßando

### Pr√©-requisitos

* Python vers√£o >=3.10
* Uma conta Maxim ([cadastre-se aqui](https://getmaxim.ai/))
* Um projeto CrewAI

### Instala√ß√£o

Instale o SDK do Maxim via pip:

```python
pip install maxim-py>=3.6.2
```

Ou adicione ao seu `requirements.txt`:

```
maxim-py>=3.6.2
```

### Configura√ß√£o B√°sica

### 1. Configure as vari√°veis de ambiente

```python
### Configura√ß√£o de Vari√°veis de Ambiente

# Crie um arquivo `.env` na raiz do seu projeto:

# Configura√ß√£o da API Maxim
MAXIM_API_KEY=your_api_key_here
MAXIM_LOG_REPO_ID=your_repo_id_here
```

### 2. Importe os pacotes necess√°rios

```python
from crewai import Agent, Task, Crew, Process
from maxim import Maxim
from maxim.logger.crewai import instrument_crewai
```

### 3. Inicialize o Maxim com sua chave de API

```python
# Inicialize o logger do Maxim
logger = Maxim().logger()

# Instrumente o CrewAI com apenas uma linha
instrument_crewai(logger)
```

### 4. Crie e execute sua aplica√ß√£o CrewAI normalmente

```python
pesquisador = Agent(
    role='Pesquisador S√™nior',
    goal='Descobrir os avan√ßos mais recentes em IA',
    backstory="Voc√™ √© um pesquisador especialista em um think tank de tecnologia...",
    verbose=True,
    llm=llm
)

# Defina a tarefa
research_task = Task(
    description="Pesquise os avan√ßos mais recentes em IA...",
    expected_output="",
    agent=pesquisador
)

# Configure e execute a crew
crew = Crew(
    agents=[pesquisador],
    tasks=[research_task],
    verbose=True
)

try:
    result = crew.kickoff()
finally:
    maxim.cleanup()  # Garanta o cleanup mesmo em caso de erros
```

√â isso! Todas as intera√ß√µes dos seus agentes CrewAI agora ser√£o registradas e estar√£o dispon√≠veis em seu painel Maxim.

Confira este Google Colab Notebook para refer√™ncia r√°pida ‚Äì [Notebook](https://colab.research.google.com/drive/1ZKIZWsmgQQ46n8TH9zLsT1negKkJA6K8?usp=sharing)

## Visualizando Seus Rastreamentos

Ap√≥s executar sua aplica√ß√£o CrewAI:

![Exemplo de rastreamento no Maxim mostrando intera√ß√µes de agentes](https://raw.githubusercontent.com/maximhq/maxim-docs/master/images/Screenshot2025-05-14at12.10.58PM.png)

1. Fa√ßa login no seu [Painel Maxim](https://getmaxim.ai/dashboard)
2. Navegue at√© seu reposit√≥rio
3. Visualize rastreamentos detalhados de agentes, incluindo:
   * Conversas dos agentes
   * Padr√µes de uso de ferramentas
   * M√©tricas de desempenho
   * An√°lises de custos

## Solu√ß√£o de Problemas

### Problemas Comuns

* **Nenhum rastreamento aparecendo**: Certifique-se de que sua chave de API e o ID do reposit√≥rio est√£o corretos

* Certifique-se de que voc√™ **chamou `instrument_crewai()`** ***antes*** de executar sua crew. Isso inicializa corretamente os hooks de logging.

* Defina `debug=True` na chamada do `instrument_crewai()` para expor erros internos:

  ```python
  instrument_crewai(logger, debug=True)
  ```

* Configure seus agentes com `verbose=True` para capturar logs detalhados:

  ```python

  agent = CrewAgent(..., verbose=True)
  ```

* Verifique cuidadosamente se `instrument_crewai()` foi chamado **antes** de criar ou executar agentes. Isso pode parecer √≥bvio, mas √© um erro comum.

### Suporte

Se voc√™ encontrar algum problema:

* Consulte a [Documenta√ß√£o do Maxim](https://getmaxim.ai/docs)
* Maxim Github [Link](https://github.com/maximhq)


# Integra√ß√£o com MLflow
Source: https://docs.crewai.com/pt-BR/observability/mlflow

Comece rapidamente a monitorar seus Agents com MLflow.

# Vis√£o Geral do MLflow

[MLflow](https://mlflow.org/) √© uma plataforma open-source que auxilia profissionais e equipes de machine learning a lidar com as complexidades do processo de aprendizagem de m√°quina.

Ela oferece um recurso de tracing que aprimora a observabilidade de LLMs em suas aplica√ß√µes de IA Generativa, capturando informa√ß√µes detalhadas sobre a execu√ß√£o dos servi√ßos de sua aplica√ß√£o.
O tracing fornece uma forma de registrar os inputs, outputs e metadados associados a cada etapa intermedi√°ria de uma requisi√ß√£o, permitindo que voc√™ identifique facilmente a origem de bugs e comportamentos inesperados.

![Vis√£o geral do uso de tracing MLflow com crewAI](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/mlflow-tracing.gif)

### Funcionalidades

* **Painel de Tracing**: Monitore as atividades dos seus agentes crewAI com pain√©is detalhados que incluem entradas, sa√≠das e metadados dos spans.
* **Tracing Automatizado**: Uma integra√ß√£o totalmente automatizada com crewAI, que pode ser habilitada executando `mlflow.crewai.autolog()`.
* **Instrumenta√ß√£o Manual de Tracing com pouco esfor√ßo**: Personalize a instrumenta√ß√£o dos traces usando as APIs de alto n√≠vel do MLflow, como decorators, wrappers de fun√ß√µes e context managers.
* **Compatibilidade com OpenTelemetry**: O MLflow Tracing suporta a exporta√ß√£o de traces para um OpenTelemetry Collector, que pode ent√£o ser usado para exportar traces para diversos backends como Jaeger, Zipkin e AWS X-Ray.
* **Empacote e Fa√ßa Deploy dos Agents**: Empacote e fa√ßa deploy de seus agents crewAI em um servidor de infer√™ncia com diversas op√ß√µes de destino.
* **Hospede LLMs com Seguran√ßa**: Hospede m√∫ltiplos LLMs de v√°rios provedores em um endpoint unificado atrav√©s do gateway do MFflow.
* **Avalia√ß√£o**: Avalie seus agents crewAI com uma ampla variedade de m√©tricas utilizando a API conveniente `mlflow.evaluate()`.

## Instru√ß√µes de Configura√ß√£o

<Steps>
  <Step title="Instale o pacote MLflow">
    ```shell
    # A integra√ß√£o crewAI est√° dispon√≠vel no mlflow>=2.19.0
    pip install mlflow
    ```
  </Step>

  <Step title="Inicie o servidor de tracking do MFflow">
    ```shell
    # Este processo √© opcional, mas √© recomendado utilizar o servidor de tracking do MLflow para melhor visualiza√ß√£o e mais funcionalidades.
    mlflow server
    ```
  </Step>

  <Step title="Inicialize o MLflow em sua aplica√ß√£o">
    Adicione as duas linhas a seguir ao c√≥digo da sua aplica√ß√£o:

    ```python
    import mlflow

    mlflow.crewai.autolog()

    # Opcional: Defina uma tracking URI e um nome de experimento caso utilize um servidor de tracking
    mlflow.set_tracking_uri("http://localhost:5000")
    mlflow.set_experiment("CrewAI")
    ```

    Exemplo de uso para tracing de Agents do CrewAI:

    ```python
    from crewai import Agent, Crew, Task
    from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource
    from crewai_tools import SerperDevTool, WebsiteSearchTool

    from textwrap import dedent

    content = "Users name is John. He is 30 years old and lives in San Francisco."
    string_source = StringKnowledgeSource(
        content=content, metadata={"preference": "personal"}
    )

    search_tool = WebsiteSearchTool()


    class TripAgents:
        def city_selection_agent(self):
            especialista_cidades = Agent(
                role="Especialista em Sele√ß√£o de Cidades",
                goal="Selecionar a melhor cidade com base no clima, esta√ß√£o e pre√ßos",
                backstory="Especialista em analisar dados de viagem para escolher destinos ideais",
                tools=[search_tool],
                verbose=True,
            )

        def local_expert(self):
            especialista_local = Agent(
                role="Especialista Local nesta cidade",
                goal="Fornecer as MELHORES informa√ß√µes sobre a cidade selecionada",
                backstory="Um guia local experiente com amplo conhecimento sobre a cidade, suas atra√ß√µes e costumes",
                tools=[search_tool],
                verbose=True,
            )


    class TripTasks:
        def identify_task(self, agent, origin, cities, interests, range):
            return Task(
                description=dedent(
                    f"""
                    Analise e selecione a melhor cidade para a viagem com base em crit√©rios espec√≠ficos como padr√µes clim√°ticos, eventos sazonais e custos de viagem. Esta tarefa envolve comparar v√°rias cidades, considerando fatores como condi√ß√µes clim√°ticas atuais, eventos culturais ou sazonais e despesas gerais de viagem.
                    Sua resposta final deve ser um relat√≥rio detalhado sobre a cidade escolhida e tudo o que voc√™ descobriu sobre ela, incluindo custos reais de voo, previs√£o do tempo e atra√ß√µes.

                    Saindo de: {origin}
                    Op√ß√µes de cidades: {cities}
                    Data da viagem: {range}
                    Interesses do viajante: {interests}
                """
                ),
                agent=agent,
                expected_output="Relat√≥rio detalhado sobre a cidade escolhida incluindo custos de voo, previs√£o do tempo e atra√ß√µes",
            )

        def gather_task(self, agent, origin, interests, range):
            return Task(
                description=dedent(
                    f"""
                    Como especialista local nesta cidade, voc√™ deve compilar um guia aprofundado para algu√©m que est√° viajando para l√° e quer ter a MELHOR viagem poss√≠vel!
                    Re√∫na informa√ß√µes sobre principais atra√ß√µes, costumes locais, eventos especiais e recomenda√ß√µes de atividades di√°rias.
                    Encontre os melhores lugares para ir, aqueles que s√≥ um local conhece.
                    Este guia deve fornecer uma vis√£o abrangente do que a cidade tem a oferecer, incluindo joias escondidas, pontos culturais, marcos imperd√≠veis, previs√£o do tempo e custos gerais.
                    A resposta final deve ser um guia completo da cidade, rico em insights culturais e dicas pr√°ticas, adaptado para aprimorar a experi√™ncia de viagem.

                    Data da viagem: {range}
                    Saindo de: {origin}
                    Interesses do viajante: {interests}
                """
                ),
                agent=agent,
                expected_output="Guia completo da cidade incluindo joias escondidas, pontos culturais e dicas pr√°ticas",
            )


    class TripCrew:
        def __init__(self, origin, cities, date_range, interests):
            self.cities = cities
            self.origin = origin
            self.interests = interests
            self.date_range = date_range

        def run(self):
            agents = TripAgents()
            tasks = TripTasks()

            city_selector_agent = agents.city_selection_agent()
            local_expert_agent = agents.local_expert()

            identify_task = tasks.identify_task(
                city_selector_agent,
                self.origin,
                self.cities,
                self.interests,
                self.date_range,
            )
            gather_task = tasks.gather_task(
                local_expert_agent, self.origin, self.interests, self.date_range
            )

            crew = Crew(
                agents=[city_selector_agent, local_expert_agent],
                tasks=[identify_task, gather_task],
                verbose=True,
                memory=True,
                knowledge={
                    "sources": [string_source],
                    "metadata": {"preference": "personal"},
                },
            )

            result = crew.kickoff()
            return result


    trip_crew = TripCrew("California", "Tokyo", "Dec 12 - Dec 20", "sports")
    result = trip_crew.run()

    print("Resultado da equipe:", result)
    ```

    Consulte a [Documenta√ß√£o de Tracing do MLflow](https://mlflow.org/docs/latest/llms/tracing/index.html) para mais configura√ß√µes e casos de uso.
  </Step>

  <Step title="Visualize as atividades dos Agents">
    Agora os traces dos seus agentes crewAI est√£o sendo capturados pelo MLflow.
    Vamos acessar o servidor de tracking do MLflow para visualizar os traces e obter insights dos seus Agents.

    Abra `127.0.0.1:5000` em seu navegador para acessar o servidor de tracking do MLflow.

    <Frame caption="Painel de Tracing do MLflow">
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/mlflow1.png" alt="Exemplo de tracing do MLflow com crewai" />
    </Frame>
  </Step>
</Steps>


# Integra√ß√£o OpenLIT
Source: https://docs.crewai.com/pt-BR/observability/openlit

Comece a monitorar seus Agentes rapidamente com apenas uma linha de c√≥digo usando OpenTelemetry.

# Vis√£o Geral do OpenLIT

[OpenLIT](https://github.com/openlit/openlit?src=crewai-docs) √© uma ferramenta open-source que simplifica o monitoramento de desempenho de agentes de IA, LLMs, VectorDBs e GPUs com apenas **uma** linha de c√≥digo.

Ela oferece rastreamento e m√©tricas nativos do OpenTelemetry para acompanhar par√¢metros importantes como custo, lat√™ncia, intera√ß√µes e sequ√™ncias de tarefas.
Essa configura√ß√£o permite acompanhar hiperpar√¢metros e monitorar problemas de desempenho, ajudando a encontrar formas de aprimorar e refinar seus agentes com o tempo.

<Frame caption="Painel do OpenLIT">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/openlit1.png" alt="Vis√£o geral do uso de agentes, incluindo custo e tokens" />

  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/openlit2.png" alt="Vis√£o geral dos rastreamentos e m√©tricas otel do agente" />

  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/openlit3.png" alt="Vis√£o detalhada dos rastreamentos do agente" />
</Frame>

### Funcionalidades

* **Painel Anal√≠tico**: Monitore a sa√∫de e desempenho dos seus Agentes com dashboards detalhados que acompanham m√©tricas, custos e intera√ß√µes dos usu√°rios.
* **SDK de Observabilidade Nativo OpenTelemetry**: SDKs neutros de fornecedor para enviar rastreamentos e m√©tricas para suas ferramentas de observabilidade existentes como Grafana, DataDog e outros.
* **Rastreamento de Custos para Modelos Customizados e Ajustados**: Adapte estimativas de custo para modelos espec√≠ficos usando arquivos de precifica√ß√£o customizados para or√ßamentos precisos.
* **Painel de Monitoramento de Exce√ß√µes**: Identifique e solucione rapidamente problemas ao rastrear exce√ß√µes comuns e erros por meio de um painel de monitoramento.
* **Conformidade e Seguran√ßa**: Detecte amea√ßas potenciais como profanidade e vazamento de dados sens√≠veis (PII).
* **Detec√ß√£o de Prompt Injection**: Identifique poss√≠veis inje√ß√µes de c√≥digo e vazamentos de segredos.
* **Gerenciamento de Chaves de API e Segredos**: Gerencie suas chaves de API e segredos do LLM de forma centralizada e segura, evitando pr√°ticas inseguras.
* **Gerenciamento de Prompt**: Gerencie e versiona prompts de Agente usando o PromptHub para acesso consistente e f√°cil entre os agentes.
* **Model Playground** Teste e compare diferentes modelos para seus agentes CrewAI antes da implanta√ß√£o.

## Instru√ß√µes de Configura√ß√£o

<Steps>
  <Step title="Implantar o OpenLIT">
    <Steps>
      <Step title="Clonar o Reposit√≥rio do OpenLIT">
        ```shell
        git clone git@github.com:openlit/openlit.git
        ```
      </Step>

      <Step title="Iniciar o Docker Compose">
        A partir do diret√≥rio raiz do [Reposit√≥rio OpenLIT](https://github.com/openlit/openlit), execute o comando abaixo:

        ```shell
        docker compose up -d
        ```
      </Step>
    </Steps>
  </Step>

  <Step title="Instalar o SDK OpenLIT">
    ```shell
    pip install openlit
    ```
  </Step>

  <Step title="Inicializar o OpenLIT em Sua Aplica√ß√£o">
    Adicione as duas linhas abaixo ao seu c√≥digo de aplica√ß√£o:

    <Tabs>
      <Tab title="Configura√ß√£o usando argumentos de fun√ß√£o">
        ```python
        import openlit
        openlit.init(otlp_endpoint="http://127.0.0.1:4318")
        ```

        Exemplo de uso para monitoramento de um Agente CrewAI:

        ```python
        from crewai import Agent, Task, Crew, Process
        import openlit

        openlit.init(disable_metrics=True)
        # Definir seus agentes
        pesquisador = Agent(
            role="Pesquisador",
            goal="Realizar pesquisas e an√°lises aprofundadas sobre IA e agentes de IA",
            backstory="Voc√™ √© um pesquisador especialista em tecnologia, engenharia de software, IA e startups. Trabalha como freelancer e est√° atualmente pesquisando para um novo cliente.",
            allow_delegation=False,
            llm='command-r'
        )


        # Definir sua task
        task = Task(
            description="Gere uma lista com 5 ideias interessantes para um artigo e escreva um par√°grafo cativante para cada ideia, mostrando o potencial de um artigo completo sobre o tema. Retorne a lista de ideias com seus par√°grafos e suas anota√ß√µes.",
            expected_output="5 t√≥picos, cada um com um par√°grafo e notas complementares.",
        )

        # Definir o agente gerente
        gerente = Agent(
            role="Gerente de Projeto",
            goal="Gerenciar eficientemente a equipe e garantir a conclus√£o de tarefas de alta qualidade",
            backstory="Voc√™ √© um gerente de projetos experiente, habilidoso em supervisionar projetos complexos e guiar equipes para o sucesso. Sua fun√ß√£o √© coordenar os esfor√ßos dos membros da equipe, garantindo que cada tarefa seja conclu√≠da no prazo e com o mais alto padr√£o.",
            allow_delegation=True,
            llm='command-r'
        )

        # Instanciar sua crew com um manager personalizado
        crew = Crew(
            agents=[pesquisador],
            tasks=[task],
            manager_agent=gerente,
            process=Process.hierarchical,
        )

        # Iniciar o trabalho da crew
        result = crew.kickoff()

        print(result)
        ```
      </Tab>

      <Tab title="Configura√ß√£o usando Vari√°veis de Ambiente">
        Adicione as duas linhas abaixo ao seu c√≥digo de aplica√ß√£o:

        ```python
        import openlit

        openlit.init()
        ```

        Execute o seguinte comando para configurar o endpoint de exporta√ß√£o OTEL:

        ```shell
        export OTEL_EXPORTER_OTLP_ENDPOINT = "http://127.0.0.1:4318"
        ```

        Exemplo de uso para monitoramento de um Agente CrewAI Async:

        ```python
        import asyncio
        from crewai import Crew, Agent, Task
        import openlit

        openlit.init(otlp_endpoint="http://127.0.0.1:4318")

        # Criar um agente com execu√ß√£o de c√≥digo habilitada
        coding_agent = Agent(
          role="Analista de Dados Python",
          goal="Analisar dados e fornecer insights usando Python",
          backstory="Voc√™ √© um analista de dados experiente com fortes habilidades em Python.",
          allow_code_execution=True,
          llm="command-r"
        )

        # Criar uma task que exige execu√ß√£o de c√≥digo
        data_analysis_task = Task(
          description="Analise o conjunto de dados fornecido e calcule a idade m√©dia dos participantes. Idades: {ages}",
          agent=coding_agent,
          expected_output="5 t√≥picos, cada um com um par√°grafo e notas complementares.",
        )

        # Criar uma crew e adicionar a task
        analysis_crew = Crew(
          agents=[coding_agent],
          tasks=[data_analysis_task]
        )

        # Fun√ß√£o async para iniciar a crew de forma ass√≠ncrona
        async def async_crew_execution():
            result = await analysis_crew.kickoff_async(inputs={"ages": [25, 30, 35, 40, 45]})
            print("Crew Result:", result)

        # Executar a fun√ß√£o async
        asyncio.run(async_crew_execution())
        ```
      </Tab>
    </Tabs>

    Consulte o [reposit√≥rio do SDK Python do OpenLIT](https://github.com/openlit/openlit/tree/main/sdk/python) para configura√ß√µes e casos de uso avan√ßados.
  </Step>

  <Step title="Visualizar e Analisar">
    Com os dados de Observabilidade dos Agentes agora sendo coletados e enviados ao OpenLIT, o pr√≥ximo passo √© visualizar e analisar esses dados para obter insights sobre o desempenho, comportamento e identificar oportunidades de melhoria dos seus Agentes.

    Basta acessar o OpenLIT em `127.0.0.1:3000` no seu navegador para come√ßar a explorar. Voc√™ pode fazer login usando as credenciais padr√£o

    * **Email**: `user@openlit.io`
    * **Senha**: `openlituser`

    <Frame caption="Painel do OpenLIT">
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/openlit1.png" alt="Vis√£o geral do uso de agentes, incluindo custo e tokens" />

      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/openlit2.png" alt="Vis√£o geral dos rastreamentos e m√©tricas otel do agente" />
    </Frame>
  </Step>
</Steps>


# Integra√ß√£o Opik
Source: https://docs.crewai.com/pt-BR/observability/opik

Saiba como usar o Comet Opik para depurar, avaliar e monitorar suas aplica√ß√µes CrewAI com rastreamento abrangente, avalia√ß√µes automatizadas e dashboards prontos para produ√ß√£o.

# Vis√£o Geral do Opik

Com o [Comet Opik](https://www.comet.com/docs/opik/), depure, avalie e monitore suas aplica√ß√µes LLM, sistemas RAG e fluxos de trabalho agentic com rastreamento detalhado, avalia√ß√µes automatizadas e dashboards prontos para produ√ß√£o.

<Frame caption="Dashboard do Agente Opik">
  <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/opik-crewai-dashboard.png" alt="Exemplo de monitoramento de agente Opik com CrewAI" />
</Frame>

O Opik oferece suporte abrangente para cada etapa do desenvolvimento da sua aplica√ß√£o CrewAI:

* **Registrar Traces e Spans**: Acompanhe automaticamente chamadas LLM e l√≥gica da aplica√ß√£o para depurar e analisar sistemas em desenvolvimento e em produ√ß√£o. Anote manualmente ou programaticamente, visualize e compare respostas entre projetos.
* **Avalie a Performance da sua Aplica√ß√£o LLM**: Avalie contra um conjunto de testes personalizado e execute m√©tricas de avalia√ß√£o nativas ou defina suas pr√≥prias m√©tricas via SDK ou UI.
* **Teste no Pipeline CI/CD**: Estabele√ßa bases de performance confi√°veis com os testes unit√°rios LLM do Opik, baseados em PyTest. Execute avalia√ß√µes online para monitoramento cont√≠nuo em produ√ß√£o.
* **Monitore & Analise Dados de Produ√ß√£o**: Entenda a performance dos seus modelos em dados in√©ditos em produ√ß√£o e gere conjuntos de dados para novas itera√ß√µes de desenvolvimento.

## Configura√ß√£o

A Comet oferece uma vers√£o hospedada da plataforma Opik, ou voc√™ pode rodar a plataforma localmente.

Para usar a vers√£o hospedada, basta [criar uma conta gratuita na Comet](https://www.comet.com/signup?utm_medium=github\&utm_source=crewai_docs) e obter sua chave de API.

Para rodar a plataforma Opik localmente, veja nosso [guia de instala√ß√£o](https://www.comet.com/docs/opik/self-host/overview/) para mais informa√ß√µes.

Neste guia, utilizaremos o exemplo de in√≠cio r√°pido da CrewAI.

<Steps>
  <Step title="Instale os pacotes necess√°rios">
    ```shell
    pip install crewai crewai-tools opik --upgrade
    ```
  </Step>

  <Step title="Configure o Opik">
    ```python
    import opik
    opik.configure(use_local=False)
    ```
  </Step>

  <Step title="Prepare o ambiente">
    Primeiro, configuramos nossas chaves de API do provedor LLM como vari√°veis de ambiente:

    ```python
    import os
    import getpass

    if "OPENAI_API_KEY" not in os.environ:
    os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter your OpenAI API key: ")
    ```
  </Step>

  <Step title="Usando a CrewAI">
    O primeiro passo √© criar nosso projeto. Vamos utilizar um exemplo da documenta√ß√£o do CrewAI:

    ```python
    from crewai import Agent, Crew, Task, Process


    class NomeDaEquipe:
        def agente_um(self) -> Agent:
            return Agent(
                role="Analista de Dados",
                goal="Analisar tend√™ncias de dados no mercado",
                backstory="Analista de dados experiente com forma√ß√£o em economia",
                verbose=True,
            )

        def agente_dois(self) -> Agent:
            return Agent(
                role="Pesquisador de Mercado",
                goal="Coletar informa√ß√µes sobre a din√¢mica do mercado",
                backstory="Pesquisador dedicado com olhar atento para detalhes",
                verbose=True,
            )

        def tarefa_um(self) -> Task:
            return Task(
                name="Tarefa de Coleta de Dados",
                description="Coletar dados recentes do mercado e identificar tend√™ncias.",
                expected_output="Um relat√≥rio resumindo as principais tend√™ncias do mercado.",
                agent=self.agente_um(),
            )

        def tarefa_dois(self) -> Task:
            return Task(
                name="Tarefa de Pesquisa de Mercado",
                description="Pesquisar fatores que afetam a din√¢mica do mercado.",
                expected_output="Uma an√°lise dos fatores que influenciam o mercado.",
                agent=self.agente_dois(),
            )

        def equipe(self) -> Crew:
            return Crew(
                agents=[self.agente_um(), self.agente_dois()],
                tasks=[self.tarefa_um(), self.tarefa_dois()],
                process=Process.sequential,
                verbose=True,
            )

    ```

    Agora podemos importar o tracker do Opik e executar nossa crew:

    ```python
    from opik.integrations.crewai import track_crewai

    track_crewai(project_name="crewai-integration-demo")

    my_crew = NomeDaEquipe().equipe()
    result = my_crew.kickoff()

    print(result)
    ```

    Ap√≥s rodar sua aplica√ß√£o CrewAI, acesse o app Opik para visualizar:

    * Traces LLM, spans e seus metadados
    * Intera√ß√µes dos agentes e fluxo de execu√ß√£o das tarefas
    * M√©tricas de performance, como lat√™ncia e uso de tokens
    * M√©tricas de avalia√ß√£o (nativas ou personalizadas)
  </Step>
</Steps>

## Recursos

* [ü¶â Documenta√ß√£o Opik](https://www.comet.com/docs/opik/)
* [üëâ Opik + CrewAI Colab](https://colab.research.google.com/github/comet-ml/opik/blob/main/apps/opik-documentation/documentation/docs/cookbook/crewai.ipynb)
* [üê¶ X](https://x.com/cometml)
* [üí¨ Slack](https://slack.comet.com/)


# Vis√£o Geral
Source: https://docs.crewai.com/pt-BR/observability/overview

Monitore, avalie e otimize seus agentes CrewAI com ferramentas de observabilidade abrangentes

## Observabilidade para CrewAI

A observabilidade √© fundamental para entender como seus agentes CrewAI est√£o desempenhando, identificar gargalos e garantir uma opera√ß√£o confi√°vel em ambientes de produ√ß√£o. Esta se√ß√£o aborda diversas ferramentas e plataformas que oferecem recursos de monitoramento, avalia√ß√£o e otimiza√ß√£o dos fluxos de trabalho dos seus agentes.

## Por que a Observabilidade √© Importante

* **Monitoramento de Desempenho**: Acompanhe tempos de execu√ß√£o dos agentes, uso de tokens e consumo de recursos
* **Garantia de Qualidade**: Avalie a qualidade e a consist√™ncia das sa√≠das em diferentes cen√°rios
* **Depura√ß√£o**: Identifique e resolva problemas no comportamento dos agentes e na execu√ß√£o de tarefas
* **Gest√£o de Custos**: Monitore o uso das APIs do LLM e os custos associados
* **Melhoria Cont√≠nua**: Colete insights para otimizar o desempenho dos agentes ao longo do tempo

## Ferramentas de Observabilidade Dispon√≠veis

### Plataformas de Monitoramento e Rastreamento

<CardGroup cols={2}>
  <Card title="AgentOps" icon="paperclip" href="/pt-BR/observability/agentops">
    Replays de sess√µes, m√©tricas e monitoramento para desenvolvimento e produ√ß√£o de agentes.
  </Card>

  <Card title="OpenLIT" icon="magnifying-glass-chart" href="/pt-BR/observability/openlit">
    Monitoramento nativo OpenTelemetry com rastreamento de custos e an√°lises de desempenho.
  </Card>

  <Card title="MLflow" icon="bars-staggered" href="/pt-BR/observability/mlflow">
    Gerenciamento do ciclo de vida de machine learning com rastreamento e avalia√ß√£o.
  </Card>

  <Card title="Langfuse" icon="link" href="/pt-BR/observability/langfuse">
    Plataforma de engenharia de LLM com rastreamento detalhado e an√°lises.
  </Card>

  <Card title="Langtrace" icon="chart-line" href="/pt-BR/observability/langtrace">
    Observabilidade open-source para LLMs e frameworks de agentes.
  </Card>

  <Card title="Arize Phoenix" icon="meteor" href="/pt-BR/observability/arize-phoenix">
    Plataforma de observabilidade de IA para monitoramento e solu√ß√£o de problemas.
  </Card>

  <Card title="Portkey" icon="key" href="/pt-BR/observability/portkey">
    Gateway de IA com monitoramento abrangente e recursos de confiabilidade.
  </Card>

  <Card title="Opik" icon="meteor" href="/pt-BR/observability/opik">
    Depure, avalie e monitore aplica√ß√µes LLM com rastreamento abrangente.
  </Card>

  <Card title="Weave" icon="network-wired" href="/pt-BR/observability/weave">
    Plataforma Weights & Biases para acompanhamento e avalia√ß√£o de aplica√ß√µes de IA.
  </Card>
</CardGroup>

### Avalia√ß√£o & Garantia de Qualidade

<CardGroup cols={2}>
  <Card title="Patronus AI" icon="shield-check" href="/pt-BR/observability/patronus-evaluation">
    Plataforma abrangente de avalia√ß√£o para sa√≠das de LLM e comportamentos de agentes.
  </Card>
</CardGroup>

## Principais M√©tricas de Observabilidade

### M√©tricas de Desempenho

* **Tempo de Execu√ß√£o**: Quanto tempo os agentes levam para concluir as tarefas
* **Uso de Tokens**: Tokens de entrada/sa√≠da consumidos pelas chamadas ao LLM
* **Lat√™ncia de API**: Tempo de resposta de servi√ßos externos
* **Taxa de Sucesso**: Percentual de tarefas conclu√≠das com sucesso

### M√©tricas de Qualidade

* **Acur√°cia da Sa√≠da**: Corre√ß√£o das respostas dos agentes
* **Consist√™ncia**: Confiabilidade em entradas semelhantes
* **Relev√¢ncia**: Qu√£o bem as sa√≠das correspondem aos resultados esperados
* **Seguran√ßa**: Conformidade com pol√≠ticas de conte√∫do e diretrizes

### M√©tricas de Custo

* **Custos de API**: Gastos decorrentes do uso do provedor LLM
* **Utiliza√ß√£o de Recursos**: Consumo de processamento e mem√≥ria
* **Custo por Tarefa**: Efici√™ncia econ√¥mica das opera√ß√µes dos agentes
* **Acompanhamento de Or√ßamento**: Monitoramento em rela√ß√£o a limites de gastos

## Primeiros Passos

1. **Escolha suas Ferramentas**: Selecione plataformas de observabilidade que atendam √†s suas necessidades
2. **Instrumente seu C√≥digo**: Adicione monitoramento √†s suas aplica√ß√µes CrewAI
3. **Configure Dashboards**: Prepare visualiza√ß√µes para as m√©tricas principais
4. **Defina Alertas**: Crie notifica√ß√µes para eventos importantes
5. **Estabele√ßa Bases de Refer√™ncia**: Me√ßa o desempenho inicial para compara√ß√£o futura
6. **Itere e Melhore**: Use os insights para otimizar seus agentes

## Boas Pr√°ticas

### Fase de Desenvolvimento

* Utilize rastreamento detalhado para entender o comportamento dos agentes
* Implemente m√©tricas de avalia√ß√£o desde o in√≠cio do desenvolvimento
* Monitore o uso de recursos durante os testes
* Estabele√ßa verifica√ß√µes automatizadas de qualidade

### Fase de Produ√ß√£o

* Implemente monitoramento e alertas abrangentes
* Acompanhe tend√™ncias de desempenho ao longo do tempo
* Monitore anomalias e degrada√ß√µes
* Mantenha visibilidade e controle dos custos

### Melhoria Cont√≠nua

* Revis√µes regulares de desempenho e otimiza√ß√£o
* Testes A/B de diferentes configura√ß√µes de agentes
* Ciclos de feedback para aprimoramento da qualidade
* Documenta√ß√£o de li√ß√µes aprendidas

Escolha as ferramentas de observabilidade que melhor se encaixam no seu caso de uso, infraestrutura e requisitos de monitoramento para garantir que seus agentes CrewAI operem de forma confi√°vel e eficiente.


# Avalia√ß√£o Patronus AI
Source: https://docs.crewai.com/pt-BR/observability/patronus-evaluation

Monitore e avalie o desempenho de agentes CrewAI utilizando a plataforma abrangente de avalia√ß√£o da Patronus AI para sa√≠das de LLM e comportamentos de agentes.

# Avalia√ß√£o Patronus AI

## Vis√£o Geral

[Patronus AI](https://patronus.ai) oferece capacidades abrangentes de avalia√ß√£o e monitoramento para agentes CrewAI, permitindo avaliar as sa√≠das dos modelos, comportamentos dos agentes e o desempenho geral do sistema. Essa integra√ß√£o possibilita implementar fluxos de avalia√ß√£o cont√≠nuos que ajudam a manter a qualidade e confiabilidade em ambientes de produ√ß√£o.

## Principais Funcionalidades

* **Avalia√ß√£o Automatizada**: Avalia√ß√£o em tempo real das sa√≠das e comportamentos dos agentes
* **Crit√©rios Personalizados**: Defina crit√©rios de avalia√ß√£o espec√≠ficos para seus casos de uso
* **Monitoramento de Desempenho**: Acompanhe m√©tricas de desempenho dos agentes ao longo do tempo
* **Garantia de Qualidade**: Assegure consist√™ncia na qualidade das sa√≠das em diferentes cen√°rios
* **Seguran√ßa & Conformidade**: Monitore poss√≠veis problemas e viola√ß√µes de pol√≠ticas

## Ferramentas de Avalia√ß√£o

A Patronus disponibiliza tr√™s principais ferramentas de avalia√ß√£o para diferentes casos de uso:

1. **PatronusEvalTool**: Permite que os agentes selecionem o avaliador e os crit√©rios mais apropriados para a tarefa de avalia√ß√£o.
2. **PatronusPredefinedCriteriaEvalTool**: Utiliza avaliador e crit√©rios predefinidos, especificados pelo usu√°rio.
3. **PatronusLocalEvaluatorTool**: Utiliza avaliadores customizados definidos pelo usu√°rio.

## Instala√ß√£o

Para utilizar essas ferramentas, √© necess√°rio instalar o pacote Patronus:

```shell
uv add patronus
```

Voc√™ tamb√©m precisar√° configurar sua chave de API da Patronus como uma vari√°vel de ambiente:

```shell
export PATRONUS_API_KEY="your_patronus_api_key"
```

## Passos para Come√ßar

Para utilizar as ferramentas de avalia√ß√£o da Patronus de forma eficaz, siga estes passos:

1. **Instale o Patronus**: Instale o pacote Patronus usando o comando acima.
2. **Configure a Chave de API**: Defina sua chave de API da Patronus como uma vari√°vel de ambiente.
3. **Escolha a Ferramenta Certa**: Selecione a ferramenta de avalia√ß√£o Patronus mais adequada √†s suas necessidades.
4. **Configure a Ferramenta**: Configure a ferramenta com os par√¢metros necess√°rios.

## Exemplos

### Utilizando PatronusEvalTool

O exemplo a seguir demonstra como usar o `PatronusEvalTool`, que permite aos agentes selecionar o avaliador e crit√©rios mais apropriados:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import PatronusEvalTool

# Initialize the tool
patronus_eval_tool = PatronusEvalTool()

# Define an agent that uses the tool
coding_agent = Agent(
    role="Agente de Programa√ß√£o",
    goal="Gerar c√≥digo de alta qualidade e verificar se a sa√≠da √© c√≥digo",
    backstory="Um programador experiente que pode gerar c√≥digo Python de alta qualidade.",
    tools=[patronus_eval_tool],
    verbose=True,
)

# Example task to generate and evaluate code
generate_code_task = Task(
    description="Crie um programa simples para gerar os N primeiros n√∫meros da sequ√™ncia de Fibonacci. Selecione o avaliador e os crit√©rios mais apropriados para avaliar sua sa√≠da.",
    expected_output="Programa que gera os N primeiros n√∫meros da sequ√™ncia de Fibonacci.",
    agent=coding_agent,
)

# Create and run the crew
crew = Crew(agents=[coding_agent], tasks=[generate_code_task])
result = crew.kickoff()
```

### Utilizando PatronusPredefinedCriteriaEvalTool

O exemplo a seguir demonstra como usar o `PatronusPredefinedCriteriaEvalTool`, que utiliza avaliador e crit√©rios predefinidos:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import PatronusPredefinedCriteriaEvalTool

# Initialize the tool with predefined criteria
patronus_eval_tool = PatronusPredefinedCriteriaEvalTool(
    evaluators=[{"evaluator": "judge", "criteria": "contains-code"}]
)

# Define an agent that uses the tool
coding_agent = Agent(
    role="Agente de Programa√ß√£o",
    goal="Gerar c√≥digo de alta qualidade",
    backstory="Um programador experiente que pode gerar c√≥digo Python de alta qualidade.",
    tools=[patronus_eval_tool],
    verbose=True,
)

# Example task to generate code
generate_code_task = Task(
    description="Crie um programa simples para gerar os N primeiros n√∫meros da sequ√™ncia de Fibonacci.",
    expected_output="Programa que gera os N primeiros n√∫meros da sequ√™ncia de Fibonacci.",
    agent=coding_agent,
)

# Create and run the crew
crew = Crew(agents=[coding_agent], tasks=[generate_code_task])
result = crew.kickoff()
```

### Utilizando PatronusLocalEvaluatorTool

O exemplo a seguir demonstra como usar o `PatronusLocalEvaluatorTool`, que utiliza avaliadores customizados via fun√ß√£o:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import PatronusLocalEvaluatorTool
from patronus import Client, EvaluationResult
import random

# Initialize the Patronus client
client = Client()

# Register a custom evaluator
@client.register_local_evaluator("random_evaluator")
def random_evaluator(**kwargs):
    score = random.random()
    return EvaluationResult(
        score_raw=score,
        pass_=score >= 0.5,
        explanation="example explanation",
    )

# Initialize the tool with the custom evaluator
patronus_eval_tool = PatronusLocalEvaluatorTool(
    patronus_client=client,
    evaluator="random_evaluator",
    evaluated_model_gold_answer="example label",
)

# Define an agent that uses the tool
coding_agent = Agent(
    role="Agente de Programa√ß√£o",
    goal="Gerar c√≥digo de alta qualidade",
    backstory="Um programador experiente que pode gerar c√≥digo Python de alta qualidade.",
    tools=[patronus_eval_tool],
    verbose=True,
)

# Example task to generate code
generate_code_task = Task(
    description="Crie um programa simples para gerar os N primeiros n√∫meros da sequ√™ncia de Fibonacci.",
    expected_output="Programa que gera os N primeiros n√∫meros da sequ√™ncia de Fibonacci.",
    agent=coding_agent,
)

# Create and run the crew
crew = Crew(agents=[coding_agent], tasks=[generate_code_task])
result = crew.kickoff()
```

## Par√¢metros

### PatronusEvalTool

O `PatronusEvalTool` n√£o exige par√¢metros durante a inicializa√ß√£o. Ele busca automaticamente os avaliadores e crit√©rios dispon√≠veis a partir da API da Patronus.

### PatronusPredefinedCriteriaEvalTool

O `PatronusPredefinedCriteriaEvalTool` aceita os seguintes par√¢metros durante a inicializa√ß√£o:

* **evaluators**: Obrigat√≥rio. Uma lista de dicion√°rios contendo o avaliador e os crit√©rios a serem utilizados. Por exemplo: `[{"evaluator": "judge", "criteria": "contains-code"}]`.

### PatronusLocalEvaluatorTool

O `PatronusLocalEvaluatorTool` aceita os seguintes par√¢metros durante a inicializa√ß√£o:

* **patronus\_client**: Obrigat√≥rio. Inst√¢ncia do cliente Patronus.
* **evaluator**: Opcional. O nome do avaliador local registrado a ser utilizado. Default √© uma string vazia.
* **evaluated\_model\_gold\_answer**: Opcional. A resposta padr√£o (‚Äúgold answer‚Äù) para uso na avalia√ß√£o. O padr√£o √© uma string vazia.

## Uso

Ao utilizar as ferramentas de avalia√ß√£o Patronus, voc√™ fornece a entrada do modelo, a sa√≠da e o contexto, e a ferramenta retorna os resultados da avalia√ß√£o a partir da API da Patronus.

Para o `PatronusEvalTool` e o `PatronusPredefinedCriteriaEvalTool`, os seguintes par√¢metros s√£o obrigat√≥rios ao chamar a ferramenta:

* **evaluated\_model\_input**: A descri√ß√£o da tarefa do agente, em texto simples.
* **evaluated\_model\_output**: A sa√≠da da tarefa pelo agente.
* **evaluated\_model\_retrieved\_context**: O contexto do agente.

Para o `PatronusLocalEvaluatorTool`, os mesmos par√¢metros s√£o necess√°rios, mas o avaliador e a resposta padr√£o s√£o especificados durante a inicializa√ß√£o.

## Conclus√£o

As ferramentas de avalia√ß√£o da Patronus fornecem uma forma poderosa de avaliar e pontuar entradas e sa√≠das de modelos utilizando a plataforma Patronus AI. Ao possibilitar que agentes avaliem suas pr√≥prias sa√≠das ou as de outros agentes, essas ferramentas ajudam a aprimorar a qualidade e confiabilidade dos fluxos de trabalho do CrewAI.


# Integra√ß√£o com Portkey
Source: https://docs.crewai.com/pt-BR/observability/portkey

Como usar Portkey com CrewAI

<img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/main/Portkey-CrewAI.png" alt="Portkey CrewAI Header Image" width="70%" />

## Introdu√ß√£o

Portkey aprimora o CrewAI com recursos prontos para produ√ß√£o, transformando seus crews de agentes experimentais em sistemas robustos ao fornecer:

* **Observabilidade completa** de cada etapa do agente, uso de ferramentas e intera√ß√µes
* **Confiabilidade incorporada** com fallbacks, tentativas autom√°ticas e balanceamento de carga
* **Rastreamento e otimiza√ß√£o de custos** para gerenciar seus gastos com IA
* **Acesso a mais de 200 LLMs** por meio de uma √∫nica integra√ß√£o
* **Guardrails** para manter o comportamento dos agentes seguro e em conformidade
* **Prompts versionados** para desempenho consistente dos agentes

### Instala√ß√£o & Configura√ß√£o

<Steps>
  <Step title="Instale os pacotes necess√°rios">
    ```bash
    pip install -U crewai portkey-ai
    ```
  </Step>

  <Step title="Gere a Chave de API" icon="lock">
    Crie uma chave de API Portkey com limites de or√ßamento/taxa opcionais no [painel da Portkey](https://app.portkey.ai/). Voc√™ tamb√©m pode adicionar configura√ß√µes para confiabilidade, cache e outros recursos a essa chave. Mais sobre isso em breve.
  </Step>

  <Step title="Configure o CrewAI com Portkey">
    A integra√ß√£o √© simples ‚Äì basta atualizar a configura√ß√£o do LLM no seu setup do CrewAI:

    ```python
    from crewai import LLM
    from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

    # Crie uma inst√¢ncia do LLM com integra√ß√£o Portkey
    gpt_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",  # Estamos usando uma chave virtual, ent√£o isso √© apenas um placeholder
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_LLM_VIRTUAL_KEY",
            trace_id="unique-trace-id",               # Opcional, para rastreamento da requisi√ß√£o
        )
    )

    #Use-os nos seus Crew Agents assim:

    	@agent
    	def lead_market_analyst(self) -> Agent:
    		return Agent(
    			config=self.agents_config['lead_market_analyst'],
    			verbose=True,
    			memory=False,
    			llm=gpt_llm
    		)

    ```

    <Info>
      **O que s√£o Virtual Keys?** Virtual keys no Portkey armazenam com seguran√ßa suas chaves de API dos provedores LLM (OpenAI, Anthropic, etc.) em um cofre criptografado. Elas facilitam a rota√ß√£o de chaves e o gerenciamento de or√ßamento. [Saiba mais sobre virtual keys aqui](https://portkey.ai/docs/product/ai-gateway/virtual-keys).
    </Info>
  </Step>
</Steps>

## Recursos para Produ√ß√£o

### 1. Observabilidade Avan√ßada

Portkey oferece observabilidade abrangente para seus agentes CrewAI, ajudando voc√™ a entender exatamente o que est√° acontecendo durante cada execu√ß√£o.

<Tabs>
  <Tab title="Traces">
    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20Product%2011.1.webp" />
    </Frame>

    Os traces fornecem uma vis√£o hier√°rquica da execu√ß√£o do seu crew, mostrando a sequ√™ncia de chamadas LLM, ativa√ß√µes de ferramentas e transi√ß√µes de estado.

    ```python
    # Adicione trace_id para habilitar o tracing hier√°rquico no Portkey
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
            trace_id="unique-session-id"  # Adicione um trace ID √∫nico
        )
    )
    ```
  </Tab>

  <Tab title="Logs">
    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20Portkey%20Docs%20Metadata.png" />
    </Frame>

    Portkey registra cada intera√ß√£o com LLMs, incluindo:

    * Payloads completos das requisi√ß√µes e respostas
    * M√©tricas de lat√™ncia e uso de tokens
    * C√°lculos de custo
    * Chamadas de ferramentas e execu√ß√µes de fun√ß√µes

    Todos os logs podem ser filtrados por metadados, trace IDs, modelos e mais, tornando mais f√°cil depurar execu√ß√µes espec√≠ficas do crew.
  </Tab>

  <Tab title="M√©tricas & Dashboards">
    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20Dashboard.png" />
    </Frame>

    Portkey oferece dashboards integrados que ajudam voc√™ a:

    * Rastrear custos e uso de tokens em todas as execu√ß√µes do crew
    * Analisar m√©tricas de desempenho, como lat√™ncia e taxas de sucesso
    * Identificar gargalos nos fluxos de trabalho dos agentes
    * Comparar diferentes configura√ß√µes de crew e LLMs

    Voc√™ pode filtrar e segmentar todas as m√©tricas por metadados personalizados para analisar tipos de crew, grupos de usu√°rios ou casos de uso espec√≠ficos.
  </Tab>

  <Tab title="Filtragem por Metadados">
    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/Metadata%20Filters%20from%20CrewAI.png" alt="Analytics with metadata filters" />
    </Frame>

    Adicione metadados personalizados √† configura√ß√£o LLM do seu CrewAI para permitir filtragem e segmenta√ß√£o poderosas:

    ```python
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
            metadata={
                "crew_type": "research_crew",
                "environment": "production",
                "_user": "user_123",   # Campo especial _user para analytics de usu√°rios
                "request_source": "mobile_app"
            }
        )
    )
    ```

    Esses metadados podem ser usados para filtrar logs, traces e m√©tricas no painel do Portkey, permitindo analisar execu√ß√µes espec√≠ficas do crew, usu√°rios ou ambientes.
  </Tab>
</Tabs>

### 2. Confiabilidade - Mantenha Seus Crews Funcionando Sem Interrup√ß√µes

Ao executar crews em produ√ß√£o, problemas podem ocorrer ‚Äì limites de taxa da API, problemas de rede ou indisponibilidade do provedor. Os recursos de confiabilidade do Portkey garantem que seus agentes continuem funcionando mesmo quando problemas surgem.

√â simples habilitar fallback na sua configura√ß√£o CrewAI usando um Config do Portkey:

```python
from crewai import LLM
from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

# Crie LLM com configura√ß√£o de fallback
portkey_llm = LLM(
    model="gpt-4o",
    max_tokens=1000,
    base_url=PORTKEY_GATEWAY_URL,
    api_key="dummy",
    extra_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        config={
            "strategy": {
                "mode": "fallback"
            },
            "targets": [
                {
                    "provider": "openai",
                    "api_key": "YOUR_OPENAI_API_KEY",
                    "override_params": {"model": "gpt-4o"}
                },
                {
                    "provider": "anthropic",
                    "api_key": "YOUR_ANTHROPIC_API_KEY",
                    "override_params": {"model": "claude-3-opus-20240229"}
                }
            ]
        }
    )
)

# Use essa configura√ß√£o LLM com seus agentes
```

Essa configura√ß√£o automaticamente tentar√° o Claude caso a requisi√ß√£o para o GPT-4o falhe, garantindo que seu crew continue funcionando.

<CardGroup cols="2">
  <Card title="Tentativas Autom√°ticas" icon="rotate" href="https://portkey.ai/docs/product/ai-gateway/automatic-retries">
    Lida automaticamente com falhas tempor√°rias. Se uma chamada LLM falhar, o Portkey far√° novas tentativas o n√∫mero especificado de vezes ‚Äì perfeito para limites de taxa ou instabilidades de rede.
  </Card>

  <Card title="Timeouts de Requisi√ß√£o" icon="clock" href="https://portkey.ai/docs/product/ai-gateway/request-timeouts">
    Evite que seus agentes fiquem travados. Defina timeouts para garantir respostas (ou falhas controladas) dentro do tempo necess√°rio.
  </Card>

  <Card title="Roteamento Condicional" icon="route" href="https://portkey.ai/docs/product/ai-gateway/conditional-routing">
    Envie diferentes solicita√ß√µes para diferentes provedores. Direcione racioc√≠nios complexos para o GPT-4, tarefas criativas para Claude e respostas r√°pidas para Gemini conforme sua necessidade.
  </Card>

  <Card title="Fallbacks" icon="shield" href="https://portkey.ai/docs/product/ai-gateway/fallbacks">
    Mantenha-se em funcionamento mesmo se seu provedor principal falhar. Troque automaticamente para provedores de backup para manter a disponibilidade.
  </Card>

  <Card title="Balanceamento de Carga" icon="scale-balanced" href="https://portkey.ai/docs/product/ai-gateway/load-balancing">
    Distribua solicita√ß√µes entre v√°rias chaves de API ou provedores. √ìtimo para opera√ß√µes de crew em grande escala e para permanecer dentro dos limites de taxa.
  </Card>
</CardGroup>

### 3. Prompting no CrewAI

O Prompt Engineering Studio do Portkey ajuda voc√™ a criar, gerenciar e otimizar os prompts usados em seus agentes CrewAI. Em vez de codificar prompts ou instru√ß√µes manualmente, use a API de renderiza√ß√£o de prompts do Portkey para buscar e aplicar din√¢micamente seus prompts versionados.

<Frame caption="Gerencie prompts na Prompt Library do Portkey">
  ![Prompt Playground Interface](https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20Portkey%20Docs.webp)
</Frame>

<Tabs>
  <Tab title="Prompt Playground">
    Prompt Playground √© um local para comparar, testar e implantar prompts perfeitos para sua aplica√ß√£o de IA. √â onde voc√™ experimenta com diferentes modelos, testa vari√°veis, compara sa√≠das e refina sua estrat√©gia de engenharia de prompts antes de implantar em produ√ß√£o. Ele permite:

    1. Desenvolver prompts de forma iterativa antes de us√°-los em seus agentes
    2. Testar prompts com diferentes vari√°veis e modelos
    3. Comparar sa√≠das entre diferentes vers√µes de prompts
    4. Colaborar com membros da equipe no desenvolvimento de prompts

    Esse ambiente visual facilita a cria√ß√£o de prompts eficazes para cada etapa do fluxo de trabalho dos seus agentes CrewAI.
  </Tab>

  <Tab title="Usando Templates de Prompt">
    A API Prompt Render recupera seus templates de prompt com todos os par√¢metros configurados:

    ```python
    from crewai import Agent, LLM
    from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL, Portkey

    # Inicialize o cliente admin do Portkey
    portkey_admin = Portkey(api_key="YOUR_PORTKEY_API_KEY")

    # Recupere o prompt usando a render API
    prompt_data = portkey_client.prompts.render(
        prompt_id="YOUR_PROMPT_ID",
        variables={
            "agent_role": "Senior Research Scientist",
        }
    )

    backstory_agent_prompt=prompt_data.data.messages[0]["content"]


    # Configure o LLM com integra√ß√£o Portkey
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_OPENAI_VIRTUAL_KEY"
        )
    )

    # Crie o agente utilizando o prompt renderizado
    researcher = Agent(
        role="Senior Research Scientist",
        goal="Discover groundbreaking insights about the assigned topic",
        backstory=backstory_agent,  # Use o prompt renderizado
        verbose=True,
        llm=portkey_llm
    )
    ```
  </Tab>

  <Tab title="Versionamento de Prompts">
    Voc√™ pode:

    * Criar m√∫ltiplas vers√µes do mesmo prompt
    * Comparar o desempenho entre vers√µes
    * Voltar a vers√µes anteriores se necess√°rio
    * Especificar qual vers√£o usar em seu c√≥digo:

    ```python
    # Use uma vers√£o espec√≠fica do prompt
    prompt_data = portkey_admin.prompts.render(
        prompt_id="YOUR_PROMPT_ID@version_number",
        variables={
            "agent_role": "Senior Research Scientist",
            "agent_goal": "Discover groundbreaking insights"
        }
    )
    ```
  </Tab>

  <Tab title="Mustache Templating para vari√°veis">
    Os prompts do Portkey usam modelos estilo Mustache para f√°cil substitui√ß√£o de vari√°veis:

    ```
    You are a {{agent_role}} with expertise in {{domain}}.

    Your mission is to {{agent_goal}} by leveraging your knowledge
    and experience in the field.

    Always maintain a {{tone}} tone and focus on providing {{focus_area}}.
    ```

    Ao renderizar, basta passar as vari√°veis:

    ```python
    prompt_data = portkey_admin.prompts.render(
        prompt_id="YOUR_PROMPT_ID",
        variables={
            "agent_role": "Senior Research Scientist",
            "domain": "artificial intelligence",
            "agent_goal": "discover groundbreaking insights",
            "tone": "professional",
            "focus_area": "practical applications"
        }
    )
    ```
  </Tab>
</Tabs>

<Card title="Prompt Engineering Studio" icon="wand-magic-sparkles" href="https://portkey.ai/docs/product/prompt-library">
  Saiba mais sobre os recursos de gerenciamento de prompts do Portkey
</Card>

### 4. Guardrails para Crews Seguros

Guardrails garantem que seus agentes CrewAI operem com seguran√ßa e respondam adequadamente em todas as situa√ß√µes.

**Por que usar Guardrails?**

Os agentes CrewAI podem apresentar falhas de diversos tipos:

* Gerar conte√∫do nocivo ou inapropriado
* Vazamento de informa√ß√µes sens√≠veis como PII
* Alucinar informa√ß√µes incorretas
* Gerar sa√≠das em formatos incorretos

Os guardrails do Portkey fornecem prote√ß√µes tanto para entradas quanto para sa√≠das.

**Implementando Guardrails**

```python
from crewai import Agent, LLM
from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

# Crie LLM com guardrails
portkey_llm = LLM(
    model="gpt-4o",
    base_url=PORTKEY_GATEWAY_URL,
    api_key="dummy",
    extra_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
        config={
            "input_guardrails": ["guardrails-id-xxx", "guardrails-id-yyy"],
            "output_guardrails": ["guardrails-id-zzz"]
        }
    )
)

# Crie agente com LLM guardrailed
researcher = Agent(
    role="Senior Research Scientist",
    goal="Discover groundbreaking insights about the assigned topic",
    backstory="You are an expert researcher with deep domain knowledge.",
    verbose=True,
    llm=portkey_llm
)
```

Os guardrails do Portkey podem:

* Detectar e redigir PII tanto em entradas quanto em sa√≠das
* Filtrar conte√∫do prejudicial ou inapropriado
* Validar formatos de resposta contra schemas
* Verificar alucina√ß√µes comparando com ground truth
* Aplicar l√≥gica e regras de neg√≥cio personalizadas

<Card title="Saiba Mais Sobre Guardrails" icon="shield-check" href="https://portkey.ai/docs/product/guardrails">
  Explore os recursos de guardrails do Portkey para aumentar a seguran√ßa dos agentes
</Card>

### 5. Rastreamento de Usu√°rio com Metadados

Rastreie usu√°rios individuais atrav√©s dos seus agentes CrewAI utilizando o sistema de metadados do Portkey.

**O que √© Metadata no Portkey?**

Metadados permitem associar dados personalizados a cada requisi√ß√£o, possibilitando filtragem, segmenta√ß√£o e analytics. O campo especial `_user` √© projetado especificamente para rastreamento de usu√°rio.

```python
from crewai import Agent, LLM
from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

# Configure o LLM com rastreamento de usu√°rio
portkey_llm = LLM(
    model="gpt-4o",
    base_url=PORTKEY_GATEWAY_URL,
    api_key="dummy",
    extra_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
        metadata={
            "_user": "user_123",  # Campo especial _user para analytics de usu√°rios
            "user_tier": "premium",
            "user_company": "Acme Corp",
            "session_id": "abc-123"
        }
    )
)

# Crie agente com LLM rastreado
researcher = Agent(
    role="Senior Research Scientist",
    goal="Discover groundbreaking insights about the assigned topic",
    backstory="You are an expert researcher with deep domain knowledge.",
    verbose=True,
    llm=portkey_llm
)
```

**Filtre Analytics por Usu√°rio**

Com os metadados configurados, voc√™ pode filtrar analytics por usu√°rio e analisar m√©tricas de desempenho individualmente:

<Frame caption="Filtre analytics por usu√°rio">
  <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/Metadata%20Filters%20from%20CrewAI.png" />
</Frame>

Isso permite:

* Rastreamento de custos e or√ßamento por usu√°rio
* Analytics personalizados por usu√°rio
* M√©tricas por equipe ou organiza√ß√£o
* Monitoramento espec√≠fico por ambiente (homologa√ß√£o x produ√ß√£o)

<Card title="Saiba Mais Sobre Metadata" icon="tags" href="https://portkey.ai/docs/product/observability/metadata">
  Veja como usar metadados personalizados para aprimorar seus analytics
</Card>

### 6. Cache para Crews Eficientes

Implemente caching para tornar seus agentes CrewAI mais eficientes e econ√¥micos:

<Tabs>
  <Tab title="Caching Simples">
    ```python
    from crewai import Agent, LLM
    from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

    # Configure o LLM com caching simples
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
            config={
                "cache": {
                    "mode": "simple"
                }
            }
        )
    )

    # Crie agente com LLM cacheado
    researcher = Agent(
        role="Senior Research Scientist",
        goal="Discover groundbreaking insights about the assigned topic",
        backstory="You are an expert researcher with deep domain knowledge.",
        verbose=True,
        llm=portkey_llm
    )
    ```

    O caching simples realiza correspond√™ncias exatas de prompts de entrada, cacheando requisi√ß√µes id√™nticas para evitar execu√ß√µes redundantes do modelo.
  </Tab>

  <Tab title="Cache Sem√¢ntico">
    ```python
    from crewai import Agent, LLM
    from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

    # Configure o LLM com cache sem√¢ntico
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="dummy",
        extra_headers=createHeaders(
            api_key="YOUR_PORTKEY_API_KEY",
            virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
            config={
                "cache": {
                    "mode": "semantic"
                }
            }
        )
    )

    # Crie agente com LLM com cache sem√¢ntico
    researcher = Agent(
        role="Senior Research Scientist",
        goal="Discover groundbreaking insights about the assigned topic",
        backstory="You are an expert researcher with deep domain knowledge.",
        verbose=True,
        llm=portkey_llm
    )
    ```

    O cache sem√¢ntico considera a similaridade contextual entre solicita√ß√µes de entrada, armazenando respostas para entradas semanticamente similares.
  </Tab>
</Tabs>

### 7. Interoperabilidade de Modelos

O CrewAI oferece suporte a m√∫ltiplos provedores de LLM, e o Portkey amplia essa capacidade fornecendo acesso a mais de 200 LLMs por meio de uma interface unificada. Voc√™ pode facilmente alternar entre diferentes modelos sem alterar a l√≥gica central do seu agente:

```python
from crewai import Agent, LLM
from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

# Configure LLMs com diferentes provedores
openai_llm = LLM(
    model="gpt-4o",
    base_url=PORTKEY_GATEWAY_URL,
    api_key="dummy",
    extra_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        virtual_key="YOUR_OPENAI_VIRTUAL_KEY"
    )
)

anthropic_llm = LLM(
    model="claude-3-5-sonnet-latest",
    max_tokens=1000,
    base_url=PORTKEY_GATEWAY_URL,
    api_key="dummy",
    extra_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        virtual_key="YOUR_ANTHROPIC_VIRTUAL_KEY"
    )
)

# Escolha qual LLM usar para cada agente conforme necess√°rio
researcher = Agent(
    role="Senior Research Scientist",
    goal="Discover groundbreaking insights about the assigned topic",
    backstory="You are an expert researcher with deep domain knowledge.",
    verbose=True,
    llm=openai_llm  # Use anthropic_llm para Anthropic
)
```

Portkey oferece acesso a LLMs de provedores como:

* OpenAI (GPT-4o, GPT-4 Turbo, etc.)
* Anthropic (Claude 3.5 Sonnet, Claude 3 Opus, etc.)
* Mistral AI (Mistral Large, Mistral Medium, etc.)
* Google Vertex AI (Gemini 1.5 Pro, etc.)
* Cohere (Command, Command-R, etc.)
* AWS Bedrock (Claude, Titan, etc.)
* Modelos locais/privados

<Card title="Provedores Suportados" icon="server" href="https://portkey.ai/docs/integrations/llms">
  Veja a lista completa de provedores LLM suportados pelo Portkey
</Card>

## Configure Governan√ßa Corporativa para o CrewAI

**Por que Governan√ßa Corporativa?**
Se voc√™ utiliza CrewAI dentro de sua organiza√ß√£o, √© importante considerar diversos aspectos de governan√ßa:

* **Gest√£o de Custos**: Controlar e rastrear os gastos com IA entre equipes
* **Controle de Acesso**: Gerenciar quais equipes podem usar modelos espec√≠ficos
* **Analytics de Uso**: Compreender como a IA est√° sendo utilizada na organiza√ß√£o
* **Seguran√ßa & Compliance**: Manuten√ß√£o de padr√µes corporativos de seguran√ßa
* **Confiabilidade**: Garantir servi√ßo consistente para todos os usu√°rios

O Portkey adiciona uma camada abrangente de governan√ßa para atender a essas necessidades corporativas. Vamos implementar esses controles passo a passo.

<Steps>
  <Step title="Crie uma Virtual Key">
    Virtual Keys s√£o a maneira segura do Portkey para gerenciar as chaves de API dos provedores de LLM. Elas fornecem controles essenciais como:

    * Limites de or√ßamento para uso da API
    * Capacidade de rate limiting
    * Armazenamento seguro das chaves de API

    Para criar uma virtual key:
    V√° at√© [Virtual Keys](https://app.portkey.ai/virtual-keys) no app Portkey. Salve e copie o ID da virtual key

    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/Virtual%20Key%20from%20Portkey%20Docs.png" width="500" />
    </Frame>

    <Note>
      Salve o ID da sua virtual key ‚Äì voc√™ precisar√° dele no pr√≥ximo passo.
    </Note>
  </Step>

  <Step title="Crie um Config Padr√£o">
    Os Configs no Portkey definem como suas requisi√ß√µes s√£o roteadas, com recursos como roteamento avan√ßado, fallbacks e tentativas autom√°ticas.

    Para criar seu config:

    1. V√° at√© [Configs](https://app.portkey.ai/configs) no painel Portkey
    2. Crie um novo config com:
       ```json
       {
           "virtual_key": "YOUR_VIRTUAL_KEY_FROM_STEP1",
          	"override_params": {
             "model": "gpt-4o" // Nome do seu modelo preferido
           }
       }
       ```
    3. Salve e anote o nome do Config para o pr√≥ximo passo

    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20Portkey%20Docs%20Config.png" width="500" />
    </Frame>
  </Step>

  <Step title="Configure a Chave de API Portkey">
    Agora crie uma chave de API Portkey e anexe a config criada no Passo 2:

    1. V√° at√© [API Keys](https://app.portkey.ai/api-keys) na Portkey e crie uma nova chave de API
    2. Selecione sua config do `Passo 2`
    3. Gere e salve sua chave de API

    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/CrewAI%20API%20Key.png" width="500" />
    </Frame>
  </Step>

  <Step title="Conecte ao CrewAI">
    Ap√≥s configurar sua chave de API Portkey com a config anexada, conecte-a aos seus agentes CrewAI:

    ```python
    from crewai import Agent, LLM
    from portkey_ai import PORTKEY_GATEWAY_URL

    # Configure o LLM com sua chave de API
    portkey_llm = LLM(
        model="gpt-4o",
        base_url=PORTKEY_GATEWAY_URL,
        api_key="YOUR_PORTKEY_API_KEY"
    )

    # Crie agente com LLM habilitado para Portkey
    researcher = Agent(
        role="Senior Research Scientist",
        goal="Discover groundbreaking insights about the assigned topic",
        backstory="You are an expert researcher with deep domain knowledge.",
        verbose=True,
        llm=portkey_llm
    )
    ```
  </Step>
</Steps>

<AccordionGroup>
  <Accordion title="Etapa 1: Implementar Controles de Or√ßamento & Rate Limits">
    ### Etapa 1: Implementar Controles de Or√ßamento & Rate Limits

    Virtual Keys permitem controle granular sobre o acesso ao LLM por equipe/departamento. Isso ajuda voc√™ a:

    * Definir [limites de or√ßamento](https://portkey.ai/docs/product/ai-gateway/virtual-keys/budget-limits)
    * Prevenir picos inesperados de uso atrav√©s de Rate limits
    * Rastrear gastos por departamento

    #### Configurando controles espec√≠ficos de departamento:

    1. V√° at√© [Virtual Keys](https://app.portkey.ai/virtual-keys) no painel Portkey
    2. Crie uma nova Virtual Key para cada departamento com limites de or√ßamento e rate limits
    3. Configure limites espec√≠ficos por departamento

    <Frame>
      <img src="https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/refs/heads/main/Virtual%20Key%20from%20Portkey%20Docs.png" width="500" />
    </Frame>
  </Accordion>

  <Accordion title="Etapa 2: Definir Regras de Acesso a Modelos">
    ### Etapa 2: Definir Regras de Acesso a Modelos

    √Ä medida que o uso de IA cresce, controlar quais equipes t√™m acesso a quais modelos se torna fundamental. Os Configs do Portkey fornecem essa camada de controle com recursos como:

    #### Recursos de Controle de Acesso:

    * **Restri√ß√µes de Modelo**: Limite o acesso a modelos espec√≠ficos
    * **Prote√ß√£o de Dados**: Implemente guardrails para dados sens√≠veis
    * **Controles de Confiabilidade**: Adicione fallbacks e tentativas autom√°ticas

    #### Exemplo de Configura√ß√£o:

    Aqui est√° um exemplo b√°sico para rotear requisi√ß√µes ao OpenAI, usando especificamente o GPT-4o:

    ```json
    {
    	"strategy": {
    		"mode": "single"
    	},
    	"targets": [
    		{
    			"virtual_key": "YOUR_OPENAI_VIRTUAL_KEY",
    			"override_params": {
    				"model": "gpt-4o"
    			}
    		}
    	]
    }
    ```

    Crie seu config na [p√°gina de Configs](https://app.portkey.ai/configs) no painel do Portkey.

    <Note>
      Os configs podem ser atualizados a qualquer momento para ajustar controles sem afetar aplica√ß√µes em execu√ß√£o.
    </Note>
  </Accordion>

  <Accordion title="Etapa 3: Implementar Controles de Acesso">
    ### Etapa 3: Implementar Controles de Acesso

    Crie chaves de API espec√≠ficas por usu√°rio que automaticamente:

    * Rastreiam uso por usu√°rio/equipe com o aux√≠lio das virtual keys
    * Aplicam configs adequadas para rotear requisi√ß√µes
    * Coletam metadados relevantes para filtragem de logs
    * Imp√µem permiss√µes de acesso

    Crie chaves de API atrav√©s de:

    * [Portkey App](https://app.portkey.ai/)
    * [API Key Management API](/pt-BR/api-reference/admin-api/control-plane/api-keys/create-api-key)

    Exemplo usando Python SDK:

    ```python
    from portkey_ai import Portkey

    portkey = Portkey(api_key="YOUR_ADMIN_API_KEY")

    api_key = portkey.api_keys.create(
        name="engineering-team",
        type="organisation",
        workspace_id="YOUR_WORKSPACE_ID",
        defaults={
            "config_id": "your-config-id",
            "metadata": {
                "environment": "production",
                "department": "engineering"
            }
        },
        scopes=["logs.view", "configs.read"]
    )
    ```

    Para instru√ß√µes detalhadas de gerenciamento de chaves, veja nossa [documenta√ß√£o de API Keys](/pt-BR/api-reference/admin-api/control-plane/api-keys/create-api-key).
  </Accordion>

  <Accordion title="Etapa 4: Implante & Monitore">
    ### Etapa 4: Implante & Monitore

    Ap√≥s distribuir as chaves de API para os membros da equipe, seu setup corporativo CrewAI est√° pronto. Cada membro pode agora usar suas chaves designadas com os n√≠veis de acesso e controles de or√ßamento apropriados.

    Monitore o uso no painel Portkey:

    * Rastreamento de custos por departamento
    * Padr√µes de uso de modelos
    * Volume de requisi√ß√µes
    * Taxa de erros
  </Accordion>
</AccordionGroup>

<Note>
  ### Recursos Corporativos Agora Dispon√≠veis

  **Sua integra√ß√£o CrewAI agora conta com:**

  * Controles de or√ßamento departamental
  * Governan√ßa de acesso a modelos
  * Rastreamento de uso & atribui√ß√£o
  * Guardrails de seguran√ßa
  * Recursos de confiabilidade
</Note>

## Perguntas Frequentes

<AccordionGroup>
  <Accordion title="Como o Portkey aprimora o CrewAI?">
    Portkey adiciona prontid√£o para produ√ß√£o ao CrewAI atrav√©s de observabilidade abrangente (traces, logs, m√©tricas), recursos de confiabilidade (fallbacks, tentativas autom√°ticas, cache) e acesso a mais de 200 LLMs por meio de uma interface unificada. Isso facilita depurar, otimizar e escalar suas aplica√ß√µes de agentes.
  </Accordion>

  <Accordion title="Posso usar Portkey com aplica√ß√µes CrewAI existentes?">
    Sim! Portkey integra-se perfeitamente a aplica√ß√µes CrewAI existentes. Basta atualizar o c√≥digo de configura√ß√£o do LLM com a vers√£o habilitada do Portkey. O restante do seu c√≥digo de agente e crew permanece inalterado.
  </Accordion>

  <Accordion title="Portkey funciona com todos os recursos do CrewAI?">
    Portkey suporta todos os recursos do CrewAI, incluindo agentes, ferramentas, workflows human-in-the-loop e todos os tipos de processo de tarefas (sequencial, hier√°rquico, etc.). Ele adiciona observabilidade e confiabilidade sem limitar nenhuma funcionalidade do framework.
  </Accordion>

  <Accordion title="Posso rastrear o uso em m√∫ltiplos agentes de um crew?">
    Sim, o Portkey permite que voc√™ use um `trace_id` consistente em m√∫ltiplos agentes de um crew para rastrear todo o fluxo de trabalho. Isso √© especialmente √∫til para crews complexos onde voc√™ deseja entender o caminho completo de execu√ß√£o entre os agentes.
  </Accordion>

  <Accordion title="Como filtro logs e traces para execu√ß√µes espec√≠ficas de crew?">
    O Portkey permite adicionar metadados personalizados √† configura√ß√£o do seu LLM, que podem ser usados para filtragem. Adicione campos como `crew_name`, `crew_type`, ou `session_id` para encontrar e analisar facilmente execu√ß√µes espec√≠ficas do crew.
  </Accordion>

  <Accordion title="Posso usar minhas pr√≥prias chaves de API com o Portkey?">
    Sim! O Portkey utiliza suas pr√≥prias chaves de API dos provedores LLM. Elas s√£o armazenadas com seguran√ßa como virtual keys, permitindo que voc√™ gerencie e gire as chaves facilmente sem alterar seu c√≥digo.
  </Accordion>
</AccordionGroup>

## Recursos

<CardGroup cols="3">
  <Card title="CrewAI Docs" icon="book" href="https://docs.crewai.com/">
    <p>Documenta√ß√£o oficial do CrewAI</p>
  </Card>

  <Card title="Agende uma Demonstra√ß√£o" icon="calendar" href="https://calendly.com/portkey-ai">
    <p>Receba orienta√ß√£o personalizada sobre como implementar essa integra√ß√£o</p>
  </Card>
</CardGroup>


# Integra√ß√£o com Weave
Source: https://docs.crewai.com/pt-BR/observability/weave

Saiba como usar o Weights & Biases (W&B) Weave para rastrear, experimentar, avaliar e melhorar suas aplica√ß√µes CrewAI.

# Vis√£o Geral do Weave

[Weights & Biases (W\&B) Weave](https://weave-docs.wandb.ai/) √© um framework para rastreamento, experimenta√ß√£o, avalia√ß√£o, implementa√ß√£o e aprimoramento de aplica√ß√µes baseadas em LLM.

![Vis√£o geral do uso do tracing do W\&B Weave com CrewAI](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/weave-tracing.gif)

O Weave oferece suporte completo para todas as etapas do desenvolvimento da sua aplica√ß√£o CrewAI:

* **Rastreamento e Monitoramento**: Acompanhe automaticamente chamadas LLM e a l√≥gica da aplica√ß√£o para depura√ß√£o e an√°lise de sistemas em produ√ß√£o
* **Itera√ß√£o Sistem√°tica**: Aperfei√ßoe e itere em prompts, conjuntos de dados e modelos
* **Avalia√ß√£o**: Utilize avaliadores personalizados ou pr√©-constru√≠dos para avaliar e aprimorar sistematicamente o desempenho dos agentes
* **Guardrails**: Proteja seus agentes com salvaguardas pr√© e p√≥s-execu√ß√£o para modera√ß√£o de conte√∫do e seguran√ßa de prompts

O Weave captura automaticamente rastreamentos (traces) de suas aplica√ß√µes CrewAI, permitindo monitorar e analisar o desempenho, as intera√ß√µes e o fluxo de execu√ß√£o dos seus agentes. Isso te ajuda a construir melhores conjuntos de dados para avalia√ß√£o e a otimizar os fluxos de trabalho dos agentes.

## Instru√ß√µes de Configura√ß√£o

<Steps>
  <Step title="Instale os pacotes necess√°rios">
    ```shell
    pip install crewai weave
    ```
  </Step>

  <Step title="Crie uma conta no W&B">
    Cadastre-se em uma [conta Weights & Biases](https://wandb.ai) caso ainda n√£o tenha uma. Voc√™ precisar√° dela para visualizar rastreamentos e m√©tricas.
  </Step>

  <Step title="Inicialize o Weave na sua aplica√ß√£o">
    Adicione o seguinte c√≥digo √† sua aplica√ß√£o:

    ```python
    import weave

    # Inicialize o Weave com o nome do seu projeto
    weave.init(project_name="crewai_demo")
    ```

    Ap√≥s a inicializa√ß√£o, o Weave fornecer√° uma URL onde voc√™ poder√° visualizar seus rastreamentos e m√©tricas.
  </Step>

  <Step title="Crie seus Crews/Flows">
    ```python
    from crewai import Agent, Task, Crew, LLM, Process

    # Crie um LLM com temperatura 0 para garantir sa√≠das determin√≠sticas
    llm = LLM(model="gpt-4o", temperature=0)

    # Crie os agentes
    pesquisador = Agent(
        role='Analista de Pesquisa',
        goal='Encontrar e analisar as melhores oportunidades de investimento',
        backstory='Especialista em an√°lise financeira e pesquisa de mercado',
        llm=llm,
        verbose=True,
        allow_delegation=False,
    )

    redator = Agent(
        role='Redator de Relat√≥rios',
        goal='Escrever relat√≥rios de investimento claros e concisos',
        backstory='Experiente na cria√ß√£o de relat√≥rios financeiros detalhados',
        llm=llm,
        verbose=True,
        allow_delegation=False,
    )

    # Crie as tarefas
    pesquisa = Task(
        description='Pesquisa aprofundada sobre o {tema}',
        expected_output='Dados de mercado abrangentes incluindo principais players, tamanho de mercado e tend√™ncias de crescimento.',
        agent=pesquisador
    )

    redacao = Task(
        description='Escreva um relat√≥rio detalhado com base na pesquisa',
        expected_output='O relat√≥rio deve ser f√°cil de ler e entender. Use t√≥picos quando aplic√°vel.',
        agent=redator
    )

    # Crie o crew
    equipe = Crew(
        agents=[pesquisador, redator],
        tasks=[pesquisa, redacao],
        verbose=True,
        process=Process.sequential,
    )

    # Execute o crew
    resultado = equipe.kickoff(inputs={"tema": "IA em ci√™ncia dos materiais"})
    print(resultado)
    ```
  </Step>

  <Step title="Visualize rastreamentos no Weave">
    Ap√≥s executar sua aplica√ß√£o CrewAI, acesse a URL do Weave fornecida durante a inicializa√ß√£o para visualizar:

    * Chamadas LLM e seus metadados
    * Intera√ß√µes dos agentes e fluxo de execu√ß√£o das tarefas
    * M√©tricas de desempenho como lat√™ncia e uso de tokens
    * Quaisquer erros ou problemas ocorridos durante a execu√ß√£o

    <Frame caption="Painel de Rastreamento do Weave">
      <img src="https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/weave-tracing.png" alt="Exemplo de rastreamento do Weave com CrewAI" />
    </Frame>
  </Step>
</Steps>

## Funcionalidades

* O Weave captura automaticamente todas as opera√ß√µes do CrewAI: intera√ß√µes dos agentes e execu√ß√µes das tarefas; chamadas LLM com metadados e uso de tokens; uso de ferramentas e resultados.
* A integra√ß√£o suporta todos os m√©todos de execu√ß√£o do CrewAI: `kickoff()`, `kickoff_for_each()`, `kickoff_async()` e `kickoff_for_each_async()`.
* Rastreamento autom√°tico de todas as [crewAI-tools](https://github.com/crewAIInc/crewAI-tools).
* Suporte ao recurso flow com patching por decorador (`@start`, `@listen`, `@router`, `@or_`, `@and_`).
* Rastreie guardrails personalizados passados para o `Task` do CrewAI com `@weave.op()`.

Para informa√ß√µes detalhadas sobre o que √© suportado, acesse a [documenta√ß√£o do Weave CrewAI](https://weave-docs.wandb.ai/guides/integrations/crewai/#getting-started-with-flow).

## Recursos

* [üìò Documenta√ß√£o do Weave](https://weave-docs.wandb.ai)
* [üìä Exemplo de dashboard Weave x CrewAI](https://wandb.ai/ayut/crewai_demo/weave/traces?cols=%7B%22wb_run_id%22%3Afalse%2C%22attributes.weave.client_version%22%3Afalse%2C%22attributes.weave.os_name%22%3Afalse%2C%22attributes.weave.os_release%22%3Afalse%2C%22attributes.weave.os_version%22%3Afalse%2C%22attributes.weave.source%22%3Afalse%2C%22attributes.weave.sys_version%22%3Afalse%7D\&peekPath=%2Fayut%2Fcrewai_demo%2Fcalls%2F0195c838-38cb-71a2-8a15-651ecddf9d89)
* [üê¶ X](https://x.com/weave_wb)


# Guia R√°pido
Source: https://docs.crewai.com/pt-BR/quickstart

Construa seu primeiro agente de IA com a CrewAI em menos de 5 minutos.

## Construa seu primeiro Agente CrewAI

Vamos criar uma tripula√ß√£o simples que nos ajudar√° a `pesquisar` e `relatar` sobre os `√∫ltimos avan√ßos em IA` para um determinado t√≥pico ou assunto.

Antes de prosseguir, certifique-se de ter conclu√≠do a instala√ß√£o da CrewAI.
Se ainda n√£o instalou, fa√ßa isso seguindo o [guia de instala√ß√£o](/pt-BR/installation).

Siga os passos abaixo para come√ßar a tripular! üö£‚Äç‚ôÇÔ∏è

<Steps>
  <Step title="Crie sua tripula√ß√£o">
    Crie um novo projeto de tripula√ß√£o executando o comando abaixo em seu terminal.
    Isso criar√° um novo diret√≥rio chamado `latest-ai-development` com a estrutura b√°sica para sua tripula√ß√£o.

    <CodeGroup>
      ```shell Terminal
      crewai create crew latest-ai-development
      ```
    </CodeGroup>
  </Step>

  <Step title="Navegue at√© o novo projeto da sua tripula√ß√£o">
    <CodeGroup>
      ```shell Terminal
      cd latest-ai-development
      ```
    </CodeGroup>
  </Step>

  <Step title="Modifique seu arquivo `agents.yaml`">
    <Tip>
      Voc√™ tamb√©m pode modificar os agentes conforme necess√°rio para atender ao seu caso de uso ou copiar e colar como est√° para seu projeto.
      Qualquer vari√°vel interpolada nos seus arquivos `agents.yaml` e `tasks.yaml`, como `{topic}`, ser√° substitu√≠da pelo valor da vari√°vel no arquivo `main.py`.
    </Tip>

    ```yaml agents.yaml
    # src/latest_ai_development/config/agents.yaml
    researcher:
      role: >
        Pesquisador S√™nior de Dados em {topic}
      goal: >
        Descobrir os avan√ßos mais recentes em {topic}
      backstory: >
        Voc√™ √© um pesquisador experiente com talento para descobrir os √∫ltimos avan√ßos em {topic}. Conhecido por sua habilidade em encontrar as informa√ß√µes mais relevantes e apresent√°-las de forma clara e concisa.

    reporting_analyst:
      role: >
        Analista de Relat√≥rios em {topic}
      goal: >
        Criar relat√≥rios detalhados com base na an√°lise de dados e descobertas de pesquisa em {topic}
      backstory: >
        Voc√™ √© um analista meticuloso com um olhar atento aos detalhes. √â conhecido por sua capacidade de transformar dados complexos em relat√≥rios claros e concisos, facilitando o entendimento e a tomada de decis√£o por parte dos outros.
    ```
  </Step>

  <Step title="Modifique seu arquivo `tasks.yaml`">
    ````yaml tasks.yaml
    # src/latest_ai_development/config/tasks.yaml
    research_task:
      description: >
        Realize uma pesquisa aprofundada sobre {topic}.
        Certifique-se de encontrar informa√ß√µes interessantes e relevantes considerando que o ano atual √© 2025.
      expected_output: >
        Uma lista com 10 t√≥picos dos dados mais relevantes sobre {topic}
      agent: researcher

    reporting_task:
      description: >
        Revise o contexto obtido e expanda cada t√≥pico em uma se√ß√£o completa para um relat√≥rio.
        Certifique-se de que o relat√≥rio seja detalhado e contenha todas as informa√ß√µes relevantes.
      expected_output: >
        Um relat√≥rio completo com os principais t√≥picos, cada um com uma se√ß√£o detalhada de informa√ß√µes.
        Formate como markdown sem usar '```'
      agent: reporting_analyst
      output_file: report.md
    ````
  </Step>

  <Step title="Modifique seu arquivo `crew.py`">
    ```python crew.py
    # src/latest_ai_development/crew.py
    from crewai import Agent, Crew, Process, Task
    from crewai.project import CrewBase, agent, crew, task
    from crewai_tools import SerperDevTool
    from crewai.agents.agent_builder.base_agent import BaseAgent
    from typing import List

    @CrewBase
    class LatestAiDevelopmentCrew():
      """LatestAiDevelopment crew"""

      agents: List[BaseAgent]
      tasks: List[Task]

      @agent
      def researcher(self) -> Agent:
        return Agent(
          config=self.agents_config['researcher'], # type: ignore[index]
          verbose=True,
          tools=[SerperDevTool()]
        )

      @agent
      def reporting_analyst(self) -> Agent:
        return Agent(
          config=self.agents_config['reporting_analyst'], # type: ignore[index]
          verbose=True
        )

      @task
      def research_task(self) -> Task:
        return Task(
          config=self.tasks_config['research_task'], # type: ignore[index]
        )

      @task
      def reporting_task(self) -> Task:
        return Task(
          config=self.tasks_config['reporting_task'], # type: ignore[index]
          output_file='output/report.md' # Este √© o arquivo que conter√° o relat√≥rio final.
        )

      @crew
      def crew(self) -> Crew:
        """Creates the LatestAiDevelopment crew"""
        return Crew(
          agents=self.agents, # Criado automaticamente pelo decorador @agent
          tasks=self.tasks, # Criado automaticamente pelo decorador @task
          process=Process.sequential,
          verbose=True,
        )
    ```
  </Step>

  <Step title="[Opcional] Adicione fun√ß√µes de pr√© e p√≥s execu√ß√£o da tripula√ß√£o">
    ```python crew.py
    # src/latest_ai_development/crew.py
    from crewai import Agent, Crew, Process, Task
    from crewai.project import CrewBase, agent, crew, task, before_kickoff, after_kickoff
    from crewai_tools import SerperDevTool

    @CrewBase
    class LatestAiDevelopmentCrew():
      """LatestAiDevelopment crew"""

      @before_kickoff
      def before_kickoff_function(self, inputs):
        print(f"Before kickoff function with inputs: {inputs}")
        return inputs # You can return the inputs or modify them as needed

      @after_kickoff
      def after_kickoff_function(self, result):
        print(f"After kickoff function with result: {result}")
        return result # You can return the result or modify it as needed

      # ... remaining code
    ```
  </Step>

  <Step title="Fique √† vontade para passar entradas personalizadas para sua tripula√ß√£o">
    Por exemplo, voc√™ pode passar o input `topic` para sua tripula√ß√£o para personalizar a pesquisa e o relat√≥rio.

    ```python main.py
    #!/usr/bin/env python
    # src/latest_ai_development/main.py
    import sys
    from latest_ai_development.crew import LatestAiDevelopmentCrew

    def run():
      """
      Run the crew.
      """
      inputs = {
        'topic': 'AI Agents'
      }
      LatestAiDevelopmentCrew().crew().kickoff(inputs=inputs)
    ```
  </Step>

  <Step title="Defina suas vari√°veis de ambiente">
    Antes de executar sua tripula√ß√£o, certifique-se de ter as seguintes chaves configuradas como vari√°veis de ambiente no seu arquivo `.env`:

    * Uma chave da API do [Serper.dev](https://serper.dev/): `SERPER_API_KEY=YOUR_KEY_HERE`
    * A configura√ß√£o do modelo de sua escolha, como uma chave de API. Veja o
      [guia de configura√ß√£o do LLM](/pt-BR/concepts/llms#setting-up-your-llm) para aprender como configurar modelos de qualquer provedor.
  </Step>

  <Step title="Trave e instale as depend√™ncias">
    * Trave e instale as depend√™ncias utilizando o comando da CLI:
      <CodeGroup>
        ```shell Terminal
        crewai install
        ```
      </CodeGroup>
    * Se quiser instalar pacotes adicionais, fa√ßa isso executando:
      <CodeGroup>
        ```shell Terminal
        uv add <package-name>
        ```
      </CodeGroup>
  </Step>

  <Step title="Execute sua tripula√ß√£o">
    * Para executar sua tripula√ß√£o, rode o seguinte comando na raiz do projeto:
      <CodeGroup>
        ```bash Terminal
        crewai run
        ```
      </CodeGroup>
  </Step>

  <Step title="Alternativa para Empresas: Crie no Crew Studio">
    Para usu√°rios do CrewAI Enterprise, voc√™ pode criar a mesma tripula√ß√£o sem escrever c√≥digo:

    1. Fa√ßa login na sua conta CrewAI Enterprise (crie uma conta gratuita em [app.crewai.com](https://app.crewai.com))
    2. Abra o Crew Studio
    3. Digite qual automa√ß√£o deseja construir
    4. Crie suas tarefas visualmente e conecte-as em sequ√™ncia
    5. Configure seus inputs e clique em "Download Code" ou "Deploy"

    ![Crew Studio Quickstart](https://mintlify.s3.us-west-1.amazonaws.com/crewai/images/enterprise/crew-studio-interface.png)

    <Card title="Experimente o CrewAI Enterprise" icon="rocket" href="https://app.crewai.com">
      Comece sua conta gratuita no CrewAI Enterprise
    </Card>
  </Step>

  <Step title="Veja seu relat√≥rio final">
    Voc√™ ver√° a sa√≠da no console e o arquivo `report.md` deve ser criado na raiz do seu projeto com o relat√≥rio final.

    Veja um exemplo de como o relat√≥rio deve ser:

    <CodeGroup>
      ```markdown output/report.md
      # Relat√≥rio Abrangente sobre a Ascens√£o e o Impacto dos Agentes de IA em 2025

      ## 1. Introduction to AI Agents
      In 2025, Artificial Intelligence (AI) agents are at the forefront of innovation across various industries. As intelligent systems that can perform tasks typically requiring human cognition, AI agents are paving the way for significant advancements in operational efficiency, decision-making, and overall productivity within sectors like Human Resources (HR) and Finance. This report aims to detail the rise of AI agents, their frameworks, applications, and potential implications on the workforce.

      ## 2. Benefits of AI Agents
      AI agents bring numerous advantages that are transforming traditional work environments. Key benefits include:

      - **Task Automation**: AI agents can carry out repetitive tasks such as data entry, scheduling, and payroll processing without human intervention, greatly reducing the time and resources spent on these activities.
      - **Improved Efficiency**: By quickly processing large datasets and performing analyses that would take humans significantly longer, AI agents enhance operational efficiency. This allows teams to focus on strategic tasks that require higher-level thinking.
      - **Enhanced Decision-Making**: AI agents can analyze trends and patterns in data, provide insights, and even suggest actions, helping stakeholders make informed decisions based on factual data rather than intuition alone.

      ## 3. Popular AI Agent Frameworks
      Several frameworks have emerged to facilitate the development of AI agents, each with its own unique features and capabilities. Some of the most popular frameworks include:

      - **Autogen**: A framework designed to streamline the development of AI agents through automation of code generation.
      - **Semantic Kernel**: Focuses on natural language processing and understanding, enabling agents to comprehend user intentions better.
      - **Promptflow**: Provides tools for developers to create conversational agents that can navigate complex interactions seamlessly.
      - **Langchain**: Specializes in leveraging various APIs to ensure agents can access and utilize external data effectively.
      - **CrewAI**: Aimed at collaborative environments, CrewAI strengthens teamwork by facilitating communication through AI-driven insights.
      - **MemGPT**: Combines memory-optimized architectures with generative capabilities, allowing for more personalized interactions with users.

      These frameworks empower developers to build versatile and intelligent agents that can engage users, perform advanced analytics, and execute various tasks aligned with organizational goals.

      ## 4. AI Agents in Human Resources
      AI agents are revolutionizing HR practices by automating and optimizing key functions:

      - **Recruiting**: AI agents can screen resumes, schedule interviews, and even conduct initial assessments, thus accelerating the hiring process while minimizing biases.
      - **Succession Planning**: AI systems analyze employee performance data and potential, helping organizations identify future leaders and plan appropriate training.
      - **Employee Engagement**: Chatbots powered by AI can facilitate feedback loops between employees and management, promoting an open culture and addressing concerns promptly.

      As AI continues to evolve, HR departments leveraging these agents can realize substantial improvements in both efficiency and employee satisfaction.

      ## 5. AI Agents in Finance
      The finance sector is seeing extensive integration of AI agents that enhance financial practices:

      - **Expense Tracking**: Automated systems manage and monitor expenses, flagging anomalies and offering recommendations based on spending patterns.
      - **Risk Assessment**: AI models assess credit risk and uncover potential fraud by analyzing transaction data and behavioral patterns.
      - **Investment Decisions**: AI agents provide stock predictions and analytics based on historical data and current market conditions, empowering investors with informative insights.

      The incorporation of AI agents into finance is fostering a more responsive and risk-aware financial landscape.

      ## 6. Market Trends and Investments
      The growth of AI agents has attracted significant investment, especially amidst the rising popularity of chatbots and generative AI technologies. Companies and entrepreneurs are eager to explore the potential of these systems, recognizing their ability to streamline operations and improve customer engagement.

      Conversely, corporations like Microsoft are taking strides to integrate AI agents into their product offerings, with enhancements to their Copilot 365 applications. This strategic move emphasizes the importance of AI literacy in the modern workplace and indicates the stabilizing of AI agents as essential business tools.

      ## 7. Future Predictions and Implications
      Experts predict that AI agents will transform essential aspects of work life. As we look toward the future, several anticipated changes include:

      - Enhanced integration of AI agents across all business functions, creating interconnected systems that leverage data from various departmental silos for comprehensive decision-making.
      - Continued advancement of AI technologies, resulting in smarter, more adaptable agents capable of learning and evolving from user interactions.
      - Increased regulatory scrutiny to ensure ethical use, especially concerning data privacy and employee surveillance as AI agents become more prevalent.

      To stay competitive and harness the full potential of AI agents, organizations must remain vigilant about latest developments in AI technology and consider continuous learning and adaptation in their strategic planning.

      ## 8. Conclusion
      The emergence of AI agents is undeniably reshaping the workplace landscape in 5. With their ability to automate tasks, enhance efficiency, and improve decision-making, AI agents are critical in driving operational success. Organizations must embrace and adapt to AI developments to thrive in an increasingly digital business environment.
      ```
    </CodeGroup>
  </Step>
</Steps>

<Check>
  Parab√©ns!

  Voc√™ configurou seu projeto de tripula√ß√£o com sucesso e est√° pronto para come√ßar a construir seus pr√≥prios fluxos de trabalho baseados em agentes!
</Check>

### Observa√ß√£o sobre Consist√™ncia nos Nomes

Os nomes utilizados nos seus arquivos YAML (`agents.yaml` e `tasks.yaml`) devem corresponder aos nomes dos m√©todos no seu c√≥digo Python.
Por exemplo, voc√™ pode referenciar o agente para tarefas espec√≠ficas a partir do arquivo `tasks.yaml`.
Essa consist√™ncia de nomes permite que a CrewAI conecte automaticamente suas configura√ß√µes ao seu c√≥digo; caso contr√°rio, sua tarefa n√£o reconhecer√° a refer√™ncia corretamente.

#### Exemplos de Refer√™ncias

<Tip>
  Observe como usamos o mesmo nome para o agente no arquivo `agents.yaml` (`email_summarizer`) e no m√©todo do arquivo `crew.py` (`email_summarizer`).
</Tip>

```yaml agents.yaml
email_summarizer:
    role: >
      Email Summarizer
    goal: >
      Summarize emails into a concise and clear summary
    backstory: >
      You will create a 5 bullet point summary of the report
    llm: provider/model-id  # Add your choice of model here
```

<Tip>
  Observe como usamos o mesmo nome para a tarefa no arquivo `tasks.yaml` (`email_summarizer_task`) e no m√©todo no arquivo `crew.py` (`email_summarizer_task`).
</Tip>

```yaml tasks.yaml
email_summarizer_task:
    description: >
      Summarize the email into a 5 bullet point summary
    expected_output: >
      A 5 bullet point summary of the email
    agent: email_summarizer
    context:
      - reporting_task
      - research_task
```

## Fazendo o Deploy da Sua Tripula√ß√£o

A forma mais f√°cil de fazer deploy da sua tripula√ß√£o em produ√ß√£o √© atrav√©s da [CrewAI Enterprise](http://app.crewai.com).

Assista a este v√≠deo tutorial para uma demonstra√ß√£o detalhada de como fazer deploy da sua tripula√ß√£o na [CrewAI Enterprise](http://app.crewai.com) usando a CLI.

<iframe width="100%" height="400" src="https://www.youtube.com/embed/3EqSV-CYDZA" title="CrewAI Deployment Guide" frameborder="0" style={{ borderRadius: '10px' }} allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

<CardGroup cols={2}>
  <Card title="Deploy no Enterprise" icon="rocket" href="http://app.crewai.com">
    Comece com o CrewAI Enterprise e fa√ßa o deploy da sua tripula√ß√£o em ambiente de produ√ß√£o com apenas alguns cliques.
  </Card>

  <Card title="Junte-se √† Comunidade" icon="comments" href="https://community.crewai.com">
    Participe da nossa comunidade open source para discutir ideias, compartilhar seus projetos e conectar-se com outros desenvolvedores CrewAI.
  </Card>
</CardGroup>


# null
Source: https://docs.crewai.com/pt-BR/snippets/snippet-intro



Um dos princ√≠pios fundamentais do desenvolvimento de software √© o DRY (Don't Repeat Yourself, ou N√£o Se Repita). Esse princ√≠pio tamb√©m se aplica √† documenta√ß√£o. Se voc√™ perceber que est√° repetindo o mesmo conte√∫do em v√°rios lugares, considere criar um snippet personalizado para manter seu conte√∫do sincronizado.


# Telemetria
Source: https://docs.crewai.com/pt-BR/telemetry

Entendendo os dados de telemetria coletados pelo CrewAI e como eles contribuem para o aprimoramento da biblioteca.

## Telemetria

<Note>
  Por padr√£o, n√£o coletamos dados que possam ser considerados informa√ß√µes pessoais segundo a GDPR e outras regulamenta√ß√µes de privacidade.
  Coletamos nomes das ferramentas e fun√ß√µes dos agentes, portanto, evite incluir qualquer informa√ß√£o pessoal nos nomes das ferramentas ou nas fun√ß√µes dos agentes.
  Como nenhuma informa√ß√£o pessoal √© coletada, n√£o √© necess√°rio se preocupar com localidade dos dados.
  Quando `share_crew` est√° ativado, dados adicionais s√£o coletados e podem conter informa√ß√µes pessoais caso sejam inclu√≠das pelo usu√°rio.
  Usu√°rios devem tomar cuidado ao habilitar este recurso para garantir conformidade com regulamenta√ß√µes de privacidade.
</Note>

O CrewAI utiliza telemetria an√¥nima para coletar estat√≠sticas de uso com o objetivo principal de aprimorar a biblioteca.
Nosso foco est√° em melhorar e desenvolver as funcionalidades, integra√ß√µes e ferramentas mais utilizadas pelos usu√°rios.

√â fundamental compreender que, por padr√£o, **NENHUM dado pessoal √© coletado** referente a prompts, descri√ß√µes de tarefas, hist√≥rias ou objetivos dos agentes,
uso de ferramentas, chamadas de API, respostas, quaisquer dados processados pelos agentes ou segredos e vari√°veis de ambiente.
Quando o recurso `share_crew` est√° ativado, dados detalhados, incluindo descri√ß√µes das tarefas, hist√≥rias ou objetivos dos agentes e outros atributos espec√≠ficos s√£o coletados
para fornecer insights mais detalhados. Essa coleta expandida pode incluir informa√ß√µes pessoais caso o usu√°rio as tenha inserido em seus crews ou tarefas.
Usu√°rios devem considerar cuidadosamente o conte√∫do de seus crews e tarefas antes de habilitar o `share_crew`.
A telemetria pode ser desabilitada ao definir a vari√°vel de ambiente `CREWAI_DISABLE_TELEMETRY` como `true` ou ao definir `OTEL_SDK_DISABLED` como `true` (observe que esta √∫ltima desabilita toda instrumenta√ß√£o OpenTelemetry globalmente).

### Exemplos:

```python
# Desabilitar apenas a telemetria do CrewAI
os.environ['CREWAI_DISABLE_TELEMETRY'] = 'true'

# Desabilitar todo o OpenTelemetry (incluindo CrewAI)
os.environ['OTEL_SDK_DISABLED'] = 'true'
```

### Explica√ß√£o dos Dados:

| Padr√£o | Dados                                          | Raz√£o e Especificidades                                                                                                                                                                                                                                                                                                                                        |
| ------ | ---------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Sim    | Vers√£o do CrewAI e Python                      | Rastreia vers√µes dos softwares. Exemplo: CrewAI v1.2.3, Python 3.8.10. Sem dados pessoais.                                                                                                                                                                                                                                                                     |
| Sim    | Metadados do Crew                              | Inclui: chave e ID gerados aleatoriamente, tipo de processo (ex: 'sequential', 'parallel'), flag booleana para uso de mem√≥ria (true/false), quantidade de tarefas, quantidade de agentes. Tudo n√£o pessoal.                                                                                                                                                    |
| Sim    | Dados do Agente                                | Inclui: chave e ID gerados aleatoriamente, nome da fun√ß√£o (n√£o deve incluir info pessoal), configura√ß√µes booleanas (verbose, delega√ß√£o habilitada, execu√ß√£o de c√≥digo permitida), m√°ximo de itera√ß√µes, m√°ximo de RPM, limite de tentativas, info do LLM (ver Atributos LLM), lista de nomes de ferramentas (n√£o deve conter info pessoal). Sem dados pessoais. |
| Sim    | Metadados da Tarefa                            | Inclui: chave e ID gerados aleatoriamente, configura√ß√µes de execu√ß√£o booleanas (async\_execution, human\_input), fun√ß√£o e chave do agente associado, lista de nomes de ferramentas. Tudo n√£o pessoal.                                                                                                                                                          |
| Sim    | Estat√≠sticas de Uso de Ferramentas             | Inclui: nome da ferramenta (n√£o deve incluir info pessoal), n√∫mero de tentativas de uso (inteiro), atributos LLM utilizados. Sem dados pessoais.                                                                                                                                                                                                               |
| Sim    | Dados de Execu√ß√£o de Testes                    | Inclui: chave e ID aleat√≥rias do crew, n√∫mero de itera√ß√µes, nome do modelo usado, score de qualidade (float), tempo de execu√ß√£o (em segundos). Tudo n√£o pessoal.                                                                                                                                                                                               |
| Sim    | Dados do Ciclo de Vida da Tarefa               | Inclui: hor√°rios de cria√ß√£o, in√≠cio/fim de execu√ß√£o, identificadores de crew e tarefa. Armazenado como spans com timestamps. Sem dados pessoais.                                                                                                                                                                                                               |
| Sim    | Atributos do LLM                               | Inclui: nome, model\_name, model, top\_k, temperatura e nome da classe do LLM. Todos t√©cnicos, sem dados pessoais.                                                                                                                                                                                                                                             |
| Sim    | Tentativa de Deploy do Crew pelo CLI do crewAI | Inclui: O fato de um deploy estar sendo realizado e o crew id, e se est√° tentando buscar logs, sem mais dados.                                                                                                                                                                                                                                                 |
| N√£o    | Dados Expandidos do Agente                     | Inclui: descri√ß√£o do objetivo, texto da hist√≥ria, identificador de arquivo i18n prompt. Usu√°rios devem garantir que n√£o haja info pessoal nesses campos de texto.                                                                                                                                                                                              |
| N√£o    | Informa√ß√µes Detalhadas da Tarefa               | Inclui: descri√ß√£o da tarefa, descri√ß√£o do resultado esperado, refer√™ncias de contexto. Usu√°rios devem garantir que n√£o haja info pessoal nessas √°reas.                                                                                                                                                                                                         |
| N√£o    | Informa√ß√µes de Ambiente                        | Inclui: plataforma, release, sistema, vers√£o e quantidade de CPUs. Exemplo: 'Windows 10', 'x86\_64'. Sem dados pessoais.                                                                                                                                                                                                                                       |
| N√£o    | Entradas e Sa√≠das de Crew e Tarefas            | Inclui: par√¢metros de entrada e resultados como dados n√£o identific√°veis. Usu√°rios devem garantir que n√£o haja info pessoal.                                                                                                                                                                                                                                   |
| N√£o    | Dados Abrangentes de Execu√ß√£o do Crew          | Inclui: logs detalhados das opera√ß√µes do crew, dados de todos os agentes e tarefas, resultado final. Tudo de natureza t√©cnica, sem dados pessoais.                                                                                                                                                                                                             |

<Note>
  "N√£o" na coluna "Padr√£o" indica que esse dado s√≥ √© coletado quando `share_crew` est√° configurado como `true`.
</Note>

### Compartilhamento Avan√ßado de Telemetria (Opt-In)

Usu√°rios podem optar por compartilhar toda a telemetria habilitando o atributo `share_crew` como `True` nas configura√ß√µes do seu crew.
Ao habilitar `share_crew`, h√° coleta detalhada dos dados de execu√ß√£o do crew e das tarefas, incluindo `goal`, `backstory`, `context` e `output` das tarefas.
Isso permite uma compreens√£o mais profunda dos padr√µes de uso.

<Warning>
  Se voc√™ habilitar o `share_crew`, os dados coletados podem incluir informa√ß√µes pessoais caso estas estejam presentes nas configura√ß√µes do crew, descri√ß√µes de tarefas ou outputs.
  Os usu√°rios devem revisar cuidadosamente seus dados e garantir conformidade com a GDPR e outras regulamenta√ß√µes de privacidade antes de habilitar esse recurso.
</Warning>


# AI Mind Tool
Source: https://docs.crewai.com/pt-BR/tools/ai-ml/aimindtool

O `AIMindTool` foi desenvolvido para consultar fontes de dados em linguagem natural.

# `AIMindTool`

## Descri√ß√£o

O `AIMindTool` √© um wrapper em torno do [AI-Minds](https://mindsdb.com/minds) fornecido pela [MindsDB](https://mindsdb.com/). Ele permite que voc√™ consulte fontes de dados em linguagem natural, bastando configurar os par√¢metros de conex√£o. Essa ferramenta √© √∫til quando voc√™ precisa de respostas para perguntas utilizando dados armazenados em diversas fontes, incluindo PostgreSQL, MySQL, MariaDB, ClickHouse, Snowflake e Google BigQuery.

Minds s√£o sistemas de IA que funcionam de forma similar aos grandes modelos de linguagem (LLMs), mas v√£o al√©m ao responder qualquer pergunta sobre qualquer dado. Isso √© realizado por meio de:

* Sele√ß√£o dos dados mais relevantes para a resposta utilizando busca param√©trica
* Compreens√£o do significado e fornecimento de respostas dentro do contexto correto atrav√©s de busca sem√¢ntica
* Entrega de respostas precisas ao analisar dados e utilizar modelos de machine learning (ML)

## Instala√ß√£o

Para incorporar esta ferramenta ao seu projeto, √© necess√°rio instalar o Minds SDK:

```shell
uv add minds-sdk
```

## Passos para Come√ßar

Para utilizar o `AIMindTool` de maneira eficaz, siga estes passos:

1. **Instala√ß√£o de Pacotes**: Verifique se os pacotes `crewai[tools]` e `minds-sdk` est√£o instalados no seu ambiente Python.
2. **Obten√ß√£o da Chave de API**: Cadastre-se para uma conta Minds [aqui](https://mdb.ai/register) e obtenha uma chave de API.
3. **Configura√ß√£o do Ambiente**: Armazene sua chave de API obtida em uma vari√°vel de ambiente chamada `MINDS_API_KEY` para facilitar seu uso pela ferramenta.

## Exemplo

O exemplo a seguir demonstra como inicializar a ferramenta e executar uma consulta:

```python Code
from crewai_tools import AIMindTool

# Initialize the AIMindTool
aimind_tool = AIMindTool(
    datasources=[
        {
            "description": "house sales data",
            "engine": "postgres",
            "connection_data": {
                "user": "demo_user",
                "password": "demo_password",
                "host": "samples.mindsdb.com",
                "port": 5432,
                "database": "demo",
                "schema": "demo_data"
            },
            "tables": ["house_sales"]
        }
    ]
)

# Run a natural language query
result = aimind_tool.run("How many 3 bedroom houses were sold in 2008?")
print(result)
```

## Par√¢metros

O `AIMindTool` aceita os seguintes par√¢metros:

* **api\_key**: Opcional. Sua chave de API da Minds. Se n√£o for fornecida, ser√° lida da vari√°vel de ambiente `MINDS_API_KEY`.
* **datasources**: Uma lista de dicion√°rios, cada um contendo as seguintes chaves:
  * **description**: Uma descri√ß√£o dos dados contidos na fonte de dados.
  * **engine**: O engine (ou tipo) da fonte de dados.
  * **connection\_data**: Um dicion√°rio contendo os par√¢metros de conex√£o da fonte de dados.
  * **tables**: Uma lista de tabelas que a fonte de dados ir√° utilizar. Isso √© opcional e pode ser omitido caso todas as tabelas da fonte de dados devam ser utilizadas.

Uma lista das fontes de dados suportadas e seus par√¢metros de conex√£o pode ser encontrada [aqui](https://docs.mdb.ai/docs/data_sources).

## Exemplo de Integra√ß√£o com Agente

Veja como integrar o `AIMindTool` com um agente CrewAI:

```python Code
from crewai import Agent
from crewai.project import agent
from crewai_tools import AIMindTool

# Initialize the tool
aimind_tool = AIMindTool(
    datasources=[
        {
            "description": "sales data",
            "engine": "postgres",
            "connection_data": {
                "user": "your_user",
                "password": "your_password",
                "host": "your_host",
                "port": 5432,
                "database": "your_db",
                "schema": "your_schema"
            },
            "tables": ["sales"]
        }
    ]
)

# Define an agent with the AIMindTool
@agent
def data_analyst(self) -> Agent:
    return Agent(
        config=self.agents_config["data_analyst"],
        allow_delegation=False,
        tools=[aimind_tool]
    )
```

## Conclus√£o

O `AIMindTool` oferece uma forma poderosa de consultar suas fontes de dados utilizando linguagem natural, facilitando a extra√ß√£o de insights sem a necessidade de escrever consultas SQL complexas. Ao conectar diversas fontes de dados e aproveitar a tecnologia AI-Minds, essa ferramenta permite que agentes acessem e analisem dados de maneira eficiente.


# Interpretador de C√≥digo
Source: https://docs.crewai.com/pt-BR/tools/ai-ml/codeinterpretertool

O `CodeInterpreterTool` √© uma poderosa ferramenta projetada para executar c√≥digo Python 3 em um ambiente seguro e isolado.

# `CodeInterpreterTool`

## Descri√ß√£o

O `CodeInterpreterTool` permite que agentes CrewAI executem c√≥digos Python 3 gerados autonomamente. Essa funcionalidade √© particularmente valiosa, pois permite que os agentes criem c√≥digos, os executem, obtenham os resultados e usem essas informa√ß√µes para orientar decis√µes e a√ß√µes subsequentes.

H√° diversas formas de usar esta ferramenta:

### Container Docker (Recomendado)

Esta √© a op√ß√£o principal. O c√≥digo √© executado em um container Docker seguro e isolado, garantindo a seguran√ßa independentemente de seu conte√∫do.
Certifique-se de que o Docker esteja instalado e em funcionamento em seu sistema. Se ainda n√£o tiver, voc√™ pode instal√°-lo a partir [deste link](https://docs.docker.com/get-docker/).

### Ambiente Sandbox

Se o Docker n√£o estiver dispon√≠vel ‚Äî seja por n√£o estar instalado ou inacess√≠vel por qualquer motivo ‚Äî o c√≥digo ser√° executado em um ambiente Python restrito, chamado de sandbox.
Esse ambiente √© bastante limitado, com restri√ß√µes severas a v√°rios m√≥dulos e fun√ß√µes embutidas.

### Execu√ß√£o N√£o Segura

**N√ÉO RECOMENDADO PARA PRODU√á√ÉO**
Este modo permite a execu√ß√£o de qualquer c√≥digo Python, inclusive chamadas perigosas para os m√≥dulos `sys, os..` e semelhantes. [Veja aqui](/pt-BR/tools/ai-ml/codeinterpretertool#enabling-unsafe-mode) como habilitar este modo.

## Registro de Logs

O `CodeInterpreterTool` registra a estrat√©gia de execu√ß√£o selecionada no STDOUT.

## Instala√ß√£o

Para utilizar esta ferramenta, voc√™ precisa instalar o pacote de ferramentas CrewAI:

```shell
pip install 'crewai[tools]'
```

## Exemplo

O exemplo a seguir demonstra como usar o `CodeInterpreterTool` com um agente CrewAI:

```python Code
from crewai import Agent, Task, Crew, Process
from crewai_tools import CodeInterpreterTool

# Initialize the tool
code_interpreter = CodeInterpreterTool()

# Define an agent that uses the tool
programmer_agent = Agent(
    role="Python Programmer",
    goal="Write and execute Python code to solve problems",
    backstory="An expert Python programmer who can write efficient code to solve complex problems.",
    tools=[code_interpreter],
    verbose=True,
)

# Example task to generate and execute code
coding_task = Task(
    description="Write a Python function to calculate the Fibonacci sequence up to the 10th number and print the result.",
    expected_output="The Fibonacci sequence up to the 10th number.",
    agent=programmer_agent,
)

# Create and run the crew
crew = Crew(
    agents=[programmer_agent],
    tasks=[coding_task],
    verbose=True,
    process=Process.sequential,
)
result = crew.kickoff()
```

Voc√™ tamb√©m pode habilitar a execu√ß√£o de c√≥digo diretamente ao criar um agente:

```python Code
from crewai import Agent

# Create an agent with code execution enabled
programmer_agent = Agent(
    role="Python Programmer",
    goal="Write and execute Python code to solve problems",
    backstory="An expert Python programmer who can write efficient code to solve complex problems.",
    allow_code_execution=True,  # This automatically adds the CodeInterpreterTool
    verbose=True,
)
```

### Habilitando o `unsafe_mode`

```python Code
from crewai_tools import CodeInterpreterTool

code = """
import os
os.system("ls -la")
"""

CodeInterpreterTool(unsafe_mode=True).run(code=code)
```

## Par√¢metros

O `CodeInterpreterTool` aceita os seguintes par√¢metros durante a inicializa√ß√£o:

* **user\_dockerfile\_path**: Opcional. Caminho para um Dockerfile personalizado a ser utilizado pelo container do interpretador de c√≥digo.
* **user\_docker\_base\_url**: Opcional. URL do daemon Docker que ser√° usado para rodar o container.
* **unsafe\_mode**: Opcional. Indica se o c√≥digo ser√° executado diretamente na m√°quina hospedeira ao inv√©s de um container Docker ou sandbox. O padr√£o √© `False`. Use com cautela!
* **default\_image\_tag**: Opcional. Tag padr√£o da imagem Docker. O padr√£o √© `code-interpreter:latest`

Ao utilizar a ferramenta com um agente, o agente precisar√° fornecer:

* **code**: Obrigat√≥rio. O c√≥digo Python 3 a ser executado.
* **libraries\_used**: Opcional. Uma lista de bibliotecas usadas no c√≥digo que precisam ser instaladas. O padr√£o √© `[]`

## Exemplo de Integra√ß√£o com Agente

Aqui est√° um exemplo mais detalhado de como integrar o `CodeInterpreterTool` com um agente CrewAI:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import CodeInterpreterTool

# Initialize the tool
code_interpreter = CodeInterpreterTool()

# Define an agent that uses the tool
data_analyst = Agent(
    role="Data Analyst",
    goal="Analyze data using Python code",
    backstory="""You are an expert data analyst who specializes in using Python
    to analyze and visualize data. You can write efficient code to process
    large datasets and extract meaningful insights.""",
    tools=[code_interpreter],
    verbose=True,
)

# Create a task for the agent
analysis_task = Task(
    description="""
    Write Python code to:
    1. Generate a random dataset of 100 points with x and y coordinates
    2. Calculate the correlation coefficient between x and y
    3. Create a scatter plot of the data
    4. Print the correlation coefficient and save the plot as 'scatter.png'

    Make sure to handle any necessary imports and print the results.
    """,
    expected_output="The correlation coefficient and confirmation that the scatter plot has been saved.",
    agent=data_analyst,
)

# Run the task
crew = Crew(
    agents=[data_analyst],
    tasks=[analysis_task],
    verbose=True,
    process=Process.sequential,
)
result = crew.kickoff()
```

## Detalhes de Implementa√ß√£o

O `CodeInterpreterTool` utiliza Docker para criar um ambiente seguro para execu√ß√£o de c√≥digo:

```python Code
class CodeInterpreterTool(BaseTool):
    name: str = "Code Interpreter"
    description: str = "Interprets Python3 code strings with a final print statement."
    args_schema: Type[BaseModel] = CodeInterpreterSchema
    default_image_tag: str = "code-interpreter:latest"

    def _run(self, **kwargs) -> str:
        code = kwargs.get("code", self.code)
        libraries_used = kwargs.get("libraries_used", [])

        if self.unsafe_mode:
            return self.run_code_unsafe(code, libraries_used)
        else:
            return self.run_code_safety(code, libraries_used)
```

A ferramenta executa os seguintes passos:

1. Verifica se a imagem Docker existe ou a constr√≥i, caso necess√°rio
2. Cria um container Docker com o diret√≥rio de trabalho atual montado
3. Instala quaisquer bibliotecas necess√°rias especificadas pelo agente
4. Executa o c√≥digo Python dentro do container
5. Retorna a sa√≠da da execu√ß√£o do c√≥digo
6. Limpa o ambiente, parando e removendo o container

## Considera√ß√µes de Seguran√ßa

Por padr√£o, o `CodeInterpreterTool` executa o c√≥digo em um container Docker isolado, fornecendo uma camada de seguran√ßa. No entanto, ainda h√° algumas considera√ß√µes importantes:

1. O container Docker tem acesso ao diret√≥rio de trabalho atual, ent√£o arquivos sens√≠veis podem ser potencialmente acessados.
2. Caso o container Docker n√£o esteja dispon√≠vel e o c√≥digo precise ser executado de forma segura, ele ser√° executado em um ambiente sandbox. Por motivos de seguran√ßa, a instala√ß√£o de bibliotecas arbitr√°rias n√£o √© permitida
3. O par√¢metro `unsafe_mode` permite que c√≥digos sejam executados diretamente na m√°quina hospedeira, o que deve ser usado apenas em ambientes confi√°veis.
4. Tenha cautela ao permitir que agentes instalem bibliotecas arbitr√°rias, pois estas podem incluir c√≥digos maliciosos.

## Conclus√£o

O `CodeInterpreterTool` oferece uma maneira poderosa para que agentes CrewAI executem c√≥digo Python em um ambiente relativamente seguro. Permitindo que agentes escrevam e executem c√≥digos, ele amplia significativamente sua capacidade de resolu√ß√£o de problemas, especialmente para tarefas que envolvem an√°lise de dados, c√°lculos ou outros trabalhos computacionais. Esta ferramenta √© especialmente √∫til para agentes que precisam realizar opera√ß√µes complexas que s√£o mais eficientemente expressas em c√≥digo do que em linguagem natural.


# Ferramenta DALL-E
Source: https://docs.crewai.com/pt-BR/tools/ai-ml/dalletool

A `DallETool` √© uma ferramenta poderosa projetada para gerar imagens a partir de descri√ß√µes textuais.

# `DallETool`

## Descri√ß√£o

Esta ferramenta √© utilizada para dar ao Agente a capacidade de gerar imagens usando o modelo DALL-E. Trata-se de um modelo baseado em transformer que gera imagens a partir de descri√ß√µes textuais.
Esta ferramenta permite que o Agente gere imagens com base no texto de entrada fornecido pelo usu√°rio.

## Instala√ß√£o

Instale o pacote crewai\_tools

```shell
pip install 'crewai[tools]'
```

## Exemplo

Lembre-se de que, ao usar esta ferramenta, o texto deve ser gerado pelo pr√≥prio Agente. O texto deve ser uma descri√ß√£o da imagem que voc√™ deseja gerar.

```python Code
from crewai_tools import DallETool

Agent(
    ...
    tools=[DallETool()],
)
```

Se necess√°rio, voc√™ tamb√©m pode ajustar os par√¢metros do modelo DALL-E passando-os como argumentos para a classe `DallETool`. Por exemplo:

```python Code
from crewai_tools import DallETool

dalle_tool = DallETool(model="dall-e-3",
                       size="1024x1024",
                       quality="standard",
                       n=1)

Agent(
    ...
    tools=[dalle_tool]
)
```

Os par√¢metros s√£o baseados no m√©todo `client.images.generate` da API OpenAI. Para mais informa√ß√µes sobre os par√¢metros,
consulte a [documenta√ß√£o da API OpenAI](https://platform.openai.com/docs/guides/images/introduction?lang=python).


# Ferramenta LangChain
Source: https://docs.crewai.com/pt-BR/tools/ai-ml/langchaintool

O `LangChainTool` √© um wrapper para ferramentas LangChain e mecanismos de consulta.

## `LangChainTool`

<Info>
  CrewAI integra-se perfeitamente com a abrangente [lista de ferramentas](https://python.langchain.com/docs/integrations/tools/) do LangChain, todas as quais podem ser usadas com CrewAI.
</Info>

```python Code
import os
from dotenv import load_dotenv
from crewai import Agent, Task, Crew
from crewai.tools import BaseTool
from pydantic import Field
from langchain_community.utilities import GoogleSerperAPIWrapper

# Set up your SERPER_API_KEY key in an .env file, eg:
# SERPER_API_KEY=<your api key>
load_dotenv()

search = GoogleSerperAPIWrapper()

class SearchTool(BaseTool):
    name: str = "Search"
    description: str = "Useful for search-based queries. Use this to find current information about markets, companies, and trends."
    search: GoogleSerperAPIWrapper = Field(default_factory=GoogleSerperAPIWrapper)

    def _run(self, query: str) -> str:
        """Execute the search query and return results"""
        try:
            return self.search.run(query)
        except Exception as e:
            return f"Error performing search: {str(e)}"

# Create Agents
researcher = Agent(
    role='Research Analyst',
    goal='Gather current market data and trends',
    backstory="""You are an expert research analyst with years of experience in
    gathering market intelligence. You're known for your ability to find
    relevant and up-to-date market information and present it in a clear,
    actionable format.""",
    tools=[SearchTool()],
    verbose=True
)

# rest of the code ...
```

## Conclus√£o

As ferramentas s√£o fundamentais para ampliar as capacidades dos agentes CrewAI, permitindo que realizem uma ampla variedade de tarefas e colaborem de forma eficaz.
Ao construir solu√ß√µes com CrewAI, aproveite tanto ferramentas personalizadas quanto existentes para potencializar seus agentes e aprimorar o ecossistema de IA. Considere utilizar tratamento de erros, mecanismos de cache e a flexibilidade dos argumentos das ferramentas para otimizar o desempenho e as capacidades dos seus agentes.


# Ferramenta LlamaIndex
Source: https://docs.crewai.com/pt-BR/tools/ai-ml/llamaindextool

A `LlamaIndexTool` √© um wrapper para ferramentas e mecanismos de consulta do LlamaIndex.

# `LlamaIndexTool`

## Descri√ß√£o

A `LlamaIndexTool` foi projetada para ser um wrapper geral em torno das ferramentas e mecanismos de consulta do LlamaIndex, permitindo que voc√™ aproveite os recursos do LlamaIndex em pipelines de RAG/agent como ferramentas que podem ser acopladas aos agentes do CrewAI. Essa ferramenta permite integrar de forma transparente as poderosas capacidades de processamento e recupera√ß√£o de dados do LlamaIndex em seus fluxos de trabalho com o CrewAI.

## Instala√ß√£o

Para utilizar esta ferramenta, √© necess√°rio instalar o LlamaIndex:

```shell
uv add llama-index
```

## Passos para Come√ßar

Para utilizar a `LlamaIndexTool` de forma eficaz, siga os passos abaixo:

1. **Instale o LlamaIndex**: Instale o pacote LlamaIndex usando o comando acima.
2. **Configure o LlamaIndex**: Siga a [documenta√ß√£o do LlamaIndex](https://docs.llamaindex.ai/) para configurar um pipeline de RAG/agent.
3. **Crie uma Ferramenta ou Mecanismo de Consulta**: Crie uma ferramenta ou mecanismo de consulta do LlamaIndex que voc√™ deseja usar com o CrewAI.

## Exemplo

Os exemplos a seguir demonstram como inicializar a ferramenta a partir de diferentes componentes do LlamaIndex:

### A partir de uma ferramenta do LlamaIndex

```python Code
from crewai_tools import LlamaIndexTool
from crewai import Agent
from llama_index.core.tools import FunctionTool

# Exemplo 1: Inicializando a partir do FunctionTool
def search_data(query: str) -> str:
    """Busca por informa√ß√µes nos dados."""
    # Sua implementa√ß√£o aqui
    return f"Results for: {query}"

# Cria√ß√£o de um LlamaIndex FunctionTool
og_tool = FunctionTool.from_defaults(
    search_data,
    name="DataSearchTool",
    description="Search for information in the data"
)

# Envolvendo com a LlamaIndexTool
tool = LlamaIndexTool.from_tool(og_tool)

# Definindo um agente que utiliza a ferramenta
@agent
def researcher(self) -> Agent:
    '''
    Este agente usa a LlamaIndexTool para buscar informa√ß√µes.
    '''
    return Agent(
        config=self.agents_config["researcher"],
        tools=[tool]
    )
```

### A partir de Ferramentas do LlamaHub

```python Code
from crewai_tools import LlamaIndexTool
from llama_index.tools.wolfram_alpha import WolframAlphaToolSpec

# Inicializando a partir das ferramentas do LlamaHub
wolfram_spec = WolframAlphaToolSpec(app_id="your_app_id")
wolfram_tools = wolfram_spec.to_tool_list()
tools = [LlamaIndexTool.from_tool(t) for t in wolfram_tools]
```

### A partir de um mecanismo de consulta do LlamaIndex

```python Code
from crewai_tools import LlamaIndexTool
from llama_index.core import VectorStoreIndex
from llama_index.core.readers import SimpleDirectoryReader

# Carregar documentos
documents = SimpleDirectoryReader("./data").load_data()

# Criar um √≠ndice
index = VectorStoreIndex.from_documents(documents)

# Criar um mecanismo de consulta
query_engine = index.as_query_engine()

# Criar uma LlamaIndexTool a partir do mecanismo de consulta
query_tool = LlamaIndexTool.from_query_engine(
    query_engine,
    name="Company Data Query Tool",
    description="Use this tool to lookup information in company documents"
)
```

## M√©todos da Classe

A `LlamaIndexTool` oferece dois m√©todos de classe principais para criar inst√¢ncias:

### from\_tool

Cria uma `LlamaIndexTool` a partir de uma ferramenta do LlamaIndex.

```python Code
@classmethod
def from_tool(cls, tool: Any, **kwargs: Any) -> "LlamaIndexTool":
    # Implementation details
```

### from\_query\_engine

Cria uma `LlamaIndexTool` a partir de um mecanismo de consulta do LlamaIndex.

```python Code
@classmethod
def from_query_engine(
    cls,
    query_engine: Any,
    name: Optional[str] = None,
    description: Optional[str] = None,
    return_direct: bool = False,
    **kwargs: Any,
) -> "LlamaIndexTool":
    # Implementation details
```

## Par√¢metros

O m√©todo `from_query_engine` aceita os seguintes par√¢metros:

* **query\_engine**: Obrigat√≥rio. O mecanismo de consulta do LlamaIndex a ser envolvido.
* **name**: Opcional. O nome da ferramenta.
* **description**: Opcional. A descri√ß√£o da ferramenta.
* **return\_direct**: Opcional. Define se deve retornar a resposta diretamente. O padr√£o √© `False`.

## Conclus√£o

A `LlamaIndexTool` oferece uma maneira poderosa de integrar as capacidades do LlamaIndex aos agentes do CrewAI. Ao envolver ferramentas e mecanismos de consulta do LlamaIndex, ela permite que os agentes utilizem funcionalidades sofisticadas de recupera√ß√£o e processamento de dados, aprimorando sua capacidade de trabalhar com fontes de informa√ß√£o complexas.


# Vis√£o Geral
Source: https://docs.crewai.com/pt-BR/tools/ai-ml/overview

Aproveite servi√ßos de IA, gere imagens, processe vis√£o e construa sistemas inteligentes

Essas ferramentas se integram com servi√ßos de IA e machine learning para aprimorar seus agentes com capacidades avan√ßadas como gera√ß√£o de imagens, processamento de vis√£o e execu√ß√£o inteligente de c√≥digo.

## **Ferramentas Dispon√≠veis**

<CardGroup cols={2}>
  <Card title="DALL-E Tool" icon="image" href="/pt-BR/tools/ai-ml/dalletool">
    Gere imagens com IA utilizando o modelo DALL-E da OpenAI.
  </Card>

  <Card title="Vision Tool" icon="eye" href="/pt-BR/tools/ai-ml/visiontool">
    Processe e analise imagens com capacidades de vis√£o computacional.
  </Card>

  <Card title="AI Mind Tool" icon="brain" href="/pt-BR/tools/ai-ml/aimindtool">
    Capacidades avan√ßadas de racioc√≠nio e tomada de decis√£o com IA.
  </Card>

  <Card title="LlamaIndex Tool" icon="llama" href="/pt-BR/tools/ai-ml/llamaindextool">
    Construa bases de conhecimento e sistemas de recupera√ß√£o com LlamaIndex.
  </Card>

  <Card title="LangChain Tool" icon="link" href="/pt-BR/tools/ai-ml/langchaintool">
    Integre com LangChain para fluxos de trabalho de IA complexos.
  </Card>

  <Card title="RAG Tool" icon="database" href="/pt-BR/tools/ai-ml/ragtool">
    Implemente sistemas de Gera√ß√£o Aumentada por Recupera√ß√£o (RAG).
  </Card>

  <Card title="Code Interpreter Tool" icon="code" href="/pt-BR/tools/ai-ml/codeinterpretertool">
    Execute c√≥digo Python e realize an√°lises de dados.
  </Card>
</CardGroup>

## **Casos de Uso Comuns**

* **Gera√ß√£o de Conte√∫do**: Crie imagens, textos e conte√∫do multim√≠dia
* **An√°lise de Dados**: Execute c√≥digo e analise conjuntos de dados complexos
* **Sistemas de Conhecimento**: Construa sistemas RAG e bancos de dados inteligentes
* **Vis√£o Computacional**: Processe e compreenda conte√∫do visual
* **Seguran√ßa em IA**: Implemente modera√ß√£o de conte√∫do e checagens de seguran√ßa

```python
from crewai_tools import DallETool, VisionTool, CodeInterpreterTool

# Create AI tools
image_generator = DallETool()
vision_processor = VisionTool()
code_executor = CodeInterpreterTool()

# Add to your agent
agent = Agent(
    role="AI Specialist",
    tools=[image_generator, vision_processor, code_executor],
    goal="Create and analyze content using AI capabilities"
)
```


# Ferramenta RAG
Source: https://docs.crewai.com/pt-BR/tools/ai-ml/ragtool

O `RagTool` √© uma ferramenta din√¢mica de base de conhecimento para responder perguntas usando Gera√ß√£o Aumentada por Recupera√ß√£o.

# `RagTool`

## Descri√ß√£o

O `RagTool` foi desenvolvido para responder perguntas aproveitando o poder da Gera√ß√£o Aumentada por Recupera√ß√£o (RAG) atrav√©s do EmbedChain.
Ele fornece uma base de conhecimento din√¢mica que pode ser consultada para recuperar informa√ß√µes relevantes de v√°rias fontes de dados.
Esta ferramenta √© particularmente √∫til para aplica√ß√µes que exigem acesso a uma ampla variedade de informa√ß√µes e precisam fornecer respostas contextualmente relevantes.

## Exemplo

O exemplo a seguir demonstra como inicializar a ferramenta e us√°-la com diferentes fontes de dados:

```python Code
from crewai_tools import RagTool

# Create a RAG tool with default settings
rag_tool = RagTool()

# Add content from a file
rag_tool.add(data_type="file", path="path/to/your/document.pdf")

# Add content from a web page
rag_tool.add(data_type="web_page", url="https://example.com")

# Define an agent with the RagTool
@agent
def knowledge_expert(self) -> Agent:
    '''
    This agent uses the RagTool to answer questions about the knowledge base.
    '''
    return Agent(
        config=self.agents_config["knowledge_expert"],
        allow_delegation=False,
        tools=[rag_tool]
    )
```

## Fontes de Dados Suportadas

O `RagTool` pode ser utilizado com uma grande variedade de fontes de dados, incluindo:

* üì∞ Arquivos PDF
* üìä Arquivos CSV
* üìÉ Arquivos JSON
* üìù Texto
* üìÅ Diret√≥rios/Pastas
* üåê P√°ginas web em HTML
* üìΩÔ∏è Canais do YouTube
* üì∫ V√≠deos do YouTube
* üìö Sites de documenta√ß√£o
* üìù Arquivos MDX
* üìÑ Arquivos DOCX
* üßæ Arquivos XML
* üì¨ Gmail
* üìù Reposit√≥rios GitHub
* üêò Bancos de dados PostgreSQL
* üê¨ Bancos de dados MySQL
* ü§ñ Conversas no Slack
* üí¨ Mensagens do Discord
* üó®Ô∏è F√≥runs Discourse
* üìù Newsletters do Substack
* üêù Conte√∫do do Beehiiv
* üíæ Arquivos Dropbox
* üñºÔ∏è Imagens
* ‚öôÔ∏è Fontes de dados personalizadas

## Par√¢metros

O `RagTool` aceita os seguintes par√¢metros:

* **summarize**: Opcional. Indica se o conte√∫do recuperado deve ser resumido. O padr√£o √© `False`.
* **adapter**: Opcional. Um adaptador personalizado para a base de conhecimento. Se n√£o for fornecido, ser√° utilizado o EmbedchainAdapter.
* **config**: Opcional. Configura√ß√£o para o aplicativo EmbedChain subjacente.

## Adicionando Conte√∫do

Voc√™ pode adicionar conte√∫do √† base de conhecimento utilizando o m√©todo `add`:

```python Code
# Add a PDF file
rag_tool.add(data_type="file", path="path/to/your/document.pdf")

# Add a web page
rag_tool.add(data_type="web_page", url="https://example.com")

# Add a YouTube video
rag_tool.add(data_type="youtube_video", url="https://www.youtube.com/watch?v=VIDEO_ID")

# Add a directory of files
rag_tool.add(data_type="directory", path="path/to/your/directory")
```

## Exemplo de Integra√ß√£o com Agente

Veja como integrar o `RagTool` com um agente do CrewAI:

```python Code
from crewai import Agent
from crewai.project import agent
from crewai_tools import RagTool

# Initialize the tool and add content
rag_tool = RagTool()
rag_tool.add(data_type="web_page", url="https://docs.crewai.com")
rag_tool.add(data_type="file", path="company_data.pdf")

# Define an agent with the RagTool
@agent
def knowledge_expert(self) -> Agent:
    return Agent(
        config=self.agents_config["knowledge_expert"],
        allow_delegation=False,
        tools=[rag_tool]
    )
```

## Configura√ß√£o Avan√ßada

√â poss√≠vel personalizar o comportamento do `RagTool` fornecendo um dicion√°rio de configura√ß√£o:

```python Code
from crewai_tools import RagTool

# Create a RAG tool with custom configuration
config = {
    "app": {
        "name": "custom_app",
    },
    "llm": {
        "provider": "openai",
        "config": {
            "model": "gpt-4",
        }
    },
    "embedding_model": {
        "provider": "openai",
        "config": {
            "model": "text-embedding-ada-002"
        }
    },
    "vectordb": {
        "provider": "elasticsearch",
        "config": {
            "collection_name": "my-collection",
            "cloud_id": "deployment-name:xxxx",
            "api_key": "your-key",
            "verify_certs": False
        }
    },
    "chunker": {
        "chunk_size": 400,
        "chunk_overlap": 100,
        "length_function": "len",
        "min_chunk_size": 0
    }
}

rag_tool = RagTool(config=config, summarize=True)
```

A ferramenta RAG interna utiliza o adaptador Embedchain, possibilitando que voc√™ forne√ßa quaisquer op√ß√µes de configura√ß√£o suportadas pelo Embedchain.
Voc√™ pode consultar a [documenta√ß√£o do Embedchain](https://docs.embedchain.ai/components/introduction) para mais detalhes.
Certifique-se de revisar as op√ß√µes de configura√ß√£o dispon√≠veis no arquivo .yaml.

## Conclus√£o

O `RagTool` oferece uma maneira poderosa de criar e consultar bases de conhecimento a partir de diversas fontes de dados. Ao explorar a Gera√ß√£o Aumentada por Recupera√ß√£o, ele permite que agentes acessem e recuperem informa√ß√µes relevantes de forma eficiente, ampliando a capacidade de fornecer respostas precisas e contextualmente apropriadas.


# Vision Tool
Source: https://docs.crewai.com/pt-BR/tools/ai-ml/visiontool

O `VisionTool` foi projetado para extrair texto de imagens.

# `VisionTool`

## Descri√ß√£o

Esta ferramenta √© utilizada para extrair texto de imagens. Quando passada para o agente, ela extrai o texto da imagem e depois o utiliza para gerar uma resposta, relat√≥rio ou qualquer outra sa√≠da.
A URL ou o CAMINHO da imagem deve ser passado para o Agente.

## Instala√ß√£o

Instale o pacote crewai\_tools

```shell
pip install 'crewai[tools]'
```

## Uso

Para usar o VisionTool, a chave da API da OpenAI deve ser definida na vari√°vel de ambiente `OPENAI_API_KEY`.

```python Code
from crewai_tools import VisionTool

vision_tool = VisionTool()

@agent
def researcher(self) -> Agent:
    '''
    This agent uses the VisionTool to extract text from images.
    '''
    return Agent(
        config=self.agents_config["researcher"],
        allow_delegation=False,
        tools=[vision_tool]
    )
```

## Argumentos

O VisionTool requer os seguintes argumentos:

| Argumento            | Tipo     | Descri√ß√£o                                                                          |
| :------------------- | :------- | :--------------------------------------------------------------------------------- |
| **image\_path\_url** | `string` | **Obrigat√≥rio**. O caminho para o arquivo de imagem do qual o texto ser√° extra√≠do. |


# Apify Actors
Source: https://docs.crewai.com/pt-BR/tools/automation/apifyactorstool

`ApifyActorsTool` permite que voc√™ execute Apify Actors para adicionar recursos de raspagem de dados na web, coleta, extra√ß√£o de dados e automa√ß√£o web aos seus fluxos de trabalho CrewAI.

# `ApifyActorsTool`

Integre [Apify Actors](https://apify.com/actors) nos seus fluxos de trabalho CrewAI.

## Descri√ß√£o

O `ApifyActorsTool` conecta [Apify Actors](https://apify.com/actors), programas em nuvem para raspagem e automa√ß√£o web, aos seus fluxos de trabalho CrewAI.
Utilize qualquer um dos mais de 4.000 Actors dispon√≠veis na [Apify Store](https://apify.com/store) para casos de uso como extra√ß√£o de dados de redes sociais, motores de busca, mapas online, sites de e-commerce, portais de viagem ou sites em geral.

Para mais detalhes, consulte a [integra√ß√£o Apify CrewAI](https://docs.apify.com/platform/integrations/crewai) na documenta√ß√£o do Apify.

## Passos para come√ßar

<Steps>
  <Step title="Instale as depend√™ncias">
    Instale `crewai[tools]` e `langchain-apify` usando pip: `pip install 'crewai[tools]' langchain-apify`.
  </Step>

  <Step title="Obtenha um token de API do Apify">
    Cadastre-se no [Apify Console](https://console.apify.com/) e obtenha seu [token de API do Apify](https://console.apify.com/settings/integrations).
  </Step>

  <Step title="Configure o ambiente">
    Defina seu token de API do Apify na vari√°vel de ambiente `APIFY_API_TOKEN` para habilitar a funcionalidade da ferramenta.
  </Step>
</Steps>

## Exemplo de uso

Use o `ApifyActorsTool` manualmente para executar o [RAG Web Browser Actor](https://apify.com/apify/rag-web-browser) e realizar uma busca na web:

```python
from crewai_tools import ApifyActorsTool

# Inicialize a ferramenta com um Apify Actor
tool = ApifyActorsTool(actor_name="apify/rag-web-browser")

# Execute a ferramenta com par√¢metros de entrada
results = tool.run(run_input={"query": "What is CrewAI?", "maxResults": 5})

# Processe os resultados
for result in results:
    print(f"URL: {result['metadata']['url']}")
    print(f"Content: {result.get('markdown', 'N/A')[:100]}...")
```

### Sa√≠da esperada

Veja abaixo a sa√≠da do c√≥digo acima:

```text
URL: https://www.example.com/crewai-intro
Content: CrewAI is a framework for building AI-powered workflows...
URL: https://docs.crewai.com/
Content: Official documentation for CrewAI...
```

O `ApifyActorsTool` busca automaticamente a defini√ß√£o do Actor e o esquema de entrada no Apify utilizando o `actor_name` fornecido e ent√£o constr√≥i a descri√ß√£o da ferramenta e o esquema dos argumentos. Isso significa que voc√™ s√≥ precisa informar um `actor_name` v√°lido, e a ferramenta faz o resto quando usada com agentes‚Äîn√£o √© necess√°rio especificar o `run_input`. Veja como funciona:

```python
from crewai import Agent
from crewai_tools import ApifyActorsTool

rag_browser = ApifyActorsTool(actor_name="apify/rag-web-browser")

agent = Agent(
    role="Research Analyst",
    goal="Find and summarize information about specific topics",
    backstory="You are an experienced researcher with attention to detail",
    tools=[rag_browser],
)
```

Voc√™ pode executar outros Actors da [Apify Store](https://apify.com/store) apenas alterando o `actor_name` e, ao usar manualmente, ajustando o `run_input` de acordo com o esquema de entrada do Actor.

Para um exemplo de uso com agentes, consulte o [template CrewAI Actor](https://apify.com/templates/python-crewai).

## Configura√ß√£o

O `ApifyActorsTool` exige os seguintes inputs para funcionar:

* **`actor_name`**
  O ID do Apify Actor a ser executado, por exemplo, `"apify/rag-web-browser"`. Explore todos os Actors na [Apify Store](https://apify.com/store).
* **`run_input`**
  Um dicion√°rio de par√¢metros de entrada para o Actor ao executar a ferramenta manualmente.
  * Por exemplo, para o Actor `apify/rag-web-browser`: `{"query": "search term", "maxResults": 5}`
  * Veja o [schema de entrada do Actor](https://apify.com/apify/rag-web-browser/input-schema) para a lista de par√¢metros de entrada.

## Recursos

* **[Apify](https://apify.com/)**: Explore a plataforma Apify.
* **[Como criar um agente de IA no Apify](https://blog.apify.com/how-to-build-an-ai-agent/)** - Um guia completo, passo a passo, para criar, publicar e monetizar agentes de IA na plataforma Apify.
* **[RAG Web Browser Actor](https://apify.com/apify/rag-web-browser)**: Um Actor popular para busca na web para LLMs.
* **[Guia de Integra√ß√£o CrewAI](https://docs.apify.com/platform/integrations/crewai)**: Siga o guia oficial para integrar Apify e CrewAI.


# Ferramenta Composio
Source: https://docs.crewai.com/pt-BR/tools/automation/composiotool

O Composio oferece mais de 250 ferramentas prontas para produ√ß√£o para agentes de IA com gerenciamento de autentica√ß√£o flex√≠vel.

# `ComposioToolSet`

## Descri√ß√£o

Composio √© uma plataforma de integra√ß√£o que permite conectar seus agentes de IA a mais de 250 ferramentas. Os principais recursos incluem:

* **Autentica√ß√£o de N√≠vel Empresarial**: Suporte integrado para OAuth, Chaves de API, JWT com atualiza√ß√£o autom√°tica de token
* **Observabilidade Completa**: Logs detalhados de uso das ferramentas, registros de execu√ß√£o, e muito mais

## Instala√ß√£o

Para incorporar as ferramentas Composio em seu projeto, siga as instru√ß√µes abaixo:

```shell
pip install composio-crewai
pip install crewai
```

Ap√≥s a conclus√£o da instala√ß√£o, execute `composio login` ou exporte sua chave de API do composio como `COMPOSIO_API_KEY`. Obtenha sua chave de API Composio [aqui](https://app.composio.dev)

## Exemplo

O exemplo a seguir demonstra como inicializar a ferramenta e executar uma a√ß√£o do github:

1. Inicialize o conjunto de ferramentas Composio

```python Code
from composio_crewai import ComposioToolSet, App, Action
from crewai import Agent, Task, Crew

toolset = ComposioToolSet()
```

2. Conecte sua conta do GitHub

<CodeGroup>
  ```shell CLI
  composio add github
  ```

  ```python Code
  request = toolset.initiate_connection(app=App.GITHUB)
  print(f"Open this URL to authenticate: {request.redirectUrl}")
  ```
</CodeGroup>

3. Obtenha ferramentas

* Recuperando todas as ferramentas de um app (n√£o recomendado em produ√ß√£o):

```python Code
tools = toolset.get_tools(apps=[App.GITHUB])
```

* Filtrando ferramentas com base em tags:

```python Code
tag = "users"

filtered_action_enums = toolset.find_actions_by_tags(
    App.GITHUB,
    tags=[tag],
)

tools = toolset.get_tools(actions=filtered_action_enums)
```

* Filtrando ferramentas com base no caso de uso:

```python Code
use_case = "Star a repository on GitHub"

filtered_action_enums = toolset.find_actions_by_use_case(
    App.GITHUB, use_case=use_case, advanced=False
)

tools = toolset.get_tools(actions=filtered_action_enums)
```

<Tip>Defina `advanced` como True para obter a√ß√µes para casos de uso complexos</Tip>

* Usando ferramentas espec√≠ficas:

Neste exemplo, usaremos a a√ß√£o `GITHUB_STAR_A_REPOSITORY_FOR_THE_AUTHENTICATED_USER` do app GitHub.

```python Code
tools = toolset.get_tools(
    actions=[Action.GITHUB_STAR_A_REPOSITORY_FOR_THE_AUTHENTICATED_USER]
)
```

Saiba mais sobre como filtrar a√ß√µes [aqui](https://docs.composio.dev/patterns/tools/use-tools/use-specific-actions)

4. Defina o agente

```python Code
crewai_agent = Agent(
    role="GitHub Agent",
    goal="You take action on GitHub using GitHub APIs",
    backstory="You are AI agent that is responsible for taking actions on GitHub on behalf of users using GitHub APIs",
    verbose=True,
    tools=tools,
    llm= # pass an llm
)
```

5. Execute a tarefa

```python Code
task = Task(
    description="Star a repo composiohq/composio on GitHub",
    agent=crewai_agent,
    expected_output="Status of the operation",
)

crew = Crew(agents=[crewai_agent], tasks=[task])

crew.kickoff()
```

* Uma lista mais detalhada de ferramentas pode ser encontrada [aqui](https://app.composio.dev)


# MultiOn Tool
Source: https://docs.crewai.com/pt-BR/tools/automation/multiontool

O `MultiOnTool` permite que agentes CrewAI naveguem e interajam com a web por meio de instru√ß√µes em linguagem natural.

## Vis√£o Geral

O `MultiOnTool` foi projetado para envolver as capacidades de navega√ß√£o web do [MultiOn](https://docs.multion.ai/welcome), permitindo que agentes CrewAI controlem navegadores web usando instru√ß√µes em linguagem natural. Esta ferramenta facilita a navega√ß√£o fluida, tornando-se um recurso essencial para projetos que requerem intera√ß√£o din√¢mica com dados web e automa√ß√£o de tarefas baseadas na web.

## Instala√ß√£o

Para utilizar esta ferramenta, √© necess√°rio instalar o pacote MultiOn:

```shell
uv add multion
```

Voc√™ tamb√©m precisar√° instalar a extens√£o de navegador do MultiOn e habilitar o uso da API.

## Passos para Come√ßar

Para usar o `MultiOnTool` de forma eficaz, siga estes passos:

1. **Instale o CrewAI**: Certifique-se de que o pacote `crewai[tools]` esteja instalado em seu ambiente Python.
2. **Instale e utilize o MultiOn**: Siga a [documenta√ß√£o do MultiOn](https://docs.multion.ai/learn/browser-extension) para instalar a extens√£o de navegador do MultiOn.
3. **Habilite o Uso da API**: Clique na extens√£o do MultiOn na pasta de extens√µes do seu navegador (n√£o no √≠cone flutuante do MultiOn na p√°gina web) para abrir as configura√ß√µes da extens√£o. Clique na op√ß√£o para habilitar a API (API Enabled).

## Exemplo

O exemplo a seguir demonstra como inicializar a ferramenta e executar uma tarefa de navega√ß√£o web:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import MultiOnTool

# Initialize the tool
multion_tool = MultiOnTool(api_key="YOUR_MULTION_API_KEY", local=False)

# Define an agent that uses the tool
browser_agent = Agent(
    role="Browser Agent",
    goal="Control web browsers using natural language",
    backstory="An expert browsing agent.",
    tools=[multion_tool],
    verbose=True,
)

# Example task to search and summarize news
browse_task = Task(
    description="Summarize the top 3 trending AI News headlines",
    expected_output="A summary of the top 3 trending AI News headlines",
    agent=browser_agent,
)

# Create and run the crew
crew = Crew(agents=[browser_agent], tasks=[browse_task])
result = crew.kickoff()
```

## Par√¢metros

O `MultiOnTool` aceita os seguintes par√¢metros durante a inicializa√ß√£o:

* **api\_key**: Opcional. Especifica a chave da API do MultiOn. Se n√£o for fornecida, a ferramenta procurar√° pela vari√°vel de ambiente `MULTION_API_KEY`.
* **local**: Opcional. Defina como `True` para executar o agente localmente em seu navegador. Certifique-se de que a extens√£o do MultiOn est√° instalada e a op√ß√£o API Enabled est√° marcada. O padr√£o √© `False`.
* **max\_steps**: Opcional. Define o n√∫mero m√°ximo de etapas que o agente MultiOn pode executar para um comando. O padr√£o √© `3`.

## Uso

Ao utilizar o `MultiOnTool`, o agente fornecer√° instru√ß√µes em linguagem natural que a ferramenta traduzir√° em a√ß√µes de navega√ß√£o web. A ferramenta retorna os resultados da sess√£o de navega√ß√£o juntamente com um status.

```python Code
# Example of using the tool with an agent
browser_agent = Agent(
    role="Web Browser Agent",
    goal="Search for and summarize information from the web",
    backstory="An expert at finding and extracting information from websites.",
    tools=[multion_tool],
    verbose=True,
)

# Create a task for the agent
search_task = Task(
    description="Search for the latest AI news on TechCrunch and summarize the top 3 headlines",
    expected_output="A summary of the top 3 AI news headlines from TechCrunch",
    agent=browser_agent,
)

# Run the task
crew = Crew(agents=[browser_agent], tasks=[search_task])
result = crew.kickoff()
```

Se o status retornado for `CONTINUE`, o agente deve ser instru√≠do a reenviar a mesma instru√ß√£o para continuar a execu√ß√£o.

## Detalhes de Implementa√ß√£o

O `MultiOnTool` √© implementado como uma subclasse de `BaseTool` do CrewAI. Ele envolve o cliente MultiOn para fornecer capacidades de navega√ß√£o web:

```python Code
class MultiOnTool(BaseTool):
    """Tool to wrap MultiOn Browse Capabilities."""

    name: str = "Multion Browse Tool"
    description: str = """Multion gives the ability for LLMs to control web browsers using natural language instructions.
            If the status is 'CONTINUE', reissue the same instruction to continue execution
        """

    # Implementation details...

    def _run(self, cmd: str, *args: Any, **kwargs: Any) -> str:
        """
        Run the Multion client with the given command.

        Args:
            cmd (str): The detailed and specific natural language instruction for web browsing
            *args (Any): Additional arguments to pass to the Multion client
            **kwargs (Any): Additional keyword arguments to pass to the Multion client
        """
        # Implementation details...
```

## Conclus√£o

O `MultiOnTool` oferece uma maneira poderosa de integrar capacidades de navega√ß√£o web em agentes CrewAI. Ao permitir que agentes interajam com sites por meio de instru√ß√µes em linguagem natural, amplia significativamente as possibilidades para tarefas baseadas na web, desde coleta de dados e pesquisa at√© intera√ß√µes automatizadas com servi√ßos online.


# Vis√£o Geral
Source: https://docs.crewai.com/pt-BR/tools/automation/overview

Automatize fluxos de trabalho e integre com plataformas e servi√ßos externos

Essas ferramentas permitem que seus agentes automatizem fluxos de trabalho, integrem com plataformas externas e conectem-se a diversos servi√ßos de terceiros para funcionalidades aprimoradas.

## **Ferramentas Dispon√≠veis**

<CardGroup cols={2}>
  <Card title="Apify Actor Tool" icon="spider" href="/pt-BR/tools/automation/apifyactorstool">
    Execute atores do Apify para tarefas de automa√ß√£o e raspagem de dados web.
  </Card>

  <Card title="Composio Tool" icon="puzzle-piece" href="/pt-BR/tools/automation/composiotool">
    Integre com centenas de aplicativos e servi√ßos atrav√©s do Composio.
  </Card>

  <Card title="Multion Tool" icon="window-restore" href="/pt-BR/tools/automation/multiontool">
    Automatize intera√ß√µes no navegador e fluxos de trabalho baseados na web.
  </Card>
</CardGroup>

## **Casos de Uso Comuns**

* **Automa√ß√£o de Fluxos de Trabalho**: Automatize tarefas e processos repetitivos
* **Integra√ß√£o com APIs**: Conecte-se a APIs e servi√ßos externos
* **Sincroniza√ß√£o de Dados**: Sincronize dados entre diferentes plataformas
* **Orquestra√ß√£o de Processos**: Coordene fluxos de trabalho complexos e com m√∫ltiplas etapas
* **Servi√ßos de Terceiros**: Aproveite ferramentas e plataformas externas

```python
from crewai_tools import ApifyActorTool, ComposioTool, MultiOnTool

# Create automation tools
apify_automation = ApifyActorTool()
platform_integration = ComposioTool()
browser_automation = MultiOnTool()

# Add to your agent
agent = Agent(
    role="Automation Specialist",
    tools=[apify_automation, platform_integration, browser_automation],
    goal="Automate workflows and integrate systems"
)
```

## **Benef√≠cios da Integra√ß√£o**

* **Efici√™ncia**: Reduza o trabalho manual por meio da automa√ß√£o
* **Escalabilidade**: Gerencie cargas de trabalho crescentes automaticamente
* **Confiabilidade**: Execu√ß√£o consistente de fluxos de trabalho
* **Conectividade**: Integre diferentes sistemas e plataformas
* **Produtividade**: Foque em tarefas de alto valor enquanto a automa√ß√£o cuida das rotinas


# Ferramenta Bedrock Invoke Agent
Source: https://docs.crewai.com/pt-BR/tools/cloud-storage/bedrockinvokeagenttool

Permite que agentes CrewAI invoquem Amazon Bedrock Agents e aproveitem suas capacidades em seus fluxos de trabalho

# `BedrockInvokeAgentTool`

A `BedrockInvokeAgentTool` permite que agentes CrewAI invoquem Amazon Bedrock Agents e aproveitem suas capacidades em seus fluxos de trabalho.

## Instala√ß√£o

```bash
uv pip install 'crewai[tools]'
```

## Requisitos

* Credenciais AWS configuradas (atrav√©s de vari√°veis de ambiente ou AWS CLI)
* Pacotes `boto3` e `python-dotenv`
* Acesso aos Amazon Bedrock Agents

## Uso

Veja como usar a ferramenta com um agente CrewAI:

```python {2, 4-8}
from crewai import Agent, Task, Crew
from crewai_tools.aws.bedrock.agents.invoke_agent_tool import BedrockInvokeAgentTool

# Initialize the tool
agent_tool = BedrockInvokeAgentTool(
    agent_id="your-agent-id",
    agent_alias_id="your-agent-alias-id"
)

# Create a CrewAI agent that uses the tool
aws_expert = Agent(
    role='AWS Service Expert',
    goal='Help users understand AWS services and quotas',
    backstory='I am an expert in AWS services and can provide detailed information about them.',
    tools=[agent_tool],
    verbose=True
)

# Create a task for the agent
quota_task = Task(
    description="Find out the current service quotas for EC2 in us-west-2 and explain any recent changes.",
    agent=aws_expert
)

# Create a crew with the agent
crew = Crew(
    agents=[aws_expert],
    tasks=[quota_task],
    verbose=2
)

# Run the crew
result = crew.kickoff()
print(result)
```

## Argumentos da Ferramenta

| Argumento            | Tipo   | Obrigat√≥rio | Padr√£o    | Descri√ß√£o                                            |
| :------------------- | :----- | :---------- | :-------- | :--------------------------------------------------- |
| **agent\_id**        | `str`  | Sim         | None      | O identificador √∫nico do agente Bedrock              |
| **agent\_alias\_id** | `str`  | Sim         | None      | O identificador √∫nico do alias do agente             |
| **session\_id**      | `str`  | N√£o         | timestamp | O identificador √∫nico da sess√£o                      |
| **enable\_trace**    | `bool` | N√£o         | False     | Define se o trace deve ser habilitado para debug     |
| **end\_session**     | `bool` | N√£o         | False     | Define se a sess√£o deve ser encerrada ap√≥s invoca√ß√£o |
| **description**      | `str`  | N√£o         | None      | Descri√ß√£o personalizada para a ferramenta            |

## Vari√°veis de Ambiente

```bash
BEDROCK_AGENT_ID=your-agent-id           # Alternativa para passar agent_id
BEDROCK_AGENT_ALIAS_ID=your-agent-alias-id # Alternativa para passar agent_alias_id
AWS_REGION=your-aws-region               # Padr√£o √© us-west-2
AWS_ACCESS_KEY_ID=your-access-key        # Necess√°rio para autentica√ß√£o AWS
AWS_SECRET_ACCESS_KEY=your-secret-key    # Necess√°rio para autentica√ß√£o AWS
```

## Uso Avan√ßado

### Fluxo de Trabalho Multiagente com Gerenciamento de Sess√£o

```python {2, 4-22}
from crewai import Agent, Task, Crew, Process
from crewai_tools.aws.bedrock.agents.invoke_agent_tool import BedrockInvokeAgentTool

# Initialize tools with session management
initial_tool = BedrockInvokeAgentTool(
    agent_id="your-agent-id",
    agent_alias_id="your-agent-alias-id",
    session_id="custom-session-id"
)

followup_tool = BedrockInvokeAgentTool(
    agent_id="your-agent-id",
    agent_alias_id="your-agent-alias-id",
    session_id="custom-session-id"
)

final_tool = BedrockInvokeAgentTool(
    agent_id="your-agent-id",
    agent_alias_id="your-agent-alias-id",
    session_id="custom-session-id",
    end_session=True
)

# Create agents for different stages
researcher = Agent(
    role='AWS Service Researcher',
    goal='Gather information about AWS services',
    backstory='I am specialized in finding detailed AWS service information.',
    tools=[initial_tool]
)

analyst = Agent(
    role='Service Compatibility Analyst',
    goal='Analyze service compatibility and requirements',
    backstory='I analyze AWS services for compatibility and integration possibilities.',
    tools=[followup_tool]
)

summarizer = Agent(
    role='Technical Documentation Writer',
    goal='Create clear technical summaries',
    backstory='I specialize in creating clear, concise technical documentation.',
    tools=[final_tool]
)

# Create tasks
research_task = Task(
    description="Find all available AWS services in us-west-2 region.",
    agent=researcher
)

analysis_task = Task(
    description="Analyze which services support IPv6 and their implementation requirements.",
    agent=analyst
)

summary_task = Task(
    description="Create a summary of IPv6-compatible services and their key features.",
    agent=summarizer
)

# Create a crew with the agents and tasks
crew = Crew(
    agents=[researcher, analyst, summarizer],
    tasks=[research_task, analysis_task, summary_task],
    process=Process.sequential,
    verbose=2
)

# Run the crew
result = crew.kickoff()
```

## Casos de Uso

### Colabora√ß√µes H√≠bridas Multiagente

* Crie fluxos de trabalho onde agentes CrewAI colaboram com agentes Bedrock gerenciados executando como servi√ßos na AWS
* Permita cen√°rios em que o processamento de dados sens√≠veis ocorre dentro do seu ambiente AWS enquanto outros agentes operam externamente
* Conecte agentes CrewAI on-premises a agentes Bedrock baseados na nuvem para fluxos de trabalho distribu√≠dos de intelig√™ncia

### Soberania e Conformidade de Dados

* Mantenha fluxos de trabalho agentivos sens√≠veis a dados dentro do seu ambiente AWS enquanto permite que agentes CrewAI externos orquestrem tarefas
* Mantenha conformidade com requisitos de resid√™ncia de dados processando informa√ß√µes sens√≠veis somente em sua conta AWS
* Permita colabora√ß√µes multiagentes seguras onde alguns agentes n√£o podem acessar dados privados da sua organiza√ß√£o

### Integra√ß√£o Transparente com Servi√ßos AWS

* Acesse qualquer servi√ßo AWS por meio do Amazon Bedrock Actions sem escrever c√≥digo de integra√ß√£o complexo
* Permita que agentes CrewAI interajam com servi√ßos AWS usando solicita√ß√µes em linguagem natural
* Aproveite as capacidades pr√©-constru√≠das dos agentes Bedrock para interagir com servi√ßos AWS como Bedrock Knowledge Bases, Lambda e outros

### Arquiteturas de Agentes H√≠bridos Escal√°veis

* Realize tarefas computacionalmente intensivas em agentes Bedrock gerenciados enquanto tarefas leves rodam em CrewAI
* Escale o processamento de agentes distribuindo cargas de trabalho entre agentes CrewAI locais e agentes Bedrock na nuvem

### Colabora√ß√£o de Agentes Entre Organiza√ß√µes

* Permita colabora√ß√£o segura entre agentes CrewAI da sua organiza√ß√£o e agentes Bedrock de organiza√ß√µes parceiras
* Crie fluxos de trabalho onde a expertise externa de agentes Bedrock pode ser incorporada sem expor dados sens√≠veis
* Construa ecossistemas de agentes que abrangem fronteiras organizacionais mantendo seguran√ßa e controle de dados


# Bedrock Knowledge Base Retriever
Source: https://docs.crewai.com/pt-BR/tools/cloud-storage/bedrockkbretriever

Recupere informa√ß√µes das Bases de Conhecimento do Amazon Bedrock usando consultas em linguagem natural

# `BedrockKBRetrieverTool`

A `BedrockKBRetrieverTool` permite que agentes CrewAI recuperem informa√ß√µes das Bases de Conhecimento do Amazon Bedrock usando consultas em linguagem natural.

## Instala√ß√£o

```bash
uv pip install 'crewai[tools]'
```

## Requisitos

* Credenciais AWS configuradas (via vari√°veis de ambiente ou AWS CLI)
* Pacotes `boto3` e `python-dotenv`
* Acesso √† Base de Conhecimento do Amazon Bedrock

## Uso

Veja como utilizar a ferramenta com um agente CrewAI:

```python {2, 4-17}
from crewai import Agent, Task, Crew
from crewai_tools.aws.bedrock.knowledge_base.retriever_tool import BedrockKBRetrieverTool

# Initialize the tool
kb_tool = BedrockKBRetrieverTool(
    knowledge_base_id="your-kb-id",
    number_of_results=5
)

# Create a CrewAI agent that uses the tool
researcher = Agent(
    role='Knowledge Base Researcher',
    goal='Find information about company policies',
    backstory='I am a researcher specialized in retrieving and analyzing company documentation.',
    tools=[kb_tool],
    verbose=True
)

# Create a task for the agent
research_task = Task(
    description="Find our company's remote work policy and summarize the key points.",
    agent=researcher
)

# Create a crew with the agent
crew = Crew(
    agents=[researcher],
    tasks=[research_task],
    verbose=2
)

# Run the crew
result = crew.kickoff()
print(result)
```

## Argumentos da Ferramenta

| Argumento                    | Tipo   | Obrigat√≥rio | Padr√£o | Descri√ß√£o                                                                     |
| :--------------------------- | :----- | :---------- | :----- | :---------------------------------------------------------------------------- |
| **knowledge\_base\_id**      | `str`  | Sim         | Nenhum | O identificador √∫nico da base de conhecimento (0-10 caracteres alfanum√©ricos) |
| **number\_of\_results**      | `int`  | N√£o         | 5      | N√∫mero m√°ximo de resultados a serem retornados                                |
| **retrieval\_configuration** | `dict` | N√£o         | Nenhum | Configura√ß√µes personalizadas para a consulta da base de conhecimento          |
| **guardrail\_configuration** | `dict` | N√£o         | Nenhum | Configura√ß√µes de filtragem de conte√∫do                                        |
| **next\_token**              | `str`  | N√£o         | Nenhum | Token para pagina√ß√£o                                                          |

## Vari√°veis de Ambiente

```bash
BEDROCK_KB_ID=your-knowledge-base-id  # Alternativa ao uso de knowledge_base_id
AWS_REGION=your-aws-region            # Padr√£o: us-east-1
AWS_ACCESS_KEY_ID=your-access-key     # Obrigat√≥rio para autentica√ß√£o AWS
AWS_SECRET_ACCESS_KEY=your-secret-key # Obrigat√≥rio para autentica√ß√£o AWS
```

## Formato da Resposta

A ferramenta retorna resultados em formato JSON:

```json
{
  "results": [
    {
      "content": "Retrieved text content",
      "content_type": "text",
      "source_type": "S3",
      "source_uri": "s3://bucket/document.pdf",
      "score": 0.95,
      "metadata": {
        "additional": "metadata"
      }
    }
  ],
  "nextToken": "pagination-token",
  "guardrailAction": "NONE"
}
```

## Uso Avan√ßado

### Configura√ß√£o de Recupera√ß√£o Personalizada

```python
kb_tool = BedrockKBRetrieverTool(
    knowledge_base_id="your-kb-id",
    retrieval_configuration={
        "vectorSearchConfiguration": {
            "numberOfResults": 10,
            "overrideSearchType": "HYBRID"
        }
    }
)

policy_expert = Agent(
    role='Policy Expert',
    goal='Analyze company policies in detail',
    backstory='I am an expert in corporate policy analysis with deep knowledge of regulatory requirements.',
    tools=[kb_tool]
)
```

## Fontes de Dados Suportadas

* Amazon S3
* Confluence
* Salesforce
* SharePoint
* P√°ginas web
* Locais de documentos personalizados
* Amazon Kendra
* Bancos de dados SQL

## Casos de Uso

### Integra√ß√£o de Conhecimento Corporativo

* Permita que agentes CrewAI acessem o conhecimento propriet√°rio da sua organiza√ß√£o sem expor dados sens√≠veis
* Permita que agentes tomem decis√µes baseadas nas pol√≠ticas, procedimentos e documenta√ß√µes espec√≠ficas da sua empresa
* Crie agentes capazes de responder perguntas com base na sua documenta√ß√£o interna mantendo a seguran√ßa dos dados

### Conhecimento Especializado de Dom√≠nio

* Conecte agentes CrewAI a bases de conhecimento espec√≠ficas do dom√≠nio (jur√≠dico, m√©dico, t√©cnico) sem re-treinamento de modelos
* Aproveite reposit√≥rios de conhecimento existentes que j√° s√£o mantidos no seu ambiente AWS
* Combine o racioc√≠nio do CrewAI com informa√ß√µes de dom√≠nio provenientes das suas bases de conhecimento

### Tomada de Decis√£o Orientada por Dados

* Baseie as respostas dos agentes CrewAI nos dados reais da sua empresa, e n√£o apenas em conhecimento geral
* Assegure que os agentes forne√ßam recomenda√ß√µes baseadas no contexto e documenta√ß√£o do seu neg√≥cio
* Reduza alucina√ß√µes ao recuperar informa√ß√µes factuais das suas bases de conhecimento

### Acesso Escal√°vel √† Informa√ß√£o

* Acesse terabytes de conhecimento organizacional sem precisar incorporar tudo aos seus modelos
* Consulte dinamicamente apenas as informa√ß√µes relevantes conforme a necessidade de cada tarefa
* Aproveite a infraestrutura escal√°vel da AWS para lidar com grandes bases de conhecimento de forma eficiente

### Conformidade e Governan√ßa

* Garanta que agentes CrewAI forne√ßam respostas alinhadas com a documenta√ß√£o aprovada da sua empresa
* Crie trilhas de auditoria das fontes de informa√ß√£o usadas pelos agentes
* Mantenha controle sobre quais fontes de informa√ß√£o os seus agentes podem acessar


# Vis√£o Geral
Source: https://docs.crewai.com/pt-BR/tools/cloud-storage/overview

Interaja com servi√ßos em nuvem, sistemas de armazenamento e plataformas de IA baseadas em nuvem

Essas ferramentas permitem que seus agentes interajam com servi√ßos em nuvem, acessem o armazenamento em nuvem e aproveitem plataformas de IA baseadas em nuvem para opera√ß√µes em escala.

## **Ferramentas Dispon√≠veis**

<CardGroup cols={2}>
  <Card title="S3 Reader Tool" icon="cloud" href="/pt-BR/tools/cloud-storage/s3readertool">
    Leia arquivos e dados de buckets Amazon S3.
  </Card>

  <Card title="S3 Writer Tool" icon="cloud-arrow-up" href="/pt-BR/tools/cloud-storage/s3writertool">
    Escreva e fa√ßa upload de arquivos para o armazenamento Amazon S3.
  </Card>

  <Card title="Bedrock Invoke Agent" icon="aws" href="/pt-BR/tools/cloud-storage/bedrockinvokeagenttool">
    Acione agentes Amazon Bedrock para tarefas orientadas por IA.
  </Card>

  <Card title="Bedrock KB Retriever" icon="database" href="/pt-BR/tools/cloud-storage/bedrockkbretriever">
    Recupere informa√ß√µes das bases de conhecimento Amazon Bedrock.
  </Card>
</CardGroup>

## **Casos de Uso Comuns**

* **Armazenamento de Arquivos**: Armazene e recupere arquivos de sistemas de armazenamento em nuvem
* **Backup de Dados**: Fa√ßa backup de dados importantes no armazenamento em nuvem
* **Servi√ßos de IA**: Acesse modelos e servi√ßos de IA baseados em nuvem
* **Recupera√ß√£o de Conhecimento**: Consulte bases de conhecimento hospedadas na nuvem
* **Opera√ß√µes Escal√°veis**: Aproveite a infraestrutura de nuvem para processamento

```python
from crewai_tools import S3ReaderTool, S3WriterTool, BedrockInvokeAgentTool

# Create cloud tools
s3_reader = S3ReaderTool()
s3_writer = S3WriterTool()
bedrock_agent = BedrockInvokeAgentTool()

# Add to your agent
agent = Agent(
    role="Cloud Operations Specialist",
    tools=[s3_reader, s3_writer, bedrock_agent],
    goal="Manage cloud resources and AI services"
)
```


# S3 Reader Tool
Source: https://docs.crewai.com/pt-BR/tools/cloud-storage/s3readertool

O `S3ReaderTool` permite que agentes CrewAI leiam arquivos de buckets Amazon S3.

# `S3ReaderTool`

## Descri√ß√£o

O `S3ReaderTool` foi projetado para ler arquivos de buckets Amazon S3. Esta ferramenta permite que os agentes CrewAI acessem e recuperem conte√∫dos armazenados no S3, tornando-a ideal para fluxos de trabalho que exigem leitura de dados, arquivos de configura√ß√£o ou qualquer outro conte√∫do armazenado no AWS S3.

## Instala√ß√£o

Para utilizar esta ferramenta, √© necess√°rio instalar as depend√™ncias requeridas:

```shell
uv add boto3
```

## Passos para Come√ßar

Para usar o `S3ReaderTool` efetivamente, siga estes passos:

1. **Instale as Depend√™ncias**: Instale os pacotes necess√°rios usando o comando acima.
2. **Configure as Credenciais AWS**: Defina suas credenciais AWS como vari√°veis de ambiente.
3. **Inicialize a Ferramenta**: Crie uma inst√¢ncia da ferramenta.
4. **Especifique o Caminho S3**: Forne√ßa o caminho S3 do arquivo que deseja ler.

## Exemplo

O exemplo a seguir demonstra como utilizar o `S3ReaderTool` para ler um arquivo de um bucket S3:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools.aws.s3 import S3ReaderTool

# Initialize the tool
s3_reader_tool = S3ReaderTool()

# Define an agent that uses the tool
file_reader_agent = Agent(
    role="File Reader",
    goal="Read files from S3 buckets",
    backstory="An expert in retrieving and processing files from cloud storage.",
    tools=[s3_reader_tool],
    verbose=True,
)

# Example task to read a configuration file
read_task = Task(
    description="Read the configuration file from {my_bucket} and summarize its contents.",
    expected_output="A summary of the configuration file contents.",
    agent=file_reader_agent,
)

# Create and run the crew
crew = Crew(agents=[file_reader_agent], tasks=[read_task])
result = crew.kickoff(inputs={"my_bucket": "s3://my-bucket/config/app-config.json"})
```

## Par√¢metros

O `S3ReaderTool` aceita o seguinte par√¢metro quando utilizado por um agente:

* **file\_path**: Obrigat√≥rio. O caminho do arquivo S3 no formato `s3://nome-do-bucket/nome-do-arquivo`.

## Credenciais AWS

A ferramenta requer credenciais AWS para acessar buckets S3. Voc√™ pode configurar essas credenciais usando vari√°veis de ambiente:

* **CREW\_AWS\_REGION**: Regi√£o AWS onde seu bucket S3 est√° localizado. O padr√£o √© `us-east-1`.
* **CREW\_AWS\_ACCESS\_KEY\_ID**: Sua AWS access key ID.
* **CREW\_AWS\_SEC\_ACCESS\_KEY**: Sua AWS secret access key.

## Uso

Ao utilizar o `S3ReaderTool` com um agente, o agente dever√° fornecer o caminho do arquivo S3:

```python Code
# Example of using the tool with an agent
file_reader_agent = Agent(
    role="File Reader",
    goal="Read files from S3 buckets",
    backstory="An expert in retrieving and processing files from cloud storage.",
    tools=[s3_reader_tool],
    verbose=True,
)

# Create a task for the agent to read a specific file
read_config_task = Task(
    description="Read the application configuration file from {my_bucket} and extract the database connection settings.",
    expected_output="The database connection settings from the configuration file.",
    agent=file_reader_agent,
)

# Run the task
crew = Crew(agents=[file_reader_agent], tasks=[read_config_task])
result = crew.kickoff(inputs={"my_bucket": "s3://my-bucket/config/app-config.json"})
```

## Tratamento de Erros

O `S3ReaderTool` inclui tratamento para erros comuns do S3:

* Formato inv√°lido de caminho S3
* Arquivos ausentes ou inacess√≠veis
* Problemas de permiss√£o
* Problemas com credenciais AWS

Quando um erro ocorre, a ferramenta retorna uma mensagem de erro com detalhes sobre o problema.

## Detalhes da Implementa√ß√£o

O `S3ReaderTool` utiliza o AWS SDK for Python (boto3) para interagir com o S3:

```python Code
class S3ReaderTool(BaseTool):
    name: str = "S3 Reader Tool"
    description: str = "Reads a file from Amazon S3 given an S3 file path"

    def _run(self, file_path: str) -> str:
        try:
            bucket_name, object_key = self._parse_s3_path(file_path)

            s3 = boto3.client(
                's3',
                region_name=os.getenv('CREW_AWS_REGION', 'us-east-1'),
                aws_access_key_id=os.getenv('CREW_AWS_ACCESS_KEY_ID'),
                aws_secret_access_key=os.getenv('CREW_AWS_SEC_ACCESS_KEY')
            )

            # Read file content from S3
            response = s3.get_object(Bucket=bucket_name, Key=object_key)
            file_content = response['Body'].read().decode('utf-8')

            return file_content
        except ClientError as e:
            return f"Error reading file from S3: {str(e)}"
```

## Conclus√£o

O `S3ReaderTool` oferece uma maneira simples de ler arquivos de buckets Amazon S3. Ao permitir que agentes acessem conte√∫dos armazenados no S3, facilita fluxos de trabalho que necessitam de acesso a arquivos na nuvem. Esta ferramenta √© especialmente √∫til para processamento de dados, gest√£o de configura√ß√µes e qualquer tarefa que envolva a obten√ß√£o de informa√ß√µes do armazenamento AWS S3.


# Ferramenta S3 Writer
Source: https://docs.crewai.com/pt-BR/tools/cloud-storage/s3writertool

A `S3WriterTool` permite que agentes CrewAI escrevam conte√∫do em arquivos em buckets Amazon S3.

# `S3WriterTool`

## Descri√ß√£o

A `S3WriterTool` foi projetada para escrever conte√∫do em arquivos em buckets Amazon S3. Esta ferramenta permite que agentes CrewAI criem ou atualizem arquivos no S3, tornando-a ideal para fluxos de trabalho que exigem armazenamento de dados, salvamento de arquivos de configura√ß√£o ou persist√™ncia de qualquer outro conte√∫do no armazenamento AWS S3.

## Instala√ß√£o

Para usar esta ferramenta, voc√™ precisa instalar as depend√™ncias necess√°rias:

```shell
uv add boto3
```

## Passos para Come√ßar

Para usar a `S3WriterTool` de forma eficaz, siga estes passos:

1. **Instale as Depend√™ncias**: Instale os pacotes necess√°rios usando o comando acima.
2. **Configure as Credenciais AWS**: Defina suas credenciais AWS como vari√°veis de ambiente.
3. **Inicialize a Ferramenta**: Crie uma inst√¢ncia da ferramenta.
4. **Especifique o Caminho no S3 e o Conte√∫do**: Forne√ßa o caminho no S3 onde deseja gravar o arquivo e o conte√∫do a ser escrito.

## Exemplo

O exemplo a seguir demonstra como usar a `S3WriterTool` para gravar conte√∫do em um arquivo em um bucket S3:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools.aws.s3 import S3WriterTool

# Initialize the tool
s3_writer_tool = S3WriterTool()

# Define an agent that uses the tool
file_writer_agent = Agent(
    role="File Writer",
    goal="Write content to files in S3 buckets",
    backstory="An expert in storing and managing files in cloud storage.",
    tools=[s3_writer_tool],
    verbose=True,
)

# Example task to write a report
write_task = Task(
    description="Generate a summary report of the quarterly sales data and save it to {my_bucket}.",
    expected_output="Confirmation that the report was successfully saved to S3.",
    agent=file_writer_agent,
)

# Create and run the crew
crew = Crew(agents=[file_writer_agent], tasks=[write_task])
result = crew.kickoff(inputs={"my_bucket": "s3://my-bucket/reports/quarterly-summary.txt"})
```

## Par√¢metros

A `S3WriterTool` aceita os seguintes par√¢metros quando utilizada por um agente:

* **file\_path**: Obrigat√≥rio. O caminho do arquivo S3 no formato `s3://bucket-name/file-name`.
* **content**: Obrigat√≥rio. O conte√∫do a ser escrito no arquivo.

## Credenciais AWS

A ferramenta requer credenciais AWS para acessar os buckets S3. Voc√™ pode configurar essas credenciais usando vari√°veis de ambiente:

* **CREW\_AWS\_REGION**: A regi√£o AWS onde seu bucket S3 est√° localizado. O padr√£o √© `us-east-1`.
* **CREW\_AWS\_ACCESS\_KEY\_ID**: Sua AWS access key ID.
* **CREW\_AWS\_SEC\_ACCESS\_KEY**: Sua AWS secret access key.

## Uso

Ao usar a `S3WriterTool` com um agente, o agente precisar√° fornecer tanto o caminho do arquivo no S3 quanto o conte√∫do a ser gravado:

```python Code
# Example of using the tool with an agent
file_writer_agent = Agent(
    role="File Writer",
    goal="Write content to files in S3 buckets",
    backstory="An expert in storing and managing files in cloud storage.",
    tools=[s3_writer_tool],
    verbose=True,
)

# Create a task for the agent to write a specific file
write_config_task = Task(
    description="""
    Create a configuration file with the following database settings:
    - host: db.example.com
    - port: 5432
    - username: app_user
    - password: secure_password

    Save this configuration as JSON to {my_bucket}.
    """,
    expected_output="Confirmation that the configuration file was successfully saved to S3.",
    agent=file_writer_agent,
)

# Run the task
crew = Crew(agents=[file_writer_agent], tasks=[write_config_task])
result = crew.kickoff(inputs={"my_bucket": "s3://my-bucket/config/db-config.json"})
```

## Tratamento de Erros

A `S3WriterTool` inclui tratamento de erros para problemas comuns no S3:

* Formato de caminho S3 inv√°lido
* Problemas de permiss√£o (ex: sem acesso de grava√ß√£o ao bucket)
* Problemas com credenciais AWS
* Bucket inexistente

Quando ocorre um erro, a ferramenta retorna uma mensagem de erro que inclui detalhes sobre o problema.

## Detalhes de Implementa√ß√£o

A `S3WriterTool` utiliza o AWS SDK para Python (boto3) para interagir com o S3:

```python Code
class S3WriterTool(BaseTool):
    name: str = "S3 Writer Tool"
    description: str = "Writes content to a file in Amazon S3 given an S3 file path"

    def _run(self, file_path: str, content: str) -> str:
        try:
            bucket_name, object_key = self._parse_s3_path(file_path)

            s3 = boto3.client(
                's3',
                region_name=os.getenv('CREW_AWS_REGION', 'us-east-1'),
                aws_access_key_id=os.getenv('CREW_AWS_ACCESS_KEY_ID'),
                aws_secret_access_key=os.getenv('CREW_AWS_SEC_ACCESS_KEY')
            )

            s3.put_object(Bucket=bucket_name, Key=object_key, Body=content.encode('utf-8'))
            return f"Successfully wrote content to {file_path}"
        except ClientError as e:
            return f"Error writing file to S3: {str(e)}"
```

## Conclus√£o

A `S3WriterTool` oferece uma maneira direta de gravar conte√∫do em arquivos em buckets Amazon S3. Ao permitir que agentes criem e atualizem arquivos no S3, ela facilita fluxos de trabalho que exigem armazenamento de arquivos em nuvem. Esta ferramenta √© particularmente √∫til para persist√™ncia de dados, gerenciamento de configura√ß√µes, gera√ß√£o de relat√≥rios e qualquer tarefa que envolva armazenar informa√ß√µes no AWS S3.


# Busca RAG no MySQL
Source: https://docs.crewai.com/pt-BR/tools/database-data/mysqltool

O `MySQLSearchTool` foi projetado para buscar em bancos de dados MySQL e retornar os resultados mais relevantes.

## Vis√£o Geral

Esta ferramenta foi desenvolvida para facilitar buscas sem√¢nticas em tabelas de bancos de dados MySQL. Utilizando a tecnologia RAG (Retrieve and Generate),
o MySQLSearchTool oferece aos usu√°rios um meio eficiente de consultar o conte√∫do de tabelas do banco de dados, especificamente adaptado para bancos MySQL.
Ela simplifica o processo de encontrar dados relevantes por meio de consultas de busca sem√¢ntica, tornando-se um recurso valioso para quem precisa
realizar consultas avan√ßadas em grandes conjuntos de dados dentro de um banco de dados MySQL.

## Instala√ß√£o

Para instalar o pacote `crewai_tools` e utilizar o MySQLSearchTool, execute o seguinte comando no seu terminal:

```shell
pip install 'crewai[tools]'
```

## Exemplo

Abaixo est√° um exemplo demonstrando como usar o MySQLSearchTool para realizar uma busca sem√¢ntica em uma tabela de um banco de dados MySQL:

```python Code
from crewai_tools import MySQLSearchTool

# Inicialize a ferramenta com o URI do banco de dados e o nome da tabela de destino
tool = MySQLSearchTool(
    db_uri='mysql://user:password@localhost:3306/mydatabase',
    table_name='employees'
)
```

## Argumentos

O MySQLSearchTool requer os seguintes argumentos para sua opera√ß√£o:

* `db_uri`: Uma string representando o URI do banco de dados MySQL a ser consultado. Este argumento √© obrigat√≥rio e deve incluir os detalhes de autentica√ß√£o necess√°rios e o local do banco de dados.
* `table_name`: Uma string especificando o nome da tabela dentro do banco de dados na qual ser√° realizada a busca sem√¢ntica. Este argumento √© obrigat√≥rio.

## Modelo e embeddings personalizados

Por padr√£o, a ferramenta utiliza o OpenAI tanto para embeddings quanto para sumariza√ß√£o. Para customizar o modelo, voc√™ pode usar um dicion√°rio de configura√ß√£o conforme o exemplo:

```python Code
tool = MySQLSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google",
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# NL2SQL Tool
Source: https://docs.crewai.com/pt-BR/tools/database-data/nl2sqltool

O `NL2SQLTool` foi projetado para converter linguagem natural em consultas SQL.

## Vis√£o Geral

Esta ferramenta √© utilizada para converter linguagem natural em consultas SQL. Quando passada para o agente, ela ir√° gerar as consultas e, em seguida, utiliz√°-las para interagir com o banco de dados.

Isso possibilita m√∫ltiplos fluxos de trabalho, como por exemplo ter um Agente acessando o banco de dados para buscar informa√ß√µes com base em um objetivo e, ent√£o, usar essas informa√ß√µes para gerar uma resposta, relat√≥rio ou qualquer outro tipo de sa√≠da. Al√©m disso, permite que o Agente atualize o banco de dados de acordo com seu objetivo.

**Aten√ß√£o**: Certifique-se de que o Agente tenha acesso a um Read-Replica ou que seja permitido que o Agente execute consultas de inser√ß√£o/atualiza√ß√£o no banco de dados.

## Requisitos

* SqlAlchemy
* Qualquer biblioteca compat√≠vel com o banco de dados (ex.: psycopg2, mysql-connector-python)

## Instala√ß√£o

Instale o pacote crewai\_tools

```shell
pip install 'crewai[tools]'
```

## Uso

Para utilizar o NL2SQLTool, voc√™ precisa passar a URI do banco de dados para a ferramenta. O formato da URI deve ser `dialect+driver://username:password@host:port/database`.

```python Code
from crewai_tools import NL2SQLTool

# psycopg2 foi instalado para rodar este exemplo com PostgreSQL
nl2sql = NL2SQLTool(db_uri="postgresql://example@localhost:5432/test_db")

@agent
def researcher(self) -> Agent:
    return Agent(
        config=self.agents_config["researcher"],
        allow_delegation=False,
        tools=[nl2sql]
    )
```

## Exemplo

O objetivo principal da tarefa era:

"Recupere a receita mensal m√©dia, m√°xima e m√≠nima para cada cidade, mas inclua apenas cidades que tenham mais de um usu√°rio. Al√©m disso, conte o n√∫mero de usu√°rios em cada cidade e classifique os resultados pela receita mensal m√©dia em ordem decrescente"

Assim, o Agente tentou obter informa√ß√µes do banco de dados; a primeira vez est√° errada, ent√£o o Agente tenta novamente, consegue a informa√ß√£o correta e repassa para o pr√≥ximo agente.

![alt text](https://github.com/crewAIInc/crewAI-tools/blob/main/crewai_tools/tools/nl2sql/images/image-2.png?raw=true)
![alt text](https://github.com/crewAIInc/crewAI-tools/raw/main/crewai_tools/tools/nl2sql/images/image-3.png)

O segundo objetivo da tarefa foi:

"Revise os dados e crie um relat√≥rio detalhado e, em seguida, crie a tabela no banco de dados com os campos baseados nos dados fornecidos. Inclua informa√ß√µes sobre a receita mensal m√©dia, m√°xima e m√≠nima para cada cidade, mas apenas inclua cidades que possuam mais de um usu√°rio. Tamb√©m conte o n√∫mero de usu√°rios em cada cidade e classifique os resultados pela receita mensal m√©dia em ordem decrescente."

Agora as coisas come√ßam a ficar interessantes: o Agente gera a consulta SQL n√£o s√≥ para criar a tabela, mas tamb√©m inserir os dados na tabela. E, ao final, o Agente ainda retorna o relat√≥rio final que condiz exatamente com o que estava no banco de dados.

![alt text](https://github.com/crewAIInc/crewAI-tools/raw/main/crewai_tools/tools/nl2sql/images/image-4.png)
![alt text](https://github.com/crewAIInc/crewAI-tools/raw/main/crewai_tools/tools/nl2sql/images/image-5.png)

![alt text](https://github.com/crewAIInc/crewAI-tools/raw/main/crewai_tools/tools/nl2sql/images/image-9.png)
![alt text](https://github.com/crewAIInc/crewAI-tools/raw/main/crewai_tools/tools/nl2sql/images/image-7.png)

Este √© um exemplo simples de como o NL2SQLTool pode ser utilizado para interagir com o banco de dados e gerar relat√≥rios baseados nos dados do banco.

A ferramenta oferece possibilidades infinitas para a l√≥gica do Agente e como ele pode interagir com o banco de dados.

```md
 DB -> Agent -> ... -> Agent -> DB
```


# Vis√£o Geral
Source: https://docs.crewai.com/pt-BR/tools/database-data/overview

Conecte-se a bancos de dados, armazenamentos vetoriais e data warehouses para acesso abrangente aos dados

Essas ferramentas permitem que seus agentes interajam com diversos sistemas de banco de dados, desde bancos de dados SQL tradicionais at√© armazenamentos vetoriais modernos e data warehouses.

## **Ferramentas Dispon√≠veis**

<CardGroup cols={2}>
  <Card title="MySQL Tool" icon="database" href="/pt-BR/tools/database-data/mysqltool">
    Conecte-se e fa√ßa consultas a bancos de dados MySQL com opera√ß√µes SQL.
  </Card>

  <Card title="PostgreSQL Search" icon="elephant" href="/pt-BR/tools/database-data/pgsearchtool">
    Pesquise e consulte bancos de dados PostgreSQL de forma eficiente.
  </Card>

  <Card title="Snowflake Search" icon="snowflake" href="/pt-BR/tools/database-data/snowflakesearchtool">
    Acesse o data warehouse Snowflake para an√°lises e relat√≥rios.
  </Card>

  <Card title="NL2SQL Tool" icon="language" href="/pt-BR/tools/database-data/nl2sqltool">
    Converta automaticamente consultas em linguagem natural para comandos SQL.
  </Card>

  <Card title="Qdrant Vector Search" icon="vector-square" href="/pt-BR/tools/database-data/qdrantvectorsearchtool">
    Pesquise embeddings vetoriais usando o banco de dados vetorial Qdrant.
  </Card>

  <Card title="Weaviate Vector Search" icon="network-wired" href="/pt-BR/tools/database-data/weaviatevectorsearchtool">
    Realize buscas sem√¢nticas com o banco de dados vetorial Weaviate.
  </Card>
</CardGroup>

## **Casos de Uso Comuns**

* **An√°lise de Dados**: Consulte bancos de dados para intelig√™ncia de neg√≥cios e relat√≥rios
* **Busca Vetorial**: Encontre conte√∫dos similares utilizando embeddings sem√¢nticos
* **Opera√ß√µes ETL**: Extraia, transforme e carregue dados entre sistemas
* **An√°lise em Tempo Real**: Acesse dados ao vivo para tomada de decis√µes

```python
from crewai_tools import MySQLTool, QdrantVectorSearchTool, NL2SQLTool

# Create database tools
mysql_db = MySQLTool()
vector_search = QdrantVectorSearchTool()
nl_to_sql = NL2SQLTool()

# Add to your agent
agent = Agent(
    role="Data Analyst",
    tools=[mysql_db, vector_search, nl_to_sql],
    goal="Extract insights from various data sources"
)
```


# PG RAG Search
Source: https://docs.crewai.com/pt-BR/tools/database-data/pgsearchtool

O `PGSearchTool` foi desenvolvido para pesquisar bancos de dados PostgreSQL e retornar os resultados mais relevantes.

## Vis√£o geral

<Note>
  O PGSearchTool est√° atualmente em desenvolvimento. Este documento descreve a funcionalidade e a interface pretendidas.
  Conforme o desenvolvimento avan√ßa, esteja ciente de que alguns recursos podem n√£o estar dispon√≠veis ou podem mudar.
</Note>

## Descri√ß√£o

O PGSearchTool √© concebido como uma ferramenta poderosa para facilitar buscas sem√¢nticas em tabelas de bancos de dados PostgreSQL. Aproveitando tecnologia avan√ßada de Recupera√ß√£o e Gera√ß√£o (RAG),
ele visa fornecer um meio eficiente para consultar o conte√∫do de tabelas de banco de dados, especificamente voltado para bancos de dados PostgreSQL.
O objetivo da ferramenta √© simplificar o processo de encontrar dados relevantes por meio de consultas sem√¢nticas, oferecendo um recurso valioso para usu√°rios que precisam realizar buscas avan√ßadas em
grandes volumes de dados dentro de um ambiente PostgreSQL.

## Instala√ß√£o

O pacote `crewai_tools`, que incluir√° o PGSearchTool assim que for lan√ßado, pode ser instalado usando o comando abaixo:

```shell
pip install 'crewai[tools]'
```

<Note>
  O PGSearchTool ainda n√£o est√° dispon√≠vel na vers√£o atual do pacote `crewai_tools`. Este comando de instala√ß√£o ser√° atualizado assim que a ferramenta for lan√ßada.
</Note>

## Exemplo de Uso

Abaixo est√° um exemplo proposto mostrando como utilizar o PGSearchTool para realizar uma busca sem√¢ntica em uma tabela dentro de um banco de dados PostgreSQL:

```python Code
from crewai_tools import PGSearchTool

# Inicialize a ferramenta com a URI do banco de dados e o nome da tabela alvo
tool = PGSearchTool(
    db_uri='postgresql://user:password@localhost:5432/mydatabase',
    table_name='employees'
)
```

## Argumentos

O PGSearchTool foi projetado para exigir os seguintes argumentos para seu funcionamento:

| Argumento       | Tipo     | Descri√ß√£o                                                                                                                                                                                                                 |
| :-------------- | :------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **db\_uri**     | `string` | **Obrigat√≥rio**. Uma string que representa a URI do banco de dados PostgreSQL a ser consultado. Este argumento ser√° obrigat√≥rio e deve incluir os detalhes necess√°rios de autentica√ß√£o e a localiza√ß√£o do banco de dados. |
| **table\_name** | `string` | **Obrigat√≥rio**. Uma string que especifica o nome da tabela dentro do banco de dados na qual a busca sem√¢ntica ser√° realizada. Este argumento tamb√©m ser√° obrigat√≥rio.                                                    |

## Modelo Personalizado e Embeddings

A ferramenta pretende usar OpenAI tanto para embeddings quanto para sumariza√ß√£o por padr√£o. Os usu√°rios ter√£o a op√ß√£o de personalizar o modelo usando um dicion√°rio de configura√ß√£o, conforme mostrado abaixo:

```python Code
tool = PGSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Qdrant Vector Search Tool
Source: https://docs.crewai.com/pt-BR/tools/database-data/qdrantvectorsearchtool

Capacidades de busca sem√¢ntica para agentes CrewAI usando o banco de dados vetorial Qdrant

## Vis√£o Geral

A ferramenta Qdrant Vector Search permite adicionar capacidades de busca sem√¢ntica aos seus agentes CrewAI utilizando o [Qdrant](https://qdrant.tech/), um mecanismo de busca por similaridade vetorial. Com essa ferramenta, seus agentes podem pesquisar em documentos armazenados em uma cole√ß√£o Qdrant usando similaridade sem√¢ntica.

## Instala√ß√£o

Instale os pacotes necess√°rios:

```bash
uv add qdrant-client
```

## Uso B√°sico

Veja um exemplo m√≠nimo de como utilizar a ferramenta:

```python
from crewai import Agent
from crewai_tools import QdrantVectorSearchTool

# Inicialize a ferramenta
qdrant_tool = QdrantVectorSearchTool(
    qdrant_url="your_qdrant_url",
    qdrant_api_key="your_qdrant_api_key",
    collection_name="your_collection"
)

# Crie um agente que utiliza a ferramenta
agent = Agent(
    role="Research Assistant",
    goal="Find relevant information in documents",
    tools=[qdrant_tool]
)

# A ferramenta usar√° automaticamente embeddings da OpenAI
# e retornar√° os 3 resultados mais relevantes com pontua√ß√£o > 0.35
```

## Exemplo Completo e Funcional

Veja um exemplo completo mostrando como:

1. Extrair texto de um PDF
2. Gerar embeddings usando OpenAI
3. Armazenar no Qdrant
4. Criar um fluxo de trabalho RAG agente CrewAI para busca sem√¢ntica

```python
import os
import uuid
import pdfplumber
from openai import OpenAI
from dotenv import load_dotenv
from crewai import Agent, Task, Crew, Process, LLM
from crewai_tools import QdrantVectorSearchTool
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct, Distance, VectorParams

# Carregar vari√°veis de ambiente
load_dotenv()

# Inicializar cliente OpenAI
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Extrair texto do PDF
def extract_text_from_pdf(pdf_path):
    text = []
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text.append(page_text.strip())
    return text

# Gerar embeddings da OpenAI
def get_openai_embedding(text):
    response = client.embeddings.create(
        input=text,
        model="text-embedding-3-small"
    )
    return response.data[0].embedding

# Armazenar texto e embeddings no Qdrant
def load_pdf_to_qdrant(pdf_path, qdrant, collection_name):
    # Extrair texto do PDF
    text_chunks = extract_text_from_pdf(pdf_path)

    # Criar cole√ß√£o no Qdrant
    if qdrant.collection_exists(collection_name):
        qdrant.delete_collection(collection_name)
    qdrant.create_collection(
        collection_name=collection_name,
        vectors_config=VectorParams(size=1536, distance=Distance.COSINE)
    )

    # Armazenar embeddings
    points = []
    for chunk in text_chunks:
        embedding = get_openai_embedding(chunk)
        points.append(PointStruct(
            id=str(uuid.uuid4()),
            vector=embedding,
            payload={"text": chunk}
        ))
    qdrant.upsert(collection_name=collection_name, points=points)

# Inicializar cliente Qdrant e carregar dados
qdrant = QdrantClient(
    url=os.getenv("QDRANT_URL"),
    api_key=os.getenv("QDRANT_API_KEY")
)
collection_name = "example_collection"
pdf_path = "path/to/your/document.pdf"
load_pdf_to_qdrant(pdf_path, qdrant, collection_name)

# Inicializar ferramenta de busca Qdrant
qdrant_tool = QdrantVectorSearchTool(
    qdrant_url=os.getenv("QDRANT_URL"),
    qdrant_api_key=os.getenv("QDRANT_API_KEY"),
    collection_name=collection_name,
    limit=3,
    score_threshold=0.35
)

# Criar agentes CrewAI
search_agent = Agent(
    role="Senior Semantic Search Agent",
    goal="Find and analyze documents based on semantic search",
    backstory="""You are an expert research assistant who can find relevant
    information using semantic search in a Qdrant database.""",
    tools=[qdrant_tool],
    verbose=True
)

answer_agent = Agent(
    role="Senior Answer Assistant",
    goal="Generate answers to questions based on the context provided",
    backstory="""You are an expert answer assistant who can generate
    answers to questions based on the context provided.""",
    tools=[qdrant_tool],
    verbose=True
)

# Definir tarefas
search_task = Task(
    description="""Search for relevant documents about the {query}.
    Your final answer should include:
    - The relevant information found
    - The similarity scores of the results
    - The metadata of the relevant documents""",
    agent=search_agent
)

answer_task = Task(
    description="""Given the context and metadata of relevant documents,
    generate a final answer based on the context.""",
    agent=answer_agent
)

# Executar fluxo CrewAI
crew = Crew(
    agents=[search_agent, answer_agent],
    tasks=[search_task, answer_task],
    process=Process.sequential,
    verbose=True
)

result = crew.kickoff(
    inputs={"query": "What is the role of X in the document?"}
)
print(result)
```

## Par√¢metros da Ferramenta

### Par√¢metros Obrigat√≥rios

* `qdrant_url` (str): URL do seu servidor Qdrant
* `qdrant_api_key` (str): Chave de API para autentica√ß√£o com o Qdrant
* `collection_name` (str): Nome da cole√ß√£o Qdrant a ser pesquisada

### Par√¢metros Opcionais

* `limit` (int): N√∫mero m√°ximo de resultados a serem retornados (padr√£o: 3)
* `score_threshold` (float): Limite m√≠nimo de similaridade (padr√£o: 0.35)
* `custom_embedding_fn` (Callable\[\[str], list\[float]]): Fun√ß√£o personalizada para vetoriza√ß√£o de textos

## Par√¢metros de Busca

A ferramenta aceita estes par√¢metros em seu schema:

* `query` (str): Consulta de busca para encontrar documentos similares
* `filter_by` (str, opcional): Campo de metadado para filtrar
* `filter_value` (str, opcional): Valor para filtrar

## Formato de Retorno

A ferramenta retorna resultados no formato JSON:

```json
[
  {
    "metadata": {
      // Todos os metadados armazenados junto com o documento
    },
    "context": "O conte√∫do textual real do documento",
    "distance": 0.95  // Pontua√ß√£o de similaridade
  }
]
```

## Embedding Padr√£o

Por padr√£o, a ferramenta utiliza o modelo `text-embedding-3-small` da OpenAI para vetoriza√ß√£o. Isso requer:

* Chave de API da OpenAI definida na vari√°vel de ambiente: `OPENAI_API_KEY`

## Embeddings Personalizados

Em vez de utilizar o modelo padr√£o de embeddings, voc√™ pode utilizar sua pr√≥pria fun√ß√£o de embeddings nos casos em que:

1. Deseja usar um modelo de embeddings diferente (ex: Cohere, HuggingFace, modelos Ollama)
2. Precisa reduzir custos utilizando modelos de c√≥digo aberto
3. Tem requisitos espec√≠ficos quanto √† dimens√£o dos vetores ou √† qualidade dos embeddings
4. Deseja utilizar embeddings espec√≠ficos para determinado dom√≠nio (ex: textos m√©dicos ou jur√≠dicos)

Veja um exemplo utilizando um modelo HuggingFace:

```python
from transformers import AutoTokenizer, AutoModel
import torch

# Carregar modelo e tokenizer
tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')
model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')

def custom_embeddings(text: str) -> list[float]:
    # Tokenizar e obter sa√≠das do modelo
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True)
    outputs = model(**inputs)

    # Usar mean pooling para obter o embedding do texto
    embeddings = outputs.last_hidden_state.mean(dim=1)

    # Converter para lista de floats e retornar
    return embeddings[0].tolist()

# Usar embeddings personalizados com a ferramenta
tool = QdrantVectorSearchTool(
    qdrant_url="your_url",
    qdrant_api_key="your_key",
    collection_name="your_collection",
    custom_embedding_fn=custom_embeddings  # Passe sua fun√ß√£o personalizada
)
```

## Tratamento de Erros

A ferramenta trata os seguintes erros espec√≠ficos:

* Lan√ßa ImportError se `qdrant-client` n√£o estiver instalado (com op√ß√£o de instalar automaticamente)
* Lan√ßa ValueError se `QDRANT_URL` n√£o estiver definido
* Solicita instala√ß√£o de `qdrant-client` se estiver ausente utilizando `uv add qdrant-client`

## Vari√°veis de Ambiente

Vari√°veis de ambiente obrigat√≥rias:

```bash
export QDRANT_URL="your_qdrant_url"  # Se n√£o for informado no construtor
export QDRANT_API_KEY="your_api_key"  # Se n√£o for informado no construtor
export OPENAI_API_KEY="your_openai_key"  # Se estiver usando embeddings padr√£o
```


# Snowflake Search Tool
Source: https://docs.crewai.com/pt-BR/tools/database-data/snowflakesearchtool

O `SnowflakeSearchTool` permite que agentes CrewAI executem consultas SQL e realizem buscas sem√¢nticas em data warehouses Snowflake.

# `SnowflakeSearchTool`

## Descri√ß√£o

O `SnowflakeSearchTool` foi desenvolvido para conectar-se a data warehouses Snowflake e executar consultas SQL com recursos avan√ßados como pool de conex√µes, l√≥gica de tentativas e execu√ß√£o ass√≠ncrona. Esta ferramenta permite que agentes CrewAI interajam com bases de dados Snowflake, sendo ideal para tarefas de an√°lise de dados, relat√≥rios e intelig√™ncia de neg√≥cios que requerem acesso a dados empresariais armazenados no Snowflake.

## Instala√ß√£o

Para utilizar esta ferramenta, √© necess√°rio instalar as depend√™ncias requeridas:

```shell
uv add cryptography snowflake-connector-python snowflake-sqlalchemy
```

Ou, alternativamente:

```shell
uv sync --extra snowflake
```

## Passos para Come√ßar

Para usar eficazmente o `SnowflakeSearchTool`, siga estes passos:

1. **Instale as Depend√™ncias**: Instale os pacotes necess√°rios usando um dos comandos acima.
2. **Configure a Conex√£o com o Snowflake**: Crie um objeto `SnowflakeConfig` com suas credenciais do Snowflake.
3. **Inicialize a Ferramenta**: Crie uma inst√¢ncia da ferramenta com a configura√ß√£o necess√°ria.
4. **Execute Consultas**: Utilize a ferramenta para rodar consultas SQL no seu banco de dados Snowflake.

## Exemplo

O exemplo a seguir demonstra como usar o `SnowflakeSearchTool` para consultar dados de um banco de dados Snowflake:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import SnowflakeSearchTool, SnowflakeConfig

# Create Snowflake configuration
config = SnowflakeConfig(
    account="your_account",
    user="your_username",
    password="your_password",
    warehouse="COMPUTE_WH",
    database="your_database",
    snowflake_schema="your_schema"
)

# Initialize the tool
snowflake_tool = SnowflakeSearchTool(config=config)

# Define an agent that uses the tool
data_analyst_agent = Agent(
    role="Data Analyst",
    goal="Analyze data from Snowflake database",
    backstory="An expert data analyst who can extract insights from enterprise data.",
    tools=[snowflake_tool],
    verbose=True,
)

# Example task to query sales data
query_task = Task(
    description="Query the sales data for the last quarter and summarize the top 5 products by revenue.",
    expected_output="A summary of the top 5 products by revenue for the last quarter.",
    agent=data_analyst_agent,
)

# Create and run the crew
crew = Crew(agents=[data_analyst_agent],
            tasks=[query_task])
result = crew.kickoff()
```

Voc√™ tamb√©m pode customizar a ferramenta com par√¢metros adicionais:

```python Code
# Initialize the tool with custom parameters
snowflake_tool = SnowflakeSearchTool(
    config=config,
    pool_size=10,
    max_retries=5,
    retry_delay=2.0,
    enable_caching=True
)
```

## Par√¢metros

### Par√¢metros do SnowflakeConfig

A classe `SnowflakeConfig` aceita os seguintes par√¢metros:

* **account**: Obrigat√≥rio. Identificador da conta Snowflake.
* **user**: Obrigat√≥rio. Nome de usu√°rio do Snowflake.
* **password**: Opcional\*. Senha do Snowflake.
* **private\_key\_path**: Opcional\*. Caminho para o arquivo de chave privada (alternativa √† senha).
* **warehouse**: Obrigat√≥rio. Nome do warehouse do Snowflake.
* **database**: Obrigat√≥rio. Banco de dados padr√£o.
* **snowflake\_schema**: Obrigat√≥rio. Schema padr√£o.
* **role**: Opcional. Papel de usu√°rio Snowflake.
* **session\_parameters**: Opcional. Par√¢metros de sess√£o personalizados como dicion√°rio.

\*√â necess√°rio fornecer `password` ou `private_key_path`.

### Par√¢metros do SnowflakeSearchTool

O `SnowflakeSearchTool` aceita os seguintes par√¢metros durante a inicializa√ß√£o:

* **config**: Obrigat√≥rio. Um objeto `SnowflakeConfig` contendo detalhes da conex√£o.
* **pool\_size**: Opcional. N√∫mero de conex√µes no pool. O padr√£o √© 5.
* **max\_retries**: Opcional. N√∫mero m√°ximo de tentativas para consultas que falharem. Padr√£o √© 3.
* **retry\_delay**: Opcional. Intervalo entre tentativas em segundos. Padr√£o √© 1.0.
* **enable\_caching**: Opcional. Define se o cache de resultados de consultas ser√° habilitado. Padr√£o √© True.

## Uso

Ao utilizar o `SnowflakeSearchTool`, voc√™ deve fornecer os seguintes par√¢metros:

* **query**: Obrigat√≥rio. Consulta SQL a ser executada.
* **database**: Opcional. Sobrescreve o banco de dados padr√£o especificado na configura√ß√£o.
* **snowflake\_schema**: Opcional. Sobrescreve o schema padr√£o especificado na configura√ß√£o.
* **timeout**: Opcional. Tempo limite da consulta em segundos. O padr√£o √© 300.

A ferramenta retornar√° os resultados da consulta como uma lista de dicion√°rios, onde cada dicion√°rio representa uma linha com os nomes das colunas como chaves.

```python Code
# Example of using the tool with an agent
data_analyst = Agent(
    role="Data Analyst",
    goal="Analyze sales data from Snowflake",
    backstory="An expert data analyst with experience in SQL and data visualization.",
    tools=[snowflake_tool],
    verbose=True
)

# The agent will use the tool with parameters like:
# query="SELECT product_name, SUM(revenue) as total_revenue FROM sales GROUP BY product_name ORDER BY total_revenue DESC LIMIT 5"
# timeout=600

# Create a task for the agent
analysis_task = Task(
    description="Query the sales database and identify the top 5 products by revenue for the last quarter.",
    expected_output="A detailed analysis of the top 5 products by revenue.",
    agent=data_analyst
)

# Run the task
crew = Crew(
    agents=[data_analyst],
    tasks=[analysis_task]
)
result = crew.kickoff()
```

## Recursos Avan√ßados

### Pool de Conex√µes

O `SnowflakeSearchTool` implementa pool de conex√µes para melhorar a performance reutilizando conex√µes com o banco de dados. Voc√™ pode controlar o tamanho do pool com o par√¢metro `pool_size`.

### Tentativas Autom√°ticas

A ferramenta tenta novamente consultas que falharem automaticamente, usando backoff exponencial. O comportamento das tentativas pode ser ajustado pelos par√¢metros `max_retries` e `retry_delay`.

### Cache de Resultados de Consultas

Para melhorar a performance em consultas repetidas, a ferramenta pode armazenar resultados em cache. Este recurso est√° habilitado por padr√£o, mas pode ser desativado ao definir `enable_caching=False`.

### Autentica√ß√£o por Par de Chaves

Al√©m de autentica√ß√£o por senha, a ferramenta tamb√©m suporta autentica√ß√£o por par de chaves para maior seguran√ßa:

```python Code
config = SnowflakeConfig(
    account="your_account",
    user="your_username",
    private_key_path="/path/to/your/private/key.p8",
    warehouse="COMPUTE_WH",
    database="your_database",
    snowflake_schema="your_schema"
)
```

## Tratamento de Erros

O `SnowflakeSearchTool` inclui uma gest√£o abrangente de erros para situa√ß√µes comuns no Snowflake:

* Falhas de conex√£o
* Timeout de consultas
* Erros de autentica√ß√£o
* Erros de banco de dados e schema

Quando um erro ocorrer, a ferramenta tentar√° repetir a opera√ß√£o (se estiver configurado) e fornecer√° informa√ß√µes detalhadas sobre o erro.

## Conclus√£o

O `SnowflakeSearchTool` oferece uma maneira poderosa de integrar data warehouses Snowflake com agentes CrewAI. Com recursos como pool de conex√µes, tentativas autom√°ticas e cache de consultas, ele possibilita acesso eficiente e confi√°vel aos dados empresariais. Esta ferramenta √© particularmente √∫til para tarefas de an√°lise de dados, relat√≥rios e intelig√™ncia de neg√≥cios que demandam acesso a dados estruturados armazenados no Snowflake.


# Busca Vetorial Weaviate
Source: https://docs.crewai.com/pt-BR/tools/database-data/weaviatevectorsearchtool

O `WeaviateVectorSearchTool` foi projetado para buscar documentos semanticamente similares em um banco de dados vetorial Weaviate.

## Vis√£o Geral

O `WeaviateVectorSearchTool` foi especificamente desenvolvido para realizar buscas sem√¢nticas em documentos armazenados em um banco de dados vetorial Weaviate. Essa ferramenta permite encontrar documentos semanticamente similares a uma determinada consulta, aproveitando o poder das embeddings vetoriais para resultados de busca mais precisos e contextualmente relevantes.

[Weaviate](https://weaviate.io/) √© um banco de dados vetorial que armazena e consulta embeddings vetoriais, possibilitando recursos de busca sem√¢ntica.

## Instala√ß√£o

Para incorporar esta ferramenta ao seu projeto, √© necess√°rio instalar o cliente Weaviate:

```shell
uv add weaviate-client
```

## Etapas para Come√ßar

Para utilizar efetivamente o `WeaviateVectorSearchTool`, siga as etapas abaixo:

1. **Instala√ß√£o dos Pacotes**: Confirme que os pacotes `crewai[tools]` e `weaviate-client` est√£o instalados em seu ambiente Python.
2. **Configura√ß√£o do Weaviate**: Configure um cluster Weaviate. Voc√™ pode seguir as instru√ß√µes na [documenta√ß√£o do Weaviate](https://weaviate.io/developers/wcs/manage-clusters/connect).
3. **Chaves de API**: Obtenha a URL do seu cluster Weaviate e a chave de API correspondente.
4. **Chave de API da OpenAI**: Certifique-se de que voc√™ tenha uma chave de API da OpenAI definida nas vari√°veis de ambiente como `OPENAI_API_KEY`.

## Exemplo

O exemplo a seguir demonstra como inicializar a ferramenta e executar uma busca:

```python Code
from crewai_tools import WeaviateVectorSearchTool

# Inicializar a ferramenta
tool = WeaviateVectorSearchTool(
    collection_name='example_collections',
    limit=3,
    weaviate_cluster_url="https://your-weaviate-cluster-url.com",
    weaviate_api_key="your-weaviate-api-key",
)

@agent
def search_agent(self) -> Agent:
    '''
    Este agente utiliza o WeaviateVectorSearchTool para buscar
    documentos semanticamente similares em um banco de dados vetorial Weaviate.
    '''
    return Agent(
        config=self.agents_config["search_agent"],
        tools=[tool]
    )
```

## Par√¢metros

O `WeaviateVectorSearchTool` aceita os seguintes par√¢metros:

* **collection\_name**: Obrigat√≥rio. O nome da cole√ß√£o a ser pesquisada.
* **weaviate\_cluster\_url**: Obrigat√≥rio. A URL do cluster Weaviate.
* **weaviate\_api\_key**: Obrigat√≥rio. A chave de API para o cluster Weaviate.
* **limit**: Opcional. O n√∫mero de resultados a serem retornados. O padr√£o √© `3`.
* **vectorizer**: Opcional. O vetorizador a ser utilizado. Se n√£o for informado, ser√° utilizado o `text2vec_openai` com o modelo `nomic-embed-text`.
* **generative\_model**: Opcional. O modelo generativo a ser utilizado. Se n√£o for informado, ser√° utilizado o `gpt-4o` da OpenAI.

## Configura√ß√£o Avan√ßada

Voc√™ pode personalizar o vetorizador e o modelo generativo utilizados pela ferramenta:

```python Code
from crewai_tools import WeaviateVectorSearchTool
from weaviate.classes.config import Configure

# Configurar modelo personalizado para vetorizador e modelo generativo
tool = WeaviateVectorSearchTool(
    collection_name='example_collections',
    limit=3,
    vectorizer=Configure.Vectorizer.text2vec_openai(model="nomic-embed-text"),
    generative_model=Configure.Generative.openai(model="gpt-4o-mini"),
    weaviate_cluster_url="https://your-weaviate-cluster-url.com",
    weaviate_api_key="your-weaviate-api-key",
)
```

## Pr√©-carregando Documentos

Voc√™ pode pr√©-carregar seu banco de dados Weaviate com documentos antes de utilizar a ferramenta:

```python Code
import os
from crewai_tools import WeaviateVectorSearchTool
import weaviate
from weaviate.classes.init import Auth

# Conectar ao Weaviate
client = weaviate.connect_to_weaviate_cloud(
    cluster_url="https://your-weaviate-cluster-url.com",
    auth_credentials=Auth.api_key("your-weaviate-api-key"),
    headers={"X-OpenAI-Api-Key": "your-openai-api-key"}
)

# Obter ou criar cole√ß√£o
test_docs = client.collections.get("example_collections")
if not test_docs:
    test_docs = client.collections.create(
        name="example_collections",
        vectorizer_config=Configure.Vectorizer.text2vec_openai(model="nomic-embed-text"),
        generative_config=Configure.Generative.openai(model="gpt-4o"),
    )

# Carregar documentos
docs_to_load = os.listdir("knowledge")
with test_docs.batch.dynamic() as batch:
    for d in docs_to_load:
        with open(os.path.join("knowledge", d), "r") as f:
            content = f.read()
        batch.add_object(
            {
                "content": content,
                "year": d.split("_")[0],
            }
        )

# Inicializar a ferramenta
tool = WeaviateVectorSearchTool(
    collection_name='example_collections',
    limit=3,
    weaviate_cluster_url="https://your-weaviate-cluster-url.com",
    weaviate_api_key="your-weaviate-api-key",
)
```

## Exemplo de Integra√ß√£o com Agente

Veja como integrar o `WeaviateVectorSearchTool` com um agente CrewAI:

```python Code
from crewai import Agent
from crewai_tools import WeaviateVectorSearchTool

# Inicializar a ferramenta
weaviate_tool = WeaviateVectorSearchTool(
    collection_name='example_collections',
    limit=3,
    weaviate_cluster_url="https://your-weaviate-cluster-url.com",
    weaviate_api_key="your-weaviate-api-key",
)

# Criar um agente com a ferramenta
rag_agent = Agent(
    name="rag_agent",
    role="Voc√™ √© um assistente √∫til que pode responder perguntas com a ajuda do WeaviateVectorSearchTool.",
    llm="gpt-4o-mini",
    tools=[weaviate_tool],
)
```

## Conclus√£o

O `WeaviateVectorSearchTool` fornece uma maneira poderosa de buscar documentos semanticamente similares em um banco de dados vetorial Weaviate. Ao utilizar embeddings vetoriais, ele permite resultados de busca mais precisos e relevantes em termos de contexto, quando comparado a buscas tradicionais baseadas em palavras-chave. Essa ferramenta √© especialmente √∫til para aplica√ß√µes que precisam encontrar informa√ß√µes a partir do significado e n√£o apenas de correspond√™ncias exatas.


# Busca RAG em CSV
Source: https://docs.crewai.com/pt-BR/tools/file-document/csvsearchtool

O `CSVSearchTool` √© uma poderosa ferramenta RAG (Gera√ß√£o com Recupera√ß√£o Aprimorada) projetada para buscas sem√¢nticas no conte√∫do de arquivos CSV.

# `CSVSearchTool`

<Note>
  **Experimental**: Ainda estamos trabalhando na melhoria das ferramentas, portanto podem ocorrer comportamentos inesperados ou mudan√ßas futuras.
</Note>

## Descri√ß√£o

Esta ferramenta √© utilizada para realizar buscas RAG (Gera√ß√£o com Recupera√ß√£o Aprimorada) no conte√∫do de um arquivo CSV. Ela permite que usu√°rios fa√ßam buscas sem√¢nticas por consultas no conte√∫do de um arquivo CSV especificado.
Este recurso √© particularmente √∫til para extrair informa√ß√µes de grandes datasets CSV, em que m√©todos de busca tradicionais poderiam ser ineficientes. Todas as ferramentas com "Search" no nome, incluindo o CSVSearchTool,
s√£o ferramentas RAG projetadas para busca em diferentes fontes de dados.

## Instala√ß√£o

Instale o pacote crewai\_tools

```shell
pip install 'crewai[tools]'
```

## Exemplo

```python Code
from crewai_tools import CSVSearchTool

# Inicialize a ferramenta com um arquivo CSV espec√≠fico.
# Esta configura√ß√£o permite que o agente busque somente no arquivo CSV fornecido.
tool = CSVSearchTool(csv='path/to/your/csvfile.csv')

# OU

# Inicialize a ferramenta sem um arquivo CSV espec√≠fico.
# O agente precisar√° informar o caminho do CSV em tempo de execu√ß√£o.
tool = CSVSearchTool()
```

## Argumentos

Os seguintes par√¢metros podem ser utilizados para personalizar o comportamento do `CSVSearchTool`:

| Argumento | Tipo     | Descri√ß√£o                                                                                                                                                                                    |
| :-------- | :------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **csv**   | `string` | *Opcional*. O caminho para o arquivo CSV que voc√™ deseja buscar. Este √© um argumento obrigat√≥rio se a ferramenta for inicializada sem um arquivo CSV espec√≠fico; caso contr√°rio, √© opcional. |

## Modelo e embeddings personalizados

Por padr√£o, a ferramenta utiliza OpenAI tanto para embeddings quanto para sumariza√ß√£o. Para personalizar o modelo, voc√™ pode usar um dicion√°rio de configura√ß√£o como segue:

```python Code
tool = CSVSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Leitura de Diret√≥rio
Source: https://docs.crewai.com/pt-BR/tools/file-document/directoryreadtool

O `DirectoryReadTool` √© uma poderosa utilidade projetada para fornecer uma listagem abrangente do conte√∫do de diret√≥rios.

# `DirectoryReadTool`

<Note>
  Ainda estamos trabalhando para melhorar as ferramentas, ent√£o pode haver comportamentos inesperados ou altera√ß√µes no futuro.
</Note>

## Descri√ß√£o

O DirectoryReadTool √© uma poderosa utilidade projetada para fornecer uma listagem abrangente do conte√∫do de diret√≥rios.
Ele pode navegar recursivamente pelo diret√≥rio especificado, oferecendo aos usu√°rios uma enumera√ß√£o detalhada de todos os arquivos, incluindo aqueles que est√£o dentro de subdiret√≥rios.
Essa ferramenta √© fundamental para tarefas que exigem um invent√°rio completo das estruturas de diret√≥rios ou para validar a organiza√ß√£o de arquivos em diret√≥rios.

## Instala√ß√£o

Para utilizar o DirectoryReadTool em seu projeto, instale o pacote `crewai_tools`. Se este pacote ainda n√£o faz parte do seu ambiente, voc√™ pode instal√°-lo usando o pip com o comando abaixo:

```shell
pip install 'crewai[tools]'
```

Esse comando instala a vers√£o mais recente do pacote `crewai_tools`, permitindo o acesso ao DirectoryReadTool, entre outras utilidades.

## Exemplo

Empregar o DirectoryReadTool √© simples. O snippet de c√≥digo a seguir demonstra como configur√°-lo e usar a ferramenta para listar o conte√∫do de um diret√≥rio especificado:

```python Code
from crewai_tools import DirectoryReadTool

# Initialize the tool so the agent can read any directory's content
# it learns about during execution
tool = DirectoryReadTool()

# OR

# Initialize the tool with a specific directory,
# so the agent can only read the content of the specified directory
tool = DirectoryReadTool(directory='/path/to/your/directory')
```

## Argumentos

Os seguintes par√¢metros podem ser usados para personalizar o comportamento do `DirectoryReadTool`:

| Argumento     | Tipo     | Descri√ß√£o                                                                                                                                                                                                                    |
| :------------ | :------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **directory** | `string` | *Opcional*. Um argumento que especifica o caminho para o diret√≥rio cujo conte√∫do voc√™ deseja listar. Aceita caminhos absolutos e relativos, direcionando a ferramenta para o diret√≥rio desejado para a listagem do conte√∫do. |


# Busca RAG em Diret√≥rio
Source: https://docs.crewai.com/pt-BR/tools/file-document/directorysearchtool

O `DirectorySearchTool` √© uma poderosa ferramenta RAG (Retrieval-Augmented Generation) desenvolvida para buscas sem√¢nticas no conte√∫do de um diret√≥rio.

# `DirectorySearchTool`

<Note>
  **Experimental**: O DirectorySearchTool est√° em desenvolvimento cont√≠nuo. As funcionalidades e recursos podem evoluir, e comportamentos inesperados podem ocorrer enquanto aprimoramos a ferramenta.
</Note>

## Descri√ß√£o

O DirectorySearchTool permite a busca sem√¢ntica dentro do conte√∫do de diret√≥rios especificados, aproveitando a metodologia de Recupera√ß√£o com Gera√ß√£o Aumentada (RAG) para uma navega√ß√£o eficiente entre arquivos. Projetada para flexibilidade, a ferramenta possibilita que usu√°rios especifiquem dinamicamente os diret√≥rios de busca em tempo de execu√ß√£o ou definam um diret√≥rio fixo durante a configura√ß√£o inicial.

## Instala√ß√£o

Para utilizar o DirectorySearchTool, comece instalando o pacote crewai\_tools. Execute o seguinte comando no seu terminal:

```shell
pip install 'crewai[tools]'
```

## Inicializa√ß√£o e Uso

Importe o DirectorySearchTool do pacote `crewai_tools` para come√ßar. Voc√™ pode inicializar a ferramenta sem especificar um diret√≥rio, permitindo definir o diret√≥rio de busca em tempo de execu√ß√£o. Alternativamente, a ferramenta pode ser inicializada j√° com um diret√≥rio predefinido.

```python Code
from crewai_tools import DirectorySearchTool

# Para especifica√ß√£o din√¢mica de diret√≥rio em tempo de execu√ß√£o
tool = DirectorySearchTool()

# Para buscas em diret√≥rio fixo
tool = DirectorySearchTool(directory='/path/to/directory')
```

## Argumentos

* `directory`: Um argumento do tipo string que especifica o diret√≥rio de busca. Este par√¢metro √© opcional durante a inicializa√ß√£o, mas obrigat√≥rio para buscas caso n√£o tenha sido definido inicialmente.

## Modelo Personalizado e Embeddings

O DirectorySearchTool utiliza OpenAI para embeddings e sumariza√ß√£o por padr√£o. As op√ß√µes de personaliza√ß√£o dessas configura√ß√µes incluem a altera√ß√£o do provedor de modelo e configura√ß√µes, ampliando a flexibilidade para usu√°rios avan√ßados.

```python Code
tool = DirectorySearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # As op√ß√µes incluem ollama, google, anthropic, llama2 e mais
            config=dict(
                model="llama2",
                # Configura√ß√µes adicionais aqui
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Pesquisa RAG em DOCX
Source: https://docs.crewai.com/pt-BR/tools/file-document/docxsearchtool

A `DOCXSearchTool` √© uma ferramenta RAG projetada para busca sem√¢ntica em documentos DOCX.

# `DOCXSearchTool`

<Note>
  Ainda estamos trabalhando na melhoria das ferramentas, portanto pode haver comportamentos inesperados ou altera√ß√µes no futuro.
</Note>

## Descri√ß√£o

A `DOCXSearchTool` √© uma ferramenta RAG desenvolvida para buscas sem√¢nticas dentro de documentos DOCX.
Ela permite que os usu√°rios pesquisem e extraiam informa√ß√µes relevantes de arquivos DOCX de forma eficiente, utilizando buscas baseadas em consultas.
Esta ferramenta √© inestim√°vel para an√°lise de dados, gest√£o da informa√ß√£o e tarefas de pesquisa,
otimizando o processo de encontrar informa√ß√µes espec√≠ficas em grandes cole√ß√µes de documentos.

## Instala√ß√£o

Instale o pacote crewai\_tools executando o seguinte comando no seu terminal:

```shell
uv pip install docx2txt 'crewai[tools]'
```

## Exemplo

O exemplo a seguir demonstra a inicializa√ß√£o da DOCXSearchTool para buscar dentro do conte√∫do de qualquer arquivo DOCX ou com o caminho de um arquivo DOCX espec√≠fico.

```python Code
from crewai_tools import DOCXSearchTool

# Inicialize a ferramenta para buscar dentro do conte√∫do de qualquer arquivo DOCX
tool = DOCXSearchTool()

# OU

# Inicialize a ferramenta com um arquivo DOCX espec√≠fico,
# assim o agente s√≥ poder√° buscar dentro do conte√∫do do arquivo DOCX especificado
tool = DOCXSearchTool(docx='path/to/your/document.docx')
```

## Argumentos

Os seguintes par√¢metros podem ser usados para customizar o comportamento da `DOCXSearchTool`:

| Argumento | Tipo     | Descri√ß√£o                                                                                                                                                                                                                                     |
| :-------- | :------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **docx**  | `string` | *Opcional*. Um argumento que especifica o caminho para o arquivo DOCX que voc√™ deseja pesquisar. Se n√£o for fornecido durante a inicializa√ß√£o, a ferramenta permite a especifica√ß√£o posterior do caminho de qualquer arquivo DOCX para busca. |

## Modelo e embeddings personalizados

Por padr√£o, a ferramenta utiliza o OpenAI tanto para embeddings quanto para sumariza√ß√£o. Para customizar o modelo, voc√™ pode usar um dicion√°rio de configura√ß√£o como no exemplo:

```python Code
tool = DOCXSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Leitura de Arquivo
Source: https://docs.crewai.com/pt-BR/tools/file-document/filereadtool

O `FileReadTool` foi desenvolvido para ler arquivos do sistema de arquivos local.

## Vis√£o Geral

<Note>
  Ainda estamos trabalhando para melhorar as ferramentas, portanto pode haver comportamentos inesperados ou altera√ß√µes no futuro.
</Note>

O FileReadTool representa conceitualmente um conjunto de funcionalidades dentro do pacote crewai\_tools voltadas para facilitar a leitura e a recupera√ß√£o de conte√∫do de arquivos.
Esse conjunto inclui ferramentas para processar arquivos de texto em lote, ler arquivos de configura√ß√£o em tempo de execu√ß√£o e importar dados para an√°lise.
Ele suporta uma variedade de formatos de arquivo baseados em texto, como `.txt`, `.csv`, `.json` e outros. Dependendo do tipo de arquivo, o conjunto oferece funcionalidades especializadas,
como converter conte√∫do JSON em um dicion√°rio Python para facilitar o uso.

## Instala√ß√£o

Para utilizar as funcionalidades anteriormente atribu√≠das ao FileReadTool, instale o pacote crewai\_tools:

```shell
pip install 'crewai[tools]'
```

## Exemplo de Uso

Para come√ßar a usar o FileReadTool:

```python Code
from crewai_tools import FileReadTool

# Inicialize a ferramenta para ler quaisquer arquivos que os agentes conhecem ou informe o caminho para
file_read_tool = FileReadTool()

# OU

# Inicialize a ferramenta com um caminho de arquivo espec√≠fico, assim o agente poder√° ler apenas o conte√∫do do arquivo especificado
file_read_tool = FileReadTool(file_path='path/to/your/file.txt')
```

## Argumentos

* `file_path`: O caminho para o arquivo que voc√™ deseja ler. Aceita caminhos absolutos e relativos. Certifique-se de que o arquivo exista e de que voc√™ tenha as permiss√µes necess√°rias para acess√°-lo.


# Escrita de Arquivo
Source: https://docs.crewai.com/pt-BR/tools/file-document/filewritetool

O `FileWriterTool` foi projetado para escrever conte√∫do em arquivos.

# `FileWriterTool`

## Descri√ß√£o

O `FileWriterTool` √© um componente do pacote crewai\_tools, projetado para simplificar o processo de escrita de conte√∫do em arquivos com compatibilidade multiplataforma (Windows, Linux, macOS).\
√â particularmente √∫til em cen√°rios como gera√ß√£o de relat√≥rios, salvamento de logs, cria√ß√£o de arquivos de configura√ß√£o e mais.\
Essa ferramenta lida com diferen√ßas de caminhos entre sistemas operacionais, suporta codifica√ß√£o UTF-8 e cria diret√≥rios automaticamente caso eles n√£o existam, facilitando a organiza√ß√£o da sua sa√≠da de forma confi√°vel em diferentes plataformas.

## Instala√ß√£o

Instale o pacote crewai\_tools para utilizar o `FileWriterTool` em seus projetos:

```shell
pip install 'crewai[tools]'
```

## Exemplo

Para come√ßar a usar o `FileWriterTool`:

```python Code
from crewai_tools import FileWriterTool

# Inicialize a ferramenta
file_writer_tool = FileWriterTool()

# Escreva conte√∫do em um arquivo em um diret√≥rio especificado
result = file_writer_tool._run('example.txt', 'This is a test content.', 'test_directory')
print(result)
```

## Argumentos

* `filename`: O nome do arquivo que voc√™ deseja criar ou sobrescrever.
* `content`: O conte√∫do a ser escrito no arquivo.
* `directory` (opcional): O caminho para o diret√≥rio onde o arquivo ser√° criado. Por padr√£o, utiliza o diret√≥rio atual (`.`). Se o diret√≥rio n√£o existir, ele ser√° criado.

## Conclus√£o

Ao integrar o `FileWriterTool` aos seus crews, os agentes podem escrever conte√∫do em arquivos de forma confi√°vel em diferentes sistemas operacionais.\
Esta ferramenta √© essencial para tarefas que exigem salvamento de dados de sa√≠da, cria√ß√£o de sistemas de arquivos estruturados e manipula√ß√£o de opera√ß√µes de arquivos multiplataforma.\
√â especialmente recomendada para usu√°rios do Windows que possam enfrentar problemas ao escrever arquivos com as opera√ß√µes padr√£o do Python.

Seguindo as orienta√ß√µes de configura√ß√£o e uso fornecidas, incorporar essa ferramenta em projetos √© simples e garante um comportamento consistente de escrita de arquivos em todas as plataformas.


# Busca JSON RAG
Source: https://docs.crewai.com/pt-BR/tools/file-document/jsonsearchtool

O `JSONSearchTool` foi projetado para buscar arquivos JSON e retornar os resultados mais relevantes.

# `JSONSearchTool`

<Note>
  O JSONSearchTool est√° atualmente em fase experimental. Isso significa que a ferramenta
  est√° em desenvolvimento ativo, e os usu√°rios podem encontrar comportamentos inesperados ou
  altera√ß√µes. Incentivamos fortemente o envio de feedback sobre quaisquer problemas ou sugest√µes de
  melhorias.
</Note>

## Descri√ß√£o

O JSONSearchTool foi projetado para facilitar buscas eficientes e precisas dentro do conte√∫do de arquivos JSON. Ele utiliza um mecanismo de busca RAG (Retrieve and Generate), permitindo que os usu√°rios especifiquem um caminho JSON para buscas direcionadas dentro de um arquivo JSON espec√≠fico. Essa capacidade melhora significativamente a precis√£o e relev√¢ncia dos resultados de busca.

## Instala√ß√£o

Para instalar o JSONSearchTool, utilize o seguinte comando pip:

```shell
pip install 'crewai[tools]'
```

## Exemplos de Uso

Aqui est√£o exemplos atualizados de como utilizar o JSONSearchTool de forma eficaz para buscar dentro de arquivos JSON. Esses exemplos consideram a implementa√ß√£o e padr√µes de uso atuais identificados na base de c√≥digo.

```python Code
from crewai_tools import JSONSearchTool

# Busca geral em conte√∫do JSON
# Esta abordagem √© adequada quando o caminho JSON j√° √© conhecido ou pode ser identificado dinamicamente.
tool = JSONSearchTool()

# Restringindo a busca a um arquivo JSON espec√≠fico
# Use este m√©todo de inicializa√ß√£o quando desejar limitar o escopo de busca a um arquivo espec√≠fico.
tool = JSONSearchTool(json_path='./path/to/your/file.json')
```

## Argumentos

* `json_path` (str, opcional): Especifica o caminho para o arquivo JSON a ser buscado. Este argumento n√£o √© obrigat√≥rio se a ferramenta for inicializada para uma busca geral. Quando fornecido, limita a busca ao arquivo JSON especificado.

## Op√ß√µes de Configura√ß√£o

O JSONSearchTool oferece ampla personaliza√ß√£o atrav√©s de um dicion√°rio de configura√ß√£o. Isso permite que os usu√°rios selecionem diferentes modelos para embeddings e sumariza√ß√£o conforme suas necessidades.

```python Code
tool = JSONSearchTool(
    config={
        "llm": {
            "provider": "ollama",  # Outras op√ß√µes incluem google, openai, anthropic, llama2, etc.
            "config": {
                "model": "llama2",
                # Configura√ß√µes opcionais adicionais podem ser especificadas aqui.
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            },
        },
        "embedding_model": {
            "provider": "google", # ou openai, ollama, ...
            "config": {
                "model": "models/embedding-001",
                "task_type": "retrieval_document",
                # Mais op√ß√µes de personaliza√ß√£o podem ser adicionadas aqui.
            },
        },
    }
)
```


# Pesquisa MDX RAG
Source: https://docs.crewai.com/pt-BR/tools/file-document/mdxsearchtool

O `MDXSearchTool` foi projetado para pesquisar arquivos MDX e retornar os resultados mais relevantes.

# `MDXSearchTool`

<Note>
  O MDXSearchTool est√° em desenvolvimento cont√≠nuo. Recursos podem ser adicionados ou removidos, e a funcionalidade pode mudar de forma imprevis√≠vel √† medida que refinamos a ferramenta.
</Note>

## Descri√ß√£o

A Ferramenta de Pesquisa MDX √© um componente do pacote `crewai_tools` focado em facilitar a extra√ß√£o avan√ßada de dados do markdown. Ela permite que usu√°rios pesquisem e extraiam informa√ß√µes relevantes de arquivos MD utilizando buscas baseadas em consulta. Esta ferramenta √© indispens√°vel para an√°lise de dados, gest√£o de informa√ß√µes e tarefas de pesquisa, agilizando o processo de encontrar informa√ß√µes espec√≠ficas em grandes cole√ß√µes de documentos.

## Instala√ß√£o

Antes de utilizar a Ferramenta de Pesquisa MDX, certifique-se de que o pacote `crewai_tools` est√° instalado. Caso n√£o esteja, voc√™ pode instal√°-lo com o comando abaixo:

```shell
pip install 'crewai[tools]'
```

## Exemplo de Uso

Para utilizar a Ferramenta de Pesquisa MDX, primeiro defina as vari√°veis de ambiente necess√°rias. Em seguida, integre a ferramenta ao seu projeto crewAI para come√ßar sua pesquisa de mercado. Veja abaixo um exemplo b√°sico de como fazer isso:

```python Code
from crewai_tools import MDXSearchTool

# Inicialize a ferramenta para pesquisar qualquer conte√∫do MDX que ela conhe√ßa durante a execu√ß√£o
tool = MDXSearchTool()

# OU

# Inicialize a ferramenta com um caminho espec√≠fico para o arquivo MDX, realizando buscas exclusivamente neste documento
tool = MDXSearchTool(mdx='path/to/your/document.mdx')
```

## Par√¢metros

* mdx: **Opcional**. Especifica o caminho do arquivo MDX para pesquisa. Pode ser informado durante a inicializa√ß√£o.

## Personaliza√ß√£o do Modelo e Embeddings

A ferramenta utiliza, por padr√£o, o OpenAI para embeddings e sumariza√ß√£o. Para personalizar, utilize um dicion√°rio de configura√ß√£o conforme exemplo abaixo:

```python Code
tool = MDXSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # As op√ß√µes incluem google, openai, anthropic, llama2, etc.
            config=dict(
                model="llama2",
                # Par√¢metros opcionais podem ser inclu√≠dos aqui.
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # Um t√≠tulo opcional para os embeddings pode ser adicionado aqui.
                # title="Embeddings",
            ),
        ),
    )
)
```


# Vis√£o Geral
Source: https://docs.crewai.com/pt-BR/tools/file-document/overview

Leia, escreva e pesquise em diversos formatos de arquivos com as ferramentas de processamento de documentos do CrewAI

Estas ferramentas permitem que seus agentes trabalhem com diversos formatos e tipos de documentos. De leitura de PDFs ao processamento de dados em JSON, essas ferramentas atendem a todas as suas necessidades de processamento de documentos.

## **Ferramentas Dispon√≠veis**

<CardGroup cols={2}>
  <Card title="Ferramenta de Leitura de Arquivos" icon="folders" href="/pt-BR/tools/file-document/filereadtool">
    Leia conte√∫do de qualquer tipo de arquivo, incluindo texto, markdown e mais.
  </Card>

  <Card title="Ferramenta de Escrita de Arquivos" icon="file-pen" href="/pt-BR/tools/file-document/filewritetool">
    Escreva conte√∫do em arquivos, crie novos documentos e salve dados processados.
  </Card>

  <Card title="Ferramenta de Pesquisa em PDF" icon="file-pdf" href="/pt-BR/tools/file-document/pdfsearchtool">
    Pesquise e extraia conte√∫do de texto de documentos PDF de forma eficiente.
  </Card>

  <Card title="Ferramenta de Pesquisa em DOCX" icon="file-word" href="/pt-BR/tools/file-document/docxsearchtool">
    Pesquise em documentos do Microsoft Word e extraia conte√∫do relevante.
  </Card>

  <Card title="Ferramenta de Pesquisa em JSON" icon="brackets-curly" href="/pt-BR/tools/file-document/jsonsearchtool">
    Fa√ßa a an√°lise e pesquisa em arquivos JSON com recursos avan√ßados de consulta.
  </Card>

  <Card title="Ferramenta de Pesquisa em CSV" icon="table" href="/pt-BR/tools/file-document/csvsearchtool">
    Processe e pesquise em arquivos CSV, extraia linhas e colunas espec√≠ficas.
  </Card>

  <Card title="Ferramenta de Pesquisa em XML" icon="code" href="/pt-BR/tools/file-document/xmlsearchtool">
    Analise arquivos XML e pesquise elementos e atributos espec√≠ficos.
  </Card>

  <Card title="Ferramenta de Pesquisa em MDX" icon="markdown" href="/pt-BR/tools/file-document/mdxsearchtool">
    Pesquise em arquivos MDX e extraia conte√∫do de documenta√ß√µes.
  </Card>

  <Card title="Ferramenta de Pesquisa em TXT" icon="file-lines" href="/pt-BR/tools/file-document/txtsearchtool">
    Pesquise em arquivos de texto simples com recursos de busca por padr√µes.
  </Card>

  <Card title="Ferramenta de Pesquisa em Diret√≥rio" icon="folder-open" href="/pt-BR/tools/file-document/directorysearchtool">
    Pesquise arquivos e pastas dentro de estruturas de diret√≥rios.
  </Card>

  <Card title="Ferramenta de Leitura de Diret√≥rio" icon="folder" href="/pt-BR/tools/file-document/directoryreadtool">
    Leia e liste conte√∫dos de diret√≥rios, estruturas de arquivos e metadados.
  </Card>
</CardGroup>

## **Casos de Uso Comuns**

* **Processamento de Documentos**: Extraia e analise conte√∫do de v√°rios formatos de arquivos
* **Importa√ß√£o de Dados**: Leia dados estruturados de arquivos CSV, JSON e XML
* **Busca por Conte√∫do**: Encontre informa√ß√µes espec√≠ficas em grandes cole√ß√µes de documentos
* **Gerenciamento de Arquivos**: Organize e manipule arquivos e diret√≥rios
* **Exporta√ß√£o de Dados**: Salve os resultados processados em v√°rios formatos de arquivo

## **Exemplo R√°pido de In√≠cio**

```python
from crewai_tools import FileReadTool, PDFSearchTool, JSONSearchTool

# Create tools
file_reader = FileReadTool()
pdf_searcher = PDFSearchTool()
json_processor = JSONSearchTool()

# Add to your agent
agent = Agent(
    role="Document Analyst",
    tools=[file_reader, pdf_searcher, json_processor],
    goal="Process and analyze various document types"
)
```

## **Dicas para Processamento de Documentos**

* **Permiss√µes de Arquivo**: Certifique-se de que seu agente possui as permiss√µes adequadas de leitura/escrita
* **Arquivos Grandes**: Considere dividir documentos muito grandes em partes menores
* **Suporte de Formatos**: Consulte a documenta√ß√£o da ferramenta para saber quais formatos de arquivos s√£o suportados
* **Tratamento de Erros**: Implemente tratamento de erros adequado para arquivos corrompidos ou inacess√≠veis


# Busca RAG em PDF
Source: https://docs.crewai.com/pt-BR/tools/file-document/pdfsearchtool

O `PDFSearchTool` √© projetado para pesquisar arquivos PDF e retornar os resultados mais relevantes.

# `PDFSearchTool`

<Note>
  Ainda estamos trabalhando para melhorar as ferramentas, ent√£o pode haver comportamentos inesperados ou mudan√ßas futuras.
</Note>

## Descri√ß√£o

O PDFSearchTool √© uma ferramenta RAG projetada para buscas sem√¢nticas dentro do conte√∫do de PDFs. Ela permite inserir uma consulta de busca e um documento PDF, aproveitando t√©cnicas avan√ßadas de busca para encontrar conte√∫dos relevantes de forma eficiente.
Essa capacidade a torna especialmente √∫til para extrair informa√ß√µes espec√≠ficas de arquivos PDF grandes rapidamente.

## Instala√ß√£o

Para come√ßar a usar o PDFSearchTool, primeiro, garanta que o pacote crewai\_tools est√° instalado com o seguinte comando:

```shell
pip install 'crewai[tools]'
```

## Exemplo

Veja como utilizar o PDFSearchTool para buscar dentro de um documento PDF:

```python Code
from crewai_tools import PDFSearchTool

# Inicialize a ferramenta permitindo buscas em qualquer conte√∫do PDF caso o caminho seja informado durante a execu√ß√£o
tool = PDFSearchTool()

# OU

# Inicialize a ferramenta com um caminho PDF espec√≠fico para buscas exclusivas naquele documento
tool = PDFSearchTool(pdf='path/to/your/document.pdf')
```

## Argumentos

* `pdf`: **Opcional** O caminho do PDF para busca. Pode ser fornecido na inicializa√ß√£o ou nos argumentos do m√©todo `run`. Caso seja fornecido na inicializa√ß√£o, a ferramenta confinar√° suas buscas ao documento especificado.

## Modelo e embeddings personalizados

Por padr√£o, a ferramenta utiliza OpenAI tanto para embeddings quanto para sumariza√ß√£o. Para personalizar o modelo, voc√™ pode usar um dicion√°rio de configura√ß√£o como no exemplo abaixo:

```python Code
tool = PDFSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Pesquisa TXT RAG
Source: https://docs.crewai.com/pt-BR/tools/file-document/txtsearchtool

O `TXTSearchTool` foi projetado para realizar uma busca RAG (Gera√ß√£o Aumentada por Recupera√ß√£o) dentro do conte√∫do de um arquivo de texto.

## Vis√£o Geral

<Note>
  Ainda estamos trabalhando para melhorar as ferramentas, por isso pode haver comportamentos inesperados ou mudan√ßas no futuro.
</Note>

Esta ferramenta √© utilizada para realizar uma busca RAG (Gera√ß√£o Aumentada por Recupera√ß√£o) dentro do conte√∫do de um arquivo de texto.
Ela permite uma busca sem√¢ntica de uma consulta dentro do conte√∫do de um arquivo de texto especificado,
tornando-se um recurso valioso para extrair rapidamente informa√ß√µes ou encontrar se√ß√µes espec√≠ficas do texto com base na consulta fornecida.

## Instala√ß√£o

Para usar o `TXTSearchTool`, primeiro √© necess√°rio instalar o pacote `crewai_tools`.
Isso pode ser feito usando o pip, um gerenciador de pacotes para Python.
Abra seu terminal ou prompt de comando e digite o seguinte comando:

```shell
pip install 'crewai[tools]'
```

Este comando far√° o download e instalar√° o TXTSearchTool junto com todas as depend√™ncias necess√°rias.

## Exemplo

O exemplo a seguir demonstra como usar o TXTSearchTool para pesquisar dentro de um arquivo de texto.
Este exemplo mostra tanto a inicializa√ß√£o da ferramenta com um arquivo de texto espec√≠fico quanto a pesquisa subsequente dentro do conte√∫do desse arquivo.

```python Code
from crewai_tools import TXTSearchTool

# Inicialize a ferramenta para pesquisar no conte√∫do de qualquer arquivo de texto
# que o agente aprender durante sua execu√ß√£o
tool = TXTSearchTool()

# OU

# Inicialize a ferramenta com um arquivo de texto espec√≠fico,
# para que o agente possa pesquisar dentro do conte√∫do desse arquivo de texto
tool = TXTSearchTool(txt='path/to/text/file.txt')
```

## Argumentos

* `txt` (str): **Opcional**. O caminho para o arquivo de texto que voc√™ deseja pesquisar.
  Este argumento s√≥ √© necess√°rio se a ferramenta n√£o foi inicializada com um arquivo de texto espec√≠fico;
  caso contr√°rio, a pesquisa ser√° realizada no arquivo de texto fornecido inicialmente.

## Modelo e embeddings personalizados

Por padr√£o, a ferramenta utiliza o OpenAI tanto para embeddings quanto para sumariza√ß√£o.
Para personalizar o modelo, voc√™ pode usar um dicion√°rio de configura√ß√£o como o exemplo a seguir:

```python Code
tool = TXTSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Busca RAG em XML
Source: https://docs.crewai.com/pt-BR/tools/file-document/xmlsearchtool

O `XMLSearchTool` foi projetado para realizar uma busca RAG (Gera√ß√£o Aumentada por Recupera√ß√£o) dentro do conte√∫do de um arquivo XML.

# `XMLSearchTool`

<Note>
  Ainda estamos trabalhando na melhoria das ferramentas, ent√£o pode haver comportamentos inesperados ou mudan√ßas no futuro.
</Note>

## Descri√ß√£o

O XMLSearchTool √© uma ferramenta RAG de ponta, desenvolvida para realizar buscas sem√¢nticas em arquivos XML.
Ideal para usu√°rios que precisam analisar e extrair informa√ß√µes do conte√∫do XML de forma eficiente, esta ferramenta permite inserir uma consulta de busca e um caminho opcional para o arquivo XML.
Ao especificar um caminho de arquivo XML, o usu√°rio pode direcionar sua busca de forma mais precisa ao conte√∫do daquele arquivo, obtendo assim resultados mais relevantes.

## Instala√ß√£o

Para come√ßar a usar o XMLSearchTool, √© necess√°rio instalar primeiro o pacote crewai\_tools. Isso pode ser feito facilmente com o seguinte comando:

```shell
pip install 'crewai[tools]'
```

## Exemplo

Aqui est√£o dois exemplos demonstrando como usar o XMLSearchTool.
O primeiro exemplo mostra a busca dentro de um arquivo XML espec√≠fico, enquanto o segundo exemplo ilustra como iniciar uma busca sem definir previamente um caminho XML, oferecendo flexibilidade no escopo da busca.

```python Code
from crewai_tools import XMLSearchTool

# Permite que agentes busquem no conte√∫do de qualquer arquivo XML
# conforme aprendem seus caminhos durante a execu√ß√£o
tool = XMLSearchTool()

# OU

# Inicializa a ferramenta com um caminho espec√≠fico para arquivo XML
# para busca exclusiva dentro desse documento
tool = XMLSearchTool(xml='path/to/your/xmlfile.xml')
```

## Argumentos

* `xml`: Este √© o caminho para o arquivo XML que voc√™ deseja buscar.
  Este par√¢metro √© opcional durante a inicializa√ß√£o da ferramenta, mas deve ser fornecido ou na inicializa√ß√£o ou como parte dos argumentos do m√©todo `run` para executar a busca.

## Modelo customizado e embeddings

Por padr√£o, a ferramenta utiliza a OpenAI tanto para embeddings quanto para sumariza√ß√£o. Para personalizar o modelo, voc√™ pode usar um dicion√°rio de configura√ß√£o conforme o exemplo a seguir:

```python Code
tool = XMLSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Vis√£o Geral das Ferramentas
Source: https://docs.crewai.com/pt-BR/tools/overview

Descubra a vasta biblioteca do CrewAI com mais de 40 ferramentas para potencializar seus agentes de IA

O CrewAI oferece uma biblioteca extensa de ferramentas pr√©-constru√≠das para aprimorar as capacidades dos seus agentes. De processamento de arquivos a web scraping, consultas em bancos de dados a servi√ßos de IA ‚Äî temos tudo o que voc√™ precisa.

## **Categorias de Ferramentas**

<CardGroup cols={2}>
  <Card title="Arquivo & Documento" icon="file-check" href="/pt-BR/tools/file-document/overview" color="#3B82F6">
    Leia, escreva e pesquise em diversos formatos de arquivo, incluindo PDF, DOCX, JSON, CSV e muito mais. Perfeito para fluxos de processamento de documentos.
  </Card>

  <Card title="Web Scraping & Navega√ß√£o" icon="globe" href="/pt-BR/tools/web-scraping/overview" color="#10B981">
    Extraia dados de sites, automatize intera√ß√µes com navegadores e fa√ßa scraping de conte√∫do em escala com ferramentas como Firecrawl, Selenium e outras.
  </Card>

  <Card title="Pesquisa & Busca" icon="magnifying-glass" href="/pt-BR/tools/search-research/overview" color="#F59E0B">
    Realize buscas na web, encontre reposit√≥rios de c√≥digo, pesquise conte√∫do no YouTube e descubra informa√ß√µes em toda a internet.
  </Card>

  <Card title="Banco de Dados & Dados" icon="database" href="/pt-BR/tools/database-data/overview" color="#8B5CF6">
    Conecte-se a bancos de dados SQL, reposit√≥rios vetoriais e data warehouses. Consulte MySQL, PostgreSQL, Snowflake, Qdrant e Weaviate.
  </Card>

  <Card title="IA & Aprendizado de M√°quina" icon="brain" href="/pt-BR/tools/ai-ml/overview" color="#EF4444">
    Gere imagens com DALL-E, execute tarefas de vis√£o computacional, integre com LangChain, construa sistemas RAG e aproveite interpretadores de c√≥digo.
  </Card>

  <Card title="Nuvem & Armazenamento" icon="cloud" href="/pt-BR/tools/cloud-storage/overview" color="#06B6D4">
    Interaja com servi√ßos em nuvem incluindo AWS S3, Amazon Bedrock e outros servi√ßos de armazenamento e IA na nuvem.
  </Card>

  <Card title="Automa√ß√£o & Integra√ß√£o" icon="bolt" href="/pt-BR/tools/automation/overview" color="#84CC16">
    Automatize fluxos de trabalho com Apify, Composio e outras plataformas de integra√ß√£o para conectar seus agentes a servi√ßos externos.
  </Card>
</CardGroup>

## **Acesso R√°pido**

Precisa de uma ferramenta espec√≠fica? Aqui est√£o algumas op√ß√µes populares:

<CardGroup cols={3}>
  <Card title="RAG Tool" icon="image" href="/pt-BR/tools/ai-ml/ragtool">
    Implemente Gera√ß√£o com Recupera√ß√£o de Dados (RAG)
  </Card>

  <Card title="Serper Dev" icon="book-atlas" href="/pt-BR/tools/search-research/serperdevtool">
    API de busca do Google
  </Card>

  <Card title="File Read" icon="file" href="/pt-BR/tools/file-document/filereadtool">
    Leia qualquer tipo de arquivo
  </Card>

  <Card title="Scrape Website" icon="globe" href="/pt-BR/tools/web-scraping/scrapewebsitetool">
    Extraia conte√∫do da web
  </Card>

  <Card title="Code Interpreter" icon="code" href="/pt-BR/tools/ai-ml/codeinterpretertool">
    Execute c√≥digo Python
  </Card>

  <Card title="S3 Reader" icon="cloud" href="/pt-BR/tools/cloud-storage/s3readertool">
    Acesse arquivos no AWS S3
  </Card>
</CardGroup>

## **Primeiros Passos**

Para usar qualquer ferramenta em seu projeto CrewAI:

1. **Importe** a ferramenta na configura√ß√£o da sua crew
2. **Adicione** √† lista de ferramentas do seu agente
3. **Configure** as chaves de API ou ajustes necess√°rios

```python
from crewai_tools import FileReadTool, SerperDevTool

# Adicione as ferramentas ao seu agente
agent = Agent(
    role="Research Analyst",
    tools=[FileReadTool(), SerperDevTool()],
    # ... outrAs configura√ß√µes
)
```

Pronto para explorar? Escolha uma categoria acima para descobrir as ferramentas que se encaixam no seu caso de uso!


# Brave Search
Source: https://docs.crewai.com/pt-BR/tools/search-research/bravesearchtool

O `BraveSearchTool` foi projetado para pesquisar na internet usando a Brave Search API.

# `BraveSearchTool`

## Descri√ß√£o

Esta ferramenta foi desenvolvida para realizar buscas na web utilizando a Brave Search API. Ela permite que voc√™ pesquise na internet com uma consulta especificada e recupere resultados relevantes. A ferramenta suporta a personaliza√ß√£o do n√∫mero de resultados e buscas espec√≠ficas por pa√≠s.

## Instala√ß√£o

Para incorporar esta ferramenta ao seu projeto, siga as instru√ß√µes de instala√ß√£o abaixo:

```shell
pip install 'crewai[tools]'
```

## Passos para Come√ßar

Para utilizar o `BraveSearchTool` de forma eficaz, siga estes passos:

1. **Instala√ß√£o do Pacote**: Confirme que o pacote `crewai[tools]` est√° instalado no seu ambiente Python.
2. **Obten√ß√£o da Chave de API**: Obtenha uma chave de API do Brave Search registrando-se em [Brave Search API](https://api.search.brave.com/app/keys).
3. **Configura√ß√£o do Ambiente**: Armazene a chave de API obtida em uma vari√°vel de ambiente chamada `BRAVE_API_KEY` para facilitar seu uso pela ferramenta.

## Exemplo

O exemplo a seguir demonstra como inicializar a ferramenta e executar uma busca com uma determinada consulta:

```python Code
from crewai_tools import BraveSearchTool

# Inicialize a ferramenta para capacidades de busca na internet
tool = BraveSearchTool()

# Execute uma busca
results = tool.run(search_query="CrewAI agent framework")
print(results)
```

## Par√¢metros

O `BraveSearchTool` aceita os seguintes par√¢metros:

* **search\_query**: Obrigat√≥rio. A consulta de pesquisa que voc√™ deseja usar para pesquisar na internet.
* **country**: Opcional. Especifique o pa√≠s dos resultados da pesquisa. O padr√£o √© string vazia.
* **n\_results**: Opcional. N√∫mero de resultados de pesquisa a serem retornados. O padr√£o √© `10`.
* **save\_file**: Opcional. Se os resultados da pesquisa devem ser salvos em um arquivo. O padr√£o √© `False`.

## Exemplo com Par√¢metros

Veja um exemplo demonstrando como usar a ferramenta com par√¢metros adicionais:

```python Code
from crewai_tools import BraveSearchTool

# Inicialize a ferramenta com par√¢metros personalizados
tool = BraveSearchTool(
    country="US",
    n_results=5,
    save_file=True
)

# Execute uma busca
results = tool.run(search_query="Latest AI developments")
print(results)
```

## Exemplo de Integra√ß√£o com Agente

Veja como integrar o `BraveSearchTool` com um agente CrewAI:

```python Code
from crewai import Agent
from crewai.project import agent
from crewai_tools import BraveSearchTool

# Inicialize a ferramenta
brave_search_tool = BraveSearchTool()

# Defina um agente com o BraveSearchTool
@agent
def researcher(self) -> Agent:
    return Agent(
        config=self.agents_config["researcher"],
        allow_delegation=False,
        tools=[brave_search_tool]
    )
```

## Conclus√£o

Ao integrar o `BraveSearchTool` em projetos Python, os usu√°rios ganham a capacidade de realizar buscas em tempo real e relevantes na internet diretamente de suas aplica√ß√µes. A ferramenta oferece uma interface simples para a poderosa Brave Search API, facilitando a recupera√ß√£o e o processamento program√°tico dos resultados de pesquisa. Seguindo as orienta√ß√µes de configura√ß√£o e uso fornecidas, a incorpora√ß√£o desta ferramenta em projetos √© simplificada e direta.


# Pesquisa com RAG em Documenta√ß√£o de C√≥digo
Source: https://docs.crewai.com/pt-BR/tools/search-research/codedocssearchtool

O `CodeDocsSearchTool` √© uma poderosa ferramenta RAG (Gera√ß√£o Aumentada por Recupera√ß√£o) projetada para buscas sem√¢nticas em documenta√ß√£o de c√≥digo.

# `CodeDocsSearchTool`

<Note>
  **Experimental**: Ainda estamos trabalhando para melhorar as ferramentas, ent√£o pode haver comportamentos inesperados ou mudan√ßas no futuro.
</Note>

## Descri√ß√£o

O CodeDocsSearchTool √© uma poderosa ferramenta RAG (Gera√ß√£o Aumentada por Recupera√ß√£o) projetada para buscas sem√¢nticas em documenta√ß√£o de c√≥digo.
Ela permite que usu√°rios encontrem de forma eficiente informa√ß√µes ou t√≥picos espec√≠ficos dentro da documenta√ß√£o de c√≥digo. Ao fornecer um `docs_url` durante a inicializa√ß√£o,
a ferramenta restringe a busca √†quele site de documenta√ß√£o em particular. Alternativamente, sem um `docs_url` espec√≠fico,
ela realiza buscas em uma ampla variedade de documenta√ß√µes de c√≥digo conhecidas ou descobertas durante sua execu√ß√£o, tornando-a vers√°til para diversas necessidades de busca em documenta√ß√£o.

## Instala√ß√£o

Para come√ßar a usar o CodeDocsSearchTool, primeiro instale o pacote crewai\_tools via pip:

```shell
pip install 'crewai[tools]'
```

## Exemplo

Utilize o CodeDocsSearchTool conforme abaixo para realizar buscas em documenta√ß√£o de c√≥digo:

```python Code
from crewai_tools import CodeDocsSearchTool

# Para buscar qualquer conte√∫do de documenta√ß√£o de c√≥digo
# se a URL for conhecida ou descoberta durante a execu√ß√£o:
tool = CodeDocsSearchTool()

# OU

# Para focar sua busca especificamente em um site de documenta√ß√£o
# fornecendo sua URL:
tool = CodeDocsSearchTool(docs_url='https://docs.example.com/reference')
```

<Note>
  Substitua '[https://docs.example.com/reference](https://docs.example.com/reference)' pela URL da documenta√ß√£o desejada
  e 'How to use search tool' pela consulta de busca relevante √†s suas necessidades.
</Note>

## Argumentos

Os seguintes par√¢metros podem ser usados para personalizar o comportamento do `CodeDocsSearchTool`:

| Argumento     | Tipo     | Descri√ß√£o                                                                |
| :------------ | :------- | :----------------------------------------------------------------------- |
| **docs\_url** | `string` | *Opcional*. Especifica a URL da documenta√ß√£o de c√≥digo a ser pesquisada. |

## Modelo e embeddings personalizados

Por padr√£o, a ferramenta utiliza a OpenAI tanto para embeddings quanto para sumariza√ß√£o. Para customizar o modelo, voc√™ pode usar um dicion√°rio de configura√ß√£o conforme abaixo:

```python Code
tool = CodeDocsSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Carregador Web EXA Search
Source: https://docs.crewai.com/pt-BR/tools/search-research/exasearchtool

O `EXASearchTool` foi projetado para realizar uma busca sem√¢ntica para uma consulta especificada a partir do conte√∫do de um texto em toda a internet.

# `EXASearchTool`

## Descri√ß√£o

O EXASearchTool foi projetado para realizar uma busca sem√¢ntica para uma consulta especificada a partir do conte√∫do de um texto em toda a internet.
Ele utiliza a API da [exa.ai](https://exa.ai/) para buscar e exibir os resultados de pesquisa mais relevantes com base na consulta fornecida pelo usu√°rio.

## Instala√ß√£o

Para incorporar esta ferramenta em seu projeto, siga as instru√ß√µes de instala√ß√£o abaixo:

```shell
pip install 'crewai[tools]'
```

## Exemplo

O exemplo a seguir demonstra como inicializar a ferramenta e executar uma busca com uma consulta determinada:

```python Code
from crewai_tools import EXASearchTool

# Initialize the tool for internet searching capabilities
tool = EXASearchTool()
```

## Etapas para Come√ßar

Para usar o EXASearchTool de forma eficaz, siga estas etapas:

<Steps>
  <Step title="Instala√ß√£o do Pacote">
    Confirme se o pacote `crewai[tools]` est√° instalado em seu ambiente Python.
  </Step>

  <Step title="Obten√ß√£o da Chave de API">
    Adquira uma chave de API da [exa.ai](https://exa.ai/) registrando-se gratuitamente em [exa.ai](https://exa.ai/).
  </Step>

  <Step title="Configura√ß√£o de Ambiente">
    Armazene a chave de API obtida em uma vari√°vel de ambiente chamada `EXA_API_KEY` para facilitar o uso pela ferramenta.
  </Step>
</Steps>

## Conclus√£o

Ao integrar o `EXASearchTool` em projetos Python, os usu√°rios ganham a capacidade de realizar buscas relevantes e em tempo real pela internet diretamente de suas aplica√ß√µes.
Seguindo as orienta√ß√µes de configura√ß√£o e uso fornecidas, a incorpora√ß√£o desta ferramenta em projetos torna-se simples e direta.


# Github Search
Source: https://docs.crewai.com/pt-BR/tools/search-research/githubsearchtool

O `GithubSearchTool` foi desenvolvido para pesquisar sites e convert√™-los em markdown limpo ou dados estruturados.

# `GithubSearchTool`

<Note>
  Ainda estamos trabalhando para melhorar as ferramentas, portanto pode haver comportamentos inesperados ou mudan√ßas no futuro.
</Note>

## Descri√ß√£o

O GithubSearchTool √© uma ferramenta de Recupera√ß√£o Aprimorada por Gera√ß√£o (RAG) especificamente projetada para realizar buscas sem√¢nticas em reposit√≥rios GitHub. Utilizando funcionalidades avan√ßadas de busca sem√¢ntica, ele examina c√≥digos, pull requests, issues e reposit√≥rios, tornando-se uma ferramenta essencial para desenvolvedores, pesquisadores ou qualquer pessoa que precise de informa√ß√µes precisas do GitHub.

## Instala√ß√£o

Para usar o GithubSearchTool, primeiro certifique-se de que o pacote crewai\_tools est√° instalado em seu ambiente Python:

```shell
pip install 'crewai[tools]'
```

Esse comando instala o pacote necess√°rio para rodar o GithubSearchTool juntamente com outras ferramentas inclu√≠das no pacote crewai\_tools.

## Exemplo

Veja como voc√™ pode usar o GithubSearchTool para realizar buscas sem√¢nticas dentro de um reposit√≥rio GitHub:

```python Code
from crewai_tools import GithubSearchTool

# Inicialize a ferramenta para buscas sem√¢nticas em um reposit√≥rio GitHub espec√≠fico
tool = GithubSearchTool(
	github_repo='https://github.com/example/repo',
	gh_token='your_github_personal_access_token',
	content_types=['code', 'issue'] # Op√ß√µes: code, repo, pr, issue
)

# OU

# Inicialize a ferramenta para buscas sem√¢nticas em um reposit√≥rio GitHub espec√≠fico, permitindo que o agente pesquise em qualquer reposit√≥rio caso tome conhecimento durante a execu√ß√£o
tool = GithubSearchTool(
	gh_token='your_github_personal_access_token',
	content_types=['code', 'issue'] # Op√ß√µes: code, repo, pr, issue
)
```

## Argumentos

* `github_repo` : A URL do reposit√≥rio GitHub onde a busca ser√° realizada. Este √© um campo obrigat√≥rio e especifica o reposit√≥rio alvo para sua pesquisa.
* `gh_token` : Seu Personal Access Token (PAT) do GitHub necess√°rio para autentica√ß√£o. Voc√™ pode criar um nas configura√ß√µes da sua conta GitHub em Developer Settings > Personal Access Tokens.
* `content_types` : Especifica os tipos de conte√∫do a serem inclu√≠dos na busca. √â necess√°rio fornecer uma lista dos tipos de conte√∫do das seguintes op√ß√µes: `code` para pesquisar dentro do c√≥digo,
  `repo` para pesquisar nas informa√ß√µes gerais do reposit√≥rio, `pr` para pesquisar em pull requests, e `issue` para pesquisar nas issues.
  Este campo √© obrigat√≥rio e permite adaptar a busca para tipos espec√≠ficos de conte√∫do dentro do reposit√≥rio GitHub.

## Modelo e embeddings personalizados

Por padr√£o, a ferramenta utiliza o OpenAI tanto para embeddings quanto para sumariza√ß√£o. Para personalizar o modelo, voc√™ pode usar um dicion√°rio de configura√ß√£o como no exemplo:

```python Code
tool = GithubSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Linkup Search Tool
Source: https://docs.crewai.com/pt-BR/tools/search-research/linkupsearchtool

O `LinkupSearchTool` permite consultar a API do Linkup para obter informa√ß√µes contextuais.

# `LinkupSearchTool`

## Descri√ß√£o

O `LinkupSearchTool` fornece a capacidade de consultar a API do Linkup para obter informa√ß√µes contextuais e recuperar resultados estruturados. Esta ferramenta √© ideal para enriquecer fluxos de trabalho com informa√ß√µes atualizadas e confi√°veis do Linkup, permitindo que agentes acessem dados relevantes durante a execu√ß√£o de suas tarefas.

## Instala√ß√£o

Para utilizar esta ferramenta, √© necess√°rio instalar o Linkup SDK:

```shell
uv add linkup-sdk
```

## Passos para come√ßar

Para usar efetivamente o `LinkupSearchTool`, siga estes passos:

1. **Chave de API**: Obtenha uma chave de API do Linkup.
2. **Configura√ß√£o do Ambiente**: Configure seu ambiente com a chave de API.
3. **Instalar SDK**: Instale o Linkup SDK usando o comando acima.

## Exemplo

O exemplo a seguir demonstra como inicializar a ferramenta e us√°-la em um agente:

```python Code
from crewai_tools import LinkupSearchTool
from crewai import Agent
import os

# Inicialize a ferramenta com sua chave de API
linkup_ferramenta = LinkupSearchTool(api_key=os.getenv("LINKUP_API_KEY"))

# Defina um agente que usa a ferramenta
@agent
def pesquisador(self) -> Agent:
    '''
    Este agente usa o LinkupSearchTool para recuperar informa√ß√µes contextuais
    da API do Linkup.
    '''
    return Agent(
        config=self.agentes_config["pesquisador"],
        tools=[linkup_ferramenta]
    )
```


# Vis√£o Geral
Source: https://docs.crewai.com/pt-BR/tools/search-research/overview

Realize pesquisas na web, encontre reposit√≥rios e pesquise informa√ß√µes em toda a internet

Essas ferramentas permitem que seus agentes pesquisem na web, explorem t√≥picos e encontrem informa√ß√µes em diversas plataformas, incluindo motores de busca, GitHub e YouTube.

## **Ferramentas Dispon√≠veis**

<CardGroup cols={2}>
  <Card title="Serper Dev Tool" icon="google" href="/pt-BR/tools/search-research/serperdevtool">
    Integra√ß√£o com a API de busca do Google para capacidades abrangentes de pesquisa na web.
  </Card>

  <Card title="Brave Search Tool" icon="shield" href="/pt-BR/tools/search-research/bravesearchtool">
    Pesquisa voltada para privacidade com o √≠ndice independente de busca do Brave.
  </Card>

  <Card title="Exa Search Tool" icon="magnifying-glass" href="/pt-BR/tools/search-research/exasearchtool">
    Pesquisa impulsionada por IA para encontrar conte√∫do espec√≠fico e relevante.
  </Card>

  <Card title="LinkUp Search Tool" icon="link" href="/pt-BR/tools/search-research/linkupsearchtool">
    Pesquisa em tempo real na web com indexa√ß√£o de conte√∫do atualizado.
  </Card>

  <Card title="GitHub Search Tool" icon="github" href="/pt-BR/tools/search-research/githubsearchtool">
    Pesquise reposit√≥rios do GitHub, c√≥digos, issues e documenta√ß√£o.
  </Card>

  <Card title="Website Search Tool" icon="globe" href="/pt-BR/tools/search-research/websitesearchtool">
    Pesquisa dentro de sites e dom√≠nios espec√≠ficos.
  </Card>

  <Card title="Code Docs Search Tool" icon="code" href="/pt-BR/tools/search-research/codedocssearchtool">
    Pesquise em documenta√ß√£o de c√≥digo e recursos t√©cnicos.
  </Card>

  <Card title="YouTube Channel Search" icon="youtube" href="/pt-BR/tools/search-research/youtubechannelsearchtool">
    Pesquise canais do YouTube para encontrar conte√∫dos e criadores espec√≠ficos.
  </Card>

  <Card title="YouTube Video Search" icon="play" href="/pt-BR/tools/search-research/youtubevideosearchtool">
    Encontre e analise v√≠deos do YouTube por assunto, palavra-chave ou crit√©rio.
  </Card>
</CardGroup>

## **Casos de Uso Comuns**

* **Pesquisa de Mercado**: Pesquise tend√™ncias de mercado e an√°lise de concorrentes
* **Descoberta de Conte√∫do**: Encontre artigos, v√≠deos e recursos relevantes
* **Pesquisa de C√≥digo**: Pesquise reposit√≥rios e documenta√ß√£o em busca de solu√ß√µes
* **Gera√ß√£o de Leads**: Pesquise empresas e pessoas
* **Pesquisa Acad√™mica**: Encontre artigos cient√≠ficos e trabalhos t√©cnicos

```python
from crewai_tools import SerperDevTool, GitHubSearchTool, YoutubeVideoSearchTool

# Create research tools
web_search = SerperDevTool()
code_search = GitHubSearchTool()
video_research = YoutubeVideoSearchTool()

# Add to your agent
agent = Agent(
    role="Research Analyst",
    tools=[web_search, code_search, video_research],
    goal="Gather comprehensive information on any topic"
)
```


# Pesquisa Serper Google
Source: https://docs.crewai.com/pt-BR/tools/search-research/serperdevtool

O `SerperDevTool` √© projetado para pesquisar na internet e retornar os resultados mais relevantes.

# `SerperDevTool`

<Note>
  Ainda estamos trabalhando na melhoria das ferramentas, portanto, pode haver comportamentos inesperados ou mudan√ßas no futuro.
</Note>

## Descri√ß√£o

Esta ferramenta foi projetada para realizar buscas sem√¢nticas para uma consulta especificada a partir do conte√∫do de um texto na internet. Ela utiliza a API do [serper.dev](https://serper.dev)
para buscar e exibir os resultados de pesquisa mais relevantes com base na consulta fornecida pelo usu√°rio.

## Instala√ß√£o

Para incorporar esta ferramenta em seu projeto, siga as instru√ß√µes de instala√ß√£o abaixo:

```shell
pip install 'crewai[tools]'
```

## Exemplo

O exemplo a seguir demonstra como inicializar a ferramenta e executar uma busca com uma consulta fornecida:

```python Code
from crewai_tools import SerperDevTool

# Inicializar a ferramenta para capacidades de busca na internet
tool = SerperDevTool()
```

## Etapas para Come√ßar

Para utilizar o `SerperDevTool` de forma eficaz, siga estes passos:

1. **Instala√ß√£o do Pacote**: Confirme se o pacote `crewai[tools]` est√° instalado em seu ambiente Python.
2. **Obten√ß√£o da Chave de API**: Adquira uma chave de API do `serper.dev` registrando-se para uma conta gratuita em `serper.dev`.
3. **Configura√ß√£o do Ambiente**: Armazene sua chave de API obtida em uma vari√°vel de ambiente chamada `SERPER_API_KEY` para facilitar o uso pela ferramenta.

## Par√¢metros

O `SerperDevTool` possui v√°rios par√¢metros que ser√£o passados para a API:

* **search\_url**: O endpoint da URL para a API de busca. (Padr√£o √© `https://google.serper.dev/search`)

* **country**: Opcional. Especifica o pa√≠s para os resultados de busca.

* **location**: Opcional. Especifica a localiza√ß√£o para os resultados de busca.

* **locale**: Opcional. Especifica o local para os resultados de busca.

* **n\_results**: N√∫mero de resultados de busca a serem retornados. O padr√£o √© `10`.

Os valores para `country`, `location`, `locale` e `search_url` podem ser encontrados no [Serper Playground](https://serper.dev/playground).

## Exemplo com Par√¢metros

Aqui est√° um exemplo demonstrando como usar a ferramenta com par√¢metros adicionais:

```python Code
from crewai_tools import SerperDevTool

tool = SerperDevTool(
    search_url="https://google.serper.dev/scholar",
    n_results=2,
)

print(tool.run(search_query="ChatGPT"))

# Using Tool: Search the internet

# Search results: Title: Role of chat gpt in public health
# Link: https://link.springer.com/article/10.1007/s10439-023-03172-7
# Snippet: ‚Ä¶ ChatGPT in public health. In this overview, we will examine the potential uses of ChatGPT in
# ---
# Title: Potential use of chat gpt in global warming
# Link: https://link.springer.com/article/10.1007/s10439-023-03171-8
# Snippet: ‚Ä¶ as ChatGPT, have the potential to play a critical role in advancing our understanding of climate
# ---

```

```python Code
from crewai_tools import SerperDevTool

tool = SerperDevTool(
    country="fr",
    locale="fr",
    location="Paris, Paris, Ile-de-France, France",
    n_results=2,
)

print(tool.run(search_query="Jeux Olympiques"))

# Using Tool: Search the internet

# Search results: Title: Jeux Olympiques de Paris 2024 - Actualit√©s, calendriers, r√©sultats
# Link: https://olympics.com/fr/paris-2024
# Snippet: Quels sont les sports pr√©sents aux Jeux Olympiques de Paris 2024 ? ¬∑ Athl√©tisme ¬∑ Aviron ¬∑ Badminton ¬∑ Basketball ¬∑ Basketball 3x3 ¬∑ Boxe ¬∑ Breaking ¬∑ Cano√´ ...
# ---
# Title: Billetterie Officielle de Paris 2024 - Jeux Olympiques et Paralympiques
# Link: https://tickets.paris2024.org/
# Snippet: Achetez vos billets exclusivement sur le site officiel de la billetterie de Paris 2024 pour participer au plus grand √©v√©nement sportif au monde.
# ---
```

## Conclus√£o

Ao integrar o `SerperDevTool` em projetos Python, os usu√°rios obt√™m a capacidade de realizar buscas em tempo real e relevantes na internet diretamente de suas aplica√ß√µes.
Os par√¢metros atualizados permitem resultados de busca mais personalizados e localizados. Seguindo as diretrizes de configura√ß√£o e uso fornecidas, a incorpora√ß√£o desta ferramenta nos projetos √© simplificada e direta.


# Pesquisa RAG em Sites
Source: https://docs.crewai.com/pt-BR/tools/search-research/websitesearchtool

O `WebsiteSearchTool` foi projetado para realizar uma busca RAG (Gera√ß√£o Aumentada por Recupera√ß√£o) dentro do conte√∫do de um site.

# `WebsiteSearchTool`

<Note>
  O WebsiteSearchTool est√° atualmente em fase experimental. Estamos trabalhando ativamente para incorporar esta ferramenta em nosso conjunto de ofertas e atualizaremos a documenta√ß√£o conforme necess√°rio.
</Note>

## Descri√ß√£o

O WebsiteSearchTool foi concebido como um conceito para realizar buscas sem√¢nticas dentro do conte√∫do de sites.
Ele visa aproveitar modelos avan√ßados de aprendizado de m√°quina, como a Gera√ß√£o Aumentada por Recupera√ß√£o (RAG), para navegar e extrair informa√ß√µes de URLs especificadas de forma eficiente.
Esta ferramenta pretende oferecer flexibilidade, permitindo que usu√°rios realizem buscas em qualquer site ou foquem em sites espec√≠ficos de seu interesse.
Por favor, note que os detalhes da implementa√ß√£o atual do WebsiteSearchTool est√£o em desenvolvimento, e as funcionalidades aqui descritas podem ainda n√£o estar acess√≠veis.

## Instala√ß√£o

Para preparar seu ambiente para quando o WebsiteSearchTool estiver dispon√≠vel, voc√™ pode instalar o pacote fundamental com:

```shell
pip install 'crewai[tools]'
```

Este comando instala as depend√™ncias necess√°rias para garantir que, assim que a ferramenta estiver totalmente integrada, os usu√°rios possam come√ßar a us√°-la imediatamente.

## Exemplo de Uso

Abaixo est√£o exemplos de como o WebsiteSearchTool poder√° ser utilizado em diferentes cen√°rios. Por favor, observe que esses exemplos s√£o ilustrativos e representam funcionalidades planejadas:

```python Code
from crewai_tools import WebsiteSearchTool

# Exemplo de inicializa√ß√£o da ferramenta que agentes podem usar
# para pesquisar em quaisquer sites descobertos
tool = WebsiteSearchTool()

# Exemplo de limita√ß√£o da busca ao conte√∫do de um site espec√≠fico,
# assim os agentes podem buscar somente dentro desse site
tool = WebsiteSearchTool(website='https://example.com')
```

## Argumentos

* `website`: Um argumento opcional destinado a especificar a URL do site para buscas direcionadas. Este argumento foi projetado para aumentar a flexibilidade da ferramenta, permitindo buscas mais focadas quando necess√°rio.

## Op√ß√µes de Personaliza√ß√£o

Por padr√£o, a ferramenta utiliza a OpenAI tanto para embeddings quanto para sumariza√ß√£o. Para personalizar o modelo, voc√™ pode usar um dicion√°rio de configura√ß√£o, conforme o exemplo abaixo:

```python Code
tool = WebsiteSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```


# Busca RAG em Canal do YouTube
Source: https://docs.crewai.com/pt-BR/tools/search-research/youtubechannelsearchtool

O `YoutubeChannelSearchTool` foi desenvolvido para realizar buscas RAG (Retrieval-Augmented Generation) no conte√∫do de um canal do Youtube.

# `YoutubeChannelSearchTool`

<Note>
  Ainda estamos trabalhando para melhorar as ferramentas, ent√£o pode haver comportamentos inesperados ou altera√ß√µes no futuro.
</Note>

## Descri√ß√£o

Esta ferramenta foi desenvolvida para realizar buscas sem√¢nticas dentro do conte√∫do de um canal espec√≠fico do Youtube.
Aproveitando a metodologia RAG (Retrieval-Augmented Generation), ela fornece resultados de busca relevantes,
tornando-se indispens√°vel para extrair informa√ß√µes ou encontrar conte√∫dos espec√≠ficos sem a necessidade de percorrer manualmente os v√≠deos.
Ela otimiza o processo de busca em canais do Youtube, sendo ideal para pesquisadores, criadores de conte√∫do e espectadores que buscam informa√ß√µes ou temas espec√≠ficos.

## Instala√ß√£o

Para utilizar o YoutubeChannelSearchTool, √© necess√°rio instalar o pacote `crewai_tools`. Execute o seguinte comando no seu terminal para instalar:

```shell
pip install 'crewai[tools]'
```

## Exemplo

O exemplo a seguir demonstra como utilizar o `YoutubeChannelSearchTool` com um agente CrewAI:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import YoutubeChannelSearchTool

# Inicializa a ferramenta para buscas gerais em canais do YouTube
youtube_channel_tool = YoutubeChannelSearchTool()

# Define um agente que utiliza a ferramenta
channel_researcher = Agent(
    role="Channel Researcher",
    goal="Extrair informa√ß√µes relevantes de canais do YouTube",
    backstory="Um pesquisador especialista em analisar conte√∫dos de canais do YouTube.",
    tools=[youtube_channel_tool],
    verbose=True,
)

# Exemplo de tarefa para buscar informa√ß√µes em um canal espec√≠fico
research_task = Task(
    description="Buscar informa√ß√µes sobre tutoriais de machine learning no canal do YouTube {youtube_channel_handle}",
    expected_output="Um resumo dos principais tutoriais de machine learning dispon√≠veis no canal.",
    agent=channel_researcher,
)

# Cria e executa o crew
crew = Crew(agents=[channel_researcher], tasks=[research_task])
result = crew.kickoff(inputs={"youtube_channel_handle": "@exampleChannel"})
```

Voc√™ tamb√©m pode inicializar a ferramenta com um handle espec√≠fico de canal do YouTube:

```python Code
# Inicializa a ferramenta com o handle espec√≠fico de um canal do YouTube
youtube_channel_tool = YoutubeChannelSearchTool(
    youtube_channel_handle='@exampleChannel'
)

# Define um agente que utiliza a ferramenta
channel_researcher = Agent(
    role="Channel Researcher",
    goal="Extrair informa√ß√µes relevantes de um canal espec√≠fico do YouTube",
    backstory="Um pesquisador especialista em analisar conte√∫dos de canais do YouTube.",
    tools=[youtube_channel_tool],
    verbose=True,
)
```

## Par√¢metros

O `YoutubeChannelSearchTool` aceita os seguintes par√¢metros:

* **youtube\_channel\_handle**: Opcional. O handle do canal do YouTube para realizar a busca. Se fornecido durante a inicializa√ß√£o, o agente n√£o precisar√° inform√°-lo ao utilizar a ferramenta. Se o handle n√£o come√ßar com '@', ser√° adicionado automaticamente.
* **config**: Opcional. Configura√ß√µes para o sistema RAG subjacente, incluindo par√¢metros de LLM e embedder.
* **summarize**: Opcional. Indica se o conte√∫do recuperado deve ser resumido. O padr√£o √© `False`.

Ao utilizar a ferramenta com um agente, o agente dever√° fornecer:

* **search\_query**: Obrigat√≥rio. A consulta de busca para encontrar informa√ß√µes relevantes no conte√∫do do canal.
* **youtube\_channel\_handle**: Obrigat√≥rio apenas se n√£o for fornecido durante a inicializa√ß√£o. O handle do canal do YouTube onde realizar a busca.

## Modelo Personalizado e Embeddings

Por padr√£o, a ferramenta utiliza o OpenAI tanto para embeddings quanto para sumariza√ß√£o. Para personalizar o modelo, √© poss√≠vel usar um dicion√°rio de configura√ß√£o como no exemplo:

```python Code
youtube_channel_tool = YoutubeChannelSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```

## Exemplo de Integra√ß√£o com Agente

Veja um exemplo mais detalhado de como integrar o `YoutubeChannelSearchTool` com um agente CrewAI:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import YoutubeChannelSearchTool

# Inicializa a ferramenta
youtube_channel_tool = YoutubeChannelSearchTool()

# Define um agente que utiliza a ferramenta
channel_researcher = Agent(
    role="Channel Researcher",
    goal="Extrair e analisar informa√ß√µes de canais do YouTube",
    backstory="""Voc√™ √© um pesquisador especialista em canais, com experi√™ncia
    em extrair e analisar informa√ß√µes de canais do YouTube. Voc√™ possui olho cl√≠nico para detalhes
    e pode rapidamente identificar pontos-chave e insights a partir do conte√∫do em v√≠deo de todo o canal.""",
    tools=[youtube_channel_tool],
    verbose=True,
)

# Crie uma tarefa para o agente
research_task = Task(
    description="""
    Buscar informa√ß√µes sobre projetos e tutoriais de ci√™ncia de dados
    no canal do YouTube {youtube_channel_handle}.

    Foque em:
    1. Principais t√©cnicas de ci√™ncia de dados abordadas
    2. S√©ries de tutoriais populares
    3. V√≠deos mais vistos ou recomendados

    Forne√ßa um resumo abrangente sobre esses pontos.
    """,
    expected_output="Um resumo detalhado sobre o conte√∫do de ci√™ncia de dados dispon√≠vel no canal.",
    agent=channel_researcher,
)

# Execute a tarefa
crew = Crew(agents=[channel_researcher], tasks=[research_task])
result = crew.kickoff(inputs={"youtube_channel_handle": "@exampleDataScienceChannel"})
```

## Detalhes da Implementa√ß√£o

O `YoutubeChannelSearchTool` √© implementado como uma subclasse de `RagTool`, que fornece a funcionalidade base para Retrieval-Augmented Generation:

```python Code
class YoutubeChannelSearchTool(RagTool):
    name: str = "Search a Youtube Channels content"
    description: str = "A tool that can be used to semantic search a query from a Youtube Channels content."
    args_schema: Type[BaseModel] = YoutubeChannelSearchToolSchema

    def __init__(self, youtube_channel_handle: Optional[str] = None, **kwargs):
        super().__init__(**kwargs)
        if youtube_channel_handle is not None:
            kwargs["data_type"] = DataType.YOUTUBE_CHANNEL
            self.add(youtube_channel_handle)
            self.description = f"A tool that can be used to semantic search a query the {youtube_channel_handle} Youtube Channels content."
            self.args_schema = FixedYoutubeChannelSearchToolSchema
            self._generate_description()

    def add(
        self,
        youtube_channel_handle: str,
        **kwargs: Any,
    ) -> None:
        if not youtube_channel_handle.startswith("@"):
            youtube_channel_handle = f"@{youtube_channel_handle}"
        super().add(youtube_channel_handle, **kwargs)
```

## Conclus√£o

O `YoutubeChannelSearchTool` oferece uma forma poderosa de buscar e extrair informa√ß√µes do conte√∫do de canais do YouTube utilizando t√©cnicas RAG. Ao possibilitar que agentes busquem entre todos os v√≠deos de um canal, facilita tarefas de extra√ß√£o e an√°lise de informa√ß√µes que seriam dif√≠ceis de executar manualmente. Esta ferramenta √© especialmente √∫til para pesquisa, an√°lise de conte√∫do e extra√ß√£o de conhecimento de canais do YouTube.


# Pesquisa RAG em V√≠deos do YouTube
Source: https://docs.crewai.com/pt-BR/tools/search-research/youtubevideosearchtool

O `YoutubeVideoSearchTool` foi projetado para realizar uma busca RAG (Gera√ß√£o Auxiliada por Recupera√ß√£o) no conte√∫do de um v√≠deo do Youtube.

# `YoutubeVideoSearchTool`

<Note>
  Ainda estamos trabalhando para melhorar as ferramentas, portanto podem ocorrer comportamentos inesperados ou mudan√ßas no futuro.
</Note>

## Descri√ß√£o

Esta ferramenta faz parte do pacote `crewai_tools` e foi projetada para realizar buscas sem√¢nticas dentro do conte√∫do de v√≠deos do Youtube, utilizando t√©cnicas de Gera√ß√£o Auxiliada por Recupera√ß√£o (RAG).
√â uma das diversas ferramentas de "Pesquisa" do pacote que aproveitam RAG para diferentes fontes.
O YoutubeVideoSearchTool permite flexibilidade nas buscas: usu√°rios podem pesquisar em qualquer conte√∫do de v√≠deo do Youtube sem especificar uma URL,
ou podem direcionar sua busca para um v√≠deo espec√≠fico fornecendo sua URL.

## Instala√ß√£o

Para utilizar o `YoutubeVideoSearchTool`, √© necess√°rio primeiro instalar o pacote `crewai_tools`.
Esse pacote cont√©m o `YoutubeVideoSearchTool` entre outras utilidades desenvolvidas para melhorar suas tarefas de an√°lise e processamento de dados.
Instale o pacote executando o seguinte comando em seu terminal:

```shell
pip install 'crewai[tools]'
```

## Exemplo

O exemplo a seguir demonstra como usar o `YoutubeVideoSearchTool` com um agente CrewAI:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import YoutubeVideoSearchTool

# Inicialize a ferramenta para buscas gerais em v√≠deos do YouTube
youtube_search_tool = YoutubeVideoSearchTool()

# Defina um agente que usa a ferramenta
video_researcher = Agent(
    role="Video Researcher",
    goal="Extract relevant information from YouTube videos",
    backstory="An expert researcher who specializes in analyzing video content.",
    tools=[youtube_search_tool],
    verbose=True,
)

# Exemplo de tarefa para buscar informa√ß√µes em um v√≠deo espec√≠fico
research_task = Task(
    description="Search for information about machine learning frameworks in the YouTube video at {youtube_video_url}",
    expected_output="A summary of the key machine learning frameworks mentioned in the video.",
    agent=video_researcher,
)

# Crie e execute a crew
crew = Crew(agents=[video_researcher], tasks=[research_task])
result = crew.kickoff(inputs={"youtube_video_url": "https://youtube.com/watch?v=example"})
```

Voc√™ tamb√©m pode inicializar a ferramenta com a URL de um v√≠deo espec√≠fico do YouTube:

```python Code
# Inicialize a ferramenta com a URL de um v√≠deo espec√≠fico do YouTube
youtube_search_tool = YoutubeVideoSearchTool(
    youtube_video_url='https://youtube.com/watch?v=example'
)

# Defina um agente que usa a ferramenta
video_researcher = Agent(
    role="Video Researcher",
    goal="Extract relevant information from a specific YouTube video",
    backstory="An expert researcher who specializes in analyzing video content.",
    tools=[youtube_search_tool],
    verbose=True,
)
```

## Par√¢metros

O `YoutubeVideoSearchTool` aceita os seguintes par√¢metros:

* **youtube\_video\_url**: Opcional. A URL do v√≠deo do YouTube para pesquisa. Se fornecida durante a inicializa√ß√£o, o agente n√£o precisar√° especificar ao utilizar a ferramenta.
* **config**: Opcional. Configura√ß√£o para o sistema RAG subjacente, incluindo defini√ß√µes de LLM e embedder.
* **summarize**: Opcional. Indica se o conte√∫do recuperado deve ser resumido. O padr√£o √© `False`.

Ao usar a ferramenta com um agente, √© necess√°rio fornecer:

* **search\_query**: Obrigat√≥rio. A consulta de busca para encontrar informa√ß√µes relevantes no conte√∫do do v√≠deo.
* **youtube\_video\_url**: Obrigat√≥rio somente se n√£o for fornecida na inicializa√ß√£o. A URL do v√≠deo do YouTube a ser pesquisado.

## Modelo e Embeddings Personalizados

Por padr√£o, a ferramenta utiliza OpenAI tanto para embeddings quanto para sumariza√ß√£o. Para personalizar o modelo, utilize um dicion√°rio de configura√ß√£o conforme exemplo:

```python Code
youtube_search_tool = YoutubeVideoSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # ou google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google", # ou openai, ollama, ...
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```

## Exemplo de Integra√ß√£o com Agente

Aqui est√° um exemplo mais detalhado de como integrar o `YoutubeVideoSearchTool` com um agente CrewAI:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import YoutubeVideoSearchTool

# Inicialize a ferramenta
youtube_search_tool = YoutubeVideoSearchTool()

# Defina um agente que usa a ferramenta
video_researcher = Agent(
    role="Video Researcher",
    goal="Extract and analyze information from YouTube videos",
    backstory="""You are an expert video researcher who specializes in extracting
    and analyzing information from YouTube videos. You have a keen eye for detail
    and can quickly identify key points and insights from video content.""",
    tools=[youtube_search_tool],
    verbose=True,
)

# Crie uma tarefa para o agente
research_task = Task(
    description="""
    Search for information about recent advancements in artificial intelligence
    in the YouTube video at {youtube_video_url}.

    Focus on:
    1. Key AI technologies mentioned
    2. Real-world applications discussed
    3. Future predictions made by the speaker

    Provide a comprehensive summary of these points.
    """,
    expected_output="A detailed summary of AI advancements, applications, and future predictions from the video.",
    agent=video_researcher,
)

# Execute a tarefa
crew = Crew(agents=[video_researcher], tasks=[research_task])
result = crew.kickoff(inputs={"youtube_video_url": "https://youtube.com/watch?v=example"})
```

## Detalhes de Implementa√ß√£o

O `YoutubeVideoSearchTool` √© implementado como uma subclasse de `RagTool`, que fornece a funcionalidade base para Gera√ß√£o Auxiliada por Recupera√ß√£o:

```python Code
class YoutubeVideoSearchTool(RagTool):
    name: str = "Search a Youtube Video content"
    description: str = "A tool that can be used to semantic search a query from a Youtube Video content."
    args_schema: Type[BaseModel] = YoutubeVideoSearchToolSchema

    def __init__(self, youtube_video_url: Optional[str] = None, **kwargs):
        super().__init__(**kwargs)
        if youtube_video_url is not None:
            kwargs["data_type"] = DataType.YOUTUBE_VIDEO
            self.add(youtube_video_url)
            self.description = f"A tool that can be used to semantic search a query the {youtube_video_url} Youtube Video content."
            self.args_schema = FixedYoutubeVideoSearchToolSchema
            self._generate_description()
```

## Conclus√£o

O `YoutubeVideoSearchTool` oferece uma maneira poderosa de pesquisar e extrair informa√ß√µes de conte√∫dos de v√≠deos do YouTube utilizando t√©cnicas RAG. Ao possibilitar que agentes pesquisem dentro do conte√∫do dos v√≠deos, facilita tarefas de extra√ß√£o e an√°lise de informa√ß√£o que anteriormente seriam dif√≠ceis de realizar. Esta ferramenta √© especialmente √∫til para pesquisas, an√°lise de conte√∫do e extra√ß√£o de conhecimento a partir de fontes em v√≠deo.


# Carregador Web Browserbase
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/browserbaseloadtool

O Browserbase √© uma plataforma para desenvolvedores para executar, gerenciar e monitorar navegadores headless de forma confi√°vel.

# `BrowserbaseLoadTool`

## Descri√ß√£o

[Browserbase](https://browserbase.com) √© uma plataforma para desenvolvedores que permite executar, gerenciar e monitorar navegadores headless de forma confi√°vel.

Potencialize suas buscas de dados para IA com:

* [Infraestrutura Serverless](https://docs.browserbase.com/under-the-hood) fornecendo navegadores confi√°veis para extrair dados de interfaces complexas
* [Modo Stealth](https://docs.browserbase.com/features/stealth-mode) com t√°ticas de fingerprinting e resolu√ß√£o autom√°tica de captcha inclu√≠das
* [Depurador de Sess√£o](https://docs.browserbase.com/features/sessions) para inspecionar sua Sess√£o do Navegador com linha do tempo de rede e logs
* [Depura√ß√£o Ao Vivo](https://docs.browserbase.com/guides/session-debug-connection/browser-remote-control) para depurar rapidamente sua automa√ß√£o

## Instala√ß√£o

* Obtenha uma chave de API e o Project ID em [browserbase.com](https://browserbase.com) e defina-os nas vari√°veis de ambiente (`BROWSERBASE_API_KEY`, `BROWSERBASE_PROJECT_ID`).
* Instale o [SDK do Browserbase](http://github.com/browserbase/python-sdk) juntamente com o pacote `crewai[tools]`:

```shell
pip install browserbase 'crewai[tools]'
```

## Exemplo

Utilize o BrowserbaseLoadTool conforme abaixo para permitir que seu agente carregue sites:

```python Code
from crewai_tools import BrowserbaseLoadTool

# Inicialize a ferramenta com a chave da API do Browserbase e o Project ID
tool = BrowserbaseLoadTool()
```

## Argumentos

Os par√¢metros a seguir podem ser usados para customizar o comportamento do `BrowserbaseLoadTool`:

| Argumento         | Tipo     | Descri√ß√£o                                                                                        |
| :---------------- | :------- | :----------------------------------------------------------------------------------------------- |
| **api\_key**      | `string` | *Opcional*. Chave de API do Browserbase. Padr√£o √© a vari√°vel de ambiente `BROWSERBASE_API_KEY`.  |
| **project\_id**   | `string` | *Opcional*. Project ID do Browserbase. Padr√£o √© a vari√°vel de ambiente `BROWSERBASE_PROJECT_ID`. |
| **text\_content** | `bool`   | *Opcional*. Recuperar somente o conte√∫do em texto. O padr√£o √© `False`.                           |
| **session\_id**   | `string` | *Opcional*. Forne√ßa um Session ID existente.                                                     |
| **proxy**         | `bool`   | *Opcional*. Habilitar/Desabilitar proxies. O padr√£o √© `False`.                                   |


# Firecrawl Crawl Website
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/firecrawlcrawlwebsitetool

O `FirecrawlCrawlWebsiteTool` foi projetado para rastrear e converter sites em markdown limpo ou dados estruturados.

# `FirecrawlCrawlWebsiteTool`

## Descri√ß√£o

[Firecrawl](https://firecrawl.dev) √© uma plataforma para rastrear e converter qualquer site em markdown limpo ou dados estruturados.

## Instala√ß√£o

* Obtenha uma chave de API em [firecrawl.dev](https://firecrawl.dev) e defina-a nas vari√°veis de ambiente (`FIRECRAWL_API_KEY`).
* Instale o [SDK do Firecrawl](https://github.com/mendableai/firecrawl) junto com o pacote `crewai[tools]`:

```shell
pip install firecrawl-py 'crewai[tools]'
```

## Exemplo

Utilize o FirecrawlScrapeFromWebsiteTool como a seguir para permitir que seu agente carregue sites:

```python Code
from crewai_tools import FirecrawlCrawlWebsiteTool

tool = FirecrawlCrawlWebsiteTool(url='firecrawl.dev')
```

## Argumentos

* `api_key`: Opcional. Especifica a chave de API do Firecrawl. Por padr√£o, utiliza a vari√°vel de ambiente `FIRECRAWL_API_KEY`.
* `url`: A URL base para iniciar o rastreamento.
* `page_options`: Opcional.
  * `onlyMainContent`: Opcional. Retorna apenas o conte√∫do principal da p√°gina, excluindo cabe√ßalhos, navega√ß√µes, rodap√©s, etc.
  * `includeHtml`: Opcional. Inclui o conte√∫do HTML bruto da p√°gina. Vai adicionar uma chave html na resposta.
* `crawler_options`: Opcional. Op√ß√µes para controlar o comportamento do rastreamento.
  * `includes`: Opcional. Padr√µes de URL para incluir no rastreamento.
  * `exclude`: Opcional. Padr√µes de URL para excluir do rastreamento.
  * `generateImgAltText`: Opcional. Gera texto alternativo para imagens usando LLMs (requer um plano pago).
  * `returnOnlyUrls`: Opcional. Se verdadeiro, retorna apenas as URLs como uma lista no status do rastreamento. Nota: a resposta ser√° uma lista de URLs dentro do campo data, n√£o uma lista de documentos.
  * `maxDepth`: Opcional. Profundidade m√°xima de rastreamento. Profundidade 1 √© a URL base, profundidade 2 inclui a URL base e seus filhos diretos, e assim por diante.
  * `mode`: Opcional. O modo de rastreamento a ser utilizado. O modo r√°pido rastreia 4x mais r√°pido em sites sem sitemap, mas pode n√£o ser t√£o preciso e n√£o deve ser usado em sites fortemente renderizados com JavaScript.
  * `limit`: Opcional. N√∫mero m√°ximo de p√°ginas a serem rastreadas.
  * `timeout`: Opcional. Tempo limite em milissegundos para a opera√ß√£o de rastreamento.


# Firecrawl Scrape Website
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/firecrawlscrapewebsitetool

A ferramenta `FirecrawlScrapeWebsiteTool` foi projetada para fazer scraping de sites e convert√™-los em markdown limpo ou dados estruturados.

# `FirecrawlScrapeWebsiteTool`

## Descri√ß√£o

[Firecrawl](https://firecrawl.dev) √© uma plataforma para rastrear e converter qualquer site em markdown limpo ou dados estruturados.

## Instala√ß√£o

* Obtenha uma chave de API em [firecrawl.dev](https://firecrawl.dev) e defina-a nas vari√°veis de ambiente (`FIRECRAWL_API_KEY`).
* Instale o [Firecrawl SDK](https://github.com/mendableai/firecrawl) junto com o pacote `crewai[tools]`:

```shell
pip install firecrawl-py 'crewai[tools]'
```

## Exemplo

Utilize o FirecrawlScrapeWebsiteTool da seguinte forma para permitir que seu agente carregue sites:

```python Code
from crewai_tools import FirecrawlScrapeWebsiteTool

tool = FirecrawlScrapeWebsiteTool(url='firecrawl.dev')
```

## Argumentos

* `api_key`: Opcional. Especifica a chave de API do Firecrawl. O padr√£o √© a vari√°vel de ambiente `FIRECRAWL_API_KEY`.
* `url`: A URL a ser raspada.
* `page_options`: Opcional.
  * `onlyMainContent`: Opcional. Retorna apenas o conte√∫do principal da p√°gina, excluindo cabe√ßalhos, navega√ß√µes, rodap√©s, etc.
  * `includeHtml`: Opcional. Inclui o conte√∫do HTML bruto da p√°gina. Ir√° gerar uma chave html na resposta.
* `extractor_options`: Opcional. Op√ß√µes para extra√ß√£o baseada em LLM de informa√ß√µes estruturadas do conte√∫do da p√°gina
  * `mode`: O modo de extra√ß√£o a ser utilizado, atualmente suporta 'llm-extraction'
  * `extractionPrompt`: Opcional. Um prompt descrevendo quais informa√ß√µes extrair da p√°gina
  * `extractionSchema`: Opcional. O esquema para os dados a serem extra√≠dos
* `timeout`: Opcional. Timeout em milissegundos para a requisi√ß√£o


# Firecrawl Search
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/firecrawlsearchtool

O `FirecrawlSearchTool` foi projetado para pesquisar sites e convert√™-los em markdown limpo ou dados estruturados.

# `FirecrawlSearchTool`

## Descri√ß√£o

[Firecrawl](https://firecrawl.dev) √© uma plataforma para rastrear e converter qualquer site em markdown limpo ou dados estruturados.

## Instala√ß√£o

* Obtenha uma chave de API em [firecrawl.dev](https://firecrawl.dev) e defina-a nas vari√°veis de ambiente (`FIRECRAWL_API_KEY`).
* Instale o [Firecrawl SDK](https://github.com/mendableai/firecrawl) junto com o pacote `crewai[tools]`:

```shell
pip install firecrawl-py 'crewai[tools]'
```

## Exemplo

Utilize o FirecrawlSearchTool da seguinte forma para permitir que seu agente carregue sites:

```python Code
from crewai_tools import FirecrawlSearchTool

tool = FirecrawlSearchTool(query='what is firecrawl?')
```

## Argumentos

* `api_key`: Opcional. Especifica a chave de API do Firecrawl. O padr√£o √© a vari√°vel de ambiente `FIRECRAWL_API_KEY`.
* `query`: A string da consulta de busca a ser utilizada na pesquisa.
* `page_options`: Opcional. Op√ß√µes para formata√ß√£o dos resultados.
  * `onlyMainContent`: Opcional. Retorna somente o conte√∫do principal da p√°gina, excluindo cabe√ßalhos, navega√ß√µes, rodap√©s, etc.
  * `includeHtml`: Opcional. Inclui o conte√∫do HTML bruto da p√°gina. Vai gerar uma chave html na resposta.
  * `fetchPageContent`: Opcional. Busca o conte√∫do completo da p√°gina.
* `search_options`: Opcional. Op√ß√µes para controle do comportamento de rastreamento.
  * `limit`: Opcional. N√∫mero m√°ximo de p√°ginas a rastrear.


# Hyperbrowser Load Tool
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/hyperbrowserloadtool

O `HyperbrowserLoadTool` permite realizar web scraping e crawling utilizando o Hyperbrowser.

# `HyperbrowserLoadTool`

## Descri√ß√£o

O `HyperbrowserLoadTool` permite realizar web scraping e crawling utilizando o [Hyperbrowser](https://hyperbrowser.ai), uma plataforma para executar e escalar browsers headless. Essa ferramenta possibilita extrair dados de uma √∫nica p√°gina ou rastrear um site inteiro, retornando o conte√∫do em markdown ou HTML corretamente formatado.

Principais Caracter√≠sticas:

* Escalabilidade Instant√¢nea ‚Äì Inicie centenas de sess√µes de browser em segundos sem se preocupar com infraestrutura
* Integra√ß√£o Simples ‚Äì Funciona perfeitamente com ferramentas populares como Puppeteer e Playwright
* APIs Poderosas ‚Äì APIs f√°ceis de usar para scraping/crawling de qualquer site
* Supera Medidas Anti-Bot ‚Äì Inclui modo stealth, bloqueio de an√∫ncios, resolu√ß√£o autom√°tica de CAPTCHA e proxies rotativos

## Instala√ß√£o

Para utilizar esta ferramenta, voc√™ precisa instalar o SDK do Hyperbrowser:

```shell
uv add hyperbrowser
```

## Passos para Come√ßar

Para usar efetivamente o `HyperbrowserLoadTool`, siga estes passos:

1. **Cadastre-se**: V√° at√© o [Hyperbrowser](https://app.hyperbrowser.ai/) para criar uma conta e gerar uma chave de API.
2. **Chave de API**: Defina a vari√°vel de ambiente `HYPERBROWSER_API_KEY` ou passe-a diretamente no construtor da ferramenta.
3. **Instale o SDK**: Instale o SDK do Hyperbrowser usando o comando acima.

## Exemplo

O exemplo a seguir demonstra como inicializar a ferramenta e utiliz√°-la para extrair dados de um site:

```python Code
from crewai_tools import HyperbrowserLoadTool
from crewai import Agent

# Initialize the tool with your API key
tool = HyperbrowserLoadTool(api_key="your_api_key")  # Or use environment variable

# Define an agent that uses the tool
@agent
def web_researcher(self) -> Agent:
    '''
    This agent uses the HyperbrowserLoadTool to scrape websites
    and extract information.
    '''
    return Agent(
        config=self.agents_config["web_researcher"],
        tools=[tool]
    )
```

## Par√¢metros

O `HyperbrowserLoadTool` aceita os seguintes par√¢metros:

### Par√¢metros do Construtor

* **api\_key**: Opcional. Sua chave de API do Hyperbrowser. Se n√£o fornecida, ser√° lida da vari√°vel de ambiente `HYPERBROWSER_API_KEY`.

### Par√¢metros de Execu√ß√£o

* **url**: Obrigat√≥rio. A URL do site a ser extra√≠do ou rastreado.
* **operation**: Opcional. A opera√ß√£o a ser realizada no site. Pode ser 'scrape' ou 'crawl'. O padr√£o √© 'scrape'.
* **params**: Opcional. Par√¢metros adicionais para a opera√ß√£o de scraping ou crawling.

## Par√¢metros Suportados

Para informa√ß√µes detalhadas sobre todos os par√¢metros suportados, acesse:

* [Par√¢metros de Scrape](https://docs.hyperbrowser.ai/reference/sdks/python/scrape#start-scrape-job-and-wait)
* [Par√¢metros de Crawl](https://docs.hyperbrowser.ai/reference/sdks/python/crawl#start-crawl-job-and-wait)

## Formato de Retorno

A ferramenta retorna o conte√∫do nos seguintes formatos:

* Para opera√ß√µes **scrape**: O conte√∫do da p√°gina no formato markdown ou HTML.
* Para opera√ß√µes **crawl**: O conte√∫do de cada p√°gina separado por divisores, incluindo a URL de cada p√°gina.

## Conclus√£o

O `HyperbrowserLoadTool` oferece uma maneira poderosa de realizar scraping e crawling em sites, lidando com cen√°rios complexos como medidas anti-bot, CAPTCHAs e muito mais. Aproveitando a plataforma do Hyperbrowser, essa ferramenta permite que agentes acessem e extraiam conte√∫do da web de forma eficiente.


# Vis√£o Geral
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/overview

Extraia dados de websites e automatize intera√ß√µes com o navegador utilizando poderosas ferramentas de scraping

Essas ferramentas permitem que seus agentes interajam com a web, extraiam dados de websites e automatizem tarefas baseadas em navegador. De raspagem simples a automa√ß√£o complexa de navegador, essas ferramentas cobrem todas as suas necessidades de intera√ß√£o com a web.

## **Ferramentas Dispon√≠veis**

<CardGroup cols={2}>
  <Card title="Ferramenta de Scrape de Website" icon="globe" href="/pt-BR/tools/web-scraping/scrapewebsitetool">
    Ferramenta de raspagem de uso geral para extrair conte√∫do de qualquer site.
  </Card>

  <Card title="Ferramenta de Scrape de Elemento" icon="crosshairs" href="/pt-BR/tools/web-scraping/scrapeelementfromwebsitetool">
    Extraia elementos espec√≠ficos de p√°ginas web com capacidades de raspagem precisa.
  </Card>

  <Card title="Ferramenta Firecrawl Crawl" icon="spider" href="/pt-BR/tools/web-scraping/firecrawlcrawlwebsitetool">
    Rastreie sites inteiros de forma sistem√°tica com o poderoso mecanismo do Firecrawl.
  </Card>

  <Card title="Ferramenta Firecrawl Scrape" icon="fire" href="/pt-BR/tools/web-scraping/firecrawlscrapewebsitetool">
    Raspagem web de alta performance com as capacidades avan√ßadas do Firecrawl.
  </Card>

  <Card title="Ferramenta Firecrawl Search" icon="magnifying-glass" href="/pt-BR/tools/web-scraping/firecrawlsearchtool">
    Pesquise e extraia conte√∫dos espec√≠ficos utilizando os recursos de busca do Firecrawl.
  </Card>

  <Card title="Ferramenta Selenium Scraping" icon="robot" href="/pt-BR/tools/web-scraping/seleniumscrapingtool">
    Automa√ß√£o de navegador e scraping com as capacidades do Selenium WebDriver.
  </Card>

  <Card title="Ferramenta ScrapFly" icon="plane" href="/pt-BR/tools/web-scraping/scrapflyscrapetool">
    Raspagem profissional de web com o servi√ßo premium do ScrapFly.
  </Card>

  <Card title="Ferramenta ScrapGraph" icon="network-wired" href="/pt-BR/tools/web-scraping/scrapegraphscrapetool">
    Raspagem baseada em grafos para relacionamentos de dados complexos.
  </Card>

  <Card title="Ferramenta Spider" icon="spider" href="/pt-BR/tools/web-scraping/spidertool">
    Rastreio abrangente de sites e capacidades de extra√ß√£o de dados.
  </Card>

  <Card title="Ferramenta BrowserBase" icon="browser" href="/pt-BR/tools/web-scraping/browserbaseloadtool">
    Automa√ß√£o de navegador baseada em nuvem com a infraestrutura do BrowserBase.
  </Card>

  <Card title="Ferramenta HyperBrowser" icon="window-maximize" href="/pt-BR/tools/web-scraping/hyperbrowserloadtool">
    Intera√ß√µes r√°pidas com o navegador atrav√©s do engine otimizado do HyperBrowser.
  </Card>

  <Card title="Ferramenta Stagehand" icon="hand" href="/pt-BR/tools/web-scraping/stagehandtool">
    Automa√ß√£o inteligente de navegador com comandos em linguagem natural.
  </Card>

  <Card title="Ferramenta Oxylabs Scraper" icon="globe" href="/pt-BR/tools/web-scraping/oxylabsscraperstool">
    Acesse dados web em escala com o Oxylabs.
  </Card>
</CardGroup>

## **Casos de Uso Comuns**

* **Extra√ß√£o de Dados**: Raspagem de informa√ß√µes de produtos, pre√ßos e avalia√ß√µes
* **Monitoramento de Conte√∫do**: Acompanhe mudan√ßas em sites e fontes de not√≠cias
* **Gera√ß√£o de Leads**: Extraia informa√ß√µes de contato e dados de empresas
* **Pesquisa de Mercado**: Coleta de intelig√™ncia competitiva e dados de mercado
* **Testes & QA**: Automatize fluxos de teste e valida√ß√£o em navegadores
* **M√≠dias Sociais**: Extraia posts, coment√°rios e an√°lises de redes sociais

## **Exemplo de In√≠cio R√°pido**

```python
from crewai_tools import ScrapeWebsiteTool, FirecrawlScrapeWebsiteTool, SeleniumScrapingTool

# Create scraping tools
simple_scraper = ScrapeWebsiteTool()
advanced_scraper = FirecrawlScrapeWebsiteTool()
browser_automation = SeleniumScrapingTool()

# Add to your agent
agent = Agent(
    role="Web Research Specialist",
    tools=[simple_scraper, advanced_scraper, browser_automation],
    goal="Extract and analyze web data efficiently"
)
```

## **Boas Pr√°ticas de Scraping**

* **Respeite o robots.txt**: Sempre verifique e siga as pol√≠ticas de scraping do website
* **Controle de Taxa (Rate Limiting)**: Implemente atrasos entre as requisi√ß√µes para evitar sobrecarregar servidores
* **User Agents**: Use strings de user agent apropriadas para identificar o seu bot
* **Conformidade Legal**: Certifique-se de que suas atividades de scraping estejam em conformidade com os termos de servi√ßo
* **Tratamento de Erros**: Implemente um tratamento de erros robusto para problemas de rede e requisi√ß√µes bloqueadas
* **Qualidade dos Dados**: Valide e limpe os dados extra√≠dos antes de processar

## **Guia de Sele√ß√£o de Ferramentas**

* **Tarefas Simples**: Use `ScrapeWebsiteTool` para extra√ß√£o b√°sica de conte√∫do
* **Sites Din√¢micos com JavaScript**: Use `SeleniumScrapingTool` para conte√∫do din√¢mico
* **Escala & Performance**: Use `FirecrawlScrapeWebsiteTool` para scraping em grande volume
* **Infraestrutura em Nuvem**: Use `BrowserBaseLoadTool` para automa√ß√£o de navegador escal√°vel
* **Fluxos Complexos**: Use `StagehandTool` para intera√ß√µes inteligentes com o navegador


# Oxylabs Scrapers
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/oxylabsscraperstool

Os Scrapers da Oxylabs permitem acessar facilmente informa√ß√µes de fontes espec√≠ficas. Veja abaixo a lista de fontes dispon√≠veis:
  - `Amazon Product`
  - `Amazon Search`
  - `Google Seach`
  - `Universal`


## Instala√ß√£o

Obtenha as credenciais criando uma conta na Oxylabs [aqui](https://oxylabs.io).

```shell
pip install 'crewai[tools]' oxylabs
```

Confira a [Documenta√ß√£o da Oxylabs](https://developers.oxylabs.io/scraping-solutions/web-scraper-api/targets) para mais informa√ß√µes sobre os par√¢metros da API.

# `OxylabsAmazonProductScraperTool`

### Exemplo

```python
from crewai_tools import OxylabsAmazonProductScraperTool

# certifique-se de que as vari√°veis OXYLABS_USERNAME e OXYLABS_PASSWORD estejam definidas
tool = OxylabsAmazonProductScraperTool()

result = tool.run(query="AAAAABBBBCC")

print(result)
```

### Par√¢metros

* `query` - c√≥digo ASIN de 10 caracteres.
* `domain` - dom√≠nio de localiza√ß√£o da Amazon.
* `geo_location` - local de entrega (*Deliver to*).
* `user_agent_type` - tipo de dispositivo e navegador.
* `render` - ativa o renderizador JavaScript ao definir como `html`.
* `callback_url` - URL do seu endpoint de callback.
* `context` - Configura√ß√µes avan√ßadas adicionais e controles para requisitos especializados.
* `parse` - retorna os dados j√° processados quando definido como true.
* `parsing_instructions` - defina sua pr√≥pria l√≥gica de parsing e transforma√ß√£o de dados que ser√° executada no resultado de scraping HTML.

### Exemplo avan√ßado

```python
from crewai_tools import OxylabsAmazonProductScraperTool

# certifique-se de que as vari√°veis OXYLABS_USERNAME e OXYLABS_PASSWORD estejam definidas
tool = OxylabsAmazonProductScraperTool(
    config={
        "domain": "com",
        "parse": True,
        "context": [
            {
                "key": "autoselect_variant",
                "value": True
            }
        ]
    }
)

result = tool.run(query="AAAAABBBBCC")

print(result)
```

# `OxylabsAmazonSearchScraperTool`

### Exemplo

```python
from crewai_tools import OxylabsAmazonSearchScraperTool

# certifique-se de que as vari√°veis OXYLABS_USERNAME e OXYLABS_PASSWORD estejam definidas
tool = OxylabsAmazonSearchScraperTool()

result = tool.run(query="headsets")

print(result)
```

### Par√¢metros

* `query` - termo de busca da Amazon.
* `domain` - Dom√≠nio de localiza√ß√£o para Bestbuy.
* `start_page` - n√∫mero da p√°gina inicial.
* `pages` - quantidade de p√°ginas a ser recuperada.
* `geo_location` - local de entrega (*Deliver to*).
* `user_agent_type` - tipo de dispositivo e navegador.
* `render` - ativa o renderizador JavaScript ao definir como `html`.
* `callback_url` - URL do seu endpoint de callback.
* `context` - Configura√ß√µes avan√ßadas adicionais e controles para requisitos especializados.
* `parse` - retorna os dados j√° processados quando definido como true.
* `parsing_instructions` - defina sua pr√≥pria l√≥gica de parsing e transforma√ß√£o de dados que ser√° executada no resultado de scraping HTML.

### Exemplo avan√ßado

```python
from crewai_tools import OxylabsAmazonSearchScraperTool

# certifique-se de que as vari√°veis OXYLABS_USERNAME e OXYLABS_PASSWORD estejam definidas
tool = OxylabsAmazonSearchScraperTool(
    config={
        "domain": 'nl',
        "start_page": 2,
        "pages": 2,
        "parse": True,
        "context": [
            {'key': 'category_id', 'value': 16391693031}
        ],
    }
)

result = tool.run(query='nirvana tshirt')

print(result)
```

# `OxylabsGoogleSearchScraperTool`

### Exemplo

```python
from crewai_tools import OxylabsGoogleSearchScraperTool

# certifique-se de que as vari√°veis OXYLABS_USERNAME e OXYLABS_PASSWORD estejam definidas
tool = OxylabsGoogleSearchScraperTool()

result = tool.run(query="iPhone 16")

print(result)
```

### Par√¢metros

* `query` - palavra-chave de busca.
* `domain` - dom√≠nio de localiza√ß√£o do Google.
* `start_page` - n√∫mero da p√°gina inicial.
* `pages` - n√∫mero de p√°ginas a ser recuperado.
* `limit` - quantidade de resultados a ser recuperada em cada p√°gina.
* `locale` - valor do header `Accept-Language`, que altera o idioma da interface da p√°gina de pesquisa do Google.
* `geo_location` - a localiza√ß√£o geogr√°fica para a qual o resultado deve ser adaptado. Usar este par√¢metro corretamente √© extremamente importante para obter os dados corretos.
* `user_agent_type` - tipo de dispositivo e navegador.
* `render` - ativa o renderizador JavaScript ao definir como `html`.
* `callback_url` - URL do seu endpoint de callback.
* `context` - Configura√ß√µes avan√ßadas adicionais e controles para requisitos especializados.
* `parse` - retorna os dados j√° processados quando definido como true.
* `parsing_instructions` - defina sua pr√≥pria l√≥gica de parsing e transforma√ß√£o de dados que ser√° executada no resultado de scraping HTML.

### Exemplo avan√ßado

```python
from crewai_tools import OxylabsGoogleSearchScraperTool

# certifique-se de que as vari√°veis OXYLABS_USERNAME e OXYLABS_PASSWORD estejam definidas
tool = OxylabsGoogleSearchScraperTool(
    config={
        "parse": True,
        "geo_location": "Paris, France",
        "user_agent_type": "tablet",
    }
)

result = tool.run(query="iPhone 16")

print(result)
```

# `OxylabsUniversalScraperTool`

### Exemplo

```python
from crewai_tools import OxylabsUniversalScraperTool

# certifique-se de que as vari√°veis OXYLABS_USERNAME e OXYLABS_PASSWORD estejam definidas
tool = OxylabsUniversalScraperTool()

result = tool.run(url="https://ip.oxylabs.io")

print(result)
```

### Par√¢metros

* `url` - URL do site a ser raspada.
* `user_agent_type` - tipo de dispositivo e navegador.
* `geo_location` - define a geolocaliza√ß√£o do proxy para coletar os dados.
* `render` - ativa o renderizador JavaScript ao definir como `html`.
* `callback_url` - URL do seu endpoint de callback.
* `context` - Configura√ß√µes avan√ßadas adicionais e controles para requisitos especializados.
* `parse` - retorna os dados j√° processados quando definido como `true`, desde que exista um parser dedicado para o tipo de p√°gina da URL fornecida.
* `parsing_instructions` - defina sua pr√≥pria l√≥gica de parsing e transforma√ß√£o de dados que ser√° executada no resultado de scraping HTML.

### Exemplo avan√ßado

```python
from crewai_tools import OxylabsUniversalScraperTool

# certifique-se de que as vari√°veis OXYLABS_USERNAME e OXYLABS_PASSWORD estejam definidas
tool = OxylabsUniversalScraperTool(
    config={
        "render": "html",
        "user_agent_type": "mobile",
        "context": [
            {"key": "force_headers", "value": True},
            {"key": "force_cookies", "value": True},
            {
                "key": "headers",
                "value": {
                    "Custom-Header-Name": "custom header content",
                },
            },
            {
                "key": "cookies",
                "value": [
                    {"key": "NID", "value": "1234567890"},
                    {"key": "1P JAR", "value": "0987654321"},
                ],
            },
            {"key": "http_method", "value": "get"},
            {"key": "follow_redirects", "value": True},
            {"key": "successful_status_codes", "value": [808, 909]},
        ],
    }
)

result = tool.run(url="https://ip.oxylabs.io")

print(result)
```


# Ferramenta de Extra√ß√£o de Elementos de Website
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/scrapeelementfromwebsitetool

A `ScrapeElementFromWebsiteTool` permite que agentes CrewAI extraiam elementos espec√≠ficos de websites usando seletores CSS.

# `ScrapeElementFromWebsiteTool`

## Descri√ß√£o

A `ScrapeElementFromWebsiteTool` foi projetada para extrair elementos espec√≠ficos de websites utilizando seletores CSS. Esta ferramenta permite que agentes CrewAI capturem conte√∫dos direcionados de p√°ginas web, tornando-se √∫til para tarefas de extra√ß√£o de dados em que apenas partes espec√≠ficas de uma p√°gina s√£o necess√°rias.

## Instala√ß√£o

Para utilizar esta ferramenta, voc√™ precisa instalar as depend√™ncias necess√°rias:

```shell
uv add requests beautifulsoup4
```

## Passos para Come√ßar

Para usar a `ScrapeElementFromWebsiteTool` de maneira eficaz, siga estes passos:

1. **Instale as Depend√™ncias**: Instale os pacotes necess√°rios com o comando acima.
2. **Identifique os Seletores CSS**: Determine os seletores CSS dos elementos que deseja extrair do site.
3. **Inicialize a Ferramenta**: Crie uma inst√¢ncia da ferramenta com os par√¢metros necess√°rios.

## Exemplo

O exemplo abaixo demonstra como usar a `ScrapeElementFromWebsiteTool` para extrair elementos espec√≠ficos de um website:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import ScrapeElementFromWebsiteTool

# Inicie a ferramenta
scrape_tool = ScrapeElementFromWebsiteTool()

# Defina um agente que utilizar√° a ferramenta
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extrair informa√ß√µes espec√≠ficas de websites",
    backstory="Um especialista em web scraping capaz de capturar conte√∫dos direcionados de p√°ginas web.",
    tools=[scrape_tool],
    verbose=True,
)

# Exemplo de tarefa para extrair manchetes de um site de not√≠cias
scrape_task = Task(
    description="Extraia as principais manchetes da p√°gina inicial da CNN. Use o seletor CSS '.headline' para atingir os elementos de manchete.",
    expected_output="Uma lista das principais manchetes da CNN.",
    agent=web_scraper_agent,
)

# Crie e execute o crew
crew = Crew(agents=[web_scraper_agent], tasks=[scrape_task])
result = crew.kickoff()
```

Voc√™ tamb√©m pode inicializar a ferramenta com par√¢metros pr√©-definidos:

```python Code
# Inicialize a ferramenta com par√¢metros pr√©-definidos
scrape_tool = ScrapeElementFromWebsiteTool(
    website_url="https://www.example.com",
    css_element=".main-content"
)
```

## Par√¢metros

A `ScrapeElementFromWebsiteTool` aceita os seguintes par√¢metros durante a inicializa√ß√£o:

* **website\_url**: Opcional. A URL do website a ser extra√≠do. Se fornecido na inicializa√ß√£o, o agente n√£o precisar√° especific√°-lo ao utilizar a ferramenta.
* **css\_element**: Opcional. O seletor CSS para os elementos a serem extra√≠dos. Se fornecido na inicializa√ß√£o, o agente n√£o precisar√° especific√°-lo ao utilizar a ferramenta.
* **cookies**: Opcional. Um dicion√°rio contendo cookies a serem enviados com a requisi√ß√£o. Isso pode ser √∫til para sites que requerem autentica√ß√£o.

## Uso

Ao utilizar a `ScrapeElementFromWebsiteTool` com um agente, o agente precisar√° fornecer os seguintes par√¢metros (a menos que j√° tenham sido especificados na inicializa√ß√£o):

* **website\_url**: A URL do website a ser extra√≠do.
* **css\_element**: O seletor CSS dos elementos a serem extra√≠dos.

A ferramenta retornar√° o conte√∫do de texto de todos os elementos que correspondam ao seletor CSS, separados por quebras de linha.

```python Code
# Exemplo de uso da ferramenta com um agente
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extrair elementos espec√≠ficos de websites",
    backstory="Um especialista em web scraping capaz de extrair conte√∫do direcionado por meio de seletores CSS.",
    tools=[scrape_tool],
    verbose=True,
)

# Crie uma tarefa para o agente extrair elementos espec√≠ficos
extract_task = Task(
    description="""
    Extraia todos os t√≠tulos de produtos da se√ß√£o de produtos em destaque no example.com.
    Use o seletor CSS '.product-title' para atingir os elementos de t√≠tulo.
    """,
    expected_output="Uma lista de t√≠tulos de produtos do site",
    agent=web_scraper_agent,
)

# Execute a tarefa utilizando um crew
crew = Crew(agents=[web_scraper_agent], tasks=[extract_task])
result = crew.kickoff()
```

## Detalhes de Implementa√ß√£o

A `ScrapeElementFromWebsiteTool` utiliza a biblioteca `requests` para buscar a p√°gina web e `BeautifulSoup` para analisar o HTML e extrair os elementos especificados:

```python Code
class ScrapeElementFromWebsiteTool(BaseTool):
    name: str = "Read a website content"
    description: str = "A tool that can be used to read a website content."

    # Implementation details...

    def _run(self, **kwargs: Any) -> Any:
        website_url = kwargs.get("website_url", self.website_url)
        css_element = kwargs.get("css_element", self.css_element)
        page = requests.get(
            website_url,
            headers=self.headers,
            cookies=self.cookies if self.cookies else {},
        )
        parsed = BeautifulSoup(page.content, "html.parser")
        elements = parsed.select(css_element)
        return "\n".join([element.get_text() for element in elements])
```

## Conclus√£o

A `ScrapeElementFromWebsiteTool` oferece uma maneira poderosa de extrair elementos espec√≠ficos de websites utilizando seletores CSS. Ao possibilitar que agentes direcionem apenas o conte√∫do que necessitam, ela torna as tarefas de web scraping mais eficientes e objetivas. Esta ferramenta √© particularmente √∫til para extra√ß√£o de dados, monitoramento de conte√∫dos e tarefas de pesquisa em que informa√ß√µes espec√≠ficas precisam ser extra√≠das de p√°ginas web.


# Ferramenta de Extra√ß√£o Scrapegraph
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/scrapegraphscrapetool

A `ScrapegraphScrapeTool` utiliza a API SmartScraper da Scrapegraph AI para extrair conte√∫do de sites de forma inteligente.

# `ScrapegraphScrapeTool`

## Descri√ß√£o

A `ScrapegraphScrapeTool` foi projetada para utilizar a API SmartScraper da Scrapegraph AI e extrair conte√∫do de sites de maneira inteligente. Esta ferramenta oferece recursos avan√ßados de web scraping com extra√ß√£o de conte√∫do potencializada por IA, tornando-se ideal para coleta de dados direcionada e tarefas de an√°lise de conte√∫do. Diferente dos scrapers tradicionais, ela entende o contexto e a estrutura das p√°ginas da web para extrair as informa√ß√µes mais relevantes, com base em instru√ß√µes em linguagem natural.

## Instala√ß√£o

Para utilizar esta ferramenta, √© necess√°rio instalar o cliente Python do Scrapegraph:

```shell
uv add scrapegraph-py
```

Voc√™ tamb√©m precisa definir sua chave de API do Scrapegraph como uma vari√°vel de ambiente:

```shell
export SCRAPEGRAPH_API_KEY="your_api_key"
```

Voc√™ pode obter uma chave de API em [Scrapegraph AI](https://scrapegraphai.com).

## Passos para Come√ßar

Para usar efetivamente a `ScrapegraphScrapeTool`, siga estes passos:

1. **Instale as depend√™ncias**: Instale o pacote necess√°rio usando o comando acima.
2. **Configure a chave de API**: Defina sua chave de API do Scrapegraph como vari√°vel de ambiente ou forne√ßa-a durante a inicializa√ß√£o.
3. **Inicialize a ferramenta**: Crie uma inst√¢ncia da ferramenta com os par√¢metros necess√°rios.
4. **Defina instru√ß√µes de extra√ß√£o**: Crie prompts em linguagem natural para guiar a extra√ß√£o de conte√∫dos espec√≠ficos.

## Exemplo

O exemplo a seguir demonstra como usar a `ScrapegraphScrapeTool` para extrair conte√∫do de um site:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import ScrapegraphScrapeTool

# Initialize the tool
scrape_tool = ScrapegraphScrapeTool(api_key="your_api_key")

# Define an agent that uses the tool
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract specific information from websites",
    backstory="An expert in web scraping who can extract targeted content from web pages.",
    tools=[scrape_tool],
    verbose=True,
)

# Example task to extract product information from an e-commerce site
scrape_task = Task(
    description="Extract product names, prices, and descriptions from the featured products section of example.com.",
    expected_output="A structured list of product information including names, prices, and descriptions.",
    agent=web_scraper_agent,
)

# Create and run the crew
crew = Crew(agents=[web_scraper_agent], tasks=[scrape_task])
result = crew.kickoff()
```

Voc√™ tamb√©m pode inicializar a ferramenta com par√¢metros pr√©-definidos:

```python Code
# Initialize the tool with predefined parameters
scrape_tool = ScrapegraphScrapeTool(
    website_url="https://www.example.com",
    user_prompt="Extract all product prices and descriptions",
    api_key="your_api_key"
)
```

## Par√¢metros

A `ScrapegraphScrapeTool` aceita os seguintes par√¢metros durante a inicializa√ß√£o:

* **api\_key**: Opcional. Sua chave de API do Scrapegraph. Se n√£o for fornecida, ser√° procurada a vari√°vel de ambiente `SCRAPEGRAPH_API_KEY`.
* **website\_url**: Opcional. A URL do site a ser extra√≠do. Se fornecida na inicializa√ß√£o, o agente n√£o precisa especific√°-la ao usar a ferramenta.
* **user\_prompt**: Opcional. Instru√ß√µes customizadas para extra√ß√£o de conte√∫do. Se fornecida na inicializa√ß√£o, o agente n√£o precisa especific√°-la ao usar a ferramenta.
* **enable\_logging**: Opcional. Define se o registro (logging) na Scrapegraph deve ser ativado. O padr√£o √© `False`.

## Uso

Ao usar a `ScrapegraphScrapeTool` com um agente, ser√° necess√°rio fornecer os seguintes par√¢metros (a menos que tenham sido especificados durante a inicializa√ß√£o):

* **website\_url**: A URL do site a ser extra√≠da.
* **user\_prompt**: Opcional. Instru√ß√µes customizadas para extra√ß√£o de conte√∫do. O padr√£o √© "Extract the main content of the webpage".

A ferramenta retornar√° o conte√∫do extra√≠do com base no prompt fornecido.

```python Code
# Example of using the tool with an agent
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract specific information from websites",
    backstory="An expert in web scraping who can extract targeted content from web pages.",
    tools=[scrape_tool],
    verbose=True,
)

# Create a task for the agent to extract specific content
extract_task = Task(
    description="Extract the main heading and summary from example.com",
    expected_output="The main heading and summary from the website",
    agent=web_scraper_agent,
)

# Run the task
crew = Crew(agents=[web_scraper_agent], tasks=[extract_task])
result = crew.kickoff()
```

## Tratamento de Erros

A `ScrapegraphScrapeTool` pode lan√ßar as seguintes exce√ß√µes:

* **ValueError**: Quando a chave da API est√° ausente ou o formato da URL √© inv√°lido.
* **RateLimitError**: Quando o limite de requisi√ß√µes da API √© excedido.
* **RuntimeError**: Quando a opera√ß√£o de extra√ß√£o falha (problemas de rede, erros da API).

Recomenda-se instruir os agentes a lidarem com potenciais erros de forma apropriada:

```python Code
# Create a task that includes error handling instructions
robust_extract_task = Task(
    description="""
    Extract the main heading from example.com.
    Be aware that you might encounter errors such as:
    - Invalid URL format
    - Missing API key
    - Rate limit exceeded
    - Network or API errors

    If you encounter any errors, provide a clear explanation of what went wrong
    and suggest possible solutions.
    """,
    expected_output="Either the extracted heading or a clear error explanation",
    agent=web_scraper_agent,
)
```

## Limita√ß√µes de Taxa

A API do Scrapegraph possui limites de requisi√ß√£o que variam conforme o seu plano de assinatura. Considere as seguintes boas pr√°ticas:

* Implemente atrasos apropriados entre requisi√ß√µes ao processar m√∫ltiplas URLs.
* Trate erros de limite de requisi√ß√£o de forma apropriada em sua aplica√ß√£o.
* Verifique os limites do seu plano de API no painel do Scrapegraph.

## Detalhes de Implementa√ß√£o

A `ScrapegraphScrapeTool` utiliza o cliente Python do Scrapegraph para se comunicar com a API SmartScraper:

```python Code
class ScrapegraphScrapeTool(BaseTool):
    """
    A tool that uses Scrapegraph AI to intelligently scrape website content.
    """

    # Implementation details...

    def _run(self, **kwargs: Any) -> Any:
        website_url = kwargs.get("website_url", self.website_url)
        user_prompt = (
            kwargs.get("user_prompt", self.user_prompt)
            or "Extract the main content of the webpage"
        )

        if not website_url:
            raise ValueError("website_url is required")

        # Validate URL format
        self._validate_url(website_url)

        try:
            # Make the SmartScraper request
            response = self._client.smartscraper(
                website_url=website_url,
                user_prompt=user_prompt,
            )

            return response
        # Error handling...
```

## Conclus√£o

A `ScrapegraphScrapeTool` oferece uma maneira poderosa de extrair conte√∫do de sites utilizando o entendimento do formato das p√°ginas pela IA. Ao permitir que os agentes direcionem informa√ß√µes espec√≠ficas por meio de prompts em linguagem natural, ela torna tarefas de web scraping mais eficientes e focadas. Esta ferramenta √© especialmente √∫til para extra√ß√£o de dados, monitoramento de conte√∫do e pesquisas em que informa√ß√µes espec√≠ficas precisam ser extra√≠das de p√°ginas web.


# Raspar Site
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/scrapewebsitetool

O `ScrapeWebsiteTool` foi desenvolvido para extrair e ler o conte√∫do de um site especificado.

# `ScrapeWebsiteTool`

<Note>
  Ainda estamos trabalhando para melhorar as ferramentas, ent√£o pode haver comportamentos inesperados ou mudan√ßas futuras.
</Note>

## Descri√ß√£o

Uma ferramenta desenvolvida para extrair e ler o conte√∫do de um site especificado. Ela √© capaz de lidar com diversos tipos de p√°ginas web fazendo requisi√ß√µes HTTP e analisando o conte√∫do HTML recebido.
Esta ferramenta pode ser especialmente √∫til para tarefas de raspagem de dados, coleta de dados ou extra√ß√£o de informa√ß√µes espec√≠ficas de sites.

## Instala√ß√£o

Instale o pacote crewai\_tools

```shell
pip install 'crewai[tools]'
```

## Exemplo

```python
from crewai_tools import ScrapeWebsiteTool

# Para permitir a raspagem de qualquer site encontrado durante a execu√ß√£o
tool = ScrapeWebsiteTool()

# Inicialize a ferramenta com a URL do site,
# assim o agente s√≥ poder√° raspar o conte√∫do do site especificado
tool = ScrapeWebsiteTool(website_url='https://www.example.com')

# Extraia o texto do site
text = tool.run()
print(text)
```

## Argumentos

| Argumento        | Tipo     | Descri√ß√£o                                                                                                                                                     |
| :--------------- | :------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **website\_url** | `string` | **Obrigat√≥rio** URL do site para leitura do arquivo. Esta √© a entrada principal da ferramenta, especificando de qual site o conte√∫do deve ser raspado e lido. |


# Ferramenta de Raspagem de Sites Scrapfly
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/scrapflyscrapetool

A `ScrapflyScrapeWebsiteTool` aproveita a API de web scraping da Scrapfly para extrair conte√∫do de sites em diversos formatos.

# `ScrapflyScrapeWebsiteTool`

## Descri√ß√£o

A `ScrapflyScrapeWebsiteTool` foi desenvolvida para aproveitar a API de web scraping da [Scrapfly](https://scrapfly.io/) para extrair conte√∫do de sites. Esta ferramenta oferece recursos avan√ßados de raspagem com suporte a navegador headless, proxies e recursos de bypass de anti-bot. Permite extrair dados de p√°ginas web em v√°rios formatos, incluindo HTML bruto, markdown e texto simples, sendo ideal para uma ampla variedade de tarefas de raspagem de sites.

## Instala√ß√£o

Para utilizar esta ferramenta, √© necess√°rio instalar o Scrapfly SDK:

```shell
uv add scrapfly-sdk
```

Voc√™ tamb√©m precisar√° obter uma chave de API da Scrapfly registrando-se em [scrapfly.io/register](https://www.scrapfly.io/register/).

## Passos para Come√ßar

Para usar a `ScrapflyScrapeWebsiteTool` de forma eficaz, siga estas etapas:

1. **Instale as Depend√™ncias**: Instale o Scrapfly SDK usando o comando acima.
2. **Obtenha a Chave de API**: Cadastre-se na Scrapfly para obter sua chave de API.
3. **Inicialize a Ferramenta**: Crie uma inst√¢ncia da ferramenta com sua chave de API.
4. **Configure os Par√¢metros de Raspagem**: Personalize os par√¢metros de raspagem conforme suas necessidades.

## Exemplo

O exemplo a seguir demonstra como usar a `ScrapflyScrapeWebsiteTool` para extrair conte√∫do de um site:

```python Code
from crewai import Agent, Task, Crew
from crewai_tools import ScrapflyScrapeWebsiteTool

# Initialize the tool
scrape_tool = ScrapflyScrapeWebsiteTool(api_key="your_scrapfly_api_key")

# Define an agent that uses the tool
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract information from websites",
    backstory="An expert in web scraping who can extract content from any website.",
    tools=[scrape_tool],
    verbose=True,
)

# Example task to extract content from a website
scrape_task = Task(
    description="Extract the main content from the product page at https://web-scraping.dev/products and summarize the available products.",
    expected_output="A summary of the products available on the website.",
    agent=web_scraper_agent,
)

# Create and run the crew
crew = Crew(agents=[web_scraper_agent], tasks=[scrape_task])
result = crew.kickoff()
```

Voc√™ tamb√©m pode personalizar os par√¢metros de raspagem:

```python Code
# Example with custom scraping parameters
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract information from websites with custom parameters",
    backstory="An expert in web scraping who can extract content from any website.",
    tools=[scrape_tool],
    verbose=True,
)

# The agent will use the tool with parameters like:
# url="https://web-scraping.dev/products"
# scrape_format="markdown"
# ignore_scrape_failures=True
# scrape_config={
#     "asp": True,  # Bypass scraping blocking solutions, like Cloudflare
#     "render_js": True,  # Enable JavaScript rendering with a cloud headless browser
#     "proxy_pool": "public_residential_pool",  # Select a proxy pool
#     "country": "us",  # Select a proxy location
#     "auto_scroll": True,  # Auto scroll the page
# }

scrape_task = Task(
    description="Extract the main content from the product page at https://web-scraping.dev/products using advanced scraping options including JavaScript rendering and proxy settings.",
    expected_output="A detailed summary of the products with all available information.",
    agent=web_scraper_agent,
)
```

## Par√¢metros

A `ScrapflyScrapeWebsiteTool` aceita os seguintes par√¢metros:

### Par√¢metros de Inicializa√ß√£o

* **api\_key**: Obrigat√≥rio. Sua chave de API da Scrapfly.

### Par√¢metros de Execu√ß√£o

* **url**: Obrigat√≥rio. A URL do site a ser raspado.
* **scrape\_format**: Opcional. O formato em que o conte√∫do da p√°gina ser√° extra√≠do. As op√ß√µes s√£o "raw" (HTML), "markdown" ou "text". O padr√£o √© "markdown".
* **scrape\_config**: Opcional. Um dicion√°rio contendo op√ß√µes adicionais de configura√ß√£o de raspagem da Scrapfly.
* **ignore\_scrape\_failures**: Opcional. Determina se as falhas de raspagem devem ser ignoradas. Se definido como `True`, a ferramenta ir√° retornar `None` ao inv√©s de lan√ßar uma exce√ß√£o caso ocorra uma falha na raspagem.

## Op√ß√µes de Configura√ß√£o Scrapfly

O par√¢metro `scrape_config` permite personalizar o comportamento da raspagem com as seguintes op√ß√µes:

* **asp**: Ativa o bypass de prote√ß√£o anti-scraping.
* **render\_js**: Ativa a renderiza√ß√£o de JavaScript com um navegador headless na nuvem.
* **proxy\_pool**: Seleciona um pool de proxies (por exemplo, "public\_residential\_pool", "datacenter").
* **country**: Seleciona a localiza√ß√£o do proxy (por exemplo, "us", "uk").
* **auto\_scroll**: Rola automaticamente a p√°gina para carregar conte√∫do lazy-loaded.
* **js**: Executa c√≥digo JavaScript personalizado via o navegador headless.

Para uma lista completa de op√ß√µes de configura√ß√£o, consulte a [documenta√ß√£o da API Scrapfly](https://scrapfly.io/docs/scrape-api/getting-started).

## Uso

Ao usar a `ScrapflyScrapeWebsiteTool` com um agente, o agente dever√° fornecer a URL do site a ser raspado e pode opcionalmente especificar o formato e op√ß√µes adicionais de configura√ß√£o:

```python Code
# Example of using the tool with an agent
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract information from websites",
    backstory="An expert in web scraping who can extract content from any website.",
    tools=[scrape_tool],
    verbose=True,
)

# Create a task for the agent
scrape_task = Task(
    description="Extract the main content from example.com in markdown format.",
    expected_output="The main content of example.com in markdown format.",
    agent=web_scraper_agent,
)

# Run the task
crew = Crew(agents=[web_scraper_agent], tasks=[scrape_task])
result = crew.kickoff()
```

Para um uso mais avan√ßado com configura√ß√µes personalizadas:

```python Code
# Create a task with more specific instructions
advanced_scrape_task = Task(
    description="""
    Extract content from example.com with the following requirements:
    - Convert the content to plain text format
    - Enable JavaScript rendering
    - Use a US-based proxy
    - Handle any scraping failures gracefully
    """,
    expected_output="The extracted content from example.com",
    agent=web_scraper_agent,
)
```

## Tratamento de Erros

Por padr√£o, a `ScrapflyScrapeWebsiteTool` ir√° lan√ßar uma exce√ß√£o se a raspagem falhar. Os agentes podem ser instru√≠dos a tratar falhas de forma mais flex√≠vel especificando o par√¢metro `ignore_scrape_failures`:

```python Code
# Create a task that instructs the agent to handle errors
error_handling_task = Task(
    description="""
    Extract content from a potentially problematic website and make sure to handle any
    scraping failures gracefully by setting ignore_scrape_failures to True.
    """,
    expected_output="Either the extracted content or a graceful error message",
    agent=web_scraper_agent,
)
```

## Detalhes de Implementa√ß√£o

A `ScrapflyScrapeWebsiteTool` utiliza o Scrapfly SDK para interagir com a API Scrapfly:

```python Code
class ScrapflyScrapeWebsiteTool(BaseTool):
    name: str = "Scrapfly web scraping API tool"
    description: str = (
        "Scrape a webpage url using Scrapfly and return its content as markdown or text"
    )

    # Implementation details...

    def _run(
        self,
        url: str,
        scrape_format: str = "markdown",
        scrape_config: Optional[Dict[str, Any]] = None,
        ignore_scrape_failures: Optional[bool] = None,
    ):
        from scrapfly import ScrapeApiResponse, ScrapeConfig

        scrape_config = scrape_config if scrape_config is not None else {}
        try:
            response: ScrapeApiResponse = self.scrapfly.scrape(
                ScrapeConfig(url, format=scrape_format, **scrape_config)
            )
            return response.scrape_result["content"]
        except Exception as e:
            if ignore_scrape_failures:
                logger.error(f"Error fetching data from {url}, exception: {e}")
                return None
            else:
                raise e
```

## Conclus√£o

A `ScrapflyScrapeWebsiteTool` oferece uma forma poderosa de extrair conte√∫do de sites usando as avan√ßadas capacidades de web scraping da Scrapfly. Com recursos como suporte a navegador headless, proxies e bypass de anti-bot, ela consegue lidar com sites complexos e extrair conte√∫do em diversos formatos. Esta ferramenta √© especialmente √∫til em tarefas de extra√ß√£o de dados, monitoramento de conte√∫do e pesquisa, onde a raspagem confi√°vel de sites √© necess√°ria.


# Selenium Scraper
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/seleniumscrapingtool

O `SeleniumScrapingTool` foi desenvolvido para extrair e ler o conte√∫do de um site espec√≠fico utilizando o Selenium.

# `SeleniumScrapingTool`

<Note>
  Esta ferramenta est√° atualmente em desenvolvimento. Conforme aprimoramos suas capacidades, os usu√°rios podem encontrar comportamentos inesperados.
  Seu feedback √© inestim√°vel para que possamos melhorar.
</Note>

## Descri√ß√£o

O `SeleniumScrapingTool` foi criado para tarefas de raspagem web de alta efici√™ncia.
Permite a extra√ß√£o precisa de conte√∫do de p√°ginas web utilizando seletores CSS para direcionar elementos espec√≠ficos.
Seu design atende a uma ampla gama de necessidades de scraping, oferecendo flexibilidade para trabalhar com qualquer URL de site fornecida.

## Instala√ß√£o

Para utilizar esta ferramenta, √© necess√°rio instalar o pacote CrewAI tools e o Selenium:

```shell
pip install 'crewai[tools]'
uv add selenium webdriver-manager
```

Voc√™ tamb√©m precisar√° ter o Chrome instalado em seu sistema, pois a ferramenta utiliza o Chrome WebDriver para automa√ß√£o do navegador.

## Exemplo

O exemplo a seguir demonstra como usar o `SeleniumScrapingTool` com um agente CrewAI:

```python Code
from crewai import Agent, Task, Crew, Process
from crewai_tools import SeleniumScrapingTool

# Inicializa a ferramenta
selenium_tool = SeleniumScrapingTool()

# Define um agente que utiliza a ferramenta
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract information from websites using Selenium",
    backstory="An expert web scraper who can extract content from dynamic websites.",
    tools=[selenium_tool],
    verbose=True,
)

# Exemplo de tarefa para extrair conte√∫do de um site
scrape_task = Task(
    description="Extract the main content from the homepage of example.com. Use the CSS selector 'main' to target the main content area.",
    expected_output="The main content from example.com's homepage.",
    agent=web_scraper_agent,
)

# Cria e executa o crew
crew = Crew(
    agents=[web_scraper_agent],
    tasks=[scrape_task],
    verbose=True,
    process=Process.sequential,
)
result = crew.kickoff()
```

Voc√™ tamb√©m pode inicializar a ferramenta com par√¢metros predefinidos:

```python Code
# Inicializa a ferramenta com par√¢metros predefinidos
selenium_tool = SeleniumScrapingTool(
    website_url='https://example.com',
    css_element='.main-content',
    wait_time=5
)

# Define um agente que utiliza a ferramenta
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract information from websites using Selenium",
    backstory="An expert web scraper who can extract content from dynamic websites.",
    tools=[selenium_tool],
    verbose=True,
)
```

## Par√¢metros

O `SeleniumScrapingTool` aceita os seguintes par√¢metros durante a inicializa√ß√£o:

* **website\_url**: Opcional. A URL do site a ser raspado. Se fornecido durante a inicializa√ß√£o, o agente n√£o precisar√° especific√°-lo ao utilizar a ferramenta.
* **css\_element**: Opcional. O seletor CSS dos elementos a serem extra√≠dos. Se fornecido durante a inicializa√ß√£o, o agente n√£o precisar√° especific√°-lo ao utilizar a ferramenta.
* **cookie**: Opcional. Um dicion√°rio contendo informa√ß√µes de cookies, √∫til para simular uma sess√£o logada e acessar conte√∫do restrito.
* **wait\_time**: Opcional. Especifica o atraso (em segundos) antes da raspagem, permitindo que o site e qualquer conte√∫do din√¢mico carreguem totalmente. O padr√£o √© `3` segundos.
* **return\_html**: Opcional. Indica se o conte√∫do HTML deve ser retornado em vez do texto simples. O padr√£o √© `False`.

Ao usar a ferramenta com um agente, o agente precisar√° fornecer os seguintes par√¢metros (a menos que tenham sido especificados durante a inicializa√ß√£o):

* **website\_url**: Obrigat√≥rio. A URL do site a ser raspado.
* **css\_element**: Obrigat√≥rio. O seletor CSS dos elementos a serem extra√≠dos.

## Exemplo de Integra√ß√£o com Agente

Aqui est√° um exemplo mais detalhado de como integrar o `SeleniumScrapingTool` com um agente CrewAI:

```python Code
from crewai import Agent, Task, Crew, Process
from crewai_tools import SeleniumScrapingTool

# Inicializa a ferramenta
selenium_tool = SeleniumScrapingTool()

# Define um agente que utiliza a ferramenta
web_scraper_agent = Agent(
    role="Web Scraper",
    goal="Extract and analyze information from dynamic websites",
    backstory="""You are an expert web scraper who specializes in extracting
    content from dynamic websites that require browser automation. You have
    extensive knowledge of CSS selectors and can identify the right selectors
    to target specific content on any website.""",
    tools=[selenium_tool],
    verbose=True,
)

# Cria uma tarefa para o agente
scrape_task = Task(
    description="""
    Extract the following information from the news website at {website_url}:

    1. The headlines of all featured articles (CSS selector: '.headline')
    2. The publication dates of these articles (CSS selector: '.pub-date')
    3. The author names where available (CSS selector: '.author')

    Compile this information into a structured format with each article's details grouped together.
    """,
    expected_output="A structured list of articles with their headlines, publication dates, and authors.",
    agent=web_scraper_agent,
)

# Executa a tarefa
crew = Crew(
    agents=[web_scraper_agent],
    tasks=[scrape_task],
    verbose=True,
    process=Process.sequential,
)
result = crew.kickoff(inputs={"website_url": "https://news-example.com"})
```

## Detalhes de Implementa√ß√£o

O `SeleniumScrapingTool` utiliza o Selenium WebDriver para automatizar intera√ß√µes com o navegador:

```python Code
class SeleniumScrapingTool(BaseTool):
    name: str = "Read a website content"
    description: str = "A tool that can be used to read a website content."
    args_schema: Type[BaseModel] = SeleniumScrapingToolSchema

    def _run(self, **kwargs: Any) -> Any:
        website_url = kwargs.get("website_url", self.website_url)
        css_element = kwargs.get("css_element", self.css_element)
        return_html = kwargs.get("return_html", self.return_html)
        driver = self._create_driver(website_url, self.cookie, self.wait_time)

        content = self._get_content(driver, css_element, return_html)
        driver.close()

        return "\n".join(content)
```

A ferramenta executa as seguintes etapas:

1. Cria uma inst√¢ncia do Chrome em modo headless
2. Navega at√© a URL especificada
3. Aguarda o tempo especificado para permitir o carregamento da p√°gina
4. Adiciona cookies se fornecidos
5. Extrai conte√∫do baseado no seletor CSS
6. Retorna o conte√∫do extra√≠do como texto ou HTML
7. Encerra a inst√¢ncia do navegador

## Tratamento de Conte√∫do Din√¢mico

O `SeleniumScrapingTool` √© especialmente √∫til para extrair sites com conte√∫do din√¢mico carregado via JavaScript. Usando uma inst√¢ncia real de navegador, ele pode:

1. Executar JavaScript na p√°gina
2. Aguardar o carregamento do conte√∫do din√¢mico
3. Interagir com elementos se necess√°rio
4. Extrair conte√∫do que n√£o estaria dispon√≠vel usando apenas requisi√ß√µes HTTP simples

Voc√™ pode ajustar o par√¢metro `wait_time` para garantir que todo o conte√∫do din√¢mico tenha sido carregado antes da extra√ß√£o.

## Conclus√£o

O `SeleniumScrapingTool` fornece uma maneira poderosa de extrair conte√∫do de sites utilizando automa√ß√£o de navegador. Ao permitir que agentes interajam com sites como um usu√°rio real, ele facilita a raspagem de conte√∫do din√¢mico que seria dif√≠cil ou imposs√≠vel de extrair utilizando m√©todos mais simples. Esta ferramenta √© especialmente √∫til para pesquisas, coleta de dados e tarefas de monitoramento que envolvem aplica√ß√µes web modernas com conte√∫do renderizado por JavaScript.


# Spider Scraper
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/spidertool

O `SpiderTool` foi projetado para extrair e ler o conte√∫do de um site especificado usando o Spider.

# `SpiderTool`

## Descri√ß√£o

[Spider](https://spider.cloud/?ref=crewai) √© o [scraper](https://github.com/spider-rs/spider/blob/main/benches/BENCHMARKS.md#benchmark-results) e crawler de c√≥digo aberto mais r√°pido que retorna dados prontos para LLM.\
Ele converte qualquer site em HTML puro, markdown, metadados ou texto e permite que voc√™ fa√ßa crawling com a√ß√µes personalizadas utilizando IA.

## Instala√ß√£o

Para usar o `SpiderTool` voc√™ precisa baixar o [Spider SDK](https://pypi.org/project/spider-client/)\
e tamb√©m o SDK `crewai[tools]`:

```shell
pip install spider-client 'crewai[tools]'
```

## Exemplo

Este exemplo mostra como voc√™ pode usar o `SpiderTool` para permitir que seu agente fa√ßa scraping e crawling de websites.\
Os dados retornados pela API do Spider j√° est√£o prontos para LLM, ent√£o n√£o √© necess√°rio fazer nenhuma limpeza adicional.

```python Code
from crewai_tools import SpiderTool

def main():
    spider_tool = SpiderTool()

    searcher = Agent(
        role="Web Research Expert",
        goal="Find related information from specific URL's",
        backstory="An expert web researcher that uses the web extremely well",
        tools=[spider_tool],
        verbose=True,
    )

    return_metadata = Task(
        description="Scrape https://spider.cloud with a limit of 1 and enable metadata",
        expected_output="Metadata and 10 word summary of spider.cloud",
        agent=searcher
    )

    crew = Crew(
        agents=[searcher],
        tasks=[
            return_metadata,
        ],
        verbose=2
    )

    crew.kickoff()

if __name__ == "__main__":
    main()
```

## Argumentos

| Argumento               | Tipo     | Descri√ß√£o                                                                                                                                                       |
| :---------------------- | :------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **api\_key**            | `string` | Especifica a chave da API do Spider. Se n√£o for definida, procura por `SPIDER_API_KEY` nas vari√°veis de ambiente.                                               |
| **params**              | `object` | Par√¢metros opcionais para a requisi√ß√£o. O padr√£o √© `{"return_format": "markdown"}` para otimizar o conte√∫do para LLMs.                                          |
| **request**             | `string` | Tipo de requisi√ß√£o a ser realizada (`http`, `chrome`, `smart`). `smart` tem como padr√£o HTTP, alterando para renderiza√ß√£o JavaScript se necess√°rio.             |
| **limit**               | `int`    | M√°ximo de p√°ginas a serem rastreadas por site. Defina como `0` ou omita para ilimitado.                                                                         |
| **depth**               | `int`    | Profundidade m√°xima do crawl. Defina como `0` para sem limite.                                                                                                  |
| **cache**               | `bool`   | Habilita cache HTTP para acelerar execu√ß√µes repetidas. O padr√£o √© `true`.                                                                                       |
| **budget**              | `object` | Define limites baseados em caminho para p√°ginas rastreadas, ex.: `{"*":1}` apenas para a p√°gina raiz.                                                           |
| **locale**              | `string` | Localidade da requisi√ß√£o, ex.: `en-US`.                                                                                                                         |
| **cookies**             | `string` | Cookies HTTP para a requisi√ß√£o.                                                                                                                                 |
| **stealth**             | `bool`   | Habilita modo furtivo para requisi√ß√µes Chrome para evitar detec√ß√£o. O padr√£o √© `true`.                                                                          |
| **headers**             | `object` | Headers HTTP como um mapa de chave-valor para todas as requisi√ß√µes.                                                                                             |
| **metadata**            | `bool`   | Armazena metadados sobre as p√°ginas e conte√∫dos, auxiliando interoperabilidade com IA. O padr√£o √© `false`.                                                      |
| **viewport**            | `object` | Define as dimens√µes de viewport do Chrome. O padr√£o √© `800x600`.                                                                                                |
| **encoding**            | `string` | Especifica o tipo de codifica√ß√£o, ex.: `UTF-8`, `SHIFT_JIS`.                                                                                                    |
| **subdomains**          | `bool`   | Inclui subdom√≠nios no crawl. O padr√£o √© `false`.                                                                                                                |
| **user\_agent**         | `string` | User agent HTTP personalizado. Padr√£o √© um agente aleat√≥rio.                                                                                                    |
| **store\_data**         | `bool`   | Habilita o armazenamento dos dados para a requisi√ß√£o. Sobrescreve `storageless` quando definido. O padr√£o √© `false`.                                            |
| **gpt\_config**         | `object` | Permite √† IA gerar a√ß√µes de crawl, com encadeamento de etapas opcional via array para `"prompt"`.                                                               |
| **fingerprint**         | `bool`   | Habilita fingerprint avan√ßado para o Chrome.                                                                                                                    |
| **storageless**         | `bool`   | Impede todo o armazenamento de dados, incluindo embeddings de IA. O padr√£o √© `false`.                                                                           |
| **readability**         | `bool`   | Pr√©-processa conte√∫do para leitura via [Mozilla‚Äôs readability](https://github.com/mozilla/readability). Melhora o conte√∫do para LLMs.                           |
| **return\_format**      | `string` | Formato para retorno dos dados: `markdown`, `raw`, `text`, `html2text`. Use `raw` para formato padr√£o da p√°gina.                                                |
| **proxy\_enabled**      | `bool`   | Habilita proxies de alta performance para evitar bloqueios em n√≠vel de rede.                                                                                    |
| **query\_selector**     | `string` | CSS query selector para extra√ß√£o de conte√∫do a partir do markup.                                                                                                |
| **full\_resources**     | `bool`   | Baixa todos os recursos vinculados ao site.                                                                                                                     |
| **request\_timeout**    | `int`    | Timeout em segundos para as requisi√ß√µes (5-60). O padr√£o √© `30`.                                                                                                |
| **run\_in\_background** | `bool`   | Executa a requisi√ß√£o em segundo plano. √ötil para armazenamento de dados e acionamento de crawls no dashboard. N√£o tem efeito se `storageless` estiver definido. |


# Ferramenta Stagehand
Source: https://docs.crewai.com/pt-BR/tools/web-scraping/stagehandtool

Ferramenta de automa√ß√£o web que integra o Stagehand ao CrewAI para intera√ß√£o e automa√ß√£o em navegadores

# Vis√£o Geral

A `StagehandTool` integra o framework [Stagehand](https://docs.stagehand.dev/get_started/introduction) com o CrewAI, permitindo que agentes interajam com sites e automatizem tarefas no navegador utilizando instru√ß√µes em linguagem natural.

## Vis√£o Geral

O Stagehand √© um poderoso framework de automa√ß√£o de navegador criado pela Browserbase que permite aos agentes de IA:

* Navegar por sites
* Clicar em bot√µes, links e outros elementos
* Preencher formul√°rios
* Extrair dados de p√°ginas web
* Observar e identificar elementos
* Realizar fluxos de trabalho complexos

A StagehandTool encapsula o SDK Python do Stagehand para fornecer aos agentes do CrewAI capacidades de controle do navegador atrav√©s de tr√™s primitivas principais:

1. **Act**: Executar a√ß√µes como clicar, digitar ou navegar
2. **Extract**: Extrair dados estruturados de p√°ginas web
3. **Observe**: Identificar e analisar elementos na p√°gina

## Pr√©-requisitos

Antes de utilizar esta ferramenta, certifique-se de que voc√™ possui:

1. Uma conta [Browserbase](https://www.browserbase.com/) com chave API e ID de projeto
2. Uma chave API para um LLM (OpenAI ou Anthropic Claude)
3. O SDK Python do Stagehand instalado

Instale a depend√™ncia necess√°ria:

```bash
pip install stagehand-py
```

## Uso

### Implementa√ß√£o B√°sica

A StagehandTool pode ser implementada de duas maneiras:

#### 1. Usando Context Manager (Recomendado)

<Tip>
  A abordagem de context manager √© recomendada, pois garante o encerramento adequado dos recursos mesmo em caso de exce√ß√µes.
</Tip>

```python
from crewai import Agent, Task, Crew
from crewai_tools import StagehandTool
from stagehand.schemas import AvailableModel

# Initialize the tool with your API keys using a context manager
with StagehandTool(
    api_key="your-browserbase-api-key",
    project_id="your-browserbase-project-id",
    model_api_key="your-llm-api-key",  # OpenAI or Anthropic API key
    model_name=AvailableModel.CLAUDE_3_7_SONNET_LATEST,  # Optional: specify which model to use
) as stagehand_tool:
    # Create an agent with the tool
    researcher = Agent(
        role="Web Researcher",
        goal="Find and summarize information from websites",
        backstory="I'm an expert at finding information online.",
        verbose=True,
        tools=[stagehand_tool],
    )

    # Create a task that uses the tool
    research_task = Task(
        description="Go to https://www.example.com and tell me what you see on the homepage.",
        agent=researcher,
    )

    # Run the crew
    crew = Crew(
        agents=[researcher],
        tasks=[research_task],
        verbose=True,
    )

    result = crew.kickoff()
    print(result)
```

#### 2. Gerenciamento Manual de Recursos

```python
from crewai import Agent, Task, Crew
from crewai_tools import StagehandTool
from stagehand.schemas import AvailableModel

# Initialize the tool with your API keys
stagehand_tool = StagehandTool(
    api_key="your-browserbase-api-key",
    project_id="your-browserbase-project-id",
    model_api_key="your-llm-api-key",
    model_name=AvailableModel.CLAUDE_3_7_SONNET_LATEST,
)

try:
    # Create an agent with the tool
    researcher = Agent(
        role="Web Researcher",
        goal="Find and summarize information from websites",
        backstory="I'm an expert at finding information online.",
        verbose=True,
        tools=[stagehand_tool],
    )

    # Create a task that uses the tool
    research_task = Task(
        description="Go to https://www.example.com and tell me what you see on the homepage.",
        agent=researcher,
    )

    # Run the crew
    crew = Crew(
        agents=[researcher],
        tasks=[research_task],
        verbose=True,
    )

    result = crew.kickoff()
    print(result)
finally:
    # Explicitly clean up resources
    stagehand_tool.close()
```

## Tipos de Comando

A StagehandTool suporta tr√™s tipos diferentes de comando para tarefas espec√≠ficas de automa√ß√£o web:

### 1. Comando Act

O tipo de comando `act` (padr√£o) permite intera√ß√µes em p√°ginas web como clicar em bot√µes, preencher formul√°rios e navegar.

```python
# Perform an action (default behavior)
result = stagehand_tool.run(
    instruction="Click the login button",
    url="https://example.com",
    command_type="act"  # Default, so can be omitted
)

# Fill out a form
result = stagehand_tool.run(
    instruction="Fill the contact form with name 'John Doe', email 'john@example.com', and message 'Hello world'",
    url="https://example.com/contact"
)
```

### 2. Comando Extract

O tipo de comando `extract` recupera dados estruturados de p√°ginas web.

```python
# Extract all product information
result = stagehand_tool.run(
    instruction="Extract all product names, prices, and descriptions",
    url="https://example.com/products",
    command_type="extract"
)

# Extract specific information with a selector
result = stagehand_tool.run(
    instruction="Extract the main article title and content",
    url="https://example.com/blog/article",
    command_type="extract",
    selector=".article-container"  # Optional CSS selector
)
```

### 3. Comando Observe

O tipo de comando `observe` identifica e analisa elementos da p√°gina web.

```python
# Find interactive elements
result = stagehand_tool.run(
    instruction="Find all interactive elements in the navigation menu",
    url="https://example.com",
    command_type="observe"
)

# Identify form fields
result = stagehand_tool.run(
    instruction="Identify all the input fields in the registration form",
    url="https://example.com/register",
    command_type="observe",
    selector="#registration-form"
)
```

## Op√ß√µes de Configura√ß√£o

Personalize o comportamento da StagehandTool com estes par√¢metros:

```python
stagehand_tool = StagehandTool(
    api_key="your-browserbase-api-key",
    project_id="your-browserbase-project-id",
    model_api_key="your-llm-api-key",
    model_name=AvailableModel.CLAUDE_3_7_SONNET_LATEST,
    dom_settle_timeout_ms=5000,  # Wait longer for DOM to settle
    headless=True,  # Run browser in headless mode
    self_heal=True,  # Attempt to recover from errors
    wait_for_captcha_solves=True,  # Wait for CAPTCHA solving
    verbose=1,  # Control logging verbosity (0-3)
)
```

## Boas Pr√°ticas

1. **Seja Espec√≠fico**: Forne√ßa instru√ß√µes detalhadas para melhores resultados
2. **Escolha o Tipo de Comando Apropriado**: Selecione o comando correto para sua tarefa
3. **Use Selectors**: Utilize seletores CSS para aumentar a precis√£o
4. **Divida Tarefas Complexas**: Separe fluxos de trabalho complexos em m√∫ltiplas chamadas da ferramenta
5. **Implemente Tratamento de Erros**: Adicione tratamento de erros para poss√≠veis problemas

## Solu√ß√£o de Problemas

Problemas comuns e solu√ß√µes:

* **Problemas de Sess√£o**: Verifique as chaves de API tanto da Browserbase quanto do provedor de LLM
* **Elemento N√£o Encontrado**: Aumente o `dom_settle_timeout_ms` para p√°ginas mais lentas
* **Falhas em A√ß√µes**: Use o `observe` para identificar corretamente os elementos antes
* **Dados Incompletos**: Refine as instru√ß√µes ou forne√ßa seletores espec√≠ficos

## Recursos Adicionais

Para d√∫vidas sobre a integra√ß√£o com o CrewAI:

* Participe da comunidade [Slack do Stagehand](https://stagehand.dev/slack)
* Abra uma issue no [reposit√≥rio Stagehand](https://github.com/browserbase/stagehand)
* Visite a [documenta√ß√£o do Stagehand](https://docs.stagehand.dev/)
